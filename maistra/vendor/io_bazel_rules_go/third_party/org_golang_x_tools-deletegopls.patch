diff -urN a/gopls/README.md b/gopls/README.md
--- a/gopls/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/README.md	1969-12-31 16:00:00
@@ -1,131 +0,0 @@
-# `gopls`, the Go language server
-
-[![PkgGoDev](https://pkg.go.dev/badge/golang.org/x/tools/gopls)](https://pkg.go.dev/golang.org/x/tools/gopls)
-
-`gopls` (pronounced "Go please") is the official Go [language server] developed
-by the Go team. It provides IDE features to any [LSP]-compatible editor.
-
-<!--TODO(rfindley): Add gifs here.-->
-
-You should not need to interact with `gopls` directly--it will be automatically
-integrated into your editor. The specific features and settings vary slightly
-by editor, so we recommend that you proceed to the
-[documentation for your editor](#editors) below.
-
-## Editors
-
-To get started with `gopls`, install an LSP plugin in your editor of choice.
-
-* [VS Code](https://github.com/golang/vscode-go/blob/master/README.md)
-* [Vim / Neovim](doc/vim.md)
-* [Emacs](doc/emacs.md)
-* [Atom](https://github.com/MordFustang21/ide-gopls)
-* [Sublime Text](doc/subl.md)
-* [Acme](https://github.com/fhs/acme-lsp)
-* [Lapce](https://github.com/lapce-community/lapce-go)
-
-If you use `gopls` with an editor that is not on this list, please send us a CL
-[updating this documentation](doc/contributing.md).
-
-## Installation
-
-For the most part, you should not need to install or update `gopls`. Your
-editor should handle that step for you.
-
-If you do want to get the latest stable version of `gopls`, run the following
-command:
-
-```sh
-go install golang.org/x/tools/gopls@latest
-```
-
-Learn more in the
-[advanced installation instructions](doc/advanced.md#installing-unreleased-versions).
-
-Learn more about gopls releases in the [release policy](doc/releases.md).
-
-## Setting up your workspace
-
-`gopls` supports both Go module, multi-module and GOPATH modes. See the
-[workspace documentation](doc/workspace.md) for information on supported
-workspace layouts.
-
-## Configuration
-
-You can configure `gopls` to change your editor experience or view additional
-debugging information. Configuration options will be made available by your
-editor, so see your [editor's instructions](#editors) for specific details. A
-full list of `gopls` settings can be found in the [settings documentation](doc/settings.md).
-
-### Environment variables
-
-`gopls` inherits your editor's environment, so be aware of any environment
-variables you configure. Some editors, such as VS Code, allow users to
-selectively override the values of some environment variables.
-
-## Support Policy
-
-Gopls is maintained by engineers on the
-[Go tools team](https://github.com/orgs/golang/teams/tools-team/members),
-who actively monitor the
-[Go](https://github.com/golang/go/issues?q=is%3Aissue+is%3Aopen+label%3Agopls)
-and
-[VS Code Go](https://github.com/golang/vscode-go/issues) issue trackers.
-
-### Supported Go versions
-
-`gopls` follows the
-[Go Release Policy](https://golang.org/doc/devel/release.html#policy),
-meaning that it officially supports the last 2 major Go releases. Per
-[issue #39146](https://go.dev/issues/39146), we attempt to maintain best-effort
-support for the last 4 major Go releases, but this support extends only to not
-breaking the build and avoiding easily fixable regressions.
-
-In the context of this discussion, gopls "supports" a Go version if it supports
-being built with that Go version as well as integrating with the `go` command
-of that Go version.
-
-The following table shows the final gopls version that supports a given Go
-version. Go releases more recent than any in the table can be used with any
-version of gopls.
-
-| Go Version  | Final gopls version with support (without warnings) |
-| ----------- | --------------------------------------------------- |
-| Go 1.12     | [gopls@v0.7.5](https://github.com/golang/tools/releases/tag/gopls%2Fv0.7.5) |
-| Go 1.15     | [gopls@v0.9.5](https://github.com/golang/tools/releases/tag/gopls%2Fv0.9.5) |
-
-Our extended support is enforced via [continuous integration with older Go
-versions](doc/contributing.md#ci). This legacy Go CI may not block releases:
-test failures may be skipped rather than fixed. Furthermore, if a regression in
-an older Go version causes irreconcilable CI failures, we may drop support for
-that Go version in CI if it is 3 or 4 Go versions old.
-
-### Supported build systems
-
-`gopls` currently only supports the `go` command, so if you are using
-a different build system, `gopls` will not work well. Bazel is not officially
-supported, but may be made to work with an appropriately configured
-`go/packages` driver. See
-[bazelbuild/rules_go#512](https://github.com/bazelbuild/rules_go/issues/512)
-for more information.
-You can follow [these instructions](https://github.com/bazelbuild/rules_go/wiki/Editor-setup)
-to configure your `gopls` to work with Bazel.
-
-### Troubleshooting
-
-If you are having issues with `gopls`, please follow the steps described in the
-[troubleshooting guide](doc/troubleshooting.md).
-
-## Additional information
-
-* [Features](doc/features.md)
-* [Command-line interface](doc/command-line.md)
-* [Advanced topics](doc/advanced.md)
-* [Contributing to `gopls`](doc/contributing.md)
-* [Integrating `gopls` with an editor](doc/design/integrating.md)
-* [Design requirements and decisions](doc/design/design.md)
-* [Implementation details](doc/design/implementation.md)
-* [Open issues](https://github.com/golang/go/issues?q=is%3Aissue+is%3Aopen+label%3Agopls)
-
-[language server]: https://langserver.org
-[LSP]: https://microsoft.github.io/language-server-protocol/
diff -urN a/gopls/api-diff/api_diff.go b/gopls/api-diff/api_diff.go
--- a/gopls/api-diff/api_diff.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/api-diff/api_diff.go	1969-12-31 16:00:00
@@ -1,89 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package main
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"log"
-	"os"
-	"os/exec"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-const usage = `api-diff <previous version> [<current version>]
-
-Compare the API of two gopls versions. If the second argument is provided, it
-will be used as the new version to compare against. Otherwise, compare against
-the current API.
-`
-
-func main() {
-	flag.Parse()
-
-	if flag.NArg() < 1 || flag.NArg() > 2 {
-		fmt.Fprint(os.Stderr, usage)
-		os.Exit(2)
-	}
-
-	oldVer := flag.Arg(0)
-	newVer := ""
-	if flag.NArg() == 2 {
-		newVer = flag.Arg(1)
-	}
-
-	apiDiff, err := diffAPI(oldVer, newVer)
-	if err != nil {
-		log.Fatal(err)
-	}
-	fmt.Println("\n" + apiDiff)
-}
-
-func diffAPI(oldVer, newVer string) (string, error) {
-	ctx := context.Background()
-	previousAPI, err := loadAPI(ctx, oldVer)
-	if err != nil {
-		return "", fmt.Errorf("loading %s: %v", oldVer, err)
-	}
-	var currentAPI *source.APIJSON
-	if newVer == "" {
-		currentAPI = source.GeneratedAPIJSON
-	} else {
-		var err error
-		currentAPI, err = loadAPI(ctx, newVer)
-		if err != nil {
-			return "", fmt.Errorf("loading %s: %v", newVer, err)
-		}
-	}
-
-	return cmp.Diff(previousAPI, currentAPI), nil
-}
-
-func loadAPI(ctx context.Context, version string) (*source.APIJSON, error) {
-	ver := fmt.Sprintf("golang.org/x/tools/gopls@%s", version)
-	cmd := exec.Command("go", "run", ver, "api-json")
-
-	stdout := &bytes.Buffer{}
-	stderr := &bytes.Buffer{}
-	cmd.Stdout = stdout
-	cmd.Stderr = stderr
-
-	if err := cmd.Run(); err != nil {
-		return nil, fmt.Errorf("go run failed: %v; stderr:\n%s", err, stderr)
-	}
-	apiJson := &source.APIJSON{}
-	if err := json.Unmarshal(stdout.Bytes(), apiJson); err != nil {
-		return nil, fmt.Errorf("unmarshal: %v", err)
-	}
-	return apiJson, nil
-}
diff -urN a/gopls/doc/advanced.md b/gopls/doc/advanced.md
--- a/gopls/doc/advanced.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/advanced.md	1969-12-31 16:00:00
@@ -1,69 +0,0 @@
-# Advanced topics
-
-This documentation is for advanced `gopls` users, who may want to test
-unreleased versions or try out special features.
-
-## Installing unreleased versions
-
-To get a specific version of `gopls` (for example, to test a prerelease
-version), run:
-
-```sh
-GO111MODULE=on go install golang.org/x/tools/gopls@vX.Y.Z
-```
-
-Where `vX.Y.Z` is the desired version.
-
-### Unstable versions
-
-To update `gopls` to the latest **unstable** version, use the following
-commands.
-
-```sh
-# Create an empty go.mod file, only for tracking requirements.
-cd $(mktemp -d)
-go mod init gopls-unstable
-
-# Use 'go get' to add requirements and to ensure they work together.
-go get -d golang.org/x/tools/gopls@master golang.org/x/tools@master
-
-go install golang.org/x/tools/gopls
-```
-
-## Working on the Go source distribution
-
-If you are working on the [Go project] itself, the `go` command that `gopls`
-invokes will have to correspond to the version of the source you are working
-on. That is, if you have checked out the Go project to `$HOME/go`, your `go`
-command should be the `$HOME/go/bin/go` executable that you built with
-`make.bash` or equivalent.
-
-You can achieve this by adding the right version of `go` to your `PATH`
-(`export PATH=$HOME/go/bin:$PATH` on Unix systems) or by configuring your
-editor.
-
-## Working with generic code
-
-Gopls has support for editing generic Go code. To enable this support, you need
-to **install gopls using Go 1.18 or later**. The easiest way to do this is by
-[installing Go 1.18+](https://go.dev/dl) and then using this Go version to
-install gopls:
-
-```
-$ go install golang.org/x/tools/gopls@latest
-```
-
-It is strongly recommended that you install the latest version of `gopls`, or
-the latest **unstable** version as [described above](#installing-unreleased-versions).
-We're still working on improving our generics support.
-
-The `gopls` built with these instructions understands generic code. See the
-[generics tutorial](https://go.dev/doc/tutorial/generics) for more information
-on how to use generics in Go!
-
-### Known issues
-
-  * [`staticcheck`](https://github.com/golang/tools/blob/master/gopls/doc/settings.md#staticcheck-bool)
-    on generic code is not supported yet.
-
-[Go project]: https://go.googlesource.com/go
diff -urN a/gopls/doc/analyzers.md b/gopls/doc/analyzers.md
--- a/gopls/doc/analyzers.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/analyzers.md	1969-12-31 16:00:00
@@ -1,742 +0,0 @@
-# Analyzers
-
-This document describes the analyzers that `gopls` uses inside the editor.
-
-Details about how to enable/disable these analyses can be found
-[here](settings.md#analyses).
-
-<!-- BEGIN Analyzers: DO NOT MANUALLY EDIT THIS SECTION -->
-## **asmdecl**
-
-report mismatches between assembly files and Go declarations
-
-**Enabled by default.**
-
-## **assign**
-
-check for useless assignments
-
-This checker reports assignments of the form x = x or a[i] = a[i].
-These are almost always useless, and even when they aren't they are
-usually a mistake.
-
-**Enabled by default.**
-
-## **atomic**
-
-check for common mistakes using the sync/atomic package
-
-The atomic checker looks for assignment statements of the form:
-
-	x = atomic.AddUint64(&x, 1)
-
-which are not atomic.
-
-**Enabled by default.**
-
-## **atomicalign**
-
-check for non-64-bits-aligned arguments to sync/atomic functions
-
-**Enabled by default.**
-
-## **bools**
-
-check for common mistakes involving boolean operators
-
-**Enabled by default.**
-
-## **buildtag**
-
-check that +build tags are well-formed and correctly located
-
-**Enabled by default.**
-
-## **cgocall**
-
-detect some violations of the cgo pointer passing rules
-
-Check for invalid cgo pointer passing.
-This looks for code that uses cgo to call C code passing values
-whose types are almost always invalid according to the cgo pointer
-sharing rules.
-Specifically, it warns about attempts to pass a Go chan, map, func,
-or slice to C, either directly, or via a pointer, array, or struct.
-
-**Enabled by default.**
-
-## **composites**
-
-check for unkeyed composite literals
-
-This analyzer reports a diagnostic for composite literals of struct
-types imported from another package that do not use the field-keyed
-syntax. Such literals are fragile because the addition of a new field
-(even if unexported) to the struct will cause compilation to fail.
-
-As an example,
-
-	err = &net.DNSConfigError{err}
-
-should be replaced by:
-
-	err = &net.DNSConfigError{Err: err}
-
-
-**Enabled by default.**
-
-## **copylocks**
-
-check for locks erroneously passed by value
-
-Inadvertently copying a value containing a lock, such as sync.Mutex or
-sync.WaitGroup, may cause both copies to malfunction. Generally such
-values should be referred to through a pointer.
-
-**Enabled by default.**
-
-## **deepequalerrors**
-
-check for calls of reflect.DeepEqual on error values
-
-The deepequalerrors checker looks for calls of the form:
-
-    reflect.DeepEqual(err1, err2)
-
-where err1 and err2 are errors. Using reflect.DeepEqual to compare
-errors is discouraged.
-
-**Enabled by default.**
-
-## **embed**
-
-check for //go:embed directive import
-
-This analyzer checks that the embed package is imported when source code contains //go:embed comment directives.
-The embed package must be imported for //go:embed directives to function.import _ "embed".
-
-**Enabled by default.**
-
-## **errorsas**
-
-report passing non-pointer or non-error values to errors.As
-
-The errorsas analysis reports calls to errors.As where the type
-of the second argument is not a pointer to a type implementing error.
-
-**Enabled by default.**
-
-## **fieldalignment**
-
-find structs that would use less memory if their fields were sorted
-
-This analyzer find structs that can be rearranged to use less memory, and provides
-a suggested edit with the most compact order.
-
-Note that there are two different diagnostics reported. One checks struct size,
-and the other reports "pointer bytes" used. Pointer bytes is how many bytes of the
-object that the garbage collector has to potentially scan for pointers, for example:
-
-	struct { uint32; string }
-
-have 16 pointer bytes because the garbage collector has to scan up through the string's
-inner pointer.
-
-	struct { string; *uint32 }
-
-has 24 pointer bytes because it has to scan further through the *uint32.
-
-	struct { string; uint32 }
-
-has 8 because it can stop immediately after the string pointer.
-
-Be aware that the most compact order is not always the most efficient.
-In rare cases it may cause two variables each updated by its own goroutine
-to occupy the same CPU cache line, inducing a form of memory contention
-known as "false sharing" that slows down both goroutines.
-
-
-**Disabled by default. Enable it by setting `"analyses": {"fieldalignment": true}`.**
-
-## **httpresponse**
-
-check for mistakes using HTTP responses
-
-A common mistake when using the net/http package is to defer a function
-call to close the http.Response Body before checking the error that
-determines whether the response is valid:
-
-	resp, err := http.Head(url)
-	defer resp.Body.Close()
-	if err != nil {
-		log.Fatal(err)
-	}
-	// (defer statement belongs here)
-
-This checker helps uncover latent nil dereference bugs by reporting a
-diagnostic for such mistakes.
-
-**Enabled by default.**
-
-## **ifaceassert**
-
-detect impossible interface-to-interface type assertions
-
-This checker flags type assertions v.(T) and corresponding type-switch cases
-in which the static type V of v is an interface that cannot possibly implement
-the target interface T. This occurs when V and T contain methods with the same
-name but different signatures. Example:
-
-	var v interface {
-		Read()
-	}
-	_ = v.(io.Reader)
-
-The Read method in v has a different signature than the Read method in
-io.Reader, so this assertion cannot succeed.
-
-
-**Enabled by default.**
-
-## **infertypeargs**
-
-check for unnecessary type arguments in call expressions
-
-Explicit type arguments may be omitted from call expressions if they can be
-inferred from function arguments, or from other type arguments:
-
-	func f[T any](T) {}
-	
-	func _() {
-		f[string]("foo") // string could be inferred
-	}
-
-
-**Enabled by default.**
-
-## **loopclosure**
-
-check references to loop variables from within nested functions
-
-This analyzer reports places where a function literal references the
-iteration variable of an enclosing loop, and the loop calls the function
-in such a way (e.g. with go or defer) that it may outlive the loop
-iteration and possibly observe the wrong value of the variable.
-
-In this example, all the deferred functions run after the loop has
-completed, so all observe the final value of v.
-
-    for _, v := range list {
-        defer func() {
-            use(v) // incorrect
-        }()
-    }
-
-One fix is to create a new variable for each iteration of the loop:
-
-    for _, v := range list {
-        v := v // new var per iteration
-        defer func() {
-            use(v) // ok
-        }()
-    }
-
-The next example uses a go statement and has a similar problem.
-In addition, it has a data race because the loop updates v
-concurrent with the goroutines accessing it.
-
-    for _, v := range elem {
-        go func() {
-            use(v)  // incorrect, and a data race
-        }()
-    }
-
-A fix is the same as before. The checker also reports problems
-in goroutines started by golang.org/x/sync/errgroup.Group.
-A hard-to-spot variant of this form is common in parallel tests:
-
-    func Test(t *testing.T) {
-        for _, test := range tests {
-            t.Run(test.name, func(t *testing.T) {
-                t.Parallel()
-                use(test) // incorrect, and a data race
-            })
-        }
-    }
-
-The t.Parallel() call causes the rest of the function to execute
-concurrent with the loop.
-
-The analyzer reports references only in the last statement,
-as it is not deep enough to understand the effects of subsequent
-statements that might render the reference benign.
-("Last statement" is defined recursively in compound
-statements such as if, switch, and select.)
-
-See: https://golang.org/doc/go_faq.html#closures_and_goroutines
-
-**Enabled by default.**
-
-## **lostcancel**
-
-check cancel func returned by context.WithCancel is called
-
-The cancellation function returned by context.WithCancel, WithTimeout,
-and WithDeadline must be called or the new context will remain live
-until its parent context is cancelled.
-(The background context is never cancelled.)
-
-**Enabled by default.**
-
-## **nilfunc**
-
-check for useless comparisons between functions and nil
-
-A useless comparison is one like f == nil as opposed to f() == nil.
-
-**Enabled by default.**
-
-## **nilness**
-
-check for redundant or impossible nil comparisons
-
-The nilness checker inspects the control-flow graph of each function in
-a package and reports nil pointer dereferences, degenerate nil
-pointers, and panics with nil values. A degenerate comparison is of the form
-x==nil or x!=nil where x is statically known to be nil or non-nil. These are
-often a mistake, especially in control flow related to errors. Panics with nil
-values are checked because they are not detectable by
-
-	if r := recover(); r != nil {
-
-This check reports conditions such as:
-
-	if f == nil { // impossible condition (f is a function)
-	}
-
-and:
-
-	p := &v
-	...
-	if p != nil { // tautological condition
-	}
-
-and:
-
-	if p == nil {
-		print(*p) // nil dereference
-	}
-
-and:
-
-	if p == nil {
-		panic(p)
-	}
-
-
-**Disabled by default. Enable it by setting `"analyses": {"nilness": true}`.**
-
-## **printf**
-
-check consistency of Printf format strings and arguments
-
-The check applies to known functions (for example, those in package fmt)
-as well as any detected wrappers of known functions.
-
-A function that wants to avail itself of printf checking but is not
-found by this analyzer's heuristics (for example, due to use of
-dynamic calls) can insert a bogus call:
-
-	if false {
-		_ = fmt.Sprintf(format, args...) // enable printf checking
-	}
-
-The -funcs flag specifies a comma-separated list of names of additional
-known formatting functions or methods. If the name contains a period,
-it must denote a specific function using one of the following forms:
-
-	dir/pkg.Function
-	dir/pkg.Type.Method
-	(*dir/pkg.Type).Method
-
-Otherwise the name is interpreted as a case-insensitive unqualified
-identifier such as "errorf". Either way, if a listed name ends in f, the
-function is assumed to be Printf-like, taking a format string before the
-argument list. Otherwise it is assumed to be Print-like, taking a list
-of arguments with no format string.
-
-
-**Enabled by default.**
-
-## **shadow**
-
-check for possible unintended shadowing of variables
-
-This analyzer check for shadowed variables.
-A shadowed variable is a variable declared in an inner scope
-with the same name and type as a variable in an outer scope,
-and where the outer variable is mentioned after the inner one
-is declared.
-
-(This definition can be refined; the module generates too many
-false positives and is not yet enabled by default.)
-
-For example:
-
-	func BadRead(f *os.File, buf []byte) error {
-		var err error
-		for {
-			n, err := f.Read(buf) // shadows the function variable 'err'
-			if err != nil {
-				break // causes return of wrong value
-			}
-			foo(buf)
-		}
-		return err
-	}
-
-
-**Disabled by default. Enable it by setting `"analyses": {"shadow": true}`.**
-
-## **shift**
-
-check for shifts that equal or exceed the width of the integer
-
-**Enabled by default.**
-
-## **simplifycompositelit**
-
-check for composite literal simplifications
-
-An array, slice, or map composite literal of the form:
-	[]T{T{}, T{}}
-will be simplified to:
-	[]T{{}, {}}
-
-This is one of the simplifications that "gofmt -s" applies.
-
-**Enabled by default.**
-
-## **simplifyrange**
-
-check for range statement simplifications
-
-A range of the form:
-	for x, _ = range v {...}
-will be simplified to:
-	for x = range v {...}
-
-A range of the form:
-	for _ = range v {...}
-will be simplified to:
-	for range v {...}
-
-This is one of the simplifications that "gofmt -s" applies.
-
-**Enabled by default.**
-
-## **simplifyslice**
-
-check for slice simplifications
-
-A slice expression of the form:
-	s[a:len(s)]
-will be simplified to:
-	s[a:]
-
-This is one of the simplifications that "gofmt -s" applies.
-
-**Enabled by default.**
-
-## **sortslice**
-
-check the argument type of sort.Slice
-
-sort.Slice requires an argument of a slice type. Check that
-the interface{} value passed to sort.Slice is actually a slice.
-
-**Enabled by default.**
-
-## **stdmethods**
-
-check signature of methods of well-known interfaces
-
-Sometimes a type may be intended to satisfy an interface but may fail to
-do so because of a mistake in its method signature.
-For example, the result of this WriteTo method should be (int64, error),
-not error, to satisfy io.WriterTo:
-
-	type myWriterTo struct{...}
-        func (myWriterTo) WriteTo(w io.Writer) error { ... }
-
-This check ensures that each method whose name matches one of several
-well-known interface methods from the standard library has the correct
-signature for that interface.
-
-Checked method names include:
-	Format GobEncode GobDecode MarshalJSON MarshalXML
-	Peek ReadByte ReadFrom ReadRune Scan Seek
-	UnmarshalJSON UnreadByte UnreadRune WriteByte
-	WriteTo
-
-
-**Enabled by default.**
-
-## **stringintconv**
-
-check for string(int) conversions
-
-This checker flags conversions of the form string(x) where x is an integer
-(but not byte or rune) type. Such conversions are discouraged because they
-return the UTF-8 representation of the Unicode code point x, and not a decimal
-string representation of x as one might expect. Furthermore, if x denotes an
-invalid code point, the conversion cannot be statically rejected.
-
-For conversions that intend on using the code point, consider replacing them
-with string(rune(x)). Otherwise, strconv.Itoa and its equivalents return the
-string representation of the value in the desired base.
-
-
-**Enabled by default.**
-
-## **structtag**
-
-check that struct field tags conform to reflect.StructTag.Get
-
-Also report certain struct tags (json, xml) used with unexported fields.
-
-**Enabled by default.**
-
-## **testinggoroutine**
-
-report calls to (*testing.T).Fatal from goroutines started by a test.
-
-Functions that abruptly terminate a test, such as the Fatal, Fatalf, FailNow, and
-Skip{,f,Now} methods of *testing.T, must be called from the test goroutine itself.
-This checker detects calls to these functions that occur within a goroutine
-started by the test. For example:
-
-func TestFoo(t *testing.T) {
-    go func() {
-        t.Fatal("oops") // error: (*T).Fatal called from non-test goroutine
-    }()
-}
-
-
-**Enabled by default.**
-
-## **tests**
-
-check for common mistaken usages of tests and examples
-
-The tests checker walks Test, Benchmark and Example functions checking
-malformed names, wrong signatures and examples documenting non-existent
-identifiers.
-
-Please see the documentation for package testing in golang.org/pkg/testing
-for the conventions that are enforced for Tests, Benchmarks, and Examples.
-
-**Enabled by default.**
-
-## **timeformat**
-
-check for calls of (time.Time).Format or time.Parse with 2006-02-01
-
-The timeformat checker looks for time formats with the 2006-02-01 (yyyy-dd-mm)
-format. Internationally, "yyyy-dd-mm" does not occur in common calendar date
-standards, and so it is more likely that 2006-01-02 (yyyy-mm-dd) was intended.
-
-
-**Enabled by default.**
-
-## **unmarshal**
-
-report passing non-pointer or non-interface values to unmarshal
-
-The unmarshal analysis reports calls to functions such as json.Unmarshal
-in which the argument type is not a pointer or an interface.
-
-**Enabled by default.**
-
-## **unreachable**
-
-check for unreachable code
-
-The unreachable analyzer finds statements that execution can never reach
-because they are preceded by an return statement, a call to panic, an
-infinite loop, or similar constructs.
-
-**Enabled by default.**
-
-## **unsafeptr**
-
-check for invalid conversions of uintptr to unsafe.Pointer
-
-The unsafeptr analyzer reports likely incorrect uses of unsafe.Pointer
-to convert integers to pointers. A conversion from uintptr to
-unsafe.Pointer is invalid if it implies that there is a uintptr-typed
-word in memory that holds a pointer value, because that word will be
-invisible to stack copying and to the garbage collector.
-
-**Enabled by default.**
-
-## **unusedparams**
-
-check for unused parameters of functions
-
-The unusedparams analyzer checks functions to see if there are
-any parameters that are not being used.
-
-To reduce false positives it ignores:
-- methods
-- parameters that do not have a name or are underscored
-- functions in test files
-- functions with empty bodies or those with just a return stmt
-
-**Disabled by default. Enable it by setting `"analyses": {"unusedparams": true}`.**
-
-## **unusedresult**
-
-check for unused results of calls to some functions
-
-Some functions like fmt.Errorf return a result and have no side effects,
-so it is always a mistake to discard the result. This analyzer reports
-calls to certain functions in which the result of the call is ignored.
-
-The set of functions may be controlled using flags.
-
-**Enabled by default.**
-
-## **unusedwrite**
-
-checks for unused writes
-
-The analyzer reports instances of writes to struct fields and
-arrays that are never read. Specifically, when a struct object
-or an array is copied, its elements are copied implicitly by
-the compiler, and any element write to this copy does nothing
-with the original object.
-
-For example:
-
-	type T struct { x int }
-	func f(input []T) {
-		for i, v := range input {  // v is a copy
-			v.x = i  // unused write to field x
-		}
-	}
-
-Another example is about non-pointer receiver:
-
-	type T struct { x int }
-	func (t T) f() {  // t is a copy
-		t.x = i  // unused write to field x
-	}
-
-
-**Disabled by default. Enable it by setting `"analyses": {"unusedwrite": true}`.**
-
-## **useany**
-
-check for constraints that could be simplified to "any"
-
-**Disabled by default. Enable it by setting `"analyses": {"useany": true}`.**
-
-## **fillreturns**
-
-suggest fixes for errors due to an incorrect number of return values
-
-This checker provides suggested fixes for type errors of the
-type "wrong number of return values (want %d, got %d)". For example:
-	func m() (int, string, *bool, error) {
-		return
-	}
-will turn into
-	func m() (int, string, *bool, error) {
-		return 0, "", nil, nil
-	}
-
-This functionality is similar to https://github.com/sqs/goreturns.
-
-
-**Enabled by default.**
-
-## **nonewvars**
-
-suggested fixes for "no new vars on left side of :="
-
-This checker provides suggested fixes for type errors of the
-type "no new vars on left side of :=". For example:
-	z := 1
-	z := 2
-will turn into
-	z := 1
-	z = 2
-
-
-**Enabled by default.**
-
-## **noresultvalues**
-
-suggested fixes for unexpected return values
-
-This checker provides suggested fixes for type errors of the
-type "no result values expected" or "too many return values".
-For example:
-	func z() { return nil }
-will turn into
-	func z() { return }
-
-
-**Enabled by default.**
-
-## **undeclaredname**
-
-suggested fixes for "undeclared name: <>"
-
-This checker provides suggested fixes for type errors of the
-type "undeclared name: <>". It will either insert a new statement,
-such as:
-
-"<> := "
-
-or a new function declaration, such as:
-
-func <>(inferred parameters) {
-	panic("implement me!")
-}
-
-
-**Enabled by default.**
-
-## **unusedvariable**
-
-check for unused variables
-
-The unusedvariable analyzer suggests fixes for unused variables errors.
-
-
-**Disabled by default. Enable it by setting `"analyses": {"unusedvariable": true}`.**
-
-## **fillstruct**
-
-note incomplete struct initializations
-
-This analyzer provides diagnostics for any struct literals that do not have
-any fields initialized. Because the suggested fix for this analysis is
-expensive to compute, callers should compute it separately, using the
-SuggestedFix function below.
-
-
-**Enabled by default.**
-
-## **stubmethods**
-
-stub methods analyzer
-
-This analyzer generates method stubs for concrete types
-in order to implement a target interface
-
-**Enabled by default.**
-
-<!-- END Analyzers: DO NOT MANUALLY EDIT THIS SECTION -->
diff -urN a/gopls/doc/command-line.md b/gopls/doc/command-line.md
--- a/gopls/doc/command-line.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/command-line.md	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-# Command line
-
-**Note: The `gopls` command-line is still experimental and subject to change at any point.**
-
-`gopls` exposes some (but not all) features on the command-line. This can be useful for debugging `gopls` itself.
-
-<!--TODO(rstambler): Generate this file.-->
-
-Learn about available commands and flags by running `gopls help`.
-
-Much of the functionality of `gopls` is available through a command line interface.
-
-There are two main reasons for this. The first is that we do not want users to rely on separate command line tools when they wish to do some task outside of an editor. The second is that the CLI assists in debugging. It is easier to reproduce behavior via single command.
-
-It is not a goal of `gopls` to be a high performance command line tool. Its command line is intended for single file/package user interaction speeds, not bulk processing.
diff -urN a/gopls/doc/commands.md b/gopls/doc/commands.md
--- a/gopls/doc/commands.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/commands.md	1969-12-31 16:00:00
@@ -1,464 +0,0 @@
-# Commands
-
-This document describes the LSP-level commands supported by `gopls`. They cannot be invoked directly by users, and all the details are subject to change, so nobody should rely on this information.
-
-<!-- BEGIN Commands: DO NOT MANUALLY EDIT THIS SECTION -->
-### **Add a dependency**
-Identifier: `gopls.add_dependency`
-
-Adds a dependency to the go.mod file for a module.
-
-Args:
-
-```
-{
-	// The go.mod file URI.
-	"URI": string,
-	// Additional args to pass to the go command.
-	"GoCmdArgs": []string,
-	// Whether to add a require directive.
-	"AddRequire": bool,
-}
-```
-
-### **Add an import**
-Identifier: `gopls.add_import`
-
-Ask the server to add an import path to a given Go file.  The method will
-call applyEdit on the client so that clients don't have to apply the edit
-themselves.
-
-Args:
-
-```
-{
-	// ImportPath is the target import path that should
-	// be added to the URI file
-	"ImportPath": string,
-	// URI is the file that the ImportPath should be
-	// added to
-	"URI": string,
-}
-```
-
-### **Apply a fix**
-Identifier: `gopls.apply_fix`
-
-Applies a fix to a region of source code.
-
-Args:
-
-```
-{
-	// The fix to apply.
-	"Fix": string,
-	// The file URI for the document to fix.
-	"URI": string,
-	// The document range to scan for fixes.
-	"Range": {
-		"start": {
-			"line": uint32,
-			"character": uint32,
-		},
-		"end": {
-			"line": uint32,
-			"character": uint32,
-		},
-	},
-}
-```
-
-### **Check for upgrades**
-Identifier: `gopls.check_upgrades`
-
-Checks for module upgrades.
-
-Args:
-
-```
-{
-	// The go.mod file URI.
-	"URI": string,
-	// The modules to check.
-	"Modules": []string,
-}
-```
-
-### **Run go mod edit -go=version**
-Identifier: `gopls.edit_go_directive`
-
-Runs `go mod edit -go=version` for a module.
-
-Args:
-
-```
-{
-	// Any document URI within the relevant module.
-	"URI": string,
-	// The version to pass to `go mod edit -go`.
-	"Version": string,
-}
-```
-
-### **Get known vulncheck result**
-Identifier: `gopls.fetch_vulncheck_result`
-
-Fetch the result of latest vulnerability check (`govulncheck`).
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-Result:
-
-```
-map[golang.org/x/tools/gopls/internal/lsp/protocol.DocumentURI]*golang.org/x/tools/gopls/internal/govulncheck.Result
-```
-
-### **Toggle gc_details**
-Identifier: `gopls.gc_details`
-
-Toggle the calculation of gc annotations.
-
-Args:
-
-```
-string
-```
-
-### **Run go generate**
-Identifier: `gopls.generate`
-
-Runs `go generate` for a given directory.
-
-Args:
-
-```
-{
-	// URI for the directory to generate.
-	"Dir": string,
-	// Whether to generate recursively (go generate ./...)
-	"Recursive": bool,
-}
-```
-
-### **Generate gopls.mod**
-Identifier: `gopls.generate_gopls_mod`
-
-(Re)generate the gopls.mod file for a workspace.
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-### **go get a package**
-Identifier: `gopls.go_get_package`
-
-Runs `go get` to fetch a package.
-
-Args:
-
-```
-{
-	// Any document URI within the relevant module.
-	"URI": string,
-	// The package to go get.
-	"Pkg": string,
-	"AddRequire": bool,
-}
-```
-
-### **List imports of a file and its package**
-Identifier: `gopls.list_imports`
-
-Retrieve a list of imports in the given Go file, and the package it
-belongs to.
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-Result:
-
-```
-{
-	// Imports is a list of imports in the requested file.
-	"Imports": []{
-		"Path": string,
-		"Name": string,
-	},
-	// PackageImports is a list of all imports in the requested file's package.
-	"PackageImports": []{
-		"Path": string,
-	},
-}
-```
-
-### **List known packages**
-Identifier: `gopls.list_known_packages`
-
-Retrieve a list of packages that are importable from the given URI.
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-Result:
-
-```
-{
-	// Packages is a list of packages relative
-	// to the URIArg passed by the command request.
-	// In other words, it omits paths that are already
-	// imported or cannot be imported due to compiler
-	// restrictions.
-	"Packages": []string,
-}
-```
-
-### **Regenerate cgo**
-Identifier: `gopls.regenerate_cgo`
-
-Regenerates cgo definitions.
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-### **Remove a dependency**
-Identifier: `gopls.remove_dependency`
-
-Removes a dependency from the go.mod file of a module.
-
-Args:
-
-```
-{
-	// The go.mod file URI.
-	"URI": string,
-	// The module path to remove.
-	"ModulePath": string,
-	"OnlyDiagnostic": bool,
-}
-```
-
-### **Reset go.mod diagnostics**
-Identifier: `gopls.reset_go_mod_diagnostics`
-
-Reset diagnostics in the go.mod file of a module.
-
-Args:
-
-```
-{
-	"URIArg": {
-		"URI": string,
-	},
-	// Optional: source of the diagnostics to reset.
-	// If not set, all resettable go.mod diagnostics will be cleared.
-	"DiagnosticSource": string,
-}
-```
-
-### **Run govulncheck.**
-Identifier: `gopls.run_govulncheck`
-
-Run vulnerability check (`govulncheck`).
-
-Args:
-
-```
-{
-	// Any document in the directory from which govulncheck will run.
-	"URI": string,
-	// Package pattern. E.g. "", ".", "./...".
-	"Pattern": string,
-}
-```
-
-Result:
-
-```
-{
-	// Token holds the progress token for LSP workDone reporting of the vulncheck
-	// invocation.
-	"Token": interface{},
-}
-```
-
-### **Run test(s)**
-Identifier: `gopls.run_tests`
-
-Runs `go test` for a specific set of test or benchmark functions.
-
-Args:
-
-```
-{
-	// The test file containing the tests to run.
-	"URI": string,
-	// Specific test names to run, e.g. TestFoo.
-	"Tests": []string,
-	// Specific benchmarks to run, e.g. BenchmarkFoo.
-	"Benchmarks": []string,
-}
-```
-
-### **Start the gopls debug server**
-Identifier: `gopls.start_debugging`
-
-Start the gopls debug server if it isn't running, and return the debug
-address.
-
-Args:
-
-```
-{
-	// Optional: the address (including port) for the debug server to listen on.
-	// If not provided, the debug server will bind to "localhost:0", and the
-	// full debug URL will be contained in the result.
-	// 
-	// If there is more than one gopls instance along the serving path (i.e. you
-	// are using a daemon), each gopls instance will attempt to start debugging.
-	// If Addr specifies a port, only the daemon will be able to bind to that
-	// port, and each intermediate gopls instance will fail to start debugging.
-	// For this reason it is recommended not to specify a port (or equivalently,
-	// to specify ":0").
-	// 
-	// If the server was already debugging this field has no effect, and the
-	// result will contain the previously configured debug URL(s).
-	"Addr": string,
-}
-```
-
-Result:
-
-```
-{
-	// The URLs to use to access the debug servers, for all gopls instances in
-	// the serving path. For the common case of a single gopls instance (i.e. no
-	// daemon), this will be exactly one address.
-	// 
-	// In the case of one or more gopls instances forwarding the LSP to a daemon,
-	// URLs will contain debug addresses for each server in the serving path, in
-	// serving order. The daemon debug address will be the last entry in the
-	// slice. If any intermediate gopls instance fails to start debugging, no
-	// error will be returned but the debug URL for that server in the URLs slice
-	// will be empty.
-	"URLs": []string,
-}
-```
-
-### **Run test(s) (legacy)**
-Identifier: `gopls.test`
-
-Runs `go test` for a specific set of test or benchmark functions.
-
-Args:
-
-```
-string,
-[]string,
-[]string
-```
-
-### **Run go mod tidy**
-Identifier: `gopls.tidy`
-
-Runs `go mod tidy` for a module.
-
-Args:
-
-```
-{
-	// The file URIs.
-	"URIs": []string,
-}
-```
-
-### **Toggle gc_details**
-Identifier: `gopls.toggle_gc_details`
-
-Toggle the calculation of gc annotations.
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-### **Update go.sum**
-Identifier: `gopls.update_go_sum`
-
-Updates the go.sum file for a module.
-
-Args:
-
-```
-{
-	// The file URIs.
-	"URIs": []string,
-}
-```
-
-### **Upgrade a dependency**
-Identifier: `gopls.upgrade_dependency`
-
-Upgrades a dependency in the go.mod file for a module.
-
-Args:
-
-```
-{
-	// The go.mod file URI.
-	"URI": string,
-	// Additional args to pass to the go command.
-	"GoCmdArgs": []string,
-	// Whether to add a require directive.
-	"AddRequire": bool,
-}
-```
-
-### **Run go mod vendor**
-Identifier: `gopls.vendor`
-
-Runs `go mod vendor` for a module.
-
-Args:
-
-```
-{
-	// The file URI.
-	"URI": string,
-}
-```
-
-<!-- END Commands: DO NOT MANUALLY EDIT THIS SECTION -->
diff -urN a/gopls/doc/contributing.md b/gopls/doc/contributing.md
--- a/gopls/doc/contributing.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/contributing.md	1969-12-31 16:00:00
@@ -1,119 +0,0 @@
-# Documentation for contributors
-
-This documentation augments the general documentation for contributing to the
-x/tools repository, described at the [repository root](../../CONTRIBUTING.md).
-
-Contributions are welcome, but since development is so active, we request that
-you file an issue and claim it before starting to work on something. Otherwise,
-it is likely that we might already be working on a fix for your issue.
-
-## Finding issues
-
-All `gopls` issues are labeled as such (see the [`gopls` label][issue-gopls]).
-Issues that are suitable for contributors are additionally tagged with the
-[`help-wanted` label][issue-wanted].
-
-Before you begin working on an issue, please leave a comment that you are
-claiming it.
-
-## Getting started
-
-Most of the `gopls` logic is in the `golang.org/x/tools/gopls/internal/lsp`
-directory.
-
-## Build
-
-To build a version of `gopls` with your changes applied:
-
-```bash
-cd /path/to/tools/gopls
-go install
-```
-
-To confirm that you are testing with the correct `gopls` version, check that
-your `gopls` version looks like this:
-
-```bash
-$ gopls version
-golang.org/x/tools/gopls master
-    golang.org/x/tools/gopls@(devel)
-```
-
-## Getting help
-
-The best way to contact the gopls team directly is via the
-[#gopls-dev](https://app.slack.com/client/T029RQSE6/CRWSN9NCD) channel on the
-gophers slack. Please feel free to ask any questions about your contribution or
-about contributing in general.
-
-## Testing
-
-To run tests for just `gopls/`, run,
-
-```bash
-cd /path/to/tools/gopls
-go test ./...
-```
-
-But, much of the gopls work involves `internal/lsp` too, so you will want to
-run both:
-
-```bash
-cd /path/to/tools
-cd gopls && go test ./...
-cd ..
-go test ./internal/lsp/...
-```
-
-There is additional information about the `internal/lsp` tests in the
-[internal/lsp/tests `README`](https://github.com/golang/tools/blob/master/internal/lsp/tests/README.md).
-
-### Regtests
-
-gopls has a suite of regression tests defined in the `./gopls/internal/regtest`
-directory. Each of these tests writes files to a temporary directory, starts a
-separate gopls session, and scripts interactions using an editor-like API. As a
-result of this overhead they can be quite slow, particularly on systems where
-file operations are costly.
-
-Due to the asynchronous nature of the LSP, regtests assertions are written
-as 'expectations' that the editor state must achieve _eventually_. This can
-make debugging the regtests difficult. To aid with debugging, the regtests
-output their LSP logs on any failure. If your CL gets a test failure while
-running the regtests, please do take a look at the description of the error and
-the LSP logs, but don't hesitate to [reach out](#getting-help) to the gopls
-team if you need help.
-
-### CI
-
-When you mail your CL and you or a fellow contributor assigns the
-`Run-TryBot=1` label in Gerrit, the
-[TryBots](https://golang.org/doc/contribute.html#trybots) will run tests in
-both the `golang.org/x/tools` and `golang.org/x/tools/gopls` modules, as
-described above.
-
-Furthermore, an additional "gopls-CI" pass will be run by _Kokoro_, which is a
-Jenkins-like Google infrastructure for running Dockerized tests. This allows us
-to run gopls tests in various environments that would be difficult to add to
-the TryBots. Notably, Kokoro runs tests on
-[older Go versions](../README.md#supported-go-versions) that are no longer supported
-by the TryBots. Per that that policy, support for these older Go versions is
-best-effort, and test failures may be skipped rather than fixed.
-
-Kokoro runs are triggered by the `Run-TryBot=1` label, just like TryBots, but
-unlike TryBots they do not automatically re-run if the "gopls-CI" result is
-removed in Gerrit. To force a re-run of the Kokoro CI on a CL containing the
-`Run-TryBot=1` label, you can reply in Gerrit with the comment "kokoro rerun".
-
-## Debugging
-
-The easiest way to debug your change is to run a single `gopls` test with a
-debugger.
-
-See also [Troubleshooting](troubleshooting.md#troubleshooting).
-
-<!--TODO(rstambler): Add more details about the debug server and viewing
-telemetry.-->
-
-[issue-gopls]: https://github.com/golang/go/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+label%3Agopls "gopls issues"
-[issue-wanted]: https://github.com/golang/go/issues?utf8=✓&q=is%3Aissue+is%3Aopen+label%3Agopls+label%3A"help+wanted" "help wanted"
diff -urN a/gopls/doc/daemon.md b/gopls/doc/daemon.md
--- a/gopls/doc/daemon.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/daemon.md	1969-12-31 16:00:00
@@ -1,183 +0,0 @@
-# Running gopls as a daemon
-
-**Note: this feature is new. If you encounter bugs, please [file an
-issue](troubleshooting.md#file-an-issue).**
-
-If you just want to try this out, skip ahead to the [quickstart](#quickstart).
-
-## Background: gopls execution modes
-
-Gopls was originally implemented as an LSP sidecar: a process started by
-editors or editor plugins, and communicated with using jsonrpc 2.0 over
-stdin/stdout. By executing as a stateful process, gopls can maintain a
-significant amount of cache and can eagerly perform analysis on the source code
-being edited.
-
-This execution mode does not work as well when there are many separate editor
-processes or when editor processes are short-lived, as is often the case for
-users of non-IDE editors such as Vim or Emacs. Having many processes means
-having many caches, consuming a significant amount of system resources. Using
-short-lived sessions means paying a start-up cost each time a session is
-created.
-
-To support these types of workflows, a new mode of gopls execution is supported
-wherein a single, persistent, shared gopls "daemon" process is responsible for
-managing all gopls sessions. In this mode, editors still start a gopls sidecar,
-but this sidecar merely acts as a thin "forwarder", responsible for forwarding
-the LSP to the shared gopls instance and recording metrics, logs, and rpc
-traces.
-
-## Quickstart
-
-To use a shared gopls instance you must either manage the daemon process
-yourself, or let the gopls forwarder processes start the shared daemon as
-needed.
-
-### Running with `-remote=auto`
-
-Automatic management of the daemon is easiest, and can be done by passing the
-flag `-remote=auto` to the gopls process started by your editor. This will
-cause this process to auto-start the gopls daemon if needed, connect to it, and
-forward the LSP. For example, here is a reasonable gopls invocation, that sets
-some additional flags for easier [debugging](#debugging):
-
-```bash
-gopls -remote=auto -logfile=auto -debug=:0 -remote.debug=:0 -rpc.trace
-```
-
-Note that the shared gopls process will automatically shut down after one
-minute with no connected clients.
-
-### Managing the daemon manually
-
-To manage the gopls daemon process via external means rather than having the
-forwarders manage it, you must start a gopls daemon process with the
-`-listen=<addr>` flag, and then pass `-remote=<addr>` to the gopls processes
-started by your editor.
-
-For example, to host the daemon on the TCP port `37374`, do:
-
-```bash
-gopls -listen=:37374 -logfile=auto -debug=:0
-```
-
-And then from the editor, run
-
-```bash
-gopls -remote=:37374 -logfile=auto -debug=:0 -rpc.trace
-```
-
-If you are on a POSIX system, you can also use unix domain sockets by prefixing
-the flag values with `unix;`. For example:
-
-```bash
-gopls -listen="unix;/tmp/gopls-daemon-socket" -logfile=auto -debug=:0
-```
-
-And connect via:
-
-```bash
-gopls -remote="unix;/tmp/gopls-daemon-socket" -logfile=auto -debug=:0 -rpc.trace
-```
-
-(Note that these flag values MUST be enclosed in quotes, because ';' is a
-special shell character. For this reason, this syntax is subject to change in
-the future.)
-
-## Debugging
-
-Debugging a shared gopls session is more complicated than a singleton session,
-because there are now two gopls processes involved with handling the LSP. Here
-are some tips:
-
-### Finding logfiles and debug addresses
-
-When running in daemon mode, you can use the `gopls inspect sessions` command
-to find the logfile and debug port for your gopls daemon instance (as well as
-for all its connected clients). By default, this inspects the default daemon
-(i.e. `-remote=auto`). To inspect a different daemon, use the `-remote` flag
-explicitly: `gopls -remote=localhost:12345 inspect sessions`.
-
-This works whether or not you have enabled `-remote.debug`.
-
-### Traversing debug pages
-
-When `-debug=:0` is passed to gopls, it runs a webserver that serves stateful
-debug pages (see [troubleshooting.md](troubleshooting.md)). You can find the
-actual port hosting these pages by either using the `gopls inspect sessions`
-command, or by checking the start of the logfile -- it will be one of the first
-log messages. For example, if using `-logfile=auto`, find the debug address by
-checking `head /tmp/gopls-<pid>.log`.
-
-By default, the gopls daemon is not started with `-debug`. To enable it, set
-the `-remote.debug` flag on the forwarder instance, so that it invokes gopls
-with `-debug` when starting the daemon.
-
-The debug pages of the forwarder process will have a link to the debug pages of
-the daemon server process. Correspondingly, the debug pages of the daemon
-process will have a link to each of its clients.
-
-This can help you find metrics, traces, and log files for all of the various
-servers and clients.
-
-### Using logfiles
-
-The gopls daemon is started with logging disabled by default. To customize
-this, pass `-remote.logfile` to the gopls forwarder. Using
-`-remote.logfile=auto`, the daemon will log to a default location (on posix
-systems: `/tmp/gopls-daemon-<pid>.log`).
-
-The gopls daemon does not log session-scoped messages: those are instead
-reflected back to the forwarder so that they can be accessed by the editor.
-Daemon logs will only contain global messages, for example logs when sessions
-connect and disconnect.
-
-It is recommended to start the forwarder gopls process with `-rpc.trace`, so
-that its logfile will contain rpc trace logs specific to the LSP session.
-
-## Using multiple shared gopls instances
-
-There may be environments where it is desirable to have more than one shared
-gopls instance. If managing the daemon manually, this can be done by simply
-choosing different `-listen` addresses for each distinct daemon process.
-
-On POSIX systems, there is also support for automatic management of distinct
-shared gopls processes: distinct daemons can be selected by passing
-`-remote="auto;<id>"`. Any gopls forwarder passing the same value for `<id>`
-will use the same shared daemon.
-
-## FAQ
-
-**Q: Why am I not saving as much memory as I expected when using a shared gopls?**
-
-A: As described in [implementation.md](design/implementation.md), gopls has a
-concept of view/session/cache. Each session and view map onto exactly one
-editor session (because they contain things like edited but unsaved buffers).
-The cache contains things that are independent of any editor session, and can
-therefore be shared.
-
-When, for example, three editor session are sharing a single gopls process,
-they will share the cache but will each have their own session and view. The
-memory savings in this mode, when compared to three separate gopls processes,
-corresponds to the amount of cache overlap across sessions.
-
-Because this hasn't mattered much in the past, it is likely that there is state
-that can be moved out of the session/view, and into the cache, thereby
-increasing the amount of memory savings in the shared mode.
-
-**Q: How do I customize the daemon instance when using `-remote=auto`?**
-
-The daemon may be customized using flags of the form `-remote.*` on the
-forwarder gopls. This causes the forwarder to invoke gopls with these settings
-when starting the daemon. As of writing, we expose the following configuration:
-
-* `-remote.logfile`: the location of the daemon logfile
-* `-remote.debug`: the daemon's debug address
-* `-remote.listen.timeout`: the amount of time the daemon should wait for new
-  connections while there are no current connections, before shutting down.
-  Must be set to a valid `time.Duration` (e.g. `30s` or `5m`). If `0`, listen
-  indefinitely. Default: `1m`.
-
-Note that once the daemon is already running, setting these flags will not
-change its configuration. These flags only matter for the forwarder process
-that actually starts the daemon.
diff -urN a/gopls/doc/design/design.md b/gopls/doc/design/design.md
--- a/gopls/doc/design/design.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/design/design.md	1969-12-31 16:00:00
@@ -1,394 +0,0 @@
-# `gopls` design documentation
-
-## Goals
-
-* `gopls` should **become the default editor backend** for the major editors used by Go programmers, fully supported by the Go team.
-* `gopls` will be a **full implementation of LSP**, as described in the [LSP specification], to standardize as many of its features as possible.
-* `gopls` will be **clean and extensible** so that it can encompass additional features in the future, allowing Go tooling to become best in class once more.
-* `gopls` will **support alternate build systems and file layouts**, allowing Go development to be simpler and more powerful in any environment.
-
-## Context
-
-While Go has a number of excellent and useful command-line tools that enhance the developer experience, it has become clear that integrating these tools with IDEs can pose challenges.
-
-Support of these tools has relied on the goodwill of community members, and they have been put under a large burden of support at times as the language, toolchain and environments change. As a result many tools have ceased to work, have had support problems, or become confusing with forks and replacements, or provided an experience that is not as good as it could be.
-See the section below on [existing solutions](#existing-solutions) for more problems and details.
-
-This is fine for tools used occasionally, but for core IDE features, this is not acceptable.
-Autocompletion, jump to definition, formatting, and other such features should always work, as they are key for Go development.
-
-The Go team will create an editor backend that works in any build system.
-It will also be able to improve upon the latency of Go tools, since each tool will no longer have to individually run the type-checker on each invocation, instead there will be a long-running process and data can be shared between the definitions, completions, diagnostics, and other features.
-
-By taking ownership of these tools and packaging them together in the form of gopls, the Go team will ensure that the Go development experience isn’t unnecessarily complicated for Go users.
-Having one editor backend will simplify the lives of Go developers, the Go team, and the maintainers of Go editor plugins.
-
-See Rebecca's excellent GopherCon keynote [talk] and [slides] for some more context.
-
-## Non-Goals
-
-* Command line speed
-
-  Although gopls will have a command line mode, it will be optimized for long running and not command responsiveness, as such it may not be the right tool for things like CI systems.
-  For such cases there will have to be an alternate tool using the same underlying libraries for consistency.
-
-* Low memory environments
-
-  In order to do a good job of processing large projects with very low latencies gopls will be holding a lot of information in memory.
-  It is presumed that developers are normally working on systems with significant RAM and this will not be a problem.
-  In general this is upheld by the large memory usage of existing IDE solutions (like IntelliJ)
-
-* Syntax highlighting
-
-  At the moment there is no editor that delegates this functionality to a separate binary, and no standard way of doing it.
-
-## Existing solutions
-
-Every year the Go team conducts a survey, asking developers about their experiences with the language.
-
-One question that is asked is “How do you feel about your editor?”.
-
-The responses told a very negative story. Some categorized quotes:
-
-* Setup
-  * "Hard to install and configure"
-  * "Inadequate documentation"
-* Performance
-  * "Performance is very poor"
-  * "Pretty slow in large projects"
-* Reliability
-  * "Features work one day, but not the next"
-  * "Tooling is not updated with new language features"
-
-Each editor has its own plugin that shells out to a variety of tools, many of which break with new Go releases or because they are no longer maintained.
-
-The individual tools each have to do the work to understand the code and all its transitive dependencies.
-
-Each feature is a different tool, with a different set of patterns for its command line, a different way to accept input and parse output, a different way of specifying source code locations.
-To support its existing feature set, VSCode installed 24 different command line tools, many of which have options or forks to configure. When looking at the set of tools that needed to be migrated to modules, across all the editors, there were 63 separate tools.
-
-All these tools need to understand the code, and they use the same standard libraries to do it. Those libraries are optimized for these kinds of tools, but even so processing that much code takes a lot of time time. Almost none of the tools are capable of returning results within 100ms.
-As developers type in their editor, multiple of these features need to activate, which means they are not just paying the cost once, but many times. The overall effect is an editing experience that feels sluggish, and features that are either not enabled or sometimes produce results that appear so slowly they are no longer useful when they arrive. This is a problem that increases with the size of the code base, which means it is getting worse over time, and is especially bad for the kinds of large code bases companies are dealing with as they use Go for more major tasks.
-
-## Requirements
-
-### Complete feature set
-
-For gopls to be considered a success it has to implement the full feature set discussed [below](#Features).
-This is the set of features that users need in order to feel as productive as they were with the tooling it is replacing. It does not include every feature of previous implementations, there are some features that are almost never used that should be dropped (like guru's pointer analysis) and some other features that do not easily fit and will have to be worked around (replacing the save hook/linter).
-
-### Equivalent or better experience
-
-For all of those features, the user experience must match or exceed the current one available in all editors.
-This is an easy statement to make, but a hard one to validate or measure. Many of the possible measures fail to capture the experience.
-
-For instance, if an attempt was made to measure the latency of a jump to definition call, the results would be fairly consistent from the old godef tool. From the gopls implementation there may be a much larger range of latencies, with the best being orders of magnitude faster, and the worse slightly worse, because gopls attempts to do far more work, but manages to cache it across calls.
-
-Or for a completion call, it might be slower but produce a better first match such that users accept it more often, resulting in an overall better experience.
-
-For the most part this has to rely on user reports. If users are refusing to switch because the experience is not better, it is clearly not done, if they are switching but most people are complaining, there are probably enough areas that are better to make the switch compelling but other areas which are worse. If most people are switching and either staying silent or being positive, it is probably done. When writing tools, the user is all that matters.
-
-### Solid community of contributors
-
-The scope and scale of the problem gopls is trying to solve is untenable for the core Go team, it is going to require a strong community to make it all happen.
-
-This implies the code must be easy to contribute to, and easy for many developers to work on in parallel. The functionality needs to be well decoupled, and have a thorough testing story.
-
-### Latencies that fall within user tolerance
-
-There has been a lot of research on acceptable latencies for user actions.
-<!-- TODO: research links -->
-The main result that affects gopls is that feedback in direct response to continuous user actions needs to be under 100ms to be imperceptible, and anything above 200ms aggravates the user.
-This means in general the aim has to be <100ms for anything that happens as the developer types.
-There will always be cases where gopls fails to meet this deadline, and there needs to be ways to make the user experience okay in those cases, but in general the point of this deadline is to inform the basic architecture design, any solution that cannot theoretically meet this goal in the long term is the wrong answer.
-
-### Easy to configure
-
-Developers are very particular, and have very differing desires in their coding experience. gopls is going to have to support a significant amount of flexibility, in order to meet those desires.
-The default settings however with no configuration at all must be the one that is best experience for most users, and where possible the features must be flexible without configuration so that the client can easily make the choices about treatment without changing its communication with gopls.
-
-## Difficulties
-
-### Volume of data
-
-<!-- TODO: project sizes -->
-* Small:
-* Medium:
-* Large:
-* Corporate mono-repo: Much much bigger
-
-Parsing and type checking large amounts of code is quite expensive, and the converted forms use a lot of space. As gopls has to keep updating this information while the developer types, it needs to manage how it caches the converted forms very carefully to balance memory use vs speed.
-
-### Cache invalidation
-
-The basic unit of operation for the type checking is the package, but the basic unit of operation for an editor is the file.
-gopls needs to be able to map files to packages efficiently, so that when files change it knows which packages need to be updated (along with any other packages that transitively depended on them).
-This is made especially difficult by the fact that changing the content of a file can modify which packages it is considered part of (either by changing the package declaration or the build tags), a file can be in more than one package, and changes can be made to files without using the editor, in which case it will not notify us of the changes.
-
-### Inappropriate core functionality
-
-The base libraries for Go (things like [go/token], [go/ast] and [go/types]) are all designed for compiler-like applications.
-They tend to worry more about throughput than memory use, they have structures that are intended to grow and then be thrown away at program exit, and they are not designed to keep going in the presence of errors in the source they are handling.
-They also have no abilities to do incremental changes.
-
-Making a long running service work well with those libraries is a very large challenge, but writing new libraries would be far more work, and cause a significant long term cost as both sets of libraries would have to be maintained. Right now it is more important to get a working tool into the hands of users. In the long term this decision may have to be revisited, new low level libraries may be the only way to keep pushing the capabilities forwards.
-
-### Build system capabilities
-
-gopls is supposed to be build system agnostic, but it must use the build system to discover how files map to packages. When it tries to do so, even when the functionality is the same, the costs (in time, CPU and memory) are very different, and can significantly impact the user experience. Designing how gopls interacts with the build system to try to minimize or hide these differences is hard.
-
-### Build tags
-
-The build tag system in Go is quite powerful, and has many use cases. Source files can exclude themselves using powerful boolean logic on the set of active tags.
-It is however designed for specifying the set of active tags on the command line, and the libraries are all designed to cope with only one valid combination at a time. There is also no way to work out the set of valid combinations.
-
-Type checking a file requires knowledge of all the other files in the same package, and that set of files is modified by the build tags. The set of exported identifiers of a package is also affected by which files are in the package, and thus its build tags.
-
-This means that even for files or packages that have no build tag controls it is not possible to produce correct results without knowing the set of build tags to consider.
-This makes it very hard to produce useful results when viewing a file.
-
-### Features not supported by LSP
-
-There are some things it would be good to be able to do that do not fit easily into the existing LSP protocol.
-For instance, displaying control flow information, automatic struct tags, complex refactoring...
-
-Each feature will have to be considered carefully, and either propose a change to LSP, or add a way to have gopls specific extensions to the protocol that are still easy to use in all the editor plugins.
-
-To avoid these at the start, only core LSP features will be implemented, as they are sufficient to meet the baseline requirements anyway, but the potential features need to be kept in mind in the core architecture.
-
-### Distribution
-
-Making sure that users are using the right version of gopls is going to be a problem. Each editor plugin is probably going to install the tools in its own way, some will choose to install it system wide, some will keep their own copy.
-
-Because it is a brand new tool, it will be changing rapidly. If users are not informed they are on an old version they will be experiencing problems that have already been fixed, which is worse for them, and then probably reporting them, which wastes time for the gopls team. There needs to be a mechanism for gopls to check if is up to date, and a recommended way to install an up to date version.
-
-### Debugging user problems
-
-gopls is essentially a very stateful long running server on the developer's machine. Its basic operation is affected by many things, from the users environment to the contents of the local build cache. The data it is operating on is often a confidential code base that cannot be shared.
-All of these things make it hard for users to report a bug usefully, or create a minimal reproduction.
-
-There needs to be easy ways for users to report what information they can, and ways to attempt to reproduce problems without their entire state. This is also needed to produce regression tests.
-
-## Basic design decisions
-
-There are some fundamental architecture decisions that affect much of the rest of the design of the tool, making fundamental trade offs that impact the user experience.
-
-### Process lifetime: *managed by the editor*
-
-Processing a large code base to fully type check and then analyze it within the latency requirements is not feasible, and is one of the primary problems with the existing solutions. This remains true even if the computed information was cached on disk, as running analyzers and type checkers ends up requiring the full AST of all files in the dependency graph.
-It is theoretically possible to do better, but only with a major re-write of the existing parsing and type checking libraries, something that is not feasible at this time.
-
-This implies that gopls should be a long running process, that is able to cache and pre-calculate results in memory so that when a request arrives it can produce the answer much faster.
-
-It could run as a daemon on the user's machine, but there are a lot of issues with managing a daemon. It may well be the right choice in the long term, and it should be allowed for in the fundamental architecture design, but to start with it will instead have a process that lasts as long as the editor that starts it, and that can easily be restarted.
-
-### Caching: *in memory*
-
-Persistent disk caches are very expensive to maintain, and require solving a lot of extra problems.
-Although building the information required is expensive compared to the latencies required of the requests, it is fairly minor compared to the startup times of an editor, so it is expected that rebuilding the information when gopls is restarted will be acceptable.
-
-The advantage gained from this is that gopls becomes stateless across restarts which means if it has issues or gets its state confused, a simple restart will often fix the problem.
-It also means that when users report problems, the entire state of the on disk cache is not needed to diagnose and reproduce the issue.
-
-### Communication: *stdin/stdout JSON*
-
-The LSP specification defines the JSON messages that are normally used, but it does not define how those message should be sent, and there are implementations of the LSP that do not use JSON (for instance, Protocol buffers are an option).
-
-The constraints on gopls are that it must be easy to integrate into *every editor* on *all operating systems*, and that it should not have large external dependencies.
-
-JSON is part of the Go standard library, and is also the native language of LSP, so it makes the most sense. By far the best supported communication mechanism is the standard input and output of a process, and the common client implementations all have ways of using [JSON rpc 2] in this mode.  There were no complete and low dependency implementations of this protocol in Go, but it is a fairly small protocol on top of the JSON library that can be implemented with a moderate effort, and would be a generally useful library to have anyway.
-
-In the future it is expected to run in separated client server mode, so writing it in a way that could use sockets instead of stdin/stdout from the start was the best way to make sure it remained possible. It was also a huge debugging aid to be able to run the gopls server by hand and watch/debug it outside the editor.
-
-### Running other tools: *no*
-
-<!--- TODO: subprocess discuss --->
-
-## Features
-
-<!--TODO(rstambler): Generate a file that lists all of the supported features.-->
-
-There is a set of features that gopls needs to expose to be a comprehensive IDE solution.
-The following is the minimum set of features, along with their existing solutions and how they should map to the LSP.
-
-### Introspection
-
-Introspection features tell developers information about their code while they work. They do not make or suggest changes.
-
----
-Diagnostics | Static analysis results of the code, including compilation and lint errors
------------ | ---
-Requires    | Full go/analysis run, which needs full AST, type and SSA information
-LSP         | [`textDocument/publishDiagnostics`]
-Previous    | `go build`, `go vet`, `golint`, [errcheck], [staticcheck] <!-- TODO: and all the rest -->
-|           | This is one of the most important IDE features, allowing fast turn around without having to run compilers and checkers in the shell. Often used to power problem lists, gutter markers and squiggle underlines in the IDE. <br/> There is some complicated design work to do in order to let users customize the set of checks being run, preferably without having to recompile the main LSP binary.
-
----
-Hover    | Information about the code under the cursor.
--------- | ---
-Requires | AST and type information for the file and all dependencies
-LSP      | [`textDocument/hover`]
-Previous | [godoc], [gogetdoc]
-|        | Used when reading code to display information known to the compiler but not always obvious from the code. For instance it may return the types of identifiers, or the documentation.
-
----
-Signature help | Function parameter information and documentation
--------------- | ---
-Requires       | AST and type information for the file and all dependencies
-LSP            | [`textDocument/signatureHelp`]
-Previous       | [gogetdoc]
-|              | As a function call is being typed into code, it is helpful to know the parameters of that call to enable the developer to call it correctly.
-
-### Navigation
-
-Navigation features are designed to make it easier for a developer to find their way round a code base.
-
----
-Definition | Select an identifier, and jump to the code where that identifier was defined.
----------- | ---
-Requires   | Full type information for file and all dependencies
-LSP        | [`textDocument/declaration`]
-|          | [`textDocument/definition`]
-|          | [`textDocument/typeDefinition`]
-Previous   | [godef] |
-|          | Asking the editor to open the place where a symbol was defined is one of the most commonly used code navigation tools inside an IDE when available. It is especially valuable when exploring an unfamiliar code base.<br/>Due to a limitation of the compiler output, it is not possible to use the binary data for this task (specifically it does not know column information) and thus it must parse from source.
-
----
-Implementation | Reports the types that implement an interface
--------------- | ---
-Requires       | Full workspace type knowledge
-LSP            | [`textDocument/implementation`]
-Previous       | [impl]
-|              | This feature is hard to scale up to large code bases, and is going to take thought to get right. It may be feasible to implemented a more limited form in the meantime.
-
----
-Document symbols | Provides the set of top level symbols in the current file.
----------------- | ---
-Requires         | AST of the current file only
-LSP              | [`textDocument/documentSymbol`]
-Previous         | [go-outline], [go-symbols]
-|                | Used to drive things like outline mode.
-
----
-References | Find all references to the symbol under the cursor.
----------- | ---
-Requires   | AST and type information for the **reverse** transitive closure
-LSP        | [`textDocument/references`]
-Previous   | [guru]
-|          | This requires knowledge of every package that could possible depend on any packages the current file is part of. In the past this has been implemented either by global knowledge, which does not scale, or by specifying a "scope" which confused users to the point where they just did not use the tools. gopls is probably going to need a more powerful solution in the long term, but to start with automatically limiting the scope may produce acceptable results. This would probably be the module if known, or some sensible parent directory otherwise.
-
----
-Folding  | Report logical hierarchies of blocks
--------- | ---
-Requires | AST of the current file only
-LSP      | [`textDocument/foldingRange`]
-Previous | [go-outline]
-|        | This is normally used to provide expand and collapse behavior in editors.
-
----
-Selection | Report regions of logical selection around the cursor
---------- | ---
-Requires  | AST of the current file only
-LSP       | [`textDocument/selectionRange`]
-Previous  | [guru]
-|         | Used in editor features like expand selection.
-
-
-### Edit assistance
-
-These features suggest or apply edits to the code for the user, including refactoring features, for which there are many potential use cases.
-Refactoring is one of the places where Go tools could potentially be very strong, but have not been so far, and thus there is huge potential for improvements in the developer experience.
-There is not yet a clear understanding of the kinds of refactoring people need or how they should express them however, and there are weaknesses in the LSP protocol around this.
-This means it may be much more of a research project.
-
-
----
-Format   | Fix the formatting of the file
--------- | ---
-Requires | AST of current file
-LSP      | [`textDocument/formatting`]
-|        | [`textDocument/rangeFormatting`]
-|        | [`textDocument/onTypeFormatting`]
-Previous | [gofmt], [goimports], [goreturns]
-|        | It will use the standard format package. <br/> Current limitations are that it does not work on malformed code. It may need some very careful changes to the formatter to allow for formatting an invalid AST or changes to force the AST to a valid mode. These changes would improve range and file mode as well, but are basically vital to onTypeFormatting
-
----
-Imports  | Rewrite the imports block automatically to match the symbols used.
--------- | ---
-Requires | AST of the current file and full symbol knowledge for all candidate packages.
-LSP      | [`textDocument/codeAction`]
-Previous | [goimports], [goreturns]
-|        | This needs knowledge of packages that are not yet in use, and the ability to find those packages by name. <br/> It also needs exported symbol information for all the packages it discovers. <br/> It should be implemented using the standard imports package, but there may need to be exposed a more fine grained API than just a file rewrite for some of the interactions.
-
----
-Autocompletion | Makes suggestions to complete the entity currently being typed.
--------------- | ---
-Requires       | AST and type information for the file and all dependencies<br/> Also full exported symbol knowledge for all packages.
-LSP            | [`textDocument/completion`]
-|              | [`completionItem/resolve`]
-Previous       | [gocode]
-|              | Autocomplete is one of the most complicated features, and the more it knows the better its suggestions can be. For instance it can autocomplete into packages that are not yet being imported if it has their public symbols. It can make better suggestions of options if it knows what kind of program you are writing. It can suggest better arguments if it knows how you normally call a function. It can suggest entire patterns of code if it knows they are common. Unlike many other features, which have a specific task, and once it is doing that task the feature is done, autocomplete will never be finished. Balancing and improving both the candidates and how they are ranked will be a research problem for a long time to come.
-
----
-Rename   | Rename an identifier
--------- | ---
-Requires | AST and type information for the **reverse** transitive closure
-LSP      | [`textDocument/rename`]
-|        | [`textDocument/prepareRename`]
-Previous | [gorename]
-|        | This uses the same information that find references does, with all the same problems and limitations. It is slightly worse because the changes it suggests make it intolerant of incorrect results. It is also dangerous using it to change the public API of a package.
-
----
-Suggested fixes | Suggestions that can be manually or automatically accepted to change the code
---------------- | ---
-Requires        | Full go/analysis run, which needs full AST, type and SSA information
-LSP             | [`textDocument/codeAction`]
-Previous        | N/A
-|               | This is a brand new feature powered by the new go/analysis engine, and it should allow a huge amount of automated refactoring.
-
-[LSP specification]: https://microsoft.github.io/language-server-protocol/specifications/specification-3-14/
-[talk]: TODO
-[slides]: https://github.com/gophercon/2019-talks/blob/master/RebeccaStambler-GoPleaseStopBreakingMyEditor/slides.pdf "Go, please stop breaking my editor!"
-[JSON rpc 2]: https://www.jsonrpc.org/specification
-
-[errcheck]: https://github.com/kisielk/errcheck
-[go-outline]: https://github.com/lukehoban/go-outline
-[go-symbols]: https://github.com/acroca/go-symbols
-[gocode]: https://github.com/stamblerre/gocode
-[godef]: https://github.com/rogpeppe/godef
-[godoc]: https://golang.org/cmd/godoc
-[gofmt]: https://golang.org/cmd/gofmt
-[gogetdoc]: https://github.com/zmb3/gogetdoc
-[goimports]: https://pkg.go.dev/golang.org/x/tools/cmd/goimports
-[gorename]: https://pkg.go.dev/golang.org/x/tools/cmd/gorename
-[goreturns]: https://github.com/sqs/goreturns
-[gotags]: https://github.com/jstemmer/gotags
-[guru]: https://pkg.go.dev/golang.org/x/tools/cmd/guru
-[impl]: https://github.com/josharian/impl
-[staticcheck]: https://staticcheck.io/docs/
-[go/types]: https://golang.org/pkg/go/types/
-[go/ast]: https://golang.org/pkg/go/ast/
-[go/token]: https://golang.org/pkg/go/token/
-
-[`completionItem/resolve`]:https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#completionItem_resolve
-[`textDocument/codeAction`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_codeAction
-[`textDocument/completion`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_completion
-[`textDocument/declaration`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_declaration
-[`textDocument/definition`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_definition
-[`textDocument/documentLink`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_documentLink
-[`textDocument/documentSymbol`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_documentSymbol
-[`textDocument/foldingRange`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_foldingRange
-[`textDocument/formatting`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_formatting
-[`textDocument/highlight`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_highlight
-[`textDocument/hover`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_hover
-[`textDocument/implementation`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_implementation
-[`textDocument/onTypeFormatting`]:https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_onTypeFormatting
-[`textDocument/prepareRename`]:https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_prepareRename
-[`textDocument/publishDiagnostics`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_publishDiagnostics
-[`textDocument/rangeFormatting`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_rangeFormatting
-[`textDocument/references`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_references
-[`textDocument/rename`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_rename
-[`textDocument/selectionRange`]:https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_selectionRange
-[`textDocument/signatureHelp`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_signatureHelp
-[`textDocument/typeDefinition`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_typeDefinition
-[`workspace/didChangeWatchedFiles`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#workspace_didChangeWatchedFiles
diff -urN a/gopls/doc/design/implementation.md b/gopls/doc/design/implementation.md
--- a/gopls/doc/design/implementation.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/design/implementation.md	1969-12-31 16:00:00
@@ -1,48 +0,0 @@
-# gopls implementation documentation
-
-This is not intended as a complete description of the implementation, for the most the part the package godoc, code comments and the code itself hold that.
-Instead this is meant to be a guide into finding parts of the implementation, and understanding some core concepts used throughout the implementation.
-
-## View/Session/Cache
-
-Throughout the code there are references to these three concepts, and they build on each other.
-
-At the base is the *Cache*. This is the level at which we hold information that is global in nature, for instance information about the file system and its contents.
-
-Above that is the *Session*, which holds information for a connection to an editor. This layer hold things like the edited files (referred to as overlays).
-
-The top layer is called the *View*. This holds the configuration, and the mapping to configured packages.
-
-The purpose of this layering is to allow a single editor session to have multiple views active whilst still sharing as much information as possible for efficiency.
-In theory if only the View layer existed, the results would be identical, but slower and using more memory.
-
-## Code location
-
-gopls will be developed in the [x/tools] Go repository; the core packages are in [internal/lsp], and the binary and integration tests are located in [gopls].
-
-Below is a list of the core packages of gopls, and their primary purpose:
-
-Package | Description
---- | ---
-[gopls] | the main binary, plugins and integration tests
-[internal/lsp] | the core message handling package
-[internal/lsp/cache] | the cache layer
-[internal/lsp/cmd] | the gopls command line layer
-[internal/lsp/debug] | features to aid in debugging gopls
-[internal/lsp/protocol] | the lsp protocol layer and wire format
-[internal/lsp/source] | the core feature implementations
-[internal/span] | a package for dealing with source file locations
-[internal/memoize] | a function invocation cache used to reduce the work done
-[internal/jsonrpc2] | an implementation of the JSON RPC2 specification
-
-[gopls]: https://github.com/golang/tools/tree/master/gopls
-[internal/jsonrpc2]: https://github.com/golang/tools/tree/master/internal/jsonrpc2
-[internal/lsp]: https://github.com/golang/tools/tree/master/internal/lsp
-[internal/lsp/cache]: https://github.com/golang/tools/tree/master/internal/lsp/cache
-[internal/lsp/cmd]: https://github.com/golang/tools/tree/master/internal/lsp/cmd
-[internal/lsp/debug]: https://github.com/golang/tools/tree/master/internal/lsp/debug
-[internal/lsp/protocol]: https://github.com/golang/tools/tree/master/internal/lsp/protocol
-[internal/lsp/source]: https://github.com/golang/tools/tree/master/internal/lsp/source
-[internal/memoize]: https://github.com/golang/tools/tree/master/internal/memoize
-[internal/span]: https://github.com/golang/tools/tree/master/internal/span
-[x/tools]: https://github.com/golang/tools
diff -urN a/gopls/doc/design/integrating.md b/gopls/doc/design/integrating.md
--- a/gopls/doc/design/integrating.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/design/integrating.md	1969-12-31 16:00:00
@@ -1,91 +0,0 @@
-# Documentation for plugin authors
-
-If you are integrating `gopls` into an editor by writing an editor plugin, there are quite a few semantics of the communication between the editor and `gopls` that are not specified by the [LSP specification].
-
-We attempt to document those details along with any other information that has been helpful to other plugin authors here.
-
-If you are implementing a plugin yourself and have questions this page does not answer, please reach out to us to ask, and then also contribute your findings back to this page.
-
-## Supported features
-
-For the most part you should look at the [list](status.md#supported-features) in the current status document to know if gopls supports a feature.
-For a truly authoritative answer you should check the [result][InitializeResult] of the [initialize] request, where gopls enumerates its support in the [ServerCapabilities].
-
-
-## Positions and ranges
-
-Many LSP requests pass position or range information. This is described in the [LSP specification][lsp-text-documents]:
-
-> A position inside a document (see Position definition below) is expressed as a zero-based line and character offset. The offsets are based on a UTF-16 string representation. So a string of the form a𐐀b the character offset of the character a is 0, the character offset of 𐐀 is 1 and the character offset of b is 3 since 𐐀 is represented using two code units in UTF-16.
-
-This means that integrators will need to calculate UTF-16 based column offsets.
-
-[`golang.org/x/tools/gopls/internal/span`] has the code to do this in go.
-[#31080] tracks making `span` and other useful packages non-internal.
-
-## Edits
-
-In order to deliver changes from gopls to the editor, the LSP supports arrays of [`TextEdit`][lsp-textedit]s in responses.
-The spec specifies exactly how these should be applied:
-
-> All text edits ranges refer to positions in the original document. Text edits ranges must never overlap, that means no part of the original document must be manipulated by more than one edit. However, it is possible that multiple edits have the same start position: multiple inserts, or any number of inserts followed by a single remove or replace edit. If multiple inserts have the same position, the order in the array defines the order in which the inserted strings appear in the resulting text.
-
-All `[]TextEdit` are sorted such that applying the array of deltas received in reverse order achieves the desired result that holds with the spec.
-
-## Errors
-
-Various error codes are described in the [LSP specification][lsp-response]. We are still determining what it means for a method to return an error; are errors only for low-level LSP/transport issues or can other conditions cause errors to be returned? See some of this discussion on [#31526].
-
-The method chosen is currently influenced by the exact treatment in the currently popular editor integrations. It may well change, and ideally would become more coherent across requests.
-
-* [`textDocument/codeAction`]: Return error if there was an error computing code actions.
-* [`textDocument/completion`]: Log errors, return empty result list.
-* [`textDocument/definition`]: Return error if there was an error computing the definition for the position.
-* [`textDocument/typeDefinition`]: Return error if there was an error computing the type definition for the position.
-* [`textDocument/formatting`]: Return error if there was an error formatting the file.
-* [`textDocument/highlight`]: Log errors, return empty result.
-* [`textDocument/hover`]: Return empty result.
-* [`textDocument/documentLink`]: Log errors, return nil result.
-* [`textDocument/publishDiagnostics`]: Log errors if there were any while computing diagnostics.
-* [`textDocument/references`]: Log errors, return empty result.
-* [`textDocument/rename`]: Return error if there was an error computing renames.
-* [`textDocument/signatureHelp`]: Log errors, return nil result.
-* [`textDocument/documentSymbols`]: Return error if there was an error computing document symbols.
-
-## Watching files
-
-It is fairly normal for files that affect `gopls` to be modified outside of the editor it is associated with.
-
-For instance, files that are needed to do correct type checking are modified by switching branches in git, or updated by a code generator.
-
-Monitoring files inside gopls directly has a lot of awkward problems, but the [LSP specification] has methods that allow gopls to request that the client notify it of file system changes, specifically [`workspace/didChangeWatchedFiles`].
-This is currently being added to gopls by a community member, and tracked in [#31553]
-
-[InitializeResult]: https://pkg.go.dev/golang.org/x/tools/gopls/internal/lsp/protocol#InitializeResult
-[ServerCapabilities]: https://pkg.go.dev/golang.org/x/tools/gopls/internal/lsp/protocol#ServerCapabilities
-[`golang.org/x/tools/gopls/internal/span`]: https://pkg.go.dev/golang.org/x/tools/internal/span#NewPoint
-
-[LSP specification]: https://microsoft.github.io/language-server-protocol/specifications/specification-3-14/
-[lsp-response]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#response-message
-[initialize]: https://microsoft.github.io/language-server-protocol/specifications/specification-3-14/#initialize
-[lsp-text-documents]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#text-documents
-[lsp-textedit]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textedit
-
-[`textDocument/codeAction`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_codeAction
-[`textDocument/completion`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_completion
-[`textDocument/definition`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_definition
-[`textDocument/typeDefinition`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_typeDefinition
-[`textDocument/formatting`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_formatting
-[`textDocument/highlight`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_highlight
-[`textDocument/hover`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_hover
-[`textDocument/documentLink`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_documentLink
-[`textDocument/publishDiagnostics`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_publishDiagnostics
-[`textDocument/references`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_references
-[`textDocument/rename`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_rename
-[`textDocument/signatureHelp`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_signatureHelp
-[`textDocument/documentSymbols`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#textDocument_documentSymbols
-[`workspace/didChangeWatchedFiles`]: https://github.com/Microsoft/language-server-protocol/blob/gh-pages/_specifications/specification-3-14.md#workspace_didChangeWatchedFiles
-
-[#31080]: https://github.com/golang/go/issues/31080
-[#31553]: https://github.com/golang/go/issues/31553
-[#31526]: https://github.com/golang/go/issues/31526
diff -urN a/gopls/doc/emacs.md b/gopls/doc/emacs.md
--- a/gopls/doc/emacs.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/emacs.md	1969-12-31 16:00:00
@@ -1,183 +0,0 @@
-# Emacs
-
-## Installing `gopls`
-
-To use `gopls` with Emacs, you must first
-[install the `gopls` binary](../README.md#installation) and ensure that the directory
-containing the resulting binary (either `$(go env GOBIN)` or `$(go env
-GOPATH)/bin`) is in your `PATH`.
-
-## Choosing an Emacs LSP client
-
-To use `gopls` with Emacs, you will need to choose and install an Emacs LSP
-client package. Two popular client packages are [LSP Mode] and [Eglot].
-
-LSP Mode takes a batteries-included approach, with many integrations enabled
-“out of the box” and several additional behaviors provided by `lsp-mode` itself.
-
-Eglot takes a minimally-intrusive approach, focusing on smooth integration with
-other established packages. It provides a few of its own `eglot-` commands but
-no additional keybindings by default.
-
-Once you have selected which client you want to use, install it per the packages
-instructions: see [Eglot 1-2-3](https://github.com/joaotavora/eglot#1-2-3) or
-[LSP Mode Installation](https://emacs-lsp.github.io/lsp-mode/page/installation/).
-
-## Common configuration
-
-Both Eglot and LSP Mode can integrate with popular packages in the Emacs
-ecosystem:
-
-* The built-in [`xref`] package provides cross-references.
-* The built-in [Flymake] package provides an on-the-fly diagnostic overlay.
-* [Company] mode displays code completion candidates (with a richer UI than
-  the built-in [`completion-at-point`]).
-
-Eglot provides documentation using the built-in [ElDoc] minor mode, while LSP
-Mode by default provides documentation using its own [`lsp-ui`] mode.
-
-Eglot by default locates the project root using the [`project`] package. In LSP
-Mode, this behavior can be configured using the `lsp-auto-guess-root` setting.
-
-## Configuring LSP Mode
-
-### Loading LSP Mode in `.emacs`
-
-```elisp
-(require 'lsp-mode)
-(add-hook 'go-mode-hook #'lsp-deferred)
-
-;; Set up before-save hooks to format buffer and add/delete imports.
-;; Make sure you don't have other gofmt/goimports hooks enabled.
-(defun lsp-go-install-save-hooks ()
-  (add-hook 'before-save-hook #'lsp-format-buffer t t)
-  (add-hook 'before-save-hook #'lsp-organize-imports t t))
-(add-hook 'go-mode-hook #'lsp-go-install-save-hooks)
-```
-
-### Configuring `gopls` via LSP Mode
-
-See [settings] for information about available gopls settings.
-
-Stable gopls settings have corresponding configuration variables in `lsp-mode`.
-For example, `(setq lsp-gopls-use-placeholders nil)` will disable placeholders
-in completion snippets. See [`lsp-go`] for a list of available variables.
-
-Experimental settings can be configured via `lsp-register-custom-settings`:
-
-```lisp
-(lsp-register-custom-settings
- '(("gopls.completeUnimported" t t)
-   ("gopls.staticcheck" t t)))
-```
-
-Note that after changing settings you must restart gopls using e.g. `M-x
-lsp-restart-workspace`.
-
-## Configuring Eglot
-
-### Configuring `project` for Go modules in `.emacs`
-
-Eglot uses the built-in `project` package to identify the LSP workspace for a
-newly-opened buffer. The `project` package does not natively know about `GOPATH`
-or Go modules. Fortunately, you can give it a custom hook to tell it to look for
-the nearest parent `go.mod` file (that is, the root of the Go module) as the
-project root.
-
-```elisp
-(require 'project)
-
-(defun project-find-go-module (dir)
-  (when-let ((root (locate-dominating-file dir "go.mod")))
-    (cons 'go-module root)))
-
-(cl-defmethod project-root ((project (head go-module)))
-  (cdr project))
-
-(add-hook 'project-find-functions #'project-find-go-module)
-```
-
-### Loading Eglot in `.emacs`
-
-```elisp
-;; Optional: load other packages before eglot to enable eglot integrations.
-(require 'company)
-(require 'yasnippet)
-
-(require 'go-mode)
-(require 'eglot)
-(add-hook 'go-mode-hook 'eglot-ensure)
-
-;; Optional: install eglot-format-buffer as a save hook.
-;; The depth of -10 places this before eglot's willSave notification,
-;; so that that notification reports the actual contents that will be saved.
-(defun eglot-format-buffer-on-save ()
-  (add-hook 'before-save-hook #'eglot-format-buffer -10 t))
-(add-hook 'go-mode-hook #'eglot-format-buffer-on-save)
-```
-
-### Configuring `gopls` via Eglot
-
-See [settings] for information about available gopls settings.
-
-LSP server settings are controlled by the `eglot-workspace-configuration`
-variable, which can be set either globally in `.emacs` or in a `.dir-locals.el` file in the project root.
-
-`.emacs`:
-```elisp
-(setq-default eglot-workspace-configuration
-    '((:gopls .
-        ((staticcheck . t)
-         (matcher . "CaseSensitive")))))
-```
-
-`.dir-locals.el`:
-```elisp
-((nil (eglot-workspace-configuration . ((gopls . ((staticcheck . t)
-						  (matcher . "CaseSensitive")))))))
-```
-
-### Organizing imports with Eglot
-
-`gopls` provides the import-organizing functionality of `goimports` as an LSP
-code action, which you can invoke as needed by running `M-x eglot-code-actions`
-(or a key of your choice bound to the `eglot-code-actions` function) and
-selecting `Organize Imports` at the prompt.
-
-Eglot does not currently support a standalone function to execute a specific
-code action (see
-[joaotavora/eglot#411](https://github.com/joaotavora/eglot/issues/411)), nor an
-option to organize imports as a `before-save-hook` (see
-[joaotavora/eglot#574](https://github.com/joaotavora/eglot/issues/574)). In the
-meantime, see those issues for discussion and possible workarounds.
-
-## Troubleshooting
-
-Common errors:
-
-* When prompted by Emacs for your project folder, if you are using modules you
-  must select the module's root folder (i.e. the directory with the "go.mod").
-  If you are using GOPATH, select your $GOPATH as your folder.
-* Emacs must have your environment set properly (PATH, GOPATH, etc). You can
-  run `M-x getenv <RET> PATH <RET>` to see if your PATH is set in Emacs. If
-  not, you can try starting Emacs from your terminal, using [this
-  package][exec-path-from-shell], or moving your shell config from `.bashrc`
-  into `.profile` and logging out and back in.
-* Make sure only one LSP client mode is installed. (For example, if using
-  `lsp-mode`, ensure that you are not _also_ enabling `eglot`.)
-* Look for errors in the `*lsp-log*` buffer or run `M-x eglot-events-buffer`.
-* Ask for help in the `#emacs` channel on the [Gophers slack].
-
-[LSP Mode]: https://emacs-lsp.github.io/lsp-mode/
-[Eglot]: https://github.com/joaotavora/eglot/blob/master/README.md
-[`xref`]: https://www.gnu.org/software/emacs/manual/html_node/emacs/Xref.html
-[Flymake]: https://www.gnu.org/software/emacs/manual/html_node/flymake/Using-Flymake.html#Using-Flymake
-[Company]: https://company-mode.github.io/
-[`completion-at-point`]: https://www.gnu.org/software/emacs/manual/html_node/elisp/Completion-in-Buffers.html
-[ElDoc]: https://elpa.gnu.org/packages/eldoc.html
-[`lsp-ui`]: https://emacs-lsp.github.io/lsp-ui/
-[`lsp-go`]: https://github.com/emacs-lsp/lsp-mode/blob/master/clients/lsp-go.el
-[`use-package`]: https://github.com/jwiegley/use-package
-[`exec-path-from-shell`]: https://github.com/purcell/exec-path-from-shell
-[settings]: settings.md
-[Gophers slack]: https://invite.slack.golangbridge.org/
diff -urN a/gopls/doc/features.md b/gopls/doc/features.md
--- a/gopls/doc/features.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/features.md	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-# Features
-
-This document describes some of the features supported by `gopls`. It is
-currently under construction, so, for a comprehensive list, see the
-[Language Server Protocol](https://microsoft.github.io/language-server-protocol/).
-
-## Special features
-
-Here, only special features outside of the LSP are described.
-
-### Symbol Queries
-
-Gopls supports some extended syntax for `workspace/symbol` requests, when using
-the `fuzzy` symbol matcher (the default). Inspired by the popular fuzzy matcher
-[FZF](https://github.com/junegunn/fzf), the following special characters are
-supported within symbol queries:
-
-| Character | Usage     | Match        |
-| --------- | --------- | ------------ |
-| `'`       | `'abc`    | exact        |
-| `^`       | `^printf` | exact prefix |
-| `$`       | `printf$` | exact suffix |
-
-## Template Files
-
-Gopls provides some support for Go template files, that is, files that
-are parsed by `text/template` or `html/template`.
-Gopls recognizes template files based on their file extension, which may be
-configured by the
-[`templateExtensions`](https://github.com/golang/tools/blob/master/gopls/doc/settings.md#templateextensions-string) setting.
-Making this list empty turns off template support.
-
-In template files, template support works inside
-the default `{{` delimiters. (Go template parsing
-allows the user to specify other delimiters, but
-gopls does not know how to do that.)
-
-Gopls template support includes the following features:
-+ **Diagnostics**: if template parsing returns an error,
-it is presented as a diagnostic. (Missing functions do not produce errors.)
-+ **Syntax Highlighting**: syntax highlighting is provided for template files.
-+  **Definitions**: gopls provides jump-to-definition inside templates, though it does not understand scoping (all templates are considered to be in one global scope).
-+  **References**: gopls provides find-references, with the same scoping limitation as definitions.
-+ **Completions**: gopls will attempt to suggest completions inside templates.
-
-### Configuring your editor
-
-In addition to configuring `templateExtensions`, you may need to configure your
-editor or LSP client to activate `gopls` for template files. For example, in
-`VS Code` you will need to configure both
-[`files.associations`](https://code.visualstudio.com/docs/languages/identifiers)
-and `build.templateExtensions` (the gopls setting).
-
-<!--TODO(rstambler): Automatically generate a list of supported features.-->
-
diff -urN a/gopls/doc/generate.go b/gopls/doc/generate.go
--- a/gopls/doc/generate.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/generate.go	1969-12-31 16:00:00
@@ -1,778 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.16
-// +build go1.16
-
-// Command generate creates API (settings, etc) documentation in JSON and
-// Markdown for machine and human consumption.
-package main
-
-import (
-	"bytes"
-	"encoding/json"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/token"
-	"go/types"
-	"io"
-	"io/ioutil"
-	"os"
-	"os/exec"
-	"path/filepath"
-	"reflect"
-	"regexp"
-	"sort"
-	"strconv"
-	"strings"
-	"time"
-	"unicode"
-
-	"github.com/jba/printsrc"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/command/commandmeta"
-	"golang.org/x/tools/gopls/internal/lsp/mod"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func main() {
-	if _, err := doMain(true); err != nil {
-		fmt.Fprintf(os.Stderr, "Generation failed: %v\n", err)
-		os.Exit(1)
-	}
-}
-
-func doMain(write bool) (bool, error) {
-	api, err := loadAPI()
-	if err != nil {
-		return false, err
-	}
-
-	sourceDir, err := pkgDir("golang.org/x/tools/gopls/internal/lsp/source")
-	if err != nil {
-		return false, err
-	}
-
-	if ok, err := rewriteFile(filepath.Join(sourceDir, "api_json.go"), api, write, rewriteAPI); !ok || err != nil {
-		return ok, err
-	}
-
-	goplsDir, err := pkgDir("golang.org/x/tools/gopls")
-	if err != nil {
-		return false, err
-	}
-
-	if ok, err := rewriteFile(filepath.Join(goplsDir, "doc", "settings.md"), api, write, rewriteSettings); !ok || err != nil {
-		return ok, err
-	}
-	if ok, err := rewriteFile(filepath.Join(goplsDir, "doc", "commands.md"), api, write, rewriteCommands); !ok || err != nil {
-		return ok, err
-	}
-	if ok, err := rewriteFile(filepath.Join(goplsDir, "doc", "analyzers.md"), api, write, rewriteAnalyzers); !ok || err != nil {
-		return ok, err
-	}
-	if ok, err := rewriteFile(filepath.Join(goplsDir, "doc", "inlayHints.md"), api, write, rewriteInlayHints); !ok || err != nil {
-		return ok, err
-	}
-
-	return true, nil
-}
-
-// pkgDir returns the directory corresponding to the import path pkgPath.
-func pkgDir(pkgPath string) (string, error) {
-	out, err := exec.Command("go", "list", "-f", "{{.Dir}}", pkgPath).Output()
-	if err != nil {
-		return "", err
-	}
-	return strings.TrimSpace(string(out)), nil
-}
-
-func loadAPI() (*source.APIJSON, error) {
-	pkgs, err := packages.Load(
-		&packages.Config{
-			Mode: packages.NeedTypes | packages.NeedTypesInfo | packages.NeedSyntax | packages.NeedDeps,
-		},
-		"golang.org/x/tools/gopls/internal/lsp/source",
-	)
-	if err != nil {
-		return nil, err
-	}
-	pkg := pkgs[0]
-
-	api := &source.APIJSON{
-		Options: map[string][]*source.OptionJSON{},
-	}
-	defaults := source.DefaultOptions()
-
-	api.Commands, err = loadCommands(pkg)
-	if err != nil {
-		return nil, err
-	}
-	api.Lenses = loadLenses(api.Commands)
-
-	// Transform the internal command name to the external command name.
-	for _, c := range api.Commands {
-		c.Command = command.ID(c.Command)
-	}
-	for _, m := range []map[string]*source.Analyzer{
-		defaults.DefaultAnalyzers,
-		defaults.TypeErrorAnalyzers,
-		defaults.ConvenienceAnalyzers,
-		// Don't yet add staticcheck analyzers.
-	} {
-		api.Analyzers = append(api.Analyzers, loadAnalyzers(m)...)
-	}
-	api.Hints = loadHints(source.AllInlayHints)
-	for _, category := range []reflect.Value{
-		reflect.ValueOf(defaults.UserOptions),
-	} {
-		// Find the type information and ast.File corresponding to the category.
-		optsType := pkg.Types.Scope().Lookup(category.Type().Name())
-		if optsType == nil {
-			return nil, fmt.Errorf("could not find %v in scope %v", category.Type().Name(), pkg.Types.Scope())
-		}
-		opts, err := loadOptions(category, optsType, pkg, "")
-		if err != nil {
-			return nil, err
-		}
-		catName := strings.TrimSuffix(category.Type().Name(), "Options")
-		api.Options[catName] = opts
-
-		// Hardcode the expected values for the analyses and code lenses
-		// settings, since their keys are not enums.
-		for _, opt := range opts {
-			switch opt.Name {
-			case "analyses":
-				for _, a := range api.Analyzers {
-					opt.EnumKeys.Keys = append(opt.EnumKeys.Keys, source.EnumKey{
-						Name:    fmt.Sprintf("%q", a.Name),
-						Doc:     a.Doc,
-						Default: strconv.FormatBool(a.Default),
-					})
-				}
-			case "codelenses":
-				// Hack: Lenses don't set default values, and we don't want to
-				// pass in the list of expected lenses to loadOptions. Instead,
-				// format the defaults using reflection here. The hackiest part
-				// is reversing lowercasing of the field name.
-				reflectField := category.FieldByName(upperFirst(opt.Name))
-				for _, l := range api.Lenses {
-					def, err := formatDefaultFromEnumBoolMap(reflectField, l.Lens)
-					if err != nil {
-						return nil, err
-					}
-					opt.EnumKeys.Keys = append(opt.EnumKeys.Keys, source.EnumKey{
-						Name:    fmt.Sprintf("%q", l.Lens),
-						Doc:     l.Doc,
-						Default: def,
-					})
-				}
-			case "hints":
-				for _, a := range api.Hints {
-					opt.EnumKeys.Keys = append(opt.EnumKeys.Keys, source.EnumKey{
-						Name:    fmt.Sprintf("%q", a.Name),
-						Doc:     a.Doc,
-						Default: strconv.FormatBool(a.Default),
-					})
-				}
-			}
-		}
-	}
-	return api, nil
-}
-
-func loadOptions(category reflect.Value, optsType types.Object, pkg *packages.Package, hierarchy string) ([]*source.OptionJSON, error) {
-	file, err := fileForPos(pkg, optsType.Pos())
-	if err != nil {
-		return nil, err
-	}
-
-	enums, err := loadEnums(pkg)
-	if err != nil {
-		return nil, err
-	}
-
-	var opts []*source.OptionJSON
-	optsStruct := optsType.Type().Underlying().(*types.Struct)
-	for i := 0; i < optsStruct.NumFields(); i++ {
-		// The types field gives us the type.
-		typesField := optsStruct.Field(i)
-
-		// If the field name ends with "Options", assume it is a struct with
-		// additional options and process it recursively.
-		if h := strings.TrimSuffix(typesField.Name(), "Options"); h != typesField.Name() {
-			// Keep track of the parent structs.
-			if hierarchy != "" {
-				h = hierarchy + "." + h
-			}
-			options, err := loadOptions(category, typesField, pkg, strings.ToLower(h))
-			if err != nil {
-				return nil, err
-			}
-			opts = append(opts, options...)
-			continue
-		}
-		path, _ := astutil.PathEnclosingInterval(file, typesField.Pos(), typesField.Pos())
-		if len(path) < 2 {
-			return nil, fmt.Errorf("could not find AST node for field %v", typesField)
-		}
-		// The AST field gives us the doc.
-		astField, ok := path[1].(*ast.Field)
-		if !ok {
-			return nil, fmt.Errorf("unexpected AST path %v", path)
-		}
-
-		// The reflect field gives us the default value.
-		reflectField := category.FieldByName(typesField.Name())
-		if !reflectField.IsValid() {
-			return nil, fmt.Errorf("could not find reflect field for %v", typesField.Name())
-		}
-
-		def, err := formatDefault(reflectField)
-		if err != nil {
-			return nil, err
-		}
-
-		typ := typesField.Type().String()
-		if _, ok := enums[typesField.Type()]; ok {
-			typ = "enum"
-		}
-		name := lowerFirst(typesField.Name())
-
-		var enumKeys source.EnumKeys
-		if m, ok := typesField.Type().(*types.Map); ok {
-			e, ok := enums[m.Key()]
-			if ok {
-				typ = strings.Replace(typ, m.Key().String(), m.Key().Underlying().String(), 1)
-			}
-			keys, err := collectEnumKeys(name, m, reflectField, e)
-			if err != nil {
-				return nil, err
-			}
-			if keys != nil {
-				enumKeys = *keys
-			}
-		}
-
-		// Get the status of the field by checking its struct tags.
-		reflectStructField, ok := category.Type().FieldByName(typesField.Name())
-		if !ok {
-			return nil, fmt.Errorf("no struct field for %s", typesField.Name())
-		}
-		status := reflectStructField.Tag.Get("status")
-
-		opts = append(opts, &source.OptionJSON{
-			Name:       name,
-			Type:       typ,
-			Doc:        lowerFirst(astField.Doc.Text()),
-			Default:    def,
-			EnumKeys:   enumKeys,
-			EnumValues: enums[typesField.Type()],
-			Status:     status,
-			Hierarchy:  hierarchy,
-		})
-	}
-	return opts, nil
-}
-
-func loadEnums(pkg *packages.Package) (map[types.Type][]source.EnumValue, error) {
-	enums := map[types.Type][]source.EnumValue{}
-	for _, name := range pkg.Types.Scope().Names() {
-		obj := pkg.Types.Scope().Lookup(name)
-		cnst, ok := obj.(*types.Const)
-		if !ok {
-			continue
-		}
-		f, err := fileForPos(pkg, cnst.Pos())
-		if err != nil {
-			return nil, fmt.Errorf("finding file for %q: %v", cnst.Name(), err)
-		}
-		path, _ := astutil.PathEnclosingInterval(f, cnst.Pos(), cnst.Pos())
-		spec := path[1].(*ast.ValueSpec)
-		value := cnst.Val().ExactString()
-		doc := valueDoc(cnst.Name(), value, spec.Doc.Text())
-		v := source.EnumValue{
-			Value: value,
-			Doc:   doc,
-		}
-		enums[obj.Type()] = append(enums[obj.Type()], v)
-	}
-	return enums, nil
-}
-
-func collectEnumKeys(name string, m *types.Map, reflectField reflect.Value, enumValues []source.EnumValue) (*source.EnumKeys, error) {
-	// Make sure the value type gets set for analyses and codelenses
-	// too.
-	if len(enumValues) == 0 && !hardcodedEnumKeys(name) {
-		return nil, nil
-	}
-	keys := &source.EnumKeys{
-		ValueType: m.Elem().String(),
-	}
-	// We can get default values for enum -> bool maps.
-	var isEnumBoolMap bool
-	if basic, ok := m.Elem().(*types.Basic); ok && basic.Kind() == types.Bool {
-		isEnumBoolMap = true
-	}
-	for _, v := range enumValues {
-		var def string
-		if isEnumBoolMap {
-			var err error
-			def, err = formatDefaultFromEnumBoolMap(reflectField, v.Value)
-			if err != nil {
-				return nil, err
-			}
-		}
-		keys.Keys = append(keys.Keys, source.EnumKey{
-			Name:    v.Value,
-			Doc:     v.Doc,
-			Default: def,
-		})
-	}
-	return keys, nil
-}
-
-func formatDefaultFromEnumBoolMap(reflectMap reflect.Value, enumKey string) (string, error) {
-	if reflectMap.Kind() != reflect.Map {
-		return "", nil
-	}
-	name := enumKey
-	if unquoted, err := strconv.Unquote(name); err == nil {
-		name = unquoted
-	}
-	for _, e := range reflectMap.MapKeys() {
-		if e.String() == name {
-			value := reflectMap.MapIndex(e)
-			if value.Type().Kind() == reflect.Bool {
-				return formatDefault(value)
-			}
-		}
-	}
-	// Assume that if the value isn't mentioned in the map, it defaults to
-	// the default value, false.
-	return formatDefault(reflect.ValueOf(false))
-}
-
-// formatDefault formats the default value into a JSON-like string.
-// VS Code exposes settings as JSON, so showing them as JSON is reasonable.
-// TODO(rstambler): Reconsider this approach, as the VS Code Go generator now
-// marshals to JSON.
-func formatDefault(reflectField reflect.Value) (string, error) {
-	def := reflectField.Interface()
-
-	// Durations marshal as nanoseconds, but we want the stringy versions,
-	// e.g. "100ms".
-	if t, ok := def.(time.Duration); ok {
-		def = t.String()
-	}
-	defBytes, err := json.Marshal(def)
-	if err != nil {
-		return "", err
-	}
-
-	// Nil values format as "null" so print them as hardcoded empty values.
-	switch reflectField.Type().Kind() {
-	case reflect.Map:
-		if reflectField.IsNil() {
-			defBytes = []byte("{}")
-		}
-	case reflect.Slice:
-		if reflectField.IsNil() {
-			defBytes = []byte("[]")
-		}
-	}
-	return string(defBytes), err
-}
-
-// valueDoc transforms a docstring documenting an constant identifier to a
-// docstring documenting its value.
-//
-// If doc is of the form "Foo is a bar", it returns '`"fooValue"` is a bar'. If
-// doc is non-standard ("this value is a bar"), it returns '`"fooValue"`: this
-// value is a bar'.
-func valueDoc(name, value, doc string) string {
-	if doc == "" {
-		return ""
-	}
-	if strings.HasPrefix(doc, name) {
-		// docstring in standard form. Replace the subject with value.
-		return fmt.Sprintf("`%s`%s", value, doc[len(name):])
-	}
-	return fmt.Sprintf("`%s`: %s", value, doc)
-}
-
-func loadCommands(pkg *packages.Package) ([]*source.CommandJSON, error) {
-	var commands []*source.CommandJSON
-
-	_, cmds, err := commandmeta.Load()
-	if err != nil {
-		return nil, err
-	}
-	// Parse the objects it contains.
-	for _, cmd := range cmds {
-		cmdjson := &source.CommandJSON{
-			Command: cmd.Name,
-			Title:   cmd.Title,
-			Doc:     cmd.Doc,
-			ArgDoc:  argsDoc(cmd.Args),
-		}
-		if cmd.Result != nil {
-			cmdjson.ResultDoc = typeDoc(cmd.Result, 0)
-		}
-		commands = append(commands, cmdjson)
-	}
-	return commands, nil
-}
-
-func argsDoc(args []*commandmeta.Field) string {
-	var b strings.Builder
-	for i, arg := range args {
-		b.WriteString(typeDoc(arg, 0))
-		if i != len(args)-1 {
-			b.WriteString(",\n")
-		}
-	}
-	return b.String()
-}
-
-func typeDoc(arg *commandmeta.Field, level int) string {
-	// Max level to expand struct fields.
-	const maxLevel = 3
-	if len(arg.Fields) > 0 {
-		if level < maxLevel {
-			return arg.FieldMod + structDoc(arg.Fields, level)
-		}
-		return "{ ... }"
-	}
-	under := arg.Type.Underlying()
-	switch u := under.(type) {
-	case *types.Slice:
-		return fmt.Sprintf("[]%s", u.Elem().Underlying().String())
-	}
-	return types.TypeString(under, nil)
-}
-
-func structDoc(fields []*commandmeta.Field, level int) string {
-	var b strings.Builder
-	b.WriteString("{\n")
-	indent := strings.Repeat("\t", level)
-	for _, fld := range fields {
-		if fld.Doc != "" && level == 0 {
-			doclines := strings.Split(fld.Doc, "\n")
-			for _, line := range doclines {
-				fmt.Fprintf(&b, "%s\t// %s\n", indent, line)
-			}
-		}
-		tag := strings.Split(fld.JSONTag, ",")[0]
-		if tag == "" {
-			tag = fld.Name
-		}
-		fmt.Fprintf(&b, "%s\t%q: %s,\n", indent, tag, typeDoc(fld, level+1))
-	}
-	fmt.Fprintf(&b, "%s}", indent)
-	return b.String()
-}
-
-func loadLenses(commands []*source.CommandJSON) []*source.LensJSON {
-	all := map[command.Command]struct{}{}
-	for k := range source.LensFuncs() {
-		all[k] = struct{}{}
-	}
-	for k := range mod.LensFuncs() {
-		if _, ok := all[k]; ok {
-			panic(fmt.Sprintf("duplicate lens %q", string(k)))
-		}
-		all[k] = struct{}{}
-	}
-
-	var lenses []*source.LensJSON
-
-	for _, cmd := range commands {
-		if _, ok := all[command.Command(cmd.Command)]; ok {
-			lenses = append(lenses, &source.LensJSON{
-				Lens:  cmd.Command,
-				Title: cmd.Title,
-				Doc:   cmd.Doc,
-			})
-		}
-	}
-	return lenses
-}
-
-func loadAnalyzers(m map[string]*source.Analyzer) []*source.AnalyzerJSON {
-	var sorted []string
-	for _, a := range m {
-		sorted = append(sorted, a.Analyzer.Name)
-	}
-	sort.Strings(sorted)
-	var json []*source.AnalyzerJSON
-	for _, name := range sorted {
-		a := m[name]
-		json = append(json, &source.AnalyzerJSON{
-			Name:    a.Analyzer.Name,
-			Doc:     a.Analyzer.Doc,
-			Default: a.Enabled,
-		})
-	}
-	return json
-}
-
-func loadHints(m map[string]*source.Hint) []*source.HintJSON {
-	var sorted []string
-	for _, h := range m {
-		sorted = append(sorted, h.Name)
-	}
-	sort.Strings(sorted)
-	var json []*source.HintJSON
-	for _, name := range sorted {
-		h := m[name]
-		json = append(json, &source.HintJSON{
-			Name: h.Name,
-			Doc:  h.Doc,
-		})
-	}
-	return json
-}
-
-func lowerFirst(x string) string {
-	if x == "" {
-		return x
-	}
-	return strings.ToLower(x[:1]) + x[1:]
-}
-
-func upperFirst(x string) string {
-	if x == "" {
-		return x
-	}
-	return strings.ToUpper(x[:1]) + x[1:]
-}
-
-func fileForPos(pkg *packages.Package, pos token.Pos) (*ast.File, error) {
-	fset := pkg.Fset
-	for _, f := range pkg.Syntax {
-		if safetoken.StartPosition(fset, f.Pos()).Filename == safetoken.StartPosition(fset, pos).Filename {
-			return f, nil
-		}
-	}
-	return nil, fmt.Errorf("no file for pos %v", pos)
-}
-
-func rewriteFile(file string, api *source.APIJSON, write bool, rewrite func([]byte, *source.APIJSON) ([]byte, error)) (bool, error) {
-	old, err := ioutil.ReadFile(file)
-	if err != nil {
-		return false, err
-	}
-
-	new, err := rewrite(old, api)
-	if err != nil {
-		return false, fmt.Errorf("rewriting %q: %v", file, err)
-	}
-
-	if !write {
-		return bytes.Equal(old, new), nil
-	}
-
-	if err := ioutil.WriteFile(file, new, 0); err != nil {
-		return false, err
-	}
-
-	return true, nil
-}
-
-func rewriteAPI(_ []byte, api *source.APIJSON) ([]byte, error) {
-	var buf bytes.Buffer
-	fmt.Fprintf(&buf, "// Code generated by \"golang.org/x/tools/gopls/doc/generate\"; DO NOT EDIT.\n\npackage source\n\nvar GeneratedAPIJSON = ")
-	if err := printsrc.NewPrinter("golang.org/x/tools/gopls/internal/lsp/source").Fprint(&buf, api); err != nil {
-		return nil, err
-	}
-	return format.Source(buf.Bytes())
-}
-
-type optionsGroup struct {
-	title   string
-	final   string
-	level   int
-	options []*source.OptionJSON
-}
-
-func rewriteSettings(doc []byte, api *source.APIJSON) ([]byte, error) {
-	result := doc
-	for category, opts := range api.Options {
-		groups := collectGroups(opts)
-
-		// First, print a table of contents.
-		section := bytes.NewBuffer(nil)
-		fmt.Fprintln(section, "")
-		for _, h := range groups {
-			writeBullet(section, h.final, h.level)
-		}
-		fmt.Fprintln(section, "")
-
-		// Currently, the settings document has a title and a subtitle, so
-		// start at level 3 for a header beginning with "###".
-		baseLevel := 3
-		for _, h := range groups {
-			level := baseLevel + h.level
-			writeTitle(section, h.final, level)
-			for _, opt := range h.options {
-				header := strMultiply("#", level+1)
-				fmt.Fprintf(section, "%s ", header)
-				opt.Write(section)
-			}
-		}
-		var err error
-		result, err = replaceSection(result, category, section.Bytes())
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	section := bytes.NewBuffer(nil)
-	for _, lens := range api.Lenses {
-		fmt.Fprintf(section, "### **%v**\n\nIdentifier: `%v`\n\n%v\n", lens.Title, lens.Lens, lens.Doc)
-	}
-	return replaceSection(result, "Lenses", section.Bytes())
-}
-
-func collectGroups(opts []*source.OptionJSON) []optionsGroup {
-	optsByHierarchy := map[string][]*source.OptionJSON{}
-	for _, opt := range opts {
-		optsByHierarchy[opt.Hierarchy] = append(optsByHierarchy[opt.Hierarchy], opt)
-	}
-
-	// As a hack, assume that uncategorized items are less important to
-	// users and force the empty string to the end of the list.
-	var containsEmpty bool
-	var sorted []string
-	for h := range optsByHierarchy {
-		if h == "" {
-			containsEmpty = true
-			continue
-		}
-		sorted = append(sorted, h)
-	}
-	sort.Strings(sorted)
-	if containsEmpty {
-		sorted = append(sorted, "")
-	}
-	var groups []optionsGroup
-	baseLevel := 0
-	for _, h := range sorted {
-		split := strings.SplitAfter(h, ".")
-		last := split[len(split)-1]
-		// Hack to capitalize all of UI.
-		if last == "ui" {
-			last = "UI"
-		}
-		// A hierarchy may look like "ui.formatting". If "ui" has no
-		// options of its own, it may not be added to the map, but it
-		// still needs a heading.
-		components := strings.Split(h, ".")
-		for i := 1; i < len(components); i++ {
-			parent := strings.Join(components[0:i], ".")
-			if _, ok := optsByHierarchy[parent]; !ok {
-				groups = append(groups, optionsGroup{
-					title: parent,
-					final: last,
-					level: baseLevel + i,
-				})
-			}
-		}
-		groups = append(groups, optionsGroup{
-			title:   h,
-			final:   last,
-			level:   baseLevel + strings.Count(h, "."),
-			options: optsByHierarchy[h],
-		})
-	}
-	return groups
-}
-
-func hardcodedEnumKeys(name string) bool {
-	return name == "analyses" || name == "codelenses"
-}
-
-func writeBullet(w io.Writer, title string, level int) {
-	if title == "" {
-		return
-	}
-	// Capitalize the first letter of each title.
-	prefix := strMultiply("  ", level)
-	fmt.Fprintf(w, "%s* [%s](#%s)\n", prefix, capitalize(title), strings.ToLower(title))
-}
-
-func writeTitle(w io.Writer, title string, level int) {
-	if title == "" {
-		return
-	}
-	// Capitalize the first letter of each title.
-	fmt.Fprintf(w, "%s %s\n\n", strMultiply("#", level), capitalize(title))
-}
-
-func capitalize(s string) string {
-	return string(unicode.ToUpper(rune(s[0]))) + s[1:]
-}
-
-func strMultiply(str string, count int) string {
-	var result string
-	for i := 0; i < count; i++ {
-		result += string(str)
-	}
-	return result
-}
-
-func rewriteCommands(doc []byte, api *source.APIJSON) ([]byte, error) {
-	section := bytes.NewBuffer(nil)
-	for _, command := range api.Commands {
-		command.Write(section)
-	}
-	return replaceSection(doc, "Commands", section.Bytes())
-}
-
-func rewriteAnalyzers(doc []byte, api *source.APIJSON) ([]byte, error) {
-	section := bytes.NewBuffer(nil)
-	for _, analyzer := range api.Analyzers {
-		fmt.Fprintf(section, "## **%v**\n\n", analyzer.Name)
-		fmt.Fprintf(section, "%s\n\n", analyzer.Doc)
-		switch analyzer.Default {
-		case true:
-			fmt.Fprintf(section, "**Enabled by default.**\n\n")
-		case false:
-			fmt.Fprintf(section, "**Disabled by default. Enable it by setting `\"analyses\": {\"%s\": true}`.**\n\n", analyzer.Name)
-		}
-	}
-	return replaceSection(doc, "Analyzers", section.Bytes())
-}
-
-func rewriteInlayHints(doc []byte, api *source.APIJSON) ([]byte, error) {
-	section := bytes.NewBuffer(nil)
-	for _, hint := range api.Hints {
-		fmt.Fprintf(section, "## **%v**\n\n", hint.Name)
-		fmt.Fprintf(section, "%s\n\n", hint.Doc)
-		switch hint.Default {
-		case true:
-			fmt.Fprintf(section, "**Enabled by default.**\n\n")
-		case false:
-			fmt.Fprintf(section, "**Disabled by default. Enable it by setting `\"hints\": {\"%s\": true}`.**\n\n", hint.Name)
-		}
-	}
-	return replaceSection(doc, "Hints", section.Bytes())
-}
-
-func replaceSection(doc []byte, sectionName string, replacement []byte) ([]byte, error) {
-	re := regexp.MustCompile(fmt.Sprintf(`(?s)<!-- BEGIN %v.* -->\n(.*?)<!-- END %v.* -->`, sectionName, sectionName))
-	idx := re.FindSubmatchIndex(doc)
-	if idx == nil {
-		return nil, fmt.Errorf("could not find section %q", sectionName)
-	}
-	result := append([]byte(nil), doc[:idx[2]]...)
-	result = append(result, replacement...)
-	result = append(result, doc[idx[3]:]...)
-	return result, nil
-}
diff -urN a/gopls/doc/generate_test.go b/gopls/doc/generate_test.go
--- a/gopls/doc/generate_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/generate_test.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.16
-// +build go1.16
-
-package main
-
-import (
-	"testing"
-
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestGenerated(t *testing.T) {
-	testenv.NeedsGoBuild(t) // This is a lie. We actually need the source code.
-
-	ok, err := doMain(false)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if !ok {
-		t.Error("documentation needs updating. run: `go run doc/generate.go` from the gopls module.")
-	}
-}
diff -urN a/gopls/doc/inlayHints.md b/gopls/doc/inlayHints.md
--- a/gopls/doc/inlayHints.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/inlayHints.md	1969-12-31 16:00:00
@@ -1,80 +0,0 @@
-# Hints
-
-This document describes the inlay hints that `gopls` uses inside the editor.
-
-<!-- BEGIN Hints: DO NOT MANUALLY EDIT THIS SECTION -->
-## **assignVariableTypes**
-
-Enable/disable inlay hints for variable types in assign statements:
-```go
-	i/* int*/, j/* int*/ := 0, len(r)-1
-```
-
-**Disabled by default. Enable it by setting `"hints": {"assignVariableTypes": true}`.**
-
-## **compositeLiteralFields**
-
-Enable/disable inlay hints for composite literal field names:
-```go
-	{/*in: */"Hello, world", /*want: */"dlrow ,olleH"}
-```
-
-**Disabled by default. Enable it by setting `"hints": {"compositeLiteralFields": true}`.**
-
-## **compositeLiteralTypes**
-
-Enable/disable inlay hints for composite literal types:
-```go
-	for _, c := range []struct {
-		in, want string
-	}{
-		/*struct{ in string; want string }*/{"Hello, world", "dlrow ,olleH"},
-	}
-```
-
-**Disabled by default. Enable it by setting `"hints": {"compositeLiteralTypes": true}`.**
-
-## **constantValues**
-
-Enable/disable inlay hints for constant values:
-```go
-	const (
-		KindNone   Kind = iota/* = 0*/
-		KindPrint/*  = 1*/
-		KindPrintf/* = 2*/
-		KindErrorf/* = 3*/
-	)
-```
-
-**Disabled by default. Enable it by setting `"hints": {"constantValues": true}`.**
-
-## **functionTypeParameters**
-
-Enable/disable inlay hints for implicit type parameters on generic functions:
-```go
-	myFoo/*[int, string]*/(1, "hello")
-```
-
-**Disabled by default. Enable it by setting `"hints": {"functionTypeParameters": true}`.**
-
-## **parameterNames**
-
-Enable/disable inlay hints for parameter names:
-```go
-	parseInt(/* str: */ "123", /* radix: */ 8)
-```
-
-**Disabled by default. Enable it by setting `"hints": {"parameterNames": true}`.**
-
-## **rangeVariableTypes**
-
-Enable/disable inlay hints for variable types in range statements:
-```go
-	for k/* int*/, v/* string*/ := range []string{} {
-		fmt.Println(k, v)
-	}
-```
-
-**Disabled by default. Enable it by setting `"hints": {"rangeVariableTypes": true}`.**
-
-<!-- END Hints: DO NOT MANUALLY EDIT THIS SECTION -->
diff -urN a/gopls/doc/releases.md b/gopls/doc/releases.md
--- a/gopls/doc/releases.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/releases.md	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-# Gopls release policy
-
-Gopls releases follow [semver](http://semver.org), with major changes and new
-features introduced only in new minor versions (i.e. versions of the form
-`v*.N.0` for some N). Subsequent patch releases contain only cherry-picked
-fixes or superficial updates.
-
-In order to align with the
-[Go release timeline](https://github.com/golang/go/wiki/Go-Release-Cycle#timeline),
-we aim to release a new minor version of Gopls approximately every three
-months, with patch releases approximately every month, according to the
-following table:
-
-| Month   | Version(s)   |
-| ----    | -------      |
-| Jan     | `v*.<N+0>.0` |
-| Jan-Mar | `v*.<N+0>.*` |
-| Apr     | `v*.<N+1>.0` |
-| Apr-Jun | `v*.<N+1>.*` |
-| Jul     | `v*.<N+2>.0` |
-| Jul-Sep | `v*.<N+2>.*` |
-| Oct     | `v*.<N+3>.0` |
-| Oct-Dec | `v*.<N+3>.*` |
-
-For more background on this policy, see https://go.dev/issue/55267.
diff -urN a/gopls/doc/semantictokens.md b/gopls/doc/semantictokens.md
--- a/gopls/doc/semantictokens.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/semantictokens.md	1969-12-31 16:00:00
@@ -1,121 +0,0 @@
-# Semantic Tokens
-
-The [LSP](https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#textDocument_semanticTokens)
-specifies semantic tokens as a way of telling clients about language-specific
-properties of pieces of code in a file being edited.
-
-The client asks for a set of semantic tokens and modifiers. This note describe which ones
-gopls will return, and under what circumstances. Gopls has no control over how the client
-converts semantic tokens into colors (or some other visible indication). In vscode it
-is possible to modify the color a theme uses by setting the `editor.semanticTokenColorCustomizations`
-object. We provide a little [guidance](#Colors) later.
-
-There are 22 semantic tokens, with 10 possible modifiers. The protocol allows each semantic
-token to be used with any of the 1024 subsets of possible modifiers, but most combinations
-don't make intuitive sense (although `async documentation` has a certain appeal).
-
-The 22 semantic tokens are `namespace`, `type`, `class`, `enum`, `interface`,
-		`struct`, `typeParameter`, `parameter`, `variable`, `property`, `enumMember`,
-		`event`, `function`, `method`, `macro`, `keyword`, `modifier`, `comment`,
-		`string`, `number`, `regexp`, `operator`.
-
-The 10 modifiers are `declaration`, `definition`, `readonly`, `static`,
-		`deprecated`, `abstract`, `async`, `modification`, `documentation`, `defaultLibrary`.
-
-The authoritative lists are in the [specification](https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#semanticTokenTypes)
-
-For the implementation to work correctly the client and server have to agree on the ordering
-of the tokens and of the modifiers. Gopls, therefore, will only send tokens and modifiers
-that the client has asked for. This document says what gopls would send if the client
-asked for everything. By default, vscode asks for everything.
-
-Gopls sends 11 token types for `.go` files and 1 for `.*tmpl` files.
-Nothing is sent for any other kind of file.
-This all could change. (When Go has generics, gopls will return `typeParameter`.)
-
-For `.*tmpl` files gopls sends `macro`, and no modifiers, for each `{{`...`}}` scope.
-
-## Semantic tokens for Go files
-
-There are two contrasting guiding principles that might be used to decide what to mark
-with semantic tokens. All clients already do some kind of syntax marking. E.g., vscode
-uses a TextMate grammar. The minimal principle would send semantic tokens only for those
-language features that cannot be reliably found without parsing Go and looking at types.
-The maximal principle would attempt to convey as much as possible about the Go code,
-using all available parsing and type information.
-
-There is much to be said for returning minimal information, but the minimal principle is
-not well-specified. Gopls has no way of knowing what the clients know about the Go program
-being edited. Even in vscode the TextMate grammars can be more or less elaborate
-and change over time. (Nonetheless, a minimal implementation would not return `keyword`,
-`number`, `comment`, or `string`.)
-
-The maximal position isn't particularly well-specified either. To chose one example, a
-format string might have formatting codes (`%[4]-3.6f`), escape sequences (`\U00010604`), and regular
-characters. Should these all be distinguished? One could even imagine distinguishing
-different runes by their Unicode language assignment, or some other Unicode property, such as
-being [confusable](http://www.unicode.org/Public/security/10.0.0/confusables.txt).
-
-Gopls does not come close to either of these principles.  Semantic tokens are returned for
-identifiers, keywords, operators, comments, and literals. (Sematic tokens do not
-cover the file. They are not returned for
-white space or punctuation, and there is no semantic token for labels.)
-The following describes more precisely what gopls
-does, with a few notes on possible alternative choices.
-The references to *object* refer to the
-```types.Object``` returned by the type checker. The references to *nodes* refer to the
-```ast.Node``` from the parser.
-
-1. __`keyword`__ All Go [keywords](https://golang.org/ref/spec#Keywords) are marked `keyword`.
-1. __`namespace`__ All package names are marked `namespace`. In an import, if there is an
-alias, it would be marked. Otherwise the last component of the import path is marked.
-1. __`type`__ Objects of type ```types.TypeName``` are marked `type`.
-If they are also ```types.Basic```
-the modifier is `defaultLibrary`. (And in ```type B struct{C}```, ```B``` has modifier `definition`.)
-1. __`parameter`__ The formal arguments in ```ast.FuncDecl``` and ```ast.FuncType``` nodes are marked `parameter`.
-1. __`variable`__  Identifiers in the
-scope of ```const``` are modified with `readonly`. ```nil``` is usually a `variable` modified with both
-`readonly` and `defaultLibrary`. (```nil``` is a predefined identifier; the user can redefine it,
-in which case it would just be a variable, or whatever.) Identifiers of type ```types.Variable``` are,
-not surprisingly, marked `variable`. Identifiers being defined (node ```ast.GenDecl```) are modified
-by `definition` and, if appropriate, `readonly`. Receivers (in method declarations) are
-`variable`.
-1. __`method`__ Methods are marked at their definition (```func (x foo) bar() {}```) or declaration
-in an ```interface```. Methods are not marked where they are used.
-In ```x.bar()```, ```x``` will be marked
-either as a `namespace` if it is a package name, or as a `variable` if it is an interface value,
-so distinguishing ```bar``` seemed superfluous.
-1. __`function`__ Bultins (```types.Builtin```) are modified with `defaultLibrary`
-(e.g., ```make```, ```len```, ```copy```). Identifiers whose
-object is ```types.Func``` or whose node is ```ast.FuncDecl``` are `function`.
-1. __`comment`__ Comments and struct tags. (Perhaps struct tags should be `property`?)
-1. __`string`__ Strings. Could add modifiers for e.g., escapes or format codes.
-1. __`number`__ Numbers. Should the ```i``` in ```23i``` be handled specially?
-1. __`operator`__ Assignment operators, binary operators, ellipses (```...```), increment/decrement
-operators, sends (```<-```), and unary operators.
-
-Gopls will send the modifier `deprecated` if it finds a comment
-```// deprecated``` in the godoc.
-
-The unused tokens for Go code are `class`, `enum`, `interface`,
-		`struct`, `typeParameter`, `property`, `enumMember`,
-		`event`, `macro`, `modifier`,
-		`regexp`
-
-## Colors
-
-These comments are about vscode.
-
-The documentation has a [helpful](https://code.visualstudio.com/api/language-extensions/semantic-highlight-guide#custom-textmate-scope-mappings)
-description of which semantic tokens correspond to scopes in TextMate grammars. Themes seem
-to use the TextMate scopes to decide on colors.
-
-Some examples of color customizations are [here](https://medium.com/@danromans/how-to-customize-semantic-token-colorization-with-visual-studio-code-ac3eab96141b).
-
-## Note
-
-While a file is being edited it may temporarily contain either
-parsing errors or type errors. In this case gopls cannot determine some (or maybe any)
-of the semantic tokens. To avoid weird flickering it is the responsibility
-of clients to maintain the semantic token information
-in the unedited part of the file, and they do.
\ No newline at end of file
diff -urN a/gopls/doc/settings.md b/gopls/doc/settings.md
--- a/gopls/doc/settings.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/settings.md	1969-12-31 16:00:00
@@ -1,570 +0,0 @@
-# Settings
-
-<!--TODO: Generate this file from the documentation in golang.org/x/tools/gopls/internal/lsp/source/options.go.-->
-
-This document describes the global settings for `gopls` inside the editor.
-The settings block will be called `"gopls"` and contains a collection of
-controls for `gopls` that the editor is not expected to understand or control.
-These settings can also be configured differently per workspace folder.
-
-In VSCode, this would be a section in your `settings.json` file that might look
-like this:
-
-```json5
-  "gopls": {
-    "ui.completion.usePlaceholders": true,
-     ...
-  },
-```
-
-## Officially supported
-
-Below is the list of settings that are officially supported for `gopls`.
-
-Any settings that are experimental or for debugging purposes are marked as
-such.
-
-To enable all experimental features, use **allExperiments: `true`**. You will
-still be able to independently override specific experimental features.
-
-<!-- BEGIN User: DO NOT MANUALLY EDIT THIS SECTION -->
-
-* [Build](#build)
-* [Formatting](#formatting)
-* [UI](#ui)
-  * [Completion](#completion)
-  * [Diagnostic](#diagnostic)
-  * [Documentation](#documentation)
-  * [Inlayhint](#inlayhint)
-  * [Navigation](#navigation)
-
-### Build
-
-#### **buildFlags** *[]string*
-
-buildFlags is the set of flags passed on to the build system when invoked.
-It is applied to queries like `go list`, which is used when discovering files.
-The most common use is to set `-tags`.
-
-Default: `[]`.
-
-#### **env** *map[string]string*
-
-env adds environment variables to external commands run by `gopls`, most notably `go list`.
-
-Default: `{}`.
-
-#### **directoryFilters** *[]string*
-
-directoryFilters can be used to exclude unwanted directories from the
-workspace. By default, all directories are included. Filters are an
-operator, `+` to include and `-` to exclude, followed by a path prefix
-relative to the workspace folder. They are evaluated in order, and
-the last filter that applies to a path controls whether it is included.
-The path prefix can be empty, so an initial `-` excludes everything.
-
-DirectoryFilters also supports the `**` operator to match 0 or more directories.
-
-Examples:
-
-Exclude node_modules at current depth: `-node_modules`
-
-Exclude node_modules at any depth: `-**/node_modules`
-
-Include only project_a: `-` (exclude everything), `+project_a`
-
-Include only project_a, but not node_modules inside it: `-`, `+project_a`, `-project_a/node_modules`
-
-Default: `["-**/node_modules"]`.
-
-#### **templateExtensions** *[]string*
-
-templateExtensions gives the extensions of file names that are treateed
-as template files. (The extension
-is the part of the file name after the final dot.)
-
-Default: `[]`.
-
-#### **memoryMode** *enum*
-
-**This setting is experimental and may be deleted.**
-
-memoryMode controls the tradeoff `gopls` makes between memory usage and
-correctness.
-
-Values other than `Normal` are untested and may break in surprising ways.
-
-Must be one of:
-
-* `"DegradeClosed"`: In DegradeClosed mode, `gopls` will collect less information about
-packages without open files. As a result, features like Find
-References and Rename will miss results in such packages.
-* `"Normal"`
-
-Default: `"Normal"`.
-
-#### **expandWorkspaceToModule** *bool*
-
-**This setting is experimental and may be deleted.**
-
-expandWorkspaceToModule instructs `gopls` to adjust the scope of the
-workspace to find the best available module root. `gopls` first looks for
-a go.mod file in any parent directory of the workspace folder, expanding
-the scope to that directory if it exists. If no viable parent directory is
-found, gopls will check if there is exactly one child directory containing
-a go.mod file, narrowing the scope to that directory if it exists.
-
-Default: `true`.
-
-#### **experimentalWorkspaceModule** *bool*
-
-**This setting is experimental and may be deleted.**
-
-experimentalWorkspaceModule opts a user into the experimental support
-for multi-module workspaces.
-
-Deprecated: this feature is deprecated and will be removed in a future
-version of gopls (https://go.dev/issue/55331).
-
-Default: `false`.
-
-#### **experimentalPackageCacheKey** *bool*
-
-**This setting is experimental and may be deleted.**
-
-experimentalPackageCacheKey controls whether to use a coarser cache key
-for package type information to increase cache hits. This setting removes
-the user's environment, build flags, and working directory from the cache
-key, which should be a safe change as all relevant inputs into the type
-checking pass are already hashed into the key. This is temporarily guarded
-by an experiment because caching behavior is subtle and difficult to
-comprehensively test.
-
-Default: `true`.
-
-#### **allowModfileModifications** *bool*
-
-**This setting is experimental and may be deleted.**
-
-allowModfileModifications disables -mod=readonly, allowing imports from
-out-of-scope modules. This option will eventually be removed.
-
-Default: `false`.
-
-#### **allowImplicitNetworkAccess** *bool*
-
-**This setting is experimental and may be deleted.**
-
-allowImplicitNetworkAccess disables GOPROXY=off, allowing implicit module
-downloads rather than requiring user action. This option will eventually
-be removed.
-
-Default: `false`.
-
-#### **standaloneTags** *[]string*
-
-standaloneTags specifies a set of build constraints that identify
-individual Go source files that make up the entire main package of an
-executable.
-
-A common example of standalone main files is the convention of using the
-directive `//go:build ignore` to denote files that are not intended to be
-included in any package, for example because they are invoked directly by
-the developer using `go run`.
-
-Gopls considers a file to be a standalone main file if and only if it has
-package name "main" and has a build directive of the exact form
-"//go:build tag" or "// +build tag", where tag is among the list of tags
-configured by this setting. Notably, if the build constraint is more
-complicated than a simple tag (such as the composite constraint
-`//go:build tag && go1.18`), the file is not considered to be a standalone
-main file.
-
-This setting is only supported when gopls is built with Go 1.16 or later.
-
-Default: `["ignore"]`.
-
-### Formatting
-
-#### **local** *string*
-
-local is the equivalent of the `goimports -local` flag, which puts
-imports beginning with this string after third-party packages. It should
-be the prefix of the import path whose imports should be grouped
-separately.
-
-Default: `""`.
-
-#### **gofumpt** *bool*
-
-gofumpt indicates if we should run gofumpt formatting.
-
-Default: `false`.
-
-### UI
-
-#### **codelenses** *map[string]bool*
-
-codelenses overrides the enabled/disabled state of code lenses. See the
-"Code Lenses" section of the
-[Settings page](https://github.com/golang/tools/blob/master/gopls/doc/settings.md#code-lenses)
-for the list of supported lenses.
-
-Example Usage:
-
-```json5
-"gopls": {
-...
-  "codelenses": {
-    "generate": false,  // Don't show the `go generate` lens.
-    "gc_details": true  // Show a code lens toggling the display of gc's choices.
-  }
-...
-}
-```
-
-Default: `{"gc_details":false,"generate":true,"regenerate_cgo":true,"tidy":true,"upgrade_dependency":true,"vendor":true}`.
-
-#### **semanticTokens** *bool*
-
-**This setting is experimental and may be deleted.**
-
-semanticTokens controls whether the LSP server will send
-semantic tokens to the client.
-
-Default: `false`.
-
-#### **noSemanticString** *bool*
-
-**This setting is experimental and may be deleted.**
-
-noSemanticString turns off the sending of the semantic token 'string'
-
-Default: `false`.
-
-#### **noSemanticNumber** *bool*
-
-**This setting is experimental and may be deleted.**
-
-noSemanticNumber  turns off the sending of the semantic token 'number'
-
-Default: `false`.
-
-#### Completion
-
-##### **usePlaceholders** *bool*
-
-placeholders enables placeholders for function parameters or struct
-fields in completion responses.
-
-Default: `false`.
-
-##### **completionBudget** *time.Duration*
-
-**This setting is for debugging purposes only.**
-
-completionBudget is the soft latency goal for completion requests. Most
-requests finish in a couple milliseconds, but in some cases deep
-completions can take much longer. As we use up our budget we
-dynamically reduce the search scope to ensure we return timely
-results. Zero means unlimited.
-
-Default: `"100ms"`.
-
-##### **matcher** *enum*
-
-**This is an advanced setting and should not be configured by most `gopls` users.**
-
-matcher sets the algorithm that is used when calculating completion
-candidates.
-
-Must be one of:
-
-* `"CaseInsensitive"`
-* `"CaseSensitive"`
-* `"Fuzzy"`
-
-Default: `"Fuzzy"`.
-
-##### **experimentalPostfixCompletions** *bool*
-
-**This setting is experimental and may be deleted.**
-
-experimentalPostfixCompletions enables artificial method snippets
-such as "someSlice.sort!".
-
-Default: `true`.
-
-#### Diagnostic
-
-##### **analyses** *map[string]bool*
-
-analyses specify analyses that the user would like to enable or disable.
-A map of the names of analysis passes that should be enabled/disabled.
-A full list of analyzers that gopls uses can be found in
-[analyzers.md](https://github.com/golang/tools/blob/master/gopls/doc/analyzers.md).
-
-Example Usage:
-
-```json5
-...
-"analyses": {
-  "unreachable": false, // Disable the unreachable analyzer.
-  "unusedparams": true  // Enable the unusedparams analyzer.
-}
-...
-```
-
-Default: `{}`.
-
-##### **staticcheck** *bool*
-
-**This setting is experimental and may be deleted.**
-
-staticcheck enables additional analyses from staticcheck.io.
-These analyses are documented on
-[Staticcheck's website](https://staticcheck.io/docs/checks/).
-
-Default: `false`.
-
-##### **annotations** *map[string]bool*
-
-**This setting is experimental and may be deleted.**
-
-annotations specifies the various kinds of optimization diagnostics
-that should be reported by the gc_details command.
-
-Can contain any of:
-
-* `"bounds"` controls bounds checking diagnostics.
-* `"escape"` controls diagnostics about escape choices.
-* `"inline"` controls diagnostics about inlining choices.
-* `"nil"` controls nil checks.
-
-Default: `{"bounds":true,"escape":true,"inline":true,"nil":true}`.
-
-##### **vulncheck** *enum*
-
-**This setting is experimental and may be deleted.**
-
-vulncheck enables vulnerability scanning.
-
-Must be one of:
-
-* `"Imports"`: In Imports mode, `gopls` will report vulnerabilities that affect packages
-directly and indirectly used by the analyzed main module.
-* `"Off"`: Disable vulnerability analysis.
-
-Default: `"Off"`.
-
-##### **diagnosticsDelay** *time.Duration*
-
-**This is an advanced setting and should not be configured by most `gopls` users.**
-
-diagnosticsDelay controls the amount of time that gopls waits
-after the most recent file modification before computing deep diagnostics.
-Simple diagnostics (parsing and type-checking) are always run immediately
-on recently modified packages.
-
-This option must be set to a valid duration string, for example `"250ms"`.
-
-Default: `"250ms"`.
-
-##### **experimentalWatchedFileDelay** *time.Duration*
-
-**This setting is experimental and may be deleted.**
-
-experimentalWatchedFileDelay controls the amount of time that gopls waits
-for additional workspace/didChangeWatchedFiles notifications to arrive,
-before processing all such notifications in a single batch. This is
-intended for use by LSP clients that don't support their own batching of
-file system notifications.
-
-This option must be set to a valid duration string, for example `"100ms"`.
-
-Deprecated: this setting is deprecated and will be removed in a future
-version of gopls (https://go.dev/issue/55332)
-
-Default: `"0s"`.
-
-#### Documentation
-
-##### **hoverKind** *enum*
-
-hoverKind controls the information that appears in the hover text.
-SingleLine and Structured are intended for use only by authors of editor plugins.
-
-Must be one of:
-
-* `"FullDocumentation"`
-* `"NoDocumentation"`
-* `"SingleLine"`
-* `"Structured"` is an experimental setting that returns a structured hover format.
-This format separates the signature from the documentation, so that the client
-can do more manipulation of these fields.\
-This should only be used by clients that support this behavior.
-* `"SynopsisDocumentation"`
-
-Default: `"FullDocumentation"`.
-
-##### **linkTarget** *string*
-
-linkTarget controls where documentation links go.
-It might be one of:
-
-* `"godoc.org"`
-* `"pkg.go.dev"`
-
-If company chooses to use its own `godoc.org`, its address can be used as well.
-
-Modules matching the GOPRIVATE environment variable will not have
-documentation links in hover.
-
-Default: `"pkg.go.dev"`.
-
-##### **linksInHover** *bool*
-
-linksInHover toggles the presence of links to documentation in hover.
-
-Default: `true`.
-
-#### Inlayhint
-
-##### **hints** *map[string]bool*
-
-**This setting is experimental and may be deleted.**
-
-hints specify inlay hints that users want to see. A full list of hints
-that gopls uses can be found in
-[inlayHints.md](https://github.com/golang/tools/blob/master/gopls/doc/inlayHints.md).
-
-Default: `{}`.
-
-#### Navigation
-
-##### **importShortcut** *enum*
-
-importShortcut specifies whether import statements should link to
-documentation or go to definitions.
-
-Must be one of:
-
-* `"Both"`
-* `"Definition"`
-* `"Link"`
-
-Default: `"Both"`.
-
-##### **symbolMatcher** *enum*
-
-**This is an advanced setting and should not be configured by most `gopls` users.**
-
-symbolMatcher sets the algorithm that is used when finding workspace symbols.
-
-Must be one of:
-
-* `"CaseInsensitive"`
-* `"CaseSensitive"`
-* `"FastFuzzy"`
-* `"Fuzzy"`
-
-Default: `"FastFuzzy"`.
-
-##### **symbolStyle** *enum*
-
-**This is an advanced setting and should not be configured by most `gopls` users.**
-
-symbolStyle controls how symbols are qualified in symbol responses.
-
-Example Usage:
-
-```json5
-"gopls": {
-...
-  "symbolStyle": "Dynamic",
-...
-}
-```
-
-Must be one of:
-
-* `"Dynamic"` uses whichever qualifier results in the highest scoring
-match for the given symbol query. Here a "qualifier" is any "/" or "."
-delimited suffix of the fully qualified symbol. i.e. "to/pkg.Foo.Field" or
-just "Foo.Field".
-* `"Full"` is fully qualified symbols, i.e.
-"path/to/pkg.Foo.Field".
-* `"Package"` is package qualified symbols i.e.
-"pkg.Foo.Field".
-
-Default: `"Dynamic"`.
-
-#### **verboseOutput** *bool*
-
-**This setting is for debugging purposes only.**
-
-verboseOutput enables additional debug logging.
-
-Default: `false`.
-
-<!-- END User: DO NOT MANUALLY EDIT THIS SECTION -->
-
-#### **newDiff** *string*
-
-newDiff enables the new diff implementation. If this is "both", for now both
-diffs will be run and statistics will be generated in a file in $TMPDIR. This
-is a risky setting; help in trying it is appreciated. If it is "old" the old
-implementation is used, and if it is "new", just the new implementation is
-used. This setting will eventually be deleted, once gopls has fully migrated to
-the new diff algorithm.
-
-Default: 'both'.
-
-## Code Lenses
-
-These are the code lenses that `gopls` currently supports. They can be enabled
-and disabled using the `codelenses` setting, documented above. Their names and
-features are subject to change.
-
-<!-- BEGIN Lenses: DO NOT MANUALLY EDIT THIS SECTION -->
-### **Toggle gc_details**
-
-Identifier: `gc_details`
-
-Toggle the calculation of gc annotations.
-### **Run go generate**
-
-Identifier: `generate`
-
-Runs `go generate` for a given directory.
-### **Regenerate cgo**
-
-Identifier: `regenerate_cgo`
-
-Regenerates cgo definitions.
-### **Run govulncheck.**
-
-Identifier: `run_govulncheck`
-
-Run vulnerability check (`govulncheck`).
-### **Run test(s) (legacy)**
-
-Identifier: `test`
-
-Runs `go test` for a specific set of test or benchmark functions.
-### **Run go mod tidy**
-
-Identifier: `tidy`
-
-Runs `go mod tidy` for a module.
-### **Upgrade a dependency**
-
-Identifier: `upgrade_dependency`
-
-Upgrades a dependency in the go.mod file for a module.
-### **Run go mod vendor**
-
-Identifier: `vendor`
-
-Runs `go mod vendor` for a module.
-<!-- END Lenses: DO NOT MANUALLY EDIT THIS SECTION -->
diff -urN a/gopls/doc/subl.md b/gopls/doc/subl.md
--- a/gopls/doc/subl.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/subl.md	1969-12-31 16:00:00
@@ -1,81 +0,0 @@
-# Sublime Text
-
-Use the [LSP] package. After installing it using Package Control, do the following:
-
-* Open the **Command Palette**
-* Find and run the command **LSP: Enable Language Server Globally**
-* Select the **gopls** item. Be careful not to select the similarly named *golsp* by mistake.
-
-Finally, you should familiarise yourself with the LSP package's *Settings* and *Key Bindings*. Find them under the menu item **Preferences > Package Settings > LSP**.
-
-## Examples
-Minimal global LSP settings, that assume **gopls** and **go** appear on the PATH seen by Sublime Text:<br>
-```
-{
-    "clients": {
-        "gopls": {
-             "enabled": true,
-         }
-    }
-}
-```
-
-Global LSP settings that supply a specific PATH for finding **gopls** and **go**, as well as some settings for Sublime LSP itself:
-```
-{
-    "clients": {
-        "gopls": {
-            "enabled": true,
-            "env": {
-                "PATH": "/path/to/your/go/bin",
-            }
-        }
-    },
-    // Recommended by https://agniva.me/gopls/2021/01/02/setting-up-gopls-sublime.html
-    // except log_stderr mentioned there is no longer recognized.
-    "show_references_in_quick_panel": true,
-    "log_debug": true,
-    // These two are recommended by LSP-json as replacement for deprecated only_show_lsp_completions
-    "inhibit_snippet_completions": true,
-    "inhibit_word_completions": true,
- }
- ```
-
-LSP and gopls settings can also be adjusted on a per-project basis to override global settings.
-```
-{
-    "folders": [
-        {
-            "path": "/path/to/a/folder/one"
-        },
-        {
-            // If you happen to be working on Go itself, this can be helpful; go-dev/bin should be on PATH.
-            "path": "/path/to/your/go-dev/src/cmd"
-        }
-     ],
-    "settings": {
-        "LSP": {
-            "gopls": {
-                // To use a specific version of gopls with Sublime Text LSP (e.g., to try new features in development)
-                "command": [
-                    "/path/to/your/go/bin/gopls"
-                ],
-                "env": {
-                    "PATH": "/path/to/your/go-dev/bin:/path/to/your/go/bin",
-                    "GOPATH": "",
-                },
-                "settings": {
-                    "experimentalWorkspaceModule": true
-                }
-            }
-        },
-        // This will apply for all languages in this project that have
-        // LSP servers, not just Go, however cannot enable just for Go.
-        "lsp_format_on_save": true,
-    }
-}
-```
-
-Usually changes to these settings are recognized after saving the project file, but it may sometimes be necessary to either restart the server(s) (**Tools > LSP > Restart Servers**) or quit and restart Sublime Text itself.
-
-[LSP]: https://packagecontrol.io/packages/LSP
diff -urN a/gopls/doc/troubleshooting.md b/gopls/doc/troubleshooting.md
--- a/gopls/doc/troubleshooting.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/troubleshooting.md	1969-12-31 16:00:00
@@ -1,48 +0,0 @@
-# Troubleshooting
-
-If you suspect that `gopls` is crashing or not working correctly, please follow the troubleshooting steps below.
-
-If `gopls` is using too much memory, please follow the steps under [Memory usage](#debug-memory-usage).
-
-## Steps
-
-VS Code users should follow [their troubleshooting guide](https://github.com/golang/vscode-go/blob/master/docs/troubleshooting.md), which has more a more specific version of these instructions.
-
-1. Verify that your project is in good shape by working with it outside of your editor. Running a command like `go build ./...` in the workspace directory will compile everything. For modules, `go mod tidy` is another good check, though it may modify your `go.mod`.
-1. Check that your editor isn't showing any diagnostics that indicate a problem with your workspace. They may appear as diagnostics on a Go file's package declaration, diagnostics in a go.mod file, or as a status or progress message. Problems in the workspace configuration can cause many different symptoms. See the [workspace setup instructions](workspace.md) for help.
-1. Make sure `gopls` is up to date by following the [installation instructions](../README.md#installation), then [restarting gopls](#restart-gopls).
-1. Optionally, [ask for help](#ask-for-help) on Gophers Slack.
-1. Finally, [report the issue](#file-an-issue) to the `gopls` developers.
-
-## Restart `gopls`
-
-`gopls` has no persistent state, so restarting it will fix transient problems. This is good and bad: good, because you can keep working, and bad, because you won't be able to debug the issue until it recurs.
-
-In most cases, closing all your open editors will guarantee that `gopls` is killed and restarted. If you don't want to do that, there may be an editor command you can use to restart only `gopls`. Note that some `vim` configurations keep the server alive for a while after the editor exits; you may need to explicitly kill `gopls` if you use `vim`.
-
-## Ask for help
-
-Gophers Slack has active editor-specific channels like [#emacs](https://gophers.slack.com/archives/C0HKHULEM), [#vim](https://gophers.slack.com/archives/C07GBR52P), and [#vscode](https://gophers.slack.com/archives/C2B4L99RS) that can help debug further. If you're confident the problem is with `gopls`, you can go straight to [#gopls](https://gophers.slack.com/archives/CJZH85XCZ). Invites are [available to everyone](https://invite.slack.golangbridge.org). Come prepared with a short description of the issue, and try to be available to answer questions for a while afterward.
-
-## File an issue
-
-We can't diagnose a problem from just a description. When filing an issue, please include as much as possible of the following information:
-
-1. Your editor and any settings you have configured (for example, your VSCode `settings.json` file).
-1. A sample program that reproduces the issue, if possible.
-1. The output of `gopls version` on the command line.
-1. A complete gopls log file from a session where the issue occurred. It should have a `go env for <workspace folder>` log line near the beginning. It's also helpful to tell us the timestamp the problem occurred, so we can find it the log. See the [instructions](#capture-logs) for information on how to capture gopls logs.
-
-Your editor may have a command that fills out some of the necessary information, such as `:GoReportGitHubIssue` in `vim-go`. Otherwise, you can use `gopls bug` on the command line. If neither of those work you can start from scratch directly on the [Go issue tracker](https://github.com/golang/go/issues/new?title=x%2Ftools%2Fgopls%3A%20%3Cfill%20this%20in%3E).
-
-## Capture logs
-
-You may have to change your editor's configuration to pass a `-logfile` flag to gopls.
-
-To increase the level of detail in your logs, start `gopls` with the `-rpc.trace` flag. To start a debug server that will allow you to see profiles and memory usage, start `gopls` with `serve --debug=localhost:6060`. You will then be able to view debug information by navigating to `localhost:6060`.
-
-If you are unsure of how to pass a flag to `gopls` through your editor, please see the [documentation for your editor](../README.md#editors).
-
-## Debug memory usage
-
-`gopls` automatically writes out memory debug information when your usage exceeds 1GB. This information can be found in your temporary directory with names like `gopls.1234-5GiB-withnames.zip`. On Windows, your temporary directory will be located at `%TMP%`, and on Unixes, it will be `$TMPDIR`, which is usually `/tmp`. Please [file an issue](#file-an-issue) with this memory debug information attached. If you are uncomfortable sharing the package names of your code, you can share the `-nonames` zip instead, but it's much less useful.
diff -urN a/gopls/doc/vim.md b/gopls/doc/vim.md
--- a/gopls/doc/vim.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/vim.md	1969-12-31 16:00:00
@@ -1,224 +0,0 @@
-# Vim / Neovim
-
-* [vim-go](#vimgo)
-* [LanguageClient-neovim](#lcneovim)
-* [Ale](#ale)
-* [vim-lsp](#vimlsp)
-* [vim-lsc](#vimlsc)
-* [coc.nvim](#cocnvim)
-* [govim](#govim)
-* [Neovim v0.5.0+](#neovim)
-  * [Installation](#neovim-install)
-  * [Custom Configuration](#neovim-config)
-  * [Imports](#neovim-imports)
-  * [Omnifunc](#neovim-omnifunc)
-  * [Additional Links](#neovim-links)
-
-## <a href="#vimgo" id="vimgo">vim-go</a>
-
-Use [vim-go] ver 1.20+, with the following configuration:
-
-```vim
-let g:go_def_mode='gopls'
-let g:go_info_mode='gopls'
-```
-
-## <a href="#lcneovim" id="lcneovim">LanguageClient-neovim</a>
-
-Use [LanguageClient-neovim], with the following configuration:
-
-```vim
-" Launch gopls when Go files are in use
-let g:LanguageClient_serverCommands = {
-       \ 'go': ['gopls']
-       \ }
-" Run gofmt on save
-autocmd BufWritePre *.go :call LanguageClient#textDocument_formatting_sync()
-```
-
-## <a href="#ale" id="ale">Ale</a>
-
-Use [ale]:
-
-```vim
-let g:ale_linters = {
-  \ 'go': ['gopls'],
-  \}
-```
-
-see [this issue][ale-issue-2179]
-
-## <a href="#vimlsp" id="vimlsp">vim-lsp</a>
-
-Use [prabirshrestha/vim-lsp], with the following configuration:
-
-```vim
-augroup LspGo
-  au!
-  autocmd User lsp_setup call lsp#register_server({
-      \ 'name': 'go-lang',
-      \ 'cmd': {server_info->['gopls']},
-      \ 'whitelist': ['go'],
-      \ })
-  autocmd FileType go setlocal omnifunc=lsp#complete
-  "autocmd FileType go nmap <buffer> gd <plug>(lsp-definition)
-  "autocmd FileType go nmap <buffer> ,n <plug>(lsp-next-error)
-  "autocmd FileType go nmap <buffer> ,p <plug>(lsp-previous-error)
-augroup END
-```
-
-## <a href="#vimlsc" id="vimlsc">vim-lsc</a>
-
-Use [natebosch/vim-lsc], with the following configuration:
-
-```vim
-let g:lsc_server_commands = {
-\  "go": {
-\    "command": "gopls serve",
-\    "log_level": -1,
-\    "suppress_stderr": v:true,
-\  },
-\}
-```
-
-The `log_level` and `suppress_stderr` parts are needed to prevent breakage from logging. See
-issues [#180](https://github.com/natebosch/vim-lsc/issues/180) and
-[#213](https://github.com/natebosch/vim-lsc/issues/213).
-
-## <a href="#cocnvim" id="cocnvim">coc.nvim</a>
-
-Use [coc.nvim], with the following `coc-settings.json` configuration:
-
-```json
-  "languageserver": {
-    "golang": {
-      "command": "gopls",
-      "rootPatterns": ["go.work", "go.mod", ".vim/", ".git/", ".hg/"],
-      "filetypes": ["go"],
-      "initializationOptions": {
-        "usePlaceholders": true
-      }
-    }
-  }
-```
-
-If you use `go.work` files, you may want to set the
-`workspace.workspaceFolderCheckCwd` option. This will force coc.nvim to search
-parent directories for `go.work` files, even if the current open directory has
-a `go.mod` file. See the
-[coc.nvim documentation](https://github.com/neoclide/coc.nvim/wiki/Using-workspaceFolders)
-for more details.
-
-Other [settings](settings.md) can be added in `initializationOptions` too.
-
-The `editor.action.organizeImport` code action will auto-format code and add missing imports. To run this automatically on save, add the following line to your `init.vim`:
-
-```vim
-autocmd BufWritePre *.go :call CocAction('runCommand', 'editor.action.organizeImport')
-```
-
-## <a href="#govim" id="govim">govim</a>
-
-In vim classic only, use the experimental [`govim`], simply follow the [install steps][govim-install].
-
-## <a href="#neovim" id="neovim">Neovim v0.5.0+</a>
-
-To use the new native LSP client in Neovim, make sure you
-[install][nvim-install] Neovim v.0.5.0+,
-the `nvim-lspconfig` configuration helper plugin, and check the
-[`gopls` configuration section][nvim-lspconfig] there.
-
-### <a href="#neovim-install" id="neovim-install">Installation</a>
-
-You can use Neovim's native plugin system.  On a Unix system, you can do that by
-cloning the `nvim-lspconfig` repository into the correct directory:
-
-```sh
-dir="${HOME}/.local/share/nvim/site/pack/nvim-lspconfig/opt/nvim-lspconfig/"
-mkdir -p "$dir"
-cd "$dir"
-git clone 'https://github.com/neovim/nvim-lspconfig.git' .
-```
-
-### <a href="#neovim-config" id="neovim-config">Custom Configuration</a>
-
-You can add custom configuration using Lua.  Here is an example of enabling the
-`unusedparams` check as well as `staticcheck`:
-
-```vim
-lua <<EOF
-  lspconfig = require "lspconfig"
-  util = require "lspconfig/util"
-
-  lspconfig.gopls.setup {
-    cmd = {"gopls", "serve"},
-    filetypes = {"go", "gomod"},
-    root_dir = util.root_pattern("go.work", "go.mod", ".git"),
-    settings = {
-      gopls = {
-        analyses = {
-          unusedparams = true,
-        },
-        staticcheck = true,
-      },
-    },
-  }
-EOF
-```
-
-### <a href="#neovim-imports" id="neovim-imports">Imports</a>
-
-To get your imports ordered on save, like `goimports` does, you can define
-a helper function in Lua:
-
-```vim
-lua <<EOF
-  -- …
-
-  function go_org_imports(wait_ms)
-    local params = vim.lsp.util.make_range_params()
-    params.context = {only = {"source.organizeImports"}}
-    local result = vim.lsp.buf_request_sync(0, "textDocument/codeAction", params, wait_ms)
-    for cid, res in pairs(result or {}) do
-      for _, r in pairs(res.result or {}) do
-        if r.edit then
-          local enc = (vim.lsp.get_client_by_id(cid) or {}).offset_encoding or "utf-16"
-          vim.lsp.util.apply_workspace_edit(r.edit, enc)
-        end
-      end
-    end
-  end
-EOF
-
-autocmd BufWritePre *.go lua go_org_imports()
-```
-
-(Taken from the [discussion][nvim-lspconfig-imports] on Neovim issue tracker.)
-
-### <a href="#neovim-omnifunc" id="neovim-omnifunc">Omnifunc</a>
-
-To make your <kbd>Ctrl</kbd>+<kbd>x</kbd>,<kbd>Ctrl</kbd>+<kbd>o</kbd> work, add
-this to your `init.vim`:
-
-```vim
-autocmd FileType go setlocal omnifunc=v:lua.vim.lsp.omnifunc
-```
-
-### <a href="#neovim-links" id="neovim-links">Additional Links</a>
-
-* [Neovim's official LSP documentation][nvim-docs].
-
-[vim-go]: https://github.com/fatih/vim-go
-[LanguageClient-neovim]: https://github.com/autozimu/LanguageClient-neovim
-[ale]: https://github.com/w0rp/ale
-[ale-issue-2179]: https://github.com/w0rp/ale/issues/2179
-[prabirshrestha/vim-lsp]: https://github.com/prabirshrestha/vim-lsp/
-[natebosch/vim-lsc]: https://github.com/natebosch/vim-lsc/
-[natebosch/vim-lsc#180]: https://github.com/natebosch/vim-lsc/issues/180
-[coc.nvim]: https://github.com/neoclide/coc.nvim/
-[`govim`]: https://github.com/myitcv/govim
-[govim-install]: https://github.com/myitcv/govim/blob/master/README.md#govim---go-development-plugin-for-vim8
-[nvim-docs]: https://neovim.io/doc/user/lsp.html
-[nvim-install]: https://github.com/neovim/neovim/wiki/Installing-Neovim
-[nvim-lspconfig]: https://github.com/neovim/nvim-lspconfig/blob/master/doc/server_configurations.md#gopls
-[nvim-lspconfig-imports]: https://github.com/neovim/nvim-lspconfig/issues/115
diff -urN a/gopls/doc/workspace.md b/gopls/doc/workspace.md
--- a/gopls/doc/workspace.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/doc/workspace.md	1969-12-31 16:00:00
@@ -1,101 +0,0 @@
-# Setting up your workspace
-
-`gopls` supports both Go module and GOPATH modes. However, it needs a defined
-scope in which language features like references, rename, and implementation
-should operate.
-
-The following options are available for configuring this scope:
-
-## Module mode
-
-### One module
-
-If you are working with a single module, you can open the module root (the
-directory containing the `go.mod` file), a subdirectory within the module,
-or a parent directory containing the module.
-
-**Note**: If you open a parent directory containing a module, it must **only**
-contain that single module. Otherwise, you are working with multiple modules.
-
-### Multiple modules
-
-Gopls has several alternatives for working on multiple modules simultaneously,
-described below. Starting with Go 1.18, Go workspaces are the preferred solution.
-
-#### Go workspaces (Go 1.18+)
-
-Starting with Go 1.18, the `go` command has native support for multi-module
-workspaces, via [`go.work`](https://go.dev/ref/mod#workspaces) files. These
-files are recognized by gopls starting with `gopls@v0.8.0`.
-
-The easiest way to work on multiple modules in Go 1.18 and later is therefore
-to create a `go.work` file containing the modules you wish to work on, and set
-your workspace root to the directory containing the `go.work` file.
-
-For example, suppose this repo is checked out into the `$WORK/tools` directory.
-We can work on both `golang.org/x/tools` and `golang.org/x/tools/gopls`
-simultaneously by creating a `go.work` file using `go work init`, followed by
-`go work use MODULE_DIRECTORIES...` to add directories containing `go.mod` files to the
-workspace:
-
-```sh
-cd $WORK
-go work init
-go work use ./tools/ ./tools/gopls/
-```
-
-...followed by opening the `$WORK` directory in our editor.
-
-#### DEPRECATED: Experimental workspace module (Go 1.17 and earlier)
-
-**This feature is deprecated and will be removed in future versions of gopls.
-Please see [issue #52897](https://go.dev/issue/52897) for additional
-information.**
-
-With earlier versions of Go, `gopls` can simulate multi-module workspaces by
-creating a synthetic module requiring the modules in the workspace root.
-See [the design document](https://github.com/golang/proposal/blob/master/design/37720-gopls-workspaces.md)
-for more information.
-
-This feature is experimental, and will eventually be removed once `go.work`
-files are accepted by all supported Go versions.
-
-You can enable this feature by configuring the
-[experimentalWorkspaceModule](settings.md#experimentalworkspacemodule-bool)
-setting.
-
-#### Multiple workspace folders
-
-If neither of the above solutions work, and your editor allows configuring the
-set of
-["workspace folders"](https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#workspaceFolder)
-used during your LSP session, you can still work on multiple modules by adding
-a workspace folder at each module root (the locations of `go.mod` files). This
-means that each module has its own scope, and features will not work across
-modules. 
-
-In VS Code, you can create a workspace folder by setting up a
-[multi-root workspace](https://code.visualstudio.com/docs/editor/multi-root-workspaces).
-View the [documentation for your editor plugin](../README.md#editor) to learn how to
-configure a workspace folder in your editor.
-
-### GOPATH mode
-
-When opening a directory within your GOPATH, the workspace scope will be just
-that directory.
-
-### At your own risk
-
-Some users or companies may have projects that encompass one `$GOPATH`. If you
-open your entire `$GOPATH` or `$GOPATH/src` folder, the workspace scope will be
-your entire `GOPATH`. If your GOPATH is large, `gopls` to be very slow to start
-because it will try to find all of the Go files in the directory you have
-opened. It will then load all of the files it has found.
-
-To work around this case, you can create a new `$GOPATH` that contains only the
-packages you want to work on.
-
----
-
-If you have additional use cases that are not mentioned above, please
-[file a new issue](https://github.com/golang/go/issues/new).
diff -urN a/gopls/go.mod b/gopls/go.mod
--- a/gopls/go.mod	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/go.mod	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-module golang.org/x/tools/gopls
-
-go 1.18
-
-require (
-	github.com/google/go-cmp v0.5.9
-	github.com/jba/printsrc v0.2.2
-	github.com/jba/templatecheck v0.6.0
-	github.com/sergi/go-diff v1.1.0
-	golang.org/x/mod v0.7.0
-	golang.org/x/sync v0.1.0
-	golang.org/x/sys v0.4.0
-	golang.org/x/text v0.6.0
-	golang.org/x/tools v0.4.0
-	golang.org/x/vuln v0.0.0-20221212182831-af59454a8a0a
-	gopkg.in/yaml.v3 v3.0.1
-	honnef.co/go/tools v0.3.3
-	mvdan.cc/gofumpt v0.4.0
-	mvdan.cc/xurls/v2 v2.4.0
-)
-
-require (
-	github.com/BurntSushi/toml v1.2.1 // indirect
-	github.com/google/safehtml v0.1.0 // indirect
-	golang.org/x/exp v0.0.0-20220722155223-a9213eeb770e // indirect
-	golang.org/x/exp/typeparams v0.0.0-20221212164502-fae10dda9338 // indirect
-)
-
-replace golang.org/x/tools => ../
diff -urN a/gopls/go.sum b/gopls/go.sum
--- a/gopls/go.sum	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/go.sum	1969-12-31 16:00:00
@@ -1,100 +0,0 @@
-github.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=
-github.com/BurntSushi/toml v0.4.1/go.mod h1:CxXYINrC8qIiEnFrOxCa7Jy5BFHlXnUU2pbicEuybxQ=
-github.com/BurntSushi/toml v1.2.1 h1:9F2/+DoOYIOksmaJFPw1tGFy1eDnIJXg+UHjuD8lTak=
-github.com/BurntSushi/toml v1.2.1/go.mod h1:CxXYINrC8qIiEnFrOxCa7Jy5BFHlXnUU2pbicEuybxQ=
-github.com/client9/misspell v0.3.4 h1:ta993UF76GwbvJcIo3Y68y/M3WxlpEHPWIGDkJYwzJI=
-github.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=
-github.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=
-github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
-github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
-github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
-github.com/frankban/quicktest v1.14.3 h1:FJKSZTDHjyhriyC81FLQ0LY93eSai0ZyR/ZIkd3ZUKE=
-github.com/frankban/quicktest v1.14.3/go.mod h1:mgiwOwqx65TmIk1wJ6Q7wvnVMocbUorkibMOrVTHZps=
-github.com/google/go-cmdtest v0.4.1-0.20220921163831-55ab3332a786/go.mod h1:apVn/GCasLZUVpAJ6oWAuyP7Ne7CEsQbTnc0plM3m+o=
-github.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=
-github.com/google/go-cmp v0.5.7/go.mod h1:n+brtR0CgQNWTVd5ZUFpTBC8YFBDLK/h/bpaJ8/DtOE=
-github.com/google/go-cmp v0.5.8/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=
-github.com/google/go-cmp v0.5.9 h1:O2Tfq5qg4qc4AmwVlvv0oLiVAGB7enBSJ2x2DqQFi38=
-github.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=
-github.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=
-github.com/google/safehtml v0.0.2/go.mod h1:L4KWwDsUJdECRAEpZoBn3O64bQaywRscowZjJAzjHnU=
-github.com/google/safehtml v0.1.0 h1:EwLKo8qawTKfsi0orxcQAZzu07cICaBeFMegAU9eaT8=
-github.com/google/safehtml v0.1.0/go.mod h1:L4KWwDsUJdECRAEpZoBn3O64bQaywRscowZjJAzjHnU=
-github.com/jba/printsrc v0.2.2 h1:9OHK51UT+/iMAEBlQIIXW04qvKyF3/vvLuwW/hL8tDU=
-github.com/jba/printsrc v0.2.2/go.mod h1:1xULjw59sL0dPdWpDoVU06TIEO/Wnfv6AHRpiElTwYM=
-github.com/jba/templatecheck v0.6.0 h1:SwM8C4hlK/YNLsdcXStfnHWE2HKkuTVwy5FKQHt5ro8=
-github.com/jba/templatecheck v0.6.0/go.mod h1:/1k7EajoSErFI9GLHAsiIJEaNLt3ALKNw2TV7z2SYv4=
-github.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=
-github.com/kr/pretty v0.3.0 h1:WgNl7dwNpEZ6jJ9k1snq4pZsg7DOEN8hP9Xw0Tsjwk0=
-github.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=
-github.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=
-github.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=
-github.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=
-github.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=
-github.com/pkg/diff v0.0.0-20210226163009-20ebb0f2a09e/go.mod h1:pJLUxLENpZxwdsKMEsNbx1VGcRFpLqf3715MtcvvzbA=
-github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
-github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
-github.com/rogpeppe/go-internal v1.6.1/go.mod h1:xXDCJY+GAPziupqXw64V24skbSoqbTEfhy4qGm1nDQc=
-github.com/rogpeppe/go-internal v1.8.1/go.mod h1:JeRgkft04UBgHMgCIwADu4Pn6Mtm5d4nPKWu0nJ5d+o=
-github.com/rogpeppe/go-internal v1.9.0 h1:73kH8U+JUqXU8lRuOHeVHaa/SZPifC7BkcraZVejAe8=
-github.com/rogpeppe/go-internal v1.9.0/go.mod h1:WtVeX8xhTBvf0smdhujwtBcq4Qrzq/fJaraNFVN+nFs=
-github.com/sergi/go-diff v1.1.0 h1:we8PVUC3FE2uYfodKH/nBHMSetSfHDR6scGdBi+erh0=
-github.com/sergi/go-diff v1.1.0/go.mod h1:STckp+ISIX8hZLjrqAeVduY0gWCT9IjLuqbuNXdaHfM=
-github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
-github.com/stretchr/testify v1.4.0 h1:2E4SXV/wtOkTonXsotYi4li6zVWxYlZuYNCXe9XRJyk=
-github.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=
-github.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=
-golang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=
-golang.org/x/exp v0.0.0-20220722155223-a9213eeb770e h1:+WEEuIdZHnUeJJmEUjyYC2gfUMj69yZXw17EnHg/otA=
-golang.org/x/exp v0.0.0-20220722155223-a9213eeb770e/go.mod h1:Kr81I6Kryrl9sr8s2FK3vxD90NdsKWRuOIl2O4CvYbA=
-golang.org/x/exp/typeparams v0.0.0-20220218215828-6cf2b201936e/go.mod h1:AbB0pIl9nAr9wVwH+Z2ZpaocVmF5I4GyWCDIsVjR0bk=
-golang.org/x/exp/typeparams v0.0.0-20221212164502-fae10dda9338 h1:2O2DON6y3XMJiQRAS1UWU+54aec2uopH3x7MAiqGW6Y=
-golang.org/x/exp/typeparams v0.0.0-20221212164502-fae10dda9338/go.mod h1:AbB0pIl9nAr9wVwH+Z2ZpaocVmF5I4GyWCDIsVjR0bk=
-golang.org/x/mod v0.6.0-dev.0.20220106191415-9b9b3d81d5e3/go.mod h1:3p9vT2HGsQu2K1YbXdKPJLVgG5VJdoTa1poYQBtP1AY=
-golang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=
-golang.org/x/mod v0.7.0 h1:LapD9S96VoQRhi/GrNTqeBJFrUjs5UHCAtTlgwA5oZA=
-golang.org/x/mod v0.7.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=
-golang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
-golang.org/x/net v0.5.0/go.mod h1:DivGGAXEgPSlEBzxGzZI+ZLohi+xUj054jfeKui00ws=
-golang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
-golang.org/x/sync v0.0.0-20220819030929-7fc1605a5dde/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
-golang.org/x/sync v0.1.0 h1:wsuoTGHzEhffawBOhz5CYhcrV4IdKZbEyZjBMuTp12o=
-golang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
-golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.0.0-20211019181941-9d821ace8654/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.0.0-20211213223007-03aa0b5f6827/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.0.0-20220829200755-d48e67d00261/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.3.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.4.0 h1:Zr2JFtRQNX3BCZ8YtxRE9hNJYC8J6I1MVbMg6owUp18=
-golang.org/x/sys v0.4.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=
-golang.org/x/term v0.4.0/go.mod h1:9P2UbLfCdcvo3p/nzKvsmas4TnlujnuoV9hGgYzW1lQ=
-golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
-golang.org/x/text v0.6.0 h1:3XmdazWV+ubf7QgHSTWeykHOci5oeekaGJBLkrkaw4k=
-golang.org/x/text v0.6.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
-golang.org/x/vuln v0.0.0-20221212182831-af59454a8a0a h1:KWIh6uTTw7r3PEz1N1OIEM8pr5bf1uP1n6JL5Ml56X8=
-golang.org/x/vuln v0.0.0-20221212182831-af59454a8a0a/go.mod h1:54iI0rrZVM8VdIvTrT/sdlVfMUJWOgvTRQN24CEtZk0=
-golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
-golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
-golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
-gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
-gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
-gopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15 h1:YR8cESwS4TdDjEe65xsg0ogRM/Nc3DYOhEAlW+xobZo=
-gopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
-gopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=
-gopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
-gopkg.in/yaml.v2 v2.2.4 h1:/eiJrUcujPVeJ3xlSWaiNi3uSVmDGBK1pDHUHAnao1I=
-gopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
-gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
-gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
-honnef.co/go/tools v0.2.2/go.mod h1:lPVVZ2BS5TfnjLyizF7o7hv7j9/L+8cZY2hLyjP9cGY=
-honnef.co/go/tools v0.3.3 h1:oDx7VAwstgpYpb3wv0oxiZlxY+foCpRAwY7Vk6XpAgA=
-honnef.co/go/tools v0.3.3/go.mod h1:jzwdWgg7Jdq75wlfblQxO4neNaFFSvgc1tD5Wv8U0Yw=
-mvdan.cc/gofumpt v0.4.0 h1:JVf4NN1mIpHogBj7ABpgOyZc65/UUOkKQFkoURsz4MM=
-mvdan.cc/gofumpt v0.4.0/go.mod h1:PljLOHDeZqgS8opHRKLzp2It2VBuSdteAgqUfzMTxlQ=
-mvdan.cc/unparam v0.0.0-20211214103731-d0ef000c54e5 h1:Jh3LAeMt1eGpxomyu3jVkmVZWW2MxZ1qIIV2TZ/nRio=
-mvdan.cc/unparam v0.0.0-20211214103731-d0ef000c54e5/go.mod h1:b8RRCBm0eeiWR8cfN88xeq2G5SG3VKGO+5UPWi5FSOY=
-mvdan.cc/xurls/v2 v2.4.0 h1:tzxjVAj+wSBmDcF6zBB7/myTy3gX9xvi8Tyr28AuQgc=
-mvdan.cc/xurls/v2 v2.4.0/go.mod h1:+GEjq9uNjqs8LQfM9nVnM8rff0OQ5Iash5rzX+N1CSg=
diff -urN a/gopls/integration/govim/Dockerfile b/gopls/integration/govim/Dockerfile
--- a/gopls/integration/govim/Dockerfile	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/Dockerfile	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-# Copyright 2019 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-
-# govim requires a more recent version of vim than is available in most
-# distros, so we build from their base image.
-FROM govim/govim:latest-vim
-ARG GOVIM_REF
-
-ENV GOPROXY=https://proxy.golang.org GOPATH=/go VIM_FLAVOR=vim
-WORKDIR /src
-
-# Clone govim. In order to use the go command for resolving latest, we download
-# a redundant copy of govim to the build cache using `go mod download`.
-RUN git clone https://github.com/govim/govim /src/govim && cd /src/govim && \
-    git checkout $GOVIM_REF
diff -urN a/gopls/integration/govim/README.md b/gopls/integration/govim/README.md
--- a/gopls/integration/govim/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/README.md	1969-12-31 16:00:00
@@ -1,47 +0,0 @@
-# govim integration tests
-
-Files in this directory configure Cloud Build to run [govim] integration tests
-against a gopls binary built from source.
-
-## Running on GCP
-
-To run these integration tests in Cloud Build, use the following steps.  Here
-we assume that `$PROJECT_ID` is a valid GCP project and `$BUCKET` is a cloud
-storage bucket owned by that project.
-
-- `cd` to the root directory of the tools project.
-- (at least once per GCP project) Build the test harness:
-```
-$ gcloud builds submit \
-	--project="${PROJECT_ID}" \
-	--config=gopls/integration/govim/cloudbuild.harness.yaml
-```
-- Run the integration tests:
-```
-$ gcloud builds submit \
-	--project="${PROJECT_ID}" \
-	--config=gopls/integration/govim/cloudbuild.yaml \
-	--substitutions=_RESULT_BUCKET="${BUCKET}"
-```
-
-## Fetching Artifacts
-
-Assuming the artifacts bucket is world readable, you can fetch integration from
-GCS. They are located at:
-
-- logs: `https://storage.googleapis.com/${BUCKET}/log-${EVALUATION_ID}.txt`
-- artifact tarball: `https://storage.googleapis.com/${BUCKET}/govim/${EVALUATION_ID}/artifacts.tar.gz`
-
-The `artifacts.go` command can be used to fetch both artifacts using an
-evaluation id.
-
-## Running locally
-
-Run `gopls/integration/govim/run_local.sh`. This may take a while the first
-time it is run, as it will require building the test harness. This script
-accepts two flags to modify its behavior:
-
-**--sudo**: run docker with `sudo`
-**--short**: run `go test -short`
-
-[govim]: https://github.com/govim/govim
diff -urN a/gopls/integration/govim/artifacts.go b/gopls/integration/govim/artifacts.go
--- a/gopls/integration/govim/artifacts.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/artifacts.go	1969-12-31 16:00:00
@@ -1,67 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package main
-
-import (
-	"flag"
-	"fmt"
-	"io/ioutil"
-	"net/http"
-	"os"
-	"path"
-)
-
-var bucket = flag.String("bucket", "golang-gopls_integration_tests", "GCS bucket holding test artifacts.")
-
-const usage = `
-artifacts [--bucket=<bucket ID>] <cloud build evaluation ID>
-
-Fetch artifacts from an integration test run. Evaluation ID should be extracted
-from the cloud build notification.
-
-In order for this to work, the GCS bucket that artifacts were written to must
-be publicly readable. By default, this fetches from the
-golang-gopls_integration_tests bucket.
-`
-
-func main() {
-	flag.Usage = func() {
-		fmt.Fprint(flag.CommandLine.Output(), usage)
-	}
-	flag.Parse()
-	if flag.NArg() != 1 {
-		flag.Usage()
-		os.Exit(2)
-	}
-	evalID := flag.Arg(0)
-	logURL := fmt.Sprintf("https://storage.googleapis.com/%s/log-%s.txt", *bucket, evalID)
-	if err := download(logURL); err != nil {
-		fmt.Fprintf(os.Stderr, "downloading logs: %v", err)
-	}
-	tarURL := fmt.Sprintf("https://storage.googleapis.com/%s/govim/%s/artifacts.tar.gz", *bucket, evalID)
-	if err := download(tarURL); err != nil {
-		fmt.Fprintf(os.Stderr, "downloading artifact tarball: %v", err)
-	}
-}
-
-func download(artifactURL string) error {
-	name := path.Base(artifactURL)
-	resp, err := http.Get(artifactURL)
-	if err != nil {
-		return fmt.Errorf("fetching from GCS: %v", err)
-	}
-	defer resp.Body.Close()
-	if resp.StatusCode != http.StatusOK {
-		return fmt.Errorf("got status code %d from GCS", resp.StatusCode)
-	}
-	data, err := ioutil.ReadAll(resp.Body)
-	if err != nil {
-		return fmt.Errorf("reading result: %v", err)
-	}
-	if err := ioutil.WriteFile(name, data, 0644); err != nil {
-		return fmt.Errorf("writing artifact: %v", err)
-	}
-	return nil
-}
diff -urN a/gopls/integration/govim/cloudbuild.harness.yaml b/gopls/integration/govim/cloudbuild.harness.yaml
--- a/gopls/integration/govim/cloudbuild.harness.yaml	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/cloudbuild.harness.yaml	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-# Copyright 2019 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-
-# Build the govim test harness that will be used to run govim integration tests
-# for gopls. See README.md for instructions on how to use this.
-steps:
-  - name: 'gcr.io/cloud-builders/docker'
-    args: ['build',
-      # To allow for breaking changes to this test harness, tag with a major
-      # version number.
-      '-t', 'gcr.io/$PROJECT_ID/govim-harness:latest',
-      '-t', 'gcr.io/$PROJECT_ID/govim-harness:3',
-      # It is assumed that this build is running from the root directory of the
-      # tools repository.
-      '-f', 'gopls/integration/govim/Dockerfile',
-      # Use the integration test directory as build context: the test harness
-      # doesn't actually require any local files.
-      'gopls/integration/govim']
-images:
-  - gcr.io/$PROJECT_ID/govim-harness
diff -urN a/gopls/integration/govim/cloudbuild.yaml b/gopls/integration/govim/cloudbuild.yaml
--- a/gopls/integration/govim/cloudbuild.yaml	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/cloudbuild.yaml	1969-12-31 16:00:00
@@ -1,51 +0,0 @@
-# Copyright 2019 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-
-# Build gopls, and run the govim integration tests.  See README.md for
-# instructions on how to use this.
-
-substitutions:
-  # This bucket must be owned by the GCP project executing the build. If
-  # you are running this from your own project, override using --substitutions.
-  _RESULT_BUCKET: 'golang-gopls_integration_tests'
-
-steps:
-  # Build gopls from source, to use with the govim integration tests.
-  - name: 'golang:1.14'
-    env: ['GOPROXY=https://proxy.golang.org']
-    dir: 'gopls'
-    args: ['go', 'build']
-
-  # Run the tests. Note that the script in this step does not return the exit
-  # code from `go test`, but rather saves it for use in the final step after
-  # uploading artifacts.
-  - name: 'gcr.io/$PROJECT_ID/govim-harness:3'
-    dir: '/src/govim'
-    volumes:
-      - name: artifacts
-        path: /artifacts
-    env:
-      - GOVIM_TESTSCRIPT_WORKDIR_ROOT=/artifacts
-      - VIM_FLAVOR=vim
-    args: ['/workspace/gopls/integration/govim/run_tests_for_cloudbuild.sh']
-
-  # The govim tests produce a large number of artifacts; tarball/gzip to reduce
-  # roundtrips and save space.
-  - name: 'ubuntu'
-    volumes:
-      - name: artifacts
-        path: /artifacts
-    args: ['tar', '-czf', 'artifacts.tar.gz', '/artifacts']
-
-  # Upload artifacts to GCS.
-  - name: 'gcr.io/cloud-builders/gsutil'
-    args: ['cp', 'artifacts.tar.gz', 'gs://${_RESULT_BUCKET}/govim/${BUILD_ID}/artifacts.tar.gz']
-
-  # Exit with the actual exit code of the integration tests.
-  - name: 'ubuntu'
-    args: ['bash', 'govim_test_result.sh']
-
-# Write build logs to the same bucket as artifacts, so they can be more easily
-# shared.
-logsBucket: 'gs://${_RESULT_BUCKET}'
diff -urN a/gopls/integration/govim/run_local.sh b/gopls/integration/govim/run_local.sh
--- a/gopls/integration/govim/run_local.sh	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/run_local.sh	1969-12-31 16:00:00
@@ -1,96 +0,0 @@
-#!/bin/bash -e
-
-# Copyright 2019 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-
-# Run govim integration tests against a local gopls.
-
-usage() {
-  cat <<EOUSAGE
-Usage: $0 [--sudo] [--short] [--version (semver|latest)]
-
-Args:
-  --sudo     run docker with sudo
-  --short    run `go test` with `-short`
-  --version  run on the specific tagged govim version (or latest) rather
-             than the default branch
-
-Run govim tests against HEAD using local docker.
-EOUSAGE
-}
-
-SUDO_IF_NEEDED=
-TEST_SHORT=
-DOCKERFILE=gopls/integration/govim/Dockerfile
-GOVIM_REF=main
-while [[ $# -gt 0 ]]; do
-  case "$1" in
-    "-h" | "--help" | "help")
-      usage
-      exit 0
-      ;;
-    "--sudo")
-      SUDO_IF_NEEDED="sudo "
-      shift
-      ;;
-    "--short")
-      TEST_SHORT="-short"
-      shift
-      ;;
-    "--version")
-      if [[ -z "$2" ]]; then
-        usage
-        exit 1
-      fi
-      GOVIM_REF=$2
-      if [[ "${GOVIM_REF}" == "latest" ]]; then
-        TMPGOPATH=$(mktemp -d)
-        trap "GOPATH=${TMPGOPATH} go clean -modcache && rm -r ${TMPGOPATH}" EXIT
-        GOVIM_REF=$(GOPATH=${TMPGOPATH} go mod download -json \
-          github.com/govim/govim@latest | jq -r .Version)
-      fi
-      shift 2
-      ;;
-    *)
-      usage
-      exit 1
-  esac
-done
-
-# Find the tools root, so that this script can be run from any directory.
-script_dir=$(dirname "$(readlink -f "$0")")
-tools_dir=$(readlink -f "${script_dir}/../../..")
-
-# Build gopls.
-cd "${tools_dir}/gopls"
-temp_gopls=$(mktemp -p "$PWD")
-trap "rm -f \"${temp_gopls}\"" EXIT
-# For consistency across environments, use golang docker to build rather than
-# the local go command.
-${SUDO_IF_NEEDED}docker run --rm -t \
-  -v "${tools_dir}:/src/tools" \
-  -w "/src/tools/gopls" \
-  golang:rc \
-  go build -o $(basename ${temp_gopls})
-
-# Build the test harness. Here we are careful to pass in a very limited build
-# context so as to optimize caching.
-echo "Checking out govim@${GOVIM_REF}"
-cd "${tools_dir}"
-${SUDO_IF_NEEDED}docker build \
-  --build-arg GOVIM_REF="${GOVIM_REF}" \
-  -t gopls-govim-harness:${GOVIM_REF} \
-  -f gopls/integration/govim/Dockerfile \
-  gopls/integration/govim
-
-# Run govim integration tests.
-echo "running govim integration tests using ${temp_gopls}"
-temp_gopls_name=$(basename "${temp_gopls}")
-${SUDO_IF_NEEDED}docker run --rm -t \
-  -v "${tools_dir}:/src/tools" \
-  -w "/src/govim" \
-  --ulimit memlock=-1:-1 \
-  gopls-govim-harness:${GOVIM_REF} \
-  go test ${TEST_SHORT} ./cmd/govim \
-    -gopls "/src/tools/gopls/${temp_gopls_name}"
diff -urN a/gopls/integration/govim/run_tests_for_cloudbuild.sh b/gopls/integration/govim/run_tests_for_cloudbuild.sh
--- a/gopls/integration/govim/run_tests_for_cloudbuild.sh	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/integration/govim/run_tests_for_cloudbuild.sh	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-#!/bin/bash
-
-# Copyright 2020 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-
-# This script runs govim integration tests but always succeeds, instead writing
-# their result to a file so that any test failure can be deferred to a later
-# build step. We do this so that we can capture govim test artifacts regardless
-# of the test results.
-
-# Substitute the locally built gopls binary for use in govim integration tests.
-go test -short ./cmd/govim -gopls /workspace/gopls/gopls
-
-# Stash the error, for use in a later build step.
-echo "exit $?" > /workspace/govim_test_result.sh
-
-# Clean up unnecessary artifacts. This is based on govim/_scripts/tidyUp.bash.
-# Since we're fetching govim using the go command, we won't have this non-go
-# source directory available to us.
-if [[ -n "$GOVIM_TESTSCRIPT_WORKDIR_ROOT" ]]; then
-  echo "Cleaning up build artifacts..."
-  # Make artifacts writable so that rm -rf doesn't complain.
-  chmod -R u+w "$GOVIM_TESTSCRIPT_WORKDIR_ROOT"
-
-  # Remove directories we don't care about.
-  find "$GOVIM_TESTSCRIPT_WORKDIR_ROOT" -type d \( -name .vim -o -name gopath \) -prune -exec rm -rf '{}' \;
-fi
diff -urN a/gopls/internal/coverage/coverage.go b/gopls/internal/coverage/coverage.go
--- a/gopls/internal/coverage/coverage.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/coverage/coverage.go	1969-12-31 16:00:00
@@ -1,266 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go.1.16
-// +build go.1.16
-
-// Running this program in the tools directory will produce a coverage file /tmp/cover.out
-// and a coverage report for all the packages under internal/lsp, accumulated by all the tests
-// under gopls.
-//
-// -o controls where the coverage file is written, defaulting to /tmp/cover.out
-// -i coverage-file will generate the report from an existing coverage file
-// -v controls verbosity (0: only report coverage, 1: report as each directory is finished,
-//
-//	2: report on each test, 3: more details, 4: too much)
-//
-// -t tests only tests packages in the given comma-separated list of directories in gopls.
-//
-//	The names should start with ., as in ./internal/regtest/bench
-//
-// -run tests. If set, -run tests is passed on to the go test command.
-//
-// Despite gopls' use of goroutines, the counts are almost deterministic.
-package main
-
-import (
-	"bytes"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"log"
-	"os"
-	"os/exec"
-	"path/filepath"
-	"sort"
-	"strings"
-	"time"
-
-	"golang.org/x/tools/cover"
-)
-
-var (
-	proFile = flag.String("i", "", "existing profile file")
-	outFile = flag.String("o", "/tmp/cover.out", "where to write the coverage file")
-	verbose = flag.Int("v", 0, "how much detail to print as tests are running")
-	tests   = flag.String("t", "", "list of tests to run")
-	run     = flag.String("run", "", "value of -run to pass to go test")
-)
-
-func main() {
-	log.SetFlags(log.Lshortfile)
-	flag.Parse()
-
-	if *proFile != "" {
-		report(*proFile)
-		return
-	}
-
-	checkCwd()
-	// find the packages under gopls containing tests
-	tests := listDirs("gopls")
-	tests = onlyTests(tests)
-	tests = realTestName(tests)
-
-	// report coverage for packages under internal/lsp
-	parg := "golang.org/x/tools/gopls/internal/lsp/..."
-
-	accum := []string{}
-	seen := make(map[string]bool)
-	now := time.Now()
-	for _, toRun := range tests {
-		if excluded(toRun) {
-			continue
-		}
-		x := runTest(toRun, parg)
-		if *verbose > 0 {
-			fmt.Printf("finished %s %.1fs\n", toRun, time.Since(now).Seconds())
-		}
-		lines := bytes.Split(x, []byte{'\n'})
-		for _, l := range lines {
-			if len(l) == 0 {
-				continue
-			}
-			if !seen[string(l)] {
-				// not accumulating counts, so only works for mode:set
-				seen[string(l)] = true
-				accum = append(accum, string(l))
-			}
-		}
-	}
-	sort.Strings(accum[1:])
-	if err := os.WriteFile(*outFile, []byte(strings.Join(accum, "\n")), 0644); err != nil {
-		log.Print(err)
-	}
-	report(*outFile)
-}
-
-type result struct {
-	Time    time.Time
-	Test    string
-	Action  string
-	Package string
-	Output  string
-	Elapsed float64
-}
-
-func runTest(tName, parg string) []byte {
-	args := []string{"test", "-short", "-coverpkg", parg, "-coverprofile", *outFile,
-		"-json"}
-	if *run != "" {
-		args = append(args, fmt.Sprintf("-run=%s", *run))
-	}
-	args = append(args, tName)
-	cmd := exec.Command("go", args...)
-	cmd.Dir = "./gopls"
-	ans, err := cmd.Output()
-	if *verbose > 1 {
-		got := strings.Split(string(ans), "\n")
-		for _, g := range got {
-			if g == "" {
-				continue
-			}
-			var m result
-			if err := json.Unmarshal([]byte(g), &m); err != nil {
-				log.Printf("%T/%v", err, err) // shouldn't happen
-				continue
-			}
-			maybePrint(m)
-		}
-	}
-	if err != nil {
-		log.Printf("%s: %q, cmd=%s", tName, ans, cmd.String())
-	}
-	buf, err := os.ReadFile(*outFile)
-	if err != nil {
-		log.Fatal(err)
-	}
-	return buf
-}
-
-func report(fn string) {
-	profs, err := cover.ParseProfiles(fn)
-	if err != nil {
-		log.Fatal(err)
-	}
-	for _, p := range profs {
-		statements, counts := 0, 0
-		for _, x := range p.Blocks {
-			statements += x.NumStmt
-			if x.Count != 0 {
-				counts += x.NumStmt // sic: if any were executed, all were
-			}
-		}
-		pc := 100 * float64(counts) / float64(statements)
-		fmt.Printf("%3.0f%% %3d/%3d %s\n", pc, counts, statements, p.FileName)
-	}
-}
-
-var todo []string // tests to run
-
-func excluded(tname string) bool {
-	if *tests == "" { // run all tests
-		return false
-	}
-	if todo == nil {
-		todo = strings.Split(*tests, ",")
-	}
-	for _, nm := range todo {
-		if tname == nm { // run this test
-			return false
-		}
-	}
-	// not in list, skip it
-	return true
-}
-
-// should m.Package be printed sometime?
-func maybePrint(m result) {
-	switch m.Action {
-	case "pass", "fail", "skip":
-		fmt.Printf("%s %s %.3f\n", m.Action, m.Test, m.Elapsed)
-	case "run":
-		if *verbose > 2 {
-			fmt.Printf("%s %s %.3f\n", m.Action, m.Test, m.Elapsed)
-		}
-	case "output":
-		if *verbose > 3 {
-			fmt.Printf("%s %s %q %.3f\n", m.Action, m.Test, m.Output, m.Elapsed)
-		}
-	case "pause", "cont":
-		if *verbose > 2 {
-			fmt.Printf("%s %s %.3f\n", m.Action, m.Test, m.Elapsed)
-		}
-	default:
-		fmt.Printf("%#v\n", m)
-		log.Fatalf("unknown action %s\n", m.Action)
-	}
-}
-
-// return only the directories that contain tests
-func onlyTests(s []string) []string {
-	ans := []string{}
-outer:
-	for _, d := range s {
-		files, err := os.ReadDir(d)
-		if err != nil {
-			log.Fatalf("%s: %v", d, err)
-		}
-		for _, de := range files {
-			if strings.Contains(de.Name(), "_test.go") {
-				ans = append(ans, d)
-				continue outer
-			}
-		}
-	}
-	return ans
-}
-
-// replace the prefix gopls/ with ./ as the tests are run in the gopls directory
-func realTestName(p []string) []string {
-	ans := []string{}
-	for _, x := range p {
-		x = x[len("gopls/"):]
-		ans = append(ans, "./"+x)
-	}
-	return ans
-}
-
-// make sure we start in a tools directory
-func checkCwd() {
-	dir, err := os.Getwd()
-	if err != nil {
-		log.Fatal(err)
-	}
-	// we expect to be at the root of golang.org/x/tools
-	cmd := exec.Command("go", "list", "-m", "-f", "{{.Dir}}", "golang.org/x/tools")
-	buf, err := cmd.Output()
-	buf = bytes.Trim(buf, "\n \t") // remove \n at end
-	if err != nil {
-		log.Fatal(err)
-	}
-	if string(buf) != dir {
-		log.Fatalf("wrong directory: in %q, should be in %q", dir, string(buf))
-	}
-	// and we expect gopls and internal/lsp as subdirectories
-	_, err = os.Stat("gopls")
-	if err != nil {
-		log.Fatalf("expected a gopls directory, %v", err)
-	}
-}
-
-func listDirs(dir string) []string {
-	ans := []string{}
-	f := func(path string, dirEntry os.DirEntry, err error) error {
-		if strings.HasSuffix(path, "/testdata") || strings.HasSuffix(path, "/typescript") {
-			return filepath.SkipDir
-		}
-		if dirEntry.IsDir() {
-			ans = append(ans, path)
-		}
-		return nil
-	}
-	filepath.WalkDir(dir, f)
-	return ans
-}
diff -urN a/gopls/internal/govulncheck/semver/semver.go b/gopls/internal/govulncheck/semver/semver.go
--- a/gopls/internal/govulncheck/semver/semver.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/semver/semver.go	1969-12-31 16:00:00
@@ -1,51 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-// Package semver provides shared utilities for manipulating
-// Go semantic versions.
-package semver
-
-import (
-	"regexp"
-	"strings"
-)
-
-// addSemverPrefix adds a 'v' prefix to s if it isn't already prefixed
-// with 'v' or 'go'. This allows us to easily test go-style SEMVER
-// strings against normal SEMVER strings.
-func addSemverPrefix(s string) string {
-	if !strings.HasPrefix(s, "v") && !strings.HasPrefix(s, "go") {
-		return "v" + s
-	}
-	return s
-}
-
-// removeSemverPrefix removes the 'v' or 'go' prefixes from go-style
-// SEMVER strings, for usage in the public vulnerability format.
-func removeSemverPrefix(s string) string {
-	s = strings.TrimPrefix(s, "v")
-	s = strings.TrimPrefix(s, "go")
-	return s
-}
-
-// CanonicalizeSemverPrefix turns a SEMVER string into the canonical
-// representation using the 'v' prefix, as used by the OSV format.
-// Input may be a bare SEMVER ("1.2.3"), Go prefixed SEMVER ("go1.2.3"),
-// or already canonical SEMVER ("v1.2.3").
-func CanonicalizeSemverPrefix(s string) string {
-	return addSemverPrefix(removeSemverPrefix(s))
-}
-
-var (
-	// Regexp for matching go tags. The groups are:
-	// 1  the major.minor version
-	// 2  the patch version, or empty if none
-	// 3  the entire prerelease, if present
-	// 4  the prerelease type ("beta" or "rc")
-	// 5  the prerelease number
-	tagRegexp = regexp.MustCompile(`^go(\d+\.\d+)(\.\d+|)((beta|rc|-pre)(\d+))?$`)
-)
diff -urN a/gopls/internal/govulncheck/semver/semver_test.go b/gopls/internal/govulncheck/semver/semver_test.go
--- a/gopls/internal/govulncheck/semver/semver_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/semver/semver_test.go	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package semver
-
-import (
-	"testing"
-)
-
-func TestCanonicalize(t *testing.T) {
-	for _, test := range []struct {
-		v    string
-		want string
-	}{
-		{"v1.2.3", "v1.2.3"},
-		{"1.2.3", "v1.2.3"},
-		{"go1.2.3", "v1.2.3"},
-	} {
-		got := CanonicalizeSemverPrefix(test.v)
-		if got != test.want {
-			t.Errorf("want %s; got %s", test.want, got)
-		}
-	}
-}
diff -urN a/gopls/internal/govulncheck/types.go b/gopls/internal/govulncheck/types.go
--- a/gopls/internal/govulncheck/types.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/types.go	1969-12-31 16:00:00
@@ -1,37 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package govulncheck
-
-import "time"
-
-// Result is the result of vulnerability scanning.
-type Result struct {
-	// Vulns contains all vulnerabilities that are called or imported by
-	// the analyzed module.
-	Vulns []*Vuln `json:",omitempty"`
-
-	// Mode contains the source of the vulnerability info.
-	// Clients of the gopls.fetch_vulncheck_result command may need
-	// to interprete the vulnerabilities differently based on the
-	// analysis mode. For example, Vuln without callstack traces
-	// indicate a vulnerability that is not used if the result was
-	// from 'govulncheck' analysis mode. On the other hand, Vuln
-	// without callstack traces just implies the package with the
-	// vulnerability is known to the workspace and we do not know
-	// whether the vulnerable symbols are actually used or not.
-	Mode AnalysisMode `json:",omitempty"`
-
-	// AsOf describes when this Result was computed using govulncheck.
-	// It is valid only with the govulncheck analysis mode.
-	AsOf time.Time `json:",omitempty"`
-}
-
-type AnalysisMode string
-
-const (
-	ModeInvalid     AnalysisMode = "" // zero value
-	ModeGovulncheck AnalysisMode = "govulncheck"
-	ModeImports     AnalysisMode = "imports"
-)
diff -urN a/gopls/internal/govulncheck/types_118.go b/gopls/internal/govulncheck/types_118.go
--- a/gopls/internal/govulncheck/types_118.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/types_118.go	1969-12-31 16:00:00
@@ -1,43 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-// Package govulncheck provides an experimental govulncheck API.
-package govulncheck
-
-import (
-	"golang.org/x/vuln/exp/govulncheck"
-)
-
-var (
-	// Source reports vulnerabilities that affect the analyzed packages.
-	Source = govulncheck.Source
-
-	// DefaultCache constructs cache for a vulnerability database client.
-	DefaultCache = govulncheck.DefaultCache
-)
-
-type (
-	// Config is the configuration for Main.
-	Config = govulncheck.Config
-
-	// Vuln represents a single OSV entry.
-	Vuln = govulncheck.Vuln
-
-	// Module represents a specific vulnerability relevant to a
-	// single module or package.
-	Module = govulncheck.Module
-
-	// Package is a Go package with known vulnerable symbols.
-	Package = govulncheck.Package
-
-	// CallStacks contains a representative call stack for each
-	// vulnerable symbol that is called.
-	CallStack = govulncheck.CallStack
-
-	// StackFrame represents a call stack entry.
-	StackFrame = govulncheck.StackFrame
-)
diff -urN a/gopls/internal/govulncheck/types_not118.go b/gopls/internal/govulncheck/types_not118.go
--- a/gopls/internal/govulncheck/types_not118.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/types_not118.go	1969-12-31 16:00:00
@@ -1,126 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.18
-// +build !go1.18
-
-package govulncheck
-
-import (
-	"go/token"
-
-	"golang.org/x/vuln/osv"
-)
-
-// Vuln represents a single OSV entry.
-type Vuln struct {
-	// OSV contains all data from the OSV entry for this vulnerability.
-	OSV *osv.Entry
-
-	// Modules contains all of the modules in the OSV entry where a
-	// vulnerable package is imported by the target source code or binary.
-	//
-	// For example, a module M with two packages M/p1 and M/p2, where only p1
-	// is vulnerable, will appear in this list if and only if p1 is imported by
-	// the target source code or binary.
-	Modules []*Module
-}
-
-func (v *Vuln) IsCalled() bool {
-	return false
-}
-
-// Module represents a specific vulnerability relevant to a single module.
-type Module struct {
-	// Path is the module path of the module containing the vulnerability.
-	//
-	// Importable packages in the standard library will have the path "stdlib".
-	Path string
-
-	// FoundVersion is the module version where the vulnerability was found.
-	FoundVersion string
-
-	// FixedVersion is the module version where the vulnerability was
-	// fixed. If there are multiple fixed versions in the OSV report, this will
-	// be the latest fixed version.
-	//
-	// This is empty if a fix is not available.
-	FixedVersion string
-
-	// Packages contains all the vulnerable packages in OSV entry that are
-	// imported by the target source code or binary.
-	//
-	// For example, given a module M with two packages M/p1 and M/p2, where
-	// both p1 and p2 are vulnerable, p1 and p2 will each only appear in this
-	// list they are individually imported by the target source code or binary.
-	Packages []*Package
-}
-
-// Package is a Go package with known vulnerable symbols.
-type Package struct {
-	// Path is the import path of the package containing the vulnerability.
-	Path string
-
-	// CallStacks contains a representative call stack for each
-	// vulnerable symbol that is called.
-	//
-	// For vulnerabilities found from binary analysis, only CallStack.Symbol
-	// will be provided.
-	//
-	// For non-affecting vulnerabilities reported from the source mode
-	// analysis, this will be empty.
-	CallStacks []CallStack
-}
-
-// CallStacks contains a representative call stack for a vulnerable
-// symbol.
-type CallStack struct {
-	// Symbol is the name of the detected vulnerable function
-	// or method.
-	//
-	// This follows the naming convention in the OSV report.
-	Symbol string
-
-	// Summary is a one-line description of the callstack, used by the
-	// default govulncheck mode.
-	//
-	// Example: module3.main calls github.com/shiyanhui/dht.DHT.Run
-	Summary string
-
-	// Frames contains an entry for each stack in the call stack.
-	//
-	// Frames are sorted starting from the entry point to the
-	// imported vulnerable symbol. The last frame in Frames should match
-	// Symbol.
-	Frames []*StackFrame
-}
-
-// StackFrame represents a call stack entry.
-type StackFrame struct {
-	// PackagePath is the import path.
-	PkgPath string
-
-	// FuncName is the function name.
-	FuncName string
-
-	// RecvType is the fully qualified receiver type,
-	// if the called symbol is a method.
-	//
-	// The client can create the final symbol name by
-	// prepending RecvType to FuncName.
-	RecvType string
-
-	// Position describes an arbitrary source position
-	// including the file, line, and column location.
-	// A Position is valid if the line number is > 0.
-	Position token.Position
-}
-
-func (sf *StackFrame) Name() string {
-	return ""
-}
-
-func (sf *StackFrame) Pos() string {
-	return ""
-}
diff -urN a/gopls/internal/govulncheck/util.go b/gopls/internal/govulncheck/util.go
--- a/gopls/internal/govulncheck/util.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/util.go	1969-12-31 16:00:00
@@ -1,36 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package govulncheck
-
-import (
-	"golang.org/x/mod/semver"
-	isem "golang.org/x/tools/gopls/internal/govulncheck/semver"
-	"golang.org/x/vuln/osv"
-)
-
-// LatestFixed returns the latest fixed version in the list of affected ranges,
-// or the empty string if there are no fixed versions.
-func LatestFixed(modulePath string, as []osv.Affected) string {
-	v := ""
-	for _, a := range as {
-		if a.Package.Name != modulePath {
-			continue
-		}
-		for _, r := range a.Ranges {
-			if r.Type == osv.TypeSemver {
-				for _, e := range r.Events {
-					if e.Fixed != "" && (v == "" ||
-						semver.Compare(isem.CanonicalizeSemverPrefix(e.Fixed), isem.CanonicalizeSemverPrefix(v)) > 0) {
-						v = e.Fixed
-					}
-				}
-			}
-		}
-	}
-	return v
-}
diff -urN a/gopls/internal/govulncheck/vulncache.go b/gopls/internal/govulncheck/vulncache.go
--- a/gopls/internal/govulncheck/vulncache.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/govulncheck/vulncache.go	1969-12-31 16:00:00
@@ -1,105 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package govulncheck
-
-import (
-	"sync"
-	"time"
-
-	vulnc "golang.org/x/vuln/client"
-	"golang.org/x/vuln/osv"
-)
-
-// inMemoryCache is an implementation of the [client.Cache] interface
-// that "decorates" another instance of that interface to provide
-// an additional layer of (memory-based) caching.
-type inMemoryCache struct {
-	mu         sync.Mutex
-	underlying vulnc.Cache
-	db         map[string]*db
-}
-
-var _ vulnc.Cache = &inMemoryCache{}
-
-type db struct {
-	retrieved time.Time
-	index     vulnc.DBIndex
-	entry     map[string][]*osv.Entry
-}
-
-// NewInMemoryCache returns a new memory-based cache that decorates
-// the provided cache (file-based, perhaps).
-func NewInMemoryCache(underlying vulnc.Cache) *inMemoryCache {
-	return &inMemoryCache{
-		underlying: underlying,
-		db:         make(map[string]*db),
-	}
-}
-
-func (c *inMemoryCache) lookupDBLocked(dbName string) *db {
-	cached := c.db[dbName]
-	if cached == nil {
-		cached = &db{entry: make(map[string][]*osv.Entry)}
-		c.db[dbName] = cached
-	}
-	return cached
-}
-
-// ReadIndex returns the index for dbName from the cache, or returns zero values
-// if it is not present.
-func (c *inMemoryCache) ReadIndex(dbName string) (vulnc.DBIndex, time.Time, error) {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	cached := c.lookupDBLocked(dbName)
-
-	if cached.retrieved.IsZero() {
-		// First time ReadIndex is called.
-		index, retrieved, err := c.underlying.ReadIndex(dbName)
-		if err != nil {
-			return index, retrieved, err
-		}
-		cached.index, cached.retrieved = index, retrieved
-	}
-	return cached.index, cached.retrieved, nil
-}
-
-// WriteIndex puts the index and retrieved time into the cache.
-func (c *inMemoryCache) WriteIndex(dbName string, index vulnc.DBIndex, retrieved time.Time) error {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	cached := c.lookupDBLocked(dbName)
-	cached.index, cached.retrieved = index, retrieved
-	// TODO(hyangah): shouldn't we invalidate all cached entries?
-	return c.underlying.WriteIndex(dbName, index, retrieved)
-}
-
-// ReadEntries returns the vulndb entries for path from the cache.
-func (c *inMemoryCache) ReadEntries(dbName, path string) ([]*osv.Entry, error) {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	cached := c.lookupDBLocked(dbName)
-	entries, ok := cached.entry[path]
-	if !ok {
-		// cache miss
-		entries, err := c.underlying.ReadEntries(dbName, path)
-		if err != nil {
-			return entries, err
-		}
-		cached.entry[path] = entries
-	}
-	return entries, nil
-}
-
-// WriteEntries puts the entries for path into the cache.
-func (c *inMemoryCache) WriteEntries(dbName, path string, entries []*osv.Entry) error {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	cached := c.lookupDBLocked(dbName)
-	cached.entry[path] = entries
-	return c.underlying.WriteEntries(dbName, path, entries)
-}
diff -urN a/gopls/internal/hooks/analysis_116.go b/gopls/internal/hooks/analysis_116.go
--- a/gopls/internal/hooks/analysis_116.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/analysis_116.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.17
-// +build !go1.17
-
-package hooks
-
-import "golang.org/x/tools/gopls/internal/lsp/source"
-
-func updateAnalyzers(options *source.Options) {
-	options.StaticcheckSupported = false
-}
diff -urN a/gopls/internal/hooks/analysis_117.go b/gopls/internal/hooks/analysis_117.go
--- a/gopls/internal/hooks/analysis_117.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/analysis_117.go	1969-12-31 16:00:00
@@ -1,62 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.17
-// +build go1.17
-
-package hooks
-
-import (
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"honnef.co/go/tools/analysis/lint"
-	"honnef.co/go/tools/quickfix"
-	"honnef.co/go/tools/simple"
-	"honnef.co/go/tools/staticcheck"
-	"honnef.co/go/tools/stylecheck"
-)
-
-func updateAnalyzers(options *source.Options) {
-	options.StaticcheckSupported = true
-
-	mapSeverity := func(severity lint.Severity) protocol.DiagnosticSeverity {
-		switch severity {
-		case lint.SeverityError:
-			return protocol.SeverityError
-		case lint.SeverityDeprecated:
-			// TODO(dh): in LSP, deprecated is a tag, not a severity.
-			//   We'll want to support this once we enable SA5011.
-			return protocol.SeverityWarning
-		case lint.SeverityWarning:
-			return protocol.SeverityWarning
-		case lint.SeverityInfo:
-			return protocol.SeverityInformation
-		case lint.SeverityHint:
-			return protocol.SeverityHint
-		default:
-			return protocol.SeverityWarning
-		}
-	}
-	add := func(analyzers []*lint.Analyzer, skip map[string]struct{}) {
-		for _, a := range analyzers {
-			if _, ok := skip[a.Analyzer.Name]; ok {
-				continue
-			}
-
-			enabled := !a.Doc.NonDefault
-			options.AddStaticcheckAnalyzer(a.Analyzer, enabled, mapSeverity(a.Doc.Severity))
-		}
-	}
-
-	add(simple.Analyzers, nil)
-	add(staticcheck.Analyzers, map[string]struct{}{
-		// This check conflicts with the vet printf check (golang/go#34494).
-		"SA5009": {},
-		// This check relies on facts from dependencies, which
-		// we don't currently compute.
-		"SA5011": {},
-	})
-	add(stylecheck.Analyzers, nil)
-	add(quickfix.Analyzers, nil)
-}
diff -urN a/gopls/internal/hooks/diff.go b/gopls/internal/hooks/diff.go
--- a/gopls/internal/hooks/diff.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/diff.go	1969-12-31 16:00:00
@@ -1,169 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package hooks
-
-import (
-	"encoding/json"
-	"fmt"
-	"io/ioutil"
-	"log"
-	"os"
-	"path/filepath"
-	"runtime"
-	"sync"
-	"time"
-
-	"github.com/sergi/go-diff/diffmatchpatch"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/diff"
-)
-
-// structure for saving information about diffs
-// while the new code is being rolled out
-type diffstat struct {
-	Before, After      int
-	Oldedits, Newedits int
-	Oldtime, Newtime   time.Duration
-	Stack              string
-	Msg                string `json:",omitempty"` // for errors
-	Ignored            int    `json:",omitempty"` // numbr of skipped records with 0 edits
-}
-
-var (
-	ignoredMu sync.Mutex
-	ignored   int // counter of diff requests on equal strings
-
-	diffStatsOnce sync.Once
-	diffStats     *os.File // never closed
-)
-
-// save writes a JSON record of statistics about diff requests to a temporary file.
-func (s *diffstat) save() {
-	diffStatsOnce.Do(func() {
-		f, err := ioutil.TempFile("", "gopls-diff-stats-*")
-		if err != nil {
-			log.Printf("can't create diff stats temp file: %v", err) // e.g. disk full
-			return
-		}
-		diffStats = f
-	})
-	if diffStats == nil {
-		return
-	}
-
-	// diff is frequently called with equal strings,
-	// so we count repeated instances but only print every 15th.
-	ignoredMu.Lock()
-	if s.Oldedits == 0 && s.Newedits == 0 {
-		ignored++
-		if ignored < 15 {
-			ignoredMu.Unlock()
-			return
-		}
-	}
-	s.Ignored = ignored
-	ignored = 0
-	ignoredMu.Unlock()
-
-	// Record the name of the file in which diff was called.
-	// There aren't many calls, so only the base name is needed.
-	if _, file, line, ok := runtime.Caller(2); ok {
-		s.Stack = fmt.Sprintf("%s:%d", filepath.Base(file), line)
-	}
-	x, err := json.Marshal(s)
-	if err != nil {
-		log.Fatalf("internal error marshalling JSON: %v", err)
-	}
-	fmt.Fprintf(diffStats, "%s\n", x)
-}
-
-// disaster is called when the diff algorithm panics or produces a
-// diff that cannot be applied. It saves the broken input in a
-// new temporary file and logs the file name, which is returned.
-func disaster(before, after string) string {
-	// We use the pid to salt the name, not os.TempFile,
-	// so that each process creates at most one file.
-	// One is sufficient for a bug report.
-	filename := fmt.Sprintf("%s/gopls-diff-bug-%x", os.TempDir(), os.Getpid())
-
-	// We use NUL as a separator: it should never appear in Go source.
-	data := before + "\x00" + after
-
-	if err := ioutil.WriteFile(filename, []byte(data), 0600); err != nil {
-		log.Printf("failed to write diff bug report: %v", err)
-		return ""
-	}
-
-	bug.Reportf("Bug detected in diff algorithm! Please send file %s to the maintainers of gopls if you are comfortable sharing its contents.", filename)
-
-	return filename
-}
-
-// BothDiffs edits calls both the new and old diffs, checks that the new diffs
-// change before into after, and attempts to preserve some statistics.
-func BothDiffs(before, after string) (edits []diff.Edit) {
-	// The new diff code contains a lot of internal checks that panic when they
-	// fail. This code catches the panics, or other failures, tries to save
-	// the failing example (and it would ask the user to send it back to us, and
-	// changes options.newDiff to 'old', if only we could figure out how.)
-	stat := diffstat{Before: len(before), After: len(after)}
-	now := time.Now()
-	oldedits := ComputeEdits(before, after)
-	stat.Oldedits = len(oldedits)
-	stat.Oldtime = time.Since(now)
-	defer func() {
-		if r := recover(); r != nil {
-			disaster(before, after)
-			edits = oldedits
-		}
-	}()
-	now = time.Now()
-	newedits := diff.Strings(before, after)
-	stat.Newedits = len(newedits)
-	stat.Newtime = time.Now().Sub(now)
-	got, err := diff.Apply(before, newedits)
-	if err != nil || got != after {
-		stat.Msg += "FAIL"
-		disaster(before, after)
-		stat.save()
-		return oldedits
-	}
-	stat.save()
-	return newedits
-}
-
-// ComputeEdits computes a diff using the github.com/sergi/go-diff implementation.
-func ComputeEdits(before, after string) (edits []diff.Edit) {
-	// The go-diff library has an unresolved panic (see golang/go#278774).
-	// TODO(rstambler): Remove the recover once the issue has been fixed
-	// upstream.
-	defer func() {
-		if r := recover(); r != nil {
-			bug.Reportf("unable to compute edits: %s", r)
-			// Report one big edit for the whole file.
-			edits = []diff.Edit{{
-				Start: 0,
-				End:   len(before),
-				New:   after,
-			}}
-		}
-	}()
-	diffs := diffmatchpatch.New().DiffMain(before, after, true)
-	edits = make([]diff.Edit, 0, len(diffs))
-	offset := 0
-	for _, d := range diffs {
-		start := offset
-		switch d.Type {
-		case diffmatchpatch.DiffDelete:
-			offset += len(d.Text)
-			edits = append(edits, diff.Edit{Start: start, End: offset})
-		case diffmatchpatch.DiffEqual:
-			offset += len(d.Text)
-		case diffmatchpatch.DiffInsert:
-			edits = append(edits, diff.Edit{Start: start, End: start, New: d.Text})
-		}
-	}
-	return edits
-}
diff -urN a/gopls/internal/hooks/diff_test.go b/gopls/internal/hooks/diff_test.go
--- a/gopls/internal/hooks/diff_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/diff_test.go	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package hooks
-
-import (
-	"io/ioutil"
-	"os"
-	"testing"
-
-	"golang.org/x/tools/internal/diff/difftest"
-)
-
-func TestDiff(t *testing.T) {
-	difftest.DiffTest(t, ComputeEdits)
-}
-
-func TestDisaster(t *testing.T) {
-	a := "This is a string,(\u0995) just for basic\nfunctionality"
-	b := "This is another string, (\u0996) to see if disaster will store stuff correctly"
-	fname := disaster(a, b)
-	buf, err := ioutil.ReadFile(fname)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if string(buf) != a+"\x00"+b {
-		t.Error("failed to record original strings")
-	}
-	if err := os.Remove(fname); err != nil {
-		t.Error(err)
-	}
-}
diff -urN a/gopls/internal/hooks/gen-licenses.sh b/gopls/internal/hooks/gen-licenses.sh
--- a/gopls/internal/hooks/gen-licenses.sh	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/gen-licenses.sh	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-#!/bin/bash -eu
-
-# Copyright 2020 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-
-set -o pipefail
-
-output=$1
-tempfile=$(mktemp)
-cd $(dirname $0)
-
-cat > $tempfile <<END
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:generate ./gen-licenses.sh licenses.go
-package hooks
-
-const licensesText = \`
-END
-
-# List all the modules gopls depends on, except other golang.org modules, which
-# are known to have the same license.
-mods=$(go list -deps -f '{{with .Module}}{{.Path}}{{end}}' golang.org/x/tools/gopls | sort -u | grep -v golang.org)
-for mod in $mods; do
-  # Find the license file, either LICENSE or COPYING, and add it to the result.
-  dir=$(go list -m -f {{.Dir}} $mod)
-  license=$(ls -1 $dir | grep -E -i '^(LICENSE|COPYING)$')
-  echo "-- $mod $license --" >> $tempfile
-  echo >> $tempfile
-  sed 's/^-- / &/' $dir/$license >> $tempfile
-  echo >> $tempfile
-done
-
-echo "\`" >> $tempfile
-mv $tempfile $output
\ No newline at end of file
diff -urN a/gopls/internal/hooks/gofumpt_117.go b/gopls/internal/hooks/gofumpt_117.go
--- a/gopls/internal/hooks/gofumpt_117.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/gofumpt_117.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.18
-// +build !go1.18
-
-package hooks
-
-import "golang.org/x/tools/gopls/internal/lsp/source"
-
-func updateGofumpt(options *source.Options) {
-}
diff -urN a/gopls/internal/hooks/gofumpt_118.go b/gopls/internal/hooks/gofumpt_118.go
--- a/gopls/internal/hooks/gofumpt_118.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/gofumpt_118.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package hooks
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"mvdan.cc/gofumpt/format"
-)
-
-func updateGofumpt(options *source.Options) {
-	options.GofumptFormat = func(ctx context.Context, langVersion, modulePath string, src []byte) ([]byte, error) {
-		return format.Source(src, format.Options{
-			LangVersion: langVersion,
-			ModulePath:  modulePath,
-		})
-	}
-}
diff -urN a/gopls/internal/hooks/hooks.go b/gopls/internal/hooks/hooks.go
--- a/gopls/internal/hooks/hooks.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/hooks.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package hooks adds all the standard gopls implementations.
-// This can be used in tests without needing to use the gopls main, and is
-// also the place to edit for custom builds of gopls.
-package hooks // import "golang.org/x/tools/gopls/internal/hooks"
-
-import (
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/diff"
-	"mvdan.cc/xurls/v2"
-)
-
-func Options(options *source.Options) {
-	options.LicensesText = licensesText
-	if options.GoDiff {
-		switch options.NewDiff {
-		case "old":
-			options.ComputeEdits = ComputeEdits
-		case "new":
-			options.ComputeEdits = diff.Strings
-		default:
-			options.ComputeEdits = BothDiffs
-		}
-	}
-	options.URLRegexp = xurls.Relaxed()
-	updateAnalyzers(options)
-	updateGofumpt(options)
-}
diff -urN a/gopls/internal/hooks/licenses.go b/gopls/internal/hooks/licenses.go
--- a/gopls/internal/hooks/licenses.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/licenses.go	1969-12-31 16:00:00
@@ -1,169 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:generate ./gen-licenses.sh licenses.go
-package hooks
-
-const licensesText = `
--- github.com/BurntSushi/toml COPYING --
-
-The MIT License (MIT)
-
-Copyright (c) 2013 TOML authors
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
-
--- github.com/google/go-cmp LICENSE --
-
-Copyright (c) 2017 The Go Authors. All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-
-   * Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-   * Redistributions in binary form must reproduce the above
-copyright notice, this list of conditions and the following disclaimer
-in the documentation and/or other materials provided with the
-distribution.
-   * Neither the name of Google Inc. nor the names of its
-contributors may be used to endorse or promote products derived from
-this software without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
--- github.com/sergi/go-diff LICENSE --
-
-Copyright (c) 2012-2016 The go-diff Authors. All rights reserved.
-
-Permission is hereby granted, free of charge, to any person obtaining a
-copy of this software and associated documentation files (the "Software"),
-to deal in the Software without restriction, including without limitation
-the rights to use, copy, modify, merge, publish, distribute, sublicense,
-and/or sell copies of the Software, and to permit persons to whom the
-Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included
-in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
-OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
-DEALINGS IN THE SOFTWARE.
-
-
--- honnef.co/go/tools LICENSE --
-
-Copyright (c) 2016 Dominik Honnef
-
-Permission is hereby granted, free of charge, to any person obtaining
-a copy of this software and associated documentation files (the
-"Software"), to deal in the Software without restriction, including
-without limitation the rights to use, copy, modify, merge, publish,
-distribute, sublicense, and/or sell copies of the Software, and to
-permit persons to whom the Software is furnished to do so, subject to
-the following conditions:
-
-The above copyright notice and this permission notice shall be
-included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
-EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
-MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
-NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
-LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
-OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
-WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
--- mvdan.cc/gofumpt LICENSE --
-
-Copyright (c) 2019, Daniel Martí. All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-
-   * Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-   * Redistributions in binary form must reproduce the above
-copyright notice, this list of conditions and the following disclaimer
-in the documentation and/or other materials provided with the
-distribution.
-   * Neither the name of the copyright holder nor the names of its
-contributors may be used to endorse or promote products derived from
-this software without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
--- mvdan.cc/xurls/v2 LICENSE --
-
-Copyright (c) 2015, Daniel Martí. All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-
-   * Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-   * Redistributions in binary form must reproduce the above
-copyright notice, this list of conditions and the following disclaimer
-in the documentation and/or other materials provided with the
-distribution.
-   * Neither the name of the copyright holder nor the names of its
-contributors may be used to endorse or promote products derived from
-this software without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-`
diff -urN a/gopls/internal/hooks/licenses_test.go b/gopls/internal/hooks/licenses_test.go
--- a/gopls/internal/hooks/licenses_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/hooks/licenses_test.go	1969-12-31 16:00:00
@@ -1,46 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package hooks
-
-import (
-	"bytes"
-	"io/ioutil"
-	"os/exec"
-	"runtime"
-	"testing"
-
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestLicenses(t *testing.T) {
-	// License text differs for older Go versions because staticcheck or gofumpt
-	// isn't supported for those versions.
-	testenv.NeedsGo1Point(t, 18)
-
-	if runtime.GOOS != "linux" && runtime.GOOS != "darwin" {
-		t.Skip("generating licenses only works on Unixes")
-	}
-	tmp, err := ioutil.TempFile("", "")
-	if err != nil {
-		t.Fatal(err)
-	}
-	tmp.Close()
-
-	if out, err := exec.Command("./gen-licenses.sh", tmp.Name()).CombinedOutput(); err != nil {
-		t.Fatalf("generating licenses failed: %q, %v", out, err)
-	}
-
-	got, err := ioutil.ReadFile(tmp.Name())
-	if err != nil {
-		t.Fatal(err)
-	}
-	want, err := ioutil.ReadFile("licenses.go")
-	if err != nil {
-		t.Fatal(err)
-	}
-	if !bytes.Equal(got, want) {
-		t.Error("combined license text needs updating. Run: `go generate ./internal/hooks` from the gopls module.")
-	}
-}
diff -urN a/gopls/internal/lsp/README.md b/gopls/internal/lsp/README.md
--- a/gopls/internal/lsp/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/README.md	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-# lsp
-
-internal/lsp provides much of the Language Server Protocol (lsp) implementation
-for gopls.
-
-Documentation for users and contributors can be found in the
-[`gopls/doc`](../../gopls/doc) directory.
diff -urN a/gopls/internal/lsp/analysis/embeddirective/embeddirective.go b/gopls/internal/lsp/analysis/embeddirective/embeddirective.go
--- a/gopls/internal/lsp/analysis/embeddirective/embeddirective.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/embeddirective/embeddirective.go	1969-12-31 16:00:00
@@ -1,58 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package embeddirective defines an Analyzer that validates import for //go:embed directive.
-package embeddirective
-
-import (
-	"go/ast"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-)
-
-const Doc = `check for //go:embed directive import
-
-This analyzer checks that the embed package is imported when source code contains //go:embed comment directives.
-The embed package must be imported for //go:embed directives to function.import _ "embed".`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "embed",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	for _, f := range pass.Files {
-		com := hasEmbedDirectiveComment(f)
-		if com != nil {
-			assertEmbedImport(pass, com, f)
-		}
-	}
-	return nil, nil
-}
-
-// Check if the comment contains //go:embed directive.
-func hasEmbedDirectiveComment(f *ast.File) *ast.Comment {
-	for _, cg := range f.Comments {
-		for _, c := range cg.List {
-			if strings.HasPrefix(c.Text, "//go:embed ") {
-				return c
-			}
-		}
-	}
-	return nil
-}
-
-// Verifies that "embed" import exists for //go:embed directive.
-func assertEmbedImport(pass *analysis.Pass, com *ast.Comment, f *ast.File) {
-	for _, imp := range f.Imports {
-		if "\"embed\"" == imp.Path.Value {
-			return
-		}
-	}
-	pass.Report(analysis.Diagnostic{Pos: com.Pos(), End: com.Pos() + 10, Message: "The \"embed\" package must be imported when using go:embed directives."})
-}
diff -urN a/gopls/internal/lsp/analysis/embeddirective/embeddirective_test.go b/gopls/internal/lsp/analysis/embeddirective/embeddirective_test.go
--- a/gopls/internal/lsp/analysis/embeddirective/embeddirective_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/embeddirective/embeddirective_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package embeddirective
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests)
-	}
-
-	analysistest.RunWithSuggestedFixes(t, testdata, Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/a.go b/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package a
-
-import (
-	"fmt"
-)
-
-//go:embed embedText // want "The \"embed\" package must be imported when using go:embed directives"
-var s string
-
-// This is main function
-func main() {
-	fmt.Println(s)
-}
diff -urN a/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/b.go b/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/b.go
--- a/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/b.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/b.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-package a
-
-import (
-	_ "embed"
-	"fmt"
-)
-
-//go:embed embedText // ok
-var s string
-
-// This is main function
-func main() {
-	fmt.Println(s)
-}
diff -urN a/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/embedText b/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/embedText
--- a/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/embedText	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/embeddirective/testdata/src/a/embedText	1969-12-31 16:00:00
@@ -1 +0,0 @@
-Hello World
\ No newline at end of file
diff -urN a/gopls/internal/lsp/analysis/fillreturns/fillreturns.go b/gopls/internal/lsp/analysis/fillreturns/fillreturns.go
--- a/gopls/internal/lsp/analysis/fillreturns/fillreturns.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillreturns/fillreturns.go	1969-12-31 16:00:00
@@ -1,279 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package fillreturns defines an Analyzer that will attempt to
-// automatically fill in a return statement that has missing
-// values with zero value elements.
-package fillreturns
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/types"
-	"regexp"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/internal/analysisinternal"
-	"golang.org/x/tools/internal/fuzzy"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-const Doc = `suggest fixes for errors due to an incorrect number of return values
-
-This checker provides suggested fixes for type errors of the
-type "wrong number of return values (want %d, got %d)". For example:
-	func m() (int, string, *bool, error) {
-		return
-	}
-will turn into
-	func m() (int, string, *bool, error) {
-		return 0, "", nil, nil
-	}
-
-This functionality is similar to https://github.com/sqs/goreturns.
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "fillreturns",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	info := pass.TypesInfo
-	if info == nil {
-		return nil, fmt.Errorf("nil TypeInfo")
-	}
-
-outer:
-	for _, typeErr := range pass.TypeErrors {
-		// Filter out the errors that are not relevant to this analyzer.
-		if !FixesError(typeErr) {
-			continue
-		}
-		var file *ast.File
-		for _, f := range pass.Files {
-			if f.Pos() <= typeErr.Pos && typeErr.Pos <= f.End() {
-				file = f
-				break
-			}
-		}
-		if file == nil {
-			continue
-		}
-
-		// Get the end position of the error.
-		// (This heuristic assumes that the buffer is formatted,
-		// at least up to the end position of the error.)
-		var buf bytes.Buffer
-		if err := format.Node(&buf, pass.Fset, file); err != nil {
-			continue
-		}
-		typeErrEndPos := analysisinternal.TypeErrorEndPos(pass.Fset, buf.Bytes(), typeErr.Pos)
-
-		// TODO(rfindley): much of the error handling code below returns, when it
-		// should probably continue.
-
-		// Get the path for the relevant range.
-		path, _ := astutil.PathEnclosingInterval(file, typeErr.Pos, typeErrEndPos)
-		if len(path) == 0 {
-			return nil, nil
-		}
-
-		// Find the enclosing return statement.
-		var ret *ast.ReturnStmt
-		var retIdx int
-		for i, n := range path {
-			if r, ok := n.(*ast.ReturnStmt); ok {
-				ret = r
-				retIdx = i
-				break
-			}
-		}
-		if ret == nil {
-			return nil, nil
-		}
-
-		// Get the function type that encloses the ReturnStmt.
-		var enclosingFunc *ast.FuncType
-		for _, n := range path[retIdx+1:] {
-			switch node := n.(type) {
-			case *ast.FuncLit:
-				enclosingFunc = node.Type
-			case *ast.FuncDecl:
-				enclosingFunc = node.Type
-			}
-			if enclosingFunc != nil {
-				break
-			}
-		}
-		if enclosingFunc == nil || enclosingFunc.Results == nil {
-			continue
-		}
-
-		// Skip any generic enclosing functions, since type parameters don't
-		// have 0 values.
-		// TODO(rfindley): We should be able to handle this if the return
-		// values are all concrete types.
-		if tparams := typeparams.ForFuncType(enclosingFunc); tparams != nil && tparams.NumFields() > 0 {
-			return nil, nil
-		}
-
-		// Find the function declaration that encloses the ReturnStmt.
-		var outer *ast.FuncDecl
-		for _, p := range path {
-			if p, ok := p.(*ast.FuncDecl); ok {
-				outer = p
-				break
-			}
-		}
-		if outer == nil {
-			return nil, nil
-		}
-
-		// Skip any return statements that contain function calls with multiple
-		// return values.
-		for _, expr := range ret.Results {
-			e, ok := expr.(*ast.CallExpr)
-			if !ok {
-				continue
-			}
-			if tup, ok := info.TypeOf(e).(*types.Tuple); ok && tup.Len() > 1 {
-				continue outer
-			}
-		}
-
-		// Duplicate the return values to track which values have been matched.
-		remaining := make([]ast.Expr, len(ret.Results))
-		copy(remaining, ret.Results)
-
-		fixed := make([]ast.Expr, len(enclosingFunc.Results.List))
-
-		// For each value in the return function declaration, find the leftmost element
-		// in the return statement that has the desired type. If no such element exists,
-		// fill in the missing value with the appropriate "zero" value.
-		// Beware that type information may be incomplete.
-		var retTyps []types.Type
-		for _, ret := range enclosingFunc.Results.List {
-			retTyp := info.TypeOf(ret.Type)
-			if retTyp == nil {
-				return nil, nil
-			}
-			retTyps = append(retTyps, retTyp)
-		}
-		matches := analysisinternal.MatchingIdents(retTyps, file, ret.Pos(), info, pass.Pkg)
-		for i, retTyp := range retTyps {
-			var match ast.Expr
-			var idx int
-			for j, val := range remaining {
-				if t := info.TypeOf(val); t == nil || !matchingTypes(t, retTyp) {
-					continue
-				}
-				if !analysisinternal.IsZeroValue(val) {
-					match, idx = val, j
-					break
-				}
-				// If the current match is a "zero" value, we keep searching in
-				// case we find a non-"zero" value match. If we do not find a
-				// non-"zero" value, we will use the "zero" value.
-				match, idx = val, j
-			}
-
-			if match != nil {
-				fixed[i] = match
-				remaining = append(remaining[:idx], remaining[idx+1:]...)
-			} else {
-				names, ok := matches[retTyp]
-				if !ok {
-					return nil, fmt.Errorf("invalid return type: %v", retTyp)
-				}
-				// Find the identifier most similar to the return type.
-				// If no identifier matches the pattern, generate a zero value.
-				if best := fuzzy.BestMatch(retTyp.String(), names); best != "" {
-					fixed[i] = ast.NewIdent(best)
-				} else if zero := analysisinternal.ZeroValue(file, pass.Pkg, retTyp); zero != nil {
-					fixed[i] = zero
-				} else {
-					return nil, nil
-				}
-			}
-		}
-
-		// Remove any non-matching "zero values" from the leftover values.
-		var nonZeroRemaining []ast.Expr
-		for _, expr := range remaining {
-			if !analysisinternal.IsZeroValue(expr) {
-				nonZeroRemaining = append(nonZeroRemaining, expr)
-			}
-		}
-		// Append leftover return values to end of new return statement.
-		fixed = append(fixed, nonZeroRemaining...)
-
-		newRet := &ast.ReturnStmt{
-			Return:  ret.Pos(),
-			Results: fixed,
-		}
-
-		// Convert the new return statement AST to text.
-		var newBuf bytes.Buffer
-		if err := format.Node(&newBuf, pass.Fset, newRet); err != nil {
-			return nil, err
-		}
-
-		pass.Report(analysis.Diagnostic{
-			Pos:     typeErr.Pos,
-			End:     typeErrEndPos,
-			Message: typeErr.Msg,
-			SuggestedFixes: []analysis.SuggestedFix{{
-				Message: "Fill in return values",
-				TextEdits: []analysis.TextEdit{{
-					Pos:     ret.Pos(),
-					End:     ret.End(),
-					NewText: newBuf.Bytes(),
-				}},
-			}},
-		})
-	}
-	return nil, nil
-}
-
-func matchingTypes(want, got types.Type) bool {
-	if want == got || types.Identical(want, got) {
-		return true
-	}
-	// Code segment to help check for untyped equality from (golang/go#32146).
-	if rhs, ok := want.(*types.Basic); ok && rhs.Info()&types.IsUntyped > 0 {
-		if lhs, ok := got.Underlying().(*types.Basic); ok {
-			return rhs.Info()&types.IsConstType == lhs.Info()&types.IsConstType
-		}
-	}
-	return types.AssignableTo(want, got) || types.ConvertibleTo(want, got)
-}
-
-// Error messages have changed across Go versions. These regexps capture recent
-// incarnations.
-//
-// TODO(rfindley): once error codes are exported and exposed via go/packages,
-// use error codes rather than string matching here.
-var wrongReturnNumRegexes = []*regexp.Regexp{
-	regexp.MustCompile(`wrong number of return values \(want (\d+), got (\d+)\)`),
-	regexp.MustCompile(`too many return values`),
-	regexp.MustCompile(`not enough return values`),
-}
-
-func FixesError(err types.Error) bool {
-	msg := strings.TrimSpace(err.Msg)
-	for _, rx := range wrongReturnNumRegexes {
-		if rx.MatchString(msg) {
-			return true
-		}
-	}
-	return false
-}
diff -urN a/gopls/internal/lsp/analysis/fillreturns/fillreturns_test.go b/gopls/internal/lsp/analysis/fillreturns/fillreturns_test.go
--- a/gopls/internal/lsp/analysis/fillreturns/fillreturns_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillreturns/fillreturns_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fillreturns_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/fillreturns"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests, "typeparams")
-	}
-	analysistest.RunWithSuggestedFixes(t, testdata, fillreturns.Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,139 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fillreturns
-
-import (
-	"errors"
-	"go/ast"
-	ast2 "go/ast"
-	"io"
-	"net/http"
-	. "net/http"
-	"net/url"
-	"strconv"
-)
-
-type T struct{}
-type T1 = T
-type I interface{}
-type I1 = I
-type z func(string, http.Handler) error
-
-func x() error {
-	return errors.New("foo")
-}
-
-// The error messages below changed in 1.18; "return values" covers both forms.
-
-func b() (string, int, error) {
-	return "", errors.New("foo") // want "return values"
-}
-
-func c() (string, int, error) {
-	return 7, errors.New("foo") // want "return values"
-}
-
-func d() (string, int, error) {
-	return "", 7 // want "return values"
-}
-
-func e() (T, error, *bool) {
-	return (z(http.ListenAndServe))("", nil) // want "return values"
-}
-
-func preserveLeft() (int, int, error) {
-	return 1, errors.New("foo") // want "return values"
-}
-
-func matchValues() (int, error, string) {
-	return errors.New("foo"), 3 // want "return values"
-}
-
-func preventDataOverwrite() (int, string) {
-	return errors.New("foo") // want "return values"
-}
-
-func closure() (string, error) {
-	_ = func() (int, error) {
-		return // want "return values"
-	}
-	return // want "return values"
-}
-
-func basic() (uint8, uint16, uint32, uint64, int8, int16, int32, int64, float32, float64, complex64, complex128, byte, rune, uint, int, uintptr, string, bool, error) {
-	return // want "return values"
-}
-
-func complex() (*int, []int, [2]int, map[int]int) {
-	return // want "return values"
-}
-
-func structsAndInterfaces() (T, url.URL, T1, I, I1, io.Reader, Client, ast2.Stmt) {
-	return // want "return values"
-}
-
-func m() (int, error) {
-	if 1 == 2 {
-		return // want "return values"
-	} else if 1 == 3 {
-		return errors.New("foo") // want "return values"
-	} else {
-		return 1 // want "return values"
-	}
-	return // want "return values"
-}
-
-func convertibleTypes() (ast2.Expr, int) {
-	return &ast2.ArrayType{} // want "return values"
-}
-
-func assignableTypes() (map[string]int, int) {
-	type X map[string]int
-	var x X
-	return x // want "return values"
-}
-
-func interfaceAndError() (I, int) {
-	return errors.New("foo") // want "return values"
-}
-
-func funcOneReturn() (string, error) {
-	return strconv.Itoa(1) // want "return values"
-}
-
-func funcMultipleReturn() (int, error, string) {
-	return strconv.Atoi("1")
-}
-
-func localFuncMultipleReturn() (string, int, error, string) {
-	return b()
-}
-
-func multipleUnused() (int, string, string, string) {
-	return 3, 4, 5 // want "return values"
-}
-
-func gotTooMany() int {
-	if true {
-		return 0, "" // want "return values"
-	} else {
-		return 1, 0, nil // want "return values"
-	}
-	return 0, 5, false // want "return values"
-}
-
-func fillVars() (int, string, ast.Node, bool, error) {
-	eint := 0
-	s := "a"
-	var t bool
-	if true {
-		err := errors.New("fail")
-		return // want "return values"
-	}
-	n := ast.NewIdent("ident")
-	int := 3
-	var b bool
-	return "" // want "return values"
-}
diff -urN a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,139 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fillreturns
-
-import (
-	"errors"
-	"go/ast"
-	ast2 "go/ast"
-	"io"
-	"net/http"
-	. "net/http"
-	"net/url"
-	"strconv"
-)
-
-type T struct{}
-type T1 = T
-type I interface{}
-type I1 = I
-type z func(string, http.Handler) error
-
-func x() error {
-	return errors.New("foo")
-}
-
-// The error messages below changed in 1.18; "return values" covers both forms.
-
-func b() (string, int, error) {
-	return "", 0, errors.New("foo") // want "return values"
-}
-
-func c() (string, int, error) {
-	return "", 7, errors.New("foo") // want "return values"
-}
-
-func d() (string, int, error) {
-	return "", 7, nil // want "return values"
-}
-
-func e() (T, error, *bool) {
-	return T{}, (z(http.ListenAndServe))("", nil), nil // want "return values"
-}
-
-func preserveLeft() (int, int, error) {
-	return 1, 0, errors.New("foo") // want "return values"
-}
-
-func matchValues() (int, error, string) {
-	return 3, errors.New("foo"), "" // want "return values"
-}
-
-func preventDataOverwrite() (int, string) {
-	return 0, "", errors.New("foo") // want "return values"
-}
-
-func closure() (string, error) {
-	_ = func() (int, error) {
-		return 0, nil // want "return values"
-	}
-	return "", nil // want "return values"
-}
-
-func basic() (uint8, uint16, uint32, uint64, int8, int16, int32, int64, float32, float64, complex64, complex128, byte, rune, uint, int, uintptr, string, bool, error) {
-	return 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "", false, nil // want "return values"
-}
-
-func complex() (*int, []int, [2]int, map[int]int) {
-	return nil, nil, nil, nil // want "return values"
-}
-
-func structsAndInterfaces() (T, url.URL, T1, I, I1, io.Reader, Client, ast2.Stmt) {
-	return T{}, url.URL{}, T{}, nil, nil, nil, Client{}, nil // want "return values"
-}
-
-func m() (int, error) {
-	if 1 == 2 {
-		return 0, nil // want "return values"
-	} else if 1 == 3 {
-		return 0, errors.New("foo") // want "return values"
-	} else {
-		return 1, nil // want "return values"
-	}
-	return 0, nil // want "return values"
-}
-
-func convertibleTypes() (ast2.Expr, int) {
-	return &ast2.ArrayType{}, 0 // want "return values"
-}
-
-func assignableTypes() (map[string]int, int) {
-	type X map[string]int
-	var x X
-	return x, 0 // want "return values"
-}
-
-func interfaceAndError() (I, int) {
-	return errors.New("foo"), 0 // want "return values"
-}
-
-func funcOneReturn() (string, error) {
-	return strconv.Itoa(1), nil // want "return values"
-}
-
-func funcMultipleReturn() (int, error, string) {
-	return strconv.Atoi("1")
-}
-
-func localFuncMultipleReturn() (string, int, error, string) {
-	return b()
-}
-
-func multipleUnused() (int, string, string, string) {
-	return 3, "", "", "", 4, 5 // want "return values"
-}
-
-func gotTooMany() int {
-	if true {
-		return 0 // want "return values"
-	} else {
-		return 1 // want "return values"
-	}
-	return 5 // want "return values"
-}
-
-func fillVars() (int, string, ast.Node, bool, error) {
-	eint := 0
-	s := "a"
-	var t bool
-	if true {
-		err := errors.New("fail")
-		return eint, s, nil, false, err // want "return values"
-	}
-	n := ast.NewIdent("ident")
-	int := 3
-	var b bool
-	return int, "", n, b, nil // want "return values"
-}
diff -urN a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go
--- a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package fillreturns
-
-func hello[T any]() int {
-	return
-}
diff -urN a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go.golden b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go.golden
--- a/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillreturns/testdata/src/a/typeparams/a.go.golden	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package fillreturns
-
-func hello[T any]() int {
-	return
-}
diff -urN a/gopls/internal/lsp/analysis/fillstruct/fillstruct.go b/gopls/internal/lsp/analysis/fillstruct/fillstruct.go
--- a/gopls/internal/lsp/analysis/fillstruct/fillstruct.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillstruct/fillstruct.go	1969-12-31 16:00:00
@@ -1,507 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package fillstruct defines an Analyzer that automatically
-// fills in a struct declaration with zero value elements for each field.
-//
-// The analyzer's diagnostic is merely a prompt.
-// The actual fix is created by a separate direct call from gopls to
-// the SuggestedFixes function.
-// Tests of Analyzer.Run can be found in ./testdata/src.
-// Tests of the SuggestedFixes logic live in ../../testdata/fillstruct.
-package fillstruct
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/token"
-	"go/types"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/go/ast/inspector"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/analysisinternal"
-	"golang.org/x/tools/internal/fuzzy"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-const Doc = `note incomplete struct initializations
-
-This analyzer provides diagnostics for any struct literals that do not have
-any fields initialized. Because the suggested fix for this analysis is
-expensive to compute, callers should compute it separately, using the
-SuggestedFix function below.
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "fillstruct",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{inspect.Analyzer},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	nodeFilter := []ast.Node{(*ast.CompositeLit)(nil)}
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		expr := n.(*ast.CompositeLit)
-
-		// Find enclosing file.
-		// TODO(adonovan): use inspect.WithStack?
-		var file *ast.File
-		for _, f := range pass.Files {
-			if f.Pos() <= expr.Pos() && expr.Pos() <= f.End() {
-				file = f
-				break
-			}
-		}
-		if file == nil {
-			return
-		}
-
-		typ := pass.TypesInfo.TypeOf(expr)
-		if typ == nil {
-			return
-		}
-
-		// Find reference to the type declaration of the struct being initialized.
-		typ = deref(typ)
-		tStruct, ok := typ.Underlying().(*types.Struct)
-		if !ok {
-			return
-		}
-		// Inv: typ is the possibly-named struct type.
-
-		fieldCount := tStruct.NumFields()
-
-		// Skip any struct that is already populated or that has no fields.
-		if fieldCount == 0 || fieldCount == len(expr.Elts) {
-			return
-		}
-
-		// Are any fields in need of filling?
-		var fillableFields []string
-		for i := 0; i < fieldCount; i++ {
-			field := tStruct.Field(i)
-			// Ignore fields that are not accessible in the current package.
-			if field.Pkg() != nil && field.Pkg() != pass.Pkg && !field.Exported() {
-				continue
-			}
-			fillableFields = append(fillableFields, fmt.Sprintf("%s: %s", field.Name(), field.Type().String()))
-		}
-		if len(fillableFields) == 0 {
-			return
-		}
-
-		// Derive a name for the struct type.
-		var name string
-		if typ != tStruct {
-			// named struct type (e.g. pkg.S[T])
-			name = types.TypeString(typ, types.RelativeTo(pass.Pkg))
-		} else {
-			// anonymous struct type
-			totalFields := len(fillableFields)
-			const maxLen = 20
-			// Find the index to cut off printing of fields.
-			var i, fieldLen int
-			for i = range fillableFields {
-				if fieldLen > maxLen {
-					break
-				}
-				fieldLen += len(fillableFields[i])
-			}
-			fillableFields = fillableFields[:i]
-			if i < totalFields {
-				fillableFields = append(fillableFields, "...")
-			}
-			name = fmt.Sprintf("anonymous struct { %s }", strings.Join(fillableFields, ", "))
-		}
-		pass.Report(analysis.Diagnostic{
-			Message: fmt.Sprintf("Fill %s", name),
-			Pos:     expr.Pos(),
-			End:     expr.End(),
-		})
-	})
-	return nil, nil
-}
-
-// SuggestedFix computes the suggested fix for the kinds of
-// diagnostics produced by the Analyzer above.
-func SuggestedFix(fset *token.FileSet, rng span.Range, content []byte, file *ast.File, pkg *types.Package, info *types.Info) (*analysis.SuggestedFix, error) {
-	if info == nil {
-		return nil, fmt.Errorf("nil types.Info")
-	}
-
-	pos := rng.Start // don't use the end
-
-	// TODO(rstambler): Using ast.Inspect would probably be more efficient than
-	// calling PathEnclosingInterval. Switch this approach.
-	path, _ := astutil.PathEnclosingInterval(file, pos, pos)
-	if len(path) == 0 {
-		return nil, fmt.Errorf("no enclosing ast.Node")
-	}
-	var expr *ast.CompositeLit
-	for _, n := range path {
-		if node, ok := n.(*ast.CompositeLit); ok {
-			expr = node
-			break
-		}
-	}
-
-	typ := info.TypeOf(expr)
-	if typ == nil {
-		return nil, fmt.Errorf("no composite literal")
-	}
-
-	// Find reference to the type declaration of the struct being initialized.
-	typ = deref(typ)
-	tStruct, ok := typ.Underlying().(*types.Struct)
-	if !ok {
-		return nil, fmt.Errorf("%s is not a (pointer to) struct type",
-			types.TypeString(typ, types.RelativeTo(pkg)))
-	}
-	// Inv: typ is the the possibly-named struct type.
-
-	fieldCount := tStruct.NumFields()
-
-	// Check which types have already been filled in. (we only want to fill in
-	// the unfilled types, or else we'll blat user-supplied details)
-	prefilledFields := map[string]ast.Expr{}
-	for _, e := range expr.Elts {
-		if kv, ok := e.(*ast.KeyValueExpr); ok {
-			if key, ok := kv.Key.(*ast.Ident); ok {
-				prefilledFields[key.Name] = kv.Value
-			}
-		}
-	}
-
-	// Use a new fileset to build up a token.File for the new composite
-	// literal. We need one line for foo{, one line for }, and one line for
-	// each field we're going to set. format.Node only cares about line
-	// numbers, so we don't need to set columns, and each line can be
-	// 1 byte long.
-	// TODO(adonovan): why is this necessary? The position information
-	// is going to be wrong for the existing trees in prefilledFields.
-	// Can't the formatter just do its best with an empty fileset?
-	fakeFset := token.NewFileSet()
-	tok := fakeFset.AddFile("", -1, fieldCount+2)
-
-	line := 2 // account for 1-based lines and the left brace
-	var fieldTyps []types.Type
-	for i := 0; i < fieldCount; i++ {
-		field := tStruct.Field(i)
-		// Ignore fields that are not accessible in the current package.
-		if field.Pkg() != nil && field.Pkg() != pkg && !field.Exported() {
-			fieldTyps = append(fieldTyps, nil)
-			continue
-		}
-		fieldTyps = append(fieldTyps, field.Type())
-	}
-	matches := analysisinternal.MatchingIdents(fieldTyps, file, rng.Start, info, pkg)
-	var elts []ast.Expr
-	for i, fieldTyp := range fieldTyps {
-		if fieldTyp == nil {
-			continue // TODO(adonovan): is this reachable?
-		}
-		fieldName := tStruct.Field(i).Name()
-
-		tok.AddLine(line - 1) // add 1 byte per line
-		if line > tok.LineCount() {
-			panic(fmt.Sprintf("invalid line number %v (of %v) for fillstruct", line, tok.LineCount()))
-		}
-		pos := tok.LineStart(line)
-
-		kv := &ast.KeyValueExpr{
-			Key: &ast.Ident{
-				NamePos: pos,
-				Name:    fieldName,
-			},
-			Colon: pos,
-		}
-		if expr, ok := prefilledFields[fieldName]; ok {
-			kv.Value = expr
-		} else {
-			names, ok := matches[fieldTyp]
-			if !ok {
-				return nil, fmt.Errorf("invalid struct field type: %v", fieldTyp)
-			}
-
-			// Find the name most similar to the field name.
-			// If no name matches the pattern, generate a zero value.
-			// NOTE: We currently match on the name of the field key rather than the field type.
-			if best := fuzzy.BestMatch(fieldName, names); best != "" {
-				kv.Value = ast.NewIdent(best)
-			} else if v := populateValue(file, pkg, fieldTyp); v != nil {
-				kv.Value = v
-			} else {
-				return nil, nil
-			}
-		}
-		elts = append(elts, kv)
-		line++
-	}
-
-	// If all of the struct's fields are unexported, we have nothing to do.
-	if len(elts) == 0 {
-		return nil, fmt.Errorf("no elements to fill")
-	}
-
-	// Add the final line for the right brace. Offset is the number of
-	// bytes already added plus 1.
-	tok.AddLine(len(elts) + 1)
-	line = len(elts) + 2
-	if line > tok.LineCount() {
-		panic(fmt.Sprintf("invalid line number %v (of %v) for fillstruct", line, tok.LineCount()))
-	}
-
-	cl := &ast.CompositeLit{
-		Type:   expr.Type,
-		Lbrace: tok.LineStart(1),
-		Elts:   elts,
-		Rbrace: tok.LineStart(line),
-	}
-
-	// Find the line on which the composite literal is declared.
-	split := bytes.Split(content, []byte("\n"))
-	lineNumber := safetoken.StartPosition(fset, expr.Lbrace).Line
-	firstLine := split[lineNumber-1] // lines are 1-indexed
-
-	// Trim the whitespace from the left of the line, and use the index
-	// to get the amount of whitespace on the left.
-	trimmed := bytes.TrimLeftFunc(firstLine, unicode.IsSpace)
-	index := bytes.Index(firstLine, trimmed)
-	whitespace := firstLine[:index]
-
-	// First pass through the formatter: turn the expr into a string.
-	var formatBuf bytes.Buffer
-	if err := format.Node(&formatBuf, fakeFset, cl); err != nil {
-		return nil, fmt.Errorf("failed to run first format on:\n%s\ngot err: %v", cl.Type, err)
-	}
-	sug := indent(formatBuf.Bytes(), whitespace)
-
-	if len(prefilledFields) > 0 {
-		// Attempt a second pass through the formatter to line up columns.
-		sourced, err := format.Source(sug)
-		if err == nil {
-			sug = indent(sourced, whitespace)
-		}
-	}
-
-	return &analysis.SuggestedFix{
-		TextEdits: []analysis.TextEdit{
-			{
-				Pos:     expr.Pos(),
-				End:     expr.End(),
-				NewText: sug,
-			},
-		},
-	}, nil
-}
-
-// indent works line by line through str, indenting (prefixing) each line with
-// ind.
-func indent(str, ind []byte) []byte {
-	split := bytes.Split(str, []byte("\n"))
-	newText := bytes.NewBuffer(nil)
-	for i, s := range split {
-		if len(s) == 0 {
-			continue
-		}
-		// Don't add the extra indentation to the first line.
-		if i != 0 {
-			newText.Write(ind)
-		}
-		newText.Write(s)
-		if i < len(split)-1 {
-			newText.WriteByte('\n')
-		}
-	}
-	return newText.Bytes()
-}
-
-// populateValue constructs an expression to fill the value of a struct field.
-//
-// When the type of a struct field is a basic literal or interface, we return
-// default values. For other types, such as maps, slices, and channels, we create
-// empty expressions such as []T{} or make(chan T) rather than using default values.
-//
-// The reasoning here is that users will call fillstruct with the intention of
-// initializing the struct, in which case setting these fields to nil has no effect.
-func populateValue(f *ast.File, pkg *types.Package, typ types.Type) ast.Expr {
-	switch u := typ.Underlying().(type) {
-	case *types.Basic:
-		switch {
-		case u.Info()&types.IsNumeric != 0:
-			return &ast.BasicLit{Kind: token.INT, Value: "0"}
-		case u.Info()&types.IsBoolean != 0:
-			return &ast.Ident{Name: "false"}
-		case u.Info()&types.IsString != 0:
-			return &ast.BasicLit{Kind: token.STRING, Value: `""`}
-		case u.Kind() == types.UnsafePointer:
-			return ast.NewIdent("nil")
-		default:
-			panic("unknown basic type")
-		}
-
-	case *types.Map:
-		k := analysisinternal.TypeExpr(f, pkg, u.Key())
-		v := analysisinternal.TypeExpr(f, pkg, u.Elem())
-		if k == nil || v == nil {
-			return nil
-		}
-		return &ast.CompositeLit{
-			Type: &ast.MapType{
-				Key:   k,
-				Value: v,
-			},
-		}
-	case *types.Slice:
-		s := analysisinternal.TypeExpr(f, pkg, u.Elem())
-		if s == nil {
-			return nil
-		}
-		return &ast.CompositeLit{
-			Type: &ast.ArrayType{
-				Elt: s,
-			},
-		}
-
-	case *types.Array:
-		a := analysisinternal.TypeExpr(f, pkg, u.Elem())
-		if a == nil {
-			return nil
-		}
-		return &ast.CompositeLit{
-			Type: &ast.ArrayType{
-				Elt: a,
-				Len: &ast.BasicLit{
-					Kind: token.INT, Value: fmt.Sprintf("%v", u.Len()),
-				},
-			},
-		}
-
-	case *types.Chan:
-		v := analysisinternal.TypeExpr(f, pkg, u.Elem())
-		if v == nil {
-			return nil
-		}
-		dir := ast.ChanDir(u.Dir())
-		if u.Dir() == types.SendRecv {
-			dir = ast.SEND | ast.RECV
-		}
-		return &ast.CallExpr{
-			Fun: ast.NewIdent("make"),
-			Args: []ast.Expr{
-				&ast.ChanType{
-					Dir:   dir,
-					Value: v,
-				},
-			},
-		}
-
-	case *types.Struct:
-		s := analysisinternal.TypeExpr(f, pkg, typ)
-		if s == nil {
-			return nil
-		}
-		return &ast.CompositeLit{
-			Type: s,
-		}
-
-	case *types.Signature:
-		var params []*ast.Field
-		for i := 0; i < u.Params().Len(); i++ {
-			p := analysisinternal.TypeExpr(f, pkg, u.Params().At(i).Type())
-			if p == nil {
-				return nil
-			}
-			params = append(params, &ast.Field{
-				Type: p,
-				Names: []*ast.Ident{
-					{
-						Name: u.Params().At(i).Name(),
-					},
-				},
-			})
-		}
-		var returns []*ast.Field
-		for i := 0; i < u.Results().Len(); i++ {
-			r := analysisinternal.TypeExpr(f, pkg, u.Results().At(i).Type())
-			if r == nil {
-				return nil
-			}
-			returns = append(returns, &ast.Field{
-				Type: r,
-			})
-		}
-		return &ast.FuncLit{
-			Type: &ast.FuncType{
-				Params: &ast.FieldList{
-					List: params,
-				},
-				Results: &ast.FieldList{
-					List: returns,
-				},
-			},
-			Body: &ast.BlockStmt{},
-		}
-
-	case *types.Pointer:
-		switch u.Elem().(type) {
-		case *types.Basic:
-			return &ast.CallExpr{
-				Fun: &ast.Ident{
-					Name: "new",
-				},
-				Args: []ast.Expr{
-					&ast.Ident{
-						Name: u.Elem().String(),
-					},
-				},
-			}
-		default:
-			return &ast.UnaryExpr{
-				Op: token.AND,
-				X:  populateValue(f, pkg, u.Elem()),
-			}
-		}
-
-	case *types.Interface:
-		if param, ok := typ.(*typeparams.TypeParam); ok {
-			// *new(T) is the zero value of a type parameter T.
-			// TODO(adonovan): one could give a more specific zero
-			// value if the type has a core type that is, say,
-			// always a number or a pointer. See go/ssa for details.
-			return &ast.StarExpr{
-				X: &ast.CallExpr{
-					Fun: ast.NewIdent("new"),
-					Args: []ast.Expr{
-						ast.NewIdent(param.Obj().Name()),
-					},
-				},
-			}
-		}
-
-		return ast.NewIdent("nil")
-	}
-	return nil
-}
-
-func deref(t types.Type) types.Type {
-	for {
-		ptr, ok := t.Underlying().(*types.Pointer)
-		if !ok {
-			return t
-		}
-		t = ptr.Elem()
-	}
-}
diff -urN a/gopls/internal/lsp/analysis/fillstruct/fillstruct_test.go b/gopls/internal/lsp/analysis/fillstruct/fillstruct_test.go
--- a/gopls/internal/lsp/analysis/fillstruct/fillstruct_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillstruct/fillstruct_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fillstruct_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/fillstruct"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests, "typeparams")
-	}
-	analysistest.Run(t, testdata, fillstruct.Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/fillstruct/testdata/src/a/a.go b/gopls/internal/lsp/analysis/fillstruct/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/fillstruct/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillstruct/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,113 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fillstruct
-
-import (
-	data "b"
-	"go/ast"
-	"go/token"
-	"unsafe"
-)
-
-type emptyStruct struct{}
-
-var _ = emptyStruct{}
-
-type basicStruct struct {
-	foo int
-}
-
-var _ = basicStruct{} // want `Fill basicStruct`
-
-type twoArgStruct struct {
-	foo int
-	bar string
-}
-
-var _ = twoArgStruct{} // want `Fill twoArgStruct`
-
-var _ = twoArgStruct{ // want `Fill twoArgStruct`
-	bar: "bar",
-}
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct
-}
-
-var _ = nestedStruct{} // want `Fill nestedStruct`
-
-var _ = data.B{} // want `Fill b.B`
-
-type typedStruct struct {
-	m  map[string]int
-	s  []int
-	c  chan int
-	c1 <-chan int
-	a  [2]string
-}
-
-var _ = typedStruct{} // want `Fill typedStruct`
-
-type funStruct struct {
-	fn func(i int) int
-}
-
-var _ = funStruct{} // want `Fill funStruct`
-
-type funStructComplex struct {
-	fn func(i int, s string) (string, int)
-}
-
-var _ = funStructComplex{} // want `Fill funStructComplex`
-
-type funStructEmpty struct {
-	fn func()
-}
-
-var _ = funStructEmpty{} // want `Fill funStructEmpty`
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{} // want `Fill Bar`
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{} // want `Fill importedStruct`
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{} // want `Fill pointerBuiltinStruct`
-
-var _ = []ast.BasicLit{
-	{}, // want `Fill go/ast.BasicLit`
-}
-
-var _ = []ast.BasicLit{{}, // want "go/ast.BasicLit"
-}
-
-type unsafeStruct struct {
-	foo unsafe.Pointer
-}
-
-var _ = unsafeStruct{} // want `Fill unsafeStruct`
diff -urN a/gopls/internal/lsp/analysis/fillstruct/testdata/src/b/b.go b/gopls/internal/lsp/analysis/fillstruct/testdata/src/b/b.go
--- a/gopls/internal/lsp/analysis/fillstruct/testdata/src/b/b.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillstruct/testdata/src/b/b.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package fillstruct
-
-type B struct {
-	ExportedInt   int
-	unexportedInt int
-}
diff -urN a/gopls/internal/lsp/analysis/fillstruct/testdata/src/typeparams/typeparams.go b/gopls/internal/lsp/analysis/fillstruct/testdata/src/typeparams/typeparams.go
--- a/gopls/internal/lsp/analysis/fillstruct/testdata/src/typeparams/typeparams.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/fillstruct/testdata/src/typeparams/typeparams.go	1969-12-31 16:00:00
@@ -1,50 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fillstruct
-
-type emptyStruct[A any] struct{}
-
-var _ = emptyStruct[int]{}
-
-type basicStruct[T any] struct {
-	foo T
-}
-
-var _ = basicStruct[int]{} // want `Fill basicStruct\[int\]`
-
-type twoArgStruct[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStruct[string, int]{} // want `Fill twoArgStruct\[string, int\]`
-
-var _ = twoArgStruct[int, string]{ // want `Fill twoArgStruct\[int, string\]`
-	bar: "bar",
-}
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct[int]
-}
-
-var _ = nestedStruct{} // want "Fill nestedStruct"
-
-func _[T any]() {
-	type S struct{ t T }
-	x := S{} // want "Fill S"
-	_ = x
-}
-
-func Test() {
-	var tests = []struct {
-		a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p string
-	}{
-		{}, // want "Fill anonymous struct { a: string, b: string, c: string, ... }"
-	}
-	for _, test := range tests {
-		_ = test
-	}
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/infertypeargs.go b/gopls/internal/lsp/analysis/infertypeargs/infertypeargs.go
--- a/gopls/internal/lsp/analysis/infertypeargs/infertypeargs.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/infertypeargs.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package infertypeargs defines an analyzer that checks for explicit function
-// arguments that could be inferred.
-package infertypeargs
-
-import (
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-)
-
-const Doc = `check for unnecessary type arguments in call expressions
-
-Explicit type arguments may be omitted from call expressions if they can be
-inferred from function arguments, or from other type arguments:
-
-	func f[T any](T) {}
-	
-	func _() {
-		f[string]("foo") // string could be inferred
-	}
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:     "infertypeargs",
-	Doc:      Doc,
-	Requires: []*analysis.Analyzer{inspect.Analyzer},
-	Run:      run,
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/infertypeargs_test.go b/gopls/internal/lsp/analysis/infertypeargs/infertypeargs_test.go
--- a/gopls/internal/lsp/analysis/infertypeargs/infertypeargs_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/infertypeargs_test.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package infertypeargs_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/infertypeargs"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	if !typeparams.Enabled {
-		t.Skip("type params are not enabled")
-	}
-	testdata := analysistest.TestData()
-	analysistest.RunWithSuggestedFixes(t, testdata, infertypeargs.Analyzer, "a")
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/run_go117.go b/gopls/internal/lsp/analysis/infertypeargs/run_go117.go
--- a/gopls/internal/lsp/analysis/infertypeargs/run_go117.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/run_go117.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.18
-// +build !go1.18
-
-package infertypeargs
-
-import "golang.org/x/tools/go/analysis"
-
-// This analyzer only relates to go1.18+, and uses the types.CheckExpr API that
-// was added in Go 1.13.
-func run(pass *analysis.Pass) (interface{}, error) {
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/run_go118.go b/gopls/internal/lsp/analysis/infertypeargs/run_go118.go
--- a/gopls/internal/lsp/analysis/infertypeargs/run_go118.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/run_go118.go	1969-12-31 16:00:00
@@ -1,111 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package infertypeargs
-
-import (
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-
-	nodeFilter := []ast.Node{
-		(*ast.CallExpr)(nil),
-	}
-
-	inspect.Preorder(nodeFilter, func(node ast.Node) {
-		call := node.(*ast.CallExpr)
-		x, lbrack, indices, rbrack := typeparams.UnpackIndexExpr(call.Fun)
-		ident := calledIdent(x)
-		if ident == nil || len(indices) == 0 {
-			return // no explicit args, nothing to do
-		}
-
-		// Confirm that instantiation actually occurred at this ident.
-		idata, ok := typeparams.GetInstances(pass.TypesInfo)[ident]
-		if !ok {
-			return // something went wrong, but fail open
-		}
-		instance := idata.Type
-
-		// Start removing argument expressions from the right, and check if we can
-		// still infer the call expression.
-		required := len(indices) // number of type expressions that are required
-		for i := len(indices) - 1; i >= 0; i-- {
-			var fun ast.Expr
-			if i == 0 {
-				// No longer an index expression: just use the parameterized operand.
-				fun = x
-			} else {
-				fun = typeparams.PackIndexExpr(x, lbrack, indices[:i], indices[i-1].End())
-			}
-			newCall := &ast.CallExpr{
-				Fun:      fun,
-				Lparen:   call.Lparen,
-				Args:     call.Args,
-				Ellipsis: call.Ellipsis,
-				Rparen:   call.Rparen,
-			}
-			info := new(types.Info)
-			typeparams.InitInstanceInfo(info)
-			if err := types.CheckExpr(pass.Fset, pass.Pkg, call.Pos(), newCall, info); err != nil {
-				// Most likely inference failed.
-				break
-			}
-			newIData := typeparams.GetInstances(info)[ident]
-			newInstance := newIData.Type
-			if !types.Identical(instance, newInstance) {
-				// The inferred result type does not match the original result type, so
-				// this simplification is not valid.
-				break
-			}
-			required = i
-		}
-		if required < len(indices) {
-			var start, end token.Pos
-			var edit analysis.TextEdit
-			if required == 0 {
-				start, end = lbrack, rbrack+1 // erase the entire index
-				edit = analysis.TextEdit{Pos: start, End: end}
-			} else {
-				start = indices[required].Pos()
-				end = rbrack
-				//  erase from end of last arg to include last comma & white-spaces
-				edit = analysis.TextEdit{Pos: indices[required-1].End(), End: end}
-			}
-			pass.Report(analysis.Diagnostic{
-				Pos:     start,
-				End:     end,
-				Message: "unnecessary type arguments",
-				SuggestedFixes: []analysis.SuggestedFix{{
-					Message:   "simplify type arguments",
-					TextEdits: []analysis.TextEdit{edit},
-				}},
-			})
-		}
-	})
-
-	return nil, nil
-}
-
-func calledIdent(x ast.Expr) *ast.Ident {
-	switch x := x.(type) {
-	case *ast.Ident:
-		return x
-	case *ast.SelectorExpr:
-		return x.Sel
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// This file contains tests for the infertyepargs checker.
-
-package a
-
-func f[T any](T) {}
-
-func g[T any]() T { var x T; return x }
-
-func h[P interface{ ~*T }, T any]() {}
-
-func _() {
-	f[string]("hello") // want "unnecessary type arguments"
-	f[int](2)          // want "unnecessary type arguments"
-	_ = g[int]()
-	h[*int, int]() // want "unnecessary type arguments"
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go.golden b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go.golden
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/basic.go.golden	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// This file contains tests for the infertyepargs checker.
-
-package a
-
-func f[T any](T) {}
-
-func g[T any]() T { var x T; return x }
-
-func h[P interface{ ~*T }, T any]() {}
-
-func _() {
-	f("hello") // want "unnecessary type arguments"
-	f(2)       // want "unnecessary type arguments"
-	_ = g[int]()
-	h[*int]() // want "unnecessary type arguments"
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported/imported.go b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported/imported.go
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported/imported.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported/imported.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package imported
-
-func F[T any](T) {}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package a
-
-import "a/imported"
-
-func _() {
-	var x int
-	imported.F[int](x) // want "unnecessary type arguments"
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go.golden b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go.golden
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/imported.go.golden	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package a
-
-import "a/imported"
-
-func _() {
-	var x int
-	imported.F(x) // want "unnecessary type arguments"
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// We should not suggest removing type arguments if doing so would change the
-// resulting type.
-
-package a
-
-func id[T any](t T) T { return t }
-
-var _ = id[int](1)        // want "unnecessary type arguments"
-var _ = id[string]("foo") // want "unnecessary type arguments"
-var _ = id[int64](2)
-
-func pair[T any](t T) (T, T) { return t, t }
-
-var _, _ = pair[int](3) // want "unnecessary type arguments"
-var _, _ = pair[int64](3)
-
-func noreturn[T any](t T) {}
-
-func _() {
-	noreturn[int64](4)
-	noreturn[int](4) // want "unnecessary type arguments"
-}
diff -urN a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go.golden b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go.golden
--- a/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/infertypeargs/testdata/src/a/notypechange.go.golden	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// We should not suggest removing type arguments if doing so would change the
-// resulting type.
-
-package a
-
-func id[T any](t T) T { return t }
-
-var _ = id(1)     // want "unnecessary type arguments"
-var _ = id("foo") // want "unnecessary type arguments"
-var _ = id[int64](2)
-
-func pair[T any](t T) (T, T) { return t, t }
-
-var _, _ = pair(3) // want "unnecessary type arguments"
-var _, _ = pair[int64](3)
-
-func noreturn[T any](t T) {}
-
-func _() {
-	noreturn[int64](4)
-	noreturn(4) // want "unnecessary type arguments"
-}
diff -urN a/gopls/internal/lsp/analysis/nonewvars/nonewvars.go b/gopls/internal/lsp/analysis/nonewvars/nonewvars.go
--- a/gopls/internal/lsp/analysis/nonewvars/nonewvars.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/nonewvars/nonewvars.go	1969-12-31 16:00:00
@@ -1,95 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package nonewvars defines an Analyzer that applies suggested fixes
-// to errors of the type "no new variables on left side of :=".
-package nonewvars
-
-import (
-	"bytes"
-	"go/ast"
-	"go/format"
-	"go/token"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-	"golang.org/x/tools/internal/analysisinternal"
-)
-
-const Doc = `suggested fixes for "no new vars on left side of :="
-
-This checker provides suggested fixes for type errors of the
-type "no new vars on left side of :=". For example:
-	z := 1
-	z := 2
-will turn into
-	z := 1
-	z = 2
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "nonewvars",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{inspect.Analyzer},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	if len(pass.TypeErrors) == 0 {
-		return nil, nil
-	}
-
-	nodeFilter := []ast.Node{(*ast.AssignStmt)(nil)}
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		assignStmt, _ := n.(*ast.AssignStmt)
-		// We only care about ":=".
-		if assignStmt.Tok != token.DEFINE {
-			return
-		}
-
-		var file *ast.File
-		for _, f := range pass.Files {
-			if f.Pos() <= assignStmt.Pos() && assignStmt.Pos() < f.End() {
-				file = f
-				break
-			}
-		}
-		if file == nil {
-			return
-		}
-
-		for _, err := range pass.TypeErrors {
-			if !FixesError(err.Msg) {
-				continue
-			}
-			if assignStmt.Pos() > err.Pos || err.Pos >= assignStmt.End() {
-				continue
-			}
-			var buf bytes.Buffer
-			if err := format.Node(&buf, pass.Fset, file); err != nil {
-				continue
-			}
-			pass.Report(analysis.Diagnostic{
-				Pos:     err.Pos,
-				End:     analysisinternal.TypeErrorEndPos(pass.Fset, buf.Bytes(), err.Pos),
-				Message: err.Msg,
-				SuggestedFixes: []analysis.SuggestedFix{{
-					Message: "Change ':=' to '='",
-					TextEdits: []analysis.TextEdit{{
-						Pos: err.Pos,
-						End: err.Pos + 1,
-					}},
-				}},
-			})
-		}
-	})
-	return nil, nil
-}
-
-func FixesError(msg string) bool {
-	return msg == "no new variables on left side of :="
-}
diff -urN a/gopls/internal/lsp/analysis/nonewvars/nonewvars_test.go b/gopls/internal/lsp/analysis/nonewvars/nonewvars_test.go
--- a/gopls/internal/lsp/analysis/nonewvars/nonewvars_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/nonewvars/nonewvars_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package nonewvars_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/nonewvars"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests, "typeparams")
-	}
-	analysistest.RunWithSuggestedFixes(t, testdata, nonewvars.Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go b/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package nonewvars
-
-import "log"
-
-func x() {
-	z := 1
-	z := 2 // want "no new variables on left side of :="
-
-	_, z := 3, 100 // want "no new variables on left side of :="
-
-	log.Println(z)
-}
diff -urN a/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/nonewvars/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package nonewvars
-
-import "log"
-
-func x() {
-	z := 1
-	z = 2 // want "no new variables on left side of :="
-
-	_, z = 3, 100 // want "no new variables on left side of :="
-
-	log.Println(z)
-}
diff -urN a/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go b/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go
--- a/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package nonewvars
-
-func hello[T any]() int {
-	var z T
-	z := 1 // want "no new variables on left side of :="
-}
diff -urN a/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go.golden b/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go.golden
--- a/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/nonewvars/testdata/src/typeparams/a.go.golden	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package nonewvars
-
-func hello[T any]() int {
-	var z T
-	z = 1 // want "no new variables on left side of :="
-}
diff -urN a/gopls/internal/lsp/analysis/noresultvalues/noresultvalues.go b/gopls/internal/lsp/analysis/noresultvalues/noresultvalues.go
--- a/gopls/internal/lsp/analysis/noresultvalues/noresultvalues.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/noresultvalues/noresultvalues.go	1969-12-31 16:00:00
@@ -1,92 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package noresultvalues defines an Analyzer that applies suggested fixes
-// to errors of the type "no result values expected".
-package noresultvalues
-
-import (
-	"bytes"
-	"go/ast"
-	"go/format"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-	"golang.org/x/tools/internal/analysisinternal"
-)
-
-const Doc = `suggested fixes for unexpected return values
-
-This checker provides suggested fixes for type errors of the
-type "no result values expected" or "too many return values".
-For example:
-	func z() { return nil }
-will turn into
-	func z() { return }
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "noresultvalues",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{inspect.Analyzer},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	if len(pass.TypeErrors) == 0 {
-		return nil, nil
-	}
-
-	nodeFilter := []ast.Node{(*ast.ReturnStmt)(nil)}
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		retStmt, _ := n.(*ast.ReturnStmt)
-
-		var file *ast.File
-		for _, f := range pass.Files {
-			if f.Pos() <= retStmt.Pos() && retStmt.Pos() < f.End() {
-				file = f
-				break
-			}
-		}
-		if file == nil {
-			return
-		}
-
-		for _, err := range pass.TypeErrors {
-			if !FixesError(err.Msg) {
-				continue
-			}
-			if retStmt.Pos() >= err.Pos || err.Pos >= retStmt.End() {
-				continue
-			}
-			var buf bytes.Buffer
-			if err := format.Node(&buf, pass.Fset, file); err != nil {
-				continue
-			}
-			pass.Report(analysis.Diagnostic{
-				Pos:     err.Pos,
-				End:     analysisinternal.TypeErrorEndPos(pass.Fset, buf.Bytes(), err.Pos),
-				Message: err.Msg,
-				SuggestedFixes: []analysis.SuggestedFix{{
-					Message: "Delete return values",
-					TextEdits: []analysis.TextEdit{{
-						Pos:     retStmt.Pos(),
-						End:     retStmt.End(),
-						NewText: []byte("return"),
-					}},
-				}},
-			})
-		}
-	})
-	return nil, nil
-}
-
-func FixesError(msg string) bool {
-	return msg == "no result values expected" ||
-		strings.HasPrefix(msg, "too many return values") && strings.Contains(msg, "want ()")
-}
diff -urN a/gopls/internal/lsp/analysis/noresultvalues/noresultvalues_test.go b/gopls/internal/lsp/analysis/noresultvalues/noresultvalues_test.go
--- a/gopls/internal/lsp/analysis/noresultvalues/noresultvalues_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/noresultvalues/noresultvalues_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package noresultvalues_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/noresultvalues"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests, "typeparams")
-	}
-	analysistest.RunWithSuggestedFixes(t, testdata, noresultvalues.Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package noresultvalues
-
-func x() { return nil } // want `no result values expected|too many return values`
-
-func y() { return nil, "hello" } // want `no result values expected|too many return values`
diff -urN a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package noresultvalues
-
-func x() { return } // want `no result values expected|too many return values`
-
-func y() { return } // want `no result values expected|too many return values`
diff -urN a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go
--- a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package noresult
-
-func hello[T any]() {
-	var z T
-	return z // want `no result values expected|too many return values`
-}
diff -urN a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go.golden b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go.golden
--- a/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/noresultvalues/testdata/src/typeparams/a.go.golden	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package noresult
-
-func hello[T any]() {
-	var z T
-	return // want `no result values expected|too many return values`
-}
diff -urN a/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit.go b/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit.go
--- a/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit.go	1969-12-31 16:00:00
@@ -1,196 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package simplifycompositelit defines an Analyzer that simplifies composite literals.
-// https://github.com/golang/go/blob/master/src/cmd/gofmt/simplify.go
-// https://golang.org/cmd/gofmt/#hdr-The_simplify_command
-package simplifycompositelit
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/printer"
-	"go/token"
-	"reflect"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-)
-
-const Doc = `check for composite literal simplifications
-
-An array, slice, or map composite literal of the form:
-	[]T{T{}, T{}}
-will be simplified to:
-	[]T{{}, {}}
-
-This is one of the simplifications that "gofmt -s" applies.`
-
-var Analyzer = &analysis.Analyzer{
-	Name:     "simplifycompositelit",
-	Doc:      Doc,
-	Requires: []*analysis.Analyzer{inspect.Analyzer},
-	Run:      run,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	nodeFilter := []ast.Node{(*ast.CompositeLit)(nil)}
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		expr := n.(*ast.CompositeLit)
-
-		outer := expr
-		var keyType, eltType ast.Expr
-		switch typ := outer.Type.(type) {
-		case *ast.ArrayType:
-			eltType = typ.Elt
-		case *ast.MapType:
-			keyType = typ.Key
-			eltType = typ.Value
-		}
-
-		if eltType == nil {
-			return
-		}
-		var ktyp reflect.Value
-		if keyType != nil {
-			ktyp = reflect.ValueOf(keyType)
-		}
-		typ := reflect.ValueOf(eltType)
-		for _, x := range outer.Elts {
-			// look at value of indexed/named elements
-			if t, ok := x.(*ast.KeyValueExpr); ok {
-				if keyType != nil {
-					simplifyLiteral(pass, ktyp, keyType, t.Key)
-				}
-				x = t.Value
-			}
-			simplifyLiteral(pass, typ, eltType, x)
-		}
-	})
-	return nil, nil
-}
-
-func simplifyLiteral(pass *analysis.Pass, typ reflect.Value, astType, x ast.Expr) {
-	// if the element is a composite literal and its literal type
-	// matches the outer literal's element type exactly, the inner
-	// literal type may be omitted
-	if inner, ok := x.(*ast.CompositeLit); ok && match(typ, reflect.ValueOf(inner.Type)) {
-		var b bytes.Buffer
-		printer.Fprint(&b, pass.Fset, inner.Type)
-		createDiagnostic(pass, inner.Type.Pos(), inner.Type.End(), b.String())
-	}
-	// if the outer literal's element type is a pointer type *T
-	// and the element is & of a composite literal of type T,
-	// the inner &T may be omitted.
-	if ptr, ok := astType.(*ast.StarExpr); ok {
-		if addr, ok := x.(*ast.UnaryExpr); ok && addr.Op == token.AND {
-			if inner, ok := addr.X.(*ast.CompositeLit); ok {
-				if match(reflect.ValueOf(ptr.X), reflect.ValueOf(inner.Type)) {
-					var b bytes.Buffer
-					printer.Fprint(&b, pass.Fset, inner.Type)
-					// Account for the & by subtracting 1 from typ.Pos().
-					createDiagnostic(pass, inner.Type.Pos()-1, inner.Type.End(), "&"+b.String())
-				}
-			}
-		}
-	}
-}
-
-func createDiagnostic(pass *analysis.Pass, start, end token.Pos, typ string) {
-	pass.Report(analysis.Diagnostic{
-		Pos:     start,
-		End:     end,
-		Message: "redundant type from array, slice, or map composite literal",
-		SuggestedFixes: []analysis.SuggestedFix{{
-			Message: fmt.Sprintf("Remove '%s'", typ),
-			TextEdits: []analysis.TextEdit{{
-				Pos:     start,
-				End:     end,
-				NewText: []byte{},
-			}},
-		}},
-	})
-}
-
-// match reports whether pattern matches val,
-// recording wildcard submatches in m.
-// If m == nil, match checks whether pattern == val.
-// from https://github.com/golang/go/blob/26154f31ad6c801d8bad5ef58df1e9263c6beec7/src/cmd/gofmt/rewrite.go#L160
-func match(pattern, val reflect.Value) bool {
-	// Otherwise, pattern and val must match recursively.
-	if !pattern.IsValid() || !val.IsValid() {
-		return !pattern.IsValid() && !val.IsValid()
-	}
-	if pattern.Type() != val.Type() {
-		return false
-	}
-
-	// Special cases.
-	switch pattern.Type() {
-	case identType:
-		// For identifiers, only the names need to match
-		// (and none of the other *ast.Object information).
-		// This is a common case, handle it all here instead
-		// of recursing down any further via reflection.
-		p := pattern.Interface().(*ast.Ident)
-		v := val.Interface().(*ast.Ident)
-		return p == nil && v == nil || p != nil && v != nil && p.Name == v.Name
-	case objectPtrType, positionType:
-		// object pointers and token positions always match
-		return true
-	case callExprType:
-		// For calls, the Ellipsis fields (token.Position) must
-		// match since that is how f(x) and f(x...) are different.
-		// Check them here but fall through for the remaining fields.
-		p := pattern.Interface().(*ast.CallExpr)
-		v := val.Interface().(*ast.CallExpr)
-		if p.Ellipsis.IsValid() != v.Ellipsis.IsValid() {
-			return false
-		}
-	}
-
-	p := reflect.Indirect(pattern)
-	v := reflect.Indirect(val)
-	if !p.IsValid() || !v.IsValid() {
-		return !p.IsValid() && !v.IsValid()
-	}
-
-	switch p.Kind() {
-	case reflect.Slice:
-		if p.Len() != v.Len() {
-			return false
-		}
-		for i := 0; i < p.Len(); i++ {
-			if !match(p.Index(i), v.Index(i)) {
-				return false
-			}
-		}
-		return true
-
-	case reflect.Struct:
-		for i := 0; i < p.NumField(); i++ {
-			if !match(p.Field(i), v.Field(i)) {
-				return false
-			}
-		}
-		return true
-
-	case reflect.Interface:
-		return match(p.Elem(), v.Elem())
-	}
-
-	// Handle token integers, etc.
-	return p.Interface() == v.Interface()
-}
-
-// Values/types for special cases.
-var (
-	identType     = reflect.TypeOf((*ast.Ident)(nil))
-	objectPtrType = reflect.TypeOf((*ast.Object)(nil))
-	positionType  = reflect.TypeOf(token.NoPos)
-	callExprType  = reflect.TypeOf((*ast.CallExpr)(nil))
-)
diff -urN a/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit_test.go b/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit_test.go
--- a/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifycompositelit/simplifycompositelit_test.go	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package simplifycompositelit_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/simplifycompositelit"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	analysistest.RunWithSuggestedFixes(t, testdata, simplifycompositelit.Analyzer, "a")
-}
diff -urN a/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go b/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,234 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package testdata
-
-type T struct {
-	x, y int
-}
-
-type T2 struct {
-	w, z int
-}
-
-var _ = [42]T{
-	T{},     // want "redundant type from array, slice, or map composite literal"
-	T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [...]T{
-	T{},     // want "redundant type from array, slice, or map composite literal"
-	T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []T{
-	T{},     // want "redundant type from array, slice, or map composite literal"
-	T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []T{
-	T{}, // want "redundant type from array, slice, or map composite literal"
-	10:  T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20:  T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []struct {
-	x, y int
-}{
-	struct{ x, y int }{}, // want "redundant type from array, slice, or map composite literal"
-	10:                   struct{ x, y int }{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20:                   struct{ x, y int }{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []interface{}{
-	T{},
-	10: T{1, 2},
-	20: T{3, 4},
-}
-
-var _ = [][]int{
-	[]int{},     // want "redundant type from array, slice, or map composite literal"
-	[]int{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	[]int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [][]int{
-	([]int{}),
-	([]int{1, 2}),
-	[]int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [][][]int{
-	[][]int{}, // want "redundant type from array, slice, or map composite literal"
-	[][]int{ // want "redundant type from array, slice, or map composite literal"
-		[]int{},           // want "redundant type from array, slice, or map composite literal"
-		[]int{0, 1, 2, 3}, // want "redundant type from array, slice, or map composite literal"
-		[]int{4, 5},       // want "redundant type from array, slice, or map composite literal"
-	},
-}
-
-var _ = map[string]T{
-	"foo": T{},     // want "redundant type from array, slice, or map composite literal"
-	"bar": T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]struct {
-	x, y int
-}{
-	"foo": struct{ x, y int }{},     // want "redundant type from array, slice, or map composite literal"
-	"bar": struct{ x, y int }{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": struct{ x, y int }{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]interface{}{
-	"foo": T{},
-	"bar": T{1, 2},
-	"bal": T{3, 4},
-}
-
-var _ = map[string][]int{
-	"foo": []int{},     // want "redundant type from array, slice, or map composite literal"
-	"bar": []int{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": []int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string][]int{
-	"foo": ([]int{}),
-	"bar": ([]int{1, 2}),
-	"bal": []int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-type Point struct {
-	a int
-	b int
-}
-
-type Piece struct {
-	a int
-	b int
-	c Point
-	d []Point
-	e *Point
-	f *Point
-}
-
-// from exp/4s/data.go
-var pieces3 = []Piece{
-	Piece{0, 0, Point{4, 1}, []Point{Point{0, 0}, Point{1, 0}, Point{1, 0}, Point{1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	Piece{1, 0, Point{1, 4}, []Point{Point{0, 0}, Point{0, 1}, Point{0, 1}, Point{0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	Piece{2, 0, Point{4, 1}, []Point{Point{0, 0}, Point{1, 0}, Point{1, 0}, Point{1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	Piece{3, 0, Point{1, 4}, []Point{Point{0, 0}, Point{0, 1}, Point{0, 1}, Point{0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [42]*T{
-	&T{},     // want "redundant type from array, slice, or map composite literal"
-	&T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	&T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [...]*T{
-	&T{},     // want "redundant type from array, slice, or map composite literal"
-	&T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	&T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*T{
-	&T{},     // want "redundant type from array, slice, or map composite literal"
-	&T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	&T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*T{
-	&T{}, // want "redundant type from array, slice, or map composite literal"
-	10:   &T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20:   &T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*struct {
-	x, y int
-}{
-	&struct{ x, y int }{}, // want "redundant type from array, slice, or map composite literal"
-	10:                    &struct{ x, y int }{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20:                    &struct{ x, y int }{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []interface{}{
-	&T{},
-	10: &T{1, 2},
-	20: &T{3, 4},
-}
-
-var _ = []*[]int{
-	&[]int{},     // want "redundant type from array, slice, or map composite literal"
-	&[]int{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	&[]int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*[]int{
-	(&[]int{}),
-	(&[]int{1, 2}),
-	&[]int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*[]*[]int{
-	&[]*[]int{}, // want "redundant type from array, slice, or map composite literal"
-	&[]*[]int{ // want "redundant type from array, slice, or map composite literal"
-		&[]int{},           // want "redundant type from array, slice, or map composite literal"
-		&[]int{0, 1, 2, 3}, // want "redundant type from array, slice, or map composite literal"
-		&[]int{4, 5},       // want "redundant type from array, slice, or map composite literal"
-	},
-}
-
-var _ = map[string]*T{
-	"foo": &T{},     // want "redundant type from array, slice, or map composite literal"
-	"bar": &T{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": &T{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]*struct {
-	x, y int
-}{
-	"foo": &struct{ x, y int }{},     // want "redundant type from array, slice, or map composite literal"
-	"bar": &struct{ x, y int }{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": &struct{ x, y int }{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]interface{}{
-	"foo": &T{},
-	"bar": &T{1, 2},
-	"bal": &T{3, 4},
-}
-
-var _ = map[string]*[]int{
-	"foo": &[]int{},     // want "redundant type from array, slice, or map composite literal"
-	"bar": &[]int{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": &[]int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]*[]int{
-	"foo": (&[]int{}),
-	"bar": (&[]int{1, 2}),
-	"bal": &[]int{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var pieces4 = []*Piece{
-	&Piece{0, 0, Point{4, 1}, []Point{Point{0, 0}, Point{1, 0}, Point{1, 0}, Point{1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	&Piece{1, 0, Point{1, 4}, []Point{Point{0, 0}, Point{0, 1}, Point{0, 1}, Point{0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	&Piece{2, 0, Point{4, 1}, []Point{Point{0, 0}, Point{1, 0}, Point{1, 0}, Point{1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	&Piece{3, 0, Point{1, 4}, []Point{Point{0, 0}, Point{0, 1}, Point{0, 1}, Point{0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[T]T2{
-	T{1, 2}: T2{3, 4}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	T{5, 6}: T2{7, 8}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[*T]*T2{
-	&T{1, 2}: &T2{3, 4}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	&T{5, 6}: &T2{7, 8}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
diff -urN a/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifycompositelit/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,234 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package testdata
-
-type T struct {
-	x, y int
-}
-
-type T2 struct {
-	w, z int
-}
-
-var _ = [42]T{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [...]T{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []T{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []T{
-	{}, // want "redundant type from array, slice, or map composite literal"
-	10: {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20: {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []struct {
-	x, y int
-}{
-	{}, // want "redundant type from array, slice, or map composite literal"
-	10: {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20: {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []interface{}{
-	T{},
-	10: T{1, 2},
-	20: T{3, 4},
-}
-
-var _ = [][]int{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [][]int{
-	([]int{}),
-	([]int{1, 2}),
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [][][]int{
-	{}, // want "redundant type from array, slice, or map composite literal"
-	{ // want "redundant type from array, slice, or map composite literal"
-		{},           // want "redundant type from array, slice, or map composite literal"
-		{0, 1, 2, 3}, // want "redundant type from array, slice, or map composite literal"
-		{4, 5},       // want "redundant type from array, slice, or map composite literal"
-	},
-}
-
-var _ = map[string]T{
-	"foo": {},     // want "redundant type from array, slice, or map composite literal"
-	"bar": {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]struct {
-	x, y int
-}{
-	"foo": {},     // want "redundant type from array, slice, or map composite literal"
-	"bar": {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]interface{}{
-	"foo": T{},
-	"bar": T{1, 2},
-	"bal": T{3, 4},
-}
-
-var _ = map[string][]int{
-	"foo": {},     // want "redundant type from array, slice, or map composite literal"
-	"bar": {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string][]int{
-	"foo": ([]int{}),
-	"bar": ([]int{1, 2}),
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-type Point struct {
-	a int
-	b int
-}
-
-type Piece struct {
-	a int
-	b int
-	c Point
-	d []Point
-	e *Point
-	f *Point
-}
-
-// from exp/4s/data.go
-var pieces3 = []Piece{
-	{0, 0, Point{4, 1}, []Point{{0, 0}, {1, 0}, {1, 0}, {1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{1, 0, Point{1, 4}, []Point{{0, 0}, {0, 1}, {0, 1}, {0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{2, 0, Point{4, 1}, []Point{{0, 0}, {1, 0}, {1, 0}, {1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{3, 0, Point{1, 4}, []Point{{0, 0}, {0, 1}, {0, 1}, {0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [42]*T{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = [...]*T{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*T{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*T{
-	{}, // want "redundant type from array, slice, or map composite literal"
-	10: {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20: {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*struct {
-	x, y int
-}{
-	{}, // want "redundant type from array, slice, or map composite literal"
-	10: {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	20: {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []interface{}{
-	&T{},
-	10: &T{1, 2},
-	20: &T{3, 4},
-}
-
-var _ = []*[]int{
-	{},     // want "redundant type from array, slice, or map composite literal"
-	{1, 2}, // want "redundant type from array, slice, or map composite literal"
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*[]int{
-	(&[]int{}),
-	(&[]int{1, 2}),
-	{3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = []*[]*[]int{
-	{}, // want "redundant type from array, slice, or map composite literal"
-	{ // want "redundant type from array, slice, or map composite literal"
-		{},           // want "redundant type from array, slice, or map composite literal"
-		{0, 1, 2, 3}, // want "redundant type from array, slice, or map composite literal"
-		{4, 5},       // want "redundant type from array, slice, or map composite literal"
-	},
-}
-
-var _ = map[string]*T{
-	"foo": {},     // want "redundant type from array, slice, or map composite literal"
-	"bar": {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]*struct {
-	x, y int
-}{
-	"foo": {},     // want "redundant type from array, slice, or map composite literal"
-	"bar": {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]interface{}{
-	"foo": &T{},
-	"bar": &T{1, 2},
-	"bal": &T{3, 4},
-}
-
-var _ = map[string]*[]int{
-	"foo": {},     // want "redundant type from array, slice, or map composite literal"
-	"bar": {1, 2}, // want "redundant type from array, slice, or map composite literal"
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[string]*[]int{
-	"foo": (&[]int{}),
-	"bar": (&[]int{1, 2}),
-	"bal": {3, 4}, // want "redundant type from array, slice, or map composite literal"
-}
-
-var pieces4 = []*Piece{
-	{0, 0, Point{4, 1}, []Point{{0, 0}, {1, 0}, {1, 0}, {1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{1, 0, Point{1, 4}, []Point{{0, 0}, {0, 1}, {0, 1}, {0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{2, 0, Point{4, 1}, []Point{{0, 0}, {1, 0}, {1, 0}, {1, 0}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{3, 0, Point{1, 4}, []Point{{0, 0}, {0, 1}, {0, 1}, {0, 1}}, nil, nil}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[T]T2{
-	{1, 2}: {3, 4}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{5, 6}: {7, 8}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
-
-var _ = map[*T]*T2{
-	{1, 2}: {3, 4}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-	{5, 6}: {7, 8}, // want "redundant type from array, slice, or map composite literal" "redundant type from array, slice, or map composite literal"
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyrange/simplifyrange.go b/gopls/internal/lsp/analysis/simplifyrange/simplifyrange.go
--- a/gopls/internal/lsp/analysis/simplifyrange/simplifyrange.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyrange/simplifyrange.go	1969-12-31 16:00:00
@@ -1,116 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package simplifyrange defines an Analyzer that simplifies range statements.
-// https://golang.org/cmd/gofmt/#hdr-The_simplify_command
-// https://github.com/golang/go/blob/master/src/cmd/gofmt/simplify.go
-package simplifyrange
-
-import (
-	"bytes"
-	"go/ast"
-	"go/printer"
-	"go/token"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-)
-
-const Doc = `check for range statement simplifications
-
-A range of the form:
-	for x, _ = range v {...}
-will be simplified to:
-	for x = range v {...}
-
-A range of the form:
-	for _ = range v {...}
-will be simplified to:
-	for range v {...}
-
-This is one of the simplifications that "gofmt -s" applies.`
-
-var Analyzer = &analysis.Analyzer{
-	Name:     "simplifyrange",
-	Doc:      Doc,
-	Requires: []*analysis.Analyzer{inspect.Analyzer},
-	Run:      run,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	nodeFilter := []ast.Node{
-		(*ast.RangeStmt)(nil),
-	}
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		var copy *ast.RangeStmt
-		if stmt, ok := n.(*ast.RangeStmt); ok {
-			x := *stmt
-			copy = &x
-		}
-		if copy == nil {
-			return
-		}
-		end := newlineIndex(pass.Fset, copy)
-
-		// Range statements of the form: for i, _ := range x {}
-		var old ast.Expr
-		if isBlank(copy.Value) {
-			old = copy.Value
-			copy.Value = nil
-		}
-		// Range statements of the form: for _ := range x {}
-		if isBlank(copy.Key) && copy.Value == nil {
-			old = copy.Key
-			copy.Key = nil
-		}
-		// Return early if neither if condition is met.
-		if old == nil {
-			return
-		}
-		pass.Report(analysis.Diagnostic{
-			Pos:            old.Pos(),
-			End:            old.End(),
-			Message:        "simplify range expression",
-			SuggestedFixes: suggestedFixes(pass.Fset, copy, end),
-		})
-	})
-	return nil, nil
-}
-
-func suggestedFixes(fset *token.FileSet, rng *ast.RangeStmt, end token.Pos) []analysis.SuggestedFix {
-	var b bytes.Buffer
-	printer.Fprint(&b, fset, rng)
-	stmt := b.Bytes()
-	index := bytes.Index(stmt, []byte("\n"))
-	// If there is a new line character, then don't replace the body.
-	if index != -1 {
-		stmt = stmt[:index]
-	}
-	return []analysis.SuggestedFix{{
-		Message: "Remove empty value",
-		TextEdits: []analysis.TextEdit{{
-			Pos:     rng.Pos(),
-			End:     end,
-			NewText: stmt[:index],
-		}},
-	}}
-}
-
-func newlineIndex(fset *token.FileSet, rng *ast.RangeStmt) token.Pos {
-	var b bytes.Buffer
-	printer.Fprint(&b, fset, rng)
-	contents := b.Bytes()
-	index := bytes.Index(contents, []byte("\n"))
-	if index == -1 {
-		return rng.End()
-	}
-	return rng.Pos() + token.Pos(index)
-}
-
-func isBlank(x ast.Expr) bool {
-	ident, ok := x.(*ast.Ident)
-	return ok && ident.Name == "_"
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyrange/simplifyrange_test.go b/gopls/internal/lsp/analysis/simplifyrange/simplifyrange_test.go
--- a/gopls/internal/lsp/analysis/simplifyrange/simplifyrange_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyrange/simplifyrange_test.go	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package simplifyrange_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/simplifyrange"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	analysistest.RunWithSuggestedFixes(t, testdata, simplifyrange.Analyzer, "a")
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go b/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package testdata
-
-import "log"
-
-func m() {
-	maps := make(map[string]string)
-	for k, _ := range maps { // want "simplify range expression"
-		log.Println(k)
-	}
-	for _ = range maps { // want "simplify range expression"
-	}
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyrange/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package testdata
-
-import "log"
-
-func m() {
-	maps := make(map[string]string)
-	for k := range maps { // want "simplify range expression"
-		log.Println(k)
-	}
-	for range maps { // want "simplify range expression"
-	}
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyslice/simplifyslice.go b/gopls/internal/lsp/analysis/simplifyslice/simplifyslice.go
--- a/gopls/internal/lsp/analysis/simplifyslice/simplifyslice.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyslice/simplifyslice.go	1969-12-31 16:00:00
@@ -1,94 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package simplifyslice defines an Analyzer that simplifies slice statements.
-// https://github.com/golang/go/blob/master/src/cmd/gofmt/simplify.go
-// https://golang.org/cmd/gofmt/#hdr-The_simplify_command
-package simplifyslice
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/printer"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-)
-
-const Doc = `check for slice simplifications
-
-A slice expression of the form:
-	s[a:len(s)]
-will be simplified to:
-	s[a:]
-
-This is one of the simplifications that "gofmt -s" applies.`
-
-var Analyzer = &analysis.Analyzer{
-	Name:     "simplifyslice",
-	Doc:      Doc,
-	Requires: []*analysis.Analyzer{inspect.Analyzer},
-	Run:      run,
-}
-
-// Note: We could also simplify slice expressions of the form s[0:b] to s[:b]
-//       but we leave them as is since sometimes we want to be very explicit
-//       about the lower bound.
-// An example where the 0 helps:
-//       x, y, z := b[0:2], b[2:4], b[4:6]
-// An example where it does not:
-//       x, y := b[:n], b[n:]
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	nodeFilter := []ast.Node{
-		(*ast.SliceExpr)(nil),
-	}
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		expr := n.(*ast.SliceExpr)
-		// - 3-index slices always require the 2nd and 3rd index
-		if expr.Max != nil {
-			return
-		}
-		s, ok := expr.X.(*ast.Ident)
-		// the array/slice object is a single, resolved identifier
-		if !ok || s.Obj == nil {
-			return
-		}
-		call, ok := expr.High.(*ast.CallExpr)
-		// the high expression is a function call with a single argument
-		if !ok || len(call.Args) != 1 || call.Ellipsis.IsValid() {
-			return
-		}
-		fun, ok := call.Fun.(*ast.Ident)
-		// the function called is "len" and it is not locally defined; and
-		// because we don't have dot imports, it must be the predefined len()
-		if !ok || fun.Name != "len" || fun.Obj != nil {
-			return
-		}
-		arg, ok := call.Args[0].(*ast.Ident)
-		// the len argument is the array/slice object
-		if !ok || arg.Obj != s.Obj {
-			return
-		}
-		var b bytes.Buffer
-		printer.Fprint(&b, pass.Fset, expr.High)
-		pass.Report(analysis.Diagnostic{
-			Pos:     expr.High.Pos(),
-			End:     expr.High.End(),
-			Message: fmt.Sprintf("unneeded: %s", b.String()),
-			SuggestedFixes: []analysis.SuggestedFix{{
-				Message: fmt.Sprintf("Remove '%s'", b.String()),
-				TextEdits: []analysis.TextEdit{{
-					Pos:     expr.High.Pos(),
-					End:     expr.High.End(),
-					NewText: []byte{},
-				}},
-			}},
-		})
-	})
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyslice/simplifyslice_test.go b/gopls/internal/lsp/analysis/simplifyslice/simplifyslice_test.go
--- a/gopls/internal/lsp/analysis/simplifyslice/simplifyslice_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyslice/simplifyslice_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package simplifyslice_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/simplifyslice"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests, "typeparams")
-	}
-	analysistest.RunWithSuggestedFixes(t, testdata, simplifyslice.Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,70 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package testdata
-
-var (
-	a [10]byte
-	b [20]float32
-	s []int
-	t struct {
-		s []byte
-	}
-
-	_ = a[0:]
-	_ = a[1:10]
-	_ = a[2:len(a)] // want "unneeded: len\\(a\\)"
-	_ = a[3:(len(a))]
-	_ = a[len(a)-1 : len(a)] // want "unneeded: len\\(a\\)"
-	_ = a[2:len(a):len(a)]
-
-	_ = a[:]
-	_ = a[:10]
-	_ = a[:len(a)] // want "unneeded: len\\(a\\)"
-	_ = a[:(len(a))]
-	_ = a[:len(a)-1]
-	_ = a[:len(a):len(a)]
-
-	_ = s[0:]
-	_ = s[1:10]
-	_ = s[2:len(s)] // want "unneeded: len\\(s\\)"
-	_ = s[3:(len(s))]
-	_ = s[len(a) : len(s)-1]
-	_ = s[0:len(b)]
-	_ = s[2:len(s):len(s)]
-
-	_ = s[:]
-	_ = s[:10]
-	_ = s[:len(s)] // want "unneeded: len\\(s\\)"
-	_ = s[:(len(s))]
-	_ = s[:len(s)-1]
-	_ = s[:len(b)]
-	_ = s[:len(s):len(s)]
-
-	_ = t.s[0:]
-	_ = t.s[1:10]
-	_ = t.s[2:len(t.s)]
-	_ = t.s[3:(len(t.s))]
-	_ = t.s[len(a) : len(t.s)-1]
-	_ = t.s[0:len(b)]
-	_ = t.s[2:len(t.s):len(t.s)]
-
-	_ = t.s[:]
-	_ = t.s[:10]
-	_ = t.s[:len(t.s)]
-	_ = t.s[:(len(t.s))]
-	_ = t.s[:len(t.s)-1]
-	_ = t.s[:len(b)]
-	_ = t.s[:len(t.s):len(t.s)]
-)
-
-func _() {
-	s := s[0:len(s)] // want "unneeded: len\\(s\\)"
-	_ = s
-}
-
-func m() {
-	maps := []int{}
-	_ = maps[1:len(maps)] // want "unneeded: len\\(maps\\)"
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,70 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package testdata
-
-var (
-	a [10]byte
-	b [20]float32
-	s []int
-	t struct {
-		s []byte
-	}
-
-	_ = a[0:]
-	_ = a[1:10]
-	_ = a[2:] // want "unneeded: len\\(a\\)"
-	_ = a[3:(len(a))]
-	_ = a[len(a)-1:] // want "unneeded: len\\(a\\)"
-	_ = a[2:len(a):len(a)]
-
-	_ = a[:]
-	_ = a[:10]
-	_ = a[:] // want "unneeded: len\\(a\\)"
-	_ = a[:(len(a))]
-	_ = a[:len(a)-1]
-	_ = a[:len(a):len(a)]
-
-	_ = s[0:]
-	_ = s[1:10]
-	_ = s[2:] // want "unneeded: len\\(s\\)"
-	_ = s[3:(len(s))]
-	_ = s[len(a) : len(s)-1]
-	_ = s[0:len(b)]
-	_ = s[2:len(s):len(s)]
-
-	_ = s[:]
-	_ = s[:10]
-	_ = s[:] // want "unneeded: len\\(s\\)"
-	_ = s[:(len(s))]
-	_ = s[:len(s)-1]
-	_ = s[:len(b)]
-	_ = s[:len(s):len(s)]
-
-	_ = t.s[0:]
-	_ = t.s[1:10]
-	_ = t.s[2:len(t.s)]
-	_ = t.s[3:(len(t.s))]
-	_ = t.s[len(a) : len(t.s)-1]
-	_ = t.s[0:len(b)]
-	_ = t.s[2:len(t.s):len(t.s)]
-
-	_ = t.s[:]
-	_ = t.s[:10]
-	_ = t.s[:len(t.s)]
-	_ = t.s[:(len(t.s))]
-	_ = t.s[:len(t.s)-1]
-	_ = t.s[:len(b)]
-	_ = t.s[:len(t.s):len(t.s)]
-)
-
-func _() {
-	s := s[0:] // want "unneeded: len\\(s\\)"
-	_ = s
-}
-
-func m() {
-	maps := []int{}
-	_ = maps[1:] // want "unneeded: len\\(maps\\)"
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go
--- a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-//
-//go:build go1.18
-// +build go1.18
-
-package testdata
-
-type List[E any] []E
-
-// TODO(suzmue): add a test for generic slice expressions when https://github.com/golang/go/issues/48618 is closed.
-// type S interface{ ~[]int }
-
-var (
-	a [10]byte
-	b [20]float32
-	p List[int]
-
-	_ = p[0:]
-	_ = p[1:10]
-	_ = p[2:len(p)] // want "unneeded: len\\(p\\)"
-	_ = p[3:(len(p))]
-	_ = p[len(a) : len(p)-1]
-	_ = p[0:len(b)]
-	_ = p[2:len(p):len(p)]
-
-	_ = p[:]
-	_ = p[:10]
-	_ = p[:len(p)] // want "unneeded: len\\(p\\)"
-	_ = p[:(len(p))]
-	_ = p[:len(p)-1]
-	_ = p[:len(b)]
-	_ = p[:len(p):len(p)]
-)
-
-func foo[E any](a List[E]) {
-	_ = a[0:len(a)] // want "unneeded: len\\(a\\)"
-}
diff -urN a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go.golden b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go.golden
--- a/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/simplifyslice/testdata/src/typeparams/typeparams.go.golden	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-//
-//go:build go1.18
-// +build go1.18
-
-package testdata
-
-type List[E any] []E
-
-// TODO(suzmue): add a test for generic slice expressions when https://github.com/golang/go/issues/48618 is closed.
-// type S interface{ ~[]int }
-
-var (
-	a [10]byte
-	b [20]float32
-	p List[int]
-
-	_ = p[0:]
-	_ = p[1:10]
-	_ = p[2:] // want "unneeded: len\\(p\\)"
-	_ = p[3:(len(p))]
-	_ = p[len(a) : len(p)-1]
-	_ = p[0:len(b)]
-	_ = p[2:len(p):len(p)]
-
-	_ = p[:]
-	_ = p[:10]
-	_ = p[:] // want "unneeded: len\\(p\\)"
-	_ = p[:(len(p))]
-	_ = p[:len(p)-1]
-	_ = p[:len(b)]
-	_ = p[:len(p):len(p)]
-)
-
-func foo[E any](a List[E]) {
-	_ = a[0:] // want "unneeded: len\\(a\\)"
-}
diff -urN a/gopls/internal/lsp/analysis/stubmethods/stubmethods.go b/gopls/internal/lsp/analysis/stubmethods/stubmethods.go
--- a/gopls/internal/lsp/analysis/stubmethods/stubmethods.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/stubmethods/stubmethods.go	1969-12-31 16:00:00
@@ -1,404 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package stubmethods
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/token"
-	"go/types"
-	"strconv"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/internal/analysisinternal"
-	"golang.org/x/tools/internal/typesinternal"
-)
-
-const Doc = `stub methods analyzer
-
-This analyzer generates method stubs for concrete types
-in order to implement a target interface`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "stubmethods",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{inspect.Analyzer},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	for _, err := range pass.TypeErrors {
-		ifaceErr := strings.Contains(err.Msg, "missing method") || strings.HasPrefix(err.Msg, "cannot convert")
-		if !ifaceErr {
-			continue
-		}
-		var file *ast.File
-		for _, f := range pass.Files {
-			if f.Pos() <= err.Pos && err.Pos < f.End() {
-				file = f
-				break
-			}
-		}
-		if file == nil {
-			continue
-		}
-		// Get the end position of the error.
-		_, _, endPos, ok := typesinternal.ReadGo116ErrorData(err)
-		if !ok {
-			var buf bytes.Buffer
-			if err := format.Node(&buf, pass.Fset, file); err != nil {
-				continue
-			}
-			endPos = analysisinternal.TypeErrorEndPos(pass.Fset, buf.Bytes(), err.Pos)
-		}
-		path, _ := astutil.PathEnclosingInterval(file, err.Pos, endPos)
-		si := GetStubInfo(pass.TypesInfo, path, err.Pos)
-		if si == nil {
-			continue
-		}
-		qf := RelativeToFiles(si.Concrete.Obj().Pkg(), file, nil, nil)
-		pass.Report(analysis.Diagnostic{
-			Pos:     err.Pos,
-			End:     endPos,
-			Message: fmt.Sprintf("Implement %s", types.TypeString(si.Interface.Type(), qf)),
-		})
-	}
-	return nil, nil
-}
-
-// StubInfo represents a concrete type
-// that wants to stub out an interface type
-type StubInfo struct {
-	// Interface is the interface that the client wants to implement.
-	// When the interface is defined, the underlying object will be a TypeName.
-	// Note that we keep track of types.Object instead of types.Type in order
-	// to keep a reference to the declaring object's package and the ast file
-	// in the case where the concrete type file requires a new import that happens to be renamed
-	// in the interface file.
-	// TODO(marwan-at-work): implement interface literals.
-	Interface *types.TypeName
-	Concrete  *types.Named
-	Pointer   bool
-}
-
-// GetStubInfo determines whether the "missing method error"
-// can be used to deduced what the concrete and interface types are.
-func GetStubInfo(ti *types.Info, path []ast.Node, pos token.Pos) *StubInfo {
-	for _, n := range path {
-		switch n := n.(type) {
-		case *ast.ValueSpec:
-			return fromValueSpec(ti, n, pos)
-		case *ast.ReturnStmt:
-			// An error here may not indicate a real error the user should know about, but it may.
-			// Therefore, it would be best to log it out for debugging/reporting purposes instead of ignoring
-			// it. However, event.Log takes a context which is not passed via the analysis package.
-			// TODO(marwan-at-work): properly log this error.
-			si, _ := fromReturnStmt(ti, pos, path, n)
-			return si
-		case *ast.AssignStmt:
-			return fromAssignStmt(ti, n, pos)
-		case *ast.CallExpr:
-			// Note that some call expressions don't carry the interface type
-			// because they don't point to a function or method declaration elsewhere.
-			// For eaxmple, "var Interface = (*Concrete)(nil)". In that case, continue
-			// this loop to encounter other possibilities such as *ast.ValueSpec or others.
-			si := fromCallExpr(ti, pos, n)
-			if si != nil {
-				return si
-			}
-		}
-	}
-	return nil
-}
-
-// fromCallExpr tries to find an *ast.CallExpr's function declaration and
-// analyzes a function call's signature against the passed in parameter to deduce
-// the concrete and interface types.
-func fromCallExpr(ti *types.Info, pos token.Pos, ce *ast.CallExpr) *StubInfo {
-	paramIdx := -1
-	for i, p := range ce.Args {
-		if pos >= p.Pos() && pos <= p.End() {
-			paramIdx = i
-			break
-		}
-	}
-	if paramIdx == -1 {
-		return nil
-	}
-	p := ce.Args[paramIdx]
-	concObj, pointer := concreteType(p, ti)
-	if concObj == nil || concObj.Obj().Pkg() == nil {
-		return nil
-	}
-	tv, ok := ti.Types[ce.Fun]
-	if !ok {
-		return nil
-	}
-	sig, ok := tv.Type.(*types.Signature)
-	if !ok {
-		return nil
-	}
-	sigVar := sig.Params().At(paramIdx)
-	iface := ifaceObjFromType(sigVar.Type())
-	if iface == nil {
-		return nil
-	}
-	return &StubInfo{
-		Concrete:  concObj,
-		Pointer:   pointer,
-		Interface: iface,
-	}
-}
-
-// fromReturnStmt analyzes a "return" statement to extract
-// a concrete type that is trying to be returned as an interface type.
-//
-// For example, func() io.Writer { return myType{} }
-// would return StubInfo with the interface being io.Writer and the concrete type being myType{}.
-func fromReturnStmt(ti *types.Info, pos token.Pos, path []ast.Node, rs *ast.ReturnStmt) (*StubInfo, error) {
-	returnIdx := -1
-	for i, r := range rs.Results {
-		if pos >= r.Pos() && pos <= r.End() {
-			returnIdx = i
-		}
-	}
-	if returnIdx == -1 {
-		return nil, fmt.Errorf("pos %d not within return statement bounds: [%d-%d]", pos, rs.Pos(), rs.End())
-	}
-	concObj, pointer := concreteType(rs.Results[returnIdx], ti)
-	if concObj == nil || concObj.Obj().Pkg() == nil {
-		return nil, nil
-	}
-	ef := enclosingFunction(path, ti)
-	if ef == nil {
-		return nil, fmt.Errorf("could not find the enclosing function of the return statement")
-	}
-	iface := ifaceType(ef.Results.List[returnIdx].Type, ti)
-	if iface == nil {
-		return nil, nil
-	}
-	return &StubInfo{
-		Concrete:  concObj,
-		Pointer:   pointer,
-		Interface: iface,
-	}, nil
-}
-
-// fromValueSpec returns *StubInfo from a variable declaration such as
-// var x io.Writer = &T{}
-func fromValueSpec(ti *types.Info, vs *ast.ValueSpec, pos token.Pos) *StubInfo {
-	var idx int
-	for i, vs := range vs.Values {
-		if pos >= vs.Pos() && pos <= vs.End() {
-			idx = i
-			break
-		}
-	}
-
-	valueNode := vs.Values[idx]
-	ifaceNode := vs.Type
-	callExp, ok := valueNode.(*ast.CallExpr)
-	// if the ValueSpec is `var _ = myInterface(...)`
-	// as opposed to `var _ myInterface = ...`
-	if ifaceNode == nil && ok && len(callExp.Args) == 1 {
-		ifaceNode = callExp.Fun
-		valueNode = callExp.Args[0]
-	}
-	concObj, pointer := concreteType(valueNode, ti)
-	if concObj == nil || concObj.Obj().Pkg() == nil {
-		return nil
-	}
-	ifaceObj := ifaceType(ifaceNode, ti)
-	if ifaceObj == nil {
-		return nil
-	}
-	return &StubInfo{
-		Concrete:  concObj,
-		Interface: ifaceObj,
-		Pointer:   pointer,
-	}
-}
-
-// fromAssignStmt returns *StubInfo from a variable re-assignment such as
-// var x io.Writer
-// x = &T{}
-func fromAssignStmt(ti *types.Info, as *ast.AssignStmt, pos token.Pos) *StubInfo {
-	idx := -1
-	var lhs, rhs ast.Expr
-	// Given a re-assignment interface conversion error,
-	// the compiler error shows up on the right hand side of the expression.
-	// For example, x = &T{} where x is io.Writer highlights the error
-	// under "&T{}" and not "x".
-	for i, hs := range as.Rhs {
-		if pos >= hs.Pos() && pos <= hs.End() {
-			idx = i
-			break
-		}
-	}
-	if idx == -1 {
-		return nil
-	}
-	// Technically, this should never happen as
-	// we would get a "cannot assign N values to M variables"
-	// before we get an interface conversion error. Nonetheless,
-	// guard against out of range index errors.
-	if idx >= len(as.Lhs) {
-		return nil
-	}
-	lhs, rhs = as.Lhs[idx], as.Rhs[idx]
-	ifaceObj := ifaceType(lhs, ti)
-	if ifaceObj == nil {
-		return nil
-	}
-	concType, pointer := concreteType(rhs, ti)
-	if concType == nil || concType.Obj().Pkg() == nil {
-		return nil
-	}
-	return &StubInfo{
-		Concrete:  concType,
-		Interface: ifaceObj,
-		Pointer:   pointer,
-	}
-}
-
-// RelativeToFiles returns a types.Qualifier that formats package
-// names according to the import environments of the files that define
-// the concrete type and the interface type. (Only the imports of the
-// latter file are provided.)
-//
-// This is similar to types.RelativeTo except if a file imports the package with a different name,
-// then it will use it. And if the file does import the package but it is ignored,
-// then it will return the original name. It also prefers package names in importEnv in case
-// an import is missing from concFile but is present among importEnv.
-//
-// Additionally, if missingImport is not nil, the function will be called whenever the concFile
-// is presented with a package that is not imported. This is useful so that as types.TypeString is
-// formatting a function signature, it is identifying packages that will need to be imported when
-// stubbing an interface.
-func RelativeToFiles(concPkg *types.Package, concFile *ast.File, ifaceImports []*ast.ImportSpec, missingImport func(name, path string)) types.Qualifier {
-	return func(other *types.Package) string {
-		if other == concPkg {
-			return ""
-		}
-
-		// Check if the concrete file already has the given import,
-		// if so return the default package name or the renamed import statement.
-		for _, imp := range concFile.Imports {
-			impPath, _ := strconv.Unquote(imp.Path.Value)
-			isIgnored := imp.Name != nil && (imp.Name.Name == "." || imp.Name.Name == "_")
-			// TODO(adonovan): this comparison disregards a vendor prefix in 'other'.
-			if impPath == other.Path() && !isIgnored {
-				importName := other.Name()
-				if imp.Name != nil {
-					importName = imp.Name.Name
-				}
-				return importName
-			}
-		}
-
-		// If the concrete file does not have the import, check if the package
-		// is renamed in the interface file and prefer that.
-		var importName string
-		for _, imp := range ifaceImports {
-			impPath, _ := strconv.Unquote(imp.Path.Value)
-			isIgnored := imp.Name != nil && (imp.Name.Name == "." || imp.Name.Name == "_")
-			// TODO(adonovan): this comparison disregards a vendor prefix in 'other'.
-			if impPath == other.Path() && !isIgnored {
-				if imp.Name != nil && imp.Name.Name != concPkg.Name() {
-					importName = imp.Name.Name
-				}
-				break
-			}
-		}
-
-		if missingImport != nil {
-			missingImport(importName, other.Path())
-		}
-
-		// Up until this point, importName must stay empty when calling missingImport,
-		// otherwise we'd end up with `import time "time"` which doesn't look idiomatic.
-		if importName == "" {
-			importName = other.Name()
-		}
-		return importName
-	}
-}
-
-// ifaceType will try to extract the types.Object that defines
-// the interface given the ast.Expr where the "missing method"
-// or "conversion" errors happen.
-func ifaceType(n ast.Expr, ti *types.Info) *types.TypeName {
-	tv, ok := ti.Types[n]
-	if !ok {
-		return nil
-	}
-	return ifaceObjFromType(tv.Type)
-}
-
-func ifaceObjFromType(t types.Type) *types.TypeName {
-	named, ok := t.(*types.Named)
-	if !ok {
-		return nil
-	}
-	_, ok = named.Underlying().(*types.Interface)
-	if !ok {
-		return nil
-	}
-	// Interfaces defined in the "builtin" package return nil a Pkg().
-	// But they are still real interfaces that we need to make a special case for.
-	// Therefore, protect gopls from panicking if a new interface type was added in the future.
-	if named.Obj().Pkg() == nil && named.Obj().Name() != "error" {
-		return nil
-	}
-	return named.Obj()
-}
-
-// concreteType tries to extract the *types.Named that defines
-// the concrete type given the ast.Expr where the "missing method"
-// or "conversion" errors happened. If the concrete type is something
-// that cannot have methods defined on it (such as basic types), this
-// method will return a nil *types.Named. The second return parameter
-// is a boolean that indicates whether the concreteType was defined as a
-// pointer or value.
-func concreteType(n ast.Expr, ti *types.Info) (*types.Named, bool) {
-	tv, ok := ti.Types[n]
-	if !ok {
-		return nil, false
-	}
-	typ := tv.Type
-	ptr, isPtr := typ.(*types.Pointer)
-	if isPtr {
-		typ = ptr.Elem()
-	}
-	named, ok := typ.(*types.Named)
-	if !ok {
-		return nil, false
-	}
-	return named, isPtr
-}
-
-// enclosingFunction returns the signature and type of the function
-// enclosing the given position.
-func enclosingFunction(path []ast.Node, info *types.Info) *ast.FuncType {
-	for _, node := range path {
-		switch t := node.(type) {
-		case *ast.FuncDecl:
-			if _, ok := info.Defs[t.Name]; ok {
-				return t.Type
-			}
-		case *ast.FuncLit:
-			if _, ok := info.Types[t]; ok {
-				return t.Type
-			}
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/a.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func x() int {
-	var z int
-	z = y // want "(undeclared name|undefined): y"
-
-	if z == m { // want "(undeclared name|undefined): m"
-		z = 1
-	}
-
-	if z == 1 {
-		z = 1
-	} else if z == n+1 { // want "(undeclared name|undefined): n"
-		z = 1
-	}
-
-	switch z {
-	case 10:
-		z = 1
-	case a: // want "(undeclared name|undefined): a"
-		z = 1
-	}
-	return z
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/channels.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/channels.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/channels.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/channels.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func channels(s string) {
-	undefinedChannels(c()) // want "(undeclared name|undefined): undefinedChannels"
-}
-
-func c() (<-chan string, chan string) {
-	return make(<-chan string), make(chan string)
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/consecutive_params.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/consecutive_params.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/consecutive_params.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/consecutive_params.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func consecutiveParams() {
-	var s string
-	undefinedConsecutiveParams(s, s) // want "(undeclared name|undefined): undefinedConsecutiveParams"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/error_param.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/error_param.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/error_param.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/error_param.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func errorParam() {
-	var err error
-	undefinedErrorParam(err) // want "(undeclared name|undefined): undefinedErrorParam"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/literals.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/literals.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/literals.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/literals.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-type T struct{}
-
-func literals() {
-	undefinedLiterals("hey compiler", T{}, &T{}) // want "(undeclared name|undefined): undefinedLiterals"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/operation.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/operation.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/operation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/operation.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-import "time"
-
-func operation() {
-	undefinedOperation(10 * time.Second) // want "(undeclared name|undefined): undefinedOperation"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/selector.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/selector.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/selector.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/selector.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func selector() {
-	m := map[int]bool{}
-	undefinedSelector(m[1]) // want "(undeclared name|undefined): undefinedSelector"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/slice.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/slice.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/slice.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/slice.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func slice() {
-	undefinedSlice([]int{1, 2}) // want "(undeclared name|undefined): undefinedSlice"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/tuple.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/tuple.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/tuple.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/tuple.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func tuple() {
-	undefinedTuple(b()) // want "(undeclared name|undefined): undefinedTuple"
-}
-
-func b() (string, error) {
-	return "", nil
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/unique_params.go b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/unique_params.go
--- a/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/unique_params.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/testdata/src/a/unique_params.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclared
-
-func uniqueArguments() {
-	var s string
-	var i int
-	undefinedUniqueArguments(s, i, s) // want "(undeclared name|undefined): undefinedUniqueArguments"
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/undeclared.go b/gopls/internal/lsp/analysis/undeclaredname/undeclared.go
--- a/gopls/internal/lsp/analysis/undeclaredname/undeclared.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/undeclared.go	1969-12-31 16:00:00
@@ -1,348 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package undeclaredname defines an Analyzer that applies suggested fixes
-// to errors of the type "undeclared name: %s".
-package undeclaredname
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/token"
-	"go/types"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/analysisinternal"
-)
-
-const Doc = `suggested fixes for "undeclared name: <>"
-
-This checker provides suggested fixes for type errors of the
-type "undeclared name: <>". It will either insert a new statement,
-such as:
-
-"<> := "
-
-or a new function declaration, such as:
-
-func <>(inferred parameters) {
-	panic("implement me!")
-}
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "undeclaredname",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{},
-	Run:              run,
-	RunDespiteErrors: true,
-}
-
-// The prefix for this error message changed in Go 1.20.
-var undeclaredNamePrefixes = []string{"undeclared name: ", "undefined: "}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	for _, err := range pass.TypeErrors {
-		runForError(pass, err)
-	}
-	return nil, nil
-}
-
-func runForError(pass *analysis.Pass, err types.Error) {
-	var name string
-	for _, prefix := range undeclaredNamePrefixes {
-		if !strings.HasPrefix(err.Msg, prefix) {
-			continue
-		}
-		name = strings.TrimPrefix(err.Msg, prefix)
-	}
-	if name == "" {
-		return
-	}
-	var file *ast.File
-	for _, f := range pass.Files {
-		if f.Pos() <= err.Pos && err.Pos < f.End() {
-			file = f
-			break
-		}
-	}
-	if file == nil {
-		return
-	}
-
-	// Get the path for the relevant range.
-	path, _ := astutil.PathEnclosingInterval(file, err.Pos, err.Pos)
-	if len(path) < 2 {
-		return
-	}
-	ident, ok := path[0].(*ast.Ident)
-	if !ok || ident.Name != name {
-		return
-	}
-
-	// Undeclared quick fixes only work in function bodies.
-	inFunc := false
-	for i := range path {
-		if _, inFunc = path[i].(*ast.FuncDecl); inFunc {
-			if i == 0 {
-				return
-			}
-			if _, isBody := path[i-1].(*ast.BlockStmt); !isBody {
-				return
-			}
-			break
-		}
-	}
-	if !inFunc {
-		return
-	}
-	// Skip selector expressions because it might be too complex
-	// to try and provide a suggested fix for fields and methods.
-	if _, ok := path[1].(*ast.SelectorExpr); ok {
-		return
-	}
-	tok := pass.Fset.File(file.Pos())
-	if tok == nil {
-		return
-	}
-	offset := safetoken.StartPosition(pass.Fset, err.Pos).Offset
-	end := tok.Pos(offset + len(name)) // TODO(adonovan): dubious! err.Pos + len(name)??
-	pass.Report(analysis.Diagnostic{
-		Pos:     err.Pos,
-		End:     end,
-		Message: err.Msg,
-	})
-}
-
-func SuggestedFix(fset *token.FileSet, rng span.Range, content []byte, file *ast.File, pkg *types.Package, info *types.Info) (*analysis.SuggestedFix, error) {
-	pos := rng.Start // don't use the end
-	path, _ := astutil.PathEnclosingInterval(file, pos, pos)
-	if len(path) < 2 {
-		return nil, fmt.Errorf("no expression found")
-	}
-	ident, ok := path[0].(*ast.Ident)
-	if !ok {
-		return nil, fmt.Errorf("no identifier found")
-	}
-
-	// Check for a possible call expression, in which case we should add a
-	// new function declaration.
-	if len(path) > 1 {
-		if _, ok := path[1].(*ast.CallExpr); ok {
-			return newFunctionDeclaration(path, file, pkg, info, fset)
-		}
-	}
-
-	// Get the place to insert the new statement.
-	insertBeforeStmt := analysisinternal.StmtToInsertVarBefore(path)
-	if insertBeforeStmt == nil {
-		return nil, fmt.Errorf("could not locate insertion point")
-	}
-
-	insertBefore := safetoken.StartPosition(fset, insertBeforeStmt.Pos()).Offset
-
-	// Get the indent to add on the line after the new statement.
-	// Since this will have a parse error, we can not use format.Source().
-	contentBeforeStmt, indent := content[:insertBefore], "\n"
-	if nl := bytes.LastIndex(contentBeforeStmt, []byte("\n")); nl != -1 {
-		indent = string(contentBeforeStmt[nl:])
-	}
-
-	// Create the new local variable statement.
-	newStmt := fmt.Sprintf("%s := %s", ident.Name, indent)
-	return &analysis.SuggestedFix{
-		Message: fmt.Sprintf("Create variable \"%s\"", ident.Name),
-		TextEdits: []analysis.TextEdit{{
-			Pos:     insertBeforeStmt.Pos(),
-			End:     insertBeforeStmt.Pos(),
-			NewText: []byte(newStmt),
-		}},
-	}, nil
-}
-
-func newFunctionDeclaration(path []ast.Node, file *ast.File, pkg *types.Package, info *types.Info, fset *token.FileSet) (*analysis.SuggestedFix, error) {
-	if len(path) < 3 {
-		return nil, fmt.Errorf("unexpected set of enclosing nodes: %v", path)
-	}
-	ident, ok := path[0].(*ast.Ident)
-	if !ok {
-		return nil, fmt.Errorf("no name for function declaration %v (%T)", path[0], path[0])
-	}
-	call, ok := path[1].(*ast.CallExpr)
-	if !ok {
-		return nil, fmt.Errorf("no call expression found %v (%T)", path[1], path[1])
-	}
-
-	// Find the enclosing function, so that we can add the new declaration
-	// below.
-	var enclosing *ast.FuncDecl
-	for _, n := range path {
-		if n, ok := n.(*ast.FuncDecl); ok {
-			enclosing = n
-			break
-		}
-	}
-	// TODO(rstambler): Support the situation when there is no enclosing
-	// function.
-	if enclosing == nil {
-		return nil, fmt.Errorf("no enclosing function found: %v", path)
-	}
-
-	pos := enclosing.End()
-
-	var paramNames []string
-	var paramTypes []types.Type
-	// keep track of all param names to later ensure uniqueness
-	nameCounts := map[string]int{}
-	for _, arg := range call.Args {
-		typ := info.TypeOf(arg)
-		if typ == nil {
-			return nil, fmt.Errorf("unable to determine type for %s", arg)
-		}
-
-		switch t := typ.(type) {
-		// this is the case where another function call returning multiple
-		// results is used as an argument
-		case *types.Tuple:
-			n := t.Len()
-			for i := 0; i < n; i++ {
-				name := typeToArgName(t.At(i).Type())
-				nameCounts[name]++
-
-				paramNames = append(paramNames, name)
-				paramTypes = append(paramTypes, types.Default(t.At(i).Type()))
-			}
-
-		default:
-			// does the argument have a name we can reuse?
-			// only happens in case of a *ast.Ident
-			var name string
-			if ident, ok := arg.(*ast.Ident); ok {
-				name = ident.Name
-			}
-
-			if name == "" {
-				name = typeToArgName(typ)
-			}
-
-			nameCounts[name]++
-
-			paramNames = append(paramNames, name)
-			paramTypes = append(paramTypes, types.Default(typ))
-		}
-	}
-
-	for n, c := range nameCounts {
-		// Any names we saw more than once will need a unique suffix added
-		// on. Reset the count to 1 to act as the suffix for the first
-		// occurrence of that name.
-		if c >= 2 {
-			nameCounts[n] = 1
-		} else {
-			delete(nameCounts, n)
-		}
-	}
-
-	params := &ast.FieldList{}
-
-	for i, name := range paramNames {
-		if suffix, repeats := nameCounts[name]; repeats {
-			nameCounts[name]++
-			name = fmt.Sprintf("%s%d", name, suffix)
-		}
-
-		// only worth checking after previous param in the list
-		if i > 0 {
-			// if type of parameter at hand is the same as the previous one,
-			// add it to the previous param list of identifiers so to have:
-			//  (s1, s2 string)
-			// and not
-			//  (s1 string, s2 string)
-			if paramTypes[i] == paramTypes[i-1] {
-				params.List[len(params.List)-1].Names = append(params.List[len(params.List)-1].Names, ast.NewIdent(name))
-				continue
-			}
-		}
-
-		params.List = append(params.List, &ast.Field{
-			Names: []*ast.Ident{
-				ast.NewIdent(name),
-			},
-			Type: analysisinternal.TypeExpr(file, pkg, paramTypes[i]),
-		})
-	}
-
-	decl := &ast.FuncDecl{
-		Name: ast.NewIdent(ident.Name),
-		Type: &ast.FuncType{
-			Params: params,
-			// TODO(rstambler): Also handle result parameters here.
-		},
-		Body: &ast.BlockStmt{
-			List: []ast.Stmt{
-				&ast.ExprStmt{
-					X: &ast.CallExpr{
-						Fun: ast.NewIdent("panic"),
-						Args: []ast.Expr{
-							&ast.BasicLit{
-								Value: `"unimplemented"`,
-							},
-						},
-					},
-				},
-			},
-		},
-	}
-
-	b := bytes.NewBufferString("\n\n")
-	if err := format.Node(b, fset, decl); err != nil {
-		return nil, err
-	}
-	return &analysis.SuggestedFix{
-		Message: fmt.Sprintf("Create function \"%s\"", ident.Name),
-		TextEdits: []analysis.TextEdit{{
-			Pos:     pos,
-			End:     pos,
-			NewText: b.Bytes(),
-		}},
-	}, nil
-}
-func typeToArgName(ty types.Type) string {
-	s := types.Default(ty).String()
-
-	switch t := ty.(type) {
-	case *types.Basic:
-		// use first letter in type name for basic types
-		return s[0:1]
-	case *types.Slice:
-		// use element type to decide var name for slices
-		return typeToArgName(t.Elem())
-	case *types.Array:
-		// use element type to decide var name for arrays
-		return typeToArgName(t.Elem())
-	case *types.Chan:
-		return "ch"
-	}
-
-	s = strings.TrimFunc(s, func(r rune) bool {
-		return !unicode.IsLetter(r)
-	})
-
-	if s == "error" {
-		return "err"
-	}
-
-	// remove package (if present)
-	// and make first letter lowercase
-	a := []rune(s[strings.LastIndexByte(s, '.')+1:])
-	a[0] = unicode.ToLower(a[0])
-	return string(a)
-}
diff -urN a/gopls/internal/lsp/analysis/undeclaredname/undeclared_test.go b/gopls/internal/lsp/analysis/undeclaredname/undeclared_test.go
--- a/gopls/internal/lsp/analysis/undeclaredname/undeclared_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/undeclaredname/undeclared_test.go	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package undeclaredname_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/undeclaredname"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	analysistest.Run(t, testdata, undeclaredname.Analyzer, "a")
-}
diff -urN a/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go b/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package a
-
-import (
-	"bytes"
-	"fmt"
-	"net/http"
-)
-
-type parent interface {
-	n(f bool)
-}
-
-type yuh struct {
-	a int
-}
-
-func (y *yuh) n(f bool) {
-	for i := 0; i < 10; i++ {
-		fmt.Println(i)
-	}
-}
-
-func a(i1 int, i2 int, i3 int) int { // want "potentially unused parameter: 'i2'"
-	i3 += i1
-	_ = func(z int) int { // want "potentially unused parameter: 'z'"
-		_ = 1
-		return 1
-	}
-	return i3
-}
-
-func b(c bytes.Buffer) { // want "potentially unused parameter: 'c'"
-	_ = 1
-}
-
-func z(h http.ResponseWriter, _ *http.Request) { // want "potentially unused parameter: 'h'"
-	fmt.Println("Before")
-}
-
-func l(h http.Handler) http.Handler {
-	return http.HandlerFunc(z)
-}
-
-func mult(a, b int) int { // want "potentially unused parameter: 'b'"
-	a += 1
-	return a
-}
-
-func y(a int) {
-	panic("yo")
-}
diff -urN a/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedparams/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package a
-
-import (
-	"bytes"
-	"fmt"
-	"net/http"
-)
-
-type parent interface {
-	n(f bool)
-}
-
-type yuh struct {
-	a int
-}
-
-func (y *yuh) n(f bool) {
-	for i := 0; i < 10; i++ {
-		fmt.Println(i)
-	}
-}
-
-func a(i1 int, _ int, i3 int) int { // want "potentially unused parameter: 'i2'"
-	i3 += i1
-	_ = func(_ int) int { // want "potentially unused parameter: 'z'"
-		_ = 1
-		return 1
-	}
-	return i3
-}
-
-func b(_ bytes.Buffer) { // want "potentially unused parameter: 'c'"
-	_ = 1
-}
-
-func z(_ http.ResponseWriter, _ *http.Request) { // want "potentially unused parameter: 'h'"
-	fmt.Println("Before")
-}
-
-func l(h http.Handler) http.Handler {
-	return http.HandlerFunc(z)
-}
-
-func mult(a, _ int) int { // want "potentially unused parameter: 'b'"
-	a += 1
-	return a
-}
-
-func y(a int) {
-	panic("yo")
-}
diff -urN a/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go b/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go
--- a/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package typeparams
-
-import (
-	"bytes"
-	"fmt"
-	"net/http"
-)
-
-type parent[T any] interface {
-	n(f T)
-}
-
-type yuh[T any] struct {
-	a T
-}
-
-func (y *yuh[int]) n(f bool) {
-	for i := 0; i < 10; i++ {
-		fmt.Println(i)
-	}
-}
-
-func a[T comparable](i1 int, i2 T, i3 int) int { // want "potentially unused parameter: 'i2'"
-	i3 += i1
-	_ = func(z int) int { // want "potentially unused parameter: 'z'"
-		_ = 1
-		return 1
-	}
-	return i3
-}
-
-func b[T any](c bytes.Buffer) { // want "potentially unused parameter: 'c'"
-	_ = 1
-}
-
-func z[T http.ResponseWriter](h T, _ *http.Request) { // want "potentially unused parameter: 'h'"
-	fmt.Println("Before")
-}
-
-func l(h http.Handler) http.Handler {
-	return http.HandlerFunc(z[http.ResponseWriter])
-}
-
-func mult(a, b int) int { // want "potentially unused parameter: 'b'"
-	a += 1
-	return a
-}
-
-func y[T any](a T) {
-	panic("yo")
-}
diff -urN a/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go.golden b/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go.golden
--- a/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedparams/testdata/src/typeparams/typeparams.go.golden	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package typeparams
-
-import (
-	"bytes"
-	"fmt"
-	"net/http"
-)
-
-type parent[T any] interface {
-	n(f T)
-}
-
-type yuh[T any] struct {
-	a T
-}
-
-func (y *yuh[int]) n(f bool) {
-	for i := 0; i < 10; i++ {
-		fmt.Println(i)
-	}
-}
-
-func a[T comparable](i1 int, _ T, i3 int) int { // want "potentially unused parameter: 'i2'"
-	i3 += i1
-	_ = func(_ int) int { // want "potentially unused parameter: 'z'"
-		_ = 1
-		return 1
-	}
-	return i3
-}
-
-func b[T any](_ bytes.Buffer) { // want "potentially unused parameter: 'c'"
-	_ = 1
-}
-
-func z[T http.ResponseWriter](_ T, _ *http.Request) { // want "potentially unused parameter: 'h'"
-	fmt.Println("Before")
-}
-
-func l(h http.Handler) http.Handler {
-	return http.HandlerFunc(z[http.ResponseWriter])
-}
-
-func mult(a, _ int) int { // want "potentially unused parameter: 'b'"
-	a += 1
-	return a
-}
-
-func y[T any](a T) {
-	panic("yo")
-}
diff -urN a/gopls/internal/lsp/analysis/unusedparams/unusedparams.go b/gopls/internal/lsp/analysis/unusedparams/unusedparams.go
--- a/gopls/internal/lsp/analysis/unusedparams/unusedparams.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedparams/unusedparams.go	1969-12-31 16:00:00
@@ -1,152 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package unusedparams defines an analyzer that checks for unused
-// parameters of functions.
-package unusedparams
-
-import (
-	"fmt"
-	"go/ast"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-)
-
-const Doc = `check for unused parameters of functions
-
-The unusedparams analyzer checks functions to see if there are
-any parameters that are not being used.
-
-To reduce false positives it ignores:
-- methods
-- parameters that do not have a name or are underscored
-- functions in test files
-- functions with empty bodies or those with just a return stmt`
-
-var Analyzer = &analysis.Analyzer{
-	Name:     "unusedparams",
-	Doc:      Doc,
-	Requires: []*analysis.Analyzer{inspect.Analyzer},
-	Run:      run,
-}
-
-type paramData struct {
-	field  *ast.Field
-	ident  *ast.Ident
-	typObj types.Object
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-	nodeFilter := []ast.Node{
-		(*ast.FuncDecl)(nil),
-		(*ast.FuncLit)(nil),
-	}
-
-	inspect.Preorder(nodeFilter, func(n ast.Node) {
-		var fieldList *ast.FieldList
-		var body *ast.BlockStmt
-
-		// Get the fieldList and body from the function node.
-		switch f := n.(type) {
-		case *ast.FuncDecl:
-			fieldList, body = f.Type.Params, f.Body
-			// TODO(golang/go#36602): add better handling for methods, if we enable methods
-			// we will get false positives if a struct is potentially implementing
-			// an interface.
-			if f.Recv != nil {
-				return
-			}
-			// Ignore functions in _test.go files to reduce false positives.
-			if file := pass.Fset.File(n.Pos()); file != nil && strings.HasSuffix(file.Name(), "_test.go") {
-				return
-			}
-		case *ast.FuncLit:
-			fieldList, body = f.Type.Params, f.Body
-		}
-		// If there are no arguments or the function is empty, then return.
-		if fieldList.NumFields() == 0 || body == nil || len(body.List) == 0 {
-			return
-		}
-
-		switch expr := body.List[0].(type) {
-		case *ast.ReturnStmt:
-			// Ignore functions that only contain a return statement to reduce false positives.
-			return
-		case *ast.ExprStmt:
-			callExpr, ok := expr.X.(*ast.CallExpr)
-			if !ok || len(body.List) > 1 {
-				break
-			}
-			// Ignore functions that only contain a panic statement to reduce false positives.
-			if fun, ok := callExpr.Fun.(*ast.Ident); ok && fun.Name == "panic" {
-				return
-			}
-		}
-
-		// Get the useful data from each field.
-		params := make(map[string]*paramData)
-		unused := make(map[*paramData]bool)
-		for _, f := range fieldList.List {
-			for _, i := range f.Names {
-				if i.Name == "_" {
-					continue
-				}
-				params[i.Name] = &paramData{
-					field:  f,
-					ident:  i,
-					typObj: pass.TypesInfo.ObjectOf(i),
-				}
-				unused[params[i.Name]] = true
-			}
-		}
-
-		// Traverse through the body of the function and
-		// check to see which parameters are unused.
-		ast.Inspect(body, func(node ast.Node) bool {
-			n, ok := node.(*ast.Ident)
-			if !ok {
-				return true
-			}
-			param, ok := params[n.Name]
-			if !ok {
-				return false
-			}
-			if nObj := pass.TypesInfo.ObjectOf(n); nObj != param.typObj {
-				return false
-			}
-			delete(unused, param)
-			return false
-		})
-
-		// Create the reports for the unused parameters.
-		for u := range unused {
-			start, end := u.field.Pos(), u.field.End()
-			if len(u.field.Names) > 1 {
-				start, end = u.ident.Pos(), u.ident.End()
-			}
-			// TODO(golang/go#36602): Add suggested fixes to automatically
-			// remove the unused parameter from every use of this
-			// function.
-			pass.Report(analysis.Diagnostic{
-				Pos:     start,
-				End:     end,
-				Message: fmt.Sprintf("potentially unused parameter: '%s'", u.ident.Name),
-				SuggestedFixes: []analysis.SuggestedFix{{
-					Message: `Replace with "_"`,
-					TextEdits: []analysis.TextEdit{{
-						Pos:     u.ident.Pos(),
-						End:     u.ident.End(),
-						NewText: []byte("_"),
-					}},
-				}},
-			})
-		}
-	})
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/analysis/unusedparams/unusedparams_test.go b/gopls/internal/lsp/analysis/unusedparams/unusedparams_test.go
--- a/gopls/internal/lsp/analysis/unusedparams/unusedparams_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedparams/unusedparams_test.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package unusedparams_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/unusedparams"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-	tests := []string{"a"}
-	if typeparams.Enabled {
-		tests = append(tests, "typeparams")
-	}
-	analysistest.RunWithSuggestedFixes(t, testdata, unusedparams.Analyzer, tests...)
-}
diff -urN a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go
--- a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go	1969-12-31 16:00:00
@@ -1,74 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package a
-
-import (
-	"fmt"
-	"os"
-)
-
-type A struct {
-	b int
-}
-
-func singleAssignment() {
-	v := "s" // want `v declared (and|but) not used`
-
-	s := []int{ // want `s declared (and|but) not used`
-		1,
-		2,
-	}
-
-	a := func(s string) bool { // want `a declared (and|but) not used`
-		return false
-	}
-
-	if 1 == 1 {
-		s := "v" // want `s declared (and|but) not used`
-	}
-
-	panic("I should survive")
-}
-
-func noOtherStmtsInBlock() {
-	v := "s" // want `v declared (and|but) not used`
-}
-
-func partOfMultiAssignment() {
-	f, err := os.Open("file") // want `f declared (and|but) not used`
-	panic(err)
-}
-
-func sideEffects(cBool chan bool, cInt chan int) {
-	b := <-c            // want `b declared (and|but) not used`
-	s := fmt.Sprint("") // want `s declared (and|but) not used`
-	a := A{             // want `a declared (and|but) not used`
-		b: func() int {
-			return 1
-		}(),
-	}
-	c := A{<-cInt}          // want `c declared (and|but) not used`
-	d := fInt() + <-cInt    // want `d declared (and|but) not used`
-	e := fBool() && <-cBool // want `e declared (and|but) not used`
-	f := map[int]int{       // want `f declared (and|but) not used`
-		fInt(): <-cInt,
-	}
-	g := []int{<-cInt}       // want `g declared (and|but) not used`
-	h := func(s string) {}   // want `h declared (and|but) not used`
-	i := func(s string) {}() // want `i declared (and|but) not used`
-}
-
-func commentAbove() {
-	// v is a variable
-	v := "s" // want `v declared (and|but) not used`
-}
-
-func fBool() bool {
-	return true
-}
-
-func fInt() int {
-	return 1
-}
diff -urN a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go.golden b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go.golden
--- a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/assign/a.go.golden	1969-12-31 16:00:00
@@ -1,59 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package a
-
-import (
-	"fmt"
-	"os"
-)
-
-type A struct {
-	b int
-}
-
-func singleAssignment() {
-	if 1 == 1 {
-	}
-
-	panic("I should survive")
-}
-
-func noOtherStmtsInBlock() {
-}
-
-func partOfMultiAssignment() {
-	_, err := os.Open("file") // want `f declared (and|but) not used`
-	panic(err)
-}
-
-func sideEffects(cBool chan bool, cInt chan int) {
-	<-c            // want `b declared (and|but) not used`
-	fmt.Sprint("") // want `s declared (and|but) not used`
-	A{             // want `a declared (and|but) not used`
-		b: func() int {
-			return 1
-		}(),
-	}
-	A{<-cInt}          // want `c declared (and|but) not used`
-	fInt() + <-cInt    // want `d declared (and|but) not used`
-	fBool() && <-cBool // want `e declared (and|but) not used`
-	map[int]int{       // want `f declared (and|but) not used`
-		fInt(): <-cInt,
-	}
-	[]int{<-cInt}       // want `g declared (and|but) not used`
-	func(s string) {}() // want `i declared (and|but) not used`
-}
-
-func commentAbove() {
-	// v is a variable
-}
-
-func fBool() bool {
-	return true
-}
-
-func fInt() int {
-	return 1
-}
diff -urN a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go
--- a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package decl
-
-func a() {
-	var b, c bool // want `b declared (and|but) not used`
-	panic(c)
-
-	if 1 == 1 {
-		var s string // want `s declared (and|but) not used`
-	}
-}
-
-func b() {
-	// b is a variable
-	var b bool // want `b declared (and|but) not used`
-}
-
-func c() {
-	var (
-		d string
-
-		// some comment for c
-		c bool // want `c declared (and|but) not used`
-	)
-
-	panic(d)
-}
diff -urN a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go.golden b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go.golden
--- a/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedvariable/testdata/src/decl/a.go.golden	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package decl
-
-func a() {
-	var c bool // want `b declared (and|but) not used`
-	panic(c)
-
-	if 1 == 1 {
-	}
-}
-
-func b() {
-	// b is a variable
-}
-
-func c() {
-	var (
-		d string
-	)
-	panic(d)
-}
diff -urN a/gopls/internal/lsp/analysis/unusedvariable/unusedvariable.go b/gopls/internal/lsp/analysis/unusedvariable/unusedvariable.go
--- a/gopls/internal/lsp/analysis/unusedvariable/unusedvariable.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedvariable/unusedvariable.go	1969-12-31 16:00:00
@@ -1,300 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package unusedvariable defines an analyzer that checks for unused variables.
-package unusedvariable
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/token"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/ast/astutil"
-)
-
-const Doc = `check for unused variables
-
-The unusedvariable analyzer suggests fixes for unused variables errors.
-`
-
-var Analyzer = &analysis.Analyzer{
-	Name:             "unusedvariable",
-	Doc:              Doc,
-	Requires:         []*analysis.Analyzer{},
-	Run:              run,
-	RunDespiteErrors: true, // an unusedvariable diagnostic is a compile error
-}
-
-// The suffix for this error message changed in Go 1.20.
-var unusedVariableSuffixes = []string{" declared and not used", " declared but not used"}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	for _, typeErr := range pass.TypeErrors {
-		for _, suffix := range unusedVariableSuffixes {
-			if strings.HasSuffix(typeErr.Msg, suffix) {
-				varName := strings.TrimSuffix(typeErr.Msg, suffix)
-				err := runForError(pass, typeErr, varName)
-				if err != nil {
-					return nil, err
-				}
-			}
-		}
-	}
-
-	return nil, nil
-}
-
-func runForError(pass *analysis.Pass, err types.Error, name string) error {
-	var file *ast.File
-	for _, f := range pass.Files {
-		if f.Pos() <= err.Pos && err.Pos < f.End() {
-			file = f
-			break
-		}
-	}
-	if file == nil {
-		return nil
-	}
-
-	path, _ := astutil.PathEnclosingInterval(file, err.Pos, err.Pos)
-	if len(path) < 2 {
-		return nil
-	}
-
-	ident, ok := path[0].(*ast.Ident)
-	if !ok || ident.Name != name {
-		return nil
-	}
-
-	diag := analysis.Diagnostic{
-		Pos:     ident.Pos(),
-		End:     ident.End(),
-		Message: err.Msg,
-	}
-
-	for i := range path {
-		switch stmt := path[i].(type) {
-		case *ast.ValueSpec:
-			// Find GenDecl to which offending ValueSpec belongs.
-			if decl, ok := path[i+1].(*ast.GenDecl); ok {
-				fixes := removeVariableFromSpec(pass, path, stmt, decl, ident)
-				// fixes may be nil
-				if len(fixes) > 0 {
-					diag.SuggestedFixes = fixes
-					pass.Report(diag)
-				}
-			}
-
-		case *ast.AssignStmt:
-			if stmt.Tok != token.DEFINE {
-				continue
-			}
-
-			containsIdent := false
-			for _, expr := range stmt.Lhs {
-				if expr == ident {
-					containsIdent = true
-				}
-			}
-			if !containsIdent {
-				continue
-			}
-
-			fixes := removeVariableFromAssignment(pass, path, stmt, ident)
-			// fixes may be nil
-			if len(fixes) > 0 {
-				diag.SuggestedFixes = fixes
-				pass.Report(diag)
-			}
-		}
-	}
-
-	return nil
-}
-
-func removeVariableFromSpec(pass *analysis.Pass, path []ast.Node, stmt *ast.ValueSpec, decl *ast.GenDecl, ident *ast.Ident) []analysis.SuggestedFix {
-	newDecl := new(ast.GenDecl)
-	*newDecl = *decl
-	newDecl.Specs = nil
-
-	for _, spec := range decl.Specs {
-		if spec != stmt {
-			newDecl.Specs = append(newDecl.Specs, spec)
-			continue
-		}
-
-		newSpec := new(ast.ValueSpec)
-		*newSpec = *stmt
-		newSpec.Names = nil
-
-		for _, n := range stmt.Names {
-			if n != ident {
-				newSpec.Names = append(newSpec.Names, n)
-			}
-		}
-
-		if len(newSpec.Names) > 0 {
-			newDecl.Specs = append(newDecl.Specs, newSpec)
-		}
-	}
-
-	// decl.End() does not include any comments, so if a comment is present we
-	// need to account for it when we delete the statement
-	end := decl.End()
-	if stmt.Comment != nil && stmt.Comment.End() > end {
-		end = stmt.Comment.End()
-	}
-
-	// There are no other specs left in the declaration, the whole statement can
-	// be deleted
-	if len(newDecl.Specs) == 0 {
-		// Find parent DeclStmt and delete it
-		for _, node := range path {
-			if declStmt, ok := node.(*ast.DeclStmt); ok {
-				return []analysis.SuggestedFix{
-					{
-						Message:   suggestedFixMessage(ident.Name),
-						TextEdits: deleteStmtFromBlock(path, declStmt),
-					},
-				}
-			}
-		}
-	}
-
-	var b bytes.Buffer
-	if err := format.Node(&b, pass.Fset, newDecl); err != nil {
-		return nil
-	}
-
-	return []analysis.SuggestedFix{
-		{
-			Message: suggestedFixMessage(ident.Name),
-			TextEdits: []analysis.TextEdit{
-				{
-					Pos: decl.Pos(),
-					// Avoid adding a new empty line
-					End:     end + 1,
-					NewText: b.Bytes(),
-				},
-			},
-		},
-	}
-}
-
-func removeVariableFromAssignment(pass *analysis.Pass, path []ast.Node, stmt *ast.AssignStmt, ident *ast.Ident) []analysis.SuggestedFix {
-	// The only variable in the assignment is unused
-	if len(stmt.Lhs) == 1 {
-		// If LHS has only one expression to be valid it has to have 1 expression
-		// on RHS
-		//
-		// RHS may have side effects, preserve RHS
-		if exprMayHaveSideEffects(stmt.Rhs[0]) {
-			// Delete until RHS
-			return []analysis.SuggestedFix{
-				{
-					Message: suggestedFixMessage(ident.Name),
-					TextEdits: []analysis.TextEdit{
-						{
-							Pos: ident.Pos(),
-							End: stmt.Rhs[0].Pos(),
-						},
-					},
-				},
-			}
-		}
-
-		// RHS does not have any side effects, delete the whole statement
-		return []analysis.SuggestedFix{
-			{
-				Message:   suggestedFixMessage(ident.Name),
-				TextEdits: deleteStmtFromBlock(path, stmt),
-			},
-		}
-	}
-
-	// Otherwise replace ident with `_`
-	return []analysis.SuggestedFix{
-		{
-			Message: suggestedFixMessage(ident.Name),
-			TextEdits: []analysis.TextEdit{
-				{
-					Pos:     ident.Pos(),
-					End:     ident.End(),
-					NewText: []byte("_"),
-				},
-			},
-		},
-	}
-}
-
-func suggestedFixMessage(name string) string {
-	return fmt.Sprintf("Remove variable %s", name)
-}
-
-func deleteStmtFromBlock(path []ast.Node, stmt ast.Stmt) []analysis.TextEdit {
-	// Find innermost enclosing BlockStmt.
-	var block *ast.BlockStmt
-	for i := range path {
-		if blockStmt, ok := path[i].(*ast.BlockStmt); ok {
-			block = blockStmt
-			break
-		}
-	}
-
-	nodeIndex := -1
-	for i, blockStmt := range block.List {
-		if blockStmt == stmt {
-			nodeIndex = i
-			break
-		}
-	}
-
-	// The statement we need to delete was not found in BlockStmt
-	if nodeIndex == -1 {
-		return nil
-	}
-
-	// Delete until the end of the block unless there is another statement after
-	// the one we are trying to delete
-	end := block.Rbrace
-	if nodeIndex < len(block.List)-1 {
-		end = block.List[nodeIndex+1].Pos()
-	}
-
-	return []analysis.TextEdit{
-		{
-			Pos: stmt.Pos(),
-			End: end,
-		},
-	}
-}
-
-// exprMayHaveSideEffects reports whether the expression may have side effects
-// (because it contains a function call or channel receive). We disregard
-// runtime panics as well written programs should not encounter them.
-func exprMayHaveSideEffects(expr ast.Expr) bool {
-	var mayHaveSideEffects bool
-	ast.Inspect(expr, func(n ast.Node) bool {
-		switch n := n.(type) {
-		case *ast.CallExpr: // possible function call
-			mayHaveSideEffects = true
-			return false
-		case *ast.UnaryExpr:
-			if n.Op == token.ARROW { // channel receive
-				mayHaveSideEffects = true
-				return false
-			}
-		case *ast.FuncLit:
-			return false // evaluating what's inside a FuncLit has no effect
-		}
-		return true
-	})
-
-	return mayHaveSideEffects
-}
diff -urN a/gopls/internal/lsp/analysis/unusedvariable/unusedvariable_test.go b/gopls/internal/lsp/analysis/unusedvariable/unusedvariable_test.go
--- a/gopls/internal/lsp/analysis/unusedvariable/unusedvariable_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/unusedvariable/unusedvariable_test.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package unusedvariable_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/unusedvariable"
-)
-
-func Test(t *testing.T) {
-	testdata := analysistest.TestData()
-
-	t.Run("decl", func(t *testing.T) {
-		analysistest.RunWithSuggestedFixes(t, testdata, unusedvariable.Analyzer, "decl")
-	})
-
-	t.Run("assign", func(t *testing.T) {
-		analysistest.RunWithSuggestedFixes(t, testdata, unusedvariable.Analyzer, "assign")
-	})
-}
diff -urN a/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go b/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go
--- a/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// This file contains tests for the useany checker.
-
-package a
-
-type Any interface{}
-
-func _[T interface{}]()                    {} // want "could use \"any\" for this empty interface"
-func _[X any, T interface{}]()             {} // want "could use \"any\" for this empty interface"
-func _[any interface{}]()                  {} // want "could use \"any\" for this empty interface"
-func _[T Any]()                            {} // want "could use \"any\" for this empty interface"
-func _[T interface{ int | interface{} }]() {} // want "could use \"any\" for this empty interface"
-func _[T interface{ int | Any }]()         {} // want "could use \"any\" for this empty interface"
-func _[T any]()                            {}
-
-type _[T interface{}] int                    // want "could use \"any\" for this empty interface"
-type _[X any, T interface{}] int             // want "could use \"any\" for this empty interface"
-type _[any interface{}] int                  // want "could use \"any\" for this empty interface"
-type _[T Any] int                            // want "could use \"any\" for this empty interface"
-type _[T interface{ int | interface{} }] int // want "could use \"any\" for this empty interface"
-type _[T interface{ int | Any }] int         // want "could use \"any\" for this empty interface"
-type _[T any] int
diff -urN a/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go.golden b/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go.golden
--- a/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/useany/testdata/src/a/a.go.golden	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// This file contains tests for the useany checker.
-
-package a
-
-type Any interface{}
-
-func _[T any]()           {} // want "could use \"any\" for this empty interface"
-func _[X any, T any]()    {} // want "could use \"any\" for this empty interface"
-func _[any interface{}]() {} // want "could use \"any\" for this empty interface"
-func _[T any]()           {} // want "could use \"any\" for this empty interface"
-func _[T any]()           {} // want "could use \"any\" for this empty interface"
-func _[T any]()           {} // want "could use \"any\" for this empty interface"
-func _[T any]()           {}
-
-type _[T any] int           // want "could use \"any\" for this empty interface"
-type _[X any, T any] int    // want "could use \"any\" for this empty interface"
-type _[any interface{}] int // want "could use \"any\" for this empty interface"
-type _[T any] int           // want "could use \"any\" for this empty interface"
-type _[T any] int           // want "could use \"any\" for this empty interface"
-type _[T any] int           // want "could use \"any\" for this empty interface"
-type _[T any] int
diff -urN a/gopls/internal/lsp/analysis/useany/useany.go b/gopls/internal/lsp/analysis/useany/useany.go
--- a/gopls/internal/lsp/analysis/useany/useany.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/useany/useany.go	1969-12-31 16:00:00
@@ -1,102 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package useany defines an Analyzer that checks for usage of interface{} in
-// constraints, rather than the predeclared any.
-package useany
-
-import (
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/inspect"
-	"golang.org/x/tools/go/ast/inspector"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-const Doc = `check for constraints that could be simplified to "any"`
-
-var Analyzer = &analysis.Analyzer{
-	Name:     "useany",
-	Doc:      Doc,
-	Requires: []*analysis.Analyzer{inspect.Analyzer},
-	Run:      run,
-}
-
-func run(pass *analysis.Pass) (interface{}, error) {
-	inspect := pass.ResultOf[inspect.Analyzer].(*inspector.Inspector)
-
-	universeAny := types.Universe.Lookup("any")
-	if universeAny == nil {
-		// Go <= 1.17. Nothing to check.
-		return nil, nil
-	}
-
-	nodeFilter := []ast.Node{
-		(*ast.TypeSpec)(nil),
-		(*ast.FuncType)(nil),
-	}
-
-	inspect.Preorder(nodeFilter, func(node ast.Node) {
-		var tparams *ast.FieldList
-		switch node := node.(type) {
-		case *ast.TypeSpec:
-			tparams = typeparams.ForTypeSpec(node)
-		case *ast.FuncType:
-			tparams = typeparams.ForFuncType(node)
-		default:
-			panic(fmt.Sprintf("unexpected node type %T", node))
-		}
-		if tparams.NumFields() == 0 {
-			return
-		}
-
-		for _, field := range tparams.List {
-			typ := pass.TypesInfo.Types[field.Type].Type
-			if typ == nil {
-				continue // something is wrong, but not our concern
-			}
-			iface, ok := typ.Underlying().(*types.Interface)
-			if !ok {
-				continue // invalid constraint
-			}
-
-			// If the constraint is the empty interface, offer a fix to use 'any'
-			// instead.
-			if iface.Empty() {
-				id, _ := field.Type.(*ast.Ident)
-				if id != nil && pass.TypesInfo.Uses[id] == universeAny {
-					continue
-				}
-
-				diag := analysis.Diagnostic{
-					Pos:     field.Type.Pos(),
-					End:     field.Type.End(),
-					Message: `could use "any" for this empty interface`,
-				}
-
-				// Only suggest a fix to 'any' if we actually resolve the predeclared
-				// any in this scope.
-				if scope := pass.TypesInfo.Scopes[node]; scope != nil {
-					if _, any := scope.LookupParent("any", token.NoPos); any == universeAny {
-						diag.SuggestedFixes = []analysis.SuggestedFix{{
-							Message: `use "any"`,
-							TextEdits: []analysis.TextEdit{{
-								Pos:     field.Type.Pos(),
-								End:     field.Type.End(),
-								NewText: []byte("any"),
-							}},
-						}}
-					}
-				}
-
-				pass.Report(diag)
-			}
-		}
-	})
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/analysis/useany/useany_test.go b/gopls/internal/lsp/analysis/useany/useany_test.go
--- a/gopls/internal/lsp/analysis/useany/useany_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/analysis/useany/useany_test.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package useany_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/go/analysis/analysistest"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/useany"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func Test(t *testing.T) {
-	if !typeparams.Enabled {
-		t.Skip("type params are not enabled")
-	}
-	testdata := analysistest.TestData()
-	analysistest.RunWithSuggestedFixes(t, testdata, useany.Analyzer, "a")
-}
diff -urN a/gopls/internal/lsp/browser/README.md b/gopls/internal/lsp/browser/README.md
--- a/gopls/internal/lsp/browser/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/browser/README.md	1969-12-31 16:00:00
@@ -1 +0,0 @@
-This package is a copy of cmd/internal/browser from the go distribution
\ No newline at end of file
diff -urN a/gopls/internal/lsp/browser/browser.go b/gopls/internal/lsp/browser/browser.go
--- a/gopls/internal/lsp/browser/browser.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/browser/browser.go	1969-12-31 16:00:00
@@ -1,67 +0,0 @@
-// Copyright 2016 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package browser provides utilities for interacting with users' browsers.
-package browser
-
-import (
-	exec "golang.org/x/sys/execabs"
-	"os"
-	"runtime"
-	"time"
-)
-
-// Commands returns a list of possible commands to use to open a url.
-func Commands() [][]string {
-	var cmds [][]string
-	if exe := os.Getenv("BROWSER"); exe != "" {
-		cmds = append(cmds, []string{exe})
-	}
-	switch runtime.GOOS {
-	case "darwin":
-		cmds = append(cmds, []string{"/usr/bin/open"})
-	case "windows":
-		cmds = append(cmds, []string{"cmd", "/c", "start"})
-	default:
-		if os.Getenv("DISPLAY") != "" {
-			// xdg-open is only for use in a desktop environment.
-			cmds = append(cmds, []string{"xdg-open"})
-		}
-	}
-	cmds = append(cmds,
-		[]string{"chrome"},
-		[]string{"google-chrome"},
-		[]string{"chromium"},
-		[]string{"firefox"},
-	)
-	return cmds
-}
-
-// Open tries to open url in a browser and reports whether it succeeded.
-func Open(url string) bool {
-	for _, args := range Commands() {
-		cmd := exec.Command(args[0], append(args[1:], url)...)
-		if cmd.Start() == nil && appearsSuccessful(cmd, 3*time.Second) {
-			return true
-		}
-	}
-	return false
-}
-
-// appearsSuccessful reports whether the command appears to have run successfully.
-// If the command runs longer than the timeout, it's deemed successful.
-// If the command runs within the timeout, it's deemed successful if it exited cleanly.
-func appearsSuccessful(cmd *exec.Cmd, timeout time.Duration) bool {
-	errc := make(chan error, 1)
-	go func() {
-		errc <- cmd.Wait()
-	}()
-
-	select {
-	case <-time.After(timeout):
-		return true
-	case err := <-errc:
-		return err == nil
-	}
-}
diff -urN a/gopls/internal/lsp/cache/analysis.go b/gopls/internal/lsp/cache/analysis.go
--- a/gopls/internal/lsp/cache/analysis.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/analysis.go	1969-12-31 16:00:00
@@ -1,1235 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-// This file defines gopls' driver for modular static analysis (go/analysis).
-
-import (
-	"bytes"
-	"context"
-	"crypto/sha256"
-	"encoding/gob"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"log"
-	"reflect"
-	"runtime/debug"
-	"sort"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/sync/errgroup"
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/gopls/internal/lsp/filecache"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/facts"
-	"golang.org/x/tools/internal/gcimporter"
-	"golang.org/x/tools/internal/memoize"
-	"golang.org/x/tools/internal/typeparams"
-	"golang.org/x/tools/internal/typesinternal"
-)
-
-/*
-
-   DESIGN
-
-   An analysis request is for a set of analyzers and an individual
-   package ID, notated (a*, p). The result is the set of diagnostics
-   for that package. It could easily be generalized to a set of
-   packages, (a*, p*), and perhaps should be, to improve performance
-   versus calling it in a loop.
-
-   The snapshot holds a cache (persistent.Map) of entries keyed by
-   (a*, p) pairs ("analysisKey") that have been requested so far. Some
-   of these entries may be invalidated during snapshot cloning after a
-   modification event.  The cache maps each (a*, p) to a promise of
-   the analysis result or "analysisSummary". The summary contains the
-   results of analysis (e.g. diagnostics) as well as the intermediate
-   results required by the recursion, such as serialized types and
-   facts.
-
-   The promise represents the result of a call to analyzeImpl, which
-   type-checks a package and then applies a graph of analyzers to it
-   in parallel postorder. (These graph edges are "horizontal": within
-   the same package.) First, analyzeImpl reads the source files of
-   package p, and obtains (recursively) the results of the "vertical"
-   dependencies (i.e. analyzers applied to the packages imported by
-   p). Only the subset of analyzers that use facts need be executed
-   recursively, but even if this subset is empty, the step is still
-   necessary because it provides type information. It is possible that
-   a package may need to be type-checked and analyzed twice, for
-   different subsets of analyzers, but the overlap is typically
-   insignificant.
-
-   With the file contents and the results of vertical dependencies,
-   analyzeImpl is then in a position to produce a key representing the
-   unit of work (parsing, type-checking, and analysis) that it has to
-   do. The key is a cryptographic hash of the "recipe" for this step,
-   including the Metadata, the file contents, the set of analyzers,
-   and the type and fact information from the vertical dependencies.
-
-   The key is sought in a machine-global persistent file-system based
-   cache. If this gopls process, or another gopls process on the same
-   machine, has already performed this analysis step, analyzeImpl will
-   make a cache hit and load the serialized summary of the results. If
-   not, it will have to proceed to type-checking and analysis, and
-   write a new cache entry. The entry contains serialized types
-   (export data) and analysis facts.
-
-   For types, we use "shallow" export data. Historically, the Go
-   compiler always produced a summary of the types for a given package
-   that included types from other packages that it indirectly
-   referenced: "deep" export data. This had the advantage that the
-   compiler (and analogous tools such as gopls) need only load one
-   file per direct import.  However, it meant that the files tended to
-   get larger based on the level of the package in the import
-   graph. For example, higher-level packages in the kubernetes module
-   have over 1MB of "deep" export data, even when they have almost no
-   content of their own, merely because they mention a major type that
-   references many others. In pathological cases the export data was
-   300x larger than the source for a package due to this quadratic
-   growth.
-
-   "Shallow" export data means that the serialized types describe only
-   a single package. If those types mention types from other packages,
-   the type checker may need to request additional packages beyond
-   just the direct imports. This means type information for the entire
-   transitive closure of imports may need to be available just in
-   case. After a cache hit or a cache miss, the summary is
-   postprocessed so that it contains the union of export data payloads
-   of all its direct dependencies.
-
-   For correct dependency analysis, the digest used as a cache key
-   must reflect the "deep" export data, so it is derived recursively
-   from the transitive closure. As an optimization, we needn't include
-   every package of the transitive closure in the deep hash, only the
-   packages that were actually requested by the type checker. This
-   allows changes to a package that have no effect on its export data
-   to be "pruned". The direct consumer will need to be re-executed,
-   but if its export data is unchanged as a result, then indirect
-   consumers may not need to be re-executed.  This allows, for example,
-   one to insert a print statement in a function and not "rebuild" the
-   whole application (though export data does record line numbers of
-   types which may be perturbed by otherwise insignificant changes.)
-
-   The summary must record whether a package is transitively
-   error-free (whether it would compile) because many analyzers are
-   not safe to run on packages with inconsistent types.
-
-   For fact encoding, we use the same fact set as the unitchecker
-   (vet) to record and serialize analysis facts. The fact
-   serialization mechanism is analogous to "deep" export data.
-
-*/
-
-// TODO(adonovan):
-// - Profile + optimize:
-//   - on a cold run, mostly type checking + export data, unsurprisingly.
-//   - on a hot-disk run, mostly type checking the IWL.
-//     Would be nice to have a benchmark that separates this out.
-//   - measure and record in the code the typical operation times
-//     and file sizes (export data + facts = cache entries).
-// - Do "port the old logic" tasks (see TODO in actuallyAnalyze).
-// - Add a (white-box) test of pruning when a change doesn't affect export data.
-// - Optimise pruning based on subset of packages mentioned in exportdata.
-// - Better logging so that it is possible to deduce why an analyzer
-//   is not being run--often due to very indirect failures.
-//   Even if the ultimate consumer decides to ignore errors,
-//   tests and other situations want to be assured of freedom from
-//   errors, not just missing results. This should be recorded.
-// - Check that the event trace is intelligible.
-// - Split this into a subpackage, gopls/internal/lsp/cache/driver,
-//   consisting of this file and three helpers from errors.go.
-//   The (*snapshot).Analyze method would stay behind and make calls
-//   to the driver package.
-//   Steps:
-//   - define a narrow driver.Snapshot interface with only these methods:
-//        Metadata(PackageID) source.Metadata
-//        GetFile(Context, URI) (source.FileHandle, error)
-//        View() *View // for Options
-//   - define a State type that encapsulates the persistent map
-//     (with its own mutex), and has methods:
-//        New() *State
-//        Clone(invalidate map[PackageID]bool) *State
-//        Destroy()
-//   - share cache.{goVersionRx,parseGoImpl}
-
-var born = time.Now()
-
-// Analyze applies a set of analyzers to the package denoted by id,
-// and returns their diagnostics for that package.
-//
-// The analyzers list must be duplicate free; order does not matter.
-//
-// Precondition: all analyzers within the process have distinct names.
-// (The names are relied on by the serialization logic.)
-func (s *snapshot) Analyze(ctx context.Context, id PackageID, analyzers []*source.Analyzer) ([]*source.Diagnostic, error) {
-	if false { // debugging
-		log.Println("Analyze@", time.Since(born)) // called after the 7s IWL in k8s
-	}
-
-	// Filter and sort enabled root analyzers.
-	// A disabled analyzer may still be run if required by another.
-	toSrc := make(map[*analysis.Analyzer]*source.Analyzer)
-	var enabled []*analysis.Analyzer
-	for _, a := range analyzers {
-		if a.IsEnabled(s.view.Options()) {
-			toSrc[a.Analyzer] = a
-			enabled = append(enabled, a.Analyzer)
-		}
-	}
-	sort.Slice(enabled, func(i, j int) bool {
-		return enabled[i].Name < enabled[j].Name
-	})
-
-	// Register fact types of required analyzers.
-	for _, a := range requiredAnalyzers(enabled) {
-		for _, f := range a.FactTypes {
-			gob.Register(f)
-		}
-	}
-
-	if false { // debugging
-		// TODO(adonovan): use proper tracing.
-		t0 := time.Now()
-		defer func() {
-			log.Printf("%v for analyze(%s, %s)", time.Since(t0), id, enabled)
-		}()
-	}
-
-	// Run the analysis.
-	res, err := s.analyze(ctx, id, enabled)
-	if err != nil {
-		return nil, err
-	}
-
-	// Report diagnostics only from enabled actions that succeeded.
-	// Errors from creating or analyzing packages are ignored.
-	// Diagnostics are reported in the order of the analyzers argument.
-	//
-	// TODO(adonovan): ignoring action errors gives the caller no way
-	// to distinguish "there are no problems in this code" from
-	// "the code (or analyzers!) are so broken that we couldn't even
-	// begin the analysis you asked for".
-	// Even if current callers choose to discard the
-	// results, we should propagate the per-action errors.
-	var results []*source.Diagnostic
-	for _, a := range enabled {
-		summary := res.Actions[a.Name]
-		if summary.Err != "" {
-			continue // action failed
-		}
-		for _, gobDiag := range summary.Diagnostics {
-			results = append(results, toSourceDiagnostic(toSrc[a], &gobDiag))
-		}
-	}
-	return results, nil
-}
-
-// analysisKey is the type of keys in the snapshot.analyses map.
-type analysisKey struct {
-	analyzerNames string
-	pkgid         PackageID
-}
-
-func (key analysisKey) String() string {
-	return fmt.Sprintf("%s@%s", key.analyzerNames, key.pkgid)
-}
-
-// analyzeSummary is a gob-serializable summary of successfully
-// applying a list of analyzers to a package.
-type analyzeSummary struct {
-	PkgPath        PackagePath // types.Package.Path() (needed to decode export data)
-	Export         []byte
-	DeepExportHash source.Hash // hash of reflexive transitive closure of export data
-	Compiles       bool        // transitively free of list/parse/type errors
-	Actions        actionsMap  // map from analyzer name to analysis results (*actionSummary)
-
-	// Not serialized: populated after the summary is computed or deserialized.
-	allExport map[PackagePath][]byte // transitive export data
-}
-
-// actionsMap defines a stable Gob encoding for a map.
-// TODO(adonovan): generalize and move to a library when we can use generics.
-type actionsMap map[string]*actionSummary
-
-var _ gob.GobEncoder = (actionsMap)(nil)
-var _ gob.GobDecoder = (*actionsMap)(nil)
-
-type actionsMapEntry struct {
-	K string
-	V *actionSummary
-}
-
-func (m actionsMap) GobEncode() ([]byte, error) {
-	entries := make([]actionsMapEntry, 0, len(m))
-	for k, v := range m {
-		entries = append(entries, actionsMapEntry{k, v})
-	}
-	sort.Slice(entries, func(i, j int) bool {
-		return entries[i].K < entries[j].K
-	})
-	var buf bytes.Buffer
-	err := gob.NewEncoder(&buf).Encode(entries)
-	return buf.Bytes(), err
-}
-
-func (m *actionsMap) GobDecode(data []byte) error {
-	var entries []actionsMapEntry
-	if err := gob.NewDecoder(bytes.NewReader(data)).Decode(&entries); err != nil {
-		return err
-	}
-	*m = make(actionsMap, len(entries))
-	for _, e := range entries {
-		(*m)[e.K] = e.V
-	}
-	return nil
-}
-
-// actionSummary is a gob-serializable summary of one possibly failed analysis action.
-// If Err is non-empty, the other fields are undefined.
-type actionSummary struct {
-	Facts       []byte      // the encoded facts.Set
-	FactsHash   source.Hash // hash(Facts)
-	Diagnostics []gobDiagnostic
-	Err         string // "" => success
-}
-
-// analyze is a memoization of analyzeImpl.
-func (s *snapshot) analyze(ctx context.Context, id PackageID, analyzers []*analysis.Analyzer) (*analyzeSummary, error) {
-	// Use the sorted list of names of analyzers in the key.
-	//
-	// TODO(adonovan): opt: account for analysis results at a
-	// finer grain to avoid duplicate work when a
-	// a proper subset of analyzers is requested?
-	// In particular, TypeErrorAnalyzers don't use facts
-	// but need to request vdeps just for type information.
-	names := make([]string, 0, len(analyzers))
-	for _, a := range analyzers {
-		names = append(names, a.Name)
-	}
-	// This key describes the result of applying a list of analyzers to a package.
-	key := analysisKey{strings.Join(names, ","), id}
-
-	// An analysisPromise represents the result of loading, parsing,
-	// type-checking and analyzing a single package.
-	type analysisPromise struct {
-		promise *memoize.Promise // [analyzeImplResult]
-	}
-
-	type analyzeImplResult struct {
-		summary *analyzeSummary
-		err     error
-	}
-
-	// Access the map once, briefly, and atomically.
-	s.mu.Lock()
-	entry, hit := s.analyses.Get(key)
-	if !hit {
-		entry = analysisPromise{
-			promise: memoize.NewPromise("analysis", func(ctx context.Context, arg interface{}) interface{} {
-				summary, err := analyzeImpl(ctx, arg.(*snapshot), analyzers, id)
-				return analyzeImplResult{summary, err}
-			}),
-		}
-		s.analyses.Set(key, entry, nil) // nothing needs releasing
-	}
-	s.mu.Unlock()
-
-	// Await result.
-	ap := entry.(analysisPromise)
-	v, err := s.awaitPromise(ctx, ap.promise)
-	if err != nil {
-		return nil, err // e.g. cancelled
-	}
-	res := v.(analyzeImplResult)
-	return res.summary, res.err
-}
-
-// analyzeImpl applies a list of analyzers (plus any others
-// transitively required by them) to a package.  It succeeds as long
-// as it could produce a types.Package, even if there were direct or
-// indirect list/parse/type errors, and even if all the analysis
-// actions failed. It usually fails only if the package was unknown,
-// a file was missing, or the operation was cancelled.
-//
-// Postcondition: analyzeImpl must not continue to use the snapshot
-// (in background goroutines) after it has returned; see memoize.RefCounted.
-func analyzeImpl(ctx context.Context, snapshot *snapshot, analyzers []*analysis.Analyzer, id PackageID) (*analyzeSummary, error) {
-	m := snapshot.Metadata(id)
-	if m == nil {
-		return nil, fmt.Errorf("no metadata for %s", id)
-	}
-
-	// Recursively analyze each "vertical" dependency
-	// for its types.Package and (perhaps) analysis.Facts.
-	// If any of them fails to produce a package, we cannot continue.
-	// We request only the analyzers that produce facts.
-	//
-	// Also, load the contents of each "compiled" Go file through
-	// the snapshot's cache.
-	//
-	// Both loops occur in parallel, and parallel with each other.
-	vdeps := make(map[PackageID]*analyzeSummary)
-	compiledGoFiles := make([]source.FileHandle, len(m.CompiledGoFiles))
-	{
-		var group errgroup.Group
-
-		// Analyze vertical dependencies.
-		// We request only the required analyzers that use facts.
-		var useFacts []*analysis.Analyzer
-		for _, a := range requiredAnalyzers(analyzers) {
-			if len(a.FactTypes) > 0 {
-				useFacts = append(useFacts, a)
-			}
-		}
-		var vdepsMu sync.Mutex
-		for _, id := range m.DepsByPkgPath {
-			id := id
-			group.Go(func() error {
-				res, err := snapshot.analyze(ctx, id, useFacts)
-				if err != nil {
-					return err // cancelled, or failed to produce a package
-				}
-
-				vdepsMu.Lock()
-				vdeps[id] = res
-				vdepsMu.Unlock()
-				return nil
-			})
-		}
-
-		// Read file contents.
-		// (In practice these will be cache hits
-		// on reads done by the initial workspace load
-		// or after a change modification event.)
-		for i, uri := range m.CompiledGoFiles {
-			i, uri := i, uri
-			group.Go(func() error {
-				fh, err := snapshot.GetFile(ctx, uri) // ~25us
-				compiledGoFiles[i] = fh
-				return err // e.g. cancelled
-			})
-		}
-
-		if err := group.Wait(); err != nil {
-			return nil, err
-		}
-	}
-
-	// Inv: analyze() of all vdeps succeeded (though some actions may have failed).
-
-	// We no longer depend on the snapshot.
-	snapshot = nil
-
-	// At this point we have the action results (serialized
-	// packages and facts) of our immediate dependencies,
-	// and the metadata and content of this package.
-	//
-	// We now compute a hash for all our inputs, and consult a
-	// global cache of promised results. If nothing material
-	// has changed, we'll make a hit in the shared cache.
-	//
-	// The hash of our inputs is based on the serialized export
-	// data and facts so that immaterial changes can be pruned
-	// without decoding.
-	key := analysisCacheKey(analyzers, m, compiledGoFiles, vdeps)
-
-	// Access the cache.
-	var summary *analyzeSummary
-	const cacheKind = "analysis"
-	if data, err := filecache.Get(cacheKind, key); err == nil {
-		// cache hit
-		mustDecode(data, &summary)
-
-	} else if err != filecache.ErrNotFound {
-		return nil, bug.Errorf("internal error reading shared cache: %v", err)
-
-	} else {
-		// Cache miss: do the work.
-		var err error
-		summary, err = actuallyAnalyze(ctx, analyzers, m, vdeps, compiledGoFiles)
-		if err != nil {
-			return nil, err
-		}
-		data := mustEncode(summary)
-		if false {
-			log.Printf("Set key=%d value=%d id=%s\n", len(key), len(data), id)
-		}
-		if err := filecache.Set(cacheKind, key, data); err != nil {
-			return nil, fmt.Errorf("internal error updating shared cache: %v", err)
-		}
-	}
-
-	// Hit or miss, we need to merge the export data from
-	// dependencies so that it includes all the types
-	// that might be summoned by the type checker.
-	//
-	// TODO(adonovan): opt: reduce this set by recording
-	// which packages were actually summoned by insert().
-	// (Just makes map smaller; probably marginal?)
-	allExport := make(map[PackagePath][]byte)
-	for _, vdep := range vdeps {
-		for k, v := range vdep.allExport {
-			allExport[k] = v
-		}
-	}
-	allExport[m.PkgPath] = summary.Export
-	summary.allExport = allExport
-
-	return summary, nil
-}
-
-// analysisCacheKey returns a cache key that is a cryptographic digest
-// of the all the values that might affect type checking and analysis:
-// the analyzer names, package metadata, names and contents of
-// compiled Go files, and vdeps information (export data and facts).
-//
-// TODO(adonovan): safety: define our own flavor of Metadata
-// containing just the fields we need, and using it in the subsequent
-// logic, to keep us honest about hashing all parts that matter?
-func analysisCacheKey(analyzers []*analysis.Analyzer, m *source.Metadata, compiledGoFiles []source.FileHandle, vdeps map[PackageID]*analyzeSummary) [sha256.Size]byte {
-	hasher := sha256.New()
-
-	// In principle, a key must be the hash of an
-	// unambiguous encoding of all the relevant data.
-	// If it's ambiguous, we risk collisons.
-
-	// analyzers
-	fmt.Fprintf(hasher, "analyzers: %d\n", len(analyzers))
-	for _, a := range analyzers {
-		fmt.Fprintln(hasher, a.Name)
-	}
-
-	// package metadata
-	fmt.Fprintf(hasher, "package: %s %s %s\n", m.ID, m.Name, m.PkgPath)
-	// We can ignore m.DepsBy{Pkg,Import}Path: although the logic
-	// uses those fields, we account for them by hashing vdeps.
-
-	// type sizes
-	// This assertion is safe, but if a black-box implementation
-	// is ever needed, record Sizeof(*int) and Alignof(int64).
-	sz := m.TypesSizes.(*types.StdSizes)
-	fmt.Fprintf(hasher, "sizes: %d %d\n", sz.WordSize, sz.MaxAlign)
-
-	// metadata errors
-	for _, err := range m.Errors {
-		fmt.Fprintf(hasher, "error: %q", err)
-	}
-
-	// module Go version
-	if m.Module != nil && m.Module.GoVersion != "" {
-		fmt.Fprintf(hasher, "go %s\n", m.Module.GoVersion)
-	}
-
-	// file names and contents
-	fmt.Fprintf(hasher, "files: %d\n", len(compiledGoFiles))
-	for _, fh := range compiledGoFiles {
-		fmt.Fprintln(hasher, fh.FileIdentity())
-	}
-
-	// vdeps, in PackageID order
-	depIDs := make([]string, 0, len(vdeps))
-	for depID := range vdeps {
-		depIDs = append(depIDs, string(depID))
-	}
-	sort.Strings(depIDs)
-	for _, id := range depIDs {
-		vdep := vdeps[PackageID(id)]
-		fmt.Fprintf(hasher, "dep: %s\n", vdep.PkgPath)
-		fmt.Fprintf(hasher, "export: %s\n", vdep.DeepExportHash)
-
-		// action results: errors and facts
-		names := make([]string, 0, len(vdep.Actions))
-		for name := range vdep.Actions {
-			names = append(names, name)
-		}
-		sort.Strings(names)
-		for _, name := range names {
-			summary := vdep.Actions[name]
-			fmt.Fprintf(hasher, "action %s\n", name)
-			if summary.Err != "" {
-				fmt.Fprintf(hasher, "error %s\n", summary.Err)
-			} else {
-				fmt.Fprintf(hasher, "facts %s\n", summary.FactsHash)
-				// We can safely omit summary.diagnostics
-				// from the key since they have no downstream effect.
-			}
-		}
-	}
-
-	var hash [sha256.Size]byte
-	hasher.Sum(hash[:0])
-	return hash
-}
-
-// actuallyAnalyze implements the cache-miss case.
-// This function does not access the snapshot.
-func actuallyAnalyze(ctx context.Context, analyzers []*analysis.Analyzer, m *source.Metadata, vdeps map[PackageID]*analyzeSummary, compiledGoFiles []source.FileHandle) (*analyzeSummary, error) {
-
-	// Create a local FileSet for processing this package only.
-	fset := token.NewFileSet()
-
-	// Parse only the "compiled" Go files.
-	// Do the computation in parallel.
-	parsed := make([]*source.ParsedGoFile, len(compiledGoFiles))
-	{
-		var group errgroup.Group
-		for i, fh := range compiledGoFiles {
-			i, fh := i, fh
-			group.Go(func() error {
-				// Call parseGoImpl directly, not the caching wrapper,
-				// as cached ASTs require the global FileSet.
-				pgf, err := parseGoImpl(ctx, fset, fh, source.ParseFull)
-				parsed[i] = pgf
-				return err
-			})
-		}
-		if err := group.Wait(); err != nil {
-			return nil, err // cancelled, or catastrophic error (e.g. missing file)
-		}
-	}
-
-	// Type-check the package.
-	pkg := typeCheckForAnalysis(fset, parsed, m, vdeps)
-
-	// Build a map of PkgPath to *Package for all packages mentioned
-	// in exportdata for use by facts.
-	pkg.factsDecoder = facts.NewDecoder(pkg.types)
-
-	// Poll cancellation state.
-	if err := ctx.Err(); err != nil {
-		return nil, err
-	}
-
-	// TODO(adonovan): port the old logic to:
-	// - gather go/packages diagnostics from m.Errors? (port goPackagesErrorDiagnostics)
-	// - record unparseable file URIs so we can suppress type errors for these files.
-	// - gather diagnostics from expandErrors + typeErrorDiagnostics + depsErrors.
-
-	// -- analysis --
-
-	// Build action graph for this package.
-	// Each graph node (action) is one unit of analysis.
-	actions := make(map[*analysis.Analyzer]*action)
-	var mkAction func(a *analysis.Analyzer) *action
-	mkAction = func(a *analysis.Analyzer) *action {
-		act, ok := actions[a]
-		if !ok {
-			var hdeps []*action
-			for _, req := range a.Requires {
-				hdeps = append(hdeps, mkAction(req))
-			}
-			act = &action{a: a, pkg: pkg, vdeps: vdeps, hdeps: hdeps}
-			actions[a] = act
-		}
-		return act
-	}
-
-	// Build actions for initial package.
-	var roots []*action
-	for _, a := range analyzers {
-		roots = append(roots, mkAction(a))
-	}
-
-	// Execute the graph in parallel.
-	execActions(roots)
-
-	// Don't return (or cache) the result in case of cancellation.
-	if err := ctx.Err(); err != nil {
-		return nil, err // cancelled
-	}
-
-	// Return summaries only for the requested actions.
-	summaries := make(map[string]*actionSummary)
-	for _, act := range roots {
-		summaries[act.a.Name] = act.summary
-	}
-
-	return &analyzeSummary{
-		PkgPath:        PackagePath(pkg.types.Path()),
-		Export:         pkg.export,
-		DeepExportHash: pkg.deepExportHash,
-		Compiles:       pkg.compiles,
-		Actions:        summaries,
-	}, nil
-}
-
-func typeCheckForAnalysis(fset *token.FileSet, parsed []*source.ParsedGoFile, m *source.Metadata, vdeps map[PackageID]*analyzeSummary) *analysisPackage {
-	if false { // debugging
-		log.Println("typeCheckForAnalysis", m.PkgPath)
-	}
-
-	pkg := &analysisPackage{
-		m:        m,
-		fset:     fset,
-		parsed:   parsed,
-		files:    make([]*ast.File, len(parsed)),
-		compiles: len(m.Errors) == 0, // false => list error
-		types:    types.NewPackage(string(m.PkgPath), string(m.Name)),
-		typesInfo: &types.Info{
-			Types:      make(map[ast.Expr]types.TypeAndValue),
-			Defs:       make(map[*ast.Ident]types.Object),
-			Uses:       make(map[*ast.Ident]types.Object),
-			Implicits:  make(map[ast.Node]types.Object),
-			Selections: make(map[*ast.SelectorExpr]*types.Selection),
-			Scopes:     make(map[ast.Node]*types.Scope),
-		},
-		typesSizes: m.TypesSizes,
-	}
-	typeparams.InitInstanceInfo(pkg.typesInfo)
-
-	for i, p := range parsed {
-		pkg.files[i] = p.File
-		if p.ParseErr != nil {
-			pkg.compiles = false // parse error
-		}
-	}
-
-	// Unsafe is special.
-	if m.PkgPath == "unsafe" {
-		pkg.types = types.Unsafe
-		return pkg
-	}
-
-	// Compute the union of transitive export data.
-	// (The actual values are shared, and not serialized.)
-	allExport := make(map[PackagePath][]byte)
-	for _, vdep := range vdeps {
-		for k, v := range vdep.allExport {
-			allExport[k] = v
-		}
-
-		if !vdep.Compiles {
-			pkg.compiles = false // transitive error
-		}
-	}
-
-	// exportHasher computes a hash of the names and export data of
-	// each package that was actually loaded during type checking.
-	//
-	// Because we use shallow export data, the hash for dependency
-	// analysis must incorporate indirect dependencies. As an
-	// optimization, we include only those that were actually
-	// used, which may be a small subset of those available.
-	//
-	// TODO(adonovan): opt: even better would be to implement a
-	// traversal over the package API like facts.NewDecoder does
-	// and only mention that set of packages in the hash.
-	// Perhaps there's a way to do that more efficiently.
-	//
-	// TODO(adonovan): opt: record the shallow hash alongside the
-	// shallow export data in the allExport map to avoid repeatedly
-	// hashing the export data.
-	//
-	// The writes to hasher below assume that type checking imports
-	// packages in a deterministic order.
-	exportHasher := sha256.New()
-	hashExport := func(pkgPath PackagePath, export []byte) {
-		fmt.Fprintf(exportHasher, "%s %d ", pkgPath, len(export))
-		exportHasher.Write(export)
-	}
-
-	// importer state
-	var (
-		insert    func(p *types.Package, name string)
-		importMap = make(map[string]*types.Package) // keys are PackagePaths
-	)
-	loadFromExportData := func(pkgPath PackagePath) (*types.Package, error) {
-		export, ok := allExport[pkgPath]
-		if !ok {
-			return nil, bug.Errorf("missing export data for %q", pkgPath)
-		}
-		hashExport(pkgPath, export)
-		imported, err := gcimporter.IImportShallow(fset, importMap, export, string(pkgPath), insert)
-		if err != nil {
-			return nil, bug.Errorf("invalid export data for %q: %v", pkgPath, err)
-		}
-		return imported, nil
-	}
-	insert = func(p *types.Package, name string) {
-		imported, err := loadFromExportData(PackagePath(p.Path()))
-		if err != nil {
-			log.Fatalf("internal error: %v", err)
-		}
-		if imported != p {
-			log.Fatalf("internal error: inconsistent packages")
-		}
-	}
-
-	cfg := &types.Config{
-		Error: func(e error) {
-			pkg.compiles = false // type error
-			pkg.typeErrors = append(pkg.typeErrors, e.(types.Error))
-		},
-		Importer: importerFunc(func(importPath string) (*types.Package, error) {
-			if importPath == "unsafe" {
-				return types.Unsafe, nil // unsafe has no export data
-			}
-
-			// Beware that returning an error from this function
-			// will cause the type checker to synthesize a fake
-			// package whose Path is importPath, potentially
-			// losing a vendor/ prefix. If type-checking errors
-			// are swallowed, these packages may be confusing.
-
-			id, ok := m.DepsByImpPath[ImportPath(importPath)]
-			if !ok {
-				// The import syntax is inconsistent with the metadata.
-				// This could be because the import declaration was
-				// incomplete and the metadata only includes complete
-				// imports; or because the metadata ignores import
-				// edges that would lead to cycles in the graph.
-				return nil, fmt.Errorf("missing metadata for import of %q", importPath)
-			}
-
-			depResult, ok := vdeps[id] // id may be ""
-			if !ok {
-				// Analogous to (*snapshot).missingPkgError
-				// in the logic for regular type-checking,
-				// but without a snapshot we can't provide
-				// such detail, and anyway most analysis
-				// failures aren't surfaced in the UI.
-				return nil, fmt.Errorf("no required module provides package %q (id=%q)", importPath, id)
-			}
-
-			// (Duplicates logic from check.go.)
-			if !source.IsValidImport(m.PkgPath, depResult.PkgPath) {
-				return nil, fmt.Errorf("invalid use of internal package %s", importPath)
-			}
-
-			return loadFromExportData(depResult.PkgPath)
-		}),
-	}
-
-	// Set Go dialect.
-	if m.Module != nil && m.Module.GoVersion != "" {
-		goVersion := "go" + m.Module.GoVersion
-		// types.NewChecker panics if GoVersion is invalid.
-		// An unparsable mod file should probably stop us
-		// before we get here, but double check just in case.
-		if goVersionRx.MatchString(goVersion) {
-			typesinternal.SetGoVersion(cfg, goVersion)
-		}
-	}
-
-	// We want to type check cgo code if go/types supports it.
-	// We passed typecheckCgo to go/packages when we Loaded.
-	// TODO(adonovan): do we actually need this??
-	typesinternal.SetUsesCgo(cfg)
-
-	check := types.NewChecker(cfg, fset, pkg.types, pkg.typesInfo)
-
-	// Type checking errors are handled via the config, so ignore them here.
-	_ = check.Files(pkg.files)
-
-	// debugging (type errors are quite normal)
-	if false {
-		if pkg.typeErrors != nil {
-			log.Printf("package %s has type errors: %v", pkg.types.Path(), pkg.typeErrors)
-		}
-	}
-
-	// Emit the export data and compute the deep hash.
-	export, err := gcimporter.IExportShallow(pkg.fset, pkg.types)
-	if err != nil {
-		log.Fatalf("internal error writing shallow export data: %v", err)
-	}
-	pkg.export = export
-	hashExport(m.PkgPath, export)
-	exportHasher.Sum(pkg.deepExportHash[:0])
-
-	return pkg
-}
-
-// analysisPackage contains information about a package, including
-// syntax trees, used transiently during its type-checking and analysis.
-type analysisPackage struct {
-	m              *source.Metadata
-	fset           *token.FileSet // local to this package
-	parsed         []*source.ParsedGoFile
-	files          []*ast.File // same as parsed[i].File
-	types          *types.Package
-	compiles       bool // package is transitively free of list/parse/type errors
-	factsDecoder   *facts.Decoder
-	export         []byte      // encoding of types.Package
-	deepExportHash source.Hash // reflexive transitive hash of export data
-	typesInfo      *types.Info
-	typeErrors     []types.Error
-	typesSizes     types.Sizes
-}
-
-// An action represents one unit of analysis work: the application of
-// one analysis to one package. Actions form a DAG, both within a
-// package (as different analyzers are applied, either in sequence or
-// parallel), and across packages (as dependencies are analyzed).
-type action struct {
-	once  sync.Once
-	a     *analysis.Analyzer
-	pkg   *analysisPackage
-	hdeps []*action                     // horizontal dependencies
-	vdeps map[PackageID]*analyzeSummary // vertical dependencies
-
-	// results of action.exec():
-	result  interface{} // result of Run function, of type a.ResultType
-	summary *actionSummary
-	err     error
-}
-
-func (act *action) String() string {
-	return fmt.Sprintf("%s@%s", act.a.Name, act.pkg.m.ID)
-}
-
-// execActions executes a set of action graph nodes in parallel.
-func execActions(actions []*action) {
-	var wg sync.WaitGroup
-	for _, act := range actions {
-		act := act
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-			act.once.Do(func() {
-				execActions(act.hdeps) // analyze "horizontal" dependencies
-				act.result, act.summary, act.err = act.exec()
-				if act.err != nil {
-					act.summary = &actionSummary{Err: act.err.Error()}
-					// TODO(adonovan): suppress logging. But
-					// shouldn't the root error's causal chain
-					// include this information?
-					if false { // debugging
-						log.Printf("act.exec(%v) failed: %v", act, act.err)
-					}
-				}
-			})
-		}()
-	}
-	wg.Wait()
-}
-
-// exec defines the execution of a single action.
-// It returns the (ephemeral) result of the analyzer's Run function,
-// along with its (serializable) facts and diagnostics.
-// Or it returns an error if the analyzer did not run to
-// completion and deliver a valid result.
-func (act *action) exec() (interface{}, *actionSummary, error) {
-	analyzer := act.a
-	pkg := act.pkg
-
-	hasFacts := len(analyzer.FactTypes) > 0
-
-	// Report an error if any action dependency (vertical or horizontal) failed.
-	// To avoid long error messages describing chains of failure,
-	// we return the dependencies' error' unadorned.
-	if hasFacts {
-		// TODO(adonovan): use deterministic order.
-		for _, res := range act.vdeps {
-			if vdep := res.Actions[analyzer.Name]; vdep.Err != "" {
-				return nil, nil, errors.New(vdep.Err)
-			}
-		}
-	}
-	for _, dep := range act.hdeps {
-		if dep.err != nil {
-			return nil, nil, dep.err
-		}
-	}
-	// Inv: all action dependencies succeeded.
-
-	// Were there list/parse/type errors that might prevent analysis?
-	if !pkg.compiles && !analyzer.RunDespiteErrors {
-		return nil, nil, fmt.Errorf("skipping analysis %q because package %q does not compile", analyzer.Name, pkg.m.ID)
-	}
-	// Inv: package is well-formed enough to proceed with analysis.
-
-	if false { // debugging
-		log.Println("action.exec", act)
-	}
-
-	// Gather analysis Result values from horizontal dependencies.
-	var inputs = make(map[*analysis.Analyzer]interface{})
-	for _, dep := range act.hdeps {
-		inputs[dep.a] = dep.result
-	}
-
-	// TODO(adonovan): opt: facts.Set works but it may be more
-	// efficient to fork and tailor it to our precise needs.
-	//
-	// We've already sharded the fact encoding by action
-	// so that it can be done in parallel (hoisting the
-	// ImportMap call so that we build the map once per package).
-	// We could eliminate locking.
-	// We could also dovetail more closely with the export data
-	// decoder to obtain a more compact representation of
-	// packages and objects (e.g. its internal IDs, instead
-	// of PkgPaths and objectpaths.)
-
-	// Read and decode analysis facts for each imported package.
-	factset, err := pkg.factsDecoder.Decode(func(imp *types.Package) ([]byte, error) {
-		if !hasFacts {
-			return nil, nil // analyzer doesn't use facts, so no vdeps
-		}
-
-		// Package.Imports() may contain a fake "C" package. Ignore it.
-		if imp.Path() == "C" {
-			return nil, nil
-		}
-
-		id, ok := pkg.m.DepsByPkgPath[PackagePath(imp.Path())]
-		if !ok {
-			// This may mean imp was synthesized by the type
-			// checker because it failed to import it for any reason
-			// (e.g. bug processing export data; metadata ignoring
-			// a cycle-forming import).
-			// In that case, the fake package's imp.Path
-			// is set to the failed importPath (and thus
-			// it may lack a "vendor/" prefix).
-			//
-			// For now, silently ignore it on the assumption
-			// that the error is already reported elsewhere.
-			// return nil, fmt.Errorf("missing metadata")
-			return nil, nil
-		}
-
-		vdep, ok := act.vdeps[id]
-		if !ok {
-			return nil, bug.Errorf("internal error in %s: missing vdep for id=%s", pkg.types.Path(), id)
-		}
-		return vdep.Actions[analyzer.Name].Facts, nil
-	})
-	if err != nil {
-		return nil, nil, fmt.Errorf("internal error decoding analysis facts: %w", err)
-	}
-
-	// TODO(adonovan): make Export*Fact panic rather than discarding
-	// undeclared fact types, so that we discover bugs in analyzers.
-	factFilter := make(map[reflect.Type]bool)
-	for _, f := range analyzer.FactTypes {
-		factFilter[reflect.TypeOf(f)] = true
-	}
-
-	// posToLocation converts from token.Pos to protocol form.
-	// TODO(adonovan): improve error messages.
-	posToLocation := func(start, end token.Pos) (protocol.Location, error) {
-		tokFile := pkg.fset.File(start)
-		for _, p := range pkg.parsed {
-			if p.Tok == tokFile {
-				if end == token.NoPos {
-					end = start
-				}
-				rng, err := p.Mapper.PosRange(start, end)
-				if err != nil {
-					return protocol.Location{}, err
-				}
-				return protocol.Location{
-					// TODO(adonovan): is this sound?
-					// See dual conversion in toSourceDiagnostic.
-					URI:   protocol.DocumentURI(p.URI),
-					Range: rng,
-				}, nil
-			}
-		}
-		return protocol.Location{},
-			bug.Errorf("internal error: token.Pos not within package")
-	}
-
-	// Now run the (pkg, analyzer) action.
-	var diagnostics []gobDiagnostic
-	pass := &analysis.Pass{
-		Analyzer:   analyzer,
-		Fset:       pkg.fset,
-		Files:      pkg.files,
-		Pkg:        pkg.types,
-		TypesInfo:  pkg.typesInfo,
-		TypesSizes: pkg.typesSizes,
-		TypeErrors: pkg.typeErrors,
-		ResultOf:   inputs,
-		Report: func(d analysis.Diagnostic) {
-			// Prefix the diagnostic category with the analyzer's name.
-			if d.Category == "" {
-				d.Category = analyzer.Name
-			} else {
-				d.Category = analyzer.Name + "." + d.Category
-			}
-
-			diagnostic, err := toGobDiagnostic(posToLocation, d)
-			if err != nil {
-				bug.Reportf("internal error converting diagnostic from analyzer %q: %v", analyzer.Name, err)
-				return
-			}
-			diagnostics = append(diagnostics, diagnostic)
-		},
-		ImportObjectFact:  factset.ImportObjectFact,
-		ExportObjectFact:  factset.ExportObjectFact,
-		ImportPackageFact: factset.ImportPackageFact,
-		ExportPackageFact: factset.ExportPackageFact,
-		AllObjectFacts:    func() []analysis.ObjectFact { return factset.AllObjectFacts(factFilter) },
-		AllPackageFacts:   func() []analysis.PackageFact { return factset.AllPackageFacts(factFilter) },
-	}
-
-	// Recover from panics (only) within the analyzer logic.
-	// (Use an anonymous function to limit the recover scope.)
-	var result interface{}
-	func() {
-		defer func() {
-			if r := recover(); r != nil {
-				// An Analyzer panicked, likely due to a bug.
-				//
-				// In general we want to discover and fix such panics quickly,
-				// so we don't suppress them, but some bugs in third-party
-				// analyzers cannot be quickly fixed, so we use an allowlist
-				// to suppress panics.
-				const strict = true
-				if strict && bug.PanicOnBugs &&
-					analyzer.Name != "buildir" { // see https://github.com/dominikh/go-tools/issues/1343
-					// Uncomment this when debugging suspected failures
-					// in the driver, not the analyzer.
-					if false {
-						debug.SetTraceback("all") // show all goroutines
-					}
-					panic(r)
-				} else {
-					// In production, suppress the panic and press on.
-					err = fmt.Errorf("analysis %s for package %s panicked: %v", analyzer.Name, pass.Pkg.Path(), r)
-				}
-			}
-		}()
-		result, err = pass.Analyzer.Run(pass)
-	}()
-	if err != nil {
-		return nil, nil, err
-	}
-
-	if got, want := reflect.TypeOf(result), pass.Analyzer.ResultType; got != want {
-		return nil, nil, bug.Errorf(
-			"internal error: on package %s, analyzer %s returned a result of type %v, but declared ResultType %v",
-			pass.Pkg.Path(), pass.Analyzer, got, want)
-	}
-
-	// Disallow Export*Fact calls after Run.
-	// (A panic means the Analyzer is abusing concurrency.)
-	pass.ExportObjectFact = func(obj types.Object, fact analysis.Fact) {
-		panic(fmt.Sprintf("%v: Pass.ExportObjectFact(%s, %T) called after Run", act, obj, fact))
-	}
-	pass.ExportPackageFact = func(fact analysis.Fact) {
-		panic(fmt.Sprintf("%v: Pass.ExportPackageFact(%T) called after Run", act, fact))
-	}
-
-	factsdata := factset.Encode()
-	return result, &actionSummary{
-		Diagnostics: diagnostics,
-		Facts:       factsdata,
-		FactsHash:   source.HashOf(factsdata),
-	}, nil
-}
-
-// requiredAnalyzers returns the transitive closure of required analyzers in preorder.
-func requiredAnalyzers(analyzers []*analysis.Analyzer) []*analysis.Analyzer {
-	var result []*analysis.Analyzer
-	seen := make(map[*analysis.Analyzer]bool)
-	var visitAll func([]*analysis.Analyzer)
-	visitAll = func(analyzers []*analysis.Analyzer) {
-		for _, a := range analyzers {
-			if !seen[a] {
-				seen[a] = true
-				result = append(result, a)
-				visitAll(a.Requires)
-			}
-		}
-	}
-	visitAll(analyzers)
-	return result
-}
-
-func mustEncode(x interface{}) []byte {
-	var buf bytes.Buffer
-	if err := gob.NewEncoder(&buf).Encode(x); err != nil {
-		log.Fatalf("internal error encoding %T: %v", x, err)
-	}
-	return buf.Bytes()
-}
-
-func mustDecode(data []byte, ptr interface{}) {
-	if err := gob.NewDecoder(bytes.NewReader(data)).Decode(ptr); err != nil {
-		log.Fatalf("internal error decoding %T: %v", ptr, err)
-	}
-}
-
-// -- data types for serialization of analysis.Diagnostic --
-
-type gobDiagnostic struct {
-	Location       protocol.Location
-	Category       string
-	Message        string
-	SuggestedFixes []gobSuggestedFix
-	Related        []gobRelatedInformation
-}
-
-type gobRelatedInformation struct {
-	Location protocol.Location
-	Message  string
-}
-
-type gobSuggestedFix struct {
-	Message   string
-	TextEdits []gobTextEdit
-}
-
-type gobTextEdit struct {
-	Location protocol.Location
-	NewText  []byte
-}
-
-// toGobDiagnostic converts an analysis.Diagnosic to a serializable gobDiagnostic,
-// which requires expanding token.Pos positions into protocol.Location form.
-func toGobDiagnostic(posToLocation func(start, end token.Pos) (protocol.Location, error), diag analysis.Diagnostic) (gobDiagnostic, error) {
-	var fixes []gobSuggestedFix
-	for _, fix := range diag.SuggestedFixes {
-		var gobEdits []gobTextEdit
-		for _, textEdit := range fix.TextEdits {
-			loc, err := posToLocation(textEdit.Pos, textEdit.End)
-			if err != nil {
-				return gobDiagnostic{}, fmt.Errorf("in SuggestedFixes: %w", err)
-			}
-			gobEdits = append(gobEdits, gobTextEdit{
-				Location: loc,
-				NewText:  textEdit.NewText,
-			})
-		}
-		fixes = append(fixes, gobSuggestedFix{
-			Message:   fix.Message,
-			TextEdits: gobEdits,
-		})
-	}
-
-	var related []gobRelatedInformation
-	for _, r := range diag.Related {
-		loc, err := posToLocation(r.Pos, r.End)
-		if err != nil {
-			return gobDiagnostic{}, fmt.Errorf("in Related: %w", err)
-		}
-		related = append(related, gobRelatedInformation{
-			Location: loc,
-			Message:  r.Message,
-		})
-	}
-
-	loc, err := posToLocation(diag.Pos, diag.End)
-	if err != nil {
-		return gobDiagnostic{}, err
-	}
-	return gobDiagnostic{
-		Location:       loc,
-		Category:       diag.Category,
-		Message:        diag.Message,
-		Related:        related,
-		SuggestedFixes: fixes,
-	}, nil
-}
diff -urN a/gopls/internal/lsp/cache/cache.go b/gopls/internal/lsp/cache/cache.go
--- a/gopls/internal/lsp/cache/cache.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/cache.go	1969-12-31 16:00:00
@@ -1,295 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"html/template"
-	"io/ioutil"
-	"os"
-	"reflect"
-	"sort"
-	"strconv"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// New Creates a new cache for gopls operation results, using the given file
-// set, shared store, and session options.
-//
-// Both the fset and store may be nil, but if store is non-nil so must be fset
-// (and they must always be used together), otherwise it may be possible to get
-// cached data referencing token.Pos values not mapped by the FileSet.
-func New(fset *token.FileSet, store *memoize.Store) *Cache {
-	index := atomic.AddInt64(&cacheIndex, 1)
-
-	if store != nil && fset == nil {
-		panic("non-nil store with nil fset")
-	}
-	if fset == nil {
-		fset = token.NewFileSet()
-	}
-	if store == nil {
-		store = &memoize.Store{}
-	}
-
-	c := &Cache{
-		id:          strconv.FormatInt(index, 10),
-		fset:        fset,
-		store:       store,
-		fileContent: map[span.URI]*fileHandle{},
-	}
-	return c
-}
-
-type Cache struct {
-	id   string
-	fset *token.FileSet
-
-	store *memoize.Store
-
-	fileMu      sync.Mutex
-	fileContent map[span.URI]*fileHandle
-}
-
-type fileHandle struct {
-	modTime time.Time
-	uri     span.URI
-	bytes   []byte
-	hash    source.Hash
-	err     error
-
-	// size is the file length as reported by Stat, for the purpose of
-	// invalidation. Probably we could just use len(bytes), but this is done
-	// defensively in case the definition of file size in the file system
-	// differs.
-	size int64
-}
-
-func (h *fileHandle) Saved() bool {
-	return true
-}
-
-// GetFile stats and (maybe) reads the file, updates the cache, and returns it.
-func (c *Cache) GetFile(ctx context.Context, uri span.URI) (source.FileHandle, error) {
-	return c.getFile(ctx, uri)
-}
-
-func (c *Cache) getFile(ctx context.Context, uri span.URI) (*fileHandle, error) {
-	fi, statErr := os.Stat(uri.Filename())
-	if statErr != nil {
-		return &fileHandle{
-			err: statErr,
-			uri: uri,
-		}, nil
-	}
-
-	c.fileMu.Lock()
-	fh, ok := c.fileContent[uri]
-	c.fileMu.Unlock()
-
-	// Check mtime and file size to infer whether the file has changed. This is
-	// an imperfect heuristic. Notably on some real systems (such as WSL) the
-	// filesystem clock resolution can be large -- 1/64s was observed. Therefore
-	// it's quite possible for multiple file modifications to occur within a
-	// single logical 'tick'. This can leave the cache in an incorrect state, but
-	// unfortunately we can't afford to pay the price of reading the actual file
-	// content here. Or to be more precise, reading would be a risky change and
-	// we don't know if we can afford it.
-	//
-	// We check file size in an attempt to reduce the probability of false cache
-	// hits.
-	if ok && fh.modTime.Equal(fi.ModTime()) && fh.size == fi.Size() {
-		return fh, nil
-	}
-
-	fh, err := readFile(ctx, uri, fi) // ~25us
-	if err != nil {
-		return nil, err
-	}
-	c.fileMu.Lock()
-	c.fileContent[uri] = fh
-	c.fileMu.Unlock()
-	return fh, nil
-}
-
-// ioLimit limits the number of parallel file reads per process.
-var ioLimit = make(chan struct{}, 128)
-
-func readFile(ctx context.Context, uri span.URI, fi os.FileInfo) (*fileHandle, error) {
-	select {
-	case ioLimit <- struct{}{}:
-	case <-ctx.Done():
-		return nil, ctx.Err()
-	}
-	defer func() { <-ioLimit }()
-
-	ctx, done := event.Start(ctx, "cache.readFile", tag.File.Of(uri.Filename()))
-	_ = ctx
-	defer done()
-
-	data, err := ioutil.ReadFile(uri.Filename()) // ~20us
-	if err != nil {
-		return &fileHandle{
-			modTime: fi.ModTime(),
-			size:    fi.Size(),
-			err:     err,
-		}, nil
-	}
-	return &fileHandle{
-		modTime: fi.ModTime(),
-		size:    fi.Size(),
-		uri:     uri,
-		bytes:   data,
-		hash:    source.HashOf(data),
-	}, nil
-}
-
-// NewSession creates a new gopls session with the given cache and options overrides.
-//
-// The provided optionsOverrides may be nil.
-func NewSession(ctx context.Context, c *Cache, optionsOverrides func(*source.Options)) *Session {
-	index := atomic.AddInt64(&sessionIndex, 1)
-	options := source.DefaultOptions().Clone()
-	if optionsOverrides != nil {
-		optionsOverrides(options)
-	}
-	s := &Session{
-		id:          strconv.FormatInt(index, 10),
-		cache:       c,
-		gocmdRunner: &gocommand.Runner{},
-		options:     options,
-		overlays:    make(map[span.URI]*overlay),
-	}
-	event.Log(ctx, "New session", KeyCreateSession.Of(s))
-	return s
-}
-
-func (h *fileHandle) URI() span.URI {
-	return h.uri
-}
-
-func (h *fileHandle) FileIdentity() source.FileIdentity {
-	return source.FileIdentity{
-		URI:  h.uri,
-		Hash: h.hash,
-	}
-}
-
-func (h *fileHandle) Read() ([]byte, error) {
-	return h.bytes, h.err
-}
-
-var cacheIndex, sessionIndex, viewIndex int64
-
-func (c *Cache) ID() string                     { return c.id }
-func (c *Cache) MemStats() map[reflect.Type]int { return c.store.Stats() }
-
-type packageStat struct {
-	id        PackageID
-	mode      source.ParseMode
-	file      int64
-	ast       int64
-	types     int64
-	typesInfo int64
-	total     int64
-}
-
-func (c *Cache) PackageStats(withNames bool) template.HTML {
-	var packageStats []packageStat
-	c.store.DebugOnlyIterate(func(k, v interface{}) {
-		switch k.(type) {
-		case packageHandleKey:
-			v := v.(typeCheckResult)
-			if v.pkg == nil {
-				break
-			}
-			typsCost := typesCost(v.pkg.types.Scope())
-			typInfoCost := typesInfoCost(v.pkg.typesInfo)
-			stat := packageStat{
-				id:        v.pkg.m.ID,
-				mode:      v.pkg.mode,
-				types:     typsCost,
-				typesInfo: typInfoCost,
-			}
-			for _, f := range v.pkg.compiledGoFiles {
-				stat.file += int64(len(f.Src))
-				stat.ast += astCost(f.File)
-			}
-			stat.total = stat.file + stat.ast + stat.types + stat.typesInfo
-			packageStats = append(packageStats, stat)
-		}
-	})
-	var totalCost int64
-	for _, stat := range packageStats {
-		totalCost += stat.total
-	}
-	sort.Slice(packageStats, func(i, j int) bool {
-		return packageStats[i].total > packageStats[j].total
-	})
-	html := "<table><thead><td>Name</td><td>total = file + ast + types + types info</td></thead>\n"
-	human := func(n int64) string {
-		return fmt.Sprintf("%.2f", float64(n)/(1024*1024))
-	}
-	var printedCost int64
-	for _, stat := range packageStats {
-		name := stat.id
-		if !withNames {
-			name = "-"
-		}
-		html += fmt.Sprintf("<tr><td>%v (%v)</td><td>%v = %v + %v + %v + %v</td></tr>\n", name, stat.mode,
-			human(stat.total), human(stat.file), human(stat.ast), human(stat.types), human(stat.typesInfo))
-		printedCost += stat.total
-		if float64(printedCost) > float64(totalCost)*.9 {
-			break
-		}
-	}
-	html += "</table>\n"
-	return template.HTML(html)
-}
-
-func astCost(f *ast.File) int64 {
-	if f == nil {
-		return 0
-	}
-	var count int64
-	ast.Inspect(f, func(_ ast.Node) bool {
-		count += 32 // nodes are pretty small.
-		return true
-	})
-	return count
-}
-
-func typesCost(scope *types.Scope) int64 {
-	cost := 64 + int64(scope.Len())*128 // types.object looks pretty big
-	for i := 0; i < scope.NumChildren(); i++ {
-		cost += typesCost(scope.Child(i))
-	}
-	return cost
-}
-
-func typesInfoCost(info *types.Info) int64 {
-	// Most of these refer to existing objects, with the exception of InitOrder, Selections, and Types.
-	cost := 24*len(info.Defs) +
-		32*len(info.Implicits) +
-		256*len(info.InitOrder) + // these are big, but there aren't many of them.
-		32*len(info.Scopes) +
-		128*len(info.Selections) + // wild guess
-		128*len(info.Types) + // wild guess
-		32*len(info.Uses)
-	return int64(cost)
-}
diff -urN a/gopls/internal/lsp/cache/check.go b/gopls/internal/lsp/cache/check.go
--- a/gopls/internal/lsp/cache/check.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/check.go	1969-12-31 16:00:00
@@ -1,849 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/types"
-	"path/filepath"
-	"regexp"
-	"strings"
-	"sync"
-
-	"golang.org/x/mod/module"
-	"golang.org/x/sync/errgroup"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/memoize"
-	"golang.org/x/tools/internal/packagesinternal"
-	"golang.org/x/tools/internal/typeparams"
-	"golang.org/x/tools/internal/typesinternal"
-)
-
-// A packageKey identifies a packageHandle in the snapshot.packages map.
-type packageKey struct {
-	mode source.ParseMode
-	id   PackageID
-}
-
-type packageHandleKey source.Hash
-
-// A packageHandle is a handle to the future result of type-checking a package.
-// The resulting package is obtained from the await() method.
-type packageHandle struct {
-	promise *memoize.Promise // [typeCheckResult]
-
-	// m is the metadata associated with the package.
-	m *source.Metadata
-
-	// key is the hashed key for the package.
-	//
-	// It includes the all bits of the transitive closure of
-	// dependencies's sources. This is more than type checking
-	// really depends on: export data of direct deps should be
-	// enough. (The key for analysis actions could similarly
-	// hash only Facts of direct dependencies.)
-	key packageHandleKey
-}
-
-// typeCheckResult contains the result of a call to
-// typeCheckImpl, which type-checks a package.
-type typeCheckResult struct {
-	pkg *pkg
-	err error
-}
-
-// buildPackageHandle returns a handle for the future results of
-// type-checking the package identified by id in the given mode.
-// It assumes that the given ID already has metadata available, so it does not
-// attempt to reload missing or invalid metadata. The caller must reload
-// metadata if needed.
-func (s *snapshot) buildPackageHandle(ctx context.Context, id PackageID, mode source.ParseMode) (*packageHandle, error) {
-	packageKey := packageKey{id: id, mode: mode}
-
-	s.mu.Lock()
-	entry, hit := s.packages.Get(packageKey)
-	m := s.meta.metadata[id]
-	s.mu.Unlock()
-
-	if m == nil {
-		return nil, fmt.Errorf("no metadata for %s", id)
-	}
-
-	if hit {
-		return entry.(*packageHandle), nil
-	}
-
-	// Begin computing the key by getting the depKeys for all dependencies.
-	// This requires reading the transitive closure of dependencies' source files.
-	//
-	// It is tempting to parallelize the recursion here, but
-	// without de-duplication of subtasks this would lead to an
-	// exponential amount of work, and computing the key is
-	// expensive as it reads all the source files transitively.
-	// Notably, we don't update the s.packages cache until the
-	// entire key has been computed.
-	// TODO(adonovan): use a promise cache to ensure that the key
-	// for each package is computed by at most one thread, then do
-	// the recursive key building of dependencies in parallel.
-	deps := make(map[PackageID]*packageHandle)
-	var depKey source.Hash // XOR of all unique deps
-	for _, depID := range m.DepsByPkgPath {
-		depHandle, err := s.buildPackageHandle(ctx, depID, s.workspaceParseMode(depID))
-		// Don't use invalid metadata for dependencies if the top-level
-		// metadata is valid. We only load top-level packages, so if the
-		// top-level is valid, all of its dependencies should be as well.
-		if err != nil {
-			event.Error(ctx, fmt.Sprintf("%s: no dep handle for %s", id, depID), err, source.SnapshotLabels(s)...)
-
-			// This check ensures we break out of the slow
-			// buildPackageHandle recursion quickly when
-			// context cancelation is detected within GetFile.
-			if ctx.Err() != nil {
-				return nil, ctx.Err() // cancelled
-			}
-
-			// One bad dependency should not prevent us from
-			// checking the entire package. Leave depKeys[i] unset.
-			continue
-		}
-
-		depKey.XORWith(source.Hash(depHandle.key))
-
-		deps[depID] = depHandle
-	}
-
-	// Read both lists of files of this package, in parallel.
-	//
-	// goFiles aren't presented to the type checker--nor
-	// are they included in the key, unsoundly--but their
-	// syntax trees are available from (*pkg).File(URI).
-	// TODO(adonovan): consider parsing them on demand?
-	// The need should be rare.
-	goFiles, compiledGoFiles, err := readGoFiles(ctx, s, m)
-	if err != nil {
-		return nil, err
-	}
-
-	// All the file reading has now been done.
-	// Create a handle for the result of type checking.
-	experimentalKey := s.View().Options().ExperimentalPackageCacheKey
-	phKey := computePackageKey(m.ID, compiledGoFiles, m, depKey, mode, experimentalKey)
-	promise, release := s.store.Promise(phKey, func(ctx context.Context, arg interface{}) interface{} {
-		pkg, err := typeCheckImpl(ctx, arg.(*snapshot), goFiles, compiledGoFiles, m, mode, deps)
-		return typeCheckResult{pkg, err}
-	})
-
-	ph := &packageHandle{
-		promise: promise,
-		m:       m,
-		key:     phKey,
-	}
-
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	// Check that the metadata has not changed
-	// (which should invalidate this handle).
-	//
-	// (In future, handles should form a graph with edges from a
-	// packageHandle to the handles for parsing its files and the
-	// handles for type-checking its immediate deps, at which
-	// point there will be no need to even access s.meta.)
-	if s.meta.metadata[ph.m.ID] != ph.m {
-		return nil, fmt.Errorf("stale metadata for %s", ph.m.ID)
-	}
-
-	// Check cache again in case another thread got there first.
-	if prev, ok := s.packages.Get(packageKey); ok {
-		prevPH := prev.(*packageHandle)
-		release()
-		if prevPH.m != ph.m {
-			return nil, bug.Errorf("existing package handle does not match for %s", ph.m.ID)
-		}
-		return prevPH, nil
-	}
-
-	// Update the map.
-	s.packages.Set(packageKey, ph, func(_, _ interface{}) { release() })
-
-	return ph, nil
-}
-
-// readGoFiles reads the content of Metadata.GoFiles and
-// Metadata.CompiledGoFiles, in parallel.
-func readGoFiles(ctx context.Context, s *snapshot, m *source.Metadata) (goFiles, compiledGoFiles []source.FileHandle, err error) {
-	var group errgroup.Group
-	getFileHandles := func(files []span.URI) []source.FileHandle {
-		fhs := make([]source.FileHandle, len(files))
-		for i, uri := range files {
-			i, uri := i, uri
-			group.Go(func() (err error) {
-				fhs[i], err = s.GetFile(ctx, uri) // ~25us
-				return
-			})
-		}
-		return fhs
-	}
-	return getFileHandles(m.GoFiles),
-		getFileHandles(m.CompiledGoFiles),
-		group.Wait()
-}
-
-func (s *snapshot) workspaceParseMode(id PackageID) source.ParseMode {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	_, ws := s.workspacePackages[id]
-	if !ws {
-		return source.ParseExported
-	}
-	if s.view.Options().MemoryMode == source.ModeNormal {
-		return source.ParseFull
-	}
-	if s.isActiveLocked(id) {
-		return source.ParseFull
-	}
-	return source.ParseExported
-}
-
-// computePackageKey returns a key representing the act of type checking
-// a package named id containing the specified files, metadata, and
-// combined dependency hash.
-func computePackageKey(id PackageID, files []source.FileHandle, m *source.Metadata, depsKey source.Hash, mode source.ParseMode, experimentalKey bool) packageHandleKey {
-	// TODO(adonovan): opt: no need to materalize the bytes; hash them directly.
-	// Also, use field separators to avoid spurious collisions.
-	b := bytes.NewBuffer(nil)
-	b.WriteString(string(id))
-	if m.Module != nil {
-		b.WriteString(m.Module.GoVersion) // go version affects type check errors.
-	}
-	if !experimentalKey {
-		// cfg was used to produce the other hashed inputs (package ID, parsed Go
-		// files, and deps). It should not otherwise affect the inputs to the type
-		// checker, so this experiment omits it. This should increase cache hits on
-		// the daemon as cfg contains the environment and working directory.
-		hc := hashConfig(m.Config)
-		b.Write(hc[:])
-	}
-	b.WriteByte(byte(mode))
-	b.Write(depsKey[:])
-	for _, file := range files {
-		b.WriteString(file.FileIdentity().String())
-	}
-	// Metadata errors are interpreted and memoized on the computed package, so
-	// we must hash them into the key here.
-	//
-	// TODO(rfindley): handle metadata diagnostics independently from
-	// type-checking diagnostics.
-	for _, err := range m.Errors {
-		b.WriteString(err.Msg)
-		b.WriteString(err.Pos)
-		b.WriteRune(rune(err.Kind))
-	}
-	return packageHandleKey(source.HashOf(b.Bytes()))
-}
-
-// hashConfig returns the hash for the *packages.Config.
-func hashConfig(config *packages.Config) source.Hash {
-	// TODO(adonovan): opt: don't materialize the bytes; hash them directly.
-	// Also, use sound field separators to avoid collisions.
-	var b bytes.Buffer
-
-	// Dir, Mode, Env, BuildFlags are the parts of the config that can change.
-	b.WriteString(config.Dir)
-	b.WriteRune(rune(config.Mode))
-
-	for _, e := range config.Env {
-		b.WriteString(e)
-	}
-	for _, f := range config.BuildFlags {
-		b.WriteString(f)
-	}
-	return source.HashOf(b.Bytes())
-}
-
-// await waits for typeCheckImpl to complete and returns its result.
-func (ph *packageHandle) await(ctx context.Context, s *snapshot) (*pkg, error) {
-	v, err := s.awaitPromise(ctx, ph.promise)
-	if err != nil {
-		return nil, err
-	}
-	data := v.(typeCheckResult)
-	return data.pkg, data.err
-}
-
-func (ph *packageHandle) CompiledGoFiles() []span.URI {
-	return ph.m.CompiledGoFiles
-}
-
-func (ph *packageHandle) ID() string {
-	return string(ph.m.ID)
-}
-
-func (ph *packageHandle) cached() (*pkg, error) {
-	v := ph.promise.Cached()
-	if v == nil {
-		return nil, fmt.Errorf("no cached type information for %s", ph.m.PkgPath)
-	}
-	data := v.(typeCheckResult)
-	return data.pkg, data.err
-}
-
-// typeCheckImpl type checks the parsed source files in compiledGoFiles.
-// (The resulting pkg also holds the parsed but not type-checked goFiles.)
-// deps holds the future results of type-checking the direct dependencies.
-func typeCheckImpl(ctx context.Context, snapshot *snapshot, goFiles, compiledGoFiles []source.FileHandle, m *source.Metadata, mode source.ParseMode, deps map[PackageID]*packageHandle) (*pkg, error) {
-	// Start type checking of direct dependencies,
-	// in parallel and asynchronously.
-	// As the type checker imports each of these
-	// packages, it will wait for its completion.
-	var wg sync.WaitGroup
-	for _, dep := range deps {
-		wg.Add(1)
-		go func(dep *packageHandle) {
-			dep.await(ctx, snapshot) // ignore result
-			wg.Done()
-		}(dep)
-	}
-	// The 'defer' below is unusual but intentional:
-	// it is not necessary that each call to dep.check
-	// complete before type checking begins, as the type
-	// checker will wait for those it needs. But they do
-	// need to complete before this function returns and
-	// the snapshot is possibly destroyed.
-	defer wg.Wait()
-
-	var filter *unexportedFilter
-	if mode == source.ParseExported {
-		filter = &unexportedFilter{uses: map[string]bool{}}
-	}
-	pkg, err := doTypeCheck(ctx, snapshot, goFiles, compiledGoFiles, m, mode, deps, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	if mode == source.ParseExported {
-		// The AST filtering is a little buggy and may remove things it
-		// shouldn't. If we only got undeclared name errors, try one more
-		// time keeping those names.
-		missing, unexpected := filter.ProcessErrors(pkg.typeErrors)
-		if len(unexpected) == 0 && len(missing) != 0 {
-			pkg, err = doTypeCheck(ctx, snapshot, goFiles, compiledGoFiles, m, mode, deps, filter)
-			if err != nil {
-				return nil, err
-			}
-			missing, unexpected = filter.ProcessErrors(pkg.typeErrors)
-		}
-		if len(unexpected) != 0 || len(missing) != 0 {
-			pkg, err = doTypeCheck(ctx, snapshot, goFiles, compiledGoFiles, m, mode, deps, nil)
-			if err != nil {
-				return nil, err
-			}
-		}
-	}
-	// If this is a replaced module in the workspace, the version is
-	// meaningless, and we don't want clients to access it.
-	if m.Module != nil {
-		version := m.Module.Version
-		if source.IsWorkspaceModuleVersion(version) {
-			version = ""
-		}
-		pkg.version = &module.Version{
-			Path:    m.Module.Path,
-			Version: version,
-		}
-	}
-
-	// We don't care about a package's errors unless we have parsed it in full.
-	if mode != source.ParseFull {
-		return pkg, nil
-	}
-
-	for _, e := range m.Errors {
-		diags, err := goPackagesErrorDiagnostics(snapshot, pkg, e)
-		if err != nil {
-			event.Error(ctx, "unable to compute positions for list errors", err, tag.Package.Of(string(pkg.ID())))
-			continue
-		}
-		pkg.diagnostics = append(pkg.diagnostics, diags...)
-	}
-
-	// Our heuristic for whether to show type checking errors is:
-	//  + If any file was 'fixed', don't show type checking errors as we
-	//    can't guarantee that they reference accurate locations in the source.
-	//  + If there is a parse error _in the current file_, suppress type
-	//    errors in that file.
-	//  + Otherwise, show type errors even in the presence of parse errors in
-	//    other package files. go/types attempts to suppress follow-on errors
-	//    due to bad syntax, so on balance type checking errors still provide
-	//    a decent signal/noise ratio as long as the file in question parses.
-
-	// Track URIs with parse errors so that we can suppress type errors for these
-	// files.
-	unparseable := map[span.URI]bool{}
-	for _, e := range pkg.parseErrors {
-		diags, err := parseErrorDiagnostics(snapshot, pkg, e)
-		if err != nil {
-			event.Error(ctx, "unable to compute positions for parse errors", err, tag.Package.Of(string(pkg.ID())))
-			continue
-		}
-		for _, diag := range diags {
-			unparseable[diag.URI] = true
-			pkg.diagnostics = append(pkg.diagnostics, diag)
-		}
-	}
-
-	if pkg.hasFixedFiles {
-		return pkg, nil
-	}
-
-	unexpanded := pkg.typeErrors
-	pkg.typeErrors = nil
-	for _, e := range expandErrors(unexpanded, snapshot.View().Options().RelatedInformationSupported) {
-		diags, err := typeErrorDiagnostics(snapshot, pkg, e)
-		if err != nil {
-			event.Error(ctx, "unable to compute positions for type errors", err, tag.Package.Of(string(pkg.ID())))
-			continue
-		}
-		pkg.typeErrors = append(pkg.typeErrors, e.primary)
-		for _, diag := range diags {
-			// If the file didn't parse cleanly, it is highly likely that type
-			// checking errors will be confusing or redundant. But otherwise, type
-			// checking usually provides a good enough signal to include.
-			if !unparseable[diag.URI] {
-				pkg.diagnostics = append(pkg.diagnostics, diag)
-			}
-		}
-	}
-
-	depsErrors, err := snapshot.depsErrors(ctx, pkg)
-	if err != nil {
-		return nil, err
-	}
-	pkg.diagnostics = append(pkg.diagnostics, depsErrors...)
-
-	return pkg, nil
-}
-
-var goVersionRx = regexp.MustCompile(`^go([1-9][0-9]*)\.(0|[1-9][0-9]*)$`)
-
-func doTypeCheck(ctx context.Context, snapshot *snapshot, goFiles, compiledGoFiles []source.FileHandle, m *source.Metadata, mode source.ParseMode, deps map[PackageID]*packageHandle, astFilter *unexportedFilter) (*pkg, error) {
-	ctx, done := event.Start(ctx, "cache.typeCheck", tag.Package.Of(string(m.ID)))
-	defer done()
-
-	pkg := &pkg{
-		m:     m,
-		mode:  mode,
-		fset:  snapshot.FileSet(), // must match parse call below (snapshot.ParseGo for now)
-		deps:  make(map[PackageID]*pkg),
-		types: types.NewPackage(string(m.PkgPath), string(m.Name)),
-		typesInfo: &types.Info{
-			Types:      make(map[ast.Expr]types.TypeAndValue),
-			Defs:       make(map[*ast.Ident]types.Object),
-			Uses:       make(map[*ast.Ident]types.Object),
-			Implicits:  make(map[ast.Node]types.Object),
-			Selections: make(map[*ast.SelectorExpr]*types.Selection),
-			Scopes:     make(map[ast.Node]*types.Scope),
-		},
-	}
-	typeparams.InitInstanceInfo(pkg.typesInfo)
-
-	// Parse the non-compiled GoFiles. (These aren't presented to
-	// the type checker but are part of the returned pkg.)
-	// TODO(adonovan): opt: parallelize parsing.
-	for _, fh := range goFiles {
-		goMode := mode
-		if mode == source.ParseExported {
-			// This package is being loaded only for type information,
-			// to which non-compiled Go files are irrelevant,
-			// so parse only the header.
-			goMode = source.ParseHeader
-		}
-		pgf, err := snapshot.ParseGo(ctx, fh, goMode)
-		if err != nil {
-			return nil, err
-		}
-		pkg.goFiles = append(pkg.goFiles, pgf)
-	}
-
-	// Parse the CompiledGoFiles: those seen by the compiler/typechecker.
-	if err := parseCompiledGoFiles(ctx, compiledGoFiles, snapshot, mode, pkg, astFilter); err != nil {
-		return nil, err
-	}
-
-	// Use the default type information for the unsafe package.
-	if m.PkgPath == "unsafe" {
-		// Don't type check Unsafe: it's unnecessary, and doing so exposes a data
-		// race to Unsafe.completed.
-		pkg.types = types.Unsafe
-		return pkg, nil
-	}
-
-	if len(m.CompiledGoFiles) == 0 {
-		// No files most likely means go/packages failed. Try to attach error
-		// messages to the file as much as possible.
-		var found bool
-		for _, e := range m.Errors {
-			srcDiags, err := goPackagesErrorDiagnostics(snapshot, pkg, e)
-			if err != nil {
-				continue
-			}
-			found = true
-			pkg.diagnostics = append(pkg.diagnostics, srcDiags...)
-		}
-		if found {
-			return pkg, nil
-		}
-		return nil, fmt.Errorf("no parsed files for package %s, expected: %v, errors: %v", pkg.m.PkgPath, pkg.compiledGoFiles, m.Errors)
-	}
-
-	cfg := &types.Config{
-		Error: func(e error) {
-			pkg.typeErrors = append(pkg.typeErrors, e.(types.Error))
-		},
-		Importer: importerFunc(func(path string) (*types.Package, error) {
-			// While all of the import errors could be reported
-			// based on the metadata before we start type checking,
-			// reporting them via types.Importer places the errors
-			// at the correct source location.
-			id, ok := pkg.m.DepsByImpPath[ImportPath(path)]
-			if !ok {
-				// If the import declaration is broken,
-				// go list may fail to report metadata about it.
-				// See TestFixImportDecl for an example.
-				return nil, fmt.Errorf("missing metadata for import of %q", path)
-			}
-			dep, ok := deps[id] // id may be ""
-			if !ok {
-				return nil, snapshot.missingPkgError(path)
-			}
-			if !source.IsValidImport(m.PkgPath, dep.m.PkgPath) {
-				return nil, fmt.Errorf("invalid use of internal package %s", path)
-			}
-			depPkg, err := dep.await(ctx, snapshot)
-			if err != nil {
-				return nil, err
-			}
-			pkg.deps[depPkg.m.ID] = depPkg
-			return depPkg.types, nil
-		}),
-	}
-	if pkg.m.Module != nil && pkg.m.Module.GoVersion != "" {
-		goVersion := "go" + pkg.m.Module.GoVersion
-		// types.NewChecker panics if GoVersion is invalid. An unparsable mod
-		// file should probably stop us before we get here, but double check
-		// just in case.
-		if goVersionRx.MatchString(goVersion) {
-			typesinternal.SetGoVersion(cfg, goVersion)
-		}
-	}
-
-	if mode != source.ParseFull {
-		cfg.DisableUnusedImportCheck = true
-		cfg.IgnoreFuncBodies = true
-	}
-
-	// We want to type check cgo code if go/types supports it.
-	// We passed typecheckCgo to go/packages when we Loaded.
-	typesinternal.SetUsesCgo(cfg)
-
-	check := types.NewChecker(cfg, pkg.fset, pkg.types, pkg.typesInfo)
-
-	var files []*ast.File
-	for _, cgf := range pkg.compiledGoFiles {
-		files = append(files, cgf.File)
-	}
-
-	// Type checking errors are handled via the config, so ignore them here.
-	_ = check.Files(files) // 50us-15ms, depending on size of package
-
-	// If the context was cancelled, we may have returned a ton of transient
-	// errors to the type checker. Swallow them.
-	if ctx.Err() != nil {
-		return nil, ctx.Err()
-	}
-	return pkg, nil
-}
-
-func parseCompiledGoFiles(ctx context.Context, compiledGoFiles []source.FileHandle, snapshot *snapshot, mode source.ParseMode, pkg *pkg, astFilter *unexportedFilter) error {
-	// TODO(adonovan): opt: parallelize this loop, which takes 1-25ms.
-	for _, fh := range compiledGoFiles {
-		var pgf *source.ParsedGoFile
-		var err error
-		// Only parse Full through the cache -- we need to own Exported ASTs
-		// to prune them.
-		if mode == source.ParseFull {
-			pgf, err = snapshot.ParseGo(ctx, fh, mode)
-		} else {
-			pgf, err = parseGoImpl(ctx, pkg.fset, fh, mode) // ~20us/KB
-		}
-		if err != nil {
-			return err
-		}
-		pkg.compiledGoFiles = append(pkg.compiledGoFiles, pgf)
-		if pgf.ParseErr != nil {
-			pkg.parseErrors = append(pkg.parseErrors, pgf.ParseErr)
-		}
-		// If we have fixed parse errors in any of the files, we should hide type
-		// errors, as they may be completely nonsensical.
-		pkg.hasFixedFiles = pkg.hasFixedFiles || pgf.Fixed
-	}
-
-	// Optionally remove parts that don't affect the exported API.
-	if mode == source.ParseExported {
-		// TODO(adonovan): opt: experiment with pre-parser
-		// trimming, either a scanner-based implementation
-		// such as https://go.dev/play/p/KUrObH1YkX8 (~31%
-		// speedup), or a byte-oriented implementation (2x
-		// speedup).
-		if astFilter != nil {
-			// aggressive pruning based on reachability
-			var files []*ast.File
-			for _, cgf := range pkg.compiledGoFiles {
-				files = append(files, cgf.File)
-			}
-			astFilter.Filter(files)
-		} else {
-			// simple trimming of function bodies
-			for _, cgf := range pkg.compiledGoFiles {
-				trimAST(cgf.File)
-			}
-		}
-	}
-
-	return nil
-}
-
-func (s *snapshot) depsErrors(ctx context.Context, pkg *pkg) ([]*source.Diagnostic, error) {
-	// Select packages that can't be found, and were imported in non-workspace packages.
-	// Workspace packages already show their own errors.
-	var relevantErrors []*packagesinternal.PackageError
-	for _, depsError := range pkg.m.DepsErrors {
-		// Up to Go 1.15, the missing package was included in the stack, which
-		// was presumably a bug. We want the next one up.
-		directImporterIdx := len(depsError.ImportStack) - 1
-		if s.view.goversion < 15 {
-			directImporterIdx = len(depsError.ImportStack) - 2
-		}
-		if directImporterIdx < 0 {
-			continue
-		}
-
-		directImporter := depsError.ImportStack[directImporterIdx]
-		if s.isWorkspacePackage(PackageID(directImporter)) {
-			continue
-		}
-		relevantErrors = append(relevantErrors, depsError)
-	}
-
-	// Don't build the import index for nothing.
-	if len(relevantErrors) == 0 {
-		return nil, nil
-	}
-
-	// Build an index of all imports in the package.
-	type fileImport struct {
-		cgf *source.ParsedGoFile
-		imp *ast.ImportSpec
-	}
-	allImports := map[string][]fileImport{}
-	for _, cgf := range pkg.compiledGoFiles {
-		// TODO(adonovan): modify Imports() to accept a single token.File (cgf.Tok).
-		for _, group := range astutil.Imports(s.FileSet(), cgf.File) {
-			for _, imp := range group {
-				if imp.Path == nil {
-					continue
-				}
-				path := strings.Trim(imp.Path.Value, `"`)
-				allImports[path] = append(allImports[path], fileImport{cgf, imp})
-			}
-		}
-	}
-
-	// Apply a diagnostic to any import involved in the error, stopping once
-	// we reach the workspace.
-	var errors []*source.Diagnostic
-	for _, depErr := range relevantErrors {
-		for i := len(depErr.ImportStack) - 1; i >= 0; i-- {
-			item := depErr.ImportStack[i]
-			if s.isWorkspacePackage(PackageID(item)) {
-				break
-			}
-
-			for _, imp := range allImports[item] {
-				rng, err := source.NewMappedRange(imp.cgf.Mapper, imp.imp.Pos(), imp.imp.End()).Range()
-				if err != nil {
-					return nil, err
-				}
-				fixes, err := goGetQuickFixes(s, imp.cgf.URI, item)
-				if err != nil {
-					return nil, err
-				}
-				errors = append(errors, &source.Diagnostic{
-					URI:            imp.cgf.URI,
-					Range:          rng,
-					Severity:       protocol.SeverityError,
-					Source:         source.TypeError,
-					Message:        fmt.Sprintf("error while importing %v: %v", item, depErr.Err),
-					SuggestedFixes: fixes,
-				})
-			}
-		}
-	}
-
-	if len(pkg.compiledGoFiles) == 0 {
-		return errors, nil
-	}
-	mod := s.GoModForFile(pkg.compiledGoFiles[0].URI)
-	if mod == "" {
-		return errors, nil
-	}
-	fh, err := s.GetFile(ctx, mod)
-	if err != nil {
-		return nil, err
-	}
-	pm, err := s.ParseMod(ctx, fh)
-	if err != nil {
-		return nil, err
-	}
-
-	// Add a diagnostic to the module that contained the lowest-level import of
-	// the missing package.
-	for _, depErr := range relevantErrors {
-		for i := len(depErr.ImportStack) - 1; i >= 0; i-- {
-			item := depErr.ImportStack[i]
-			m := s.Metadata(PackageID(item))
-			if m == nil || m.Module == nil {
-				continue
-			}
-			modVer := module.Version{Path: m.Module.Path, Version: m.Module.Version}
-			reference := findModuleReference(pm.File, modVer)
-			if reference == nil {
-				continue
-			}
-			rng, err := pm.Mapper.OffsetRange(reference.Start.Byte, reference.End.Byte)
-			if err != nil {
-				return nil, err
-			}
-			fixes, err := goGetQuickFixes(s, pm.URI, item)
-			if err != nil {
-				return nil, err
-			}
-			errors = append(errors, &source.Diagnostic{
-				URI:            pm.URI,
-				Range:          rng,
-				Severity:       protocol.SeverityError,
-				Source:         source.TypeError,
-				Message:        fmt.Sprintf("error while importing %v: %v", item, depErr.Err),
-				SuggestedFixes: fixes,
-			})
-			break
-		}
-	}
-	return errors, nil
-}
-
-// missingPkgError returns an error message for a missing package that varies
-// based on the user's workspace mode.
-func (s *snapshot) missingPkgError(pkgPath string) error {
-	var b strings.Builder
-	if s.workspaceMode()&moduleMode == 0 {
-		gorootSrcPkg := filepath.FromSlash(filepath.Join(s.view.goroot, "src", pkgPath))
-		fmt.Fprintf(&b, "cannot find package %q in any of \n\t%s (from $GOROOT)", pkgPath, gorootSrcPkg)
-		for _, gopath := range filepath.SplitList(s.view.gopath) {
-			gopathSrcPkg := filepath.FromSlash(filepath.Join(gopath, "src", pkgPath))
-			fmt.Fprintf(&b, "\n\t%s (from $GOPATH)", gopathSrcPkg)
-		}
-	} else {
-		fmt.Fprintf(&b, "no required module provides package %q", pkgPath)
-		if err := s.getInitializationError(); err != nil {
-			fmt.Fprintf(&b, "\n(workspace configuration error: %s)", err.MainError)
-		}
-	}
-	return errors.New(b.String())
-}
-
-type extendedError struct {
-	primary     types.Error
-	secondaries []types.Error
-}
-
-func (e extendedError) Error() string {
-	return e.primary.Error()
-}
-
-// expandErrors duplicates "secondary" errors by mapping them to their main
-// error. Some errors returned by the type checker are followed by secondary
-// errors which give more information about the error. These are errors in
-// their own right, and they are marked by starting with \t. For instance, when
-// there is a multiply-defined function, the secondary error points back to the
-// definition first noticed.
-//
-// This function associates the secondary error with its primary error, which can
-// then be used as RelatedInformation when the error becomes a diagnostic.
-//
-// If supportsRelatedInformation is false, the secondary is instead embedded as
-// additional context in the primary error.
-func expandErrors(errs []types.Error, supportsRelatedInformation bool) []extendedError {
-	var result []extendedError
-	for i := 0; i < len(errs); {
-		original := extendedError{
-			primary: errs[i],
-		}
-		for i++; i < len(errs); i++ {
-			spl := errs[i]
-			if len(spl.Msg) == 0 || spl.Msg[0] != '\t' {
-				break
-			}
-			spl.Msg = spl.Msg[1:]
-			original.secondaries = append(original.secondaries, spl)
-		}
-
-		// Clone the error to all its related locations -- VS Code, at least,
-		// doesn't do it for us.
-		result = append(result, original)
-		for i, mainSecondary := range original.secondaries {
-			// Create the new primary error, with a tweaked message, in the
-			// secondary's location. We need to start from the secondary to
-			// capture its unexported location fields.
-			relocatedSecondary := mainSecondary
-			if supportsRelatedInformation {
-				relocatedSecondary.Msg = fmt.Sprintf("%v (see details)", original.primary.Msg)
-			} else {
-				relocatedSecondary.Msg = fmt.Sprintf("%v (this error: %v)", original.primary.Msg, mainSecondary.Msg)
-			}
-			relocatedSecondary.Soft = original.primary.Soft
-
-			// Copy over the secondary errors, noting the location of the
-			// current error we're cloning.
-			clonedError := extendedError{primary: relocatedSecondary, secondaries: []types.Error{original.primary}}
-			for j, secondary := range original.secondaries {
-				if i == j {
-					secondary.Msg += " (this error)"
-				}
-				clonedError.secondaries = append(clonedError.secondaries, secondary)
-			}
-			result = append(result, clonedError)
-		}
-
-	}
-	return result
-}
-
-// An importFunc is an implementation of the single-method
-// types.Importer interface based on a function value.
-type importerFunc func(path string) (*types.Package, error)
-
-func (f importerFunc) Import(path string) (*types.Package, error) { return f(path) }
diff -urN a/gopls/internal/lsp/cache/debug.go b/gopls/internal/lsp/cache/debug.go
--- a/gopls/internal/lsp/cache/debug.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/debug.go	1969-12-31 16:00:00
@@ -1,53 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"fmt"
-	"os"
-	"sort"
-)
-
-// This file contains helpers that can be used to instrument code while
-// debugging.
-
-// debugEnabled toggles the helpers below.
-const debugEnabled = false
-
-// If debugEnabled is true, debugf formats its arguments and prints to stderr.
-// If debugEnabled is false, it is a no-op.
-func debugf(format string, args ...interface{}) {
-	if !debugEnabled {
-		return
-	}
-	if false {
-		_ = fmt.Sprintf(format, args...) // encourage vet to validate format strings
-	}
-	fmt.Fprintf(os.Stderr, ">>> "+format+"\n", args...)
-}
-
-// If debugEnabled is true, dumpWorkspace prints a summary of workspace
-// packages to stderr. If debugEnabled is false, it is a no-op.
-func (s *snapshot) dumpWorkspace(context string) {
-	if !debugEnabled {
-		return
-	}
-
-	debugf("workspace (after %s):", context)
-	var ids []PackageID
-	for id := range s.workspacePackages {
-		ids = append(ids, id)
-	}
-
-	sort.Slice(ids, func(i, j int) bool {
-		return ids[i] < ids[j]
-	})
-
-	for _, id := range ids {
-		pkgPath := s.workspacePackages[id]
-		_, ok := s.meta.metadata[id]
-		debugf("  %s:%s (metadata: %t)", id, pkgPath, ok)
-	}
-}
diff -urN a/gopls/internal/lsp/cache/error_test.go b/gopls/internal/lsp/cache/error_test.go
--- a/gopls/internal/lsp/cache/error_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/error_test.go	1969-12-31 16:00:00
@@ -1,52 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"strings"
-	"testing"
-)
-
-func TestParseErrorMessage(t *testing.T) {
-	tests := []struct {
-		name             string
-		in               string
-		expectedFileName string
-		expectedLine     int
-		expectedColumn   int
-	}{
-		{
-			name:             "from go list output",
-			in:               "\nattributes.go:13:1: expected 'package', found 'type'",
-			expectedFileName: "attributes.go",
-			expectedLine:     13,
-			expectedColumn:   1,
-		},
-	}
-
-	for _, tt := range tests {
-		t.Run(tt.name, func(t *testing.T) {
-			spn := parseGoListError(tt.in, ".")
-			fn := spn.URI().Filename()
-
-			if !strings.HasSuffix(fn, tt.expectedFileName) {
-				t.Errorf("expected filename with suffix %v but got %v", tt.expectedFileName, fn)
-			}
-
-			if !spn.HasPosition() {
-				t.Fatalf("expected span to have position")
-			}
-
-			pos := spn.Start()
-			if pos.Line() != tt.expectedLine {
-				t.Errorf("expected line %v but got %v", tt.expectedLine, pos.Line())
-			}
-
-			if pos.Column() != tt.expectedColumn {
-				t.Errorf("expected line %v but got %v", tt.expectedLine, pos.Line())
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/cache/errors.go b/gopls/internal/lsp/cache/errors.go
--- a/gopls/internal/lsp/cache/errors.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/errors.go	1969-12-31 16:00:00
@@ -1,391 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-// This file defines routines to convert diagnostics from go list, go
-// get, go/packages, parsing, type checking, and analysis into
-// source.Diagnostic form, and suggesting quick fixes.
-
-import (
-	"fmt"
-	"go/scanner"
-	"go/types"
-	"log"
-	"regexp"
-	"strconv"
-	"strings"
-
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/analysisinternal"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/typesinternal"
-)
-
-func goPackagesErrorDiagnostics(snapshot *snapshot, pkg *pkg, e packages.Error) ([]*source.Diagnostic, error) {
-	if msg, spn, ok := parseGoListImportCycleError(snapshot, e, pkg); ok {
-		rng, err := spanToRange(pkg, spn)
-		if err != nil {
-			return nil, err
-		}
-		return []*source.Diagnostic{{
-			URI:      spn.URI(),
-			Range:    rng,
-			Severity: protocol.SeverityError,
-			Source:   source.ListError,
-			Message:  msg,
-		}}, nil
-	}
-
-	var spn span.Span
-	if e.Pos == "" {
-		spn = parseGoListError(e.Msg, pkg.m.Config.Dir)
-		// We may not have been able to parse a valid span. Apply the errors to all files.
-		if _, err := spanToRange(pkg, spn); err != nil {
-			var diags []*source.Diagnostic
-			for _, cgf := range pkg.compiledGoFiles {
-				diags = append(diags, &source.Diagnostic{
-					URI:      cgf.URI,
-					Severity: protocol.SeverityError,
-					Source:   source.ListError,
-					Message:  e.Msg,
-				})
-			}
-			return diags, nil
-		}
-	} else {
-		spn = span.ParseInDir(e.Pos, pkg.m.Config.Dir)
-	}
-
-	rng, err := spanToRange(pkg, spn)
-	if err != nil {
-		return nil, err
-	}
-	return []*source.Diagnostic{{
-		URI:      spn.URI(),
-		Range:    rng,
-		Severity: protocol.SeverityError,
-		Source:   source.ListError,
-		Message:  e.Msg,
-	}}, nil
-}
-
-func parseErrorDiagnostics(snapshot *snapshot, pkg *pkg, errList scanner.ErrorList) ([]*source.Diagnostic, error) {
-	// The first parser error is likely the root cause of the problem.
-	if errList.Len() <= 0 {
-		return nil, fmt.Errorf("no errors in %v", errList)
-	}
-	e := errList[0]
-	pgf, err := pkg.File(span.URIFromPath(e.Pos.Filename))
-	if err != nil {
-		return nil, err
-	}
-	pos := pgf.Tok.Pos(e.Pos.Offset)
-	spn, err := span.NewRange(pgf.Tok, pos, pos).Span()
-	if err != nil {
-		return nil, err
-	}
-	rng, err := spanToRange(pkg, spn)
-	if err != nil {
-		return nil, err
-	}
-	return []*source.Diagnostic{{
-		URI:      spn.URI(),
-		Range:    rng,
-		Severity: protocol.SeverityError,
-		Source:   source.ParseError,
-		Message:  e.Msg,
-	}}, nil
-}
-
-var importErrorRe = regexp.MustCompile(`could not import ([^\s]+)`)
-var unsupportedFeatureRe = regexp.MustCompile(`.*require.* go(\d+\.\d+) or later`)
-
-func typeErrorDiagnostics(snapshot *snapshot, pkg *pkg, e extendedError) ([]*source.Diagnostic, error) {
-	code, spn, err := typeErrorData(pkg, e.primary)
-	if err != nil {
-		return nil, err
-	}
-	rng, err := spanToRange(pkg, spn)
-	if err != nil {
-		return nil, err
-	}
-	diag := &source.Diagnostic{
-		URI:      spn.URI(),
-		Range:    rng,
-		Severity: protocol.SeverityError,
-		Source:   source.TypeError,
-		Message:  e.primary.Msg,
-	}
-	if code != 0 {
-		diag.Code = code.String()
-		diag.CodeHref = typesCodeHref(snapshot, code)
-	}
-	switch code {
-	case typesinternal.UnusedVar, typesinternal.UnusedImport:
-		diag.Tags = append(diag.Tags, protocol.Unnecessary)
-	}
-
-	for _, secondary := range e.secondaries {
-		_, secondarySpan, err := typeErrorData(pkg, secondary)
-		if err != nil {
-			return nil, err
-		}
-		rng, err := spanToRange(pkg, secondarySpan)
-		if err != nil {
-			return nil, err
-		}
-		diag.Related = append(diag.Related, source.RelatedInformation{
-			URI:     secondarySpan.URI(),
-			Range:   rng,
-			Message: secondary.Msg,
-		})
-	}
-
-	if match := importErrorRe.FindStringSubmatch(e.primary.Msg); match != nil {
-		diag.SuggestedFixes, err = goGetQuickFixes(snapshot, spn.URI(), match[1])
-		if err != nil {
-			return nil, err
-		}
-	}
-	if match := unsupportedFeatureRe.FindStringSubmatch(e.primary.Msg); match != nil {
-		diag.SuggestedFixes, err = editGoDirectiveQuickFix(snapshot, spn.URI(), match[1])
-		if err != nil {
-			return nil, err
-		}
-	}
-	return []*source.Diagnostic{diag}, nil
-}
-
-func goGetQuickFixes(snapshot *snapshot, uri span.URI, pkg string) ([]source.SuggestedFix, error) {
-	// Go get only supports module mode for now.
-	if snapshot.workspaceMode()&moduleMode == 0 {
-		return nil, nil
-	}
-	title := fmt.Sprintf("go get package %v", pkg)
-	cmd, err := command.NewGoGetPackageCommand(title, command.GoGetPackageArgs{
-		URI:        protocol.URIFromSpanURI(uri),
-		AddRequire: true,
-		Pkg:        pkg,
-	})
-	if err != nil {
-		return nil, err
-	}
-	return []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)}, nil
-}
-
-func editGoDirectiveQuickFix(snapshot *snapshot, uri span.URI, version string) ([]source.SuggestedFix, error) {
-	// Go mod edit only supports module mode.
-	if snapshot.workspaceMode()&moduleMode == 0 {
-		return nil, nil
-	}
-	title := fmt.Sprintf("go mod edit -go=%s", version)
-	cmd, err := command.NewEditGoDirectiveCommand(title, command.EditGoDirectiveArgs{
-		URI:     protocol.URIFromSpanURI(uri),
-		Version: version,
-	})
-	if err != nil {
-		return nil, err
-	}
-	return []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)}, nil
-}
-
-// toSourceDiagnostic converts a gobDiagnostic to "source" form.
-func toSourceDiagnostic(srcAnalyzer *source.Analyzer, gobDiag *gobDiagnostic) *source.Diagnostic {
-	kinds := srcAnalyzer.ActionKind
-	if len(srcAnalyzer.ActionKind) == 0 {
-		kinds = append(kinds, protocol.QuickFix)
-	}
-	fixes := suggestedAnalysisFixes(gobDiag, kinds)
-	if srcAnalyzer.Fix != "" {
-		cmd, err := command.NewApplyFixCommand(gobDiag.Message, command.ApplyFixArgs{
-			URI:   gobDiag.Location.URI,
-			Range: gobDiag.Location.Range,
-			Fix:   srcAnalyzer.Fix,
-		})
-		if err != nil {
-			// JSON marshalling of these argument values cannot fail.
-			log.Fatalf("internal error in NewApplyFixCommand: %v", err)
-		}
-		for _, kind := range kinds {
-			fixes = append(fixes, source.SuggestedFixFromCommand(cmd, kind))
-		}
-	}
-
-	severity := srcAnalyzer.Severity
-	if severity == 0 {
-		severity = protocol.SeverityWarning
-	}
-	diag := &source.Diagnostic{
-		// TODO(adonovan): is this sound? See dual conversion in posToLocation.
-		URI:            span.URI(gobDiag.Location.URI),
-		Range:          gobDiag.Location.Range,
-		Severity:       severity,
-		Source:         source.AnalyzerErrorKind(gobDiag.Category),
-		Message:        gobDiag.Message,
-		Related:        relatedInformation(gobDiag),
-		SuggestedFixes: fixes,
-	}
-	// If the fixes only delete code, assume that the diagnostic is reporting dead code.
-	if onlyDeletions(fixes) {
-		diag.Tags = []protocol.DiagnosticTag{protocol.Unnecessary}
-	}
-	return diag
-}
-
-// onlyDeletions returns true if all of the suggested fixes are deletions.
-func onlyDeletions(fixes []source.SuggestedFix) bool {
-	for _, fix := range fixes {
-		if fix.Command != nil {
-			return false
-		}
-		for _, edits := range fix.Edits {
-			for _, edit := range edits {
-				if edit.NewText != "" {
-					return false
-				}
-				if protocol.ComparePosition(edit.Range.Start, edit.Range.End) == 0 {
-					return false
-				}
-			}
-		}
-	}
-	return len(fixes) > 0
-}
-
-func typesCodeHref(snapshot *snapshot, code typesinternal.ErrorCode) string {
-	target := snapshot.View().Options().LinkTarget
-	return source.BuildLink(target, "golang.org/x/tools/internal/typesinternal", code.String())
-}
-
-func suggestedAnalysisFixes(diag *gobDiagnostic, kinds []protocol.CodeActionKind) []source.SuggestedFix {
-	var fixes []source.SuggestedFix
-	for _, fix := range diag.SuggestedFixes {
-		edits := make(map[span.URI][]protocol.TextEdit)
-		for _, e := range fix.TextEdits {
-			uri := span.URI(e.Location.URI)
-			edits[uri] = append(edits[uri], protocol.TextEdit{
-				Range:   e.Location.Range,
-				NewText: string(e.NewText),
-			})
-		}
-		for _, kind := range kinds {
-			fixes = append(fixes, source.SuggestedFix{
-				Title:      fix.Message,
-				Edits:      edits,
-				ActionKind: kind,
-			})
-		}
-
-	}
-	return fixes
-}
-
-func relatedInformation(diag *gobDiagnostic) []source.RelatedInformation {
-	var out []source.RelatedInformation
-	for _, related := range diag.Related {
-		out = append(out, source.RelatedInformation{
-			URI:     span.URI(related.Location.URI),
-			Range:   related.Location.Range,
-			Message: related.Message,
-		})
-	}
-	return out
-}
-
-func typeErrorData(pkg *pkg, terr types.Error) (typesinternal.ErrorCode, span.Span, error) {
-	ecode, start, end, ok := typesinternal.ReadGo116ErrorData(terr)
-	if !ok {
-		start, end = terr.Pos, terr.Pos
-		ecode = 0
-	}
-	// go/types may return invalid positions in some cases, such as
-	// in errors on tokens missing from the syntax tree.
-	if !start.IsValid() {
-		return 0, span.Span{}, fmt.Errorf("type error (%q, code %d, go116=%t) without position", terr.Msg, ecode, ok)
-	}
-	// go/types errors retain their FileSet.
-	// Sanity-check that we're using the right one.
-	fset := pkg.FileSet()
-	if fset != terr.Fset {
-		return 0, span.Span{}, bug.Errorf("wrong FileSet for type error")
-	}
-	posn := safetoken.StartPosition(fset, start)
-	if !posn.IsValid() {
-		return 0, span.Span{}, fmt.Errorf("position %d of type error %q (code %q) not found in FileSet", start, start, terr)
-	}
-	pgf, err := pkg.File(span.URIFromPath(posn.Filename))
-	if err != nil {
-		return 0, span.Span{}, err
-	}
-	if !end.IsValid() || end == start {
-		end = analysisinternal.TypeErrorEndPos(fset, pgf.Src, start)
-	}
-	spn, err := span.FileSpan(pgf.Mapper.TokFile, start, end)
-	if err != nil {
-		return 0, span.Span{}, err
-	}
-	return ecode, spn, nil
-}
-
-// spanToRange converts a span.Span to a protocol.Range,
-// assuming that the span belongs to the package whose diagnostics are being computed.
-func spanToRange(pkg *pkg, spn span.Span) (protocol.Range, error) {
-	pgf, err := pkg.File(spn.URI())
-	if err != nil {
-		return protocol.Range{}, err
-	}
-	return pgf.Mapper.Range(spn)
-}
-
-// parseGoListError attempts to parse a standard `go list` error message
-// by stripping off the trailing error message.
-//
-// It works only on errors whose message is prefixed by colon,
-// followed by a space (": "). For example:
-//
-//	attributes.go:13:1: expected 'package', found 'type'
-func parseGoListError(input, wd string) span.Span {
-	input = strings.TrimSpace(input)
-	msgIndex := strings.Index(input, ": ")
-	if msgIndex < 0 {
-		return span.Parse(input)
-	}
-	return span.ParseInDir(input[:msgIndex], wd)
-}
-
-func parseGoListImportCycleError(snapshot *snapshot, e packages.Error, pkg *pkg) (string, span.Span, bool) {
-	re := regexp.MustCompile(`(.*): import stack: \[(.+)\]`)
-	matches := re.FindStringSubmatch(strings.TrimSpace(e.Msg))
-	if len(matches) < 3 {
-		return e.Msg, span.Span{}, false
-	}
-	msg := matches[1]
-	importList := strings.Split(matches[2], " ")
-	// Since the error is relative to the current package. The import that is causing
-	// the import cycle error is the second one in the list.
-	if len(importList) < 2 {
-		return msg, span.Span{}, false
-	}
-	// Imports have quotation marks around them.
-	circImp := strconv.Quote(importList[1])
-	for _, cgf := range pkg.compiledGoFiles {
-		// Search file imports for the import that is causing the import cycle.
-		for _, imp := range cgf.File.Imports {
-			if imp.Path.Value == circImp {
-				spn, err := span.NewRange(cgf.Tok, imp.Pos(), imp.End()).Span()
-				if err != nil {
-					return msg, span.Span{}, false
-				}
-				return msg, spn, true
-			}
-		}
-	}
-	return msg, span.Span{}, false
-}
diff -urN a/gopls/internal/lsp/cache/graph.go b/gopls/internal/lsp/cache/graph.go
--- a/gopls/internal/lsp/cache/graph.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/graph.go	1969-12-31 16:00:00
@@ -1,124 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// A metadataGraph is an immutable and transitively closed import
-// graph of Go packages, as obtained from go/packages.
-type metadataGraph struct {
-	// metadata maps package IDs to their associated metadata.
-	metadata map[PackageID]*source.Metadata
-
-	// importedBy maps package IDs to the list of packages that import them.
-	importedBy map[PackageID][]PackageID
-
-	// ids maps file URIs to package IDs, sorted by (!valid, cli, packageID).
-	// A single file may belong to multiple packages due to tests packages.
-	ids map[span.URI][]PackageID
-}
-
-// Clone creates a new metadataGraph, applying the given updates to the
-// receiver.
-func (g *metadataGraph) Clone(updates map[PackageID]*source.Metadata) *metadataGraph {
-	if len(updates) == 0 {
-		// Optimization: since the graph is immutable, we can return the receiver.
-		return g
-	}
-	result := &metadataGraph{metadata: make(map[PackageID]*source.Metadata, len(g.metadata))}
-	// Copy metadata.
-	for id, m := range g.metadata {
-		result.metadata[id] = m
-	}
-	for id, m := range updates {
-		if m == nil {
-			delete(result.metadata, id)
-		} else {
-			result.metadata[id] = m
-		}
-	}
-	result.build()
-	return result
-}
-
-// build constructs g.importedBy and g.uris from g.metadata.
-func (g *metadataGraph) build() {
-	// Build the import graph.
-	g.importedBy = make(map[PackageID][]PackageID)
-	for id, m := range g.metadata {
-		for _, depID := range m.DepsByPkgPath {
-			g.importedBy[depID] = append(g.importedBy[depID], id)
-		}
-	}
-
-	// Collect file associations.
-	g.ids = make(map[span.URI][]PackageID)
-	for id, m := range g.metadata {
-		uris := map[span.URI]struct{}{}
-		for _, uri := range m.CompiledGoFiles {
-			uris[uri] = struct{}{}
-		}
-		for _, uri := range m.GoFiles {
-			uris[uri] = struct{}{}
-		}
-		for uri := range uris {
-			g.ids[uri] = append(g.ids[uri], id)
-		}
-	}
-
-	// Sort and filter file associations.
-	for uri, ids := range g.ids {
-		sort.Slice(ids, func(i, j int) bool {
-			cli := source.IsCommandLineArguments(ids[i])
-			clj := source.IsCommandLineArguments(ids[j])
-			if cli != clj {
-				return clj
-			}
-
-			// 2. packages appear in name order.
-			return ids[i] < ids[j]
-		})
-
-		// Choose the best IDs for each URI, according to the following rules:
-		//  - If there are any valid real packages, choose them.
-		//  - Else, choose the first valid command-line-argument package, if it exists.
-		//
-		// TODO(rfindley): it might be better to track all IDs here, and exclude
-		// them later when type checking, but this is the existing behavior.
-		for i, id := range ids {
-			// If we've seen *anything* prior to command-line arguments package, take
-			// it. Note that ids[0] may itself be command-line-arguments.
-			if i > 0 && source.IsCommandLineArguments(id) {
-				g.ids[uri] = ids[:i]
-				break
-			}
-		}
-	}
-}
-
-// reverseReflexiveTransitiveClosure returns a new mapping containing the
-// metadata for the specified packages along with any package that
-// transitively imports one of them, keyed by ID, including all the initial packages.
-func (g *metadataGraph) reverseReflexiveTransitiveClosure(ids ...PackageID) map[PackageID]*source.Metadata {
-	seen := make(map[PackageID]*source.Metadata)
-	var visitAll func([]PackageID)
-	visitAll = func(ids []PackageID) {
-		for _, id := range ids {
-			if seen[id] == nil {
-				if m := g.metadata[id]; m != nil {
-					seen[id] = m
-					visitAll(g.importedBy[id])
-				}
-			}
-		}
-	}
-	visitAll(ids)
-	return seen
-}
diff -urN a/gopls/internal/lsp/cache/imports.go b/gopls/internal/lsp/cache/imports.go
--- a/gopls/internal/lsp/cache/imports.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/imports.go	1969-12-31 16:00:00
@@ -1,212 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"fmt"
-	"os"
-	"reflect"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/keys"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/imports"
-)
-
-type importsState struct {
-	ctx context.Context
-
-	mu                     sync.Mutex
-	processEnv             *imports.ProcessEnv
-	cleanupProcessEnv      func()
-	cacheRefreshDuration   time.Duration
-	cacheRefreshTimer      *time.Timer
-	cachedModFileHash      source.Hash
-	cachedBuildFlags       []string
-	cachedDirectoryFilters []string
-}
-
-func (s *importsState) runProcessEnvFunc(ctx context.Context, snapshot *snapshot, fn func(*imports.Options) error) error {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	// Find the hash of active mod files, if any. Using the unsaved content
-	// is slightly wasteful, since we'll drop caches a little too often, but
-	// the mod file shouldn't be changing while people are autocompleting.
-	//
-	// TODO(rfindley): consider instead hashing on-disk modfiles here.
-	var modFileHash source.Hash
-	for m := range snapshot.workspace.ActiveModFiles() {
-		fh, err := snapshot.GetFile(ctx, m)
-		if err != nil {
-			return err
-		}
-		modFileHash.XORWith(fh.FileIdentity().Hash)
-	}
-
-	// view.goEnv is immutable -- changes make a new view. Options can change.
-	// We can't compare build flags directly because we may add -modfile.
-	snapshot.view.optionsMu.Lock()
-	localPrefix := snapshot.view.options.Local
-	currentBuildFlags := snapshot.view.options.BuildFlags
-	currentDirectoryFilters := snapshot.view.options.DirectoryFilters
-	changed := !reflect.DeepEqual(currentBuildFlags, s.cachedBuildFlags) ||
-		snapshot.view.options.VerboseOutput != (s.processEnv.Logf != nil) ||
-		modFileHash != s.cachedModFileHash ||
-		!reflect.DeepEqual(snapshot.view.options.DirectoryFilters, s.cachedDirectoryFilters)
-	snapshot.view.optionsMu.Unlock()
-
-	// If anything relevant to imports has changed, clear caches and
-	// update the processEnv. Clearing caches blocks on any background
-	// scans.
-	if changed {
-		// As a special case, skip cleanup the first time -- we haven't fully
-		// initialized the environment yet and calling GetResolver will do
-		// unnecessary work and potentially mess up the go.mod file.
-		if s.cleanupProcessEnv != nil {
-			if resolver, err := s.processEnv.GetResolver(); err == nil {
-				if modResolver, ok := resolver.(*imports.ModuleResolver); ok {
-					modResolver.ClearForNewMod()
-				}
-			}
-			s.cleanupProcessEnv()
-		}
-		s.cachedModFileHash = modFileHash
-		s.cachedBuildFlags = currentBuildFlags
-		s.cachedDirectoryFilters = currentDirectoryFilters
-		var err error
-		s.cleanupProcessEnv, err = s.populateProcessEnv(ctx, snapshot)
-		if err != nil {
-			return err
-		}
-	}
-
-	// Run the user function.
-	opts := &imports.Options{
-		// Defaults.
-		AllErrors:   true,
-		Comments:    true,
-		Fragment:    true,
-		FormatOnly:  false,
-		TabIndent:   true,
-		TabWidth:    8,
-		Env:         s.processEnv,
-		LocalPrefix: localPrefix,
-	}
-
-	if err := fn(opts); err != nil {
-		return err
-	}
-
-	if s.cacheRefreshTimer == nil {
-		// Don't refresh more than twice per minute.
-		delay := 30 * time.Second
-		// Don't spend more than a couple percent of the time refreshing.
-		if adaptive := 50 * s.cacheRefreshDuration; adaptive > delay {
-			delay = adaptive
-		}
-		s.cacheRefreshTimer = time.AfterFunc(delay, s.refreshProcessEnv)
-	}
-
-	return nil
-}
-
-// populateProcessEnv sets the dynamically configurable fields for the view's
-// process environment. Assumes that the caller is holding the s.view.importsMu.
-func (s *importsState) populateProcessEnv(ctx context.Context, snapshot *snapshot) (cleanup func(), err error) {
-	pe := s.processEnv
-
-	if snapshot.view.Options().VerboseOutput {
-		pe.Logf = func(format string, args ...interface{}) {
-			event.Log(ctx, fmt.Sprintf(format, args...))
-		}
-	} else {
-		pe.Logf = nil
-	}
-
-	// Extract invocation details from the snapshot to use with goimports.
-	//
-	// TODO(rfindley): refactor to extract the necessary invocation logic into
-	// separate functions. Using goCommandInvocation is unnecessarily indirect,
-	// and has led to memory leaks in the past, when the snapshot was
-	// unintentionally held past its lifetime.
-	_, inv, cleanupInvocation, err := snapshot.goCommandInvocation(ctx, source.LoadWorkspace, &gocommand.Invocation{
-		WorkingDir: snapshot.view.rootURI.Filename(),
-	})
-	if err != nil {
-		return nil, err
-	}
-
-	pe.BuildFlags = inv.BuildFlags
-	pe.ModFlag = "readonly" // processEnv operations should not mutate the modfile
-	pe.Env = map[string]string{}
-	for _, kv := range inv.Env {
-		split := strings.SplitN(kv, "=", 2)
-		if len(split) != 2 {
-			continue
-		}
-		pe.Env[split[0]] = split[1]
-	}
-	// We don't actually use the invocation, so clean it up now.
-	cleanupInvocation()
-
-	// If the snapshot uses a synthetic workspace directory, create a copy for
-	// the lifecycle of the importsState.
-	//
-	// Notably, we cannot use the snapshot invocation working directory, as that
-	// is tied to the lifecycle of the snapshot.
-	//
-	// Otherwise return a no-op cleanup function.
-	cleanup = func() {}
-	if snapshot.usesWorkspaceDir() {
-		tmpDir, err := makeWorkspaceDir(ctx, snapshot.workspace, snapshot)
-		if err != nil {
-			return nil, err
-		}
-		pe.WorkingDir = tmpDir
-		cleanup = func() {
-			os.RemoveAll(tmpDir) // ignore error
-		}
-	} else {
-		pe.WorkingDir = snapshot.view.rootURI.Filename()
-	}
-
-	return cleanup, nil
-}
-
-func (s *importsState) refreshProcessEnv() {
-	start := time.Now()
-
-	s.mu.Lock()
-	env := s.processEnv
-	if resolver, err := s.processEnv.GetResolver(); err == nil {
-		resolver.ClearForNewScan()
-	}
-	s.mu.Unlock()
-
-	event.Log(s.ctx, "background imports cache refresh starting")
-	if err := imports.PrimeCache(context.Background(), env); err == nil {
-		event.Log(s.ctx, fmt.Sprintf("background refresh finished after %v", time.Since(start)))
-	} else {
-		event.Log(s.ctx, fmt.Sprintf("background refresh finished after %v", time.Since(start)), keys.Err.Of(err))
-	}
-	s.mu.Lock()
-	s.cacheRefreshDuration = time.Since(start)
-	s.cacheRefreshTimer = nil
-	s.mu.Unlock()
-}
-
-func (s *importsState) destroy() {
-	s.mu.Lock()
-	if s.cleanupProcessEnv != nil {
-		s.cleanupProcessEnv()
-	}
-	s.mu.Unlock()
-}
diff -urN a/gopls/internal/lsp/cache/keys.go b/gopls/internal/lsp/cache/keys.go
--- a/gopls/internal/lsp/cache/keys.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/keys.go	1969-12-31 16:00:00
@@ -1,52 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"io"
-
-	"golang.org/x/tools/internal/event/label"
-)
-
-var (
-	KeyCreateSession   = NewSessionKey("create_session", "A new session was added")
-	KeyUpdateSession   = NewSessionKey("update_session", "Updated information about a session")
-	KeyShutdownSession = NewSessionKey("shutdown_session", "A session was shut down")
-)
-
-// SessionKey represents an event label key that has a *Session value.
-type SessionKey struct {
-	name        string
-	description string
-}
-
-// NewSessionKey creates a new Key for *Session values.
-func NewSessionKey(name, description string) *SessionKey {
-	return &SessionKey{name: name, description: description}
-}
-
-func (k *SessionKey) Name() string        { return k.name }
-func (k *SessionKey) Description() string { return k.description }
-
-func (k *SessionKey) Format(w io.Writer, buf []byte, l label.Label) {
-	io.WriteString(w, k.From(l).ID())
-}
-
-// Of creates a new Label with this key and the supplied session.
-func (k *SessionKey) Of(v *Session) label.Label { return label.OfValue(k, v) }
-
-// Get can be used to get the session for the key from a label.Map.
-func (k *SessionKey) Get(lm label.Map) *Session {
-	if t := lm.Find(k); t.Valid() {
-		return k.From(t)
-	}
-	return nil
-}
-
-// From can be used to get the session value from a Label.
-func (k *SessionKey) From(t label.Label) *Session {
-	err, _ := t.UnpackValue().(*Session)
-	return err
-}
diff -urN a/gopls/internal/lsp/cache/load.go b/gopls/internal/lsp/cache/load.go
--- a/gopls/internal/lsp/cache/load.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/load.go	1969-12-31 16:00:00
@@ -1,788 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"sort"
-	"strings"
-	"sync/atomic"
-	"time"
-
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/packagesinternal"
-)
-
-var loadID uint64 // atomic identifier for loads
-
-// errNoPackages indicates that a load query matched no packages.
-var errNoPackages = errors.New("no packages returned")
-
-// load calls packages.Load for the given scopes, updating package metadata,
-// import graph, and mapped files with the result.
-//
-// The resulting error may wrap the moduleErrorMap error type, representing
-// errors associated with specific modules.
-func (s *snapshot) load(ctx context.Context, allowNetwork bool, scopes ...loadScope) (err error) {
-	id := atomic.AddUint64(&loadID, 1)
-	eventName := fmt.Sprintf("go/packages.Load #%d", id) // unique name for logging
-
-	var query []string
-	var containsDir bool // for logging
-
-	// Keep track of module query -> module path so that we can later correlate query
-	// errors with errors.
-	moduleQueries := make(map[string]string)
-	for _, scope := range scopes {
-		switch scope := scope.(type) {
-		case packageLoadScope:
-			// The only time we pass package paths is when we're doing a
-			// partial workspace load. In those cases, the paths came back from
-			// go list and should already be GOPATH-vendorized when appropriate.
-			query = append(query, string(scope))
-
-		case fileLoadScope:
-			uri := span.URI(scope)
-			fh := s.FindFile(uri)
-			if fh == nil || s.View().FileKind(fh) != source.Go {
-				// Don't try to load a file that doesn't exist, or isn't a go file.
-				continue
-			}
-			contents, err := fh.Read()
-			if err != nil {
-				continue
-			}
-			if isStandaloneFile(contents, s.view.Options().StandaloneTags) {
-				query = append(query, uri.Filename())
-			} else {
-				query = append(query, fmt.Sprintf("file=%s", uri.Filename()))
-			}
-
-		case moduleLoadScope:
-			switch scope {
-			case "std", "cmd":
-				query = append(query, string(scope))
-			default:
-				modQuery := fmt.Sprintf("%s/...", scope)
-				query = append(query, modQuery)
-				moduleQueries[modQuery] = string(scope)
-			}
-
-		case viewLoadScope:
-			// If we are outside of GOPATH, a module, or some other known
-			// build system, don't load subdirectories.
-			if !s.ValidBuildConfiguration() {
-				query = append(query, "./")
-			} else {
-				query = append(query, "./...")
-			}
-
-		default:
-			panic(fmt.Sprintf("unknown scope type %T", scope))
-		}
-		switch scope.(type) {
-		case viewLoadScope, moduleLoadScope:
-			containsDir = true
-		}
-	}
-	if len(query) == 0 {
-		return nil
-	}
-	sort.Strings(query) // for determinism
-
-	ctx, done := event.Start(ctx, "cache.view.load", tag.Query.Of(query))
-	defer done()
-
-	flags := source.LoadWorkspace
-	if allowNetwork {
-		flags |= source.AllowNetwork
-	}
-	_, inv, cleanup, err := s.goCommandInvocation(ctx, flags, &gocommand.Invocation{
-		WorkingDir: s.view.rootURI.Filename(),
-	})
-	if err != nil {
-		return err
-	}
-
-	// Set a last resort deadline on packages.Load since it calls the go
-	// command, which may hang indefinitely if it has a bug. golang/go#42132
-	// and golang/go#42255 have more context.
-	ctx, cancel := context.WithTimeout(ctx, 10*time.Minute)
-	defer cancel()
-
-	cfg := s.config(ctx, inv)
-	pkgs, err := packages.Load(cfg, query...)
-	cleanup()
-
-	// If the context was canceled, return early. Otherwise, we might be
-	// type-checking an incomplete result. Check the context directly,
-	// because go/packages adds extra information to the error.
-	if ctx.Err() != nil {
-		return ctx.Err()
-	}
-
-	// This log message is sought for by TestReloadOnlyOnce.
-	labels := append(source.SnapshotLabels(s), tag.Query.Of(query), tag.PackageCount.Of(len(pkgs)))
-	if err != nil {
-		event.Error(ctx, eventName, err, labels...)
-	} else {
-		event.Log(ctx, eventName, labels...)
-	}
-
-	if len(pkgs) == 0 {
-		if err == nil {
-			err = errNoPackages
-		}
-		return fmt.Errorf("packages.Load error: %w", err)
-	}
-
-	moduleErrs := make(map[string][]packages.Error) // module path -> errors
-	filterer := buildFilterer(s.view.rootURI.Filename(), s.view.gomodcache, s.view.Options())
-	newMetadata := make(map[PackageID]*source.Metadata)
-	for _, pkg := range pkgs {
-		// The Go command returns synthetic list results for module queries that
-		// encountered module errors.
-		//
-		// For example, given a module path a.mod, we'll query for "a.mod/..." and
-		// the go command will return a package named "a.mod/..." holding this
-		// error. Save it for later interpretation.
-		//
-		// See golang/go#50862 for more details.
-		if mod := moduleQueries[pkg.PkgPath]; mod != "" { // a synthetic result for the unloadable module
-			if len(pkg.Errors) > 0 {
-				moduleErrs[mod] = pkg.Errors
-			}
-			continue
-		}
-
-		if !containsDir || s.view.Options().VerboseOutput {
-			event.Log(ctx, eventName, append(
-				source.SnapshotLabels(s),
-				tag.Package.Of(pkg.ID),
-				tag.Files.Of(pkg.CompiledGoFiles))...)
-		}
-
-		// Ignore packages with no sources, since we will never be able to
-		// correctly invalidate that metadata.
-		if len(pkg.GoFiles) == 0 && len(pkg.CompiledGoFiles) == 0 {
-			continue
-		}
-		// Special case for the builtin package, as it has no dependencies.
-		if pkg.PkgPath == "builtin" {
-			if len(pkg.GoFiles) != 1 {
-				return fmt.Errorf("only expected 1 file for builtin, got %v", len(pkg.GoFiles))
-			}
-			s.setBuiltin(pkg.GoFiles[0])
-			continue
-		}
-		// Skip test main packages.
-		if isTestMain(pkg, s.view.gocache) {
-			continue
-		}
-		// Skip filtered packages. They may be added anyway if they're
-		// dependencies of non-filtered packages.
-		//
-		// TODO(rfindley): why exclude metadata arbitrarily here? It should be safe
-		// to capture all metadata.
-		if s.view.allFilesExcluded(pkg, filterer) {
-			continue
-		}
-		if err := buildMetadata(ctx, pkg, cfg, query, newMetadata, nil); err != nil {
-			return err
-		}
-	}
-
-	s.mu.Lock()
-
-	// Compute the minimal metadata updates (for Clone)
-	// required to preserve this invariant:
-	// for all id, s.packages.Get(id).m == s.meta.metadata[id].
-	updates := make(map[PackageID]*source.Metadata)
-	for _, m := range newMetadata {
-		if existing := s.meta.metadata[m.ID]; existing == nil {
-			updates[m.ID] = m
-			delete(s.shouldLoad, m.ID)
-		}
-	}
-	// Assert the invariant.
-	s.packages.Range(func(k, v interface{}) {
-		pk, ph := k.(packageKey), v.(*packageHandle)
-		if s.meta.metadata[pk.id] != ph.m {
-			// TODO(adonovan): upgrade to unconditional panic after Jan 2023.
-			bug.Reportf("inconsistent metadata")
-		}
-	})
-
-	event.Log(ctx, fmt.Sprintf("%s: updating metadata for %d packages", eventName, len(updates)))
-
-	s.meta = s.meta.Clone(updates)
-	s.resetIsActivePackageLocked()
-
-	s.workspacePackages = computeWorkspacePackagesLocked(s, s.meta)
-	s.dumpWorkspace("load")
-	s.mu.Unlock()
-
-	// Recompute the workspace package handle for any packages we invalidated.
-	//
-	// This is (putatively) an optimization since handle
-	// construction prefetches the content of all Go source files.
-	// It is safe to ignore errors, or omit this step entirely.
-	for _, m := range updates {
-		s.buildPackageHandle(ctx, m.ID, s.workspaceParseMode(m.ID)) // ignore error
-	}
-
-	if len(moduleErrs) > 0 {
-		return &moduleErrorMap{moduleErrs}
-	}
-
-	return nil
-}
-
-type moduleErrorMap struct {
-	errs map[string][]packages.Error // module path -> errors
-}
-
-func (m *moduleErrorMap) Error() string {
-	var paths []string // sort for stability
-	for path, errs := range m.errs {
-		if len(errs) > 0 { // should always be true, but be cautious
-			paths = append(paths, path)
-		}
-	}
-	sort.Strings(paths)
-
-	var buf bytes.Buffer
-	fmt.Fprintf(&buf, "%d modules have errors:\n", len(paths))
-	for _, path := range paths {
-		fmt.Fprintf(&buf, "\t%s:%s\n", path, m.errs[path][0].Msg)
-	}
-
-	return buf.String()
-}
-
-// workspaceLayoutErrors returns an error decribing a misconfiguration of the
-// workspace, along with related diagnostic.
-//
-// The unusual argument ordering of results is intentional: if the resulting
-// error is nil, so must be the resulting diagnostics.
-//
-// If ctx is cancelled, it may return ctx.Err(), nil.
-//
-// TODO(rfindley): separate workspace diagnostics from critical workspace
-// errors.
-func (s *snapshot) workspaceLayoutError(ctx context.Context) (error, []*source.Diagnostic) {
-	// TODO(rfindley): do we really not want to show a critical error if the user
-	// has no go.mod files?
-	if len(s.workspace.getKnownModFiles()) == 0 {
-		return nil, nil
-	}
-
-	// TODO(rfindley): both of the checks below should be delegated to the workspace.
-	if s.view.effectiveGO111MODULE() == off {
-		return nil, nil
-	}
-	if s.workspace.moduleSource != legacyWorkspace {
-		return nil, nil
-	}
-
-	// If the user has one module per view, there is nothing to warn about.
-	if s.ValidBuildConfiguration() && len(s.workspace.getKnownModFiles()) == 1 {
-		return nil, nil
-	}
-
-	// Apply diagnostics about the workspace configuration to relevant open
-	// files.
-	openFiles := s.openFiles()
-
-	// If the snapshot does not have a valid build configuration, it may be
-	// that the user has opened a directory that contains multiple modules.
-	// Check for that an warn about it.
-	if !s.ValidBuildConfiguration() {
-		var msg string
-		if s.view.goversion >= 18 {
-			msg = `gopls was not able to find modules in your workspace.
-When outside of GOPATH, gopls needs to know which modules you are working on.
-You can fix this by opening your workspace to a folder inside a Go module, or
-by using a go.work file to specify multiple modules.
-See the documentation for more information on setting up your workspace:
-https://github.com/golang/tools/blob/master/gopls/doc/workspace.md.`
-		} else {
-			msg = `gopls requires a module at the root of your workspace.
-You can work with multiple modules by upgrading to Go 1.18 or later, and using
-go workspaces (go.work files).
-See the documentation for more information on setting up your workspace:
-https://github.com/golang/tools/blob/master/gopls/doc/workspace.md.`
-		}
-		return fmt.Errorf(msg), s.applyCriticalErrorToFiles(ctx, msg, openFiles)
-	}
-
-	// If the user has one active go.mod file, they may still be editing files
-	// in nested modules. Check the module of each open file and add warnings
-	// that the nested module must be opened as a workspace folder.
-	if len(s.workspace.ActiveModFiles()) == 1 {
-		// Get the active root go.mod file to compare against.
-		var rootMod string
-		for uri := range s.workspace.ActiveModFiles() {
-			rootMod = uri.Filename()
-		}
-		rootDir := filepath.Dir(rootMod)
-		nestedModules := make(map[string][]source.VersionedFileHandle)
-		for _, fh := range openFiles {
-			mod, err := findRootPattern(ctx, filepath.Dir(fh.URI().Filename()), "go.mod", s)
-			if err != nil {
-				if ctx.Err() != nil {
-					return ctx.Err(), nil
-				}
-				continue
-			}
-			if mod == "" {
-				continue
-			}
-			if mod != rootMod && source.InDir(rootDir, mod) {
-				modDir := filepath.Dir(mod)
-				nestedModules[modDir] = append(nestedModules[modDir], fh)
-			}
-		}
-		var multiModuleMsg string
-		if s.view.goversion >= 18 {
-			multiModuleMsg = `To work on multiple modules at once, please use a go.work file.
-See https://github.com/golang/tools/blob/master/gopls/doc/workspace.md for more information on using workspaces.`
-		} else {
-			multiModuleMsg = `To work on multiple modules at once, please upgrade to Go 1.18 and use a go.work file.
-See https://github.com/golang/tools/blob/master/gopls/doc/workspace.md for more information on using workspaces.`
-		}
-		// Add a diagnostic to each file in a nested module to mark it as
-		// "orphaned". Don't show a general diagnostic in the progress bar,
-		// because the user may still want to edit a file in a nested module.
-		var srcDiags []*source.Diagnostic
-		for modDir, uris := range nestedModules {
-			msg := fmt.Sprintf("This file is in %s, which is a nested module in the %s module.\n%s", modDir, rootMod, multiModuleMsg)
-			srcDiags = append(srcDiags, s.applyCriticalErrorToFiles(ctx, msg, uris)...)
-		}
-		if len(srcDiags) != 0 {
-			return fmt.Errorf("You have opened a nested module.\n%s", multiModuleMsg), srcDiags
-		}
-	}
-	return nil, nil
-}
-
-func (s *snapshot) applyCriticalErrorToFiles(ctx context.Context, msg string, files []source.VersionedFileHandle) []*source.Diagnostic {
-	var srcDiags []*source.Diagnostic
-	for _, fh := range files {
-		// Place the diagnostics on the package or module declarations.
-		var rng protocol.Range
-		switch s.view.FileKind(fh) {
-		case source.Go:
-			if pgf, err := s.ParseGo(ctx, fh, source.ParseHeader); err == nil {
-				// Check that we have a valid `package foo` range to use for positioning the error.
-				if pgf.File.Package.IsValid() && pgf.File.Name != nil && pgf.File.Name.End().IsValid() {
-					pkgDecl := span.NewRange(pgf.Tok, pgf.File.Package, pgf.File.Name.End())
-					if spn, err := pkgDecl.Span(); err == nil {
-						rng, _ = pgf.Mapper.Range(spn)
-					}
-				}
-			}
-		case source.Mod:
-			if pmf, err := s.ParseMod(ctx, fh); err == nil {
-				if mod := pmf.File.Module; mod != nil && mod.Syntax != nil {
-					rng, _ = pmf.Mapper.OffsetRange(mod.Syntax.Start.Byte, mod.Syntax.End.Byte)
-				}
-			}
-		}
-		srcDiags = append(srcDiags, &source.Diagnostic{
-			URI:      fh.URI(),
-			Range:    rng,
-			Severity: protocol.SeverityError,
-			Source:   source.ListError,
-			Message:  msg,
-		})
-	}
-	return srcDiags
-}
-
-// getWorkspaceDir returns the URI for the workspace directory
-// associated with this snapshot. The workspace directory is a
-// temporary directory containing the go.mod file computed from all
-// active modules.
-func (s *snapshot) getWorkspaceDir(ctx context.Context) (span.URI, error) {
-	s.mu.Lock()
-	dir, err := s.workspaceDir, s.workspaceDirErr
-	s.mu.Unlock()
-	if dir == "" && err == nil { // cache miss
-		dir, err = makeWorkspaceDir(ctx, s.workspace, s)
-		s.mu.Lock()
-		s.workspaceDir, s.workspaceDirErr = dir, err
-		s.mu.Unlock()
-	}
-	return span.URIFromPath(dir), err
-}
-
-// makeWorkspaceDir creates a temporary directory containing a go.mod
-// and go.sum file for each module in the workspace.
-// Note: snapshot's mutex must be unlocked for it to satisfy FileSource.
-func makeWorkspaceDir(ctx context.Context, workspace *workspace, fs source.FileSource) (string, error) {
-	file, err := workspace.modFile(ctx, fs)
-	if err != nil {
-		return "", err
-	}
-	modContent, err := file.Format()
-	if err != nil {
-		return "", err
-	}
-	sumContent, err := workspace.sumFile(ctx, fs)
-	if err != nil {
-		return "", err
-	}
-	tmpdir, err := ioutil.TempDir("", "gopls-workspace-mod")
-	if err != nil {
-		return "", err
-	}
-	for name, content := range map[string][]byte{
-		"go.mod": modContent,
-		"go.sum": sumContent,
-	} {
-		if err := ioutil.WriteFile(filepath.Join(tmpdir, name), content, 0644); err != nil {
-			os.RemoveAll(tmpdir) // ignore error
-			return "", err
-		}
-	}
-	return tmpdir, nil
-}
-
-// buildMetadata populates the updates map with metadata updates to
-// apply, based on the given pkg. It recurs through pkg.Imports to ensure that
-// metadata exists for all dependencies.
-func buildMetadata(ctx context.Context, pkg *packages.Package, cfg *packages.Config, query []string, updates map[PackageID]*source.Metadata, path []PackageID) error {
-	// Allow for multiple ad-hoc packages in the workspace (see #47584).
-	pkgPath := PackagePath(pkg.PkgPath)
-	id := PackageID(pkg.ID)
-	if source.IsCommandLineArguments(id) {
-		suffix := ":" + strings.Join(query, ",")
-		id = PackageID(pkg.ID + suffix)
-		pkgPath = PackagePath(pkg.PkgPath + suffix)
-	}
-
-	if _, ok := updates[id]; ok {
-		// If we've already seen this dependency, there may be an import cycle, or
-		// we may have reached the same package transitively via distinct paths.
-		// Check the path to confirm.
-
-		// TODO(rfindley): this doesn't look sufficient. Any single piece of new
-		// metadata could theoretically introduce import cycles in the metadata
-		// graph. What's the point of this limited check here (and is it even
-		// possible to get an import cycle in data from go/packages)? Consider
-		// simply returning, so that this function need not return an error.
-		//
-		// We should consider doing a more complete guard against import cycles
-		// elsewhere.
-		for _, prev := range path {
-			if prev == id {
-				return fmt.Errorf("import cycle detected: %q", id)
-			}
-		}
-		return nil
-	}
-
-	// Recreate the metadata rather than reusing it to avoid locking.
-	m := &source.Metadata{
-		ID:         id,
-		PkgPath:    pkgPath,
-		Name:       PackageName(pkg.Name),
-		ForTest:    PackagePath(packagesinternal.GetForTest(pkg)),
-		TypesSizes: pkg.TypesSizes,
-		Config:     cfg,
-		Module:     pkg.Module,
-		DepsErrors: packagesinternal.GetDepsErrors(pkg),
-	}
-	updates[id] = m
-
-	for _, err := range pkg.Errors {
-		// Filter out parse errors from go list. We'll get them when we
-		// actually parse, and buggy overlay support may generate spurious
-		// errors. (See TestNewModule_Issue38207.)
-		if strings.Contains(err.Msg, "expected '") {
-			continue
-		}
-		m.Errors = append(m.Errors, err)
-	}
-
-	for _, filename := range pkg.CompiledGoFiles {
-		uri := span.URIFromPath(filename)
-		m.CompiledGoFiles = append(m.CompiledGoFiles, uri)
-	}
-	for _, filename := range pkg.GoFiles {
-		uri := span.URIFromPath(filename)
-		m.GoFiles = append(m.GoFiles, uri)
-	}
-
-	depsByImpPath := make(map[ImportPath]PackageID)
-	depsByPkgPath := make(map[PackagePath]PackageID)
-	for importPath, imported := range pkg.Imports {
-		importPath := ImportPath(importPath)
-
-		// It is not an invariant that importPath == imported.PkgPath.
-		// For example, package "net" imports "golang.org/x/net/dns/dnsmessage"
-		// which refers to the package whose ID and PkgPath are both
-		// "vendor/golang.org/x/net/dns/dnsmessage". Notice the ImportMap,
-		// which maps ImportPaths to PackagePaths:
-		//
-		// $ go list -json net vendor/golang.org/x/net/dns/dnsmessage
-		// {
-		// 	"ImportPath": "net",
-		// 	"Name": "net",
-		// 	"Imports": [
-		// 		"C",
-		// 		"vendor/golang.org/x/net/dns/dnsmessage",
-		// 		"vendor/golang.org/x/net/route",
-		// 		...
-		// 	],
-		// 	"ImportMap": {
-		// 		"golang.org/x/net/dns/dnsmessage": "vendor/golang.org/x/net/dns/dnsmessage",
-		// 		"golang.org/x/net/route": "vendor/golang.org/x/net/route"
-		// 	},
-		//      ...
-		// }
-		// {
-		// 	"ImportPath": "vendor/golang.org/x/net/dns/dnsmessage",
-		// 	"Name": "dnsmessage",
-		//      ...
-		// }
-		//
-		// (Beware that, for historical reasons, go list uses
-		// the JSON field "ImportPath" for the package's
-		// path--effectively the linker symbol prefix.)
-		//
-		// The example above is slightly special to go list
-		// because it's in the std module.  Otherwise,
-		// vendored modules are simply modules whose directory
-		// is vendor/ instead of GOMODCACHE, and the
-		// import path equals the package path.
-		//
-		// But in GOPATH (non-module) mode, it's possible for
-		// package vendoring to cause a non-identity ImportMap,
-		// as in this example:
-		//
-		// $ cd $HOME/src
-		// $ find . -type f
-		// ./b/b.go
-		// ./vendor/example.com/a/a.go
-		// $ cat ./b/b.go
-		// package b
-		// import _ "example.com/a"
-		// $ cat ./vendor/example.com/a/a.go
-		// package a
-		// $ GOPATH=$HOME GO111MODULE=off go list -json ./b | grep -A2 ImportMap
-		//     "ImportMap": {
-		//         "example.com/a": "vendor/example.com/a"
-		//     },
-
-		// Don't remember any imports with significant errors.
-		//
-		// The len=0 condition is a heuristic check for imports of
-		// non-existent packages (for which go/packages will create
-		// an edge to a synthesized node). The heuristic is unsound
-		// because some valid packages have zero files, for example,
-		// a directory containing only the file p_test.go defines an
-		// empty package p.
-		// TODO(adonovan): clarify this. Perhaps go/packages should
-		// report which nodes were synthesized.
-		if importPath != "unsafe" && len(imported.CompiledGoFiles) == 0 {
-			depsByImpPath[importPath] = "" // missing
-			continue
-		}
-
-		depsByImpPath[importPath] = PackageID(imported.ID)
-		depsByPkgPath[PackagePath(imported.PkgPath)] = PackageID(imported.ID)
-		if err := buildMetadata(ctx, imported, cfg, query, updates, append(path, id)); err != nil {
-			event.Error(ctx, "error in dependency", err)
-		}
-	}
-	m.DepsByImpPath = depsByImpPath
-	m.DepsByPkgPath = depsByPkgPath
-
-	return nil
-}
-
-// containsPackageLocked reports whether p is a workspace package for the
-// snapshot s.
-//
-// s.mu must be held while calling this function.
-func containsPackageLocked(s *snapshot, m *source.Metadata) bool {
-	// In legacy workspace mode, or if a package does not have an associated
-	// module, a package is considered inside the workspace if any of its files
-	// are under the workspace root (and not excluded).
-	//
-	// Otherwise if the package has a module it must be an active module (as
-	// defined by the module root or go.work file) and at least one file must not
-	// be filtered out by directoryFilters.
-	if m.Module != nil && s.workspace.moduleSource != legacyWorkspace {
-		modURI := span.URIFromPath(m.Module.GoMod)
-		_, ok := s.workspace.activeModFiles[modURI]
-		if !ok {
-			return false
-		}
-
-		uris := map[span.URI]struct{}{}
-		for _, uri := range m.CompiledGoFiles {
-			uris[uri] = struct{}{}
-		}
-		for _, uri := range m.GoFiles {
-			uris[uri] = struct{}{}
-		}
-
-		filterFunc := s.view.filterFunc()
-		for uri := range uris {
-			// Don't use view.contains here. go.work files may include modules
-			// outside of the workspace folder.
-			if !strings.Contains(string(uri), "/vendor/") && !filterFunc(uri) {
-				return true
-			}
-		}
-		return false
-	}
-
-	return containsFileInWorkspaceLocked(s, m)
-}
-
-// containsOpenFileLocked reports whether any file referenced by m is open in
-// the snapshot s.
-//
-// s.mu must be held while calling this function.
-func containsOpenFileLocked(s *snapshot, m *source.Metadata) bool {
-	uris := map[span.URI]struct{}{}
-	for _, uri := range m.CompiledGoFiles {
-		uris[uri] = struct{}{}
-	}
-	for _, uri := range m.GoFiles {
-		uris[uri] = struct{}{}
-	}
-
-	for uri := range uris {
-		if s.isOpenLocked(uri) {
-			return true
-		}
-	}
-	return false
-}
-
-// containsFileInWorkspaceLocked reports whether m contains any file inside the
-// workspace of the snapshot s.
-//
-// s.mu must be held while calling this function.
-func containsFileInWorkspaceLocked(s *snapshot, m *source.Metadata) bool {
-	uris := map[span.URI]struct{}{}
-	for _, uri := range m.CompiledGoFiles {
-		uris[uri] = struct{}{}
-	}
-	for _, uri := range m.GoFiles {
-		uris[uri] = struct{}{}
-	}
-
-	for uri := range uris {
-		// In order for a package to be considered for the workspace, at least one
-		// file must be contained in the workspace and not vendored.
-
-		// The package's files are in this view. It may be a workspace package.
-		// Vendored packages are not likely to be interesting to the user.
-		if !strings.Contains(string(uri), "/vendor/") && s.view.contains(uri) {
-			return true
-		}
-	}
-	return false
-}
-
-// computeWorkspacePackagesLocked computes workspace packages in the snapshot s
-// for the given metadata graph.
-//
-// s.mu must be held while calling this function.
-func computeWorkspacePackagesLocked(s *snapshot, meta *metadataGraph) map[PackageID]PackagePath {
-	workspacePackages := make(map[PackageID]PackagePath)
-	for _, m := range meta.metadata {
-		if !containsPackageLocked(s, m) {
-			continue
-		}
-
-		if source.IsCommandLineArguments(m.ID) {
-			// If all the files contained in m have a real package, we don't need to
-			// keep m as a workspace package.
-			if allFilesHaveRealPackages(meta, m) {
-				continue
-			}
-
-			// We only care about command-line-arguments packages if they are still
-			// open.
-			if !containsOpenFileLocked(s, m) {
-				continue
-			}
-		}
-
-		switch {
-		case m.ForTest == "":
-			// A normal package.
-			workspacePackages[m.ID] = m.PkgPath
-		case m.ForTest == m.PkgPath, m.ForTest+"_test" == m.PkgPath:
-			// The test variant of some workspace package or its x_test.
-			// To load it, we need to load the non-test variant with -test.
-			//
-			// Notably, this excludes intermediate test variants from workspace
-			// packages.
-			workspacePackages[m.ID] = m.ForTest
-		}
-	}
-	return workspacePackages
-}
-
-// allFilesHaveRealPackages reports whether all files referenced by m are
-// contained in a "real" package (not command-line-arguments).
-//
-// If m is valid but all "real" packages containing any file are invalid, this
-// function returns false.
-//
-// If m is not a command-line-arguments package, this is trivially true.
-func allFilesHaveRealPackages(g *metadataGraph, m *source.Metadata) bool {
-	n := len(m.CompiledGoFiles)
-checkURIs:
-	for _, uri := range append(m.CompiledGoFiles[0:n:n], m.GoFiles...) {
-		for _, id := range g.ids[uri] {
-			if !source.IsCommandLineArguments(id) {
-				continue checkURIs
-			}
-		}
-		return false
-	}
-	return true
-}
-
-func isTestMain(pkg *packages.Package, gocache string) bool {
-	// Test mains must have an import path that ends with ".test".
-	if !strings.HasSuffix(pkg.PkgPath, ".test") {
-		return false
-	}
-	// Test main packages are always named "main".
-	if pkg.Name != "main" {
-		return false
-	}
-	// Test mains always have exactly one GoFile that is in the build cache.
-	if len(pkg.GoFiles) > 1 {
-		return false
-	}
-	if !source.InDir(gocache, pkg.GoFiles[0]) {
-		return false
-	}
-	return true
-}
diff -urN a/gopls/internal/lsp/cache/maps.go b/gopls/internal/lsp/cache/maps.go
--- a/gopls/internal/lsp/cache/maps.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/maps.go	1969-12-31 16:00:00
@@ -1,218 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/persistent"
-)
-
-// TODO(euroelessar): Use generics once support for go1.17 is dropped.
-
-type filesMap struct {
-	impl *persistent.Map
-}
-
-// uriLessInterface is the < relation for "any" values containing span.URIs.
-func uriLessInterface(a, b interface{}) bool {
-	return a.(span.URI) < b.(span.URI)
-}
-
-func newFilesMap() filesMap {
-	return filesMap{
-		impl: persistent.NewMap(uriLessInterface),
-	}
-}
-
-func (m filesMap) Clone() filesMap {
-	return filesMap{
-		impl: m.impl.Clone(),
-	}
-}
-
-func (m filesMap) Destroy() {
-	m.impl.Destroy()
-}
-
-func (m filesMap) Get(key span.URI) (source.VersionedFileHandle, bool) {
-	value, ok := m.impl.Get(key)
-	if !ok {
-		return nil, false
-	}
-	return value.(source.VersionedFileHandle), true
-}
-
-func (m filesMap) Range(do func(key span.URI, value source.VersionedFileHandle)) {
-	m.impl.Range(func(key, value interface{}) {
-		do(key.(span.URI), value.(source.VersionedFileHandle))
-	})
-}
-
-func (m filesMap) Set(key span.URI, value source.VersionedFileHandle) {
-	m.impl.Set(key, value, nil)
-}
-
-func (m filesMap) Delete(key span.URI) {
-	m.impl.Delete(key)
-}
-
-func parseKeyLessInterface(a, b interface{}) bool {
-	return parseKeyLess(a.(parseKey), b.(parseKey))
-}
-
-func parseKeyLess(a, b parseKey) bool {
-	if a.mode != b.mode {
-		return a.mode < b.mode
-	}
-	if a.file.Hash != b.file.Hash {
-		return a.file.Hash.Less(b.file.Hash)
-	}
-	return a.file.URI < b.file.URI
-}
-
-type isActivePackageCacheMap struct {
-	impl *persistent.Map
-}
-
-func newIsActivePackageCacheMap() isActivePackageCacheMap {
-	return isActivePackageCacheMap{
-		impl: persistent.NewMap(func(a, b interface{}) bool {
-			return a.(PackageID) < b.(PackageID)
-		}),
-	}
-}
-
-func (m isActivePackageCacheMap) Clone() isActivePackageCacheMap {
-	return isActivePackageCacheMap{
-		impl: m.impl.Clone(),
-	}
-}
-
-func (m isActivePackageCacheMap) Destroy() {
-	m.impl.Destroy()
-}
-
-func (m isActivePackageCacheMap) Get(key PackageID) (bool, bool) {
-	value, ok := m.impl.Get(key)
-	if !ok {
-		return false, false
-	}
-	return value.(bool), true
-}
-
-func (m isActivePackageCacheMap) Set(key PackageID, value bool) {
-	m.impl.Set(key, value, nil)
-}
-
-type parseKeysByURIMap struct {
-	impl *persistent.Map
-}
-
-func newParseKeysByURIMap() parseKeysByURIMap {
-	return parseKeysByURIMap{
-		impl: persistent.NewMap(uriLessInterface),
-	}
-}
-
-func (m parseKeysByURIMap) Clone() parseKeysByURIMap {
-	return parseKeysByURIMap{
-		impl: m.impl.Clone(),
-	}
-}
-
-func (m parseKeysByURIMap) Destroy() {
-	m.impl.Destroy()
-}
-
-func (m parseKeysByURIMap) Get(key span.URI) ([]parseKey, bool) {
-	value, ok := m.impl.Get(key)
-	if !ok {
-		return nil, false
-	}
-	return value.([]parseKey), true
-}
-
-func (m parseKeysByURIMap) Range(do func(key span.URI, value []parseKey)) {
-	m.impl.Range(func(key, value interface{}) {
-		do(key.(span.URI), value.([]parseKey))
-	})
-}
-
-func (m parseKeysByURIMap) Set(key span.URI, value []parseKey) {
-	m.impl.Set(key, value, nil)
-}
-
-func (m parseKeysByURIMap) Delete(key span.URI) {
-	m.impl.Delete(key)
-}
-
-func packageKeyLessInterface(x, y interface{}) bool {
-	return packageKeyLess(x.(packageKey), y.(packageKey))
-}
-
-func packageKeyLess(x, y packageKey) bool {
-	if x.mode != y.mode {
-		return x.mode < y.mode
-	}
-	return x.id < y.id
-}
-
-type knownDirsSet struct {
-	impl *persistent.Map
-}
-
-func newKnownDirsSet() knownDirsSet {
-	return knownDirsSet{
-		impl: persistent.NewMap(func(a, b interface{}) bool {
-			return a.(span.URI) < b.(span.URI)
-		}),
-	}
-}
-
-func (s knownDirsSet) Clone() knownDirsSet {
-	return knownDirsSet{
-		impl: s.impl.Clone(),
-	}
-}
-
-func (s knownDirsSet) Destroy() {
-	s.impl.Destroy()
-}
-
-func (s knownDirsSet) Contains(key span.URI) bool {
-	_, ok := s.impl.Get(key)
-	return ok
-}
-
-func (s knownDirsSet) Range(do func(key span.URI)) {
-	s.impl.Range(func(key, value interface{}) {
-		do(key.(span.URI))
-	})
-}
-
-func (s knownDirsSet) SetAll(other knownDirsSet) {
-	s.impl.SetAll(other.impl)
-}
-
-func (s knownDirsSet) Insert(key span.URI) {
-	s.impl.Set(key, nil, nil)
-}
-
-func (s knownDirsSet) Remove(key span.URI) {
-	s.impl.Delete(key)
-}
-
-// analysisKeyLessInterface is the less-than relation for analysisKey
-// values wrapped in an interface.
-func analysisKeyLessInterface(a, b interface{}) bool {
-	x, y := a.(analysisKey), b.(analysisKey)
-	if cmp := strings.Compare(x.analyzerNames, y.analyzerNames); cmp != 0 {
-		return cmp < 0
-	}
-	return x.pkgid < y.pkgid
-}
diff -urN a/gopls/internal/lsp/cache/mod.go b/gopls/internal/lsp/cache/mod.go
--- a/gopls/internal/lsp/cache/mod.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/mod.go	1969-12-31 16:00:00
@@ -1,526 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"path/filepath"
-	"regexp"
-	"strings"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/module"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// ParseMod parses a go.mod file, using a cache. It may return partial results and an error.
-func (s *snapshot) ParseMod(ctx context.Context, fh source.FileHandle) (*source.ParsedModule, error) {
-	uri := fh.URI()
-
-	s.mu.Lock()
-	entry, hit := s.parseModHandles.Get(uri)
-	s.mu.Unlock()
-
-	type parseModResult struct {
-		parsed *source.ParsedModule
-		err    error
-	}
-
-	// cache miss?
-	if !hit {
-		promise, release := s.store.Promise(fh.FileIdentity(), func(ctx context.Context, _ interface{}) interface{} {
-			parsed, err := parseModImpl(ctx, fh)
-			return parseModResult{parsed, err}
-		})
-
-		entry = promise
-		s.mu.Lock()
-		s.parseModHandles.Set(uri, entry, func(_, _ interface{}) { release() })
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(parseModResult)
-	return res.parsed, res.err
-}
-
-// parseModImpl parses the go.mod file whose name and contents are in fh.
-// It may return partial results and an error.
-func parseModImpl(ctx context.Context, fh source.FileHandle) (*source.ParsedModule, error) {
-	_, done := event.Start(ctx, "cache.ParseMod", tag.URI.Of(fh.URI()))
-	defer done()
-
-	contents, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	m := protocol.NewColumnMapper(fh.URI(), contents)
-	file, parseErr := modfile.Parse(fh.URI().Filename(), contents, nil)
-	// Attempt to convert the error to a standardized parse error.
-	var parseErrors []*source.Diagnostic
-	if parseErr != nil {
-		mfErrList, ok := parseErr.(modfile.ErrorList)
-		if !ok {
-			return nil, fmt.Errorf("unexpected parse error type %v", parseErr)
-		}
-		for _, mfErr := range mfErrList {
-			rng, err := m.OffsetRange(mfErr.Pos.Byte, mfErr.Pos.Byte)
-			if err != nil {
-				return nil, err
-			}
-			parseErrors = append(parseErrors, &source.Diagnostic{
-				URI:      fh.URI(),
-				Range:    rng,
-				Severity: protocol.SeverityError,
-				Source:   source.ParseError,
-				Message:  mfErr.Err.Error(),
-			})
-		}
-	}
-	return &source.ParsedModule{
-		URI:         fh.URI(),
-		Mapper:      m,
-		File:        file,
-		ParseErrors: parseErrors,
-	}, parseErr
-}
-
-// ParseWork parses a go.work file, using a cache. It may return partial results and an error.
-// TODO(adonovan): move to new work.go file.
-func (s *snapshot) ParseWork(ctx context.Context, fh source.FileHandle) (*source.ParsedWorkFile, error) {
-	uri := fh.URI()
-
-	s.mu.Lock()
-	entry, hit := s.parseWorkHandles.Get(uri)
-	s.mu.Unlock()
-
-	type parseWorkResult struct {
-		parsed *source.ParsedWorkFile
-		err    error
-	}
-
-	// cache miss?
-	if !hit {
-		handle, release := s.store.Promise(fh.FileIdentity(), func(ctx context.Context, _ interface{}) interface{} {
-			parsed, err := parseWorkImpl(ctx, fh)
-			return parseWorkResult{parsed, err}
-		})
-
-		entry = handle
-		s.mu.Lock()
-		s.parseWorkHandles.Set(uri, entry, func(_, _ interface{}) { release() })
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(parseWorkResult)
-	return res.parsed, res.err
-}
-
-// parseWorkImpl parses a go.work file. It may return partial results and an error.
-func parseWorkImpl(ctx context.Context, fh source.FileHandle) (*source.ParsedWorkFile, error) {
-	_, done := event.Start(ctx, "cache.ParseWork", tag.URI.Of(fh.URI()))
-	defer done()
-
-	contents, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	m := protocol.NewColumnMapper(fh.URI(), contents)
-	file, parseErr := modfile.ParseWork(fh.URI().Filename(), contents, nil)
-	// Attempt to convert the error to a standardized parse error.
-	var parseErrors []*source.Diagnostic
-	if parseErr != nil {
-		mfErrList, ok := parseErr.(modfile.ErrorList)
-		if !ok {
-			return nil, fmt.Errorf("unexpected parse error type %v", parseErr)
-		}
-		for _, mfErr := range mfErrList {
-			rng, err := m.OffsetRange(mfErr.Pos.Byte, mfErr.Pos.Byte)
-			if err != nil {
-				return nil, err
-			}
-			parseErrors = append(parseErrors, &source.Diagnostic{
-				URI:      fh.URI(),
-				Range:    rng,
-				Severity: protocol.SeverityError,
-				Source:   source.ParseError,
-				Message:  mfErr.Err.Error(),
-			})
-		}
-	}
-	return &source.ParsedWorkFile{
-		URI:         fh.URI(),
-		Mapper:      m,
-		File:        file,
-		ParseErrors: parseErrors,
-	}, parseErr
-}
-
-// goSum reads the go.sum file for the go.mod file at modURI, if it exists. If
-// it doesn't exist, it returns nil.
-func (s *snapshot) goSum(ctx context.Context, modURI span.URI) []byte {
-	// Get the go.sum file, either from the snapshot or directly from the
-	// cache. Avoid (*snapshot).GetFile here, as we don't want to add
-	// nonexistent file handles to the snapshot if the file does not exist.
-	sumURI := span.URIFromPath(sumFilename(modURI))
-	var sumFH source.FileHandle = s.FindFile(sumURI)
-	if sumFH == nil {
-		var err error
-		sumFH, err = s.view.cache.getFile(ctx, sumURI)
-		if err != nil {
-			return nil
-		}
-	}
-	content, err := sumFH.Read()
-	if err != nil {
-		return nil
-	}
-	return content
-}
-
-func sumFilename(modURI span.URI) string {
-	return strings.TrimSuffix(modURI.Filename(), ".mod") + ".sum"
-}
-
-// ModWhy returns the "go mod why" result for each module named in a
-// require statement in the go.mod file.
-// TODO(adonovan): move to new mod_why.go file.
-func (s *snapshot) ModWhy(ctx context.Context, fh source.FileHandle) (map[string]string, error) {
-	uri := fh.URI()
-
-	if s.View().FileKind(fh) != source.Mod {
-		return nil, fmt.Errorf("%s is not a go.mod file", uri)
-	}
-
-	s.mu.Lock()
-	entry, hit := s.modWhyHandles.Get(uri)
-	s.mu.Unlock()
-
-	type modWhyResult struct {
-		why map[string]string
-		err error
-	}
-
-	// cache miss?
-	if !hit {
-		handle := memoize.NewPromise("modWhy", func(ctx context.Context, arg interface{}) interface{} {
-			why, err := modWhyImpl(ctx, arg.(*snapshot), fh)
-			return modWhyResult{why, err}
-		})
-
-		entry = handle
-		s.mu.Lock()
-		s.modWhyHandles.Set(uri, entry, nil)
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(modWhyResult)
-	return res.why, res.err
-}
-
-// modWhyImpl returns the result of "go mod why -m" on the specified go.mod file.
-func modWhyImpl(ctx context.Context, snapshot *snapshot, fh source.FileHandle) (map[string]string, error) {
-	ctx, done := event.Start(ctx, "cache.ModWhy", tag.URI.Of(fh.URI()))
-	defer done()
-
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		return nil, err
-	}
-	// No requires to explain.
-	if len(pm.File.Require) == 0 {
-		return nil, nil // empty result
-	}
-	// Run `go mod why` on all the dependencies.
-	inv := &gocommand.Invocation{
-		Verb:       "mod",
-		Args:       []string{"why", "-m"},
-		WorkingDir: filepath.Dir(fh.URI().Filename()),
-	}
-	for _, req := range pm.File.Require {
-		inv.Args = append(inv.Args, req.Mod.Path)
-	}
-	stdout, err := snapshot.RunGoCommandDirect(ctx, source.Normal, inv)
-	if err != nil {
-		return nil, err
-	}
-	whyList := strings.Split(stdout.String(), "\n\n")
-	if len(whyList) != len(pm.File.Require) {
-		return nil, fmt.Errorf("mismatched number of results: got %v, want %v", len(whyList), len(pm.File.Require))
-	}
-	why := make(map[string]string, len(pm.File.Require))
-	for i, req := range pm.File.Require {
-		why[req.Mod.Path] = whyList[i]
-	}
-	return why, nil
-}
-
-// extractGoCommandError tries to parse errors that come from the go command
-// and shape them into go.mod diagnostics.
-// TODO: rename this to 'load errors'
-func (s *snapshot) extractGoCommandErrors(ctx context.Context, goCmdError error) []*source.Diagnostic {
-	if goCmdError == nil {
-		return nil
-	}
-
-	type locatedErr struct {
-		spn span.Span
-		msg string
-	}
-	diagLocations := map[*source.ParsedModule]locatedErr{}
-	backupDiagLocations := map[*source.ParsedModule]locatedErr{}
-
-	// If moduleErrs is non-nil, go command errors are scoped to specific
-	// modules.
-	var moduleErrs *moduleErrorMap
-	_ = errors.As(goCmdError, &moduleErrs)
-
-	// Match the error against all the mod files in the workspace.
-	for _, uri := range s.ModFiles() {
-		fh, err := s.GetFile(ctx, uri)
-		if err != nil {
-			event.Error(ctx, "getting modfile for Go command error", err)
-			continue
-		}
-		pm, err := s.ParseMod(ctx, fh)
-		if err != nil {
-			// Parsing errors are reported elsewhere
-			return nil
-		}
-		var msgs []string // error messages to consider
-		if moduleErrs != nil {
-			if pm.File.Module != nil {
-				for _, mes := range moduleErrs.errs[pm.File.Module.Mod.Path] {
-					msgs = append(msgs, mes.Error())
-				}
-			}
-		} else {
-			msgs = append(msgs, goCmdError.Error())
-		}
-		for _, msg := range msgs {
-			if strings.Contains(goCmdError.Error(), "errors parsing go.mod") {
-				// The go command emits parse errors for completely invalid go.mod files.
-				// Those are reported by our own diagnostics and can be ignored here.
-				// As of writing, we are not aware of any other errors that include
-				// file/position information, so don't even try to find it.
-				continue
-			}
-			spn, found, err := s.matchErrorToModule(ctx, pm, msg)
-			if err != nil {
-				event.Error(ctx, "matching error to module", err)
-				continue
-			}
-			le := locatedErr{
-				spn: spn,
-				msg: msg,
-			}
-			if found {
-				diagLocations[pm] = le
-			} else {
-				backupDiagLocations[pm] = le
-			}
-		}
-	}
-
-	// If we didn't find any good matches, assign diagnostics to all go.mod files.
-	if len(diagLocations) == 0 {
-		diagLocations = backupDiagLocations
-	}
-
-	var srcErrs []*source.Diagnostic
-	for pm, le := range diagLocations {
-		diag, err := s.goCommandDiagnostic(pm, le.spn, le.msg)
-		if err != nil {
-			event.Error(ctx, "building go command diagnostic", err)
-			continue
-		}
-		srcErrs = append(srcErrs, diag)
-	}
-	return srcErrs
-}
-
-var moduleVersionInErrorRe = regexp.MustCompile(`[:\s]([+-._~0-9A-Za-z]+)@([+-._~0-9A-Za-z]+)[:\s]`)
-
-// matchErrorToModule matches a go command error message to a go.mod file.
-// Some examples:
-//
-//	example.com@v1.2.2: reading example.com/@v/v1.2.2.mod: no such file or directory
-//	go: github.com/cockroachdb/apd/v2@v2.0.72: reading github.com/cockroachdb/apd/go.mod at revision v2.0.72: unknown revision v2.0.72
-//	go: example.com@v1.2.3 requires\n\trandom.org@v1.2.3: parsing go.mod:\n\tmodule declares its path as: bob.org\n\tbut was required as: random.org
-//
-// It returns the location of a reference to the one of the modules and true
-// if one exists. If none is found it returns a fallback location and false.
-func (s *snapshot) matchErrorToModule(ctx context.Context, pm *source.ParsedModule, goCmdError string) (span.Span, bool, error) {
-	var reference *modfile.Line
-	matches := moduleVersionInErrorRe.FindAllStringSubmatch(goCmdError, -1)
-
-	for i := len(matches) - 1; i >= 0; i-- {
-		ver := module.Version{Path: matches[i][1], Version: matches[i][2]}
-		// Any module versions that come from the workspace module should not
-		// be shown to the user.
-		if source.IsWorkspaceModuleVersion(ver.Version) {
-			continue
-		}
-		if err := module.Check(ver.Path, ver.Version); err != nil {
-			continue
-		}
-		reference = findModuleReference(pm.File, ver)
-		if reference != nil {
-			break
-		}
-	}
-
-	if reference == nil {
-		// No match for the module path was found in the go.mod file.
-		// Show the error on the module declaration, if one exists, or
-		// just the first line of the file.
-		if pm.File.Module == nil {
-			return span.New(pm.URI, span.NewPoint(1, 1, 0), span.Point{}), false, nil
-		}
-		spn, err := spanFromPositions(pm.Mapper, pm.File.Module.Syntax.Start, pm.File.Module.Syntax.End)
-		return spn, false, err
-	}
-
-	spn, err := spanFromPositions(pm.Mapper, reference.Start, reference.End)
-	return spn, true, err
-}
-
-// goCommandDiagnostic creates a diagnostic for a given go command error.
-func (s *snapshot) goCommandDiagnostic(pm *source.ParsedModule, spn span.Span, goCmdError string) (*source.Diagnostic, error) {
-	rng, err := pm.Mapper.Range(spn)
-	if err != nil {
-		return nil, err
-	}
-
-	matches := moduleVersionInErrorRe.FindAllStringSubmatch(goCmdError, -1)
-	var innermost *module.Version
-	for i := len(matches) - 1; i >= 0; i-- {
-		ver := module.Version{Path: matches[i][1], Version: matches[i][2]}
-		// Any module versions that come from the workspace module should not
-		// be shown to the user.
-		if source.IsWorkspaceModuleVersion(ver.Version) {
-			continue
-		}
-		if err := module.Check(ver.Path, ver.Version); err != nil {
-			continue
-		}
-		innermost = &ver
-		break
-	}
-
-	switch {
-	case strings.Contains(goCmdError, "inconsistent vendoring"):
-		cmd, err := command.NewVendorCommand("Run go mod vendor", command.URIArg{URI: protocol.URIFromSpanURI(pm.URI)})
-		if err != nil {
-			return nil, err
-		}
-		return &source.Diagnostic{
-			URI:      pm.URI,
-			Range:    rng,
-			Severity: protocol.SeverityError,
-			Source:   source.ListError,
-			Message: `Inconsistent vendoring detected. Please re-run "go mod vendor".
-See https://github.com/golang/go/issues/39164 for more detail on this issue.`,
-			SuggestedFixes: []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)},
-		}, nil
-
-	case strings.Contains(goCmdError, "updates to go.sum needed"), strings.Contains(goCmdError, "missing go.sum entry"):
-		var args []protocol.DocumentURI
-		for _, uri := range s.ModFiles() {
-			args = append(args, protocol.URIFromSpanURI(uri))
-		}
-		tidyCmd, err := command.NewTidyCommand("Run go mod tidy", command.URIArgs{URIs: args})
-		if err != nil {
-			return nil, err
-		}
-		updateCmd, err := command.NewUpdateGoSumCommand("Update go.sum", command.URIArgs{URIs: args})
-		if err != nil {
-			return nil, err
-		}
-		msg := "go.sum is out of sync with go.mod. Please update it by applying the quick fix."
-		if innermost != nil {
-			msg = fmt.Sprintf("go.sum is out of sync with go.mod: entry for %v is missing. Please updating it by applying the quick fix.", innermost)
-		}
-		return &source.Diagnostic{
-			URI:      pm.URI,
-			Range:    rng,
-			Severity: protocol.SeverityError,
-			Source:   source.ListError,
-			Message:  msg,
-			SuggestedFixes: []source.SuggestedFix{
-				source.SuggestedFixFromCommand(tidyCmd, protocol.QuickFix),
-				source.SuggestedFixFromCommand(updateCmd, protocol.QuickFix),
-			},
-		}, nil
-	case strings.Contains(goCmdError, "disabled by GOPROXY=off") && innermost != nil:
-		title := fmt.Sprintf("Download %v@%v", innermost.Path, innermost.Version)
-		cmd, err := command.NewAddDependencyCommand(title, command.DependencyArgs{
-			URI:        protocol.URIFromSpanURI(pm.URI),
-			AddRequire: false,
-			GoCmdArgs:  []string{fmt.Sprintf("%v@%v", innermost.Path, innermost.Version)},
-		})
-		if err != nil {
-			return nil, err
-		}
-		return &source.Diagnostic{
-			URI:            pm.URI,
-			Range:          rng,
-			Severity:       protocol.SeverityError,
-			Message:        fmt.Sprintf("%v@%v has not been downloaded", innermost.Path, innermost.Version),
-			Source:         source.ListError,
-			SuggestedFixes: []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)},
-		}, nil
-	default:
-		return &source.Diagnostic{
-			URI:      pm.URI,
-			Range:    rng,
-			Severity: protocol.SeverityError,
-			Source:   source.ListError,
-			Message:  goCmdError,
-		}, nil
-	}
-}
-
-func findModuleReference(mf *modfile.File, ver module.Version) *modfile.Line {
-	for _, req := range mf.Require {
-		if req.Mod == ver {
-			return req.Syntax
-		}
-	}
-	for _, ex := range mf.Exclude {
-		if ex.Mod == ver {
-			return ex.Syntax
-		}
-	}
-	for _, rep := range mf.Replace {
-		if rep.New == ver || rep.Old == ver {
-			return rep.Syntax
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cache/mod_tidy.go b/gopls/internal/lsp/cache/mod_tidy.go
--- a/gopls/internal/lsp/cache/mod_tidy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/mod_tidy.go	1969-12-31 16:00:00
@@ -1,484 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"strconv"
-	"strings"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// ModTidy returns the go.mod file that would be obtained by running
-// "go mod tidy". Concurrent requests are combined into a single command.
-func (s *snapshot) ModTidy(ctx context.Context, pm *source.ParsedModule) (*source.TidiedModule, error) {
-	uri := pm.URI
-	if pm.File == nil {
-		return nil, fmt.Errorf("cannot tidy unparseable go.mod file: %v", uri)
-	}
-
-	s.mu.Lock()
-	entry, hit := s.modTidyHandles.Get(uri)
-	s.mu.Unlock()
-
-	type modTidyResult struct {
-		tidied *source.TidiedModule
-		err    error
-	}
-
-	// Cache miss?
-	if !hit {
-		// If the file handle is an overlay, it may not be written to disk.
-		// The go.mod file has to be on disk for `go mod tidy` to work.
-		// TODO(rfindley): is this still true with Go 1.16 overlay support?
-		fh, err := s.GetFile(ctx, pm.URI)
-		if err != nil {
-			return nil, err
-		}
-		if _, ok := fh.(*overlay); ok {
-			if info, _ := os.Stat(uri.Filename()); info == nil {
-				return nil, source.ErrNoModOnDisk
-			}
-		}
-
-		if criticalErr := s.GetCriticalError(ctx); criticalErr != nil {
-			return &source.TidiedModule{
-				Diagnostics: criticalErr.Diagnostics,
-			}, nil
-		}
-		if ctx.Err() != nil { // must check ctx after GetCriticalError
-			return nil, ctx.Err()
-		}
-
-		if err := s.awaitLoaded(ctx); err != nil {
-			return nil, err
-		}
-
-		handle := memoize.NewPromise("modTidy", func(ctx context.Context, arg interface{}) interface{} {
-			tidied, err := modTidyImpl(ctx, arg.(*snapshot), uri.Filename(), pm)
-			return modTidyResult{tidied, err}
-		})
-
-		entry = handle
-		s.mu.Lock()
-		s.modTidyHandles.Set(uri, entry, nil)
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(modTidyResult)
-	return res.tidied, res.err
-}
-
-// modTidyImpl runs "go mod tidy" on a go.mod file.
-func modTidyImpl(ctx context.Context, snapshot *snapshot, filename string, pm *source.ParsedModule) (*source.TidiedModule, error) {
-	ctx, done := event.Start(ctx, "cache.ModTidy", tag.URI.Of(filename))
-	defer done()
-
-	inv := &gocommand.Invocation{
-		Verb:       "mod",
-		Args:       []string{"tidy"},
-		WorkingDir: filepath.Dir(filename),
-	}
-	// TODO(adonovan): ensure that unsaved overlays are passed through to 'go'.
-	tmpURI, inv, cleanup, err := snapshot.goCommandInvocation(ctx, source.WriteTemporaryModFile, inv)
-	if err != nil {
-		return nil, err
-	}
-	// Keep the temporary go.mod file around long enough to parse it.
-	defer cleanup()
-
-	if _, err := snapshot.view.gocmdRunner.Run(ctx, *inv); err != nil {
-		return nil, err
-	}
-
-	// Go directly to disk to get the temporary mod file,
-	// since it is always on disk.
-	tempContents, err := ioutil.ReadFile(tmpURI.Filename())
-	if err != nil {
-		return nil, err
-	}
-	ideal, err := modfile.Parse(tmpURI.Filename(), tempContents, nil)
-	if err != nil {
-		// We do not need to worry about the temporary file's parse errors
-		// since it has been "tidied".
-		return nil, err
-	}
-
-	// Compare the original and tidied go.mod files to compute errors and
-	// suggested fixes.
-	diagnostics, err := modTidyDiagnostics(ctx, snapshot, pm, ideal)
-	if err != nil {
-		return nil, err
-	}
-
-	return &source.TidiedModule{
-		Diagnostics:   diagnostics,
-		TidiedContent: tempContents,
-	}, nil
-}
-
-// modTidyDiagnostics computes the differences between the original and tidied
-// go.mod files to produce diagnostic and suggested fixes. Some diagnostics
-// may appear on the Go files that import packages from missing modules.
-func modTidyDiagnostics(ctx context.Context, snapshot *snapshot, pm *source.ParsedModule, ideal *modfile.File) (diagnostics []*source.Diagnostic, err error) {
-	// First, determine which modules are unused and which are missing from the
-	// original go.mod file.
-	var (
-		unused          = make(map[string]*modfile.Require, len(pm.File.Require))
-		missing         = make(map[string]*modfile.Require, len(ideal.Require))
-		wrongDirectness = make(map[string]*modfile.Require, len(pm.File.Require))
-	)
-	for _, req := range pm.File.Require {
-		unused[req.Mod.Path] = req
-	}
-	for _, req := range ideal.Require {
-		origReq := unused[req.Mod.Path]
-		if origReq == nil {
-			missing[req.Mod.Path] = req
-			continue
-		} else if origReq.Indirect != req.Indirect {
-			wrongDirectness[req.Mod.Path] = origReq
-		}
-		delete(unused, req.Mod.Path)
-	}
-	for _, req := range wrongDirectness {
-		// Handle dependencies that are incorrectly labeled indirect and
-		// vice versa.
-		srcDiag, err := directnessDiagnostic(pm.Mapper, req, snapshot.View().Options().ComputeEdits)
-		if err != nil {
-			// We're probably in a bad state if we can't compute a
-			// directnessDiagnostic, but try to keep going so as to not suppress
-			// other, valid diagnostics.
-			event.Error(ctx, "computing directness diagnostic", err)
-			continue
-		}
-		diagnostics = append(diagnostics, srcDiag)
-	}
-	// Next, compute any diagnostics for modules that are missing from the
-	// go.mod file. The fixes will be for the go.mod file, but the
-	// diagnostics should also appear in both the go.mod file and the import
-	// statements in the Go files in which the dependencies are used.
-	missingModuleFixes := map[*modfile.Require][]source.SuggestedFix{}
-	for _, req := range missing {
-		srcDiag, err := missingModuleDiagnostic(pm, req)
-		if err != nil {
-			return nil, err
-		}
-		missingModuleFixes[req] = srcDiag.SuggestedFixes
-		diagnostics = append(diagnostics, srcDiag)
-	}
-	// Add diagnostics for missing modules anywhere they are imported in the
-	// workspace.
-	// TODO(adonovan): opt: opportunities for parallelism abound.
-	for _, m := range snapshot.workspaceMetadata() {
-		// Read both lists of files of this package, in parallel.
-		goFiles, compiledGoFiles, err := readGoFiles(ctx, snapshot, m)
-		if err != nil {
-			return nil, err
-		}
-
-		missingImports := map[string]*modfile.Require{}
-
-		// If -mod=readonly is not set we may have successfully imported
-		// packages from missing modules. Otherwise they'll be in
-		// MissingDependencies. Combine both.
-		for imp := range parseImports(ctx, snapshot, goFiles) {
-			if req, ok := missing[imp]; ok {
-				missingImports[imp] = req
-				break
-			}
-			// If the import is a package of the dependency, then add the
-			// package to the map, this will eliminate the need to do this
-			// prefix package search on each import for each file.
-			// Example:
-			//
-			// import (
-			//   "golang.org/x/tools/go/expect"
-			//   "golang.org/x/tools/go/packages"
-			// )
-			// They both are related to the same module: "golang.org/x/tools".
-			var match string
-			for _, req := range ideal.Require {
-				if strings.HasPrefix(imp, req.Mod.Path) && len(req.Mod.Path) > len(match) {
-					match = req.Mod.Path
-				}
-			}
-			if req, ok := missing[match]; ok {
-				missingImports[imp] = req
-			}
-		}
-		// None of this package's imports are from missing modules.
-		if len(missingImports) == 0 {
-			continue
-		}
-		for _, goFile := range compiledGoFiles {
-			pgf, err := snapshot.ParseGo(ctx, goFile, source.ParseHeader)
-			if err != nil {
-				continue
-			}
-			file, m := pgf.File, pgf.Mapper
-			if file == nil || m == nil {
-				continue
-			}
-			imports := make(map[string]*ast.ImportSpec)
-			for _, imp := range file.Imports {
-				if imp.Path == nil {
-					continue
-				}
-				if target, err := strconv.Unquote(imp.Path.Value); err == nil {
-					imports[target] = imp
-				}
-			}
-			if len(imports) == 0 {
-				continue
-			}
-			for importPath, req := range missingImports {
-				imp, ok := imports[importPath]
-				if !ok {
-					continue
-				}
-				fixes, ok := missingModuleFixes[req]
-				if !ok {
-					return nil, fmt.Errorf("no missing module fix for %q (%q)", importPath, req.Mod.Path)
-				}
-				srcErr, err := missingModuleForImport(pgf.Tok, m, imp, req, fixes)
-				if err != nil {
-					return nil, err
-				}
-				diagnostics = append(diagnostics, srcErr)
-			}
-		}
-	}
-	// Finally, add errors for any unused dependencies.
-	onlyDiagnostic := len(diagnostics) == 0 && len(unused) == 1
-	for _, req := range unused {
-		srcErr, err := unusedDiagnostic(pm.Mapper, req, onlyDiagnostic)
-		if err != nil {
-			return nil, err
-		}
-		diagnostics = append(diagnostics, srcErr)
-	}
-	return diagnostics, nil
-}
-
-// unusedDiagnostic returns a source.Diagnostic for an unused require.
-func unusedDiagnostic(m *protocol.ColumnMapper, req *modfile.Require, onlyDiagnostic bool) (*source.Diagnostic, error) {
-	rng, err := m.OffsetRange(req.Syntax.Start.Byte, req.Syntax.End.Byte)
-	if err != nil {
-		return nil, err
-	}
-	title := fmt.Sprintf("Remove dependency: %s", req.Mod.Path)
-	cmd, err := command.NewRemoveDependencyCommand(title, command.RemoveDependencyArgs{
-		URI:            protocol.URIFromSpanURI(m.URI),
-		OnlyDiagnostic: onlyDiagnostic,
-		ModulePath:     req.Mod.Path,
-	})
-	if err != nil {
-		return nil, err
-	}
-	return &source.Diagnostic{
-		URI:            m.URI,
-		Range:          rng,
-		Severity:       protocol.SeverityWarning,
-		Source:         source.ModTidyError,
-		Message:        fmt.Sprintf("%s is not used in this module", req.Mod.Path),
-		SuggestedFixes: []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)},
-	}, nil
-}
-
-// directnessDiagnostic extracts errors when a dependency is labeled indirect when
-// it should be direct and vice versa.
-func directnessDiagnostic(m *protocol.ColumnMapper, req *modfile.Require, computeEdits source.DiffFunction) (*source.Diagnostic, error) {
-	rng, err := m.OffsetRange(req.Syntax.Start.Byte, req.Syntax.End.Byte)
-	if err != nil {
-		return nil, err
-	}
-	direction := "indirect"
-	if req.Indirect {
-		direction = "direct"
-
-		// If the dependency should be direct, just highlight the // indirect.
-		if comments := req.Syntax.Comment(); comments != nil && len(comments.Suffix) > 0 {
-			end := comments.Suffix[0].Start
-			end.LineRune += len(comments.Suffix[0].Token)
-			end.Byte += len(comments.Suffix[0].Token)
-			rng, err = m.OffsetRange(comments.Suffix[0].Start.Byte, end.Byte)
-			if err != nil {
-				return nil, err
-			}
-		}
-	}
-	// If the dependency should be indirect, add the // indirect.
-	edits, err := switchDirectness(req, m, computeEdits)
-	if err != nil {
-		return nil, err
-	}
-	return &source.Diagnostic{
-		URI:      m.URI,
-		Range:    rng,
-		Severity: protocol.SeverityWarning,
-		Source:   source.ModTidyError,
-		Message:  fmt.Sprintf("%s should be %s", req.Mod.Path, direction),
-		SuggestedFixes: []source.SuggestedFix{{
-			Title: fmt.Sprintf("Change %s to %s", req.Mod.Path, direction),
-			Edits: map[span.URI][]protocol.TextEdit{
-				m.URI: edits,
-			},
-			ActionKind: protocol.QuickFix,
-		}},
-	}, nil
-}
-
-func missingModuleDiagnostic(pm *source.ParsedModule, req *modfile.Require) (*source.Diagnostic, error) {
-	var rng protocol.Range
-	// Default to the start of the file if there is no module declaration.
-	if pm.File != nil && pm.File.Module != nil && pm.File.Module.Syntax != nil {
-		start, end := pm.File.Module.Syntax.Span()
-		var err error
-		rng, err = pm.Mapper.OffsetRange(start.Byte, end.Byte)
-		if err != nil {
-			return nil, err
-		}
-	}
-	title := fmt.Sprintf("Add %s to your go.mod file", req.Mod.Path)
-	cmd, err := command.NewAddDependencyCommand(title, command.DependencyArgs{
-		URI:        protocol.URIFromSpanURI(pm.Mapper.URI),
-		AddRequire: !req.Indirect,
-		GoCmdArgs:  []string{req.Mod.Path + "@" + req.Mod.Version},
-	})
-	if err != nil {
-		return nil, err
-	}
-	return &source.Diagnostic{
-		URI:            pm.Mapper.URI,
-		Range:          rng,
-		Severity:       protocol.SeverityError,
-		Source:         source.ModTidyError,
-		Message:        fmt.Sprintf("%s is not in your go.mod file", req.Mod.Path),
-		SuggestedFixes: []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)},
-	}, nil
-}
-
-// switchDirectness gets the edits needed to change an indirect dependency to
-// direct and vice versa.
-func switchDirectness(req *modfile.Require, m *protocol.ColumnMapper, computeEdits source.DiffFunction) ([]protocol.TextEdit, error) {
-	// We need a private copy of the parsed go.mod file, since we're going to
-	// modify it.
-	copied, err := modfile.Parse("", m.Content, nil)
-	if err != nil {
-		return nil, err
-	}
-	// Change the directness in the matching require statement. To avoid
-	// reordering the require statements, rewrite all of them.
-	var requires []*modfile.Require
-	seenVersions := make(map[string]string)
-	for _, r := range copied.Require {
-		if seen := seenVersions[r.Mod.Path]; seen != "" && seen != r.Mod.Version {
-			// Avoid a panic in SetRequire below, which panics on conflicting
-			// versions.
-			return nil, fmt.Errorf("%q has conflicting versions: %q and %q", r.Mod.Path, seen, r.Mod.Version)
-		}
-		seenVersions[r.Mod.Path] = r.Mod.Version
-		if r.Mod.Path == req.Mod.Path {
-			requires = append(requires, &modfile.Require{
-				Mod:      r.Mod,
-				Syntax:   r.Syntax,
-				Indirect: !r.Indirect,
-			})
-			continue
-		}
-		requires = append(requires, r)
-	}
-	copied.SetRequire(requires)
-	newContent, err := copied.Format()
-	if err != nil {
-		return nil, err
-	}
-	// Calculate the edits to be made due to the change.
-	edits := computeEdits(string(m.Content), string(newContent))
-	return source.ToProtocolEdits(m, edits)
-}
-
-// missingModuleForImport creates an error for a given import path that comes
-// from a missing module.
-func missingModuleForImport(file *token.File, m *protocol.ColumnMapper, imp *ast.ImportSpec, req *modfile.Require, fixes []source.SuggestedFix) (*source.Diagnostic, error) {
-	if req.Syntax == nil {
-		return nil, fmt.Errorf("no syntax for %v", req)
-	}
-	rng, err := m.PosRange(imp.Path.Pos(), imp.Path.End())
-	if err != nil {
-		return nil, err
-	}
-	return &source.Diagnostic{
-		URI:            m.URI,
-		Range:          rng,
-		Severity:       protocol.SeverityError,
-		Source:         source.ModTidyError,
-		Message:        fmt.Sprintf("%s is not in your go.mod file", req.Mod.Path),
-		SuggestedFixes: fixes,
-	}, nil
-}
-
-func spanFromPositions(m *protocol.ColumnMapper, s, e modfile.Position) (span.Span, error) {
-	toPoint := func(offset int) (span.Point, error) {
-		l, c, err := span.ToPosition(m.TokFile, offset)
-		if err != nil {
-			return span.Point{}, err
-		}
-		return span.NewPoint(l, c, offset), nil
-	}
-	start, err := toPoint(s.Byte)
-	if err != nil {
-		return span.Span{}, err
-	}
-	end, err := toPoint(e.Byte)
-	if err != nil {
-		return span.Span{}, err
-	}
-	return span.New(m.URI, start, end), nil
-}
-
-// parseImports parses the headers of the specified files and returns
-// the set of strings that appear in import declarations within
-// GoFiles. Errors are ignored.
-//
-// (We can't simply use Metadata.Imports because it is based on
-// CompiledGoFiles, after cgo processing.)
-func parseImports(ctx context.Context, s *snapshot, files []source.FileHandle) map[string]bool {
-	s.mu.Lock() // peekOrParse requires a locked snapshot (!)
-	defer s.mu.Unlock()
-	seen := make(map[string]bool)
-	for _, file := range files {
-		f, err := peekOrParse(ctx, s, file, source.ParseHeader)
-		if err != nil {
-			continue
-		}
-		for _, spec := range f.File.Imports {
-			path, _ := strconv.Unquote(spec.Path.Value)
-			seen[path] = true
-		}
-	}
-	return seen
-}
diff -urN a/gopls/internal/lsp/cache/mod_vuln.go b/gopls/internal/lsp/cache/mod_vuln.go
--- a/gopls/internal/lsp/cache/mod_vuln.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/mod_vuln.go	1969-12-31 16:00:00
@@ -1,75 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"os"
-
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/gopls/internal/vulncheck"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// ModVuln returns import vulnerability analysis for the given go.mod URI.
-// Concurrent requests are combined into a single command.
-func (s *snapshot) ModVuln(ctx context.Context, modURI span.URI) (*govulncheck.Result, error) {
-	s.mu.Lock()
-	entry, hit := s.modVulnHandles.Get(modURI)
-	s.mu.Unlock()
-
-	type modVuln struct {
-		result *govulncheck.Result
-		err    error
-	}
-
-	// Cache miss?
-	if !hit {
-		// If the file handle is an overlay, it may not be written to disk.
-		// The go.mod file has to be on disk for vulncheck to work.
-		//
-		// TODO(hyangah): use overlays for vulncheck.
-		fh, err := s.GetFile(ctx, modURI)
-		if err != nil {
-			return nil, err
-		}
-		if _, ok := fh.(*overlay); ok {
-			if info, _ := os.Stat(modURI.Filename()); info == nil {
-				return nil, source.ErrNoModOnDisk
-			}
-		}
-
-		handle := memoize.NewPromise("modVuln", func(ctx context.Context, arg interface{}) interface{} {
-			result, err := modVulnImpl(ctx, arg.(*snapshot), modURI)
-			return modVuln{result, err}
-		})
-
-		entry = handle
-		s.mu.Lock()
-		s.modVulnHandles.Set(modURI, entry, nil)
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(modVuln)
-	return res.result, res.err
-}
-
-func modVulnImpl(ctx context.Context, s *snapshot, uri span.URI) (*govulncheck.Result, error) {
-	if vulncheck.VulnerablePackages == nil {
-		return &govulncheck.Result{}, nil
-	}
-	fh, err := s.GetFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	return vulncheck.VulnerablePackages(ctx, s, fh)
-}
diff -urN a/gopls/internal/lsp/cache/os_darwin.go b/gopls/internal/lsp/cache/os_darwin.go
--- a/gopls/internal/lsp/cache/os_darwin.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/os_darwin.go	1969-12-31 16:00:00
@@ -1,59 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"bytes"
-	"fmt"
-	"os"
-	"path/filepath"
-	"strings"
-	"syscall"
-	"unsafe"
-)
-
-func init() {
-	checkPathCase = darwinCheckPathCase
-}
-
-func darwinCheckPathCase(path string) error {
-	// Darwin provides fcntl(F_GETPATH) to get a path for an arbitrary FD.
-	// Conveniently for our purposes, it gives the canonical case back. But
-	// there's no guarantee that it will follow the same route through the
-	// filesystem that the original path did.
-
-	path, err := filepath.Abs(path)
-	if err != nil {
-		return err
-	}
-	fd, err := syscall.Open(path, os.O_RDONLY, 0)
-	if err != nil {
-		return err
-	}
-	defer syscall.Close(fd)
-	buf := make([]byte, 4096) // No MAXPATHLEN in syscall, I think it's 1024, this is bigger.
-
-	// Wheeee! syscall doesn't expose a way to call Fcntl except FcntlFlock.
-	// As of writing, it just passes the pointer through, so we can just lie.
-	if err := syscall.FcntlFlock(uintptr(fd), syscall.F_GETPATH, (*syscall.Flock_t)(unsafe.Pointer(&buf[0]))); err != nil {
-		return err
-	}
-	buf = buf[:bytes.IndexByte(buf, 0)]
-
-	isRoot := func(p string) bool {
-		return p[len(p)-1] == filepath.Separator
-	}
-	// Darwin seems to like having multiple names for the same folder. Match as much of the suffix as we can.
-	for got, want := path, string(buf); !isRoot(got) && !isRoot(want); got, want = filepath.Dir(got), filepath.Dir(want) {
-		g, w := filepath.Base(got), filepath.Base(want)
-		if !strings.EqualFold(g, w) {
-			break
-		}
-		if g != w {
-			return fmt.Errorf("case mismatch in path %q: component %q is listed by macOS as %q", path, g, w)
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cache/os_windows.go b/gopls/internal/lsp/cache/os_windows.go
--- a/gopls/internal/lsp/cache/os_windows.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/os_windows.go	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package cache
-
-import (
-	"fmt"
-	"path/filepath"
-	"syscall"
-)
-
-func init() {
-	checkPathCase = windowsCheckPathCase
-}
-
-func windowsCheckPathCase(path string) error {
-	// Back in the day, Windows used to have short and long filenames, and
-	// it still supports those APIs. GetLongPathName gets the real case for a
-	// path, so we can use it here. Inspired by
-	// http://stackoverflow.com/q/2113822.
-
-	// Short paths can be longer than long paths, and unicode, so be generous.
-	buflen := 4 * len(path)
-	namep, err := syscall.UTF16PtrFromString(path)
-	if err != nil {
-		return err
-	}
-	short := make([]uint16, buflen)
-	n, err := syscall.GetShortPathName(namep, &short[0], uint32(len(short)*2)) // buflen is in bytes.
-	if err != nil {
-		return err
-	}
-	if int(n) > len(short)*2 {
-		return fmt.Errorf("short buffer too short: %v vs %v*2", n, len(short))
-	}
-	long := make([]uint16, buflen)
-	n, err = syscall.GetLongPathName(&short[0], &long[0], uint32(len(long)*2))
-	if err != nil {
-		return err
-	}
-	if int(n) > len(long)*2 {
-		return fmt.Errorf("long buffer too short: %v vs %v*2", n, len(long))
-	}
-	longstr := syscall.UTF16ToString(long)
-
-	isRoot := func(p string) bool {
-		return p[len(p)-1] == filepath.Separator
-	}
-	for got, want := path, longstr; !isRoot(got) && !isRoot(want); got, want = filepath.Dir(got), filepath.Dir(want) {
-		if g, w := filepath.Base(got), filepath.Base(want); g != w {
-			return fmt.Errorf("case mismatch in path %q: component %q is listed by Windows as %q", path, g, w)
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cache/parse.go b/gopls/internal/lsp/cache/parse.go
--- a/gopls/internal/lsp/cache/parse.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/parse.go	1969-12-31 16:00:00
@@ -1,1346 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/ast"
-	"go/parser"
-	"go/scanner"
-	"go/token"
-	"go/types"
-	"path/filepath"
-	"reflect"
-	"strconv"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// parseKey uniquely identifies a parsed Go file.
-type parseKey struct {
-	file source.FileIdentity
-	mode source.ParseMode
-}
-
-// ParseGo parses the file whose contents are provided by fh, using a cache.
-// The resulting tree may have be fixed up.
-//
-// Token position information will be added to the snapshot's FileSet.
-//
-// The parser mode must not be ParseExported: that mode is used during
-// type checking to destructively trim the tree to reduce work,
-// which is not safe for values from a shared cache.
-// TODO(adonovan): opt: shouldn't parseGoImpl do the trimming?
-// Then we can cache the result since it would never change.
-//
-// TODO(adonovan): in the absence of any way to add existing an
-// token.File to a new FileSet (see go.dev/issue/53200), caching ASTs
-// implies a global FileSet.
-func (s *snapshot) ParseGo(ctx context.Context, fh source.FileHandle, mode source.ParseMode) (*source.ParsedGoFile, error) {
-	if mode == source.ParseExported {
-		panic("only type checking should use Exported")
-	}
-
-	key := parseKey{
-		file: fh.FileIdentity(),
-		mode: mode,
-	}
-
-	s.mu.Lock()
-	entry, hit := s.parsedGoFiles.Get(key)
-	s.mu.Unlock()
-
-	// cache miss?
-	if !hit {
-		promise, release := s.store.Promise(key, func(ctx context.Context, arg interface{}) interface{} {
-			parsed, err := parseGoImpl(ctx, arg.(*snapshot).FileSet(), fh, mode)
-			return parseGoResult{parsed, err}
-		})
-
-		s.mu.Lock()
-		// Check cache again in case another thread got there first.
-		if prev, ok := s.parsedGoFiles.Get(key); ok {
-			entry = prev
-			release()
-		} else {
-			entry = promise
-			s.parsedGoFiles.Set(key, entry, func(_, _ interface{}) { release() })
-
-			// In order to correctly invalidate the key above, we must keep track of
-			// the parse key just created.
-			//
-			// TODO(rfindley): use a two-level map URI->parseKey->promise.
-			keys, _ := s.parseKeysByURI.Get(fh.URI())
-
-			// Only record the new key if it doesn't exist. This is overly cautious:
-			// we should only be setting the key if it doesn't exist. However, this
-			// logic will be replaced soon, and erring on the side of caution seemed
-			// wise.
-			foundKey := false
-			for _, existing := range keys {
-				if existing == key {
-					foundKey = true
-					break
-				}
-			}
-			if !foundKey {
-				keys = append(keys, key)
-				s.parseKeysByURI.Set(fh.URI(), keys)
-			}
-		}
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(parseGoResult)
-	return res.parsed, res.err
-}
-
-// peekParseGoLocked peeks at the cache used by ParseGo but does not
-// populate it or wait for other threads to do so. On cache hit, it returns
-// the cache result of parseGoImpl; otherwise it returns (nil, nil).
-func (s *snapshot) peekParseGoLocked(fh source.FileHandle, mode source.ParseMode) (*source.ParsedGoFile, error) {
-	entry, hit := s.parsedGoFiles.Get(parseKey{fh.FileIdentity(), mode})
-	if !hit {
-		return nil, nil // no-one has requested this file
-	}
-	v := entry.(*memoize.Promise).Cached()
-	if v == nil {
-		return nil, nil // parsing is still in progress
-	}
-	res := v.(parseGoResult)
-	return res.parsed, res.err
-}
-
-// parseGoResult holds the result of a call to parseGoImpl.
-type parseGoResult struct {
-	parsed *source.ParsedGoFile
-	err    error
-}
-
-// parseGoImpl parses the Go source file whose content is provided by fh.
-func parseGoImpl(ctx context.Context, fset *token.FileSet, fh source.FileHandle, mode source.ParseMode) (*source.ParsedGoFile, error) {
-	ctx, done := event.Start(ctx, "cache.parseGo", tag.File.Of(fh.URI().Filename()))
-	defer done()
-
-	ext := filepath.Ext(fh.URI().Filename())
-	if ext != ".go" && ext != "" { // files generated by cgo have no extension
-		return nil, fmt.Errorf("cannot parse non-Go file %s", fh.URI())
-	}
-	src, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-
-	parserMode := parser.AllErrors | parser.ParseComments
-	if mode == source.ParseHeader {
-		parserMode = parser.ImportsOnly | parser.ParseComments
-	}
-
-	file, err := parser.ParseFile(fset, fh.URI().Filename(), src, parserMode)
-	var parseErr scanner.ErrorList
-	if err != nil {
-		// We passed a byte slice, so the only possible error is a parse error.
-		parseErr = err.(scanner.ErrorList)
-	}
-
-	tok := fset.File(file.Pos())
-	if tok == nil {
-		// file.Pos is the location of the package declaration (issue #53202). If there was
-		// none, we can't find the token.File that ParseFile created, and we
-		// have no choice but to recreate it.
-		tok = fset.AddFile(fh.URI().Filename(), -1, len(src))
-		tok.SetLinesForContent(src)
-	}
-
-	fixed := false
-	// If there were parse errors, attempt to fix them up.
-	if parseErr != nil {
-		// Fix any badly parsed parts of the AST.
-		fixed = fixAST(file, tok, src)
-
-		for i := 0; i < 10; i++ {
-			// Fix certain syntax errors that render the file unparseable.
-			newSrc := fixSrc(file, tok, src)
-			if newSrc == nil {
-				break
-			}
-
-			// If we thought there was something to fix 10 times in a row,
-			// it is likely we got stuck in a loop somehow. Log out a diff
-			// of the last changes we made to aid in debugging.
-			if i == 9 {
-				unified := diff.Unified("before", "after", string(src), string(newSrc))
-				event.Log(ctx, fmt.Sprintf("fixSrc loop - last diff:\n%v", unified), tag.File.Of(tok.Name()))
-			}
-
-			newFile, _ := parser.ParseFile(fset, fh.URI().Filename(), newSrc, parserMode)
-			if newFile != nil {
-				// Maintain the original parseError so we don't try formatting the doctored file.
-				file = newFile
-				src = newSrc
-				tok = fset.File(file.Pos())
-
-				fixed = fixAST(file, tok, src)
-			}
-		}
-	}
-
-	return &source.ParsedGoFile{
-		URI:   fh.URI(),
-		Mode:  mode,
-		Src:   src,
-		Fixed: fixed,
-		File:  file,
-		Tok:   tok,
-		Mapper: &protocol.ColumnMapper{
-			URI:     fh.URI(),
-			TokFile: tok,
-			Content: src,
-		},
-		ParseErr: parseErr,
-	}, nil
-}
-
-// An unexportedFilter removes as much unexported AST from a set of Files as possible.
-type unexportedFilter struct {
-	uses map[string]bool
-}
-
-// Filter records uses of unexported identifiers and filters out all other
-// unexported declarations.
-func (f *unexportedFilter) Filter(files []*ast.File) {
-	// Iterate to fixed point -- unexported types can include other unexported types.
-	oldLen := len(f.uses)
-	for {
-		for _, file := range files {
-			f.recordUses(file)
-		}
-		if len(f.uses) == oldLen {
-			break
-		}
-		oldLen = len(f.uses)
-	}
-
-	for _, file := range files {
-		var newDecls []ast.Decl
-		for _, decl := range file.Decls {
-			if f.filterDecl(decl) {
-				newDecls = append(newDecls, decl)
-			}
-		}
-		file.Decls = newDecls
-		file.Scope = nil
-		file.Unresolved = nil
-		file.Comments = nil
-		trimAST(file)
-	}
-}
-
-func (f *unexportedFilter) keep(ident *ast.Ident) bool {
-	return ast.IsExported(ident.Name) || f.uses[ident.Name]
-}
-
-func (f *unexportedFilter) filterDecl(decl ast.Decl) bool {
-	switch decl := decl.(type) {
-	case *ast.FuncDecl:
-		if ident := source.RecvIdent(decl.Recv); ident != nil && !f.keep(ident) {
-			return false
-		}
-		return f.keep(decl.Name)
-	case *ast.GenDecl:
-		if decl.Tok == token.CONST {
-			// Constants can involve iota, and iota is hard to deal with.
-			return true
-		}
-		var newSpecs []ast.Spec
-		for _, spec := range decl.Specs {
-			if f.filterSpec(spec) {
-				newSpecs = append(newSpecs, spec)
-			}
-		}
-		decl.Specs = newSpecs
-		return len(newSpecs) != 0
-	case *ast.BadDecl:
-		return false
-	}
-	panic(fmt.Sprintf("unknown ast.Decl %T", decl))
-}
-
-func (f *unexportedFilter) filterSpec(spec ast.Spec) bool {
-	switch spec := spec.(type) {
-	case *ast.ImportSpec:
-		return true
-	case *ast.ValueSpec:
-		var newNames []*ast.Ident
-		for _, name := range spec.Names {
-			if f.keep(name) {
-				newNames = append(newNames, name)
-			}
-		}
-		spec.Names = newNames
-		return len(spec.Names) != 0
-	case *ast.TypeSpec:
-		if !f.keep(spec.Name) {
-			return false
-		}
-		switch typ := spec.Type.(type) {
-		case *ast.StructType:
-			// In practice this no longer filters anything;
-			// see comment at StructType case in recordUses.
-			f.filterFieldList(typ.Fields)
-		case *ast.InterfaceType:
-			f.filterFieldList(typ.Methods)
-		}
-		return true
-	}
-	panic(fmt.Sprintf("unknown ast.Spec %T", spec))
-}
-
-func (f *unexportedFilter) filterFieldList(fields *ast.FieldList) {
-	var newFields []*ast.Field
-	for _, field := range fields.List {
-		if len(field.Names) == 0 {
-			// Keep embedded fields: they can export methods and fields.
-			newFields = append(newFields, field)
-		}
-		for _, name := range field.Names {
-			if f.keep(name) {
-				newFields = append(newFields, field)
-				break
-			}
-		}
-	}
-	fields.List = newFields
-}
-
-func (f *unexportedFilter) recordUses(file *ast.File) {
-	for _, decl := range file.Decls {
-		switch decl := decl.(type) {
-		case *ast.FuncDecl:
-			// Ignore methods on dropped types.
-			if ident := source.RecvIdent(decl.Recv); ident != nil && !f.keep(ident) {
-				break
-			}
-			// Ignore functions with dropped names.
-			if !f.keep(decl.Name) {
-				break
-			}
-			f.recordFuncType(decl.Type)
-		case *ast.GenDecl:
-			for _, spec := range decl.Specs {
-				switch spec := spec.(type) {
-				case *ast.ValueSpec:
-					for i, name := range spec.Names {
-						// Don't mess with constants -- iota is hard.
-						if f.keep(name) || decl.Tok == token.CONST {
-							f.recordIdents(spec.Type)
-							if len(spec.Values) > i {
-								f.recordIdents(spec.Values[i])
-							}
-						}
-					}
-				case *ast.TypeSpec:
-					switch typ := spec.Type.(type) {
-					case *ast.StructType:
-						// We used to trim unexported fields but this
-						// had observable consequences. For example,
-						// the 'fieldalignment' analyzer would compute
-						// incorrect diagnostics from the size and
-						// offsets, and the UI hover information for
-						// types was inaccurate. So now we keep them.
-						if typ.Fields != nil {
-							for _, field := range typ.Fields.List {
-								f.recordIdents(field.Type)
-							}
-						}
-					case *ast.InterfaceType:
-						f.recordInterfaceMethodUses(typ.Methods)
-					}
-				}
-			}
-		}
-	}
-}
-
-// recordIdents records unexported identifiers in an Expr in uses.
-// These may be types, e.g. in map[key]value, function names, e.g. in foo(),
-// or simple variable references. References that will be discarded, such
-// as those in function literal bodies, are ignored.
-func (f *unexportedFilter) recordIdents(x ast.Expr) {
-	ast.Inspect(x, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		if complit, ok := n.(*ast.CompositeLit); ok {
-			// We clear out composite literal contents; just record their type.
-			f.recordIdents(complit.Type)
-			return false
-		}
-		if flit, ok := n.(*ast.FuncLit); ok {
-			f.recordFuncType(flit.Type)
-			return false
-		}
-		if ident, ok := n.(*ast.Ident); ok && !ast.IsExported(ident.Name) {
-			f.uses[ident.Name] = true
-		}
-		return true
-	})
-}
-
-// recordFuncType records the types mentioned by a function type.
-func (f *unexportedFilter) recordFuncType(fn *ast.FuncType) {
-	// Parameter and result types of retained functions need to be retained.
-	if fn.Params != nil {
-		for _, field := range fn.Params.List {
-			f.recordIdents(field.Type)
-		}
-	}
-	if fn.Results != nil {
-		for _, field := range fn.Results.List {
-			f.recordIdents(field.Type)
-		}
-	}
-}
-
-// recordInterfaceMethodUses records unexported identifiers used in interface methods.
-func (f *unexportedFilter) recordInterfaceMethodUses(methods *ast.FieldList) {
-	if methods != nil {
-		for _, method := range methods.List {
-			if len(method.Names) == 0 {
-				// I, pkg.I, I[T] -- embedded interface:
-				// may contribute exported names.
-				f.recordIdents(method.Type)
-			} else if ft, ok := method.Type.(*ast.FuncType); ok {
-				// f(T) -- ordinary interface method:
-				// needs all its types retained.
-				f.recordFuncType(ft)
-			}
-		}
-	}
-}
-
-// ProcessErrors records additional uses from errors, returning the new uses
-// and any unexpected errors.
-func (f *unexportedFilter) ProcessErrors(errors []types.Error) (map[string]bool, []types.Error) {
-	var unexpected []types.Error
-	missing := map[string]bool{}
-	for _, err := range errors {
-		if strings.Contains(err.Msg, "missing return") {
-			continue
-		}
-		const undeclared = "undeclared name: "
-		if strings.HasPrefix(err.Msg, undeclared) {
-			missing[strings.TrimPrefix(err.Msg, undeclared)] = true
-			f.uses[strings.TrimPrefix(err.Msg, undeclared)] = true
-			continue
-		}
-		unexpected = append(unexpected, err)
-	}
-	return missing, unexpected
-}
-
-// trimAST clears any part of the AST not relevant to type checking
-// the package-level declarations.
-func trimAST(file *ast.File) {
-	// Eliminate bodies of top-level functions, methods, inits.
-	for _, decl := range file.Decls {
-		if fn, ok := decl.(*ast.FuncDecl); ok {
-			fn.Body = nil
-		}
-	}
-
-	// Simplify remaining declarations.
-	ast.Inspect(file, func(n ast.Node) bool {
-		switch n := n.(type) {
-		case *ast.FuncLit:
-			// Eliminate bodies of literal functions.
-			// func() { ... } => func() {}
-			n.Body.List = nil
-		case *ast.CompositeLit:
-			// types.Info.Types for long slice/array literals are particularly
-			// expensive. Try to clear them out: T{e, ..., e} => T{}
-			at, ok := n.Type.(*ast.ArrayType)
-			if !ok {
-				// Map or struct literal: no harm removing all its fields.
-				n.Elts = nil
-				break
-			}
-
-			// Removing the elements from an ellipsis array changes its type.
-			// Try to set the length explicitly so we can continue.
-			//  [...]T{e, ..., e} => [3]T[]{}
-			if _, ok := at.Len.(*ast.Ellipsis); ok {
-				length, ok := arrayLength(n)
-				if !ok {
-					break
-				}
-				at.Len = &ast.BasicLit{
-					Kind:     token.INT,
-					Value:    fmt.Sprint(length),
-					ValuePos: at.Len.Pos(),
-				}
-			}
-			n.Elts = nil
-		}
-		return true
-	})
-}
-
-// arrayLength returns the length of some simple forms of ellipsis array literal.
-// Notably, it handles the tables in golang.org/x/text.
-func arrayLength(array *ast.CompositeLit) (int, bool) {
-	litVal := func(expr ast.Expr) (int, bool) {
-		lit, ok := expr.(*ast.BasicLit)
-		if !ok {
-			return 0, false
-		}
-		val, err := strconv.ParseInt(lit.Value, 10, 64)
-		if err != nil {
-			return 0, false
-		}
-		return int(val), true
-	}
-	largestKey := -1
-	for _, elt := range array.Elts {
-		kve, ok := elt.(*ast.KeyValueExpr)
-		if !ok {
-			continue
-		}
-		switch key := kve.Key.(type) {
-		case *ast.BasicLit:
-			if val, ok := litVal(key); ok && largestKey < val {
-				largestKey = val
-			}
-		case *ast.BinaryExpr:
-			// golang.org/x/text uses subtraction (and only subtraction) in its indices.
-			if key.Op != token.SUB {
-				break
-			}
-			x, ok := litVal(key.X)
-			if !ok {
-				break
-			}
-			y, ok := litVal(key.Y)
-			if !ok {
-				break
-			}
-			if val := x - y; largestKey < val {
-				largestKey = val
-			}
-		}
-	}
-	if largestKey != -1 {
-		return largestKey + 1, true
-	}
-	return len(array.Elts), true
-}
-
-// fixAST inspects the AST and potentially modifies any *ast.BadStmts so that it can be
-// type-checked more effectively.
-//
-// If fixAST returns true, the resulting AST is considered "fixed", meaning
-// positions have been mangled, and type checker errors may not make sense.
-func fixAST(n ast.Node, tok *token.File, src []byte) (fixed bool) {
-	var err error
-	walkASTWithParent(n, func(n, parent ast.Node) bool {
-		switch n := n.(type) {
-		case *ast.BadStmt:
-			if fixed = fixDeferOrGoStmt(n, parent, tok, src); fixed {
-				// Recursively fix in our fixed node.
-				_ = fixAST(parent, tok, src)
-			} else {
-				err = fmt.Errorf("unable to parse defer or go from *ast.BadStmt: %v", err)
-			}
-			return false
-		case *ast.BadExpr:
-			if fixed = fixArrayType(n, parent, tok, src); fixed {
-				// Recursively fix in our fixed node.
-				_ = fixAST(parent, tok, src)
-				return false
-			}
-
-			// Fix cases where parser interprets if/for/switch "init"
-			// statement as "cond" expression, e.g.:
-			//
-			//   // "i := foo" is init statement, not condition.
-			//   for i := foo
-			//
-			fixInitStmt(n, parent, tok, src)
-
-			return false
-		case *ast.SelectorExpr:
-			// Fix cases where a keyword prefix results in a phantom "_" selector, e.g.:
-			//
-			//   foo.var<> // want to complete to "foo.variance"
-			//
-			fixPhantomSelector(n, tok, src)
-			return true
-
-		case *ast.BlockStmt:
-			switch parent.(type) {
-			case *ast.SwitchStmt, *ast.TypeSwitchStmt, *ast.SelectStmt:
-				// Adjust closing curly brace of empty switch/select
-				// statements so we can complete inside them.
-				fixEmptySwitch(n, tok, src)
-			}
-
-			return true
-		default:
-			return true
-		}
-	})
-	return fixed
-}
-
-// walkASTWithParent walks the AST rooted at n. The semantics are
-// similar to ast.Inspect except it does not call f(nil).
-func walkASTWithParent(n ast.Node, f func(n ast.Node, parent ast.Node) bool) {
-	var ancestors []ast.Node
-	ast.Inspect(n, func(n ast.Node) (recurse bool) {
-		defer func() {
-			if recurse {
-				ancestors = append(ancestors, n)
-			}
-		}()
-
-		if n == nil {
-			ancestors = ancestors[:len(ancestors)-1]
-			return false
-		}
-
-		var parent ast.Node
-		if len(ancestors) > 0 {
-			parent = ancestors[len(ancestors)-1]
-		}
-
-		return f(n, parent)
-	})
-}
-
-// fixSrc attempts to modify the file's source code to fix certain
-// syntax errors that leave the rest of the file unparsed.
-func fixSrc(f *ast.File, tf *token.File, src []byte) (newSrc []byte) {
-	walkASTWithParent(f, func(n, parent ast.Node) bool {
-		if newSrc != nil {
-			return false
-		}
-
-		switch n := n.(type) {
-		case *ast.BlockStmt:
-			newSrc = fixMissingCurlies(f, n, parent, tf, src)
-		case *ast.SelectorExpr:
-			newSrc = fixDanglingSelector(n, tf, src)
-		}
-
-		return newSrc == nil
-	})
-
-	return newSrc
-}
-
-// fixMissingCurlies adds in curly braces for block statements that
-// are missing curly braces. For example:
-//
-//	if foo
-//
-// becomes
-//
-//	if foo {}
-func fixMissingCurlies(f *ast.File, b *ast.BlockStmt, parent ast.Node, tok *token.File, src []byte) []byte {
-	// If the "{" is already in the source code, there isn't anything to
-	// fix since we aren't missing curlies.
-	if b.Lbrace.IsValid() {
-		braceOffset, err := safetoken.Offset(tok, b.Lbrace)
-		if err != nil {
-			return nil
-		}
-		if braceOffset < len(src) && src[braceOffset] == '{' {
-			return nil
-		}
-	}
-
-	parentLine := tok.Line(parent.Pos())
-
-	if parentLine >= tok.LineCount() {
-		// If we are the last line in the file, no need to fix anything.
-		return nil
-	}
-
-	// Insert curlies at the end of parent's starting line. The parent
-	// is the statement that contains the block, e.g. *ast.IfStmt. The
-	// block's Pos()/End() can't be relied upon because they are based
-	// on the (missing) curly braces. We assume the statement is a
-	// single line for now and try sticking the curly braces at the end.
-	insertPos := tok.LineStart(parentLine+1) - 1
-
-	// Scootch position backwards until it's not in a comment. For example:
-	//
-	// if foo<> // some amazing comment |
-	// someOtherCode()
-	//
-	// insertPos will be located at "|", so we back it out of the comment.
-	didSomething := true
-	for didSomething {
-		didSomething = false
-		for _, c := range f.Comments {
-			if c.Pos() < insertPos && insertPos <= c.End() {
-				insertPos = c.Pos()
-				didSomething = true
-			}
-		}
-	}
-
-	// Bail out if line doesn't end in an ident or ".". This is to avoid
-	// cases like below where we end up making things worse by adding
-	// curlies:
-	//
-	//   if foo &&
-	//     bar<>
-	switch precedingToken(insertPos, tok, src) {
-	case token.IDENT, token.PERIOD:
-		// ok
-	default:
-		return nil
-	}
-
-	var buf bytes.Buffer
-	buf.Grow(len(src) + 3)
-	offset, err := safetoken.Offset(tok, insertPos)
-	if err != nil {
-		return nil
-	}
-	buf.Write(src[:offset])
-
-	// Detect if we need to insert a semicolon to fix "for" loop situations like:
-	//
-	//   for i := foo(); foo<>
-	//
-	// Just adding curlies is not sufficient to make things parse well.
-	if fs, ok := parent.(*ast.ForStmt); ok {
-		if _, ok := fs.Cond.(*ast.BadExpr); !ok {
-			if xs, ok := fs.Post.(*ast.ExprStmt); ok {
-				if _, ok := xs.X.(*ast.BadExpr); ok {
-					buf.WriteByte(';')
-				}
-			}
-		}
-	}
-
-	// Insert "{}" at insertPos.
-	buf.WriteByte('{')
-	buf.WriteByte('}')
-	buf.Write(src[offset:])
-	return buf.Bytes()
-}
-
-// fixEmptySwitch moves empty switch/select statements' closing curly
-// brace down one line. This allows us to properly detect incomplete
-// "case" and "default" keywords as inside the switch statement. For
-// example:
-//
-//	switch {
-//	def<>
-//	}
-//
-// gets parsed like:
-//
-//	switch {
-//	}
-//
-// Later we manually pull out the "def" token, but we need to detect
-// that our "<>" position is inside the switch block. To do that we
-// move the curly brace so it looks like:
-//
-//	switch {
-//
-//	}
-func fixEmptySwitch(body *ast.BlockStmt, tok *token.File, src []byte) {
-	// We only care about empty switch statements.
-	if len(body.List) > 0 || !body.Rbrace.IsValid() {
-		return
-	}
-
-	// If the right brace is actually in the source code at the
-	// specified position, don't mess with it.
-	braceOffset, err := safetoken.Offset(tok, body.Rbrace)
-	if err != nil {
-		return
-	}
-	if braceOffset < len(src) && src[braceOffset] == '}' {
-		return
-	}
-
-	braceLine := tok.Line(body.Rbrace)
-	if braceLine >= tok.LineCount() {
-		// If we are the last line in the file, no need to fix anything.
-		return
-	}
-
-	// Move the right brace down one line.
-	body.Rbrace = tok.LineStart(braceLine + 1)
-}
-
-// fixDanglingSelector inserts real "_" selector expressions in place
-// of phantom "_" selectors. For example:
-//
-//	func _() {
-//		x.<>
-//	}
-//
-// var x struct { i int }
-//
-// To fix completion at "<>", we insert a real "_" after the "." so the
-// following declaration of "x" can be parsed and type checked
-// normally.
-func fixDanglingSelector(s *ast.SelectorExpr, tf *token.File, src []byte) []byte {
-	if !isPhantomUnderscore(s.Sel, tf, src) {
-		return nil
-	}
-
-	if !s.X.End().IsValid() {
-		return nil
-	}
-
-	insertOffset, err := safetoken.Offset(tf, s.X.End())
-	if err != nil {
-		return nil
-	}
-	// Insert directly after the selector's ".".
-	insertOffset++
-	if src[insertOffset-1] != '.' {
-		return nil
-	}
-
-	var buf bytes.Buffer
-	buf.Grow(len(src) + 1)
-	buf.Write(src[:insertOffset])
-	buf.WriteByte('_')
-	buf.Write(src[insertOffset:])
-	return buf.Bytes()
-}
-
-// fixPhantomSelector tries to fix selector expressions with phantom
-// "_" selectors. In particular, we check if the selector is a
-// keyword, and if so we swap in an *ast.Ident with the keyword text. For example:
-//
-// foo.var
-//
-// yields a "_" selector instead of "var" since "var" is a keyword.
-//
-// TODO(rfindley): should this constitute an ast 'fix'?
-func fixPhantomSelector(sel *ast.SelectorExpr, tf *token.File, src []byte) {
-	if !isPhantomUnderscore(sel.Sel, tf, src) {
-		return
-	}
-
-	// Only consider selectors directly abutting the selector ".". This
-	// avoids false positives in cases like:
-	//
-	//   foo. // don't think "var" is our selector
-	//   var bar = 123
-	//
-	if sel.Sel.Pos() != sel.X.End()+1 {
-		return
-	}
-
-	maybeKeyword := readKeyword(sel.Sel.Pos(), tf, src)
-	if maybeKeyword == "" {
-		return
-	}
-
-	replaceNode(sel, sel.Sel, &ast.Ident{
-		Name:    maybeKeyword,
-		NamePos: sel.Sel.Pos(),
-	})
-}
-
-// isPhantomUnderscore reports whether the given ident is a phantom
-// underscore. The parser sometimes inserts phantom underscores when
-// it encounters otherwise unparseable situations.
-func isPhantomUnderscore(id *ast.Ident, tok *token.File, src []byte) bool {
-	if id == nil || id.Name != "_" {
-		return false
-	}
-
-	// Phantom underscore means the underscore is not actually in the
-	// program text.
-	offset, err := safetoken.Offset(tok, id.Pos())
-	if err != nil {
-		return false
-	}
-	return len(src) <= offset || src[offset] != '_'
-}
-
-// fixInitStmt fixes cases where the parser misinterprets an
-// if/for/switch "init" statement as the "cond" conditional. In cases
-// like "if i := 0" the user hasn't typed the semicolon yet so the
-// parser is looking for the conditional expression. However, "i := 0"
-// are not valid expressions, so we get a BadExpr.
-//
-// fixInitStmt returns valid AST for the original source.
-func fixInitStmt(bad *ast.BadExpr, parent ast.Node, tok *token.File, src []byte) {
-	if !bad.Pos().IsValid() || !bad.End().IsValid() {
-		return
-	}
-
-	// Try to extract a statement from the BadExpr.
-	start, err := safetoken.Offset(tok, bad.Pos())
-	if err != nil {
-		return
-	}
-	end, err := safetoken.Offset(tok, bad.End()-1)
-	if err != nil {
-		return
-	}
-	stmtBytes := src[start : end+1]
-	stmt, err := parseStmt(bad.Pos(), stmtBytes)
-	if err != nil {
-		return
-	}
-
-	// If the parent statement doesn't already have an "init" statement,
-	// move the extracted statement into the "init" field and insert a
-	// dummy expression into the required "cond" field.
-	switch p := parent.(type) {
-	case *ast.IfStmt:
-		if p.Init != nil {
-			return
-		}
-		p.Init = stmt
-		p.Cond = &ast.Ident{
-			Name:    "_",
-			NamePos: stmt.End(),
-		}
-	case *ast.ForStmt:
-		if p.Init != nil {
-			return
-		}
-		p.Init = stmt
-		p.Cond = &ast.Ident{
-			Name:    "_",
-			NamePos: stmt.End(),
-		}
-	case *ast.SwitchStmt:
-		if p.Init != nil {
-			return
-		}
-		p.Init = stmt
-		p.Tag = nil
-	}
-}
-
-// readKeyword reads the keyword starting at pos, if any.
-func readKeyword(pos token.Pos, tok *token.File, src []byte) string {
-	var kwBytes []byte
-	offset, err := safetoken.Offset(tok, pos)
-	if err != nil {
-		return ""
-	}
-	for i := offset; i < len(src); i++ {
-		// Use a simplified identifier check since keywords are always lowercase ASCII.
-		if src[i] < 'a' || src[i] > 'z' {
-			break
-		}
-		kwBytes = append(kwBytes, src[i])
-
-		// Stop search at arbitrarily chosen too-long-for-a-keyword length.
-		if len(kwBytes) > 15 {
-			return ""
-		}
-	}
-
-	if kw := string(kwBytes); token.Lookup(kw).IsKeyword() {
-		return kw
-	}
-
-	return ""
-}
-
-// fixArrayType tries to parse an *ast.BadExpr into an *ast.ArrayType.
-// go/parser often turns lone array types like "[]int" into BadExprs
-// if it isn't expecting a type.
-func fixArrayType(bad *ast.BadExpr, parent ast.Node, tok *token.File, src []byte) bool {
-	// Our expected input is a bad expression that looks like "[]someExpr".
-
-	from := bad.Pos()
-	to := bad.End()
-
-	if !from.IsValid() || !to.IsValid() {
-		return false
-	}
-
-	exprBytes := make([]byte, 0, int(to-from)+3)
-	// Avoid doing tok.Offset(to) since that panics if badExpr ends at EOF.
-	// It also panics if the position is not in the range of the file, and
-	// badExprs may not necessarily have good positions, so check first.
-	fromOffset, err := safetoken.Offset(tok, from)
-	if err != nil {
-		return false
-	}
-	toOffset, err := safetoken.Offset(tok, to-1)
-	if err != nil {
-		return false
-	}
-	exprBytes = append(exprBytes, src[fromOffset:toOffset+1]...)
-	exprBytes = bytes.TrimSpace(exprBytes)
-
-	// If our expression ends in "]" (e.g. "[]"), add a phantom selector
-	// so we can complete directly after the "[]".
-	if len(exprBytes) > 0 && exprBytes[len(exprBytes)-1] == ']' {
-		exprBytes = append(exprBytes, '_')
-	}
-
-	// Add "{}" to turn our ArrayType into a CompositeLit. This is to
-	// handle the case of "[...]int" where we must make it a composite
-	// literal to be parseable.
-	exprBytes = append(exprBytes, '{', '}')
-
-	expr, err := parseExpr(from, exprBytes)
-	if err != nil {
-		return false
-	}
-
-	cl, _ := expr.(*ast.CompositeLit)
-	if cl == nil {
-		return false
-	}
-
-	at, _ := cl.Type.(*ast.ArrayType)
-	if at == nil {
-		return false
-	}
-
-	return replaceNode(parent, bad, at)
-}
-
-// precedingToken scans src to find the token preceding pos.
-func precedingToken(pos token.Pos, tok *token.File, src []byte) token.Token {
-	s := &scanner.Scanner{}
-	s.Init(tok, src, nil, 0)
-
-	var lastTok token.Token
-	for {
-		p, t, _ := s.Scan()
-		if t == token.EOF || p >= pos {
-			break
-		}
-
-		lastTok = t
-	}
-	return lastTok
-}
-
-// fixDeferOrGoStmt tries to parse an *ast.BadStmt into a defer or a go statement.
-//
-// go/parser packages a statement of the form "defer x." as an *ast.BadStmt because
-// it does not include a call expression. This means that go/types skips type-checking
-// this statement entirely, and we can't use the type information when completing.
-// Here, we try to generate a fake *ast.DeferStmt or *ast.GoStmt to put into the AST,
-// instead of the *ast.BadStmt.
-func fixDeferOrGoStmt(bad *ast.BadStmt, parent ast.Node, tok *token.File, src []byte) bool {
-	// Check if we have a bad statement containing either a "go" or "defer".
-	s := &scanner.Scanner{}
-	s.Init(tok, src, nil, 0)
-
-	var (
-		pos token.Pos
-		tkn token.Token
-	)
-	for {
-		if tkn == token.EOF {
-			return false
-		}
-		if pos >= bad.From {
-			break
-		}
-		pos, tkn, _ = s.Scan()
-	}
-
-	var stmt ast.Stmt
-	switch tkn {
-	case token.DEFER:
-		stmt = &ast.DeferStmt{
-			Defer: pos,
-		}
-	case token.GO:
-		stmt = &ast.GoStmt{
-			Go: pos,
-		}
-	default:
-		return false
-	}
-
-	var (
-		from, to, last   token.Pos
-		lastToken        token.Token
-		braceDepth       int
-		phantomSelectors []token.Pos
-	)
-FindTo:
-	for {
-		to, tkn, _ = s.Scan()
-
-		if from == token.NoPos {
-			from = to
-		}
-
-		switch tkn {
-		case token.EOF:
-			break FindTo
-		case token.SEMICOLON:
-			// If we aren't in nested braces, end of statement means
-			// end of expression.
-			if braceDepth == 0 {
-				break FindTo
-			}
-		case token.LBRACE:
-			braceDepth++
-		}
-
-		// This handles the common dangling selector case. For example in
-		//
-		// defer fmt.
-		// y := 1
-		//
-		// we notice the dangling period and end our expression.
-		//
-		// If the previous token was a "." and we are looking at a "}",
-		// the period is likely a dangling selector and needs a phantom
-		// "_". Likewise if the current token is on a different line than
-		// the period, the period is likely a dangling selector.
-		if lastToken == token.PERIOD && (tkn == token.RBRACE || tok.Line(to) > tok.Line(last)) {
-			// Insert phantom "_" selector after the dangling ".".
-			phantomSelectors = append(phantomSelectors, last+1)
-			// If we aren't in a block then end the expression after the ".".
-			if braceDepth == 0 {
-				to = last + 1
-				break
-			}
-		}
-
-		lastToken = tkn
-		last = to
-
-		switch tkn {
-		case token.RBRACE:
-			braceDepth--
-			if braceDepth <= 0 {
-				if braceDepth == 0 {
-					// +1 to include the "}" itself.
-					to += 1
-				}
-				break FindTo
-			}
-		}
-	}
-
-	fromOffset, err := safetoken.Offset(tok, from)
-	if err != nil {
-		return false
-	}
-	if !from.IsValid() || fromOffset >= len(src) {
-		return false
-	}
-
-	toOffset, err := safetoken.Offset(tok, to)
-	if err != nil {
-		return false
-	}
-	if !to.IsValid() || toOffset >= len(src) {
-		return false
-	}
-
-	// Insert any phantom selectors needed to prevent dangling "." from messing
-	// up the AST.
-	exprBytes := make([]byte, 0, int(to-from)+len(phantomSelectors))
-	for i, b := range src[fromOffset:toOffset] {
-		if len(phantomSelectors) > 0 && from+token.Pos(i) == phantomSelectors[0] {
-			exprBytes = append(exprBytes, '_')
-			phantomSelectors = phantomSelectors[1:]
-		}
-		exprBytes = append(exprBytes, b)
-	}
-
-	if len(phantomSelectors) > 0 {
-		exprBytes = append(exprBytes, '_')
-	}
-
-	expr, err := parseExpr(from, exprBytes)
-	if err != nil {
-		return false
-	}
-
-	// Package the expression into a fake *ast.CallExpr and re-insert
-	// into the function.
-	call := &ast.CallExpr{
-		Fun:    expr,
-		Lparen: to,
-		Rparen: to,
-	}
-
-	switch stmt := stmt.(type) {
-	case *ast.DeferStmt:
-		stmt.Call = call
-	case *ast.GoStmt:
-		stmt.Call = call
-	}
-
-	return replaceNode(parent, bad, stmt)
-}
-
-// parseStmt parses the statement in src and updates its position to
-// start at pos.
-func parseStmt(pos token.Pos, src []byte) (ast.Stmt, error) {
-	// Wrap our expression to make it a valid Go file we can pass to ParseFile.
-	fileSrc := bytes.Join([][]byte{
-		[]byte("package fake;func _(){"),
-		src,
-		[]byte("}"),
-	}, nil)
-
-	// Use ParseFile instead of ParseExpr because ParseFile has
-	// best-effort behavior, whereas ParseExpr fails hard on any error.
-	fakeFile, err := parser.ParseFile(token.NewFileSet(), "", fileSrc, 0)
-	if fakeFile == nil {
-		return nil, fmt.Errorf("error reading fake file source: %v", err)
-	}
-
-	// Extract our expression node from inside the fake file.
-	if len(fakeFile.Decls) == 0 {
-		return nil, fmt.Errorf("error parsing fake file: %v", err)
-	}
-
-	fakeDecl, _ := fakeFile.Decls[0].(*ast.FuncDecl)
-	if fakeDecl == nil || len(fakeDecl.Body.List) == 0 {
-		return nil, fmt.Errorf("no statement in %s: %v", src, err)
-	}
-
-	stmt := fakeDecl.Body.List[0]
-
-	// parser.ParseFile returns undefined positions.
-	// Adjust them for the current file.
-	offsetPositions(stmt, pos-1-(stmt.Pos()-1))
-
-	return stmt, nil
-}
-
-// parseExpr parses the expression in src and updates its position to
-// start at pos.
-func parseExpr(pos token.Pos, src []byte) (ast.Expr, error) {
-	stmt, err := parseStmt(pos, src)
-	if err != nil {
-		return nil, err
-	}
-
-	exprStmt, ok := stmt.(*ast.ExprStmt)
-	if !ok {
-		return nil, fmt.Errorf("no expr in %s: %v", src, err)
-	}
-
-	return exprStmt.X, nil
-}
-
-var tokenPosType = reflect.TypeOf(token.NoPos)
-
-// offsetPositions applies an offset to the positions in an ast.Node.
-func offsetPositions(n ast.Node, offset token.Pos) {
-	ast.Inspect(n, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-
-		v := reflect.ValueOf(n).Elem()
-
-		switch v.Kind() {
-		case reflect.Struct:
-			for i := 0; i < v.NumField(); i++ {
-				f := v.Field(i)
-				if f.Type() != tokenPosType {
-					continue
-				}
-
-				if !f.CanSet() {
-					continue
-				}
-
-				// Don't offset invalid positions: they should stay invalid.
-				if !token.Pos(f.Int()).IsValid() {
-					continue
-				}
-
-				f.SetInt(f.Int() + int64(offset))
-			}
-		}
-
-		return true
-	})
-}
-
-// replaceNode updates parent's child oldChild to be newChild. It
-// returns whether it replaced successfully.
-func replaceNode(parent, oldChild, newChild ast.Node) bool {
-	if parent == nil || oldChild == nil || newChild == nil {
-		return false
-	}
-
-	parentVal := reflect.ValueOf(parent).Elem()
-	if parentVal.Kind() != reflect.Struct {
-		return false
-	}
-
-	newChildVal := reflect.ValueOf(newChild)
-
-	tryReplace := func(v reflect.Value) bool {
-		if !v.CanSet() || !v.CanInterface() {
-			return false
-		}
-
-		// If the existing value is oldChild, we found our child. Make
-		// sure our newChild is assignable and then make the swap.
-		if v.Interface() == oldChild && newChildVal.Type().AssignableTo(v.Type()) {
-			v.Set(newChildVal)
-			return true
-		}
-
-		return false
-	}
-
-	// Loop over parent's struct fields.
-	for i := 0; i < parentVal.NumField(); i++ {
-		f := parentVal.Field(i)
-
-		switch f.Kind() {
-		// Check interface and pointer fields.
-		case reflect.Interface, reflect.Ptr:
-			if tryReplace(f) {
-				return true
-			}
-
-		// Search through any slice fields.
-		case reflect.Slice:
-			for i := 0; i < f.Len(); i++ {
-				if tryReplace(f.Index(i)) {
-					return true
-				}
-			}
-		}
-	}
-
-	return false
-}
diff -urN a/gopls/internal/lsp/cache/parse_test.go b/gopls/internal/lsp/cache/parse_test.go
--- a/gopls/internal/lsp/cache/parse_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/parse_test.go	1969-12-31 16:00:00
@@ -1,217 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"bytes"
-	"go/ast"
-	"go/format"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"reflect"
-	"sort"
-	"testing"
-
-	"golang.org/x/tools/go/packages"
-)
-
-func TestArrayLength(t *testing.T) {
-	tests := []struct {
-		expr   string
-		length int
-	}{
-		{`[...]int{0,1,2,3,4,5,6,7,8,9}`, 10},
-		{`[...]int{9:0}`, 10},
-		{`[...]int{19-10:0}`, 10},
-		{`[...]int{19-10:0, 17-10:0, 18-10:0}`, 10},
-	}
-
-	for _, tt := range tests {
-		expr, err := parser.ParseExpr(tt.expr)
-		if err != nil {
-			t.Fatal(err)
-		}
-		l, ok := arrayLength(expr.(*ast.CompositeLit))
-		if !ok {
-			t.Errorf("arrayLength did not recognize expression %#v", expr)
-		}
-		if l != tt.length {
-			t.Errorf("arrayLength(%#v) = %v, want %v", expr, l, tt.length)
-		}
-	}
-}
-
-func TestTrim(t *testing.T) {
-	tests := []struct {
-		name string
-		file string
-		kept []string
-	}{
-		{
-			name: "delete_unused",
-			file: `
-type x struct{}
-func y()
-var z int
-`,
-			kept: []string{},
-		},
-		{
-			// From the common type in testing.
-			name: "unexported_embedded",
-			file: `
-type x struct {}
-type Exported struct { x }
-`,
-			kept: []string{"Exported", "x"},
-		},
-		{
-			// From the d type in unicode.
-			name: "exported_field_unexported_type",
-			file: `
-type x struct {}
-type Exported struct {
-	X x
-}
-`,
-			kept: []string{"Exported", "x"},
-		},
-		{
-			// From errNotExist in io/fs.
-			name: "exported_var_function_call",
-			file: `
-func x() int { return 0 }
-var Exported = x()
-`,
-			kept: []string{"Exported", "x"},
-		},
-		{
-			// From DefaultServeMux in net/http.
-			name: "exported_pointer_to_unexported_var",
-			file: `
-var Exported = &x
-var x int
-`,
-			kept: []string{"Exported", "x"},
-		},
-		{
-			// From DefaultWriter in goldmark/renderer/html.
-			name: "exported_pointer_to_composite_lit",
-			file: `
-var Exported = &x{}
-type x struct{}
-`,
-			kept: []string{"Exported", "x"},
-		},
-		{
-			// From SelectDir in reflect.
-			name: "leave_constants",
-			file: `
-type Enum int
-const (
-	_             Enum = iota
-	EnumOne
-)
-`,
-			kept: []string{"Enum", "EnumOne"},
-		},
-		{
-			name: "constant_conversion",
-			file: `
-type x int
-const (
-	foo x = 0
-)
-`,
-			kept: []string{"x", "foo"},
-		},
-		{
-			name: "unexported_return",
-			file: `
-type x int
-func Exported() x {}
-type y int
-type Interface interface {
-	Exported() y
-}
-`,
-			kept: []string{"Exported", "Interface", "x", "y"},
-		},
-		{
-			name: "drop_composite_literals",
-			file: `
-type x int
-type Exported struct {
-	foo x
-}
-var Var = Exported{foo:1}
-`,
-			kept: []string{"Exported", "Var", "x"},
-		},
-		{
-			name: "drop_function_literals",
-			file: `
-type x int
-var Exported = func() { return x(0) }
-`,
-			kept: []string{"Exported"},
-		},
-		{
-			name: "missing_receiver_panic",
-			file: `
-			func() foo() {}
-`,
-			kept: []string{},
-		},
-	}
-
-	for _, tt := range tests {
-		t.Run(tt.name, func(t *testing.T) {
-			fset := token.NewFileSet()
-			file, err := parser.ParseFile(fset, "main.go", "package main\n\n"+tt.file, parser.AllErrors)
-			if err != nil {
-				t.Fatal(err)
-			}
-			filter := &unexportedFilter{uses: map[string]bool{}}
-			filter.Filter([]*ast.File{file})
-			pkg := types.NewPackage("main", "main")
-			checker := types.NewChecker(&types.Config{
-				DisableUnusedImportCheck: true,
-			}, fset, pkg, nil)
-			if err := checker.Files([]*ast.File{file}); err != nil {
-				t.Error(err)
-			}
-			names := pkg.Scope().Names()
-			sort.Strings(names)
-			sort.Strings(tt.kept)
-			if !reflect.DeepEqual(names, tt.kept) {
-				t.Errorf("package contains names %v, wanted %v", names, tt.kept)
-			}
-		})
-	}
-}
-
-func TestPkg(t *testing.T) {
-	t.Skip("for manual debugging")
-	fset := token.NewFileSet()
-	pkgs, err := packages.Load(&packages.Config{
-		Mode: packages.NeedSyntax | packages.NeedFiles,
-		Fset: fset,
-	}, "io")
-	if err != nil {
-		t.Fatal(err)
-	}
-	if len(pkgs[0].Errors) != 0 {
-		t.Fatal(pkgs[0].Errors)
-	}
-	filter := &unexportedFilter{uses: map[string]bool{}}
-	filter.Filter(pkgs[0].Syntax)
-	for _, file := range pkgs[0].Syntax {
-		buf := &bytes.Buffer{}
-		format.Node(buf, fset, file)
-		t.Log(buf.String())
-	}
-}
diff -urN a/gopls/internal/lsp/cache/parsemode_go116.go b/gopls/internal/lsp/cache/parsemode_go116.go
--- a/gopls/internal/lsp/cache/parsemode_go116.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/parsemode_go116.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.17
-// +build !go1.17
-
-package cache
-
-// The parser.SkipObjectResolution mode flag is not supported before Go 1.17.
-const skipObjectResolution = 0
diff -urN a/gopls/internal/lsp/cache/parsemode_go117.go b/gopls/internal/lsp/cache/parsemode_go117.go
--- a/gopls/internal/lsp/cache/parsemode_go117.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/parsemode_go117.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.17
-// +build go1.17
-
-package cache
-
-import "go/parser"
-
-const skipObjectResolution = parser.SkipObjectResolution
diff -urN a/gopls/internal/lsp/cache/pkg.go b/gopls/internal/lsp/cache/pkg.go
--- a/gopls/internal/lsp/cache/pkg.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/pkg.go	1969-12-31 16:00:00
@@ -1,173 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"fmt"
-	"go/ast"
-	"go/scanner"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/mod/module"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// Convenient local aliases for typed strings.
-type (
-	PackageID   = source.PackageID
-	PackagePath = source.PackagePath
-	PackageName = source.PackageName
-	ImportPath  = source.ImportPath
-)
-
-// pkg contains parse trees and type information for a package.
-type pkg struct {
-	m               *source.Metadata
-	mode            source.ParseMode
-	fset            *token.FileSet // for now, same as the snapshot's FileSet
-	goFiles         []*source.ParsedGoFile
-	compiledGoFiles []*source.ParsedGoFile
-	diagnostics     []*source.Diagnostic
-	deps            map[PackageID]*pkg // use m.DepsBy{Pkg,Imp}Path to look up ID
-	version         *module.Version    // may be nil; may differ from m.Module.Version
-	parseErrors     []scanner.ErrorList
-	typeErrors      []types.Error
-	types           *types.Package
-	typesInfo       *types.Info
-	hasFixedFiles   bool // if true, AST was sufficiently mangled that we should hide type errors
-
-	analyses memoize.Store // maps analyzer.Name to Promise[actionResult]
-}
-
-func (p *pkg) String() string { return string(p.ID()) }
-
-// A loadScope defines a package loading scope for use with go/packages.
-type loadScope interface {
-	aScope()
-}
-
-type (
-	fileLoadScope    span.URI // load packages containing a file (including command-line-arguments)
-	packageLoadScope string   // load a specific package (the value is its PackageID)
-	moduleLoadScope  string   // load packages in a specific module
-	viewLoadScope    span.URI // load the workspace
-)
-
-// Implement the loadScope interface.
-func (fileLoadScope) aScope()    {}
-func (packageLoadScope) aScope() {}
-func (moduleLoadScope) aScope()  {}
-func (viewLoadScope) aScope()    {}
-
-func (p *pkg) ID() PackageID        { return p.m.ID }
-func (p *pkg) Name() PackageName    { return p.m.Name }
-func (p *pkg) PkgPath() PackagePath { return p.m.PkgPath }
-
-func (p *pkg) ParseMode() source.ParseMode {
-	return p.mode
-}
-
-func (p *pkg) CompiledGoFiles() []*source.ParsedGoFile {
-	return p.compiledGoFiles
-}
-
-func (p *pkg) File(uri span.URI) (*source.ParsedGoFile, error) {
-	for _, cgf := range p.compiledGoFiles {
-		if cgf.URI == uri {
-			return cgf, nil
-		}
-	}
-	for _, gf := range p.goFiles {
-		if gf.URI == uri {
-			return gf, nil
-		}
-	}
-	return nil, fmt.Errorf("no parsed file for %s in %v", uri, p.m.ID)
-}
-
-func (p *pkg) GetSyntax() []*ast.File {
-	var syntax []*ast.File
-	for _, pgf := range p.compiledGoFiles {
-		syntax = append(syntax, pgf.File)
-	}
-	return syntax
-}
-
-func (p *pkg) FileSet() *token.FileSet {
-	return p.fset
-}
-
-func (p *pkg) GetTypes() *types.Package {
-	return p.types
-}
-
-func (p *pkg) GetTypesInfo() *types.Info {
-	return p.typesInfo
-}
-
-func (p *pkg) GetTypesSizes() types.Sizes {
-	return p.m.TypesSizes
-}
-
-func (p *pkg) ForTest() string {
-	return string(p.m.ForTest)
-}
-
-// DirectDep returns the directly imported dependency of this package,
-// given its PackagePath.  (If you have an ImportPath, e.g. a string
-// from an import declaration, use ResolveImportPath instead.
-// They may differ in case of vendoring.)
-func (p *pkg) DirectDep(pkgPath PackagePath) (source.Package, error) {
-	if id, ok := p.m.DepsByPkgPath[pkgPath]; ok {
-		if imp := p.deps[id]; imp != nil {
-			return imp, nil
-		}
-	}
-	return nil, fmt.Errorf("package does not import package with path %s", pkgPath)
-}
-
-// ResolveImportPath returns the directly imported dependency of this package,
-// given its ImportPath. See also DirectDep.
-func (p *pkg) ResolveImportPath(importPath ImportPath) (source.Package, error) {
-	if id, ok := p.m.DepsByImpPath[importPath]; ok && id != "" {
-		if imp := p.deps[id]; imp != nil {
-			return imp, nil
-		}
-	}
-	return nil, fmt.Errorf("package does not import %s", importPath)
-}
-
-func (p *pkg) Imports() []source.Package {
-	var result []source.Package // unordered
-	for _, dep := range p.deps {
-		result = append(result, dep)
-	}
-	return result
-}
-
-func (p *pkg) Version() *module.Version {
-	return p.version
-}
-
-func (p *pkg) HasListOrParseErrors() bool {
-	return len(p.m.Errors) != 0 || len(p.parseErrors) != 0
-}
-
-func (p *pkg) HasTypeErrors() bool {
-	return len(p.typeErrors) != 0
-}
-
-func (p *pkg) DiagnosticsForFile(uri span.URI) []*source.Diagnostic {
-	var res []*source.Diagnostic
-	for _, diag := range p.diagnostics {
-		if diag.URI == uri {
-			res = append(res, diag)
-		}
-	}
-	return res
-}
diff -urN a/gopls/internal/lsp/cache/session.go b/gopls/internal/lsp/cache/session.go
--- a/gopls/internal/lsp/cache/session.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/session.go	1969-12-31 16:00:00
@@ -1,884 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"fmt"
-	"os"
-	"strconv"
-	"strings"
-	"sync"
-	"sync/atomic"
-
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/imports"
-	"golang.org/x/tools/internal/persistent"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-type Session struct {
-	// Unique identifier for this session.
-	id string
-
-	// Immutable attributes shared across views.
-	cache       *Cache            // shared cache
-	gocmdRunner *gocommand.Runner // limits go command concurrency
-
-	optionsMu sync.Mutex
-	options   *source.Options
-
-	viewMu  sync.Mutex
-	views   []*View
-	viewMap map[span.URI]*View // map of URI->best view
-
-	overlayMu sync.Mutex
-	overlays  map[span.URI]*overlay
-}
-
-type overlay struct {
-	session *Session
-	uri     span.URI
-	text    []byte
-	hash    source.Hash
-	version int32
-	kind    source.FileKind
-
-	// saved is true if a file matches the state on disk,
-	// and therefore does not need to be part of the overlay sent to go/packages.
-	saved bool
-}
-
-func (o *overlay) Read() ([]byte, error) {
-	return o.text, nil
-}
-
-func (o *overlay) FileIdentity() source.FileIdentity {
-	return source.FileIdentity{
-		URI:  o.uri,
-		Hash: o.hash,
-	}
-}
-
-func (o *overlay) VersionedFileIdentity() source.VersionedFileIdentity {
-	return source.VersionedFileIdentity{
-		URI:       o.uri,
-		SessionID: o.session.id,
-		Version:   o.version,
-	}
-}
-
-func (o *overlay) Kind() source.FileKind {
-	return o.kind
-}
-
-func (o *overlay) URI() span.URI {
-	return o.uri
-}
-
-func (o *overlay) Version() int32 {
-	return o.version
-}
-
-func (o *overlay) Session() string {
-	return o.session.id
-}
-
-func (o *overlay) Saved() bool {
-	return o.saved
-}
-
-// closedFile implements LSPFile for a file that the editor hasn't told us about.
-type closedFile struct {
-	source.FileHandle
-}
-
-func (c *closedFile) VersionedFileIdentity() source.VersionedFileIdentity {
-	return source.VersionedFileIdentity{
-		URI:       c.FileHandle.URI(),
-		SessionID: "",
-		Version:   0,
-	}
-}
-
-func (c *closedFile) Saved() bool {
-	return true
-}
-
-func (c *closedFile) Session() string {
-	return ""
-}
-
-func (c *closedFile) Version() int32 {
-	return 0
-}
-
-// ID returns the unique identifier for this session on this server.
-func (s *Session) ID() string     { return s.id }
-func (s *Session) String() string { return s.id }
-
-// Options returns a copy of the SessionOptions for this session.
-func (s *Session) Options() *source.Options {
-	s.optionsMu.Lock()
-	defer s.optionsMu.Unlock()
-	return s.options
-}
-
-// SetOptions sets the options of this session to new values.
-func (s *Session) SetOptions(options *source.Options) {
-	s.optionsMu.Lock()
-	defer s.optionsMu.Unlock()
-	s.options = options
-}
-
-// Shutdown the session and all views it has created.
-func (s *Session) Shutdown(ctx context.Context) {
-	var views []*View
-	s.viewMu.Lock()
-	views = append(views, s.views...)
-	s.views = nil
-	s.viewMap = nil
-	s.viewMu.Unlock()
-	for _, view := range views {
-		view.shutdown()
-	}
-	event.Log(ctx, "Shutdown session", KeyShutdownSession.Of(s))
-}
-
-// Cache returns the cache that created this session, for debugging only.
-func (s *Session) Cache() *Cache {
-	return s.cache
-}
-
-// NewView creates a new View, returning it and its first snapshot. If a
-// non-empty tempWorkspace directory is provided, the View will record a copy
-// of its gopls workspace module in that directory, so that client tooling
-// can execute in the same main module.  On success it also returns a release
-// function that must be called when the Snapshot is no longer needed.
-func (s *Session) NewView(ctx context.Context, name string, folder span.URI, options *source.Options) (*View, source.Snapshot, func(), error) {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-	for _, view := range s.views {
-		if span.SameExistingFile(view.folder, folder) {
-			return nil, nil, nil, source.ErrViewExists
-		}
-	}
-	view, snapshot, release, err := s.createView(ctx, name, folder, options, 0)
-	if err != nil {
-		return nil, nil, nil, err
-	}
-	s.views = append(s.views, view)
-	// we always need to drop the view map
-	s.viewMap = make(map[span.URI]*View)
-	return view, snapshot, release, nil
-}
-
-func (s *Session) createView(ctx context.Context, name string, folder span.URI, options *source.Options, seqID uint64) (*View, *snapshot, func(), error) {
-	index := atomic.AddInt64(&viewIndex, 1)
-
-	// Get immutable workspace configuration.
-	//
-	// TODO(rfindley): this info isn't actually immutable. For example, GOWORK
-	// could be changed, or a user's environment could be modified.
-	// We need a mechanism to invalidate it.
-	wsInfo, err := s.getWorkspaceInformation(ctx, folder, options)
-	if err != nil {
-		return nil, nil, func() {}, err
-	}
-
-	root := folder
-	// filterFunc is the path filter function for this workspace folder. Notably,
-	// it is relative to folder (which is specified by the user), not root.
-	filterFunc := pathExcludedByFilterFunc(folder.Filename(), wsInfo.gomodcache, options)
-	rootSrc, err := findWorkspaceModuleSource(ctx, root, s, filterFunc, options.ExperimentalWorkspaceModule)
-	if err != nil {
-		return nil, nil, func() {}, err
-	}
-	if options.ExpandWorkspaceToModule && rootSrc != "" {
-		root = span.Dir(rootSrc)
-	}
-
-	explicitGowork := os.Getenv("GOWORK")
-	if v, ok := options.Env["GOWORK"]; ok {
-		explicitGowork = v
-	}
-	goworkURI := span.URIFromPath(explicitGowork)
-
-	// Build the gopls workspace, collecting active modules in the view.
-	workspace, err := newWorkspace(ctx, root, goworkURI, s, filterFunc, wsInfo.effectiveGO111MODULE() == off, options.ExperimentalWorkspaceModule)
-	if err != nil {
-		return nil, nil, func() {}, err
-	}
-
-	// We want a true background context and not a detached context here
-	// the spans need to be unrelated and no tag values should pollute it.
-	baseCtx := event.Detach(xcontext.Detach(ctx))
-	backgroundCtx, cancel := context.WithCancel(baseCtx)
-
-	v := &View{
-		id:                   strconv.FormatInt(index, 10),
-		cache:                s.cache,
-		gocmdRunner:          s.gocmdRunner,
-		initialWorkspaceLoad: make(chan struct{}),
-		initializationSema:   make(chan struct{}, 1),
-		options:              options,
-		baseCtx:              baseCtx,
-		name:                 name,
-		folder:               folder,
-		moduleUpgrades:       map[span.URI]map[string]string{},
-		vulns:                map[span.URI]*govulncheck.Result{},
-		filesByURI:           make(map[span.URI]span.URI),
-		filesByBase:          make(map[string][]canonicalURI),
-		rootURI:              root,
-		rootSrc:              rootSrc,
-		explicitGowork:       goworkURI,
-		workspaceInformation: *wsInfo,
-	}
-	v.importsState = &importsState{
-		ctx: backgroundCtx,
-		processEnv: &imports.ProcessEnv{
-			GocmdRunner: s.gocmdRunner,
-			SkipPathInScan: func(dir string) bool {
-				prefix := strings.TrimSuffix(string(v.folder), "/") + "/"
-				uri := strings.TrimSuffix(string(span.URIFromPath(dir)), "/")
-				if !strings.HasPrefix(uri+"/", prefix) {
-					return false
-				}
-				filterer := source.NewFilterer(options.DirectoryFilters)
-				rel := strings.TrimPrefix(uri, prefix)
-				disallow := filterer.Disallow(rel)
-				return disallow
-			},
-		},
-	}
-	v.snapshot = &snapshot{
-		sequenceID:           seqID,
-		globalID:             nextSnapshotID(),
-		view:                 v,
-		backgroundCtx:        backgroundCtx,
-		cancel:               cancel,
-		store:                s.cache.store,
-		packages:             persistent.NewMap(packageKeyLessInterface),
-		meta:                 &metadataGraph{},
-		files:                newFilesMap(),
-		isActivePackageCache: newIsActivePackageCacheMap(),
-		parsedGoFiles:        persistent.NewMap(parseKeyLessInterface),
-		parseKeysByURI:       newParseKeysByURIMap(),
-		symbolizeHandles:     persistent.NewMap(uriLessInterface),
-		analyses:             persistent.NewMap(analysisKeyLessInterface),
-		workspacePackages:    make(map[PackageID]PackagePath),
-		unloadableFiles:      make(map[span.URI]struct{}),
-		parseModHandles:      persistent.NewMap(uriLessInterface),
-		parseWorkHandles:     persistent.NewMap(uriLessInterface),
-		modTidyHandles:       persistent.NewMap(uriLessInterface),
-		modVulnHandles:       persistent.NewMap(uriLessInterface),
-		modWhyHandles:        persistent.NewMap(uriLessInterface),
-		knownSubdirs:         newKnownDirsSet(),
-		workspace:            workspace,
-	}
-	// Save one reference in the view.
-	v.releaseSnapshot = v.snapshot.Acquire()
-
-	// Record the environment of the newly created view in the log.
-	event.Log(ctx, viewEnv(v))
-
-	// Initialize the view without blocking.
-	initCtx, initCancel := context.WithCancel(xcontext.Detach(ctx))
-	v.initCancelFirstAttempt = initCancel
-	snapshot := v.snapshot
-
-	// Pass a second reference to the background goroutine.
-	bgRelease := snapshot.Acquire()
-	go func() {
-		defer bgRelease()
-		snapshot.initialize(initCtx, true)
-	}()
-
-	// Return a third reference to the caller.
-	return v, snapshot, snapshot.Acquire(), nil
-}
-
-// View returns a view with a matching name, if the session has one.
-func (s *Session) View(name string) *View {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-	for _, view := range s.views {
-		if view.Name() == name {
-			return view
-		}
-	}
-	return nil
-}
-
-// ViewOf returns a view corresponding to the given URI.
-// If the file is not already associated with a view, pick one using some heuristics.
-func (s *Session) ViewOf(uri span.URI) (*View, error) {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-	return s.viewOfLocked(uri)
-}
-
-// Precondition: caller holds s.viewMu lock.
-func (s *Session) viewOfLocked(uri span.URI) (*View, error) {
-	// Check if we already know this file.
-	if v, found := s.viewMap[uri]; found {
-		return v, nil
-	}
-	// Pick the best view for this file and memoize the result.
-	if len(s.views) == 0 {
-		return nil, fmt.Errorf("no views in session")
-	}
-	s.viewMap[uri] = bestViewForURI(uri, s.views)
-	return s.viewMap[uri], nil
-}
-
-func (s *Session) Views() []*View {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-	result := make([]*View, len(s.views))
-	copy(result, s.views)
-	return result
-}
-
-// bestViewForURI returns the most closely matching view for the given URI
-// out of the given set of views.
-func bestViewForURI(uri span.URI, views []*View) *View {
-	// we need to find the best view for this file
-	var longest *View
-	for _, view := range views {
-		if longest != nil && len(longest.Folder()) > len(view.Folder()) {
-			continue
-		}
-		// TODO(rfindley): this should consider the workspace layout (i.e.
-		// go.work).
-		if view.contains(uri) {
-			longest = view
-		}
-	}
-	if longest != nil {
-		return longest
-	}
-	// Try our best to return a view that knows the file.
-	for _, view := range views {
-		if view.knownFile(uri) {
-			return view
-		}
-	}
-	// TODO: are there any more heuristics we can use?
-	return views[0]
-}
-
-// RemoveView removes the view v from the session
-func (s *Session) RemoveView(view *View) {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-	i := s.dropView(view)
-	if i == -1 { // error reported elsewhere
-		return
-	}
-	// delete this view... we don't care about order but we do want to make
-	// sure we can garbage collect the view
-	s.views = removeElement(s.views, i)
-}
-
-// updateView recreates the view with the given options.
-//
-// If the resulting error is non-nil, the view may or may not have already been
-// dropped from the session.
-func (s *Session) updateView(ctx context.Context, view *View, options *source.Options) (*View, error) {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-
-	return s.updateViewLocked(ctx, view, options)
-}
-
-func (s *Session) updateViewLocked(ctx context.Context, view *View, options *source.Options) (*View, error) {
-	// Preserve the snapshot ID if we are recreating the view.
-	view.snapshotMu.Lock()
-	if view.snapshot == nil {
-		view.snapshotMu.Unlock()
-		panic("updateView called after View was already shut down")
-	}
-	seqID := view.snapshot.sequenceID // Preserve sequence IDs when updating a view in place.
-	view.snapshotMu.Unlock()
-
-	i := s.dropView(view)
-	if i == -1 {
-		return nil, fmt.Errorf("view %q not found", view.id)
-	}
-
-	v, _, release, err := s.createView(ctx, view.name, view.folder, options, seqID)
-	release()
-
-	if err != nil {
-		// we have dropped the old view, but could not create the new one
-		// this should not happen and is very bad, but we still need to clean
-		// up the view array if it happens
-		s.views = removeElement(s.views, i)
-		return nil, err
-	}
-	// substitute the new view into the array where the old view was
-	s.views[i] = v
-	return v, nil
-}
-
-// removeElement removes the ith element from the slice replacing it with the last element.
-// TODO(adonovan): generics, someday.
-func removeElement(slice []*View, index int) []*View {
-	last := len(slice) - 1
-	slice[index] = slice[last]
-	slice[last] = nil // aid GC
-	return slice[:last]
-}
-
-// dropView removes v from the set of views for the receiver s and calls
-// v.shutdown, returning the index of v in s.views (if found), or -1 if v was
-// not found. s.viewMu must be held while calling this function.
-func (s *Session) dropView(v *View) int {
-	// we always need to drop the view map
-	s.viewMap = make(map[span.URI]*View)
-	for i := range s.views {
-		if v == s.views[i] {
-			// we found the view, drop it and return the index it was found at
-			s.views[i] = nil
-			v.shutdown()
-			return i
-		}
-	}
-	// TODO(rfindley): it looks wrong that we don't shutdown v in this codepath.
-	// We should never get here.
-	bug.Reportf("tried to drop nonexistent view %q", v.id)
-	return -1
-}
-
-func (s *Session) ModifyFiles(ctx context.Context, changes []source.FileModification) error {
-	_, release, err := s.DidModifyFiles(ctx, changes)
-	release()
-	return err
-}
-
-// TODO(rfindley): fileChange seems redundant with source.FileModification.
-// De-dupe into a common representation for changes.
-type fileChange struct {
-	content    []byte
-	exists     bool
-	fileHandle source.VersionedFileHandle
-
-	// isUnchanged indicates whether the file action is one that does not
-	// change the actual contents of the file. Opens and closes should not
-	// be treated like other changes, since the file content doesn't change.
-	isUnchanged bool
-}
-
-// DidModifyFiles reports a file modification to the session. It returns
-// the new snapshots after the modifications have been applied, paired with
-// the affected file URIs for those snapshots.
-// On success, it returns a release function that
-// must be called when the snapshots are no longer needed.
-//
-// TODO(rfindley): what happens if this function fails? It must leave us in a
-// broken state, which we should surface to the user, probably as a request to
-// restart gopls.
-func (s *Session) DidModifyFiles(ctx context.Context, changes []source.FileModification) (map[source.Snapshot][]span.URI, func(), error) {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-
-	// Update overlays.
-	//
-	// TODO(rfindley): I think we do this while holding viewMu to prevent views
-	// from seeing the updated file content before they have processed
-	// invalidations, which could lead to a partial view of the changes (i.e.
-	// spurious diagnostics). However, any such view would immediately be
-	// invalidated here, so it is possible that we could update overlays before
-	// acquiring viewMu.
-	overlays, err := s.updateOverlays(ctx, changes)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	// Re-create views whose root may have changed.
-	//
-	// checkRoots controls whether to re-evaluate view definitions when
-	// collecting views below. Any change to a go.mod or go.work file may have
-	// affected the definition of the view.
-	checkRoots := false
-	for _, c := range changes {
-		if isGoMod(c.URI) || isGoWork(c.URI) {
-			checkRoots = true
-			break
-		}
-	}
-
-	if checkRoots {
-		for _, view := range s.views {
-			// Check whether the view must be recreated. This logic looks hacky,
-			// as it uses the existing view gomodcache and options to re-evaluate
-			// the workspace source, then expects view creation to compute the same
-			// root source after first re-evaluating gomodcache and options.
-			//
-			// Well, it *is* a bit hacky, but in practice we will get the same
-			// gomodcache and options, as any environment change affecting these
-			// should have already invalidated the view (c.f. minorOptionsChange).
-			//
-			// TODO(rfindley): clean this up.
-			filterFunc := pathExcludedByFilterFunc(view.folder.Filename(), view.gomodcache, view.Options())
-			src, err := findWorkspaceModuleSource(ctx, view.folder, s, filterFunc, view.Options().ExperimentalWorkspaceModule)
-			if err != nil {
-				return nil, nil, err
-			}
-			if src != view.rootSrc {
-				_, err := s.updateViewLocked(ctx, view, view.Options())
-				if err != nil {
-					// Catastrophic failure, equivalent to a failure of session
-					// initialization and therefore should almost never happen. One
-					// scenario where this failure mode could occur is if some file
-					// permissions have changed preventing us from reading go.mod
-					// files.
-					//
-					// The view may or may not still exist. The best we can do is log
-					// and move on.
-					//
-					// TODO(rfindley): consider surfacing this error more loudly. We
-					// could report a bug, but it's not really a bug.
-					event.Error(ctx, "recreating view", err)
-				}
-			}
-		}
-	}
-
-	// Collect information about views affected by these changes.
-	views := make(map[*View]map[span.URI]*fileChange)
-	affectedViews := map[span.URI][]*View{}
-	// forceReloadMetadata records whether any change is the magic
-	// source.InvalidateMetadata action.
-	forceReloadMetadata := false
-	for _, c := range changes {
-		if c.Action == source.InvalidateMetadata {
-			forceReloadMetadata = true
-		}
-		// Build the list of affected views.
-		var changedViews []*View
-		for _, view := range s.views {
-			// Don't propagate changes that are outside of the view's scope
-			// or knowledge.
-			if !view.relevantChange(c) {
-				continue
-			}
-			changedViews = append(changedViews, view)
-		}
-		// If the change is not relevant to any view, but the change is
-		// happening in the editor, assign it the most closely matching view.
-		if len(changedViews) == 0 {
-			if c.OnDisk {
-				continue
-			}
-			bestView, err := s.viewOfLocked(c.URI)
-			if err != nil {
-				return nil, nil, err
-			}
-			changedViews = append(changedViews, bestView)
-		}
-		affectedViews[c.URI] = changedViews
-
-		isUnchanged := c.Action == source.Open || c.Action == source.Close
-
-		// Apply the changes to all affected views.
-		for _, view := range changedViews {
-			// Make sure that the file is added to the view's knownFiles set.
-			view.canonicalURI(c.URI, true) // ignore result
-			if _, ok := views[view]; !ok {
-				views[view] = make(map[span.URI]*fileChange)
-			}
-			if fh, ok := overlays[c.URI]; ok {
-				views[view][c.URI] = &fileChange{
-					content:     fh.text,
-					exists:      true,
-					fileHandle:  fh,
-					isUnchanged: isUnchanged,
-				}
-			} else {
-				fsFile, err := s.cache.getFile(ctx, c.URI)
-				if err != nil {
-					return nil, nil, err
-				}
-				content, err := fsFile.Read()
-				fh := &closedFile{fsFile}
-				views[view][c.URI] = &fileChange{
-					content:     content,
-					exists:      err == nil,
-					fileHandle:  fh,
-					isUnchanged: isUnchanged,
-				}
-			}
-		}
-	}
-
-	var releases []func()
-	viewToSnapshot := map[*View]*snapshot{}
-	for view, changed := range views {
-		snapshot, release := view.invalidateContent(ctx, changed, forceReloadMetadata)
-		releases = append(releases, release)
-		viewToSnapshot[view] = snapshot
-	}
-
-	// The release function is called when the
-	// returned URIs no longer need to be valid.
-	release := func() {
-		for _, release := range releases {
-			release()
-		}
-	}
-
-	// We only want to diagnose each changed file once, in the view to which
-	// it "most" belongs. We do this by picking the best view for each URI,
-	// and then aggregating the set of snapshots and their URIs (to avoid
-	// diagnosing the same snapshot multiple times).
-	snapshotURIs := map[source.Snapshot][]span.URI{}
-	for _, mod := range changes {
-		viewSlice, ok := affectedViews[mod.URI]
-		if !ok || len(viewSlice) == 0 {
-			continue
-		}
-		view := bestViewForURI(mod.URI, viewSlice)
-		snapshot, ok := viewToSnapshot[view]
-		if !ok {
-			panic(fmt.Sprintf("no snapshot for view %s", view.Folder()))
-		}
-		snapshotURIs[snapshot] = append(snapshotURIs[snapshot], mod.URI)
-	}
-
-	return snapshotURIs, release, nil
-}
-
-// ExpandModificationsToDirectories returns the set of changes with the
-// directory changes removed and expanded to include all of the files in
-// the directory.
-func (s *Session) ExpandModificationsToDirectories(ctx context.Context, changes []source.FileModification) []source.FileModification {
-	var snapshots []*snapshot
-	s.viewMu.Lock()
-	for _, v := range s.views {
-		snapshot, release := v.getSnapshot()
-		defer release()
-		snapshots = append(snapshots, snapshot)
-	}
-	s.viewMu.Unlock()
-
-	knownDirs := knownDirectories(ctx, snapshots)
-	defer knownDirs.Destroy()
-
-	var result []source.FileModification
-	for _, c := range changes {
-		if !knownDirs.Contains(c.URI) {
-			result = append(result, c)
-			continue
-		}
-		affectedFiles := knownFilesInDir(ctx, snapshots, c.URI)
-		var fileChanges []source.FileModification
-		for uri := range affectedFiles {
-			fileChanges = append(fileChanges, source.FileModification{
-				URI:        uri,
-				Action:     c.Action,
-				LanguageID: "",
-				OnDisk:     c.OnDisk,
-				// changes to directories cannot include text or versions
-			})
-		}
-		result = append(result, fileChanges...)
-	}
-	return result
-}
-
-// knownDirectories returns all of the directories known to the given
-// snapshots, including workspace directories and their subdirectories.
-// It is responsibility of the caller to destroy the returned set.
-func knownDirectories(ctx context.Context, snapshots []*snapshot) knownDirsSet {
-	result := newKnownDirsSet()
-	for _, snapshot := range snapshots {
-		dirs := snapshot.workspace.dirs(ctx, snapshot)
-		for _, dir := range dirs {
-			result.Insert(dir)
-		}
-		knownSubdirs := snapshot.getKnownSubdirs(dirs)
-		result.SetAll(knownSubdirs)
-		knownSubdirs.Destroy()
-	}
-	return result
-}
-
-// knownFilesInDir returns the files known to the snapshots in the session.
-// It does not respect symlinks.
-func knownFilesInDir(ctx context.Context, snapshots []*snapshot, dir span.URI) map[span.URI]struct{} {
-	files := map[span.URI]struct{}{}
-
-	for _, snapshot := range snapshots {
-		for _, uri := range snapshot.knownFilesInDir(ctx, dir) {
-			files[uri] = struct{}{}
-		}
-	}
-	return files
-}
-
-// Precondition: caller holds s.viewMu lock.
-func (s *Session) updateOverlays(ctx context.Context, changes []source.FileModification) (map[span.URI]*overlay, error) {
-	s.overlayMu.Lock()
-	defer s.overlayMu.Unlock()
-
-	for _, c := range changes {
-		// Don't update overlays for metadata invalidations.
-		if c.Action == source.InvalidateMetadata {
-			continue
-		}
-
-		o, ok := s.overlays[c.URI]
-
-		// If the file is not opened in an overlay and the change is on disk,
-		// there's no need to update an overlay. If there is an overlay, we
-		// may need to update the overlay's saved value.
-		if !ok && c.OnDisk {
-			continue
-		}
-
-		// Determine the file kind on open, otherwise, assume it has been cached.
-		var kind source.FileKind
-		switch c.Action {
-		case source.Open:
-			kind = source.FileKindForLang(c.LanguageID)
-		default:
-			if !ok {
-				return nil, fmt.Errorf("updateOverlays: modifying unopened overlay %v", c.URI)
-			}
-			kind = o.kind
-		}
-
-		// Closing a file just deletes its overlay.
-		if c.Action == source.Close {
-			delete(s.overlays, c.URI)
-			continue
-		}
-
-		// If the file is on disk, check if its content is the same as in the
-		// overlay. Saves and on-disk file changes don't come with the file's
-		// content.
-		text := c.Text
-		if text == nil && (c.Action == source.Save || c.OnDisk) {
-			if !ok {
-				return nil, fmt.Errorf("no known content for overlay for %s", c.Action)
-			}
-			text = o.text
-		}
-		// On-disk changes don't come with versions.
-		version := c.Version
-		if c.OnDisk || c.Action == source.Save {
-			version = o.version
-		}
-		hash := source.HashOf(text)
-		var sameContentOnDisk bool
-		switch c.Action {
-		case source.Delete:
-			// Do nothing. sameContentOnDisk should be false.
-		case source.Save:
-			// Make sure the version and content (if present) is the same.
-			if false && o.version != version { // Client no longer sends the version
-				return nil, fmt.Errorf("updateOverlays: saving %s at version %v, currently at %v", c.URI, c.Version, o.version)
-			}
-			if c.Text != nil && o.hash != hash {
-				return nil, fmt.Errorf("updateOverlays: overlay %s changed on save", c.URI)
-			}
-			sameContentOnDisk = true
-		default:
-			fh, err := s.cache.getFile(ctx, c.URI)
-			if err != nil {
-				return nil, err
-			}
-			_, readErr := fh.Read()
-			sameContentOnDisk = (readErr == nil && fh.FileIdentity().Hash == hash)
-		}
-		o = &overlay{
-			session: s,
-			uri:     c.URI,
-			version: version,
-			text:    text,
-			kind:    kind,
-			hash:    hash,
-			saved:   sameContentOnDisk,
-		}
-
-		// When opening files, ensure that we actually have a well-defined view and file kind.
-		if c.Action == source.Open {
-			view, err := s.viewOfLocked(o.uri)
-			if err != nil {
-				return nil, fmt.Errorf("updateOverlays: finding view for %s: %v", o.uri, err)
-			}
-			if kind := view.FileKind(o); kind == source.UnknownKind {
-				return nil, fmt.Errorf("updateOverlays: unknown file kind for %s", o.uri)
-			}
-		}
-
-		s.overlays[c.URI] = o
-	}
-
-	// Get the overlays for each change while the session's overlay map is
-	// locked.
-	overlays := make(map[span.URI]*overlay)
-	for _, c := range changes {
-		if o, ok := s.overlays[c.URI]; ok {
-			overlays[c.URI] = o
-		}
-	}
-	return overlays, nil
-}
-
-// GetFile returns a handle for the specified file.
-func (s *Session) GetFile(ctx context.Context, uri span.URI) (source.FileHandle, error) {
-	if overlay := s.readOverlay(uri); overlay != nil {
-		return overlay, nil
-	}
-	// Fall back to the cache-level file system.
-	return s.cache.getFile(ctx, uri)
-}
-
-func (s *Session) readOverlay(uri span.URI) *overlay {
-	s.overlayMu.Lock()
-	defer s.overlayMu.Unlock()
-
-	if overlay, ok := s.overlays[uri]; ok {
-		return overlay
-	}
-	return nil
-}
-
-// Overlays returns a slice of file overlays for the session.
-func (s *Session) Overlays() []source.Overlay {
-	s.overlayMu.Lock()
-	defer s.overlayMu.Unlock()
-
-	overlays := make([]source.Overlay, 0, len(s.overlays))
-	for _, overlay := range s.overlays {
-		overlays = append(overlays, overlay)
-	}
-	return overlays
-}
-
-// FileWatchingGlobPatterns returns glob patterns to watch every directory
-// known by the view. For views within a module, this is the module root,
-// any directory in the module root, and any replace targets.
-func (s *Session) FileWatchingGlobPatterns(ctx context.Context) map[string]struct{} {
-	s.viewMu.Lock()
-	defer s.viewMu.Unlock()
-	patterns := map[string]struct{}{}
-	for _, view := range s.views {
-		snapshot, release := view.getSnapshot()
-		for k, v := range snapshot.fileWatchingGlobPatterns(ctx) {
-			patterns[k] = v
-		}
-		release()
-	}
-	return patterns
-}
diff -urN a/gopls/internal/lsp/cache/snapshot.go b/gopls/internal/lsp/cache/snapshot.go
--- a/gopls/internal/lsp/cache/snapshot.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/snapshot.go	1969-12-31 16:00:00
@@ -1,2368 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"io"
-	"io/ioutil"
-	"log"
-	"os"
-	"path/filepath"
-	"regexp"
-	"runtime"
-	"sort"
-	"strconv"
-	"strings"
-	"sync"
-	"sync/atomic"
-	"unsafe"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/module"
-	"golang.org/x/mod/semver"
-	"golang.org/x/sync/errgroup"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/memoize"
-	"golang.org/x/tools/internal/packagesinternal"
-	"golang.org/x/tools/internal/persistent"
-	"golang.org/x/tools/internal/typesinternal"
-)
-
-type snapshot struct {
-	sequenceID uint64
-	globalID   source.GlobalSnapshotID
-	view       *View
-
-	cancel        func()
-	backgroundCtx context.Context
-
-	store *memoize.Store // cache of handles shared by all snapshots
-
-	refcount    sync.WaitGroup // number of references
-	destroyedBy *string        // atomically set to non-nil in Destroy once refcount = 0
-
-	// initialized reports whether the snapshot has been initialized. Concurrent
-	// initialization is guarded by the view.initializationSema. Each snapshot is
-	// initialized at most once: concurrent initialization is guarded by
-	// view.initializationSema.
-	initialized bool
-	// initializedErr holds the last error resulting from initialization. If
-	// initialization fails, we only retry when the the workspace modules change,
-	// to avoid too many go/packages calls.
-	initializedErr *source.CriticalError
-
-	// mu guards all of the maps in the snapshot, as well as the builtin URI.
-	mu sync.Mutex
-
-	// builtin pins the AST and package for builtin.go in memory.
-	builtin span.URI
-
-	// meta holds loaded metadata.
-	//
-	// meta is guarded by mu, but the metadataGraph itself is immutable.
-	// TODO(rfindley): in many places we hold mu while operating on meta, even
-	// though we only need to hold mu while reading the pointer.
-	meta *metadataGraph
-
-	// files maps file URIs to their corresponding FileHandles.
-	// It may invalidated when a file's content changes.
-	files filesMap
-
-	// parsedGoFiles maps a parseKey to the handle of the future result of parsing it.
-	parsedGoFiles *persistent.Map // from parseKey to *memoize.Promise[parseGoResult]
-
-	// parseKeysByURI records the set of keys of parsedGoFiles that
-	// need to be invalidated for each URI.
-	// TODO(adonovan): opt: parseKey = ParseMode + URI, so this could
-	// be just a set of ParseModes, or we could loop over AllParseModes.
-	parseKeysByURI parseKeysByURIMap
-
-	// symbolizeHandles maps each file URI to a handle for the future
-	// result of computing the symbols declared in that file.
-	symbolizeHandles *persistent.Map // from span.URI to *memoize.Promise[symbolizeResult]
-
-	// packages maps a packageKey to a *packageHandle.
-	// It may be invalidated when a file's content changes.
-	//
-	// Invariants to preserve:
-	//  - packages.Get(id).meta == meta.metadata[id] for all ids
-	//  - if a package is in packages, then all of its dependencies should also
-	//    be in packages, unless there is a missing import
-	packages *persistent.Map // from packageKey to *packageHandle
-
-	// isActivePackageCache maps package ID to the cached value if it is active or not.
-	// It may be invalidated when metadata changes or a new file is opened or closed.
-	isActivePackageCache isActivePackageCacheMap
-
-	// analyses maps an analysisKey (which identifies a package
-	// and a set of analyzers) to the handle for the future result
-	// of loading the package and analyzing it.
-	analyses *persistent.Map // from analysisKey to analysisHandle
-
-	// workspacePackages contains the workspace's packages, which are loaded
-	// when the view is created.
-	workspacePackages map[PackageID]PackagePath
-
-	// shouldLoad tracks packages that need to be reloaded, mapping a PackageID
-	// to the package paths that should be used to reload it
-	//
-	// When we try to load a package, we clear it from the shouldLoad map
-	// regardless of whether the load succeeded, to prevent endless loads.
-	shouldLoad map[PackageID][]PackagePath
-
-	// unloadableFiles keeps track of files that we've failed to load.
-	unloadableFiles map[span.URI]struct{}
-
-	// parseModHandles keeps track of any parseModHandles for the snapshot.
-	// The handles need not refer to only the view's go.mod file.
-	parseModHandles *persistent.Map // from span.URI to *memoize.Promise[parseModResult]
-
-	// parseWorkHandles keeps track of any parseWorkHandles for the snapshot.
-	// The handles need not refer to only the view's go.work file.
-	parseWorkHandles *persistent.Map // from span.URI to *memoize.Promise[parseWorkResult]
-
-	// Preserve go.mod-related handles to avoid garbage-collecting the results
-	// of various calls to the go command. The handles need not refer to only
-	// the view's go.mod file.
-	modTidyHandles *persistent.Map // from span.URI to *memoize.Promise[modTidyResult]
-	modWhyHandles  *persistent.Map // from span.URI to *memoize.Promise[modWhyResult]
-	modVulnHandles *persistent.Map // from span.URI to *memoize.Promise[modVulnResult]
-
-	workspace *workspace // (not guarded by mu)
-
-	// The cached result of makeWorkspaceDir, created on demand and deleted by Snapshot.Destroy.
-	workspaceDir    string
-	workspaceDirErr error
-
-	// knownSubdirs is the set of subdirectories in the workspace, used to
-	// create glob patterns for file watching.
-	knownSubdirs             knownDirsSet
-	knownSubdirsPatternCache string
-	// unprocessedSubdirChanges are any changes that might affect the set of
-	// subdirectories in the workspace. They are not reflected to knownSubdirs
-	// during the snapshot cloning step as it can slow down cloning.
-	unprocessedSubdirChanges []*fileChange
-}
-
-var globalSnapshotID uint64
-
-func nextSnapshotID() source.GlobalSnapshotID {
-	return source.GlobalSnapshotID(atomic.AddUint64(&globalSnapshotID, 1))
-}
-
-var _ memoize.RefCounted = (*snapshot)(nil) // snapshots are reference-counted
-
-// Acquire prevents the snapshot from being destroyed until the returned function is called.
-//
-// (s.Acquire().release() could instead be expressed as a pair of
-// method calls s.IncRef(); s.DecRef(). The latter has the advantage
-// that the DecRefs are fungible and don't require holding anything in
-// addition to the refcounted object s, but paradoxically that is also
-// an advantage of the current approach, which forces the caller to
-// consider the release function at every stage, making a reference
-// leak more obvious.)
-func (s *snapshot) Acquire() func() {
-	type uP = unsafe.Pointer
-	if destroyedBy := atomic.LoadPointer((*uP)(uP(&s.destroyedBy))); destroyedBy != nil {
-		log.Panicf("%d: acquire() after Destroy(%q)", s.globalID, *(*string)(destroyedBy))
-	}
-	s.refcount.Add(1)
-	return s.refcount.Done
-}
-
-func (s *snapshot) awaitPromise(ctx context.Context, p *memoize.Promise) (interface{}, error) {
-	return p.Get(ctx, s)
-}
-
-// destroy waits for all leases on the snapshot to expire then releases
-// any resources (reference counts and files) associated with it.
-// Snapshots being destroyed can be awaited using v.destroyWG.
-//
-// TODO(adonovan): move this logic into the release function returned
-// by Acquire when the reference count becomes zero. (This would cost
-// us the destroyedBy debug info, unless we add it to the signature of
-// memoize.RefCounted.Acquire.)
-//
-// The destroyedBy argument is used for debugging.
-//
-// v.snapshotMu must be held while calling this function, in order to preserve
-// the invariants described by the the docstring for v.snapshot.
-func (v *View) destroy(s *snapshot, destroyedBy string) {
-	v.snapshotWG.Add(1)
-	go func() {
-		defer v.snapshotWG.Done()
-		s.destroy(destroyedBy)
-	}()
-}
-
-func (s *snapshot) destroy(destroyedBy string) {
-	// Wait for all leases to end before commencing destruction.
-	s.refcount.Wait()
-
-	// Report bad state as a debugging aid.
-	// Not foolproof: another thread could acquire() at this moment.
-	type uP = unsafe.Pointer // looking forward to generics...
-	if old := atomic.SwapPointer((*uP)(uP(&s.destroyedBy)), uP(&destroyedBy)); old != nil {
-		log.Panicf("%d: Destroy(%q) after Destroy(%q)", s.globalID, destroyedBy, *(*string)(old))
-	}
-
-	s.packages.Destroy()
-	s.isActivePackageCache.Destroy()
-	s.analyses.Destroy()
-	s.files.Destroy()
-	s.parsedGoFiles.Destroy()
-	s.parseKeysByURI.Destroy()
-	s.knownSubdirs.Destroy()
-	s.symbolizeHandles.Destroy()
-	s.parseModHandles.Destroy()
-	s.parseWorkHandles.Destroy()
-	s.modTidyHandles.Destroy()
-	s.modVulnHandles.Destroy()
-	s.modWhyHandles.Destroy()
-
-	if s.workspaceDir != "" {
-		if err := os.RemoveAll(s.workspaceDir); err != nil {
-			event.Error(context.Background(), "cleaning workspace dir", err)
-		}
-	}
-}
-
-func (s *snapshot) SequenceID() uint64 {
-	return s.sequenceID
-}
-
-func (s *snapshot) GlobalID() source.GlobalSnapshotID {
-	return s.globalID
-}
-
-func (s *snapshot) View() source.View {
-	return s.view
-}
-
-func (s *snapshot) BackgroundContext() context.Context {
-	return s.backgroundCtx
-}
-
-func (s *snapshot) FileSet() *token.FileSet {
-	return s.view.cache.fset
-}
-
-func (s *snapshot) ModFiles() []span.URI {
-	var uris []span.URI
-	for modURI := range s.workspace.ActiveModFiles() {
-		uris = append(uris, modURI)
-	}
-	return uris
-}
-
-func (s *snapshot) WorkFile() span.URI {
-	return s.workspace.workFile
-}
-
-func (s *snapshot) Templates() map[span.URI]source.VersionedFileHandle {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	tmpls := map[span.URI]source.VersionedFileHandle{}
-	s.files.Range(func(k span.URI, fh source.VersionedFileHandle) {
-		if s.view.FileKind(fh) == source.Tmpl {
-			tmpls[k] = fh
-		}
-	})
-	return tmpls
-}
-
-func (s *snapshot) ValidBuildConfiguration() bool {
-	// Since we only really understand the `go` command, if the user has a
-	// different GOPACKAGESDRIVER, assume that their configuration is valid.
-	if s.view.hasGopackagesDriver {
-		return true
-	}
-	// Check if the user is working within a module or if we have found
-	// multiple modules in the workspace.
-	if len(s.workspace.ActiveModFiles()) > 0 {
-		return true
-	}
-	// The user may have a multiple directories in their GOPATH.
-	// Check if the workspace is within any of them.
-	// TODO(rfindley): this should probably be subject to "if GO111MODULES = off {...}".
-	for _, gp := range filepath.SplitList(s.view.gopath) {
-		if source.InDir(filepath.Join(gp, "src"), s.view.rootURI.Filename()) {
-			return true
-		}
-	}
-	return false
-}
-
-// workspaceMode describes the way in which the snapshot's workspace should
-// be loaded.
-func (s *snapshot) workspaceMode() workspaceMode {
-	var mode workspaceMode
-
-	// If the view has an invalid configuration, don't build the workspace
-	// module.
-	validBuildConfiguration := s.ValidBuildConfiguration()
-	if !validBuildConfiguration {
-		return mode
-	}
-	// If the view is not in a module and contains no modules, but still has a
-	// valid workspace configuration, do not create the workspace module.
-	// It could be using GOPATH or a different build system entirely.
-	if len(s.workspace.ActiveModFiles()) == 0 && validBuildConfiguration {
-		return mode
-	}
-	mode |= moduleMode
-	options := s.view.Options()
-	// The -modfile flag is available for Go versions >= 1.14.
-	if options.TempModfile && s.view.workspaceInformation.goversion >= 14 {
-		mode |= tempModfile
-	}
-	return mode
-}
-
-// config returns the configuration used for the snapshot's interaction with
-// the go/packages API. It uses the given working directory.
-//
-// TODO(rstambler): go/packages requires that we do not provide overlays for
-// multiple modules in on config, so buildOverlay needs to filter overlays by
-// module.
-func (s *snapshot) config(ctx context.Context, inv *gocommand.Invocation) *packages.Config {
-	s.view.optionsMu.Lock()
-	verboseOutput := s.view.options.VerboseOutput
-	s.view.optionsMu.Unlock()
-
-	cfg := &packages.Config{
-		Context:    ctx,
-		Dir:        inv.WorkingDir,
-		Env:        inv.Env,
-		BuildFlags: inv.BuildFlags,
-		Mode: packages.NeedName |
-			packages.NeedFiles |
-			packages.NeedCompiledGoFiles |
-			packages.NeedImports |
-			packages.NeedDeps |
-			packages.NeedTypesSizes |
-			packages.NeedModule |
-			packages.LoadMode(packagesinternal.DepsErrors) |
-			packages.LoadMode(packagesinternal.ForTest),
-		Fset:    nil, // we do our own parsing
-		Overlay: s.buildOverlay(),
-		ParseFile: func(*token.FileSet, string, []byte) (*ast.File, error) {
-			panic("go/packages must not be used to parse files")
-		},
-		Logf: func(format string, args ...interface{}) {
-			if verboseOutput {
-				event.Log(ctx, fmt.Sprintf(format, args...))
-			}
-		},
-		Tests: true,
-	}
-	packagesinternal.SetModFile(cfg, inv.ModFile)
-	packagesinternal.SetModFlag(cfg, inv.ModFlag)
-	// We want to type check cgo code if go/types supports it.
-	if typesinternal.SetUsesCgo(&types.Config{}) {
-		cfg.Mode |= packages.LoadMode(packagesinternal.TypecheckCgo)
-	}
-	packagesinternal.SetGoCmdRunner(cfg, s.view.gocmdRunner)
-	return cfg
-}
-
-func (s *snapshot) RunGoCommandDirect(ctx context.Context, mode source.InvocationFlags, inv *gocommand.Invocation) (*bytes.Buffer, error) {
-	_, inv, cleanup, err := s.goCommandInvocation(ctx, mode, inv)
-	if err != nil {
-		return nil, err
-	}
-	defer cleanup()
-
-	return s.view.gocmdRunner.Run(ctx, *inv)
-}
-
-func (s *snapshot) RunGoCommandPiped(ctx context.Context, mode source.InvocationFlags, inv *gocommand.Invocation, stdout, stderr io.Writer) error {
-	_, inv, cleanup, err := s.goCommandInvocation(ctx, mode, inv)
-	if err != nil {
-		return err
-	}
-	defer cleanup()
-	return s.view.gocmdRunner.RunPiped(ctx, *inv, stdout, stderr)
-}
-
-func (s *snapshot) RunGoCommands(ctx context.Context, allowNetwork bool, wd string, run func(invoke func(...string) (*bytes.Buffer, error)) error) (bool, []byte, []byte, error) {
-	var flags source.InvocationFlags
-	if s.workspaceMode()&tempModfile != 0 {
-		flags = source.WriteTemporaryModFile
-	} else {
-		flags = source.Normal
-	}
-	if allowNetwork {
-		flags |= source.AllowNetwork
-	}
-	tmpURI, inv, cleanup, err := s.goCommandInvocation(ctx, flags, &gocommand.Invocation{WorkingDir: wd})
-	if err != nil {
-		return false, nil, nil, err
-	}
-	defer cleanup()
-	invoke := func(args ...string) (*bytes.Buffer, error) {
-		inv.Verb = args[0]
-		inv.Args = args[1:]
-		return s.view.gocmdRunner.Run(ctx, *inv)
-	}
-	if err := run(invoke); err != nil {
-		return false, nil, nil, err
-	}
-	if flags.Mode() != source.WriteTemporaryModFile {
-		return false, nil, nil, nil
-	}
-	var modBytes, sumBytes []byte
-	modBytes, err = ioutil.ReadFile(tmpURI.Filename())
-	if err != nil && !os.IsNotExist(err) {
-		return false, nil, nil, err
-	}
-	sumBytes, err = ioutil.ReadFile(strings.TrimSuffix(tmpURI.Filename(), ".mod") + ".sum")
-	if err != nil && !os.IsNotExist(err) {
-		return false, nil, nil, err
-	}
-	return true, modBytes, sumBytes, nil
-}
-
-// goCommandInvocation populates inv with configuration for running go commands on the snapshot.
-//
-// TODO(rfindley): refactor this function to compose the required configuration
-// explicitly, rather than implicitly deriving it from flags and inv.
-//
-// TODO(adonovan): simplify cleanup mechanism. It's hard to see, but
-// it used only after call to tempModFile. Clarify that it is only
-// non-nil on success.
-func (s *snapshot) goCommandInvocation(ctx context.Context, flags source.InvocationFlags, inv *gocommand.Invocation) (tmpURI span.URI, updatedInv *gocommand.Invocation, cleanup func(), err error) {
-	s.view.optionsMu.Lock()
-	allowModfileModificationOption := s.view.options.AllowModfileModifications
-	allowNetworkOption := s.view.options.AllowImplicitNetworkAccess
-
-	// TODO(rfindley): this is very hard to follow, and may not even be doing the
-	// right thing: should inv.Env really trample view.options? Do we ever invoke
-	// this with a non-empty inv.Env?
-	//
-	// We should refactor to make it clearer that the correct env is being used.
-	inv.Env = append(append(append(os.Environ(), s.view.options.EnvSlice()...), inv.Env...), "GO111MODULE="+s.view.GO111MODULE())
-	inv.BuildFlags = append([]string{}, s.view.options.BuildFlags...)
-	s.view.optionsMu.Unlock()
-	cleanup = func() {} // fallback
-
-	// All logic below is for module mode.
-	if s.workspaceMode()&moduleMode == 0 {
-		return "", inv, cleanup, nil
-	}
-
-	mode, allowNetwork := flags.Mode(), flags.AllowNetwork()
-	if !allowNetwork && !allowNetworkOption {
-		inv.Env = append(inv.Env, "GOPROXY=off")
-	}
-
-	// What follows is rather complicated logic for how to actually run the go
-	// command. A word of warning: this is the result of various incremental
-	// features added to gopls, and varying behavior of the Go command across Go
-	// versions. It can surely be cleaned up significantly, but tread carefully.
-	//
-	// Roughly speaking we need to resolve four things:
-	//  - the working directory.
-	//  - the -mod flag
-	//  - the -modfile flag
-	//
-	// These are dependent on a number of factors: whether we need to run in a
-	// synthetic workspace, whether flags are supported at the current go
-	// version, and what we're actually trying to achieve (the
-	// source.InvocationFlags).
-
-	var modURI span.URI
-	// Select the module context to use.
-	// If we're type checking, we need to use the workspace context, meaning
-	// the main (workspace) module. Otherwise, we should use the module for
-	// the passed-in working dir.
-	if mode == source.LoadWorkspace {
-		switch s.workspace.moduleSource {
-		case legacyWorkspace:
-			for m := range s.workspace.ActiveModFiles() { // range to access the only element
-				modURI = m
-			}
-		case goWorkWorkspace:
-			if s.view.goversion >= 18 {
-				break
-			}
-			// Before go 1.18, the Go command did not natively support go.work files,
-			// so we 'fake' them with a workspace module.
-			fallthrough
-		case fileSystemWorkspace, goplsModWorkspace:
-			var tmpDir span.URI
-			var err error
-			tmpDir, err = s.getWorkspaceDir(ctx)
-			if err != nil {
-				return "", nil, cleanup, err
-			}
-			inv.WorkingDir = tmpDir.Filename()
-			modURI = span.URIFromPath(filepath.Join(tmpDir.Filename(), "go.mod"))
-		}
-	} else {
-		modURI = s.GoModForFile(span.URIFromPath(inv.WorkingDir))
-	}
-
-	var modContent []byte
-	if modURI != "" {
-		modFH, err := s.GetFile(ctx, modURI)
-		if err != nil {
-			return "", nil, cleanup, err
-		}
-		modContent, err = modFH.Read()
-		if err != nil {
-			return "", nil, cleanup, err
-		}
-	}
-
-	// TODO(rfindley): in the case of go.work mode, modURI is empty and we fall
-	// back on the default behavior of vendorEnabled with an empty modURI. Figure
-	// out what is correct here and implement it explicitly.
-	vendorEnabled, err := s.vendorEnabled(ctx, modURI, modContent)
-	if err != nil {
-		return "", nil, cleanup, err
-	}
-
-	mutableModFlag := ""
-	// If the mod flag isn't set, populate it based on the mode and workspace.
-	if inv.ModFlag == "" {
-		if s.view.goversion >= 16 {
-			mutableModFlag = "mod"
-		}
-
-		switch mode {
-		case source.LoadWorkspace, source.Normal:
-			if vendorEnabled {
-				inv.ModFlag = "vendor"
-			} else if !allowModfileModificationOption {
-				inv.ModFlag = "readonly"
-			} else {
-				inv.ModFlag = mutableModFlag
-			}
-		case source.WriteTemporaryModFile:
-			inv.ModFlag = mutableModFlag
-			// -mod must be readonly when using go.work files - see issue #48941
-			inv.Env = append(inv.Env, "GOWORK=off")
-		}
-	}
-
-	// Only use a temp mod file if the modfile can actually be mutated.
-	needTempMod := inv.ModFlag == mutableModFlag
-	useTempMod := s.workspaceMode()&tempModfile != 0
-	if needTempMod && !useTempMod {
-		return "", nil, cleanup, source.ErrTmpModfileUnsupported
-	}
-
-	// We should use -modfile if:
-	//  - the workspace mode supports it
-	//  - we're using a go.work file on go1.18+, or we need a temp mod file (for
-	//    example, if running go mod tidy in a go.work workspace)
-	//
-	// TODO(rfindley): this is very hard to follow. Refactor.
-	useWorkFile := !needTempMod && s.workspace.moduleSource == goWorkWorkspace && s.view.goversion >= 18
-	if useWorkFile {
-		// Since we're running in the workspace root, the go command will resolve GOWORK automatically.
-	} else if useTempMod {
-		if modURI == "" {
-			return "", nil, cleanup, fmt.Errorf("no go.mod file found in %s", inv.WorkingDir)
-		}
-		modFH, err := s.GetFile(ctx, modURI)
-		if err != nil {
-			return "", nil, cleanup, err
-		}
-		// Use the go.sum if it happens to be available.
-		gosum := s.goSum(ctx, modURI)
-		tmpURI, cleanup, err = tempModFile(modFH, gosum)
-		if err != nil {
-			return "", nil, cleanup, err
-		}
-		inv.ModFile = tmpURI.Filename()
-	}
-
-	return tmpURI, inv, cleanup, nil
-}
-
-// usesWorkspaceDir reports whether the snapshot should use a synthetic
-// workspace directory for running workspace go commands such as go list.
-//
-// TODO(rfindley): this logic is duplicated with goCommandInvocation. Clean up
-// the latter, and deduplicate.
-func (s *snapshot) usesWorkspaceDir() bool {
-	switch s.workspace.moduleSource {
-	case legacyWorkspace:
-		return false
-	case goWorkWorkspace:
-		if s.view.goversion >= 18 {
-			return false
-		}
-		// Before go 1.18, the Go command did not natively support go.work files,
-		// so we 'fake' them with a workspace module.
-	}
-	return true
-}
-
-func (s *snapshot) buildOverlay() map[string][]byte {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	overlays := make(map[string][]byte)
-	s.files.Range(func(uri span.URI, fh source.VersionedFileHandle) {
-		overlay, ok := fh.(*overlay)
-		if !ok {
-			return
-		}
-		if overlay.saved {
-			return
-		}
-		// TODO(rstambler): Make sure not to send overlays outside of the current view.
-		overlays[uri.Filename()] = overlay.text
-	})
-	return overlays
-}
-
-// TypeCheck type-checks the specified packages in the given mode.
-func (s *snapshot) TypeCheck(ctx context.Context, mode source.TypecheckMode, ids ...PackageID) ([]source.Package, error) {
-	// Build all the handles...
-	var phs []*packageHandle
-	for _, id := range ids {
-		parseMode := source.ParseFull
-		if mode == source.TypecheckWorkspace {
-			parseMode = s.workspaceParseMode(id)
-		}
-
-		ph, err := s.buildPackageHandle(ctx, id, parseMode)
-		if err != nil {
-			return nil, err
-		}
-		phs = append(phs, ph)
-	}
-
-	// ...then await them all.
-	var pkgs []source.Package
-	for _, ph := range phs {
-		pkg, err := ph.await(ctx, s)
-		if err != nil {
-			return nil, err
-		}
-		pkgs = append(pkgs, pkg)
-	}
-	return pkgs, nil
-}
-
-func (s *snapshot) MetadataForFile(ctx context.Context, uri span.URI) ([]*source.Metadata, error) {
-	s.mu.Lock()
-
-	// Start with the set of package associations derived from the last load.
-	ids := s.meta.ids[uri]
-
-	shouldLoad := false // whether any packages containing uri are marked 'shouldLoad'
-	for _, id := range ids {
-		if len(s.shouldLoad[id]) > 0 {
-			shouldLoad = true
-		}
-	}
-
-	// Check if uri is known to be unloadable.
-	_, unloadable := s.unloadableFiles[uri]
-
-	s.mu.Unlock()
-
-	// Reload if loading is likely to improve the package associations for uri:
-	//  - uri is not contained in any valid packages
-	//  - ...or one of the packages containing uri is marked 'shouldLoad'
-	//  - ...but uri is not unloadable
-	if (shouldLoad || len(ids) == 0) && !unloadable {
-		scope := fileLoadScope(uri)
-		err := s.load(ctx, false, scope)
-
-		// Guard against failed loads due to context cancellation.
-		//
-		// Return the context error here as the current operation is no longer
-		// valid.
-		if ctxErr := ctx.Err(); ctxErr != nil {
-			return nil, ctxErr
-		}
-
-		// We must clear scopes after loading.
-		//
-		// TODO(rfindley): unlike reloadWorkspace, this is simply marking loaded
-		// packages as loaded. We could do this from snapshot.load and avoid
-		// raciness.
-		s.clearShouldLoad(scope)
-
-		// Don't return an error here, as we may still return stale IDs.
-		// Furthermore, the result of MetadataForFile should be consistent upon
-		// subsequent calls, even if the file is marked as unloadable.
-		if err != nil && !errors.Is(err, errNoPackages) {
-			event.Error(ctx, "MetadataForFile", err)
-		}
-	}
-
-	// Retrieve the metadata.
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	ids = s.meta.ids[uri]
-	metas := make([]*source.Metadata, len(ids))
-	for i, id := range ids {
-		metas[i] = s.meta.metadata[id]
-		if metas[i] == nil {
-			panic("nil metadata")
-		}
-	}
-	// Metadata is only ever added by loading,
-	// so if we get here and still have
-	// no IDs, uri is unloadable.
-	if !unloadable && len(ids) == 0 {
-		s.unloadableFiles[uri] = struct{}{}
-	}
-
-	// Sort packages "narrowest" to "widest" (in practice: non-tests before tests).
-	sort.Slice(metas, func(i, j int) bool {
-		return len(metas[i].CompiledGoFiles) < len(metas[j].CompiledGoFiles)
-	})
-
-	return metas, nil
-}
-
-func (s *snapshot) ReverseDependencies(ctx context.Context, id PackageID, transitive bool) (map[PackageID]*source.Metadata, error) {
-	if err := s.awaitLoaded(ctx); err != nil {
-		return nil, err
-	}
-	s.mu.Lock()
-	meta := s.meta
-	s.mu.Unlock()
-
-	var rdeps map[PackageID]*source.Metadata
-	if transitive {
-		rdeps = meta.reverseReflexiveTransitiveClosure(id)
-
-		// Remove the original package ID from the map.
-		// (Callers all want irreflexivity but it's easier
-		// to compute reflexively then subtract.)
-		delete(rdeps, id)
-
-	} else {
-		// direct reverse dependencies
-		rdeps = make(map[PackageID]*source.Metadata)
-		for _, rdepID := range meta.importedBy[id] {
-			if rdep := meta.metadata[rdepID]; rdep != nil {
-				rdeps[rdepID] = rdep
-			}
-		}
-	}
-
-	return rdeps, nil
-}
-
-func (s *snapshot) workspaceMetadata() (meta []*source.Metadata) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	for id := range s.workspacePackages {
-		meta = append(meta, s.meta.metadata[id])
-	}
-	return meta
-}
-
-func (s *snapshot) isActiveLocked(id PackageID) (active bool) {
-	if seen, ok := s.isActivePackageCache.Get(id); ok {
-		return seen
-	}
-	defer func() {
-		s.isActivePackageCache.Set(id, active)
-	}()
-	m, ok := s.meta.metadata[id]
-	if !ok {
-		return false
-	}
-	for _, cgf := range m.CompiledGoFiles {
-		if s.isOpenLocked(cgf) {
-			return true
-		}
-	}
-	// TODO(rfindley): it looks incorrect that we don't also check GoFiles here.
-	// If a CGo file is open, we want to consider the package active.
-	for _, dep := range m.DepsByPkgPath {
-		if s.isActiveLocked(dep) {
-			return true
-		}
-	}
-	return false
-}
-
-func (s *snapshot) resetIsActivePackageLocked() {
-	s.isActivePackageCache.Destroy()
-	s.isActivePackageCache = newIsActivePackageCacheMap()
-}
-
-const fileExtensions = "go,mod,sum,work"
-
-func (s *snapshot) fileWatchingGlobPatterns(ctx context.Context) map[string]struct{} {
-	extensions := fileExtensions
-	for _, ext := range s.View().Options().TemplateExtensions {
-		extensions += "," + ext
-	}
-	// Work-around microsoft/vscode#100870 by making sure that we are,
-	// at least, watching the user's entire workspace. This will still be
-	// applied to every folder in the workspace.
-	patterns := map[string]struct{}{
-		fmt.Sprintf("**/*.{%s}", extensions): {},
-	}
-
-	if s.view.explicitGowork != "" {
-		patterns[s.view.explicitGowork.Filename()] = struct{}{}
-	}
-
-	// Add a pattern for each Go module in the workspace that is not within the view.
-	dirs := s.workspace.dirs(ctx, s)
-	for _, dir := range dirs {
-		dirName := dir.Filename()
-
-		// If the directory is within the view's folder, we're already watching
-		// it with the first pattern above.
-		if source.InDir(s.view.folder.Filename(), dirName) {
-			continue
-		}
-		// TODO(rstambler): If microsoft/vscode#3025 is resolved before
-		// microsoft/vscode#101042, we will need a work-around for Windows
-		// drive letter casing.
-		patterns[fmt.Sprintf("%s/**/*.{%s}", dirName, extensions)] = struct{}{}
-	}
-
-	// Some clients do not send notifications for changes to directories that
-	// contain Go code (golang/go#42348). To handle this, explicitly watch all
-	// of the directories in the workspace. We find them by adding the
-	// directories of every file in the snapshot's workspace directories.
-	// There may be thousands.
-	if pattern := s.getKnownSubdirsPattern(dirs); pattern != "" {
-		patterns[pattern] = struct{}{}
-	}
-
-	return patterns
-}
-
-func (s *snapshot) getKnownSubdirsPattern(wsDirs []span.URI) string {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	// First, process any pending changes and update the set of known
-	// subdirectories.
-	// It may change list of known subdirs and therefore invalidate the cache.
-	s.applyKnownSubdirsChangesLocked(wsDirs)
-
-	if s.knownSubdirsPatternCache == "" {
-		var builder strings.Builder
-		s.knownSubdirs.Range(func(uri span.URI) {
-			if builder.Len() == 0 {
-				builder.WriteString("{")
-			} else {
-				builder.WriteString(",")
-			}
-			builder.WriteString(uri.Filename())
-		})
-		if builder.Len() > 0 {
-			builder.WriteString("}")
-			s.knownSubdirsPatternCache = builder.String()
-		}
-	}
-
-	return s.knownSubdirsPatternCache
-}
-
-// collectAllKnownSubdirs collects all of the subdirectories within the
-// snapshot's workspace directories. None of the workspace directories are
-// included.
-func (s *snapshot) collectAllKnownSubdirs(ctx context.Context) {
-	dirs := s.workspace.dirs(ctx, s)
-
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	s.knownSubdirs.Destroy()
-	s.knownSubdirs = newKnownDirsSet()
-	s.knownSubdirsPatternCache = ""
-	s.files.Range(func(uri span.URI, fh source.VersionedFileHandle) {
-		s.addKnownSubdirLocked(uri, dirs)
-	})
-}
-
-func (s *snapshot) getKnownSubdirs(wsDirs []span.URI) knownDirsSet {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	// First, process any pending changes and update the set of known
-	// subdirectories.
-	s.applyKnownSubdirsChangesLocked(wsDirs)
-
-	return s.knownSubdirs.Clone()
-}
-
-func (s *snapshot) applyKnownSubdirsChangesLocked(wsDirs []span.URI) {
-	for _, c := range s.unprocessedSubdirChanges {
-		if c.isUnchanged {
-			continue
-		}
-		if !c.exists {
-			s.removeKnownSubdirLocked(c.fileHandle.URI())
-		} else {
-			s.addKnownSubdirLocked(c.fileHandle.URI(), wsDirs)
-		}
-	}
-	s.unprocessedSubdirChanges = nil
-}
-
-func (s *snapshot) addKnownSubdirLocked(uri span.URI, dirs []span.URI) {
-	dir := filepath.Dir(uri.Filename())
-	// First check if the directory is already known, because then we can
-	// return early.
-	if s.knownSubdirs.Contains(span.URIFromPath(dir)) {
-		return
-	}
-	var matched span.URI
-	for _, wsDir := range dirs {
-		if source.InDir(wsDir.Filename(), dir) {
-			matched = wsDir
-			break
-		}
-	}
-	// Don't watch any directory outside of the workspace directories.
-	if matched == "" {
-		return
-	}
-	for {
-		if dir == "" || dir == matched.Filename() {
-			break
-		}
-		uri := span.URIFromPath(dir)
-		if s.knownSubdirs.Contains(uri) {
-			break
-		}
-		s.knownSubdirs.Insert(uri)
-		dir = filepath.Dir(dir)
-		s.knownSubdirsPatternCache = ""
-	}
-}
-
-func (s *snapshot) removeKnownSubdirLocked(uri span.URI) {
-	dir := filepath.Dir(uri.Filename())
-	for dir != "" {
-		uri := span.URIFromPath(dir)
-		if !s.knownSubdirs.Contains(uri) {
-			break
-		}
-		if info, _ := os.Stat(dir); info == nil {
-			s.knownSubdirs.Remove(uri)
-			s.knownSubdirsPatternCache = ""
-		}
-		dir = filepath.Dir(dir)
-	}
-}
-
-// knownFilesInDir returns the files known to the given snapshot that are in
-// the given directory. It does not respect symlinks.
-func (s *snapshot) knownFilesInDir(ctx context.Context, dir span.URI) []span.URI {
-	var files []span.URI
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	s.files.Range(func(uri span.URI, fh source.VersionedFileHandle) {
-		if source.InDir(dir.Filename(), uri.Filename()) {
-			files = append(files, uri)
-		}
-	})
-	return files
-}
-
-func (s *snapshot) ActiveMetadata(ctx context.Context) ([]*source.Metadata, error) {
-	if err := s.awaitLoaded(ctx); err != nil {
-		return nil, err
-	}
-
-	if s.view.Options().MemoryMode == source.ModeNormal {
-		return s.workspaceMetadata(), nil
-	}
-
-	// ModeDegradeClosed
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	var active []*source.Metadata
-	for id := range s.workspacePackages {
-		if s.isActiveLocked(id) {
-			active = append(active, s.Metadata(id))
-		}
-	}
-	return active, nil
-}
-
-// Symbols extracts and returns the symbols for each file in all the snapshot's views.
-func (s *snapshot) Symbols(ctx context.Context) map[span.URI][]source.Symbol {
-	// Read the set of Go files out of the snapshot.
-	var goFiles []source.VersionedFileHandle
-	s.mu.Lock()
-	s.files.Range(func(uri span.URI, f source.VersionedFileHandle) {
-		if s.View().FileKind(f) == source.Go {
-			goFiles = append(goFiles, f)
-		}
-	})
-	s.mu.Unlock()
-
-	// Symbolize them in parallel.
-	var (
-		group    errgroup.Group
-		nprocs   = 2 * runtime.GOMAXPROCS(-1) // symbolize is a mix of I/O and CPU
-		resultMu sync.Mutex
-		result   = make(map[span.URI][]source.Symbol)
-	)
-	group.SetLimit(nprocs)
-	for _, f := range goFiles {
-		f := f
-		group.Go(func() error {
-			symbols, err := s.symbolize(ctx, f)
-			if err != nil {
-				return err
-			}
-			resultMu.Lock()
-			result[f.URI()] = symbols
-			resultMu.Unlock()
-			return nil
-		})
-	}
-	// Keep going on errors, but log the first failure.
-	// Partial results are better than no symbol results.
-	if err := group.Wait(); err != nil {
-		event.Error(ctx, "getting snapshot symbols", err)
-	}
-	return result
-}
-
-func (s *snapshot) AllMetadata(ctx context.Context) ([]*source.Metadata, error) {
-	if err := s.awaitLoaded(ctx); err != nil {
-		return nil, err
-	}
-
-	s.mu.Lock()
-	g := s.meta
-	s.mu.Unlock()
-
-	meta := make([]*source.Metadata, 0, len(g.metadata))
-	for _, m := range g.metadata {
-		meta = append(meta, m)
-	}
-	return meta, nil
-}
-
-func (s *snapshot) CachedImportPaths(ctx context.Context) (map[PackagePath]source.Package, error) {
-	// Don't reload workspace package metadata.
-	// This function is meant to only return currently cached information.
-	s.AwaitInitialized(ctx)
-
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	results := map[PackagePath]source.Package{}
-	s.packages.Range(func(_, v interface{}) {
-		cachedPkg, err := v.(*packageHandle).cached()
-		if err != nil {
-			return
-		}
-		for _, newPkg := range cachedPkg.deps {
-			pkgPath := newPkg.PkgPath()
-			if oldPkg, ok := results[pkgPath]; ok {
-				// Using the same trick as NarrowestPackage, prefer non-variants.
-				if len(newPkg.compiledGoFiles) < len(oldPkg.(*pkg).compiledGoFiles) {
-					results[pkgPath] = newPkg
-				}
-			} else {
-				results[pkgPath] = newPkg
-			}
-		}
-	})
-	return results, nil
-}
-
-// TODO(rfindley): clarify that this is only active modules. Or update to just
-// use findRootPattern.
-func (s *snapshot) GoModForFile(uri span.URI) span.URI {
-	return moduleForURI(s.workspace.activeModFiles, uri)
-}
-
-func moduleForURI(modFiles map[span.URI]struct{}, uri span.URI) span.URI {
-	var match span.URI
-	for modURI := range modFiles {
-		if !source.InDir(span.Dir(modURI).Filename(), uri.Filename()) {
-			continue
-		}
-		if len(modURI) > len(match) {
-			match = modURI
-		}
-	}
-	return match
-}
-
-func (s *snapshot) Metadata(id PackageID) *source.Metadata {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	return s.meta.metadata[id]
-}
-
-// clearShouldLoad clears package IDs that no longer need to be reloaded after
-// scopes has been loaded.
-func (s *snapshot) clearShouldLoad(scopes ...loadScope) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	for _, scope := range scopes {
-		switch scope := scope.(type) {
-		case packageLoadScope:
-			scopePath := PackagePath(scope)
-			var toDelete []PackageID
-			for id, pkgPaths := range s.shouldLoad {
-				for _, pkgPath := range pkgPaths {
-					if pkgPath == scopePath {
-						toDelete = append(toDelete, id)
-					}
-				}
-			}
-			for _, id := range toDelete {
-				delete(s.shouldLoad, id)
-			}
-		case fileLoadScope:
-			uri := span.URI(scope)
-			ids := s.meta.ids[uri]
-			for _, id := range ids {
-				delete(s.shouldLoad, id)
-			}
-		}
-	}
-}
-
-// noValidMetadataForURILocked reports whether there is any valid metadata for
-// the given URI.
-func (s *snapshot) noValidMetadataForURILocked(uri span.URI) bool {
-	for _, id := range s.meta.ids[uri] {
-		if _, ok := s.meta.metadata[id]; ok {
-			return false
-		}
-	}
-	return true
-}
-
-func (s *snapshot) isWorkspacePackage(id PackageID) bool {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	_, ok := s.workspacePackages[id]
-	return ok
-}
-
-func (s *snapshot) FindFile(uri span.URI) source.VersionedFileHandle {
-	uri, _ = s.view.canonicalURI(uri, true)
-
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	result, _ := s.files.Get(uri)
-	return result
-}
-
-// GetVersionedFile returns a File for the given URI. If the file is unknown it
-// is added to the managed set.
-//
-// GetVersionedFile succeeds even if the file does not exist. A non-nil error return
-// indicates some type of internal error, for example if ctx is cancelled.
-func (s *snapshot) GetVersionedFile(ctx context.Context, uri span.URI) (source.VersionedFileHandle, error) {
-	uri, _ = s.view.canonicalURI(uri, true)
-
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	if fh, ok := s.files.Get(uri); ok {
-		return fh, nil
-	}
-
-	fh, err := s.view.cache.getFile(ctx, uri) // read the file
-	if err != nil {
-		return nil, err
-	}
-	closed := &closedFile{fh}
-	s.files.Set(uri, closed)
-	return closed, nil
-}
-
-// GetFile implements the fileSource interface by wrapping GetVersionedFile.
-func (s *snapshot) GetFile(ctx context.Context, uri span.URI) (source.FileHandle, error) {
-	return s.GetVersionedFile(ctx, uri)
-}
-
-func (s *snapshot) IsOpen(uri span.URI) bool {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	return s.isOpenLocked(uri)
-
-}
-
-func (s *snapshot) openFiles() []source.VersionedFileHandle {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	var open []source.VersionedFileHandle
-	s.files.Range(func(uri span.URI, fh source.VersionedFileHandle) {
-		if isFileOpen(fh) {
-			open = append(open, fh)
-		}
-	})
-	return open
-}
-
-func (s *snapshot) isOpenLocked(uri span.URI) bool {
-	fh, _ := s.files.Get(uri)
-	return isFileOpen(fh)
-}
-
-func isFileOpen(fh source.VersionedFileHandle) bool {
-	_, open := fh.(*overlay)
-	return open
-}
-
-func (s *snapshot) awaitLoaded(ctx context.Context) error {
-	loadErr := s.awaitLoadedAllErrors(ctx)
-
-	// TODO(rfindley): eliminate this function as part of simplifying
-	// CriticalErrors.
-	if loadErr != nil {
-		return loadErr.MainError
-	}
-	return nil
-}
-
-func (s *snapshot) GetCriticalError(ctx context.Context) *source.CriticalError {
-	if wsErr := s.workspace.criticalError(ctx, s); wsErr != nil {
-		return wsErr
-	}
-
-	loadErr := s.awaitLoadedAllErrors(ctx)
-	if loadErr != nil && errors.Is(loadErr.MainError, context.Canceled) {
-		return nil
-	}
-
-	// Even if packages didn't fail to load, we still may want to show
-	// additional warnings.
-	if loadErr == nil {
-		active, _ := s.ActiveMetadata(ctx)
-		if msg := shouldShowAdHocPackagesWarning(s, active); msg != "" {
-			return &source.CriticalError{
-				MainError: errors.New(msg),
-			}
-		}
-		// Even if workspace packages were returned, there still may be an error
-		// with the user's workspace layout. Workspace packages that only have the
-		// ID "command-line-arguments" are usually a symptom of a bad workspace
-		// configuration.
-		//
-		// This heuristic is path-dependent: we only get command-line-arguments
-		// packages when we've loaded using file scopes, which only occurs
-		// on-demand or via orphaned file reloading.
-		//
-		// TODO(rfindley): re-evaluate this heuristic.
-		if containsCommandLineArguments(active) {
-			err, diags := s.workspaceLayoutError(ctx)
-			if err != nil {
-				if ctx.Err() != nil {
-					return nil // see the API documentation for source.Snapshot
-				}
-				return &source.CriticalError{
-					MainError:   err,
-					Diagnostics: diags,
-				}
-			}
-		}
-		return nil
-	}
-
-	if errMsg := loadErr.MainError.Error(); strings.Contains(errMsg, "cannot find main module") || strings.Contains(errMsg, "go.mod file not found") {
-		err, diags := s.workspaceLayoutError(ctx)
-		if err != nil {
-			if ctx.Err() != nil {
-				return nil // see the API documentation for source.Snapshot
-			}
-			return &source.CriticalError{
-				MainError:   err,
-				Diagnostics: diags,
-			}
-		}
-	}
-	return loadErr
-}
-
-// A portion of this text is expected by TestBrokenWorkspace_OutsideModule.
-const adHocPackagesWarning = `You are outside of a module and outside of $GOPATH/src.
-If you are using modules, please open your editor to a directory in your module.
-If you believe this warning is incorrect, please file an issue: https://github.com/golang/go/issues/new.`
-
-func shouldShowAdHocPackagesWarning(snapshot source.Snapshot, active []*source.Metadata) string {
-	if !snapshot.ValidBuildConfiguration() {
-		for _, m := range active {
-			// A blank entry in DepsByImpPath
-			// indicates a missing dependency.
-			for _, importID := range m.DepsByImpPath {
-				if importID == "" {
-					return adHocPackagesWarning
-				}
-			}
-		}
-	}
-	return ""
-}
-
-func containsCommandLineArguments(metas []*source.Metadata) bool {
-	for _, m := range metas {
-		if source.IsCommandLineArguments(m.ID) {
-			return true
-		}
-	}
-	return false
-}
-
-func (s *snapshot) awaitLoadedAllErrors(ctx context.Context) *source.CriticalError {
-	// Do not return results until the snapshot's view has been initialized.
-	s.AwaitInitialized(ctx)
-
-	// TODO(rfindley): Should we be more careful about returning the
-	// initialization error? Is it possible for the initialization error to be
-	// corrected without a successful reinitialization?
-	if err := s.getInitializationError(); err != nil {
-		return err
-	}
-
-	// TODO(rfindley): revisit this handling. Calling reloadWorkspace with a
-	// cancelled context should have the same effect, so this preemptive handling
-	// should not be necessary.
-	//
-	// Also: GetCriticalError ignores context cancellation errors. Should we be
-	// returning nil here?
-	if ctx.Err() != nil {
-		return &source.CriticalError{MainError: ctx.Err()}
-	}
-
-	// TODO(rfindley): reloading is not idempotent: if we try to reload or load
-	// orphaned files below and fail, we won't try again. For that reason, we
-	// could get different results from subsequent calls to this function, which
-	// may cause critical errors to be suppressed.
-
-	if err := s.reloadWorkspace(ctx); err != nil {
-		diags := s.extractGoCommandErrors(ctx, err)
-		return &source.CriticalError{
-			MainError:   err,
-			Diagnostics: diags,
-		}
-	}
-
-	if err := s.reloadOrphanedOpenFiles(ctx); err != nil {
-		diags := s.extractGoCommandErrors(ctx, err)
-		return &source.CriticalError{
-			MainError:   err,
-			Diagnostics: diags,
-		}
-	}
-	return nil
-}
-
-func (s *snapshot) getInitializationError() *source.CriticalError {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	return s.initializedErr
-}
-
-func (s *snapshot) AwaitInitialized(ctx context.Context) {
-	select {
-	case <-ctx.Done():
-		return
-	case <-s.view.initialWorkspaceLoad:
-	}
-	// We typically prefer to run something as intensive as the IWL without
-	// blocking. I'm not sure if there is a way to do that here.
-	s.initialize(ctx, false)
-}
-
-// reloadWorkspace reloads the metadata for all invalidated workspace packages.
-func (s *snapshot) reloadWorkspace(ctx context.Context) error {
-	var scopes []loadScope
-	var seen map[PackagePath]bool
-	s.mu.Lock()
-	for _, pkgPaths := range s.shouldLoad {
-		for _, pkgPath := range pkgPaths {
-			if seen == nil {
-				seen = make(map[PackagePath]bool)
-			}
-			if seen[pkgPath] {
-				continue
-			}
-			seen[pkgPath] = true
-			scopes = append(scopes, packageLoadScope(pkgPath))
-		}
-	}
-	s.mu.Unlock()
-
-	if len(scopes) == 0 {
-		return nil
-	}
-
-	// If the view's build configuration is invalid, we cannot reload by
-	// package path. Just reload the directory instead.
-	if !s.ValidBuildConfiguration() {
-		scopes = []loadScope{viewLoadScope("LOAD_INVALID_VIEW")}
-	}
-
-	err := s.load(ctx, false, scopes...)
-
-	// Unless the context was canceled, set "shouldLoad" to false for all
-	// of the metadata we attempted to load.
-	if !errors.Is(err, context.Canceled) {
-		s.clearShouldLoad(scopes...)
-	}
-
-	return err
-}
-
-func (s *snapshot) reloadOrphanedOpenFiles(ctx context.Context) error {
-	// When we load ./... or a package path directly, we may not get packages
-	// that exist only in overlays. As a workaround, we search all of the files
-	// available in the snapshot and reload their metadata individually using a
-	// file= query if the metadata is unavailable.
-	files := s.orphanedOpenFiles()
-
-	// Files without a valid package declaration can't be loaded. Don't try.
-	var scopes []loadScope
-	for _, file := range files {
-		pgf, err := s.ParseGo(ctx, file, source.ParseHeader)
-		if err != nil {
-			continue
-		}
-		if !pgf.File.Package.IsValid() {
-			continue
-		}
-
-		scopes = append(scopes, fileLoadScope(file.URI()))
-	}
-
-	if len(scopes) == 0 {
-		return nil
-	}
-
-	// The regtests match this exact log message, keep them in sync.
-	event.Log(ctx, "reloadOrphanedFiles reloading", tag.Query.Of(scopes))
-	err := s.load(ctx, false, scopes...)
-
-	// If we failed to load some files, i.e. they have no metadata,
-	// mark the failures so we don't bother retrying until the file's
-	// content changes.
-	//
-	// TODO(rstambler): This may be an overestimate if the load stopped
-	// early for an unrelated errors. Add a fallback?
-	//
-	// Check for context cancellation so that we don't incorrectly mark files
-	// as unloadable, but don't return before setting all workspace packages.
-	if ctx.Err() == nil && err != nil {
-		event.Error(ctx, "reloadOrphanedFiles: failed to load", err, tag.Query.Of(scopes))
-		s.mu.Lock()
-		for _, scope := range scopes {
-			uri := span.URI(scope.(fileLoadScope))
-			if s.noValidMetadataForURILocked(uri) {
-				s.unloadableFiles[uri] = struct{}{}
-			}
-		}
-		s.mu.Unlock()
-	}
-	return nil
-}
-
-func (s *snapshot) orphanedOpenFiles() []source.VersionedFileHandle {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	var files []source.VersionedFileHandle
-	s.files.Range(func(uri span.URI, fh source.VersionedFileHandle) {
-		// Only consider open files, which will be represented as overlays.
-		if _, isOverlay := fh.(*overlay); !isOverlay {
-			return
-		}
-		// Don't try to reload metadata for go.mod files.
-		if s.view.FileKind(fh) != source.Go {
-			return
-		}
-		// If the URI doesn't belong to this view, then it's not in a workspace
-		// package and should not be reloaded directly.
-		if !source.InDir(s.view.folder.Filename(), uri.Filename()) {
-			return
-		}
-		// Don't reload metadata for files we've already deemed unloadable.
-		if _, ok := s.unloadableFiles[uri]; ok {
-			return
-		}
-		if s.noValidMetadataForURILocked(uri) {
-			files = append(files, fh)
-		}
-	})
-	return files
-}
-
-// TODO(golang/go#53756): this function needs to consider more than just the
-// absolute URI, for example:
-//   - the position of /vendor/ with respect to the relevant module root
-//   - whether or not go.work is in use (as vendoring isn't supported in workspace mode)
-//
-// Most likely, each call site of inVendor needs to be reconsidered to
-// understand and correctly implement the desired behavior.
-func inVendor(uri span.URI) bool {
-	_, after, found := cut(string(uri), "/vendor/")
-	// Only subdirectories of /vendor/ are considered vendored
-	// (/vendor/a/foo.go is vendored, /vendor/foo.go is not).
-	return found && strings.Contains(after, "/")
-}
-
-// TODO(adonovan): replace with strings.Cut when we can assume go1.18.
-func cut(s, sep string) (before, after string, found bool) {
-	if i := strings.Index(s, sep); i >= 0 {
-		return s[:i], s[i+len(sep):], true
-	}
-	return s, "", false
-}
-
-// unappliedChanges is a file source that handles an uncloned snapshot.
-type unappliedChanges struct {
-	originalSnapshot *snapshot
-	changes          map[span.URI]*fileChange
-}
-
-func (ac *unappliedChanges) GetFile(ctx context.Context, uri span.URI) (source.FileHandle, error) {
-	if c, ok := ac.changes[uri]; ok {
-		return c.fileHandle, nil
-	}
-	return ac.originalSnapshot.GetFile(ctx, uri)
-}
-
-func (s *snapshot) clone(ctx, bgCtx context.Context, changes map[span.URI]*fileChange, forceReloadMetadata bool) (*snapshot, func()) {
-	ctx, done := event.Start(ctx, "snapshot.clone")
-	defer done()
-
-	newWorkspace, reinit := s.workspace.Clone(ctx, changes, &unappliedChanges{
-		originalSnapshot: s,
-		changes:          changes,
-	})
-
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	// Changes to vendor tree may require reinitialization,
-	// either because of an initialization error
-	// (e.g. "inconsistent vendoring detected"), or because
-	// one or more modules may have moved into or out of the
-	// vendor tree after 'go mod vendor' or 'rm -fr vendor/'.
-	for uri := range changes {
-		if inVendor(uri) && s.initializedErr != nil ||
-			strings.HasSuffix(string(uri), "/vendor/modules.txt") {
-			reinit = true
-			break
-		}
-	}
-
-	bgCtx, cancel := context.WithCancel(bgCtx)
-	result := &snapshot{
-		sequenceID:           s.sequenceID + 1,
-		globalID:             nextSnapshotID(),
-		store:                s.store,
-		view:                 s.view,
-		backgroundCtx:        bgCtx,
-		cancel:               cancel,
-		builtin:              s.builtin,
-		initialized:          s.initialized,
-		initializedErr:       s.initializedErr,
-		packages:             s.packages.Clone(),
-		isActivePackageCache: s.isActivePackageCache.Clone(),
-		analyses:             s.analyses.Clone(),
-		files:                s.files.Clone(),
-		parsedGoFiles:        s.parsedGoFiles.Clone(),
-		parseKeysByURI:       s.parseKeysByURI.Clone(),
-		symbolizeHandles:     s.symbolizeHandles.Clone(),
-		workspacePackages:    make(map[PackageID]PackagePath, len(s.workspacePackages)),
-		unloadableFiles:      make(map[span.URI]struct{}, len(s.unloadableFiles)),
-		parseModHandles:      s.parseModHandles.Clone(),
-		parseWorkHandles:     s.parseWorkHandles.Clone(),
-		modTidyHandles:       s.modTidyHandles.Clone(),
-		modWhyHandles:        s.modWhyHandles.Clone(),
-		modVulnHandles:       s.modVulnHandles.Clone(),
-		knownSubdirs:         s.knownSubdirs.Clone(),
-		workspace:            newWorkspace,
-	}
-
-	// The snapshot should be initialized if either s was uninitialized, or we've
-	// detected a change that triggers reinitialization.
-	if reinit {
-		result.initialized = false
-	}
-
-	// Create a lease on the new snapshot.
-	// (Best to do this early in case the code below hides an
-	// incref/decref operation that might destroy it prematurely.)
-	release := result.Acquire()
-
-	// Copy the set of unloadable files.
-	//
-	// TODO(rfindley): this looks wrong. Shouldn't we clear unloadableFiles on
-	// changes to environment or workspace layout, or more generally on any
-	// metadata change?
-	//
-	// Maybe not, as major configuration changes cause a new view.
-	for k, v := range s.unloadableFiles {
-		result.unloadableFiles[k] = v
-	}
-
-	// TODO(adonovan): merge loops over "changes".
-	for uri, change := range changes {
-		// Optimization: if the content did not change, we don't need to evict the
-		// parsed file. This is not the case for e.g. the files map, which may
-		// switch from on-disk state to overlay. Parsed files depend only on
-		// content and parse mode (which is captured in the parse key).
-		//
-		// NOTE: This also makes it less likely that we re-parse a file due to a
-		// cache-miss but get a cache-hit for the corresponding package. In the
-		// past, there was code that relied on ParseGo returning the type-checked
-		// syntax tree. That code was wrong, but avoiding invalidation here limits
-		// the blast radius of these types of bugs.
-		if !change.isUnchanged {
-			keys, ok := result.parseKeysByURI.Get(uri)
-			if ok {
-				for _, key := range keys {
-					result.parsedGoFiles.Delete(key)
-				}
-				result.parseKeysByURI.Delete(uri)
-			}
-		}
-
-		// Invalidate go.mod-related handles.
-		result.modTidyHandles.Delete(uri)
-		result.modWhyHandles.Delete(uri)
-		result.modVulnHandles.Delete(uri)
-
-		// Invalidate handles for cached symbols.
-		result.symbolizeHandles.Delete(uri)
-	}
-
-	// Add all of the known subdirectories, but don't update them for the
-	// changed files. We need to rebuild the workspace module to know the
-	// true set of known subdirectories, but we don't want to do that in clone.
-	result.knownSubdirs = s.knownSubdirs.Clone()
-	result.knownSubdirsPatternCache = s.knownSubdirsPatternCache
-	for _, c := range changes {
-		result.unprocessedSubdirChanges = append(result.unprocessedSubdirChanges, c)
-	}
-
-	// directIDs keeps track of package IDs that have directly changed.
-	// Note: this is not a set, it's a map from id to invalidateMetadata.
-	directIDs := map[PackageID]bool{}
-
-	// Invalidate all package metadata if the workspace module has changed.
-	if reinit {
-		for k := range s.meta.metadata {
-			directIDs[k] = true
-		}
-	}
-
-	// Compute invalidations based on file changes.
-	anyImportDeleted := false      // import deletions can resolve cycles
-	anyFileOpenedOrClosed := false // opened files affect workspace packages
-	anyFileAdded := false          // adding a file can resolve missing dependencies
-
-	for uri, change := range changes {
-		// The original FileHandle for this URI is cached on the snapshot.
-		originalFH, _ := s.files.Get(uri)
-		var originalOpen, newOpen bool
-		_, originalOpen = originalFH.(*overlay)
-		_, newOpen = change.fileHandle.(*overlay)
-		anyFileOpenedOrClosed = anyFileOpenedOrClosed || (originalOpen != newOpen)
-		anyFileAdded = anyFileAdded || (originalFH == nil && change.fileHandle != nil)
-
-		// If uri is a Go file, check if it has changed in a way that would
-		// invalidate metadata. Note that we can't use s.view.FileKind here,
-		// because the file type that matters is not what the *client* tells us,
-		// but what the Go command sees.
-		var invalidateMetadata, pkgFileChanged, importDeleted bool
-		if strings.HasSuffix(uri.Filename(), ".go") {
-			invalidateMetadata, pkgFileChanged, importDeleted = metadataChanges(ctx, s, originalFH, change.fileHandle)
-		}
-
-		invalidateMetadata = invalidateMetadata || forceReloadMetadata || reinit
-		anyImportDeleted = anyImportDeleted || importDeleted
-
-		// Mark all of the package IDs containing the given file.
-		filePackageIDs := invalidatedPackageIDs(uri, s.meta.ids, pkgFileChanged)
-		for id := range filePackageIDs {
-			directIDs[id] = directIDs[id] || invalidateMetadata // may insert 'false'
-		}
-
-		// Invalidate the previous modTidyHandle if any of the files have been
-		// saved or if any of the metadata has been invalidated.
-		if invalidateMetadata || fileWasSaved(originalFH, change.fileHandle) {
-			// TODO(maybe): Only delete mod handles for
-			// which the withoutURI is relevant.
-			// Requires reverse-engineering the go command. (!)
-			result.modTidyHandles.Clear()
-			result.modWhyHandles.Clear()
-			result.modVulnHandles.Clear()
-		}
-
-		result.parseModHandles.Delete(uri)
-		result.parseWorkHandles.Delete(uri)
-		// Handle the invalidated file; it may have new contents or not exist.
-		if !change.exists {
-			result.files.Delete(uri)
-		} else {
-			result.files.Set(uri, change.fileHandle)
-		}
-
-		// Make sure to remove the changed file from the unloadable set.
-		delete(result.unloadableFiles, uri)
-	}
-
-	// Deleting an import can cause list errors due to import cycles to be
-	// resolved. The best we can do without parsing the list error message is to
-	// hope that list errors may have been resolved by a deleted import.
-	//
-	// We could do better by parsing the list error message. We already do this
-	// to assign a better range to the list error, but for such critical
-	// functionality as metadata, it's better to be conservative until it proves
-	// impractical.
-	//
-	// We could also do better by looking at which imports were deleted and
-	// trying to find cycles they are involved in. This fails when the file goes
-	// from an unparseable state to a parseable state, as we don't have a
-	// starting point to compare with.
-	if anyImportDeleted {
-		for id, metadata := range s.meta.metadata {
-			if len(metadata.Errors) > 0 {
-				directIDs[id] = true
-			}
-		}
-	}
-
-	// Adding a file can resolve missing dependencies from existing packages.
-	//
-	// We could be smart here and try to guess which packages may have been
-	// fixed, but until that proves necessary, just invalidate metadata for any
-	// package with missing dependencies.
-	if anyFileAdded {
-		for id, metadata := range s.meta.metadata {
-			for _, impID := range metadata.DepsByImpPath {
-				if impID == "" { // missing import
-					directIDs[id] = true
-					break
-				}
-			}
-		}
-	}
-
-	// Invalidate reverse dependencies too.
-	// idsToInvalidate keeps track of transitive reverse dependencies.
-	// If an ID is present in the map, invalidate its types.
-	// If an ID's value is true, invalidate its metadata too.
-	idsToInvalidate := map[PackageID]bool{}
-	var addRevDeps func(PackageID, bool)
-	addRevDeps = func(id PackageID, invalidateMetadata bool) {
-		current, seen := idsToInvalidate[id]
-		newInvalidateMetadata := current || invalidateMetadata
-
-		// If we've already seen this ID, and the value of invalidate
-		// metadata has not changed, we can return early.
-		if seen && current == newInvalidateMetadata {
-			return
-		}
-		idsToInvalidate[id] = newInvalidateMetadata
-		for _, rid := range s.meta.importedBy[id] {
-			addRevDeps(rid, invalidateMetadata)
-		}
-	}
-	for id, invalidateMetadata := range directIDs {
-		addRevDeps(id, invalidateMetadata)
-	}
-
-	// Delete invalidated package type information.
-	for id := range idsToInvalidate {
-		for _, mode := range source.AllParseModes {
-			key := packageKey{mode, id}
-			result.packages.Delete(key)
-		}
-	}
-
-	// Delete invalidated analysis actions.
-	var actionsToDelete []analysisKey
-	result.analyses.Range(func(k, _ interface{}) {
-		key := k.(analysisKey)
-		if _, ok := idsToInvalidate[key.pkgid]; ok {
-			actionsToDelete = append(actionsToDelete, key)
-		}
-	})
-	for _, key := range actionsToDelete {
-		result.analyses.Delete(key)
-	}
-
-	// If a file has been deleted, we must delete metadata for all packages
-	// containing that file.
-	//
-	// TODO(rfindley): why not keep invalid metadata in this case? If we
-	// otherwise allow operate on invalid metadata, why not continue to do so,
-	// skipping the missing file?
-	skipID := map[PackageID]bool{}
-	for _, c := range changes {
-		if c.exists {
-			continue
-		}
-		// The file has been deleted.
-		if ids, ok := s.meta.ids[c.fileHandle.URI()]; ok {
-			for _, id := range ids {
-				skipID[id] = true
-			}
-		}
-	}
-
-	// Any packages that need loading in s still need loading in the new
-	// snapshot.
-	for k, v := range s.shouldLoad {
-		if result.shouldLoad == nil {
-			result.shouldLoad = make(map[PackageID][]PackagePath)
-		}
-		result.shouldLoad[k] = v
-	}
-
-	// Compute which metadata updates are required. We only need to invalidate
-	// packages directly containing the affected file, and only if it changed in
-	// a relevant way.
-	metadataUpdates := make(map[PackageID]*source.Metadata)
-	for k, v := range s.meta.metadata {
-		invalidateMetadata := idsToInvalidate[k]
-
-		// For metadata that has been newly invalidated, capture package paths
-		// requiring reloading in the shouldLoad map.
-		if invalidateMetadata && !source.IsCommandLineArguments(v.ID) {
-			if result.shouldLoad == nil {
-				result.shouldLoad = make(map[PackageID][]PackagePath)
-			}
-			needsReload := []PackagePath{v.PkgPath}
-			if v.ForTest != "" && v.ForTest != v.PkgPath {
-				// When reloading test variants, always reload their ForTest package as
-				// well. Otherwise, we may miss test variants in the resulting load.
-				//
-				// TODO(rfindley): is this actually sufficient? Is it possible that
-				// other test variants may be invalidated? Either way, we should
-				// determine exactly what needs to be reloaded here.
-				needsReload = append(needsReload, v.ForTest)
-			}
-			result.shouldLoad[k] = needsReload
-		}
-
-		// Check whether the metadata should be deleted.
-		if skipID[k] || invalidateMetadata {
-			metadataUpdates[k] = nil
-			continue
-		}
-	}
-
-	// Update metadata, if necessary.
-	result.meta = s.meta.Clone(metadataUpdates)
-
-	// Update workspace and active packages, if necessary.
-	if result.meta != s.meta || anyFileOpenedOrClosed {
-		result.workspacePackages = computeWorkspacePackagesLocked(result, result.meta)
-		result.resetIsActivePackageLocked()
-	} else {
-		result.workspacePackages = s.workspacePackages
-	}
-
-	// Don't bother copying the importedBy graph,
-	// as it changes each time we update metadata.
-
-	// TODO(rfindley): consolidate the this workspace mode detection with
-	// workspace invalidation.
-	workspaceModeChanged := s.workspaceMode() != result.workspaceMode()
-
-	// If the snapshot's workspace mode has changed, the packages loaded using
-	// the previous mode are no longer relevant, so clear them out.
-	if workspaceModeChanged {
-		result.workspacePackages = map[PackageID]PackagePath{}
-	}
-	result.dumpWorkspace("clone")
-	return result, release
-}
-
-// invalidatedPackageIDs returns all packages invalidated by a change to uri.
-// If we haven't seen this URI before, we guess based on files in the same
-// directory. This is of course incorrect in build systems where packages are
-// not organized by directory.
-//
-// If packageFileChanged is set, the file is either a new file, or has a new
-// package name. In this case, all known packages in the directory will be
-// invalidated.
-func invalidatedPackageIDs(uri span.URI, known map[span.URI][]PackageID, packageFileChanged bool) map[PackageID]struct{} {
-	invalidated := make(map[PackageID]struct{})
-
-	// At a minimum, we invalidate packages known to contain uri.
-	for _, id := range known[uri] {
-		invalidated[id] = struct{}{}
-	}
-
-	// If the file didn't move to a new package, we should only invalidate the
-	// packages it is currently contained inside.
-	if !packageFileChanged && len(invalidated) > 0 {
-		return invalidated
-	}
-
-	// This is a file we don't yet know about, or which has moved packages. Guess
-	// relevant packages by considering files in the same directory.
-
-	// Cache of FileInfo to avoid unnecessary stats for multiple files in the
-	// same directory.
-	stats := make(map[string]struct {
-		os.FileInfo
-		error
-	})
-	getInfo := func(dir string) (os.FileInfo, error) {
-		if res, ok := stats[dir]; ok {
-			return res.FileInfo, res.error
-		}
-		fi, err := os.Stat(dir)
-		stats[dir] = struct {
-			os.FileInfo
-			error
-		}{fi, err}
-		return fi, err
-	}
-	dir := filepath.Dir(uri.Filename())
-	fi, err := getInfo(dir)
-	if err == nil {
-		// Aggregate all possibly relevant package IDs.
-		for knownURI, ids := range known {
-			knownDir := filepath.Dir(knownURI.Filename())
-			knownFI, err := getInfo(knownDir)
-			if err != nil {
-				continue
-			}
-			if os.SameFile(fi, knownFI) {
-				for _, id := range ids {
-					invalidated[id] = struct{}{}
-				}
-			}
-		}
-	}
-	return invalidated
-}
-
-// fileWasSaved reports whether the FileHandle passed in has been saved. It
-// accomplishes this by checking to see if the original and current FileHandles
-// are both overlays, and if the current FileHandle is saved while the original
-// FileHandle was not saved.
-func fileWasSaved(originalFH, currentFH source.FileHandle) bool {
-	c, ok := currentFH.(*overlay)
-	if !ok || c == nil {
-		return true
-	}
-	o, ok := originalFH.(*overlay)
-	if !ok || o == nil {
-		return c.saved
-	}
-	return !o.saved && c.saved
-}
-
-// metadataChanges detects features of the change from oldFH->newFH that may
-// affect package metadata.
-//
-// It uses lockedSnapshot to access cached parse information. lockedSnapshot
-// must be locked.
-//
-// The result parameters have the following meaning:
-//   - invalidate means that package metadata for packages containing the file
-//     should be invalidated.
-//   - pkgFileChanged means that the file->package associates for the file have
-//     changed (possibly because the file is new, or because its package name has
-//     changed).
-//   - importDeleted means that an import has been deleted, or we can't
-//     determine if an import was deleted due to errors.
-func metadataChanges(ctx context.Context, lockedSnapshot *snapshot, oldFH, newFH source.FileHandle) (invalidate, pkgFileChanged, importDeleted bool) {
-	if oldFH == nil || newFH == nil { // existential changes
-		changed := (oldFH == nil) != (newFH == nil)
-		return changed, changed, (newFH == nil) // we don't know if an import was deleted
-	}
-
-	// If the file hasn't changed, there's no need to reload.
-	if oldFH.FileIdentity() == newFH.FileIdentity() {
-		return false, false, false
-	}
-
-	// Parse headers to compare package names and imports.
-	oldHead, oldErr := peekOrParse(ctx, lockedSnapshot, oldFH, source.ParseHeader)
-	newHead, newErr := peekOrParse(ctx, lockedSnapshot, newFH, source.ParseHeader)
-
-	if oldErr != nil || newErr != nil {
-		// TODO(rfindley): we can get here if newFH does not exists. There is
-		// asymmetry here, in that newFH may be non-nil even if the underlying file
-		// does not exist.
-		//
-		// We should not produce a non-nil filehandle for a file that does not exist.
-		errChanged := (oldErr == nil) != (newErr == nil)
-		return errChanged, errChanged, (newErr != nil) // we don't know if an import was deleted
-	}
-
-	// `go list` fails completely if the file header cannot be parsed. If we go
-	// from a non-parsing state to a parsing state, we should reload.
-	if oldHead.ParseErr != nil && newHead.ParseErr == nil {
-		return true, true, true // We don't know what changed, so fall back on full invalidation.
-	}
-
-	// If a package name has changed, the set of package imports may have changed
-	// in ways we can't detect here. Assume an import has been deleted.
-	if oldHead.File.Name.Name != newHead.File.Name.Name {
-		return true, true, true
-	}
-
-	// Check whether package imports have changed. Only consider potentially
-	// valid imports paths.
-	oldImports := validImports(oldHead.File.Imports)
-	newImports := validImports(newHead.File.Imports)
-
-	for path := range newImports {
-		if _, ok := oldImports[path]; ok {
-			delete(oldImports, path)
-		} else {
-			invalidate = true // a new, potentially valid import was added
-		}
-	}
-
-	if len(oldImports) > 0 {
-		invalidate = true
-		importDeleted = true
-	}
-
-	// If the change does not otherwise invalidate metadata, get the full ASTs in
-	// order to check magic comments.
-	//
-	// Note: if this affects performance we can probably avoid parsing in the
-	// common case by first scanning the source for potential comments.
-	if !invalidate {
-		origFull, oldErr := peekOrParse(ctx, lockedSnapshot, oldFH, source.ParseFull)
-		currFull, newErr := peekOrParse(ctx, lockedSnapshot, newFH, source.ParseFull)
-		if oldErr == nil && newErr == nil {
-			invalidate = magicCommentsChanged(origFull.File, currFull.File)
-		} else {
-			// At this point, we shouldn't ever fail to produce a ParsedGoFile, as
-			// we're already past header parsing.
-			bug.Reportf("metadataChanges: unparseable file %v (old error: %v, new error: %v)", oldFH.URI(), oldErr, newErr)
-		}
-	}
-
-	return invalidate, pkgFileChanged, importDeleted
-}
-
-// peekOrParse returns the cached ParsedGoFile if it exists,
-// otherwise parses without populating the cache.
-//
-// It returns an error if the file could not be read (note that parsing errors
-// are stored in ParsedGoFile.ParseErr).
-//
-// lockedSnapshot must be locked.
-func peekOrParse(ctx context.Context, lockedSnapshot *snapshot, fh source.FileHandle, mode source.ParseMode) (*source.ParsedGoFile, error) {
-	// Peek in the cache without populating it.
-	// We do this to reduce retained heap, not work.
-	if parsed, _ := lockedSnapshot.peekParseGoLocked(fh, mode); parsed != nil {
-		return parsed, nil // cache hit
-	}
-	return parseGoImpl(ctx, token.NewFileSet(), fh, mode)
-}
-
-func magicCommentsChanged(original *ast.File, current *ast.File) bool {
-	oldComments := extractMagicComments(original)
-	newComments := extractMagicComments(current)
-	if len(oldComments) != len(newComments) {
-		return true
-	}
-	for i := range oldComments {
-		if oldComments[i] != newComments[i] {
-			return true
-		}
-	}
-	return false
-}
-
-// validImports extracts the set of valid import paths from imports.
-func validImports(imports []*ast.ImportSpec) map[string]struct{} {
-	m := make(map[string]struct{})
-	for _, spec := range imports {
-		if path := spec.Path.Value; validImportPath(path) {
-			m[path] = struct{}{}
-		}
-	}
-	return m
-}
-
-func validImportPath(path string) bool {
-	path, err := strconv.Unquote(path)
-	if err != nil {
-		return false
-	}
-	if path == "" {
-		return false
-	}
-	if path[len(path)-1] == '/' {
-		return false
-	}
-	return true
-}
-
-var buildConstraintOrEmbedRe = regexp.MustCompile(`^//(go:embed|go:build|\s*\+build).*`)
-
-// extractMagicComments finds magic comments that affect metadata in f.
-func extractMagicComments(f *ast.File) []string {
-	var results []string
-	for _, cg := range f.Comments {
-		for _, c := range cg.List {
-			if buildConstraintOrEmbedRe.MatchString(c.Text) {
-				results = append(results, c.Text)
-			}
-		}
-	}
-	return results
-}
-
-func (s *snapshot) BuiltinFile(ctx context.Context) (*source.ParsedGoFile, error) {
-	s.AwaitInitialized(ctx)
-
-	s.mu.Lock()
-	builtin := s.builtin
-	s.mu.Unlock()
-
-	if builtin == "" {
-		return nil, fmt.Errorf("no builtin package for view %s", s.view.name)
-	}
-
-	fh, err := s.GetFile(ctx, builtin)
-	if err != nil {
-		return nil, err
-	}
-	return s.ParseGo(ctx, fh, source.ParseFull)
-}
-
-func (s *snapshot) IsBuiltin(ctx context.Context, uri span.URI) bool {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	// We should always get the builtin URI in a canonical form, so use simple
-	// string comparison here. span.CompareURI is too expensive.
-	return uri == s.builtin
-}
-
-func (s *snapshot) setBuiltin(path string) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	s.builtin = span.URIFromPath(path)
-}
-
-// BuildGoplsMod generates a go.mod file for all modules in the workspace. It
-// bypasses any existing gopls.mod.
-func (s *snapshot) BuildGoplsMod(ctx context.Context) (*modfile.File, error) {
-	allModules, err := findModules(s.view.folder, pathExcludedByFilterFunc(s.view.rootURI.Filename(), s.view.gomodcache, s.View().Options()), 0)
-	if err != nil {
-		return nil, err
-	}
-	return buildWorkspaceModFile(ctx, allModules, s)
-}
-
-// TODO(rfindley): move this to workspace.go
-func buildWorkspaceModFile(ctx context.Context, modFiles map[span.URI]struct{}, fs source.FileSource) (*modfile.File, error) {
-	file := &modfile.File{}
-	file.AddModuleStmt("gopls-workspace")
-	// Track the highest Go version, to be set on the workspace module.
-	// Fall back to 1.12 -- old versions insist on having some version.
-	goVersion := "1.12"
-
-	paths := map[string]span.URI{}
-	excludes := map[string][]string{}
-	var sortedModURIs []span.URI
-	for uri := range modFiles {
-		sortedModURIs = append(sortedModURIs, uri)
-	}
-	sort.Slice(sortedModURIs, func(i, j int) bool {
-		return sortedModURIs[i] < sortedModURIs[j]
-	})
-	for _, modURI := range sortedModURIs {
-		fh, err := fs.GetFile(ctx, modURI)
-		if err != nil {
-			return nil, err
-		}
-		content, err := fh.Read()
-		if err != nil {
-			return nil, err
-		}
-		parsed, err := modfile.Parse(fh.URI().Filename(), content, nil)
-		if err != nil {
-			return nil, err
-		}
-		if file == nil || parsed.Module == nil {
-			return nil, fmt.Errorf("no module declaration for %s", modURI)
-		}
-		// Prepend "v" to go versions to make them valid semver.
-		if parsed.Go != nil && semver.Compare("v"+goVersion, "v"+parsed.Go.Version) < 0 {
-			goVersion = parsed.Go.Version
-		}
-		path := parsed.Module.Mod.Path
-		if seen, ok := paths[path]; ok {
-			return nil, fmt.Errorf("found module %q multiple times in the workspace, at:\n\t%q\n\t%q", path, seen, modURI)
-		}
-		paths[path] = modURI
-		// If the module's path includes a major version, we expect it to have
-		// a matching major version.
-		_, majorVersion, _ := module.SplitPathVersion(path)
-		if majorVersion == "" {
-			majorVersion = "/v0"
-		}
-		majorVersion = strings.TrimLeft(majorVersion, "/.") // handle gopkg.in versions
-		file.AddNewRequire(path, source.WorkspaceModuleVersion(majorVersion), false)
-		if err := file.AddReplace(path, "", span.Dir(modURI).Filename(), ""); err != nil {
-			return nil, err
-		}
-		for _, exclude := range parsed.Exclude {
-			excludes[exclude.Mod.Path] = append(excludes[exclude.Mod.Path], exclude.Mod.Version)
-		}
-	}
-	if goVersion != "" {
-		file.AddGoStmt(goVersion)
-	}
-	// Go back through all of the modules to handle any of their replace
-	// statements.
-	for _, modURI := range sortedModURIs {
-		fh, err := fs.GetFile(ctx, modURI)
-		if err != nil {
-			return nil, err
-		}
-		content, err := fh.Read()
-		if err != nil {
-			return nil, err
-		}
-		parsed, err := modfile.Parse(fh.URI().Filename(), content, nil)
-		if err != nil {
-			return nil, err
-		}
-		// If any of the workspace modules have replace directives, they need
-		// to be reflected in the workspace module.
-		for _, rep := range parsed.Replace {
-			// Don't replace any modules that are in our workspace--we should
-			// always use the version in the workspace.
-			if _, ok := paths[rep.Old.Path]; ok {
-				continue
-			}
-			newPath := rep.New.Path
-			newVersion := rep.New.Version
-			// If a replace points to a module in the workspace, make sure we
-			// direct it to version of the module in the workspace.
-			if m, ok := paths[rep.New.Path]; ok {
-				newPath = span.Dir(m).Filename()
-				newVersion = ""
-			} else if rep.New.Version == "" && !filepath.IsAbs(rep.New.Path) {
-				// Make any relative paths absolute.
-				newPath = filepath.Join(span.Dir(modURI).Filename(), rep.New.Path)
-			}
-			if err := file.AddReplace(rep.Old.Path, rep.Old.Version, newPath, newVersion); err != nil {
-				return nil, err
-			}
-		}
-	}
-	for path, versions := range excludes {
-		for _, version := range versions {
-			file.AddExclude(path, version)
-		}
-	}
-	file.SortBlocks()
-	return file, nil
-}
-
-func buildWorkspaceSumFile(ctx context.Context, modFiles map[span.URI]struct{}, fs source.FileSource) ([]byte, error) {
-	allSums := map[module.Version][]string{}
-	for modURI := range modFiles {
-		// TODO(rfindley): factor out this pattern into a uripath package.
-		sumURI := span.URIFromPath(filepath.Join(filepath.Dir(modURI.Filename()), "go.sum"))
-		fh, err := fs.GetFile(ctx, sumURI)
-		if err != nil {
-			continue
-		}
-		data, err := fh.Read()
-		if os.IsNotExist(err) {
-			continue
-		}
-		if err != nil {
-			return nil, fmt.Errorf("reading go sum: %w", err)
-		}
-		if err := readGoSum(allSums, sumURI.Filename(), data); err != nil {
-			return nil, err
-		}
-	}
-	// This logic to write go.sum is copied (with minor modifications) from
-	// https://cs.opensource.google/go/go/+/master:src/cmd/go/internal/modfetch/fetch.go;l=631;drc=762eda346a9f4062feaa8a9fc0d17d72b11586f0
-	var mods []module.Version
-	for m := range allSums {
-		mods = append(mods, m)
-	}
-	module.Sort(mods)
-
-	var buf bytes.Buffer
-	for _, m := range mods {
-		list := allSums[m]
-		sort.Strings(list)
-		// Note (rfindley): here we add all sum lines without verification, because
-		// the assumption is that if they come from a go.sum file, they are
-		// trusted.
-		for _, h := range list {
-			fmt.Fprintf(&buf, "%s %s %s\n", m.Path, m.Version, h)
-		}
-	}
-	return buf.Bytes(), nil
-}
-
-// readGoSum is copied (with minor modifications) from
-// https://cs.opensource.google/go/go/+/master:src/cmd/go/internal/modfetch/fetch.go;l=398;drc=762eda346a9f4062feaa8a9fc0d17d72b11586f0
-func readGoSum(dst map[module.Version][]string, file string, data []byte) error {
-	lineno := 0
-	for len(data) > 0 {
-		var line []byte
-		lineno++
-		i := bytes.IndexByte(data, '\n')
-		if i < 0 {
-			line, data = data, nil
-		} else {
-			line, data = data[:i], data[i+1:]
-		}
-		f := strings.Fields(string(line))
-		if len(f) == 0 {
-			// blank line; skip it
-			continue
-		}
-		if len(f) != 3 {
-			return fmt.Errorf("malformed go.sum:\n%s:%d: wrong number of fields %v", file, lineno, len(f))
-		}
-		mod := module.Version{Path: f[0], Version: f[1]}
-		dst[mod] = append(dst[mod], f[2])
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cache/standalone_go115.go b/gopls/internal/lsp/cache/standalone_go115.go
--- a/gopls/internal/lsp/cache/standalone_go115.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/standalone_go115.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.16
-// +build !go1.16
-
-package cache
-
-// isStandaloneFile returns false, as the 'standaloneTags' setting is
-// unsupported on Go 1.15 and earlier.
-func isStandaloneFile(src []byte, standaloneTags []string) bool {
-	return false
-}
diff -urN a/gopls/internal/lsp/cache/standalone_go116.go b/gopls/internal/lsp/cache/standalone_go116.go
--- a/gopls/internal/lsp/cache/standalone_go116.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/standalone_go116.go	1969-12-31 16:00:00
@@ -1,50 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.16
-// +build go1.16
-
-package cache
-
-import (
-	"go/build/constraint"
-	"go/parser"
-	"go/token"
-)
-
-// isStandaloneFile reports whether a file with the given contents should be
-// considered a 'standalone main file', meaning a package that consists of only
-// a single file.
-func isStandaloneFile(src []byte, standaloneTags []string) bool {
-	f, err := parser.ParseFile(token.NewFileSet(), "", src, parser.PackageClauseOnly|parser.ParseComments)
-	if err != nil {
-		return false
-	}
-
-	if f.Name == nil || f.Name.Name != "main" {
-		return false
-	}
-
-	for _, cg := range f.Comments {
-		// Even with PackageClauseOnly the parser consumes the semicolon following
-		// the package clause, so we must guard against comments that come after
-		// the package name.
-		if cg.Pos() > f.Name.Pos() {
-			continue
-		}
-		for _, comment := range cg.List {
-			if c, err := constraint.Parse(comment.Text); err == nil {
-				if tag, ok := c.(*constraint.TagExpr); ok {
-					for _, t := range standaloneTags {
-						if t == tag.Tag {
-							return true
-						}
-					}
-				}
-			}
-		}
-	}
-
-	return false
-}
diff -urN a/gopls/internal/lsp/cache/standalone_go116_test.go b/gopls/internal/lsp/cache/standalone_go116_test.go
--- a/gopls/internal/lsp/cache/standalone_go116_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/standalone_go116_test.go	1969-12-31 16:00:00
@@ -1,96 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.16
-// +build go1.16
-
-package cache
-
-import (
-	"testing"
-)
-
-func TestIsStandaloneFile(t *testing.T) {
-	tests := []struct {
-		desc           string
-		contents       string
-		standaloneTags []string
-		want           bool
-	}{
-		{
-			"new syntax",
-			"//go:build ignore\n\npackage main\n",
-			[]string{"ignore"},
-			true,
-		},
-		{
-			"legacy syntax",
-			"// +build ignore\n\npackage main\n",
-			[]string{"ignore"},
-			true,
-		},
-		{
-			"multiple tags",
-			"//go:build ignore\n\npackage main\n",
-			[]string{"exclude", "ignore"},
-			true,
-		},
-		{
-			"invalid tag",
-			"// +build ignore\n\npackage main\n",
-			[]string{"script"},
-			false,
-		},
-		{
-			"non-main package",
-			"//go:build ignore\n\npackage p\n",
-			[]string{"ignore"},
-			false,
-		},
-		{
-			"alternate tag",
-			"// +build script\n\npackage main\n",
-			[]string{"script"},
-			true,
-		},
-		{
-			"both syntax",
-			"//go:build ignore\n// +build ignore\n\npackage main\n",
-			[]string{"ignore"},
-			true,
-		},
-		{
-			"after comments",
-			"// A non-directive comment\n//go:build ignore\n\npackage main\n",
-			[]string{"ignore"},
-			true,
-		},
-		{
-			"after package decl",
-			"package main //go:build ignore\n",
-			[]string{"ignore"},
-			false,
-		},
-		{
-			"on line after package decl",
-			"package main\n\n//go:build ignore\n",
-			[]string{"ignore"},
-			false,
-		},
-		{
-			"combined with other expressions",
-			"\n\n//go:build ignore || darwin\n\npackage main\n",
-			[]string{"ignore"},
-			false,
-		},
-	}
-
-	for _, test := range tests {
-		t.Run(test.desc, func(t *testing.T) {
-			if got := isStandaloneFile([]byte(test.contents), test.standaloneTags); got != test.want {
-				t.Errorf("isStandaloneFile(%q, %v) = %t, want %t", test.contents, test.standaloneTags, got, test.want)
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/cache/symbols.go b/gopls/internal/lsp/cache/symbols.go
--- a/gopls/internal/lsp/cache/symbols.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/symbols.go	1969-12-31 16:00:00
@@ -1,238 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"go/ast"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/memoize"
-)
-
-// symbolize returns the result of symbolizing the file identified by fh, using a cache.
-func (s *snapshot) symbolize(ctx context.Context, fh source.FileHandle) ([]source.Symbol, error) {
-	uri := fh.URI()
-
-	s.mu.Lock()
-	entry, hit := s.symbolizeHandles.Get(uri)
-	s.mu.Unlock()
-
-	type symbolizeResult struct {
-		symbols []source.Symbol
-		err     error
-	}
-
-	// Cache miss?
-	if !hit {
-		type symbolHandleKey source.Hash
-		key := symbolHandleKey(fh.FileIdentity().Hash)
-		promise, release := s.store.Promise(key, func(_ context.Context, arg interface{}) interface{} {
-			symbols, err := symbolizeImpl(arg.(*snapshot), fh)
-			return symbolizeResult{symbols, err}
-		})
-
-		entry = promise
-
-		s.mu.Lock()
-		s.symbolizeHandles.Set(uri, entry, func(_, _ interface{}) { release() })
-		s.mu.Unlock()
-	}
-
-	// Await result.
-	v, err := s.awaitPromise(ctx, entry.(*memoize.Promise))
-	if err != nil {
-		return nil, err
-	}
-	res := v.(symbolizeResult)
-	return res.symbols, res.err
-}
-
-// symbolizeImpl reads and parses a file and extracts symbols from it.
-// It may use a parsed file already present in the cache but
-// otherwise does not populate the cache.
-func symbolizeImpl(snapshot *snapshot, fh source.FileHandle) ([]source.Symbol, error) {
-	src, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-
-	var (
-		file     *ast.File
-		fileDesc *token.File
-	)
-
-	// If the file has already been fully parsed through the
-	// cache, we can just use the result. But we don't want to
-	// populate the cache after a miss.
-	snapshot.mu.Lock()
-	pgf, _ := snapshot.peekParseGoLocked(fh, source.ParseFull)
-	snapshot.mu.Unlock()
-	if pgf != nil {
-		file = pgf.File
-		fileDesc = pgf.Tok
-	}
-
-	// Otherwise, we parse the file ourselves. Notably we don't use parseGo here,
-	// so that we can avoid parsing comments and can skip object resolution,
-	// which has a meaningful impact on performance. Neither comments nor objects
-	// are necessary for symbol construction.
-	if file == nil {
-		fset := token.NewFileSet()
-		file, err = parser.ParseFile(fset, fh.URI().Filename(), src, skipObjectResolution)
-		if file == nil {
-			return nil, err
-		}
-		fileDesc = fset.File(file.Package)
-	}
-
-	w := &symbolWalker{
-		mapper: lsppos.NewTokenMapper(src, fileDesc),
-	}
-
-	w.fileDecls(file.Decls)
-
-	return w.symbols, w.firstError
-}
-
-type symbolWalker struct {
-	mapper *lsppos.TokenMapper // for computing positions
-
-	symbols    []source.Symbol
-	firstError error
-}
-
-func (w *symbolWalker) atNode(node ast.Node, name string, kind protocol.SymbolKind, path ...*ast.Ident) {
-	var b strings.Builder
-	for _, ident := range path {
-		if ident != nil {
-			b.WriteString(ident.Name)
-			b.WriteString(".")
-		}
-	}
-	b.WriteString(name)
-
-	rng, err := w.mapper.Range(node.Pos(), node.End())
-	if err != nil {
-		w.error(err)
-		return
-	}
-	sym := source.Symbol{
-		Name:  b.String(),
-		Kind:  kind,
-		Range: rng,
-	}
-	w.symbols = append(w.symbols, sym)
-}
-
-func (w *symbolWalker) error(err error) {
-	if err != nil && w.firstError == nil {
-		w.firstError = err
-	}
-}
-
-func (w *symbolWalker) fileDecls(decls []ast.Decl) {
-	for _, decl := range decls {
-		switch decl := decl.(type) {
-		case *ast.FuncDecl:
-			kind := protocol.Function
-			var recv *ast.Ident
-			if decl.Recv.NumFields() > 0 {
-				kind = protocol.Method
-				recv = unpackRecv(decl.Recv.List[0].Type)
-			}
-			w.atNode(decl.Name, decl.Name.Name, kind, recv)
-		case *ast.GenDecl:
-			for _, spec := range decl.Specs {
-				switch spec := spec.(type) {
-				case *ast.TypeSpec:
-					kind := guessKind(spec)
-					w.atNode(spec.Name, spec.Name.Name, kind)
-					w.walkType(spec.Type, spec.Name)
-				case *ast.ValueSpec:
-					for _, name := range spec.Names {
-						kind := protocol.Variable
-						if decl.Tok == token.CONST {
-							kind = protocol.Constant
-						}
-						w.atNode(name, name.Name, kind)
-					}
-				}
-			}
-		}
-	}
-}
-
-func guessKind(spec *ast.TypeSpec) protocol.SymbolKind {
-	switch spec.Type.(type) {
-	case *ast.InterfaceType:
-		return protocol.Interface
-	case *ast.StructType:
-		return protocol.Struct
-	case *ast.FuncType:
-		return protocol.Function
-	}
-	return protocol.Class
-}
-
-func unpackRecv(rtyp ast.Expr) *ast.Ident {
-	// Extract the receiver identifier. Lifted from go/types/resolver.go
-L:
-	for {
-		switch t := rtyp.(type) {
-		case *ast.ParenExpr:
-			rtyp = t.X
-		case *ast.StarExpr:
-			rtyp = t.X
-		default:
-			break L
-		}
-	}
-	if name, _ := rtyp.(*ast.Ident); name != nil {
-		return name
-	}
-	return nil
-}
-
-// walkType processes symbols related to a type expression. path is path of
-// nested type identifiers to the type expression.
-func (w *symbolWalker) walkType(typ ast.Expr, path ...*ast.Ident) {
-	switch st := typ.(type) {
-	case *ast.StructType:
-		for _, field := range st.Fields.List {
-			w.walkField(field, protocol.Field, protocol.Field, path...)
-		}
-	case *ast.InterfaceType:
-		for _, field := range st.Methods.List {
-			w.walkField(field, protocol.Interface, protocol.Method, path...)
-		}
-	}
-}
-
-// walkField processes symbols related to the struct field or interface method.
-//
-// unnamedKind and namedKind are the symbol kinds if the field is resp. unnamed
-// or named. path is the path of nested identifiers containing the field.
-func (w *symbolWalker) walkField(field *ast.Field, unnamedKind, namedKind protocol.SymbolKind, path ...*ast.Ident) {
-	if len(field.Names) == 0 {
-		switch typ := field.Type.(type) {
-		case *ast.SelectorExpr:
-			// embedded qualified type
-			w.atNode(field, typ.Sel.Name, unnamedKind, path...)
-		default:
-			w.atNode(field, types.ExprString(field.Type), unnamedKind, path...)
-		}
-	}
-	for _, name := range field.Names {
-		w.atNode(name, name.Name, namedKind, path...)
-		w.walkType(field.Type, append(path, name)...)
-	}
-}
diff -urN a/gopls/internal/lsp/cache/view.go b/gopls/internal/lsp/cache/view.go
--- a/gopls/internal/lsp/cache/view.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/view.go	1969-12-31 16:00:00
@@ -1,1195 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package cache implements the caching layer for gopls.
-package cache
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path"
-	"path/filepath"
-	"reflect"
-	"regexp"
-	"sort"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/semver"
-	exec "golang.org/x/sys/execabs"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/imports"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-type View struct {
-	id string
-
-	cache       *Cache            // shared cache
-	gocmdRunner *gocommand.Runner // limits go command concurrency
-
-	// baseCtx is the context handed to NewView. This is the parent of all
-	// background contexts created for this view.
-	baseCtx context.Context
-
-	// name is the user-specified name of this view.
-	name string
-
-	optionsMu sync.Mutex
-	options   *source.Options
-
-	// Workspace information. The fields below are immutable, and together with
-	// options define the build list. Any change to these fields results in a new
-	// View.
-	//
-	// TODO(rfindley): consolidate and/or eliminate redundancy in these fields,
-	// which have evolved from different sources over time.
-	folder               span.URI // user-specified workspace folder
-	rootURI              span.URI // either folder or dir(rootSrc) (TODO: deprecate, in favor of folder+rootSrc)
-	rootSrc              span.URI // file providing module information (go.mod or go.work); may be empty
-	explicitGowork       span.URI // explicitGowork: if non-empty, a user-specified go.work location (TODO: deprecate)
-	workspaceInformation          // grab-bag of Go environment information (TODO: cleanup)
-
-	importsState *importsState
-
-	// moduleUpgrades tracks known upgrades for module paths in each modfile.
-	// Each modfile has a map of module name to upgrade version.
-	moduleUpgradesMu sync.Mutex
-	moduleUpgrades   map[span.URI]map[string]string
-
-	// vulns maps each go.mod file's URI to its known vulnerabilities.
-	vulnsMu sync.Mutex
-	vulns   map[span.URI]*govulncheck.Result
-
-	// filesByURI maps URIs to the canonical URI for the file it denotes.
-	// We also keep a set of candidates for a given basename
-	// to reduce the set of pairs that need to be tested for sameness.
-	//
-	// TODO(rfindley): move this file tracking to the session.
-	filesByMu   sync.Mutex
-	filesByURI  map[span.URI]span.URI     // key is noncanonical URI (alias)
-	filesByBase map[string][]canonicalURI // key is basename
-
-	// initCancelFirstAttempt can be used to terminate the view's first
-	// attempt at initialization.
-	initCancelFirstAttempt context.CancelFunc
-
-	// Track the latest snapshot via the snapshot field, guarded by snapshotMu.
-	//
-	// Invariant: whenever the snapshot field is overwritten, destroy(snapshot)
-	// is called on the previous (overwritten) snapshot while snapshotMu is held,
-	// incrementing snapshotWG. During shutdown the final snapshot is
-	// overwritten with nil and destroyed, guaranteeing that all observed
-	// snapshots have been destroyed via the destroy method, and snapshotWG may
-	// be waited upon to let these destroy operations complete.
-	snapshotMu      sync.Mutex
-	snapshot        *snapshot      // latest snapshot; nil after shutdown has been called
-	releaseSnapshot func()         // called when snapshot is no longer needed
-	snapshotWG      sync.WaitGroup // refcount for pending destroy operations
-
-	// initialWorkspaceLoad is closed when the first workspace initialization has
-	// completed. If we failed to load, we only retry if the go.mod file changes,
-	// to avoid too many go/packages calls.
-	initialWorkspaceLoad chan struct{}
-
-	// initializationSema is used limit concurrent initialization of snapshots in
-	// the view. We use a channel instead of a mutex to avoid blocking when a
-	// context is canceled.
-	//
-	// This field (along with snapshot.initialized) guards against duplicate
-	// initialization of snapshots. Do not change it without adjusting snapshot
-	// accordingly.
-	initializationSema chan struct{}
-}
-
-type workspaceInformation struct {
-	// The Go version in use: X in Go 1.X.
-	goversion int
-
-	// The complete output of the go version command.
-	// (Call gocommand.ParseGoVersionOutput to extract a version
-	// substring such as go1.19.1 or go1.20-rc.1, go1.21-abcdef01.)
-	goversionOutput string
-
-	// hasGopackagesDriver is true if the user has a value set for the
-	// GOPACKAGESDRIVER environment variable or a gopackagesdriver binary on
-	// their machine.
-	hasGopackagesDriver bool
-
-	// `go env` variables that need to be tracked by gopls.
-	//
-	// TODO(rfindley): eliminate this in favor of goEnv, or vice-versa.
-	environmentVariables
-
-	// goEnv is the `go env` output collected when a view is created.
-	// It includes the values of the environment variables above.
-	goEnv map[string]string
-}
-
-// effectiveGO111MODULE reports the value of GO111MODULE effective in the go
-// command at this go version, accounting for default values at different go
-// versions.
-func (w workspaceInformation) effectiveGO111MODULE() go111module {
-	// Off by default until Go 1.12.
-	go111module := w.GO111MODULE()
-	if go111module == "off" || (w.goversion < 12 && go111module == "") {
-		return off
-	}
-	// On by default as of Go 1.16.
-	if go111module == "on" || (w.goversion >= 16 && go111module == "") {
-		return on
-	}
-	return auto
-}
-
-// GO111MODULE returns the value of GO111MODULE to use for running the go
-// command. It differs from the user's environment in order to allow for the
-// more forgiving default value "auto" when using recent go versions.
-//
-// TODO(rfindley): it is probably not worthwhile diverging from the go command
-// here. The extra forgiveness may be nice, but breaks the invariant that
-// running the go command from the command line produces the same build list.
-//
-// Put differently: we shouldn't go out of our way to make GOPATH work, when
-// the go command does not.
-func (w workspaceInformation) GO111MODULE() string {
-	if w.goversion >= 16 && w.go111module == "" {
-		return "auto"
-	}
-	return w.go111module
-}
-
-type go111module int
-
-const (
-	off = go111module(iota)
-	auto
-	on
-)
-
-// environmentVariables holds important environment variables captured by a
-// call to `go env`.
-type environmentVariables struct {
-	gocache, gopath, goroot, goprivate, gomodcache string
-
-	// Don't use go111module directly, because we choose to use a different
-	// default (auto) on Go 1.16 and later, to avoid spurious errors. Use
-	// the workspaceInformation.GO111MODULE method instead.
-	go111module string
-}
-
-// workspaceMode holds various flags defining how the gopls workspace should
-// behave. They may be derived from the environment, user configuration, or
-// depend on the Go version.
-//
-// TODO(rfindley): remove workspace mode, in favor of explicit checks.
-type workspaceMode int
-
-const (
-	moduleMode workspaceMode = 1 << iota
-
-	// tempModfile indicates whether or not the -modfile flag should be used.
-	tempModfile
-)
-
-func (v *View) ID() string { return v.id }
-
-// tempModFile creates a temporary go.mod file based on the contents
-// of the given go.mod file. On success, it is the caller's
-// responsibility to call the cleanup function when the file is no
-// longer needed.
-func tempModFile(modFh source.FileHandle, gosum []byte) (tmpURI span.URI, cleanup func(), err error) {
-	filenameHash := source.Hashf("%s", modFh.URI().Filename())
-	tmpMod, err := ioutil.TempFile("", fmt.Sprintf("go.%s.*.mod", filenameHash))
-	if err != nil {
-		return "", nil, err
-	}
-	defer tmpMod.Close()
-
-	tmpURI = span.URIFromPath(tmpMod.Name())
-	tmpSumName := sumFilename(tmpURI)
-
-	content, err := modFh.Read()
-	if err != nil {
-		return "", nil, err
-	}
-
-	if _, err := tmpMod.Write(content); err != nil {
-		return "", nil, err
-	}
-
-	// We use a distinct name here to avoid subtlety around the fact
-	// that both 'return' and 'defer' update the "cleanup" variable.
-	doCleanup := func() {
-		_ = os.Remove(tmpSumName)
-		_ = os.Remove(tmpURI.Filename())
-	}
-
-	// Be careful to clean up if we return an error from this function.
-	defer func() {
-		if err != nil {
-			doCleanup()
-			cleanup = nil
-		}
-	}()
-
-	// Create an analogous go.sum, if one exists.
-	if gosum != nil {
-		if err := ioutil.WriteFile(tmpSumName, gosum, 0655); err != nil {
-			return "", nil, err
-		}
-	}
-
-	return tmpURI, doCleanup, nil
-}
-
-// Name returns the user visible name of this view.
-func (v *View) Name() string {
-	return v.name
-}
-
-// Folder returns the folder at the base of this view.
-func (v *View) Folder() span.URI {
-	return v.folder
-}
-
-func (v *View) Options() *source.Options {
-	v.optionsMu.Lock()
-	defer v.optionsMu.Unlock()
-	return v.options
-}
-
-func (v *View) FileKind(fh source.FileHandle) source.FileKind {
-	// The kind of an unsaved buffer comes from the
-	// TextDocumentItem.LanguageID field in the didChange event,
-	// not from the file name. They may differ.
-	if o, ok := fh.(source.Overlay); ok {
-		if o.Kind() != source.UnknownKind {
-			return o.Kind()
-		}
-	}
-
-	fext := filepath.Ext(fh.URI().Filename())
-	switch fext {
-	case ".go":
-		return source.Go
-	case ".mod":
-		return source.Mod
-	case ".sum":
-		return source.Sum
-	case ".work":
-		return source.Work
-	}
-	exts := v.Options().TemplateExtensions
-	for _, ext := range exts {
-		if fext == ext || fext == "."+ext {
-			return source.Tmpl
-		}
-	}
-	// and now what? This should never happen, but it does for cgo before go1.15
-	return source.Go
-}
-
-func minorOptionsChange(a, b *source.Options) bool {
-	// Check if any of the settings that modify our understanding of files have been changed
-	if !reflect.DeepEqual(a.Env, b.Env) {
-		return false
-	}
-	if !reflect.DeepEqual(a.DirectoryFilters, b.DirectoryFilters) {
-		return false
-	}
-	if !reflect.DeepEqual(a.StandaloneTags, b.StandaloneTags) {
-		return false
-	}
-	if a.MemoryMode != b.MemoryMode {
-		return false
-	}
-	aBuildFlags := make([]string, len(a.BuildFlags))
-	bBuildFlags := make([]string, len(b.BuildFlags))
-	copy(aBuildFlags, a.BuildFlags)
-	copy(bBuildFlags, b.BuildFlags)
-	sort.Strings(aBuildFlags)
-	sort.Strings(bBuildFlags)
-	// the rest of the options are benign
-	return reflect.DeepEqual(aBuildFlags, bBuildFlags)
-}
-
-// SetViewOptions sets the options of the given view to new values. Calling
-// this may cause the view to be invalidated and a replacement view added to
-// the session. If so the new view will be returned, otherwise the original one
-// will be returned.
-func (s *Session) SetViewOptions(ctx context.Context, v *View, options *source.Options) (*View, error) {
-	// no need to rebuild the view if the options were not materially changed
-	v.optionsMu.Lock()
-	if minorOptionsChange(v.options, options) {
-		v.options = options
-		v.optionsMu.Unlock()
-		return v, nil
-	}
-	v.optionsMu.Unlock()
-	newView, err := s.updateView(ctx, v, options)
-	return newView, err
-}
-
-// viewEnv returns a string describing the environment of a newly created view.
-func viewEnv(v *View) string {
-	v.optionsMu.Lock()
-	env := v.options.EnvSlice()
-	buildFlags := append([]string{}, v.options.BuildFlags...)
-	v.optionsMu.Unlock()
-
-	var buf bytes.Buffer
-	fmt.Fprintf(&buf, `go env for %v
-(root %s)
-(go version %s)
-(valid build configuration = %v)
-(build flags: %v)
-`,
-		v.folder.Filename(),
-		v.rootURI.Filename(),
-		strings.TrimRight(v.workspaceInformation.goversionOutput, "\n"),
-		v.snapshot.ValidBuildConfiguration(),
-		buildFlags)
-
-	fullEnv := make(map[string]string)
-	for k, v := range v.goEnv {
-		fullEnv[k] = v
-	}
-	for _, v := range env {
-		s := strings.SplitN(v, "=", 2)
-		if len(s) != 2 {
-			continue
-		}
-		if _, ok := fullEnv[s[0]]; ok {
-			fullEnv[s[0]] = s[1]
-		}
-	}
-	for k, v := range fullEnv {
-		fmt.Fprintf(&buf, "%s=%s\n", k, v)
-	}
-
-	return buf.String()
-}
-
-func (s *snapshot) RunProcessEnvFunc(ctx context.Context, fn func(*imports.Options) error) error {
-	return s.view.importsState.runProcessEnvFunc(ctx, s, fn)
-}
-
-// separated out from its sole use in locateTemplateFiles for testability
-func fileHasExtension(path string, suffixes []string) bool {
-	ext := filepath.Ext(path)
-	if ext != "" && ext[0] == '.' {
-		ext = ext[1:]
-	}
-	for _, s := range suffixes {
-		if s != "" && ext == s {
-			return true
-		}
-	}
-	return false
-}
-
-func (s *snapshot) locateTemplateFiles(ctx context.Context) {
-	if len(s.view.Options().TemplateExtensions) == 0 {
-		return
-	}
-	suffixes := s.view.Options().TemplateExtensions
-
-	// The workspace root may have been expanded to a module, but we should apply
-	// directory filters based on the configured workspace folder.
-	//
-	// TODO(rfindley): we should be more principled about paths outside of the
-	// workspace folder: do we even consider them? Do we support absolute
-	// exclusions? Relative exclusions starting with ..?
-	dir := s.workspace.root.Filename()
-	relativeTo := s.view.folder.Filename()
-
-	searched := 0
-	filterer := buildFilterer(dir, s.view.gomodcache, s.view.Options())
-	// Change to WalkDir when we move up to 1.16
-	err := filepath.Walk(dir, func(path string, fi os.FileInfo, err error) error {
-		if err != nil {
-			return err
-		}
-		relpath := strings.TrimPrefix(path, relativeTo)
-		excluded := pathExcludedByFilter(relpath, filterer)
-		if fileHasExtension(path, suffixes) && !excluded && !fi.IsDir() {
-			k := span.URIFromPath(path)
-			_, err := s.GetVersionedFile(ctx, k)
-			if err != nil {
-				return nil
-			}
-		}
-		searched++
-		if fileLimit > 0 && searched > fileLimit {
-			return errExhausted
-		}
-		return nil
-	})
-	if err != nil {
-		event.Error(ctx, "searching for template files failed", err)
-	}
-}
-
-func (v *View) contains(uri span.URI) bool {
-	// TODO(rfindley): should we ignore the root here? It is not provided by the
-	// user, and is undefined when go.work is outside the workspace. It would be
-	// better to explicitly consider the set of active modules wherever relevant.
-	inRoot := source.InDir(v.rootURI.Filename(), uri.Filename())
-	inFolder := source.InDir(v.folder.Filename(), uri.Filename())
-
-	if !inRoot && !inFolder {
-		return false
-	}
-
-	return !v.filterFunc()(uri)
-}
-
-// filterFunc returns a func that reports whether uri is filtered by the currently configured
-// directoryFilters.
-func (v *View) filterFunc() func(span.URI) bool {
-	filterer := buildFilterer(v.rootURI.Filename(), v.gomodcache, v.Options())
-	return func(uri span.URI) bool {
-		// Only filter relative to the configured root directory.
-		if source.InDir(v.folder.Filename(), uri.Filename()) {
-			return pathExcludedByFilter(strings.TrimPrefix(uri.Filename(), v.folder.Filename()), filterer)
-		}
-		return false
-	}
-}
-
-func (v *View) relevantChange(c source.FileModification) bool {
-	// If the file is known to the view, the change is relevant.
-	if v.knownFile(c.URI) {
-		return true
-	}
-	// The go.work/gopls.mod may not be "known" because we first access it
-	// through the session. As a result, treat changes to the view's go.work or
-	// gopls.mod file as always relevant, even if they are only on-disk
-	// changes.
-	// TODO(rstambler): Make sure the go.work/gopls.mod files are always known
-	// to the view.
-	for _, src := range []workspaceSource{goWorkWorkspace, goplsModWorkspace} {
-		if c.URI == uriForSource(v.rootURI, v.explicitGowork, src) {
-			return true
-		}
-	}
-
-	// Note: CL 219202 filtered out on-disk changes here that were not known to
-	// the view, but this introduces a race when changes arrive before the view
-	// is initialized (and therefore, before it knows about files). Since that CL
-	// had neither test nor associated issue, and cited only emacs behavior, this
-	// logic was deleted.
-
-	return v.contains(c.URI)
-}
-
-// knownFile reports whether the specified valid URI (or an alias) is known to the view.
-func (v *View) knownFile(uri span.URI) bool {
-	_, known := v.canonicalURI(uri, false)
-	return known
-}
-
-// TODO(adonovan): opt: eliminate 'filename' optimization. I doubt the
-// cost of allocation is significant relative to the
-// stat/open/fstat/close operations that follow on Windows.
-type canonicalURI struct {
-	uri      span.URI
-	filename string // = uri.Filename(), an optimization (on Windows)
-}
-
-// canonicalURI returns the canonical URI that denotes the same file
-// as uri, which may differ due to case insensitivity, unclean paths,
-// soft or hard links, and so on.  If no previous alias was found, or
-// the file is missing, insert determines whether to make uri the
-// canonical representative of the file or to return false.
-//
-// The cache grows indefinitely without invalidation: file system
-// operations may cause two URIs that used to denote the same file to
-// no longer to do so. Also, the basename cache grows without bound.
-// TODO(adonovan): fix both bugs.
-func (v *View) canonicalURI(uri span.URI, insert bool) (span.URI, bool) {
-	v.filesByMu.Lock()
-	defer v.filesByMu.Unlock()
-
-	// Have we seen this exact URI before?
-	if canonical, ok := v.filesByURI[uri]; ok {
-		return canonical, true
-	}
-
-	// Inspect all candidates with the same lowercase basename.
-	// This heuristic is easily defeated by symbolic links to files.
-	// Files with some basenames (e.g. doc.go) are very numerous.
-	//
-	// The set of candidates grows without bound, and incurs a
-	// linear sequence of SameFile queries to the file system.
-	//
-	// It is tempting to fetch the device/inode pair that
-	// uniquely identifies a file once, and then compare those
-	// pairs, but that would cause us to cache stale file system
-	// state (in addition to the filesByURI staleness).
-	filename := uri.Filename()
-	basename := strings.ToLower(filepath.Base(filename))
-	if candidates := v.filesByBase[basename]; candidates != nil {
-		if pathStat, _ := os.Stat(filename); pathStat != nil {
-			for _, c := range candidates {
-				if cStat, _ := os.Stat(c.filename); cStat != nil {
-					// On Windows, SameFile is more expensive as it must
-					// open the file and use the equivalent of fstat(2).
-					if os.SameFile(pathStat, cStat) {
-						v.filesByURI[uri] = c.uri
-						return c.uri, true
-					}
-				}
-			}
-		}
-	}
-
-	// No candidates, stat failed, or no candidate matched.
-	if insert {
-		v.filesByURI[uri] = uri
-		v.filesByBase[basename] = append(v.filesByBase[basename], canonicalURI{uri, filename})
-	}
-	return uri, insert
-}
-
-// shutdown releases resources associated with the view, and waits for ongoing
-// work to complete.
-func (v *View) shutdown() {
-	// Cancel the initial workspace load if it is still running.
-	v.initCancelFirstAttempt()
-
-	v.snapshotMu.Lock()
-	if v.snapshot != nil {
-		v.releaseSnapshot()
-		v.destroy(v.snapshot, "View.shutdown")
-		v.snapshot = nil
-		v.releaseSnapshot = nil
-	}
-	v.snapshotMu.Unlock()
-
-	v.importsState.destroy()
-	v.snapshotWG.Wait()
-}
-
-func (s *snapshot) IgnoredFile(uri span.URI) bool {
-	filename := uri.Filename()
-	var prefixes []string
-	if len(s.workspace.ActiveModFiles()) == 0 {
-		for _, entry := range filepath.SplitList(s.view.gopath) {
-			prefixes = append(prefixes, filepath.Join(entry, "src"))
-		}
-	} else {
-		prefixes = append(prefixes, s.view.gomodcache)
-		for m := range s.workspace.ActiveModFiles() {
-			prefixes = append(prefixes, span.Dir(m).Filename())
-		}
-	}
-	for _, prefix := range prefixes {
-		if strings.HasPrefix(filename, prefix) {
-			return checkIgnored(filename[len(prefix):])
-		}
-	}
-	return false
-}
-
-// checkIgnored implements go list's exclusion rules.
-// Quoting “go help list”:
-//
-//	Directory and file names that begin with "." or "_" are ignored
-//	by the go tool, as are directories named "testdata".
-func checkIgnored(suffix string) bool {
-	for _, component := range strings.Split(suffix, string(filepath.Separator)) {
-		if len(component) == 0 {
-			continue
-		}
-		if component[0] == '.' || component[0] == '_' || component == "testdata" {
-			return true
-		}
-	}
-	return false
-}
-
-func (v *View) Snapshot(ctx context.Context) (source.Snapshot, func()) {
-	return v.getSnapshot()
-}
-
-func (v *View) getSnapshot() (*snapshot, func()) {
-	v.snapshotMu.Lock()
-	defer v.snapshotMu.Unlock()
-	if v.snapshot == nil {
-		panic("getSnapshot called after shutdown")
-	}
-	return v.snapshot, v.snapshot.Acquire()
-}
-
-func (s *snapshot) initialize(ctx context.Context, firstAttempt bool) {
-	select {
-	case <-ctx.Done():
-		return
-	case s.view.initializationSema <- struct{}{}:
-	}
-
-	defer func() {
-		<-s.view.initializationSema
-	}()
-
-	s.mu.Lock()
-	initialized := s.initialized
-	s.mu.Unlock()
-
-	if initialized {
-		return
-	}
-
-	s.loadWorkspace(ctx, firstAttempt)
-	s.collectAllKnownSubdirs(ctx)
-}
-
-func (s *snapshot) loadWorkspace(ctx context.Context, firstAttempt bool) {
-	defer func() {
-		s.mu.Lock()
-		s.initialized = true
-		s.mu.Unlock()
-		if firstAttempt {
-			close(s.view.initialWorkspaceLoad)
-		}
-	}()
-
-	// TODO(rFindley): we should only locate template files on the first attempt,
-	// or guard it via a different mechanism.
-	s.locateTemplateFiles(ctx)
-
-	// Collect module paths to load by parsing go.mod files. If a module fails to
-	// parse, capture the parsing failure as a critical diagnostic.
-	var scopes []loadScope                  // scopes to load
-	var modDiagnostics []*source.Diagnostic // diagnostics for broken go.mod files
-	addError := func(uri span.URI, err error) {
-		modDiagnostics = append(modDiagnostics, &source.Diagnostic{
-			URI:      uri,
-			Severity: protocol.SeverityError,
-			Source:   source.ListError,
-			Message:  err.Error(),
-		})
-	}
-
-	if len(s.workspace.ActiveModFiles()) > 0 {
-		for modURI := range s.workspace.ActiveModFiles() {
-			// Be careful not to add context cancellation errors as critical module
-			// errors.
-			fh, err := s.GetFile(ctx, modURI)
-			if err != nil {
-				if ctx.Err() == nil {
-					addError(modURI, err)
-				}
-				continue
-			}
-			parsed, err := s.ParseMod(ctx, fh)
-			if err != nil {
-				if ctx.Err() == nil {
-					addError(modURI, err)
-				}
-				continue
-			}
-			if parsed.File == nil || parsed.File.Module == nil {
-				addError(modURI, fmt.Errorf("no module path for %s", modURI))
-				continue
-			}
-			path := parsed.File.Module.Mod.Path
-			scopes = append(scopes, moduleLoadScope(path))
-		}
-	} else {
-		scopes = append(scopes, viewLoadScope("LOAD_VIEW"))
-	}
-
-	// If we're loading anything, ensure we also load builtin,
-	// since it provides fake definitions (and documentation)
-	// for types like int that are used everywhere.
-	if len(scopes) > 0 {
-		scopes = append(scopes, packageLoadScope("builtin"))
-	}
-	err := s.load(ctx, true, scopes...)
-
-	// If the context is canceled on the first attempt, loading has failed
-	// because the go command has timed out--that should be a critical error.
-	if err != nil && !firstAttempt && ctx.Err() != nil {
-		return
-	}
-
-	var criticalErr *source.CriticalError
-	switch {
-	case err != nil && ctx.Err() != nil:
-		event.Error(ctx, fmt.Sprintf("initial workspace load: %v", err), err)
-		criticalErr = &source.CriticalError{
-			MainError: err,
-		}
-	case err != nil:
-		event.Error(ctx, "initial workspace load failed", err)
-		extractedDiags := s.extractGoCommandErrors(ctx, err)
-		criticalErr = &source.CriticalError{
-			MainError:   err,
-			Diagnostics: append(modDiagnostics, extractedDiags...),
-		}
-	case len(modDiagnostics) == 1:
-		criticalErr = &source.CriticalError{
-			MainError:   fmt.Errorf(modDiagnostics[0].Message),
-			Diagnostics: modDiagnostics,
-		}
-	case len(modDiagnostics) > 1:
-		criticalErr = &source.CriticalError{
-			MainError:   fmt.Errorf("error loading module names"),
-			Diagnostics: modDiagnostics,
-		}
-	}
-
-	// Lock the snapshot when setting the initialized error.
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	s.initializedErr = criticalErr
-}
-
-// invalidateContent invalidates the content of a Go file,
-// including any position and type information that depends on it.
-//
-// invalidateContent returns a non-nil snapshot for the new content, along with
-// a callback which the caller must invoke to release that snapshot.
-func (v *View) invalidateContent(ctx context.Context, changes map[span.URI]*fileChange, forceReloadMetadata bool) (*snapshot, func()) {
-	// Detach the context so that content invalidation cannot be canceled.
-	ctx = xcontext.Detach(ctx)
-
-	// This should be the only time we hold the view's snapshot lock for any period of time.
-	v.snapshotMu.Lock()
-	defer v.snapshotMu.Unlock()
-
-	prevSnapshot, prevReleaseSnapshot := v.snapshot, v.releaseSnapshot
-
-	if prevSnapshot == nil {
-		panic("invalidateContent called after shutdown")
-	}
-
-	// Cancel all still-running previous requests, since they would be
-	// operating on stale data.
-	prevSnapshot.cancel()
-
-	// Do not clone a snapshot until its view has finished initializing.
-	prevSnapshot.AwaitInitialized(ctx)
-
-	// Save one lease of the cloned snapshot in the view.
-	v.snapshot, v.releaseSnapshot = prevSnapshot.clone(ctx, v.baseCtx, changes, forceReloadMetadata)
-
-	prevReleaseSnapshot()
-	v.destroy(prevSnapshot, "View.invalidateContent")
-
-	// Return a second lease to the caller.
-	return v.snapshot, v.snapshot.Acquire()
-}
-
-func (s *Session) getWorkspaceInformation(ctx context.Context, folder span.URI, options *source.Options) (*workspaceInformation, error) {
-	if err := checkPathCase(folder.Filename()); err != nil {
-		return nil, fmt.Errorf("invalid workspace folder path: %w; check that the casing of the configured workspace folder path agrees with the casing reported by the operating system", err)
-	}
-	var err error
-	inv := gocommand.Invocation{
-		WorkingDir: folder.Filename(),
-		Env:        options.EnvSlice(),
-	}
-	goversion, err := gocommand.GoVersion(ctx, inv, s.gocmdRunner)
-	if err != nil {
-		return nil, err
-	}
-	goversionOutput, err := gocommand.GoVersionOutput(ctx, inv, s.gocmdRunner)
-	if err != nil {
-		return nil, err
-	}
-
-	// Make sure to get the `go env` before continuing with initialization.
-	envVars, env, err := s.getGoEnv(ctx, folder.Filename(), goversion, options.EnvSlice())
-	if err != nil {
-		return nil, err
-	}
-	// The value of GOPACKAGESDRIVER is not returned through the go command.
-	gopackagesdriver := os.Getenv("GOPACKAGESDRIVER")
-	// TODO(rfindley): this looks wrong, or at least overly defensive. If the
-	// value of GOPACKAGESDRIVER is not returned from the go command... why do we
-	// look it up here?
-	for _, s := range env {
-		split := strings.SplitN(s, "=", 2)
-		if split[0] == "GOPACKAGESDRIVER" {
-			bug.Reportf("found GOPACKAGESDRIVER from the go command") // see note above
-			gopackagesdriver = split[1]
-		}
-	}
-
-	// A user may also have a gopackagesdriver binary on their machine, which
-	// works the same way as setting GOPACKAGESDRIVER.
-	tool, _ := exec.LookPath("gopackagesdriver")
-	hasGopackagesDriver := gopackagesdriver != "off" && (gopackagesdriver != "" || tool != "")
-
-	return &workspaceInformation{
-		hasGopackagesDriver:  hasGopackagesDriver,
-		goversion:            goversion,
-		goversionOutput:      goversionOutput,
-		environmentVariables: envVars,
-		goEnv:                env,
-	}, nil
-}
-
-// findWorkspaceModuleSource searches for a "module source" relative to the
-// given folder URI. A module source is the go.work or go.mod file that
-// provides module information.
-//
-// As a special case, this function returns a module source in a nested
-// directory if it finds no other module source, and exactly one nested module.
-//
-// If no module source is found, it returns "".
-func findWorkspaceModuleSource(ctx context.Context, folderURI span.URI, fs source.FileSource, excludePath func(string) bool, experimental bool) (span.URI, error) {
-	patterns := []string{"go.work", "go.mod"}
-	if experimental {
-		patterns = []string{"go.work", "gopls.mod", "go.mod"}
-	}
-	folder := folderURI.Filename()
-	for _, basename := range patterns {
-		match, err := findRootPattern(ctx, folder, basename, fs)
-		if err != nil {
-			if ctxErr := ctx.Err(); ctxErr != nil {
-				return "", ctxErr
-			}
-			return "", err
-		}
-		if match != "" {
-			return span.URIFromPath(match), nil
-		}
-	}
-
-	// The experimental workspace can handle nested modules at this point...
-	if experimental {
-		return "", nil
-	}
-
-	// ...else we should check if there's exactly one nested module.
-	all, err := findModules(folderURI, excludePath, 2)
-	if err == errExhausted {
-		// Fall-back behavior: if we don't find any modules after searching 10000
-		// files, assume there are none.
-		event.Log(ctx, fmt.Sprintf("stopped searching for modules after %d files", fileLimit))
-		return "", nil
-	}
-	if err != nil {
-		return "", err
-	}
-	if len(all) == 1 {
-		// range to access first element.
-		for uri := range all {
-			return uri, nil
-		}
-	}
-	return "", nil
-}
-
-// findRootPattern looks for files with the given basename in dir or any parent
-// directory of dir, using the provided FileSource. It returns the first match,
-// starting from dir and search parents.
-//
-// The resulting string is either the file path of a matching file with the
-// given basename, or "" if none was found.
-func findRootPattern(ctx context.Context, dir, basename string, fs source.FileSource) (string, error) {
-	for dir != "" {
-		target := filepath.Join(dir, basename)
-		exists, err := fileExists(ctx, span.URIFromPath(target), fs)
-		if err != nil {
-			return "", err // not readable or context cancelled
-		}
-		if exists {
-			return target, nil
-		}
-		// Trailing separators must be trimmed, otherwise filepath.Split is a noop.
-		next, _ := filepath.Split(strings.TrimRight(dir, string(filepath.Separator)))
-		if next == dir {
-			break
-		}
-		dir = next
-	}
-	return "", nil
-}
-
-// OS-specific path case check, for case-insensitive filesystems.
-var checkPathCase = defaultCheckPathCase
-
-func defaultCheckPathCase(path string) error {
-	return nil
-}
-
-// getGoEnv gets the view's various GO* values.
-func (s *Session) getGoEnv(ctx context.Context, folder string, goversion int, configEnv []string) (environmentVariables, map[string]string, error) {
-	envVars := environmentVariables{}
-	vars := map[string]*string{
-		"GOCACHE":     &envVars.gocache,
-		"GOPATH":      &envVars.gopath,
-		"GOROOT":      &envVars.goroot,
-		"GOPRIVATE":   &envVars.goprivate,
-		"GOMODCACHE":  &envVars.gomodcache,
-		"GO111MODULE": &envVars.go111module,
-	}
-
-	// We can save ~200 ms by requesting only the variables we care about.
-	args := append([]string{"-json"}, imports.RequiredGoEnvVars...)
-	for k := range vars {
-		args = append(args, k)
-	}
-	// TODO(rfindley): GOWORK is not a property of the session. It may change
-	// when a workfile is added or removed.
-	//
-	// We need to distinguish between GOWORK values that are set by the GOWORK
-	// environment variable, and GOWORK values that are computed based on the
-	// location of a go.work file in the directory hierarchy.
-	args = append(args, "GOWORK")
-
-	inv := gocommand.Invocation{
-		Verb:       "env",
-		Args:       args,
-		Env:        configEnv,
-		WorkingDir: folder,
-	}
-	// Don't go through runGoCommand, as we don't need a temporary -modfile to
-	// run `go env`.
-	stdout, err := s.gocmdRunner.Run(ctx, inv)
-	if err != nil {
-		return environmentVariables{}, nil, err
-	}
-	env := make(map[string]string)
-	if err := json.Unmarshal(stdout.Bytes(), &env); err != nil {
-		return environmentVariables{}, nil, err
-	}
-
-	for key, ptr := range vars {
-		*ptr = env[key]
-	}
-
-	// Old versions of Go don't have GOMODCACHE, so emulate it.
-	//
-	// TODO(rfindley): consistent with the treatment of go111module, we should
-	// provide a wrapper method rather than mutating this value.
-	if envVars.gomodcache == "" && envVars.gopath != "" {
-		envVars.gomodcache = filepath.Join(filepath.SplitList(envVars.gopath)[0], "pkg/mod")
-	}
-	return envVars, env, err
-}
-
-func (v *View) IsGoPrivatePath(target string) bool {
-	return globsMatchPath(v.goprivate, target)
-}
-
-func (v *View) ModuleUpgrades(modfile span.URI) map[string]string {
-	v.moduleUpgradesMu.Lock()
-	defer v.moduleUpgradesMu.Unlock()
-
-	upgrades := map[string]string{}
-	for mod, ver := range v.moduleUpgrades[modfile] {
-		upgrades[mod] = ver
-	}
-	return upgrades
-}
-
-func (v *View) RegisterModuleUpgrades(modfile span.URI, upgrades map[string]string) {
-	// Return early if there are no upgrades.
-	if len(upgrades) == 0 {
-		return
-	}
-
-	v.moduleUpgradesMu.Lock()
-	defer v.moduleUpgradesMu.Unlock()
-
-	m := v.moduleUpgrades[modfile]
-	if m == nil {
-		m = make(map[string]string)
-		v.moduleUpgrades[modfile] = m
-	}
-	for mod, ver := range upgrades {
-		m[mod] = ver
-	}
-}
-
-func (v *View) ClearModuleUpgrades(modfile span.URI) {
-	v.moduleUpgradesMu.Lock()
-	defer v.moduleUpgradesMu.Unlock()
-
-	delete(v.moduleUpgrades, modfile)
-}
-
-const maxGovulncheckResultAge = 1 * time.Hour // Invalidate results older than this limit.
-var timeNow = time.Now                        // for testing
-
-func (v *View) Vulnerabilities(modfiles ...span.URI) map[span.URI]*govulncheck.Result {
-	m := make(map[span.URI]*govulncheck.Result)
-	now := timeNow()
-	v.vulnsMu.Lock()
-	defer v.vulnsMu.Unlock()
-
-	if len(modfiles) == 0 { // empty means all modfiles
-		for modfile := range v.vulns {
-			modfiles = append(modfiles, modfile)
-		}
-	}
-	for _, modfile := range modfiles {
-		vuln := v.vulns[modfile]
-		if vuln != nil && now.Sub(vuln.AsOf) > maxGovulncheckResultAge {
-			v.vulns[modfile] = nil // same as SetVulnerabilities(modfile, nil)
-			vuln = nil
-		}
-		m[modfile] = vuln
-	}
-	return m
-}
-
-func (v *View) SetVulnerabilities(modfile span.URI, vulns *govulncheck.Result) {
-	v.vulnsMu.Lock()
-	defer v.vulnsMu.Unlock()
-
-	v.vulns[modfile] = vulns
-}
-
-func (v *View) GoVersion() int {
-	return v.workspaceInformation.goversion
-}
-
-func (v *View) GoVersionString() string {
-	return gocommand.ParseGoVersionOutput(v.workspaceInformation.goversionOutput)
-}
-
-// Copied from
-// https://cs.opensource.google/go/go/+/master:src/cmd/go/internal/str/path.go;l=58;drc=2910c5b4a01a573ebc97744890a07c1a3122c67a
-func globsMatchPath(globs, target string) bool {
-	for globs != "" {
-		// Extract next non-empty glob in comma-separated list.
-		var glob string
-		if i := strings.Index(globs, ","); i >= 0 {
-			glob, globs = globs[:i], globs[i+1:]
-		} else {
-			glob, globs = globs, ""
-		}
-		if glob == "" {
-			continue
-		}
-
-		// A glob with N+1 path elements (N slashes) needs to be matched
-		// against the first N+1 path elements of target,
-		// which end just before the N+1'th slash.
-		n := strings.Count(glob, "/")
-		prefix := target
-		// Walk target, counting slashes, truncating at the N+1'th slash.
-		for i := 0; i < len(target); i++ {
-			if target[i] == '/' {
-				if n == 0 {
-					prefix = target[:i]
-					break
-				}
-				n--
-			}
-		}
-		if n > 0 {
-			// Not enough prefix elements.
-			continue
-		}
-		matched, _ := path.Match(glob, prefix)
-		if matched {
-			return true
-		}
-	}
-	return false
-}
-
-var modFlagRegexp = regexp.MustCompile(`-mod[ =](\w+)`)
-
-// TODO(rstambler): Consolidate modURI and modContent back into a FileHandle
-// after we have a version of the workspace go.mod file on disk. Getting a
-// FileHandle from the cache for temporary files is problematic, since we
-// cannot delete it.
-func (s *snapshot) vendorEnabled(ctx context.Context, modURI span.URI, modContent []byte) (bool, error) {
-	// Legacy GOPATH workspace?
-	if s.workspaceMode()&moduleMode == 0 {
-		return false, nil
-	}
-
-	// Explicit -mod flag?
-	matches := modFlagRegexp.FindStringSubmatch(s.view.goEnv["GOFLAGS"])
-	if len(matches) != 0 {
-		modFlag := matches[1]
-		if modFlag != "" {
-			// Don't override an explicit '-mod=vendor' argument.
-			// We do want to override '-mod=readonly': it would break various module code lenses,
-			// and on 1.16 we know -modfile is available, so we won't mess with go.mod anyway.
-			return modFlag == "vendor", nil
-		}
-	}
-
-	modFile, err := modfile.Parse(modURI.Filename(), modContent, nil)
-	if err != nil {
-		return false, err
-	}
-
-	// No vendor directory?
-	if fi, err := os.Stat(filepath.Join(s.view.rootURI.Filename(), "vendor")); err != nil || !fi.IsDir() {
-		return false, nil
-	}
-
-	// Vendoring enabled by default by go declaration in go.mod?
-	vendorEnabled := modFile.Go != nil && modFile.Go.Version != "" && semver.Compare("v"+modFile.Go.Version, "v1.14") >= 0
-	return vendorEnabled, nil
-}
-
-func (v *View) allFilesExcluded(pkg *packages.Package, filterer *source.Filterer) bool {
-	folder := filepath.ToSlash(v.folder.Filename())
-	for _, f := range pkg.GoFiles {
-		f = filepath.ToSlash(f)
-		if !strings.HasPrefix(f, folder) {
-			return false
-		}
-		if !pathExcludedByFilter(strings.TrimPrefix(f, folder), filterer) {
-			return false
-		}
-	}
-	return true
-}
-
-func pathExcludedByFilterFunc(root, gomodcache string, opts *source.Options) func(string) bool {
-	filterer := buildFilterer(root, gomodcache, opts)
-	return func(path string) bool {
-		return pathExcludedByFilter(path, filterer)
-	}
-}
-
-// pathExcludedByFilter reports whether the path (relative to the workspace
-// folder) should be excluded by the configured directory filters.
-//
-// TODO(rfindley): passing root and gomodcache here makes it confusing whether
-// path should be absolute or relative, and has already caused at least one
-// bug.
-func pathExcludedByFilter(path string, filterer *source.Filterer) bool {
-	path = strings.TrimPrefix(filepath.ToSlash(path), "/")
-	return filterer.Disallow(path)
-}
-
-func buildFilterer(root, gomodcache string, opts *source.Options) *source.Filterer {
-	// TODO(rfindley): this looks wrong. If gomodcache isn't actually nested
-	// under root, this will do the wrong thing.
-	gomodcache = strings.TrimPrefix(filepath.ToSlash(strings.TrimPrefix(gomodcache, root)), "/")
-	filters := opts.DirectoryFilters
-	if gomodcache != "" {
-		filters = append(filters, "-"+gomodcache)
-	}
-	return source.NewFilterer(filters)
-}
diff -urN a/gopls/internal/lsp/cache/view_test.go b/gopls/internal/lsp/cache/view_test.go
--- a/gopls/internal/lsp/cache/view_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/view_test.go	1969-12-31 16:00:00
@@ -1,288 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package cache
-
-import (
-	"context"
-	"encoding/json"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"testing"
-	"time"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func TestCaseInsensitiveFilesystem(t *testing.T) {
-	base, err := ioutil.TempDir("", t.Name())
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	inner := filepath.Join(base, "a/B/c/DEFgh")
-	if err := os.MkdirAll(inner, 0777); err != nil {
-		t.Fatal(err)
-	}
-	file := filepath.Join(inner, "f.go")
-	if err := ioutil.WriteFile(file, []byte("hi"), 0777); err != nil {
-		t.Fatal(err)
-	}
-	if _, err := os.Stat(filepath.Join(inner, "F.go")); err != nil {
-		t.Skip("filesystem is case-sensitive")
-	}
-
-	tests := []struct {
-		path string
-		err  bool
-	}{
-		{file, false},
-		{filepath.Join(inner, "F.go"), true},
-		{filepath.Join(base, "a/b/c/defgh/f.go"), true},
-	}
-	for _, tt := range tests {
-		err := checkPathCase(tt.path)
-		if err != nil != tt.err {
-			t.Errorf("checkPathCase(%q) = %v, wanted error: %v", tt.path, err, tt.err)
-		}
-	}
-}
-
-func TestFindWorkspaceModuleSource(t *testing.T) {
-	workspace := `
--- a/go.mod --
-module a
--- a/x/x.go
-package x
--- a/x/y/y.go
-package x
--- b/go.mod --
-module b
--- b/c/go.mod --
-module bc
--- d/gopls.mod --
-module d-goplsworkspace
--- d/e/go.mod --
-module de
--- f/g/go.mod --
-module fg
--- h/go.work --
-go 1.18
--- h/i/go.mod --
-module hi
-`
-	dir, err := fake.Tempdir(fake.UnpackTxt(workspace))
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(dir)
-
-	tests := []struct {
-		folder, want string
-		experimental bool
-	}{
-		{"", "", false}, // no module at root, and more than one nested module
-		{"a", "a/go.mod", false},
-		{"a/x", "a/go.mod", false},
-		{"a/x/y", "a/go.mod", false},
-		{"b/c", "b/c/go.mod", false},
-		{"d", "d/e/go.mod", false},
-		{"d", "d/gopls.mod", true},
-		{"d/e", "d/e/go.mod", false},
-		{"d/e", "d/gopls.mod", true},
-		{"f", "f/g/go.mod", false},
-		{"f", "", true},
-		{"h", "h/go.work", false},
-		{"h/i", "h/go.work", false},
-	}
-
-	for _, test := range tests {
-		ctx := context.Background()
-		rel := fake.RelativeTo(dir)
-		folderURI := span.URIFromPath(rel.AbsPath(test.folder))
-		excludeNothing := func(string) bool { return false }
-		got, err := findWorkspaceModuleSource(ctx, folderURI, &osFileSource{}, excludeNothing, test.experimental)
-		if err != nil {
-			t.Fatal(err)
-		}
-		want := span.URI("")
-		if test.want != "" {
-			want = span.URIFromPath(rel.AbsPath(test.want))
-		}
-		if got != want {
-			t.Errorf("findWorkspaceModuleSource(%q, %t) = %q, want %q", test.folder, test.experimental, got, want)
-		}
-	}
-}
-
-func TestInVendor(t *testing.T) {
-	for _, tt := range []struct {
-		path     string
-		inVendor bool
-	}{
-		{"foo/vendor/x.go", false},
-		{"foo/vendor/x/x.go", true},
-		{"foo/x.go", false},
-		{"foo/vendor/foo.txt", false},
-		{"foo/vendor/modules.txt", false},
-	} {
-		if got := inVendor(span.URIFromPath(tt.path)); got != tt.inVendor {
-			t.Errorf("expected %s inVendor %v, got %v", tt.path, tt.inVendor, got)
-		}
-	}
-}
-
-func TestFilters(t *testing.T) {
-	tests := []struct {
-		filters  []string
-		included []string
-		excluded []string
-	}{
-		{
-			included: []string{"x"},
-		},
-		{
-			filters:  []string{"-"},
-			excluded: []string{"x", "x/a"},
-		},
-		{
-			filters:  []string{"-x", "+y"},
-			included: []string{"y", "y/a", "z"},
-			excluded: []string{"x", "x/a"},
-		},
-		{
-			filters:  []string{"-x", "+x/y", "-x/y/z"},
-			included: []string{"x/y", "x/y/a", "a"},
-			excluded: []string{"x", "x/a", "x/y/z/a"},
-		},
-		{
-			filters:  []string{"+foobar", "-foo"},
-			included: []string{"foobar", "foobar/a"},
-			excluded: []string{"foo", "foo/a"},
-		},
-	}
-
-	for _, tt := range tests {
-		filterer := source.NewFilterer(tt.filters)
-		for _, inc := range tt.included {
-			if pathExcludedByFilter(inc, filterer) {
-				t.Errorf("filters %q excluded %v, wanted included", tt.filters, inc)
-			}
-		}
-		for _, exc := range tt.excluded {
-			if !pathExcludedByFilter(exc, filterer) {
-				t.Errorf("filters %q included %v, wanted excluded", tt.filters, exc)
-			}
-		}
-	}
-}
-
-func TestSuffixes(t *testing.T) {
-	type file struct {
-		path string
-		want bool
-	}
-	type cases struct {
-		option []string
-		files  []file
-	}
-	tests := []cases{
-		{[]string{"tmpl", "gotmpl"}, []file{ // default
-			{"foo", false},
-			{"foo.tmpl", true},
-			{"foo.gotmpl", true},
-			{"tmpl", false},
-			{"tmpl.go", false}},
-		},
-		{[]string{"tmpl", "gotmpl", "html", "gohtml"}, []file{
-			{"foo.gotmpl", true},
-			{"foo.html", true},
-			{"foo.gohtml", true},
-			{"html", false}},
-		},
-		{[]string{"tmpl", "gotmpl", ""}, []file{ // possible user mistake
-			{"foo.gotmpl", true},
-			{"foo.go", false},
-			{"foo", false}},
-		},
-	}
-	for _, a := range tests {
-		suffixes := a.option
-		for _, b := range a.files {
-			got := fileHasExtension(b.path, suffixes)
-			if got != b.want {
-				t.Errorf("got %v, want %v, option %q, file %q (%+v)",
-					got, b.want, a.option, b.path, b)
-			}
-		}
-	}
-}
-
-func TestView_Vulnerabilities(t *testing.T) {
-	// TODO(hyangah): use t.Cleanup when we get rid of go1.13 legacy CI.
-	defer func() { timeNow = time.Now }()
-
-	now := time.Now()
-
-	view := &View{
-		vulns: make(map[span.URI]*govulncheck.Result),
-	}
-	file1, file2 := span.URIFromPath("f1/go.mod"), span.URIFromPath("f2/go.mod")
-
-	vuln1 := &govulncheck.Result{AsOf: now.Add(-(maxGovulncheckResultAge * 3) / 4)} // already ~3/4*maxGovulncheckResultAge old
-	view.SetVulnerabilities(file1, vuln1)
-
-	vuln2 := &govulncheck.Result{AsOf: now} // fresh.
-	view.SetVulnerabilities(file2, vuln2)
-
-	t.Run("fresh", func(t *testing.T) {
-		got := view.Vulnerabilities()
-		want := map[span.URI]*govulncheck.Result{
-			file1: vuln1,
-			file2: vuln2,
-		}
-
-		if diff := cmp.Diff(toJSON(want), toJSON(got)); diff != "" {
-			t.Errorf("view.Vulnerabilities() mismatch (-want +got):\n%s", diff)
-		}
-	})
-
-	// maxGovulncheckResultAge/2 later
-	timeNow = func() time.Time { return now.Add(maxGovulncheckResultAge / 2) }
-	t.Run("after30min", func(t *testing.T) {
-		got := view.Vulnerabilities()
-		want := map[span.URI]*govulncheck.Result{
-			file1: nil, // expired.
-			file2: vuln2,
-		}
-
-		if diff := cmp.Diff(toJSON(want), toJSON(got)); diff != "" {
-			t.Errorf("view.Vulnerabilities() mismatch (-want +got):\n%s", diff)
-		}
-	})
-
-	// maxGovulncheckResultAge later
-	timeNow = func() time.Time { return now.Add(maxGovulncheckResultAge + time.Minute) }
-
-	t.Run("after1hr", func(t *testing.T) {
-		got := view.Vulnerabilities()
-		want := map[span.URI]*govulncheck.Result{
-			file1: nil,
-			file2: nil,
-		}
-
-		if diff := cmp.Diff(toJSON(want), toJSON(got)); diff != "" {
-			t.Errorf("view.Vulnerabilities() mismatch (-want +got):\n%s", diff)
-		}
-	})
-}
-
-func toJSON(x interface{}) string {
-	b, _ := json.MarshalIndent(x, "", " ")
-	return string(b)
-}
diff -urN a/gopls/internal/lsp/cache/workspace.go b/gopls/internal/lsp/cache/workspace.go
--- a/gopls/internal/lsp/cache/workspace.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/workspace.go	1969-12-31 16:00:00
@@ -1,647 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"os"
-	"path/filepath"
-	"sort"
-	"strings"
-	"sync"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// workspaceSource reports how the set of active modules has been derived.
-type workspaceSource int
-
-const (
-	legacyWorkspace     = iota // non-module or single module mode
-	goplsModWorkspace          // modules provided by a gopls.mod file
-	goWorkWorkspace            // modules provided by a go.work file
-	fileSystemWorkspace        // modules found by walking the filesystem
-)
-
-func (s workspaceSource) String() string {
-	switch s {
-	case legacyWorkspace:
-		return "legacy"
-	case goplsModWorkspace:
-		return "gopls.mod"
-	case goWorkWorkspace:
-		return "go.work"
-	case fileSystemWorkspace:
-		return "file system"
-	default:
-		return "!(unknown module source)"
-	}
-}
-
-// workspaceCommon holds immutable information about the workspace setup.
-//
-// TODO(rfindley): there is some redundancy here with workspaceInformation.
-// Reconcile these two types.
-type workspaceCommon struct {
-	root        span.URI
-	excludePath func(string) bool
-
-	// explicitGowork is, if non-empty, the URI for the explicit go.work file
-	// provided via the user's environment.
-	explicitGowork span.URI
-}
-
-// workspace tracks go.mod files in the workspace, along with the
-// gopls.mod file, to provide support for multi-module workspaces.
-//
-// Specifically, it provides:
-//   - the set of modules contained within in the workspace root considered to
-//     be 'active'
-//   - the workspace modfile, to be used for the go command `-modfile` flag
-//   - the set of workspace directories
-//
-// This type is immutable (or rather, idempotent), so that it may be shared
-// across multiple snapshots.
-type workspace struct {
-	workspaceCommon
-
-	// The source of modules in this workspace.
-	moduleSource workspaceSource
-
-	// activeModFiles holds the active go.mod files.
-	activeModFiles map[span.URI]struct{}
-
-	// knownModFiles holds the set of all go.mod files in the workspace.
-	// In all modes except for legacy, this is equivalent to modFiles.
-	knownModFiles map[span.URI]struct{}
-
-	// workFile, if nonEmpty, is the go.work file for the workspace.
-	workFile span.URI
-
-	// The workspace module is lazily re-built once after being invalidated.
-	// buildMu+built guards this reconstruction.
-	//
-	// file and wsDirs may be non-nil even if built == false, if they were copied
-	// from the previous workspace module version. In this case, they will be
-	// preserved if building fails.
-	buildMu  sync.Mutex
-	built    bool
-	buildErr error
-	mod      *modfile.File
-	sum      []byte
-	wsDirs   map[span.URI]struct{}
-}
-
-// newWorkspace creates a new workspace at the given root directory,
-// determining its module source based on the presence of a gopls.mod or
-// go.work file, and the go111moduleOff and useWsModule settings.
-//
-// If useWsModule is set, the workspace may use a synthetic mod file replacing
-// all modules in the root.
-//
-// If there is no active workspace file (a gopls.mod or go.work), newWorkspace
-// scans the filesystem to find modules.
-//
-// TODO(rfindley): newWorkspace should perhaps never fail, relying instead on
-// the criticalError method to surface problems in the workspace.
-func newWorkspace(ctx context.Context, root, explicitGowork span.URI, fs source.FileSource, excludePath func(string) bool, go111moduleOff, useWsModule bool) (*workspace, error) {
-	ws := &workspace{
-		workspaceCommon: workspaceCommon{
-			root:           root,
-			explicitGowork: explicitGowork,
-			excludePath:    excludePath,
-		},
-	}
-
-	// The user may have a gopls.mod or go.work file that defines their
-	// workspace.
-	//
-	// TODO(rfindley): if GO111MODULE=off, this looks wrong, though there are
-	// probably other problems.
-	if err := ws.loadExplicitWorkspaceFile(ctx, fs); err == nil {
-		return ws, nil
-	}
-
-	// Otherwise, in all other modes, search for all of the go.mod files in the
-	// workspace.
-	knownModFiles, err := findModules(root, excludePath, 0)
-	if err != nil {
-		return nil, err
-	}
-	ws.knownModFiles = knownModFiles
-
-	switch {
-	case go111moduleOff:
-		ws.moduleSource = legacyWorkspace
-	case useWsModule:
-		ws.activeModFiles = knownModFiles
-		ws.moduleSource = fileSystemWorkspace
-	default:
-		ws.moduleSource = legacyWorkspace
-		activeModFiles, err := getLegacyModules(ctx, root, fs)
-		if err != nil {
-			return nil, err
-		}
-		ws.activeModFiles = activeModFiles
-	}
-	return ws, nil
-}
-
-// loadExplicitWorkspaceFile loads workspace information from go.work or
-// gopls.mod files, setting the active modules, mod file, and module source
-// accordingly.
-func (ws *workspace) loadExplicitWorkspaceFile(ctx context.Context, fs source.FileSource) error {
-	for _, src := range []workspaceSource{goWorkWorkspace, goplsModWorkspace} {
-		fh, err := fs.GetFile(ctx, uriForSource(ws.root, ws.explicitGowork, src))
-		if err != nil {
-			return err
-		}
-		contents, err := fh.Read()
-		if err != nil {
-			continue // TODO(rfindley): is it correct to proceed here?
-		}
-		var file *modfile.File
-		var activeModFiles map[span.URI]struct{}
-		switch src {
-		case goWorkWorkspace:
-			file, activeModFiles, err = parseGoWork(ctx, ws.root, fh.URI(), contents, fs)
-			ws.workFile = fh.URI()
-		case goplsModWorkspace:
-			file, activeModFiles, err = parseGoplsMod(ws.root, fh.URI(), contents)
-		}
-		if err != nil {
-			ws.buildMu.Lock()
-			ws.built = true
-			ws.buildErr = err
-			ws.buildMu.Unlock()
-		}
-		ws.mod = file
-		ws.activeModFiles = activeModFiles
-		ws.moduleSource = src
-		return nil
-	}
-	return noHardcodedWorkspace
-}
-
-var noHardcodedWorkspace = errors.New("no hardcoded workspace")
-
-// TODO(rfindley): eliminate getKnownModFiles.
-func (w *workspace) getKnownModFiles() map[span.URI]struct{} {
-	return w.knownModFiles
-}
-
-// ActiveModFiles returns the set of active mod files for the current workspace.
-func (w *workspace) ActiveModFiles() map[span.URI]struct{} {
-	return w.activeModFiles
-}
-
-// criticalError returns a critical error related to the workspace setup.
-func (w *workspace) criticalError(ctx context.Context, fs source.FileSource) (res *source.CriticalError) {
-	// For now, we narrowly report errors related to `go.work` files.
-	//
-	// TODO(rfindley): investigate whether other workspace validation errors
-	// can be consolidated here.
-	if w.moduleSource == goWorkWorkspace {
-		// We should have already built the modfile, but build here to be
-		// consistent about accessing w.mod after w.build.
-		//
-		// TODO(rfindley): build eagerly. Building lazily is a premature
-		// optimization that poses a significant burden on the code.
-		w.build(ctx, fs)
-		if w.buildErr != nil {
-			return &source.CriticalError{
-				MainError: w.buildErr,
-			}
-		}
-	}
-	return nil
-}
-
-// modFile gets the workspace modfile associated with this workspace,
-// computing it if it doesn't exist.
-//
-// A fileSource must be passed in to solve a chicken-egg problem: it is not
-// correct to pass in the snapshot file source to newWorkspace when
-// invalidating, because at the time these are called the snapshot is locked.
-// So we must pass it in later on when actually using the modFile.
-func (w *workspace) modFile(ctx context.Context, fs source.FileSource) (*modfile.File, error) {
-	w.build(ctx, fs)
-	return w.mod, w.buildErr
-}
-
-func (w *workspace) sumFile(ctx context.Context, fs source.FileSource) ([]byte, error) {
-	w.build(ctx, fs)
-	return w.sum, w.buildErr
-}
-
-func (w *workspace) build(ctx context.Context, fs source.FileSource) {
-	w.buildMu.Lock()
-	defer w.buildMu.Unlock()
-
-	if w.built {
-		return
-	}
-	// Building should never be cancelled. Since the workspace module is shared
-	// across multiple snapshots, doing so would put us in a bad state, and it
-	// would not be obvious to the user how to recover.
-	ctx = xcontext.Detach(ctx)
-
-	// If the module source is from the filesystem, try to build the workspace
-	// module from active modules discovered by scanning the filesystem. Fall
-	// back on the pre-existing mod file if parsing fails.
-	if w.moduleSource == fileSystemWorkspace {
-		file, err := buildWorkspaceModFile(ctx, w.activeModFiles, fs)
-		switch {
-		case err == nil:
-			w.mod = file
-		case w.mod != nil:
-			// Parsing failed, but we have a previous file version.
-			event.Error(ctx, "building workspace mod file", err)
-		default:
-			// No file to fall back on.
-			w.buildErr = err
-		}
-	}
-
-	if w.mod != nil {
-		w.wsDirs = map[span.URI]struct{}{
-			w.root: {},
-		}
-		for _, r := range w.mod.Replace {
-			// We may be replacing a module with a different version, not a path
-			// on disk.
-			if r.New.Version != "" {
-				continue
-			}
-			w.wsDirs[span.URIFromPath(r.New.Path)] = struct{}{}
-		}
-	}
-
-	// Ensure that there is always at least the root dir.
-	if len(w.wsDirs) == 0 {
-		w.wsDirs = map[span.URI]struct{}{
-			w.root: {},
-		}
-	}
-
-	sum, err := buildWorkspaceSumFile(ctx, w.activeModFiles, fs)
-	if err == nil {
-		w.sum = sum
-	} else {
-		event.Error(ctx, "building workspace sum file", err)
-	}
-
-	w.built = true
-}
-
-// dirs returns the workspace directories for the loaded modules.
-func (w *workspace) dirs(ctx context.Context, fs source.FileSource) []span.URI {
-	w.build(ctx, fs)
-	var dirs []span.URI
-	for d := range w.wsDirs {
-		dirs = append(dirs, d)
-	}
-	sort.Slice(dirs, func(i, j int) bool { return dirs[i] < dirs[j] })
-	return dirs
-}
-
-// Clone returns a (possibly) new workspace after invalidating the changed
-// files. If w is still valid in the presence of changedURIs, it returns itself
-// unmodified.
-//
-// The returned needReinit flag indicates to the caller that the workspace
-// needs to be reinitialized (because a relevant go.mod or go.work file has
-// been changed).
-//
-// TODO(rfindley): it looks wrong that we return 'needReinit' here. The caller
-// should determine whether to re-initialize..
-func (w *workspace) Clone(ctx context.Context, changes map[span.URI]*fileChange, fs source.FileSource) (_ *workspace, needReinit bool) {
-	// Prevent races to w.modFile or w.wsDirs below, if w has not yet been built.
-	w.buildMu.Lock()
-	defer w.buildMu.Unlock()
-
-	// Clone the workspace. This may be discarded if nothing changed.
-	changed := false
-	result := &workspace{
-		workspaceCommon: w.workspaceCommon,
-		moduleSource:    w.moduleSource,
-		knownModFiles:   make(map[span.URI]struct{}),
-		activeModFiles:  make(map[span.URI]struct{}),
-		workFile:        w.workFile,
-		mod:             w.mod,
-		sum:             w.sum,
-		wsDirs:          w.wsDirs,
-	}
-	for k, v := range w.knownModFiles {
-		result.knownModFiles[k] = v
-	}
-	for k, v := range w.activeModFiles {
-		result.activeModFiles[k] = v
-	}
-
-	equalURI := func(a, b span.URI) (r bool) {
-		// This query is a strange mix of syntax and file system state:
-		// deletion of a file causes a false result if the name doesn't change.
-		// Our tests exercise only the first clause.
-		return a == b || span.SameExistingFile(a, b)
-	}
-
-	// First handle changes to the go.work or gopls.mod file. This must be
-	// considered before any changes to go.mod or go.sum files, as these files
-	// determine which modules we care about. If go.work/gopls.mod has changed
-	// we need to either re-read it if it exists or walk the filesystem if it
-	// has been deleted. go.work should override the gopls.mod if both exist.
-	changed, needReinit = handleWorkspaceFileChanges(ctx, result, changes, fs)
-	// Next, handle go.mod changes that could affect our workspace.
-	for uri, change := range changes {
-		// Otherwise, we only care about go.mod files in the workspace directory.
-		if change.isUnchanged || !isGoMod(uri) || !source.InDir(result.root.Filename(), uri.Filename()) {
-			continue
-		}
-		changed = true
-		active := result.moduleSource != legacyWorkspace || equalURI(modURI(w.root), uri)
-		needReinit = needReinit || (active && change.fileHandle.Saved())
-		// Don't mess with the list of mod files if using go.work or gopls.mod.
-		if result.moduleSource == goplsModWorkspace || result.moduleSource == goWorkWorkspace {
-			continue
-		}
-		if change.exists {
-			result.knownModFiles[uri] = struct{}{}
-			if active {
-				result.activeModFiles[uri] = struct{}{}
-			}
-		} else {
-			delete(result.knownModFiles, uri)
-			delete(result.activeModFiles, uri)
-		}
-	}
-
-	// Finally, process go.sum changes for any modules that are now active.
-	for uri, change := range changes {
-		if !isGoSum(uri) {
-			continue
-		}
-		// TODO(rFindley) factor out this URI mangling.
-		dir := filepath.Dir(uri.Filename())
-		modURI := span.URIFromPath(filepath.Join(dir, "go.mod"))
-		if _, active := result.activeModFiles[modURI]; !active {
-			continue
-		}
-		// Only changes to active go.sum files actually cause the workspace to
-		// change.
-		changed = true
-		needReinit = needReinit || change.fileHandle.Saved()
-	}
-
-	if !changed {
-		return w, false
-	}
-
-	return result, needReinit
-}
-
-// handleWorkspaceFileChanges handles changes related to a go.work or gopls.mod
-// file, updating ws accordingly. ws.root must be set.
-func handleWorkspaceFileChanges(ctx context.Context, ws *workspace, changes map[span.URI]*fileChange, fs source.FileSource) (changed, reload bool) {
-	if ws.moduleSource != goWorkWorkspace && ws.moduleSource != goplsModWorkspace {
-		return false, false
-	}
-
-	uri := uriForSource(ws.root, ws.explicitGowork, ws.moduleSource)
-	// File opens/closes are just no-ops.
-	change, ok := changes[uri]
-	if !ok || change.isUnchanged {
-		return false, false
-	}
-	if change.exists {
-		// Only invalidate if the file if it actually parses.
-		// Otherwise, stick with the current file.
-		var parsedFile *modfile.File
-		var parsedModules map[span.URI]struct{}
-		var err error
-		switch ws.moduleSource {
-		case goWorkWorkspace:
-			parsedFile, parsedModules, err = parseGoWork(ctx, ws.root, uri, change.content, fs)
-		case goplsModWorkspace:
-			parsedFile, parsedModules, err = parseGoplsMod(ws.root, uri, change.content)
-		}
-		if err != nil {
-			// An unparseable file should not invalidate the workspace:
-			// nothing good could come from changing the workspace in
-			// this case.
-			//
-			// TODO(rfindley): well actually, it could potentially lead to a better
-			// critical error. Evaluate whether we can unify this case with the
-			// error returned by newWorkspace, without needlessly invalidating
-			// metadata.
-			event.Error(ctx, fmt.Sprintf("parsing %s", filepath.Base(uri.Filename())), err)
-		} else {
-			// only update the modfile if it parsed.
-			changed = true
-			reload = change.fileHandle.Saved()
-			ws.mod = parsedFile
-			ws.knownModFiles = parsedModules
-			ws.activeModFiles = make(map[span.URI]struct{})
-			for k, v := range parsedModules {
-				ws.activeModFiles[k] = v
-			}
-		}
-		return changed, reload
-	}
-	// go.work/gopls.mod is deleted. We should never see this as the view should have been recreated.
-	panic(fmt.Sprintf("internal error: workspace file %q deleted without reinitialization", uri))
-}
-
-// goplsModURI returns the URI for the gopls.mod file contained in root.
-func uriForSource(root, explicitGowork span.URI, src workspaceSource) span.URI {
-	var basename string
-	switch src {
-	case goplsModWorkspace:
-		basename = "gopls.mod"
-	case goWorkWorkspace:
-		if explicitGowork != "" {
-			return explicitGowork
-		}
-		basename = "go.work"
-	default:
-		return ""
-	}
-	return span.URIFromPath(filepath.Join(root.Filename(), basename))
-}
-
-// modURI returns the URI for the go.mod file contained in root.
-func modURI(root span.URI) span.URI {
-	return span.URIFromPath(filepath.Join(root.Filename(), "go.mod"))
-}
-
-// isGoMod reports if uri is a go.mod file.
-func isGoMod(uri span.URI) bool {
-	return filepath.Base(uri.Filename()) == "go.mod"
-}
-
-// isGoWork reports if uri is a go.work file.
-func isGoWork(uri span.URI) bool {
-	return filepath.Base(uri.Filename()) == "go.work"
-}
-
-// isGoSum reports if uri is a go.sum or go.work.sum file.
-func isGoSum(uri span.URI) bool {
-	return filepath.Base(uri.Filename()) == "go.sum" || filepath.Base(uri.Filename()) == "go.work.sum"
-}
-
-// fileExists reports if the file uri exists within source.
-func fileExists(ctx context.Context, uri span.URI, source source.FileSource) (bool, error) {
-	fh, err := source.GetFile(ctx, uri)
-	if err != nil {
-		return false, err
-	}
-	return fileHandleExists(fh)
-}
-
-// fileHandleExists reports if the file underlying fh actually exits.
-func fileHandleExists(fh source.FileHandle) (bool, error) {
-	_, err := fh.Read()
-	if err == nil {
-		return true, nil
-	}
-	if os.IsNotExist(err) {
-		return false, nil
-	}
-	return false, err
-}
-
-// getLegacyModules returns a module set containing at most the root module.
-func getLegacyModules(ctx context.Context, root span.URI, fs source.FileSource) (map[span.URI]struct{}, error) {
-	uri := span.URIFromPath(filepath.Join(root.Filename(), "go.mod"))
-	modules := make(map[span.URI]struct{})
-	exists, err := fileExists(ctx, uri, fs)
-	if err != nil {
-		return nil, err
-	}
-	if exists {
-		modules[uri] = struct{}{}
-	}
-	return modules, nil
-}
-
-func parseGoWork(ctx context.Context, root, uri span.URI, contents []byte, fs source.FileSource) (*modfile.File, map[span.URI]struct{}, error) {
-	workFile, err := modfile.ParseWork(uri.Filename(), contents, nil)
-	if err != nil {
-		return nil, nil, fmt.Errorf("parsing go.work: %w", err)
-	}
-	modFiles := make(map[span.URI]struct{})
-	for _, dir := range workFile.Use {
-		// The resulting modfile must use absolute paths, so that it can be
-		// written to a temp directory.
-		dir.Path = absolutePath(root, dir.Path)
-		modURI := span.URIFromPath(filepath.Join(dir.Path, "go.mod"))
-		modFiles[modURI] = struct{}{}
-	}
-
-	// TODO(rfindley): we should either not build the workspace modfile here, or
-	// not fail so hard. A failure in building the workspace modfile should not
-	// invalidate the active module paths extracted above.
-	modFile, err := buildWorkspaceModFile(ctx, modFiles, fs)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	// Require a go directive, per the spec.
-	if workFile.Go == nil || workFile.Go.Version == "" {
-		return nil, nil, fmt.Errorf("go.work has missing or incomplete go directive")
-	}
-	if err := modFile.AddGoStmt(workFile.Go.Version); err != nil {
-		return nil, nil, err
-	}
-
-	return modFile, modFiles, nil
-}
-
-func parseGoplsMod(root, uri span.URI, contents []byte) (*modfile.File, map[span.URI]struct{}, error) {
-	modFile, err := modfile.Parse(uri.Filename(), contents, nil)
-	if err != nil {
-		return nil, nil, fmt.Errorf("parsing gopls.mod: %w", err)
-	}
-	modFiles := make(map[span.URI]struct{})
-	for _, replace := range modFile.Replace {
-		if replace.New.Version != "" {
-			return nil, nil, fmt.Errorf("gopls.mod: replaced module %q@%q must not have version", replace.New.Path, replace.New.Version)
-		}
-		// The resulting modfile must use absolute paths, so that it can be
-		// written to a temp directory.
-		replace.New.Path = absolutePath(root, replace.New.Path)
-		modURI := span.URIFromPath(filepath.Join(replace.New.Path, "go.mod"))
-		modFiles[modURI] = struct{}{}
-	}
-	return modFile, modFiles, nil
-}
-
-func absolutePath(root span.URI, path string) string {
-	dirFP := filepath.FromSlash(path)
-	if !filepath.IsAbs(dirFP) {
-		dirFP = filepath.Join(root.Filename(), dirFP)
-	}
-	return dirFP
-}
-
-// errExhausted is returned by findModules if the file scan limit is reached.
-var errExhausted = errors.New("exhausted")
-
-// Limit go.mod search to 1 million files. As a point of reference,
-// Kubernetes has 22K files (as of 2020-11-24).
-const fileLimit = 1000000
-
-// findModules recursively walks the root directory looking for go.mod files,
-// returning the set of modules it discovers. If modLimit is non-zero,
-// searching stops once modLimit modules have been found.
-//
-// TODO(rfindley): consider overlays.
-func findModules(root span.URI, excludePath func(string) bool, modLimit int) (map[span.URI]struct{}, error) {
-	// Walk the view's folder to find all modules in the view.
-	modFiles := make(map[span.URI]struct{})
-	searched := 0
-	errDone := errors.New("done")
-	err := filepath.Walk(root.Filename(), func(path string, info os.FileInfo, err error) error {
-		if err != nil {
-			// Probably a permission error. Keep looking.
-			return filepath.SkipDir
-		}
-		// For any path that is not the workspace folder, check if the path
-		// would be ignored by the go command. Vendor directories also do not
-		// contain workspace modules.
-		if info.IsDir() && path != root.Filename() {
-			suffix := strings.TrimPrefix(path, root.Filename())
-			switch {
-			case checkIgnored(suffix),
-				strings.Contains(filepath.ToSlash(suffix), "/vendor/"),
-				excludePath(suffix):
-				return filepath.SkipDir
-			}
-		}
-		// We're only interested in go.mod files.
-		uri := span.URIFromPath(path)
-		if isGoMod(uri) {
-			modFiles[uri] = struct{}{}
-		}
-		if modLimit > 0 && len(modFiles) >= modLimit {
-			return errDone
-		}
-		searched++
-		if fileLimit > 0 && searched >= fileLimit {
-			return errExhausted
-		}
-		return nil
-	})
-	if err == errDone {
-		return modFiles, nil
-	}
-	return modFiles, err
-}
diff -urN a/gopls/internal/lsp/cache/workspace_test.go b/gopls/internal/lsp/cache/workspace_test.go
--- a/gopls/internal/lsp/cache/workspace_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cache/workspace_test.go	1969-12-31 16:00:00
@@ -1,366 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cache
-
-import (
-	"context"
-	"errors"
-	"os"
-	"strings"
-	"testing"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// osFileSource is a fileSource that just reads from the operating system.
-type osFileSource struct {
-	overlays map[span.URI]fakeOverlay
-}
-
-type fakeOverlay struct {
-	source.VersionedFileHandle
-	uri     span.URI
-	content string
-	err     error
-	saved   bool
-}
-
-func (o fakeOverlay) Saved() bool { return o.saved }
-
-func (o fakeOverlay) Read() ([]byte, error) {
-	if o.err != nil {
-		return nil, o.err
-	}
-	return []byte(o.content), nil
-}
-
-func (o fakeOverlay) URI() span.URI {
-	return o.uri
-}
-
-// change updates the file source with the given file content. For convenience,
-// empty content signals a deletion. If saved is true, these changes are
-// persisted to disk.
-func (s *osFileSource) change(ctx context.Context, uri span.URI, content string, saved bool) (*fileChange, error) {
-	if content == "" {
-		delete(s.overlays, uri)
-		if saved {
-			if err := os.Remove(uri.Filename()); err != nil {
-				return nil, err
-			}
-		}
-		fh, err := s.GetFile(ctx, uri)
-		if err != nil {
-			return nil, err
-		}
-		data, err := fh.Read()
-		return &fileChange{exists: err == nil, content: data, fileHandle: &closedFile{fh}}, nil
-	}
-	if s.overlays == nil {
-		s.overlays = map[span.URI]fakeOverlay{}
-	}
-	s.overlays[uri] = fakeOverlay{uri: uri, content: content, saved: saved}
-	return &fileChange{
-		exists:     content != "",
-		content:    []byte(content),
-		fileHandle: s.overlays[uri],
-	}, nil
-}
-
-func (s *osFileSource) GetFile(ctx context.Context, uri span.URI) (source.FileHandle, error) {
-	if overlay, ok := s.overlays[uri]; ok {
-		return overlay, nil
-	}
-	fi, statErr := os.Stat(uri.Filename())
-	if statErr != nil {
-		return &fileHandle{
-			err: statErr,
-			uri: uri,
-		}, nil
-	}
-	fh, err := readFile(ctx, uri, fi)
-	if err != nil {
-		return nil, err
-	}
-	return fh, nil
-}
-
-type wsState struct {
-	source  workspaceSource
-	modules []string
-	dirs    []string
-	sum     string
-}
-
-type wsChange struct {
-	content string
-	saved   bool
-}
-
-func TestWorkspaceModule(t *testing.T) {
-	tests := []struct {
-		desc         string
-		initial      string // txtar-encoded
-		legacyMode   bool
-		initialState wsState
-		updates      map[string]wsChange
-		wantChanged  bool
-		wantReload   bool
-		finalState   wsState
-	}{
-		{
-			desc: "legacy mode",
-			initial: `
--- go.mod --
-module mod.com
--- go.sum --
-golang.org/x/mod v0.3.0 h1:deadbeef
--- a/go.mod --
-module moda.com`,
-			legacyMode: true,
-			initialState: wsState{
-				modules: []string{"./go.mod"},
-				source:  legacyWorkspace,
-				dirs:    []string{"."},
-				sum:     "golang.org/x/mod v0.3.0 h1:deadbeef\n",
-			},
-		},
-		{
-			desc: "nested module",
-			initial: `
--- go.mod --
-module mod.com
--- a/go.mod --
-module moda.com`,
-			initialState: wsState{
-				modules: []string{"./go.mod", "a/go.mod"},
-				source:  fileSystemWorkspace,
-				dirs:    []string{".", "a"},
-			},
-		},
-		{
-			desc: "adding module",
-			initial: `
--- gopls.mod --
-require moda.com v0.0.0-goplsworkspace
-replace moda.com => $SANDBOX_WORKDIR/a
--- a/go.mod --
-module moda.com
--- b/go.mod --
-module modb.com`,
-			initialState: wsState{
-				modules: []string{"a/go.mod"},
-				source:  goplsModWorkspace,
-				dirs:    []string{".", "a"},
-			},
-			updates: map[string]wsChange{
-				"gopls.mod": {`module gopls-workspace
-
-require moda.com v0.0.0-goplsworkspace
-require modb.com v0.0.0-goplsworkspace
-
-replace moda.com => $SANDBOX_WORKDIR/a
-replace modb.com => $SANDBOX_WORKDIR/b`, true},
-			},
-			wantChanged: true,
-			wantReload:  true,
-			finalState: wsState{
-				modules: []string{"a/go.mod", "b/go.mod"},
-				source:  goplsModWorkspace,
-				dirs:    []string{".", "a", "b"},
-			},
-		},
-		{
-			desc: "broken module parsing",
-			initial: `
--- a/go.mod --
-module moda.com
-
-require gopls.test v0.0.0-goplsworkspace
-replace gopls.test => ../../gopls.test // (this path shouldn't matter)
--- b/go.mod --
-module modb.com`,
-			initialState: wsState{
-				modules: []string{"a/go.mod", "b/go.mod"},
-				source:  fileSystemWorkspace,
-				dirs:    []string{".", "a", "b", "../gopls.test"},
-			},
-			updates: map[string]wsChange{
-				"a/go.mod": {`modul moda.com
-
-require gopls.test v0.0.0-goplsworkspace
-replace gopls.test => ../../gopls.test2`, false},
-			},
-			wantChanged: true,
-			wantReload:  false,
-			finalState: wsState{
-				modules: []string{"a/go.mod", "b/go.mod"},
-				source:  fileSystemWorkspace,
-				// finalDirs should be unchanged: we should preserve dirs in the presence
-				// of a broken modfile.
-				dirs: []string{".", "a", "b", "../gopls.test"},
-			},
-		},
-	}
-
-	for _, test := range tests {
-		t.Run(test.desc, func(t *testing.T) {
-			ctx := context.Background()
-			dir, err := fake.Tempdir(fake.UnpackTxt(test.initial))
-			if err != nil {
-				t.Fatal(err)
-			}
-			defer os.RemoveAll(dir)
-			root := span.URIFromPath(dir)
-
-			fs := &osFileSource{}
-			excludeNothing := func(string) bool { return false }
-			w, err := newWorkspace(ctx, root, "", fs, excludeNothing, false, !test.legacyMode)
-			if err != nil {
-				t.Fatal(err)
-			}
-			rel := fake.RelativeTo(dir)
-			checkState(ctx, t, fs, rel, w, test.initialState)
-
-			// Apply updates.
-			if test.updates != nil {
-				changes := make(map[span.URI]*fileChange)
-				for k, v := range test.updates {
-					content := strings.ReplaceAll(v.content, "$SANDBOX_WORKDIR", string(rel))
-					uri := span.URIFromPath(rel.AbsPath(k))
-					changes[uri], err = fs.change(ctx, uri, content, v.saved)
-					if err != nil {
-						t.Fatal(err)
-					}
-				}
-				got, gotReinit := w.Clone(ctx, changes, fs)
-				gotChanged := got != w
-				if gotChanged != test.wantChanged {
-					t.Errorf("w.invalidate(): got changed %t, want %t", gotChanged, test.wantChanged)
-				}
-				if gotReinit != test.wantReload {
-					t.Errorf("w.invalidate(): got reload %t, want %t", gotReinit, test.wantReload)
-				}
-				checkState(ctx, t, fs, rel, got, test.finalState)
-			}
-		})
-	}
-}
-
-func workspaceFromTxtar(t *testing.T, files string) (*workspace, func(), error) {
-	ctx := context.Background()
-	dir, err := fake.Tempdir(fake.UnpackTxt(files))
-	if err != nil {
-		return nil, func() {}, err
-	}
-	cleanup := func() {
-		os.RemoveAll(dir)
-	}
-	root := span.URIFromPath(dir)
-
-	fs := &osFileSource{}
-	excludeNothing := func(string) bool { return false }
-	workspace, err := newWorkspace(ctx, root, "", fs, excludeNothing, false, false)
-	return workspace, cleanup, err
-}
-
-func TestWorkspaceParseError(t *testing.T) {
-	w, cleanup, err := workspaceFromTxtar(t, `
--- go.work --
-go 1.18
-
-usa ./typo
--- typo/go.mod --
-module foo
-`)
-	defer cleanup()
-	if err != nil {
-		t.Fatalf("error creating workspace: %v; want no error", err)
-	}
-	w.buildMu.Lock()
-	built, buildErr := w.built, w.buildErr
-	w.buildMu.Unlock()
-	if !built || buildErr == nil {
-		t.Fatalf("built, buildErr: got %v, %v; want true, non-nil", built, buildErr)
-	}
-	var errList modfile.ErrorList
-	if !errors.As(buildErr, &errList) {
-		t.Fatalf("expected error to be an errorlist; got %v", buildErr)
-	}
-	if len(errList) != 1 {
-		t.Fatalf("expected errorList to have one element; got %v elements", len(errList))
-	}
-	parseErr := errList[0]
-	if parseErr.Pos.Line != 3 {
-		t.Fatalf("expected error to be on line 3; got %v", parseErr.Pos.Line)
-	}
-}
-
-func TestWorkspaceMissingModFile(t *testing.T) {
-	w, cleanup, err := workspaceFromTxtar(t, `
--- go.work --
-go 1.18
-
-use ./missing
-`)
-	defer cleanup()
-	if err != nil {
-		t.Fatalf("error creating workspace: %v; want no error", err)
-	}
-	w.buildMu.Lock()
-	built, buildErr := w.built, w.buildErr
-	w.buildMu.Unlock()
-	if !built || buildErr == nil {
-		t.Fatalf("built, buildErr: got %v, %v; want true, non-nil", built, buildErr)
-	}
-}
-
-func checkState(ctx context.Context, t *testing.T, fs source.FileSource, rel fake.RelativeTo, got *workspace, want wsState) {
-	t.Helper()
-	if got.moduleSource != want.source {
-		t.Errorf("module source = %v, want %v", got.moduleSource, want.source)
-	}
-	modules := make(map[span.URI]struct{})
-	for k := range got.ActiveModFiles() {
-		modules[k] = struct{}{}
-	}
-	for _, modPath := range want.modules {
-		path := rel.AbsPath(modPath)
-		uri := span.URIFromPath(path)
-		if _, ok := modules[uri]; !ok {
-			t.Errorf("missing module %q", uri)
-		}
-		delete(modules, uri)
-	}
-	for remaining := range modules {
-		t.Errorf("unexpected module %q", remaining)
-	}
-	gotDirs := got.dirs(ctx, fs)
-	gotM := make(map[span.URI]bool)
-	for _, dir := range gotDirs {
-		gotM[dir] = true
-	}
-	for _, dir := range want.dirs {
-		path := rel.AbsPath(dir)
-		uri := span.URIFromPath(path)
-		if !gotM[uri] {
-			t.Errorf("missing dir %q", uri)
-		}
-		delete(gotM, uri)
-	}
-	for remaining := range gotM {
-		t.Errorf("unexpected dir %q", remaining)
-	}
-	gotSumBytes, err := got.sumFile(ctx, fs)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if gotSum := string(gotSumBytes); gotSum != want.sum {
-		t.Errorf("got final sum %q, want %q", gotSum, want.sum)
-	}
-}
diff -urN a/gopls/internal/lsp/call_hierarchy.go b/gopls/internal/lsp/call_hierarchy.go
--- a/gopls/internal/lsp/call_hierarchy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/call_hierarchy.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func (s *Server) prepareCallHierarchy(ctx context.Context, params *protocol.CallHierarchyPrepareParams) ([]protocol.CallHierarchyItem, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-
-	return source.PrepareCallHierarchy(ctx, snapshot, fh, params.Position)
-}
-
-func (s *Server) incomingCalls(ctx context.Context, params *protocol.CallHierarchyIncomingCallsParams) ([]protocol.CallHierarchyIncomingCall, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.Item.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-
-	return source.IncomingCalls(ctx, snapshot, fh, params.Item.Range.Start)
-}
-
-func (s *Server) outgoingCalls(ctx context.Context, params *protocol.CallHierarchyOutgoingCallsParams) ([]protocol.CallHierarchyOutgoingCall, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.Item.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-
-	return source.OutgoingCalls(ctx, snapshot, fh, params.Item.Range.Start)
-}
diff -urN a/gopls/internal/lsp/cmd/call_hierarchy.go b/gopls/internal/lsp/cmd/call_hierarchy.go
--- a/gopls/internal/lsp/cmd/call_hierarchy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/call_hierarchy.go	1969-12-31 16:00:00
@@ -1,146 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// callHierarchy implements the callHierarchy verb for gopls.
-type callHierarchy struct {
-	app *Application
-}
-
-func (c *callHierarchy) Name() string      { return "call_hierarchy" }
-func (c *callHierarchy) Parent() string    { return c.app.Name() }
-func (c *callHierarchy) Usage() string     { return "<position>" }
-func (c *callHierarchy) ShortHelp() string { return "display selected identifier's call hierarchy" }
-func (c *callHierarchy) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls call_hierarchy helper/helper.go:8:6
-	$ gopls call_hierarchy helper/helper.go:#53
-`)
-	printFlagDefaults(f)
-}
-
-func (c *callHierarchy) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("call_hierarchy expects 1 argument (position)")
-	}
-
-	conn, err := c.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-
-	p := protocol.CallHierarchyPrepareParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-			Position:     loc.Range.Start,
-		},
-	}
-
-	callItems, err := conn.PrepareCallHierarchy(ctx, &p)
-	if err != nil {
-		return err
-	}
-	if len(callItems) == 0 {
-		return fmt.Errorf("function declaration identifier not found at %v", args[0])
-	}
-
-	for _, item := range callItems {
-		incomingCalls, err := conn.IncomingCalls(ctx, &protocol.CallHierarchyIncomingCallsParams{Item: item})
-		if err != nil {
-			return err
-		}
-		for i, call := range incomingCalls {
-			// From the spec: CallHierarchyIncomingCall.FromRanges is relative to
-			// the caller denoted by CallHierarchyIncomingCall.from.
-			printString, err := callItemPrintString(ctx, conn, call.From, call.From.URI, call.FromRanges)
-			if err != nil {
-				return err
-			}
-			fmt.Printf("caller[%d]: %s\n", i, printString)
-		}
-
-		printString, err := callItemPrintString(ctx, conn, item, "", nil)
-		if err != nil {
-			return err
-		}
-		fmt.Printf("identifier: %s\n", printString)
-
-		outgoingCalls, err := conn.OutgoingCalls(ctx, &protocol.CallHierarchyOutgoingCallsParams{Item: item})
-		if err != nil {
-			return err
-		}
-		for i, call := range outgoingCalls {
-			// From the spec: CallHierarchyOutgoingCall.FromRanges is the range
-			// relative to the caller, e.g the item passed to
-			printString, err := callItemPrintString(ctx, conn, call.To, item.URI, call.FromRanges)
-			if err != nil {
-				return err
-			}
-			fmt.Printf("callee[%d]: %s\n", i, printString)
-		}
-	}
-
-	return nil
-}
-
-// callItemPrintString returns a protocol.CallHierarchyItem object represented as a string.
-// item and call ranges (protocol.Range) are converted to user friendly spans (1-indexed).
-func callItemPrintString(ctx context.Context, conn *connection, item protocol.CallHierarchyItem, callsURI protocol.DocumentURI, calls []protocol.Range) (string, error) {
-	itemFile := conn.openFile(ctx, item.URI.SpanURI())
-	if itemFile.err != nil {
-		return "", itemFile.err
-	}
-	itemSpan, err := itemFile.mapper.Span(protocol.Location{URI: item.URI, Range: item.Range})
-	if err != nil {
-		return "", err
-	}
-
-	callsFile := conn.openFile(ctx, callsURI.SpanURI())
-	if callsURI != "" && callsFile.err != nil {
-		return "", callsFile.err
-	}
-	var callRanges []string
-	for _, rng := range calls {
-		callSpan, err := callsFile.mapper.Span(protocol.Location{URI: item.URI, Range: rng})
-		if err != nil {
-			return "", err
-		}
-
-		spn := fmt.Sprint(callSpan)
-		callRanges = append(callRanges, fmt.Sprint(spn[strings.Index(spn, ":")+1:]))
-	}
-
-	printString := fmt.Sprintf("function %s in %v", item.Name, itemSpan)
-	if len(calls) > 0 {
-		printString = fmt.Sprintf("ranges %s in %s from/to %s", strings.Join(callRanges, ", "), callsURI.SpanURI().Filename(), printString)
-	}
-	return printString, nil
-}
diff -urN a/gopls/internal/lsp/cmd/capabilities_test.go b/gopls/internal/lsp/cmd/capabilities_test.go
--- a/gopls/internal/lsp/cmd/capabilities_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/capabilities_test.go	1969-12-31 16:00:00
@@ -1,166 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// TestCapabilities does some minimal validation of the server's adherence to the LSP.
-// The checks in the test are added as changes are made and errors noticed.
-func TestCapabilities(t *testing.T) {
-	tmpDir, err := ioutil.TempDir("", "fake")
-	if err != nil {
-		t.Fatal(err)
-	}
-	tmpFile := filepath.Join(tmpDir, "fake.go")
-	if err := ioutil.WriteFile(tmpFile, []byte(""), 0775); err != nil {
-		t.Fatal(err)
-	}
-	if err := ioutil.WriteFile(filepath.Join(tmpDir, "go.mod"), []byte("module fake\n\ngo 1.12\n"), 0775); err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(tmpDir)
-
-	app := New("gopls-test", tmpDir, os.Environ(), nil)
-	c := newConnection(app)
-	ctx := context.Background()
-	defer c.terminate(ctx)
-
-	params := &protocol.ParamInitialize{}
-	params.RootURI = protocol.URIFromPath(c.Client.app.wd)
-	params.Capabilities.Workspace.Configuration = true
-
-	// Send an initialize request to the server.
-	c.Server = lsp.NewServer(cache.NewSession(ctx, cache.New(nil, nil), app.options), c.Client)
-	result, err := c.Server.Initialize(ctx, params)
-	if err != nil {
-		t.Fatal(err)
-	}
-	// Validate initialization result.
-	if err := validateCapabilities(result); err != nil {
-		t.Error(err)
-	}
-	// Complete initialization of server.
-	if err := c.Server.Initialized(ctx, &protocol.InitializedParams{}); err != nil {
-		t.Fatal(err)
-	}
-
-	// Open the file on the server side.
-	uri := protocol.URIFromPath(tmpFile)
-	if err := c.Server.DidOpen(ctx, &protocol.DidOpenTextDocumentParams{
-		TextDocument: protocol.TextDocumentItem{
-			URI:        uri,
-			LanguageID: "go",
-			Version:    1,
-			Text:       `package main; func main() {};`,
-		},
-	}); err != nil {
-		t.Fatal(err)
-	}
-
-	// If we are sending a full text change, the change.Range must be nil.
-	// It is not enough for the Change to be empty, as that is ambiguous.
-	if err := c.Server.DidChange(ctx, &protocol.DidChangeTextDocumentParams{
-		TextDocument: protocol.VersionedTextDocumentIdentifier{
-			TextDocumentIdentifier: protocol.TextDocumentIdentifier{
-				URI: uri,
-			},
-			Version: 2,
-		},
-		ContentChanges: []protocol.TextDocumentContentChangeEvent{
-			{
-				Range: nil,
-				Text:  `package main; func main() { fmt.Println("") }`,
-			},
-		},
-	}); err != nil {
-		t.Fatal(err)
-	}
-
-	// Send a code action request to validate expected types.
-	actions, err := c.Server.CodeAction(ctx, &protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: uri,
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	for _, action := range actions {
-		// Validate that an empty command is sent along with import organization responses.
-		if action.Kind == protocol.SourceOrganizeImports && action.Command != nil {
-			t.Errorf("unexpected command for import organization")
-		}
-	}
-
-	if err := c.Server.DidSave(ctx, &protocol.DidSaveTextDocumentParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: uri,
-		},
-		// LSP specifies that a file can be saved with optional text, so this field must be nil.
-		Text: nil,
-	}); err != nil {
-		t.Fatal(err)
-	}
-
-	// Send a completion request to validate expected types.
-	list, err := c.Server.Completion(ctx, &protocol.CompletionParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{
-				URI: uri,
-			},
-			Position: protocol.Position{
-				Line:      0,
-				Character: 28,
-			},
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	for _, item := range list.Items {
-		// All other completion items should have nil commands.
-		// An empty command will be treated as a command with the name '' by VS Code.
-		// This causes VS Code to report errors to users about invalid commands.
-		if item.Command != nil {
-			t.Errorf("unexpected command for completion item")
-		}
-		// The item's TextEdit must be a pointer, as VS Code considers TextEdits
-		// that don't contain the cursor position to be invalid.
-		var textEdit interface{} = item.TextEdit
-		if _, ok := textEdit.(*protocol.TextEdit); !ok {
-			t.Errorf("textEdit is not a *protocol.TextEdit, instead it is %T", textEdit)
-		}
-	}
-	if err := c.Server.Shutdown(ctx); err != nil {
-		t.Fatal(err)
-	}
-	if err := c.Server.Exit(ctx); err != nil {
-		t.Fatal(err)
-	}
-}
-
-func validateCapabilities(result *protocol.InitializeResult) error {
-	// If the client sends "false" for RenameProvider.PrepareSupport,
-	// the server must respond with a boolean.
-	if v, ok := result.Capabilities.RenameProvider.(bool); !ok {
-		return fmt.Errorf("RenameProvider must be a boolean if PrepareSupport is false (got %T)", v)
-	}
-	// The same goes for CodeActionKind.ValueSet.
-	if v, ok := result.Capabilities.CodeActionProvider.(bool); !ok {
-		return fmt.Errorf("CodeActionSupport must be a boolean if CodeActionKind.ValueSet has length 0 (got %T)", v)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/check.go b/gopls/internal/lsp/cmd/check.go
--- a/gopls/internal/lsp/cmd/check.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/check.go	1969-12-31 16:00:00
@@ -1,73 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// check implements the check verb for gopls.
-type check struct {
-	app *Application
-}
-
-func (c *check) Name() string      { return "check" }
-func (c *check) Parent() string    { return c.app.Name() }
-func (c *check) Usage() string     { return "<filename>" }
-func (c *check) ShortHelp() string { return "show diagnostic results for the specified file" }
-func (c *check) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example: show the diagnostic results of this file:
-
-	$ gopls check internal/lsp/cmd/check.go
-`)
-	printFlagDefaults(f)
-}
-
-// Run performs the check on the files specified by args and prints the
-// results to stdout.
-func (c *check) Run(ctx context.Context, args ...string) error {
-	if len(args) == 0 {
-		// no files, so no results
-		return nil
-	}
-	checking := map[span.URI]*cmdFile{}
-	var uris []span.URI
-	// now we ready to kick things off
-	conn, err := c.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-	for _, arg := range args {
-		uri := span.URIFromPath(arg)
-		uris = append(uris, uri)
-		file := conn.openFile(ctx, uri)
-		if file.err != nil {
-			return file.err
-		}
-		checking[uri] = file
-	}
-	if err := conn.diagnoseFiles(ctx, uris); err != nil {
-		return err
-	}
-	conn.Client.filesMu.Lock()
-	defer conn.Client.filesMu.Unlock()
-
-	for _, file := range checking {
-		for _, d := range file.diagnostics {
-			spn, err := file.mapper.RangeSpan(d.Range)
-			if err != nil {
-				return fmt.Errorf("Could not convert position %v for %q", d.Range, d.Message)
-			}
-			fmt.Printf("%v: %v\n", spn, d.Message)
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/cmd.go b/gopls/internal/lsp/cmd/cmd.go
--- a/gopls/internal/lsp/cmd/cmd.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/cmd.go	1969-12-31 16:00:00
@@ -1,635 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package cmd handles the gopls command line.
-// It contains a handler for each of the modes, along with all the flag handling
-// and the command line output format.
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"go/token"
-	"io/ioutil"
-	"log"
-	"os"
-	"reflect"
-	"sort"
-	"strings"
-	"sync"
-	"text/tabwriter"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/tool"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// Application is the main application as passed to tool.Main
-// It handles the main command line parsing and dispatch to the sub commands.
-type Application struct {
-	// Core application flags
-
-	// Embed the basic profiling flags supported by the tool package
-	tool.Profile
-
-	// We include the server configuration directly for now, so the flags work
-	// even without the verb.
-	// TODO: Remove this when we stop allowing the serve verb by default.
-	Serve Serve
-
-	// the options configuring function to invoke when building a server
-	options func(*source.Options)
-
-	// The name of the binary, used in help and telemetry.
-	name string
-
-	// The working directory to run commands in.
-	wd string
-
-	// The environment variables to use.
-	env []string
-
-	// Support for remote LSP server.
-	Remote string `flag:"remote" help:"forward all commands to a remote lsp specified by this flag. With no special prefix, this is assumed to be a TCP address. If prefixed by 'unix;', the subsequent address is assumed to be a unix domain socket. If 'auto', or prefixed by 'auto;', the remote address is automatically resolved based on the executing environment."`
-
-	// Verbose enables verbose logging.
-	Verbose bool `flag:"v,verbose" help:"verbose output"`
-
-	// VeryVerbose enables a higher level of verbosity in logging output.
-	VeryVerbose bool `flag:"vv,veryverbose" help:"very verbose output"`
-
-	// Control ocagent export of telemetry
-	OCAgent string `flag:"ocagent" help:"the address of the ocagent (e.g. http://localhost:55678), or off"`
-
-	// PrepareOptions is called to update the options when a new view is built.
-	// It is primarily to allow the behavior of gopls to be modified by hooks.
-	PrepareOptions func(*source.Options)
-}
-
-func (app *Application) verbose() bool {
-	return app.Verbose || app.VeryVerbose
-}
-
-// New returns a new Application ready to run.
-func New(name, wd string, env []string, options func(*source.Options)) *Application {
-	if wd == "" {
-		wd, _ = os.Getwd()
-	}
-	app := &Application{
-		options: options,
-		name:    name,
-		wd:      wd,
-		env:     env,
-		OCAgent: "off", //TODO: Remove this line to default the exporter to on
-
-		Serve: Serve{
-			RemoteListenTimeout: 1 * time.Minute,
-		},
-	}
-	app.Serve.app = app
-	return app
-}
-
-// Name implements tool.Application returning the binary name.
-func (app *Application) Name() string { return app.name }
-
-// Usage implements tool.Application returning empty extra argument usage.
-func (app *Application) Usage() string { return "" }
-
-// ShortHelp implements tool.Application returning the main binary help.
-func (app *Application) ShortHelp() string {
-	return ""
-}
-
-// DetailedHelp implements tool.Application returning the main binary help.
-// This includes the short help for all the sub commands.
-func (app *Application) DetailedHelp(f *flag.FlagSet) {
-	w := tabwriter.NewWriter(f.Output(), 0, 0, 2, ' ', 0)
-	defer w.Flush()
-
-	fmt.Fprint(w, `
-gopls is a Go language server.
-
-It is typically used with an editor to provide language features. When no
-command is specified, gopls will default to the 'serve' command. The language
-features can also be accessed via the gopls command-line interface.
-
-Usage:
-  gopls help [<subject>]
-
-Command:
-`)
-	fmt.Fprint(w, "\nMain\t\n")
-	for _, c := range app.mainCommands() {
-		fmt.Fprintf(w, "  %s\t%s\n", c.Name(), c.ShortHelp())
-	}
-	fmt.Fprint(w, "\t\nFeatures\t\n")
-	for _, c := range app.featureCommands() {
-		fmt.Fprintf(w, "  %s\t%s\n", c.Name(), c.ShortHelp())
-	}
-	fmt.Fprint(w, "\nflags:\n")
-	printFlagDefaults(f)
-}
-
-// this is a slightly modified version of flag.PrintDefaults to give us control
-func printFlagDefaults(s *flag.FlagSet) {
-	var flags [][]*flag.Flag
-	seen := map[flag.Value]int{}
-	s.VisitAll(func(f *flag.Flag) {
-		if i, ok := seen[f.Value]; !ok {
-			seen[f.Value] = len(flags)
-			flags = append(flags, []*flag.Flag{f})
-		} else {
-			flags[i] = append(flags[i], f)
-		}
-	})
-	for _, entry := range flags {
-		sort.SliceStable(entry, func(i, j int) bool {
-			return len(entry[i].Name) < len(entry[j].Name)
-		})
-		var b strings.Builder
-		for i, f := range entry {
-			switch i {
-			case 0:
-				b.WriteString("  -")
-			default:
-				b.WriteString(",-")
-			}
-			b.WriteString(f.Name)
-		}
-
-		f := entry[0]
-		name, usage := flag.UnquoteUsage(f)
-		if len(name) > 0 {
-			b.WriteString("=")
-			b.WriteString(name)
-		}
-		// Boolean flags of one ASCII letter are so common we
-		// treat them specially, putting their usage on the same line.
-		if b.Len() <= 4 { // space, space, '-', 'x'.
-			b.WriteString("\t")
-		} else {
-			// Four spaces before the tab triggers good alignment
-			// for both 4- and 8-space tab stops.
-			b.WriteString("\n    \t")
-		}
-		b.WriteString(strings.ReplaceAll(usage, "\n", "\n    \t"))
-		if !isZeroValue(f, f.DefValue) {
-			if reflect.TypeOf(f.Value).Elem().Name() == "stringValue" {
-				fmt.Fprintf(&b, " (default %q)", f.DefValue)
-			} else {
-				fmt.Fprintf(&b, " (default %v)", f.DefValue)
-			}
-		}
-		fmt.Fprint(s.Output(), b.String(), "\n")
-	}
-}
-
-// isZeroValue is copied from the flags package
-func isZeroValue(f *flag.Flag, value string) bool {
-	// Build a zero value of the flag's Value type, and see if the
-	// result of calling its String method equals the value passed in.
-	// This works unless the Value type is itself an interface type.
-	typ := reflect.TypeOf(f.Value)
-	var z reflect.Value
-	if typ.Kind() == reflect.Ptr {
-		z = reflect.New(typ.Elem())
-	} else {
-		z = reflect.Zero(typ)
-	}
-	return value == z.Interface().(flag.Value).String()
-}
-
-// Run takes the args after top level flag processing, and invokes the correct
-// sub command as specified by the first argument.
-// If no arguments are passed it will invoke the server sub command, as a
-// temporary measure for compatibility.
-func (app *Application) Run(ctx context.Context, args ...string) error {
-	ctx = debug.WithInstance(ctx, app.wd, app.OCAgent)
-	if len(args) == 0 {
-		s := flag.NewFlagSet(app.Name(), flag.ExitOnError)
-		return tool.Run(ctx, s, &app.Serve, args)
-	}
-	command, args := args[0], args[1:]
-	for _, c := range app.Commands() {
-		if c.Name() == command {
-			s := flag.NewFlagSet(app.Name(), flag.ExitOnError)
-			return tool.Run(ctx, s, c, args)
-		}
-	}
-	return tool.CommandLineErrorf("Unknown command %v", command)
-}
-
-// commands returns the set of commands supported by the gopls tool on the
-// command line.
-// The command is specified by the first non flag argument.
-func (app *Application) Commands() []tool.Application {
-	var commands []tool.Application
-	commands = append(commands, app.mainCommands()...)
-	commands = append(commands, app.featureCommands()...)
-	return commands
-}
-
-func (app *Application) mainCommands() []tool.Application {
-	return []tool.Application{
-		&app.Serve,
-		&version{app: app},
-		&bug{app: app},
-		&help{app: app},
-		&apiJSON{app: app},
-		&licenses{app: app},
-	}
-}
-
-func (app *Application) featureCommands() []tool.Application {
-	return []tool.Application{
-		&callHierarchy{app: app},
-		&check{app: app},
-		&definition{app: app},
-		&foldingRanges{app: app},
-		&format{app: app},
-		&highlight{app: app},
-		&implementation{app: app},
-		&imports{app: app},
-		newRemote(app, ""),
-		newRemote(app, "inspect"),
-		&links{app: app},
-		&prepareRename{app: app},
-		&references{app: app},
-		&rename{app: app},
-		&semtok{app: app},
-		&signature{app: app},
-		&suggestedFix{app: app},
-		&symbols{app: app},
-		newWorkspace(app),
-		&workspaceSymbol{app: app},
-		&vulncheck{app: app},
-	}
-}
-
-var (
-	internalMu          sync.Mutex
-	internalConnections = make(map[string]*connection)
-)
-
-func (app *Application) connect(ctx context.Context) (*connection, error) {
-	switch {
-	case app.Remote == "":
-		connection := newConnection(app)
-		connection.Server = lsp.NewServer(cache.NewSession(ctx, cache.New(nil, nil), app.options), connection.Client)
-		ctx = protocol.WithClient(ctx, connection.Client)
-		return connection, connection.initialize(ctx, app.options)
-	case strings.HasPrefix(app.Remote, "internal@"):
-		internalMu.Lock()
-		defer internalMu.Unlock()
-		opts := source.DefaultOptions().Clone()
-		if app.options != nil {
-			app.options(opts)
-		}
-		key := fmt.Sprintf("%s %v %v %v", app.wd, opts.PreferredContentFormat, opts.HierarchicalDocumentSymbolSupport, opts.SymbolMatcher)
-		if c := internalConnections[key]; c != nil {
-			return c, nil
-		}
-		remote := app.Remote[len("internal@"):]
-		ctx := xcontext.Detach(ctx) //TODO:a way of shutting down the internal server
-		connection, err := app.connectRemote(ctx, remote)
-		if err != nil {
-			return nil, err
-		}
-		internalConnections[key] = connection
-		return connection, nil
-	default:
-		return app.connectRemote(ctx, app.Remote)
-	}
-}
-
-// CloseTestConnections terminates shared connections used in command tests. It
-// should only be called from tests.
-func CloseTestConnections(ctx context.Context) {
-	for _, c := range internalConnections {
-		c.Shutdown(ctx)
-		c.Exit(ctx)
-	}
-}
-
-func (app *Application) connectRemote(ctx context.Context, remote string) (*connection, error) {
-	connection := newConnection(app)
-	conn, err := lsprpc.ConnectToRemote(ctx, remote)
-	if err != nil {
-		return nil, err
-	}
-	stream := jsonrpc2.NewHeaderStream(conn)
-	cc := jsonrpc2.NewConn(stream)
-	connection.Server = protocol.ServerDispatcher(cc)
-	ctx = protocol.WithClient(ctx, connection.Client)
-	cc.Go(ctx,
-		protocol.Handlers(
-			protocol.ClientHandler(connection.Client,
-				jsonrpc2.MethodNotFound)))
-	return connection, connection.initialize(ctx, app.options)
-}
-
-var matcherString = map[source.SymbolMatcher]string{
-	source.SymbolFuzzy:           "fuzzy",
-	source.SymbolCaseSensitive:   "caseSensitive",
-	source.SymbolCaseInsensitive: "caseInsensitive",
-}
-
-func (c *connection) initialize(ctx context.Context, options func(*source.Options)) error {
-	params := &protocol.ParamInitialize{}
-	params.RootURI = protocol.URIFromPath(c.Client.app.wd)
-	params.Capabilities.Workspace.Configuration = true
-
-	// Make sure to respect configured options when sending initialize request.
-	opts := source.DefaultOptions().Clone()
-	if options != nil {
-		options(opts)
-	}
-	// If you add an additional option here, you must update the map key in connect.
-	params.Capabilities.TextDocument.Hover = protocol.HoverClientCapabilities{
-		ContentFormat: []protocol.MarkupKind{opts.PreferredContentFormat},
-	}
-	params.Capabilities.TextDocument.DocumentSymbol.HierarchicalDocumentSymbolSupport = opts.HierarchicalDocumentSymbolSupport
-	params.Capabilities.TextDocument.SemanticTokens = protocol.SemanticTokensClientCapabilities{}
-	params.Capabilities.TextDocument.SemanticTokens.Formats = []string{"relative"}
-	params.Capabilities.TextDocument.SemanticTokens.Requests.Range = true
-	params.Capabilities.TextDocument.SemanticTokens.Requests.Full = true
-	params.Capabilities.TextDocument.SemanticTokens.TokenTypes = lsp.SemanticTypes()
-	params.Capabilities.TextDocument.SemanticTokens.TokenModifiers = lsp.SemanticModifiers()
-	params.InitializationOptions = map[string]interface{}{
-		"symbolMatcher": matcherString[opts.SymbolMatcher],
-	}
-	if _, err := c.Server.Initialize(ctx, params); err != nil {
-		return err
-	}
-	if err := c.Server.Initialized(ctx, &protocol.InitializedParams{}); err != nil {
-		return err
-	}
-	return nil
-}
-
-type connection struct {
-	protocol.Server
-	Client *cmdClient
-}
-
-type cmdClient struct {
-	protocol.Server
-	app  *Application
-	fset *token.FileSet
-
-	diagnosticsMu   sync.Mutex
-	diagnosticsDone chan struct{}
-
-	filesMu sync.Mutex
-	files   map[span.URI]*cmdFile
-}
-
-type cmdFile struct {
-	uri         span.URI
-	mapper      *protocol.ColumnMapper
-	err         error
-	open        bool
-	diagnostics []protocol.Diagnostic
-}
-
-func newConnection(app *Application) *connection {
-	return &connection{
-		Client: &cmdClient{
-			app:   app,
-			fset:  token.NewFileSet(),
-			files: make(map[span.URI]*cmdFile),
-		},
-	}
-}
-
-// fileURI converts a DocumentURI to a file:// span.URI, panicking if it's not a file.
-func fileURI(uri protocol.DocumentURI) span.URI {
-	sURI := uri.SpanURI()
-	if !sURI.IsFile() {
-		panic(fmt.Sprintf("%q is not a file URI", uri))
-	}
-	return sURI
-}
-
-func (c *cmdClient) CodeLensRefresh(context.Context) error { return nil }
-
-func (c *cmdClient) LogTrace(context.Context, *protocol.LogTraceParams) error { return nil }
-
-func (c *cmdClient) ShowMessage(ctx context.Context, p *protocol.ShowMessageParams) error { return nil }
-
-func (c *cmdClient) ShowMessageRequest(ctx context.Context, p *protocol.ShowMessageRequestParams) (*protocol.MessageActionItem, error) {
-	return nil, nil
-}
-
-func (c *cmdClient) LogMessage(ctx context.Context, p *protocol.LogMessageParams) error {
-	switch p.Type {
-	case protocol.Error:
-		log.Print("Error:", p.Message)
-	case protocol.Warning:
-		log.Print("Warning:", p.Message)
-	case protocol.Info:
-		if c.app.verbose() {
-			log.Print("Info:", p.Message)
-		}
-	case protocol.Log:
-		if c.app.verbose() {
-			log.Print("Log:", p.Message)
-		}
-	default:
-		if c.app.verbose() {
-			log.Print(p.Message)
-		}
-	}
-	return nil
-}
-
-func (c *cmdClient) Event(ctx context.Context, t *interface{}) error { return nil }
-
-func (c *cmdClient) RegisterCapability(ctx context.Context, p *protocol.RegistrationParams) error {
-	return nil
-}
-
-func (c *cmdClient) UnregisterCapability(ctx context.Context, p *protocol.UnregistrationParams) error {
-	return nil
-}
-
-func (c *cmdClient) WorkspaceFolders(ctx context.Context) ([]protocol.WorkspaceFolder, error) {
-	return nil, nil
-}
-
-func (c *cmdClient) Configuration(ctx context.Context, p *protocol.ParamConfiguration) ([]interface{}, error) {
-	results := make([]interface{}, len(p.Items))
-	for i, item := range p.Items {
-		if item.Section != "gopls" {
-			continue
-		}
-		env := map[string]interface{}{}
-		for _, value := range c.app.env {
-			l := strings.SplitN(value, "=", 2)
-			if len(l) != 2 {
-				continue
-			}
-			env[l[0]] = l[1]
-		}
-		m := map[string]interface{}{
-			"env": env,
-			"analyses": map[string]bool{
-				"fillreturns":    true,
-				"nonewvars":      true,
-				"noresultvalues": true,
-				"undeclaredname": true,
-			},
-		}
-		if c.app.VeryVerbose {
-			m["verboseOutput"] = true
-		}
-		results[i] = m
-	}
-	return results, nil
-}
-
-func (c *cmdClient) ApplyEdit(ctx context.Context, p *protocol.ApplyWorkspaceEditParams) (*protocol.ApplyWorkspaceEditResult, error) {
-	return &protocol.ApplyWorkspaceEditResult{Applied: false, FailureReason: "not implemented"}, nil
-}
-
-func (c *cmdClient) PublishDiagnostics(ctx context.Context, p *protocol.PublishDiagnosticsParams) error {
-	if p.URI == "gopls://diagnostics-done" {
-		close(c.diagnosticsDone)
-	}
-	// Don't worry about diagnostics without versions.
-	if p.Version == 0 {
-		return nil
-	}
-
-	c.filesMu.Lock()
-	defer c.filesMu.Unlock()
-
-	file := c.getFile(ctx, fileURI(p.URI))
-	file.diagnostics = p.Diagnostics
-	return nil
-}
-
-func (c *cmdClient) Progress(context.Context, *protocol.ProgressParams) error {
-	return nil
-}
-
-func (c *cmdClient) ShowDocument(context.Context, *protocol.ShowDocumentParams) (*protocol.ShowDocumentResult, error) {
-	return nil, nil
-}
-
-func (c *cmdClient) WorkDoneProgressCreate(context.Context, *protocol.WorkDoneProgressCreateParams) error {
-	return nil
-}
-
-func (c *cmdClient) getFile(ctx context.Context, uri span.URI) *cmdFile {
-	file, found := c.files[uri]
-	if !found || file.err != nil {
-		file = &cmdFile{
-			uri: uri,
-		}
-		c.files[uri] = file
-	}
-	if file.mapper == nil {
-		fname := uri.Filename()
-		content, err := ioutil.ReadFile(fname)
-		if err != nil {
-			file.err = fmt.Errorf("getFile: %v: %v", uri, err)
-			return file
-		}
-		f := c.fset.AddFile(fname, -1, len(content))
-		f.SetLinesForContent(content)
-		file.mapper = &protocol.ColumnMapper{
-			URI:     uri,
-			TokFile: f,
-			Content: content,
-		}
-	}
-	return file
-}
-
-func (c *cmdClient) openFile(ctx context.Context, uri span.URI) *cmdFile {
-	c.filesMu.Lock()
-	defer c.filesMu.Unlock()
-
-	file := c.getFile(ctx, uri)
-	if file.err != nil || file.open {
-		return file
-	}
-	file.open = true
-	return file
-}
-
-func (c *connection) openFile(ctx context.Context, uri span.URI) *cmdFile {
-	file := c.Client.openFile(ctx, uri)
-	if file.err != nil {
-		return file
-	}
-
-	p := &protocol.DidOpenTextDocumentParams{
-		TextDocument: protocol.TextDocumentItem{
-			URI:        protocol.URIFromSpanURI(uri),
-			LanguageID: "go",
-			Version:    1,
-			Text:       string(file.mapper.Content),
-		},
-	}
-	if err := c.Server.DidOpen(ctx, p); err != nil {
-		file.err = fmt.Errorf("%v: %v", uri, err)
-	}
-	return file
-}
-
-func (c *connection) semanticTokens(ctx context.Context, p *protocol.SemanticTokensRangeParams) (*protocol.SemanticTokens, error) {
-	// use range to avoid limits on full
-	resp, err := c.Server.SemanticTokensRange(ctx, p)
-	if err != nil {
-		return nil, err
-	}
-	return resp, nil
-}
-
-func (c *connection) diagnoseFiles(ctx context.Context, files []span.URI) error {
-	var untypedFiles []interface{}
-	for _, file := range files {
-		untypedFiles = append(untypedFiles, string(file))
-	}
-	c.Client.diagnosticsMu.Lock()
-	defer c.Client.diagnosticsMu.Unlock()
-
-	c.Client.diagnosticsDone = make(chan struct{})
-	_, err := c.Server.NonstandardRequest(ctx, "gopls/diagnoseFiles", map[string]interface{}{"files": untypedFiles})
-	if err != nil {
-		close(c.Client.diagnosticsDone)
-		return err
-	}
-
-	<-c.Client.diagnosticsDone
-	return nil
-}
-
-func (c *connection) terminate(ctx context.Context) {
-	if strings.HasPrefix(c.Client.app.Remote, "internal@") {
-		// internal connections need to be left alive for the next test
-		return
-	}
-	//TODO: do we need to handle errors on these calls?
-	c.Shutdown(ctx)
-	//TODO: right now calling exit terminates the process, we should rethink that
-	//server.Exit(ctx)
-}
-
-// Implement io.Closer.
-func (c *cmdClient) Close() error {
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/definition.go b/gopls/internal/lsp/cmd/definition.go
--- a/gopls/internal/lsp/cmd/definition.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/definition.go	1969-12-31 16:00:00
@@ -1,136 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"os"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// A Definition is the result of a 'definition' query.
-type Definition struct {
-	Span        span.Span `json:"span"`        // span of the definition
-	Description string    `json:"description"` // description of the denoted object
-}
-
-// These constant is printed in the help, and then used in a test to verify the
-// help is still valid.
-// They refer to "Set" in "flag.FlagSet" from the DetailedHelp method below.
-const (
-	exampleLine   = 44
-	exampleColumn = 47
-	exampleOffset = 1270
-)
-
-// definition implements the definition verb for gopls.
-type definition struct {
-	app *Application
-
-	JSON              bool `flag:"json" help:"emit output in JSON format"`
-	MarkdownSupported bool `flag:"markdown" help:"support markdown in responses"`
-}
-
-func (d *definition) Name() string      { return "definition" }
-func (d *definition) Parent() string    { return d.app.Name() }
-func (d *definition) Usage() string     { return "[definition-flags] <position>" }
-func (d *definition) ShortHelp() string { return "show declaration of selected identifier" }
-func (d *definition) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprintf(f.Output(), `
-Example: show the definition of the identifier at syntax at offset %[1]v in this file (flag.FlagSet):
-
-	$ gopls definition internal/lsp/cmd/definition.go:%[1]v:%[2]v
-	$ gopls definition internal/lsp/cmd/definition.go:#%[3]v
-
-definition-flags:
-`, exampleLine, exampleColumn, exampleOffset)
-	printFlagDefaults(f)
-}
-
-// Run performs the definition query as specified by args and prints the
-// results to stdout.
-func (d *definition) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("definition expects 1 argument")
-	}
-	// Plaintext makes more sense for the command line.
-	opts := d.app.options
-	d.app.options = func(o *source.Options) {
-		if opts != nil {
-			opts(o)
-		}
-		o.PreferredContentFormat = protocol.PlainText
-		if d.MarkdownSupported {
-			o.PreferredContentFormat = protocol.Markdown
-		}
-	}
-	conn, err := d.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-	}
-	p := protocol.DefinitionParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	locs, err := conn.Definition(ctx, &p)
-	if err != nil {
-		return fmt.Errorf("%v: %v", from, err)
-	}
-
-	if len(locs) == 0 {
-		return fmt.Errorf("%v: not an identifier", from)
-	}
-	q := protocol.HoverParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	hover, err := conn.Hover(ctx, &q)
-	if err != nil {
-		return fmt.Errorf("%v: %v", from, err)
-	}
-	if hover == nil {
-		return fmt.Errorf("%v: not an identifier", from)
-	}
-	file = conn.openFile(ctx, fileURI(locs[0].URI))
-	if file.err != nil {
-		return fmt.Errorf("%v: %v", from, file.err)
-	}
-	definition, err := file.mapper.Span(locs[0])
-	if err != nil {
-		return fmt.Errorf("%v: %v", from, err)
-	}
-	description := strings.TrimSpace(hover.Contents.Value)
-	result := &Definition{
-		Span:        definition,
-		Description: description,
-	}
-	if d.JSON {
-		enc := json.NewEncoder(os.Stdout)
-		enc.SetIndent("", "\t")
-		return enc.Encode(result)
-	}
-	fmt.Printf("%v: defined here as %s", result.Span, result.Description)
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/folding_range.go b/gopls/internal/lsp/cmd/folding_range.go
--- a/gopls/internal/lsp/cmd/folding_range.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/folding_range.go	1969-12-31 16:00:00
@@ -1,73 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// foldingRanges implements the folding_ranges verb for gopls
-type foldingRanges struct {
-	app *Application
-}
-
-func (r *foldingRanges) Name() string      { return "folding_ranges" }
-func (r *foldingRanges) Parent() string    { return r.app.Name() }
-func (r *foldingRanges) Usage() string     { return "<file>" }
-func (r *foldingRanges) ShortHelp() string { return "display selected file's folding ranges" }
-func (r *foldingRanges) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ gopls folding_ranges helper/helper.go
-`)
-	printFlagDefaults(f)
-}
-
-func (r *foldingRanges) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("folding_ranges expects 1 argument (file)")
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-
-	p := protocol.FoldingRangeParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(from.URI()),
-		},
-	}
-
-	ranges, err := conn.FoldingRange(ctx, &p)
-	if err != nil {
-		return err
-	}
-
-	for _, r := range ranges {
-		fmt.Printf("%v:%v-%v:%v\n",
-			r.StartLine+1,
-			r.StartCharacter+1,
-			r.EndLine+1,
-			r.EndCharacter,
-		)
-	}
-
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/format.go b/gopls/internal/lsp/cmd/format.go
--- a/gopls/internal/lsp/cmd/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/format.go	1969-12-31 16:00:00
@@ -1,109 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"io/ioutil"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/diff"
-)
-
-// format implements the format verb for gopls.
-type format struct {
-	Diff  bool `flag:"d,diff" help:"display diffs instead of rewriting files"`
-	Write bool `flag:"w,write" help:"write result to (source) file instead of stdout"`
-	List  bool `flag:"l,list" help:"list files whose formatting differs from gofmt's"`
-
-	app *Application
-}
-
-func (c *format) Name() string      { return "format" }
-func (c *format) Parent() string    { return c.app.Name() }
-func (c *format) Usage() string     { return "[format-flags] <filerange>" }
-func (c *format) ShortHelp() string { return "format the code according to the go standard" }
-func (c *format) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-The arguments supplied may be simple file names, or ranges within files.
-
-Example: reformat this file:
-
-	$ gopls format -w internal/lsp/cmd/check.go
-
-format-flags:
-`)
-	printFlagDefaults(f)
-}
-
-// Run performs the check on the files specified by args and prints the
-// results to stdout.
-func (c *format) Run(ctx context.Context, args ...string) error {
-	if len(args) == 0 {
-		// no files, so no results
-		return nil
-	}
-	// now we ready to kick things off
-	conn, err := c.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-	for _, arg := range args {
-		spn := span.Parse(arg)
-		file := conn.openFile(ctx, spn.URI())
-		if file.err != nil {
-			return file.err
-		}
-		filename := spn.URI().Filename()
-		loc, err := file.mapper.Location(spn)
-		if err != nil {
-			return err
-		}
-		if loc.Range.Start != loc.Range.End {
-			return fmt.Errorf("only full file formatting supported")
-		}
-		p := protocol.DocumentFormattingParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		}
-		edits, err := conn.Formatting(ctx, &p)
-		if err != nil {
-			return fmt.Errorf("%v: %v", spn, err)
-		}
-		formatted, sedits, err := source.ApplyProtocolEdits(file.mapper, edits)
-		if err != nil {
-			return fmt.Errorf("%v: %v", spn, err)
-		}
-		printIt := true
-		if c.List {
-			printIt = false
-			if len(edits) > 0 {
-				fmt.Println(filename)
-			}
-		}
-		if c.Write {
-			printIt = false
-			if len(edits) > 0 {
-				ioutil.WriteFile(filename, []byte(formatted), 0644)
-			}
-		}
-		if c.Diff {
-			printIt = false
-			unified, err := diff.ToUnified(filename+".orig", filename, string(file.mapper.Content), sedits)
-			if err != nil {
-				return err
-			}
-			fmt.Print(unified)
-		}
-		if printIt {
-			fmt.Print(formatted)
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/help_test.go b/gopls/internal/lsp/cmd/help_test.go
--- a/gopls/internal/lsp/cmd/help_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/help_test.go	1969-12-31 16:00:00
@@ -1,57 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd_test
-
-import (
-	"bytes"
-	"context"
-	"flag"
-	"io/ioutil"
-	"path/filepath"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/cmd"
-	"golang.org/x/tools/internal/testenv"
-	"golang.org/x/tools/internal/tool"
-)
-
-//go:generate go test -run Help -update-help-files
-
-var updateHelpFiles = flag.Bool("update-help-files", false, "Write out the help files instead of checking them")
-
-const appName = "gopls"
-
-func TestHelpFiles(t *testing.T) {
-	testenv.NeedsGoBuild(t) // This is a lie. We actually need the source code.
-	app := cmd.New(appName, "", nil, nil)
-	ctx := context.Background()
-	for _, page := range append(app.Commands(), app) {
-		t.Run(page.Name(), func(t *testing.T) {
-			var buf bytes.Buffer
-			s := flag.NewFlagSet(page.Name(), flag.ContinueOnError)
-			s.SetOutput(&buf)
-			tool.Run(ctx, s, page, []string{"-h"})
-			name := page.Name()
-			if name == appName {
-				name = "usage"
-			}
-			helpFile := filepath.Join("usage", name+".hlp")
-			got := buf.Bytes()
-			if *updateHelpFiles {
-				if err := ioutil.WriteFile(helpFile, got, 0666); err != nil {
-					t.Errorf("Failed writing %v: %v", helpFile, err)
-				}
-				return
-			}
-			expect, err := ioutil.ReadFile(helpFile)
-			switch {
-			case err != nil:
-				t.Errorf("Missing help file %q", helpFile)
-			case !bytes.Equal(expect, got):
-				t.Errorf("Help file %q did not match, got:\n%q\nwant:\n%q", helpFile, string(got), string(expect))
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/highlight.go b/gopls/internal/lsp/cmd/highlight.go
--- a/gopls/internal/lsp/cmd/highlight.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/highlight.go	1969-12-31 16:00:00
@@ -1,86 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// highlight implements the highlight verb for gopls.
-type highlight struct {
-	app *Application
-}
-
-func (r *highlight) Name() string      { return "highlight" }
-func (r *highlight) Parent() string    { return r.app.Name() }
-func (r *highlight) Usage() string     { return "<position>" }
-func (r *highlight) ShortHelp() string { return "display selected identifier's highlights" }
-func (r *highlight) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls highlight helper/helper.go:8:6
-	$ gopls highlight helper/helper.go:#53
-`)
-	printFlagDefaults(f)
-}
-
-func (r *highlight) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("highlight expects 1 argument (position)")
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-
-	p := protocol.DocumentHighlightParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-			Position:     loc.Range.Start,
-		},
-	}
-	highlights, err := conn.DocumentHighlight(ctx, &p)
-	if err != nil {
-		return err
-	}
-
-	var results []span.Span
-	for _, h := range highlights {
-		l := protocol.Location{Range: h.Range}
-		s, err := file.mapper.Span(l)
-		if err != nil {
-			return err
-		}
-		results = append(results, s)
-	}
-	// Sort results to make tests deterministic since DocumentHighlight uses a map.
-	span.SortSpans(results)
-
-	for _, s := range results {
-		fmt.Println(s)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/implementation.go b/gopls/internal/lsp/cmd/implementation.go
--- a/gopls/internal/lsp/cmd/implementation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/implementation.go	1969-12-31 16:00:00
@@ -1,88 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// implementation implements the implementation verb for gopls
-type implementation struct {
-	app *Application
-}
-
-func (i *implementation) Name() string      { return "implementation" }
-func (i *implementation) Parent() string    { return i.app.Name() }
-func (i *implementation) Usage() string     { return "<position>" }
-func (i *implementation) ShortHelp() string { return "display selected identifier's implementation" }
-func (i *implementation) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls implementation helper/helper.go:8:6
-	$ gopls implementation helper/helper.go:#53
-`)
-	printFlagDefaults(f)
-}
-
-func (i *implementation) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("implementation expects 1 argument (position)")
-	}
-
-	conn, err := i.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-
-	p := protocol.ImplementationParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-			Position:     loc.Range.Start,
-		},
-	}
-
-	implementations, err := conn.Implementation(ctx, &p)
-	if err != nil {
-		return err
-	}
-
-	var spans []string
-	for _, impl := range implementations {
-		f := conn.openFile(ctx, fileURI(impl.URI))
-		span, err := f.mapper.Span(impl)
-		if err != nil {
-			return err
-		}
-		spans = append(spans, fmt.Sprint(span))
-	}
-	sort.Strings(spans)
-
-	for _, s := range spans {
-		fmt.Println(s)
-	}
-
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/imports.go b/gopls/internal/lsp/cmd/imports.go
--- a/gopls/internal/lsp/cmd/imports.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/imports.go	1969-12-31 16:00:00
@@ -1,104 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"io/ioutil"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/tool"
-)
-
-// imports implements the import verb for gopls.
-type imports struct {
-	Diff  bool `flag:"d,diff" help:"display diffs instead of rewriting files"`
-	Write bool `flag:"w,write" help:"write result to (source) file instead of stdout"`
-
-	app *Application
-}
-
-func (t *imports) Name() string      { return "imports" }
-func (t *imports) Parent() string    { return t.app.Name() }
-func (t *imports) Usage() string     { return "[imports-flags] <filename>" }
-func (t *imports) ShortHelp() string { return "updates import statements" }
-func (t *imports) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprintf(f.Output(), `
-Example: update imports statements in a file:
-
-	$ gopls imports -w internal/lsp/cmd/check.go
-
-imports-flags:
-`)
-	printFlagDefaults(f)
-}
-
-// Run performs diagnostic checks on the file specified and either;
-// - if -w is specified, updates the file in place;
-// - if -d is specified, prints out unified diffs of the changes; or
-// - otherwise, prints the new versions to stdout.
-func (t *imports) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("imports expects 1 argument")
-	}
-	conn, err := t.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	uri := from.URI()
-	file := conn.openFile(ctx, uri)
-	if file.err != nil {
-		return file.err
-	}
-	actions, err := conn.CodeAction(ctx, &protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		return fmt.Errorf("%v: %v", from, err)
-	}
-	var edits []protocol.TextEdit
-	for _, a := range actions {
-		if a.Title != "Organize Imports" {
-			continue
-		}
-		for _, c := range a.Edit.DocumentChanges {
-			if c.TextDocumentEdit != nil {
-				if fileURI(c.TextDocumentEdit.TextDocument.URI) == uri {
-					edits = append(edits, c.TextDocumentEdit.Edits...)
-				}
-			}
-		}
-	}
-	newContent, sedits, err := source.ApplyProtocolEdits(file.mapper, edits)
-	if err != nil {
-		return fmt.Errorf("%v: %v", edits, err)
-	}
-	filename := file.uri.Filename()
-	switch {
-	case t.Write:
-		if len(edits) > 0 {
-			ioutil.WriteFile(filename, []byte(newContent), 0644)
-		}
-	case t.Diff:
-		unified, err := diff.ToUnified(filename+".orig", filename, string(file.mapper.Content), sedits)
-		if err != nil {
-			return err
-		}
-		fmt.Print(unified)
-	default:
-		fmt.Print(string(newContent))
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/info.go b/gopls/internal/lsp/cmd/info.go
--- a/gopls/internal/lsp/cmd/info.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/info.go	1969-12-31 16:00:00
@@ -1,246 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"net/url"
-	"os"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/browser"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/tool"
-)
-
-// help implements the help command.
-type help struct {
-	app *Application
-}
-
-func (h *help) Name() string      { return "help" }
-func (h *help) Parent() string    { return h.app.Name() }
-func (h *help) Usage() string     { return "" }
-func (h *help) ShortHelp() string { return "print usage information for subcommands" }
-func (h *help) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-
-Examples:
-$ gopls help                         # main gopls help message
-$ gopls help remote                  # help on 'remote' command
-$ gopls help remote sessions         # help on 'remote sessions' subcommand
-`)
-	printFlagDefaults(f)
-}
-
-// Run prints help information about a subcommand.
-func (h *help) Run(ctx context.Context, args ...string) error {
-	find := func(cmds []tool.Application, name string) tool.Application {
-		for _, cmd := range cmds {
-			if cmd.Name() == name {
-				return cmd
-			}
-		}
-		return nil
-	}
-
-	// Find the subcommand denoted by args (empty => h.app).
-	var cmd tool.Application = h.app
-	for i, arg := range args {
-		cmd = find(getSubcommands(cmd), arg)
-		if cmd == nil {
-			return tool.CommandLineErrorf(
-				"no such subcommand: %s", strings.Join(args[:i+1], " "))
-		}
-	}
-
-	// 'gopls help cmd subcmd' is equivalent to 'gopls cmd subcmd -h'.
-	// The flag package prints the usage information (defined by tool.Run)
-	// when it sees the -h flag.
-	fs := flag.NewFlagSet(cmd.Name(), flag.ExitOnError)
-	return tool.Run(ctx, fs, h.app, append(args[:len(args):len(args)], "-h"))
-}
-
-// version implements the version command.
-type version struct {
-	JSON bool `flag:"json" help:"outputs in json format."`
-
-	app *Application
-}
-
-func (v *version) Name() string      { return "version" }
-func (v *version) Parent() string    { return v.app.Name() }
-func (v *version) Usage() string     { return "" }
-func (v *version) ShortHelp() string { return "print the gopls version information" }
-func (v *version) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), ``)
-	printFlagDefaults(f)
-}
-
-// Run prints version information to stdout.
-func (v *version) Run(ctx context.Context, args ...string) error {
-	var mode = debug.PlainText
-	if v.JSON {
-		mode = debug.JSON
-	}
-
-	return debug.PrintVersionInfo(ctx, os.Stdout, v.app.verbose(), mode)
-}
-
-// bug implements the bug command.
-type bug struct {
-	app *Application
-}
-
-func (b *bug) Name() string      { return "bug" }
-func (b *bug) Parent() string    { return b.app.Name() }
-func (b *bug) Usage() string     { return "" }
-func (b *bug) ShortHelp() string { return "report a bug in gopls" }
-func (b *bug) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), ``)
-	printFlagDefaults(f)
-}
-
-const goplsBugPrefix = "x/tools/gopls: <DESCRIBE THE PROBLEM>"
-const goplsBugHeader = `ATTENTION: Please answer these questions BEFORE submitting your issue. Thanks!
-
-#### What did you do?
-If possible, provide a recipe for reproducing the error.
-A complete runnable program is good.
-A link on play.golang.org is better.
-A failing unit test is the best.
-
-#### What did you expect to see?
-
-
-#### What did you see instead?
-
-
-`
-
-// Run collects some basic information and then prepares an issue ready to
-// be reported.
-func (b *bug) Run(ctx context.Context, args ...string) error {
-	buf := &bytes.Buffer{}
-	fmt.Fprint(buf, goplsBugHeader)
-	debug.PrintVersionInfo(ctx, buf, true, debug.Markdown)
-	body := buf.String()
-	title := strings.Join(args, " ")
-	if !strings.HasPrefix(title, goplsBugPrefix) {
-		title = goplsBugPrefix + title
-	}
-	if !browser.Open("https://github.com/golang/go/issues/new?title=" + url.QueryEscape(title) + "&body=" + url.QueryEscape(body)) {
-		fmt.Print("Please file a new issue at golang.org/issue/new using this template:\n\n")
-		fmt.Print(body)
-	}
-	return nil
-}
-
-type apiJSON struct {
-	app *Application
-}
-
-func (j *apiJSON) Name() string      { return "api-json" }
-func (j *apiJSON) Parent() string    { return j.app.Name() }
-func (j *apiJSON) Usage() string     { return "" }
-func (j *apiJSON) ShortHelp() string { return "print json describing gopls API" }
-func (j *apiJSON) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), ``)
-	printFlagDefaults(f)
-}
-
-func (j *apiJSON) Run(ctx context.Context, args ...string) error {
-	js, err := json.MarshalIndent(source.GeneratedAPIJSON, "", "\t")
-	if err != nil {
-		return err
-	}
-	fmt.Fprint(os.Stdout, string(js))
-	return nil
-}
-
-type licenses struct {
-	app *Application
-}
-
-func (l *licenses) Name() string      { return "licenses" }
-func (l *licenses) Parent() string    { return l.app.Name() }
-func (l *licenses) Usage() string     { return "" }
-func (l *licenses) ShortHelp() string { return "print licenses of included software" }
-func (l *licenses) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), ``)
-	printFlagDefaults(f)
-}
-
-const licensePreamble = `
-gopls is made available under the following BSD-style license:
-
-Copyright (c) 2009 The Go Authors. All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-
-   * Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-   * Redistributions in binary form must reproduce the above
-copyright notice, this list of conditions and the following disclaimer
-in the documentation and/or other materials provided with the
-distribution.
-   * Neither the name of Google Inc. nor the names of its
-contributors may be used to endorse or promote products derived from
-this software without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-gopls implements the LSP specification, which is made available under the following license:
-
-Copyright (c) Microsoft Corporation
-
-All rights reserved.
-
-MIT License
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation
-files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy,
-modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software
-is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
-OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
-BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT
-OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
-gopls also includes software made available under these licenses:
-`
-
-func (l *licenses) Run(ctx context.Context, args ...string) error {
-	opts := source.DefaultOptions()
-	l.app.options(opts)
-	txt := licensePreamble
-	if opts.LicensesText == "" {
-		txt += "(development gopls, license information not available)"
-	} else {
-		txt += opts.LicensesText
-	}
-	fmt.Fprint(os.Stdout, txt)
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/links.go b/gopls/internal/lsp/cmd/links.go
--- a/gopls/internal/lsp/cmd/links.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/links.go	1969-12-31 16:00:00
@@ -1,77 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"os"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// links implements the links verb for gopls.
-type links struct {
-	JSON bool `flag:"json" help:"emit document links in JSON format"`
-
-	app *Application
-}
-
-func (l *links) Name() string      { return "links" }
-func (l *links) Parent() string    { return l.app.Name() }
-func (l *links) Usage() string     { return "[links-flags] <filename>" }
-func (l *links) ShortHelp() string { return "list links in a file" }
-func (l *links) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprintf(f.Output(), `
-Example: list links contained within a file:
-
-	$ gopls links internal/lsp/cmd/check.go
-
-links-flags:
-`)
-	printFlagDefaults(f)
-}
-
-// Run finds all the links within a document
-// - if -json is specified, outputs location range and uri
-// - otherwise, prints the a list of unique links
-func (l *links) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("links expects 1 argument")
-	}
-	conn, err := l.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	uri := from.URI()
-	file := conn.openFile(ctx, uri)
-	if file.err != nil {
-		return file.err
-	}
-	results, err := conn.DocumentLink(ctx, &protocol.DocumentLinkParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		return fmt.Errorf("%v: %v", from, err)
-	}
-	if l.JSON {
-		enc := json.NewEncoder(os.Stdout)
-		enc.SetIndent("", "\t")
-		return enc.Encode(results)
-	}
-	for _, v := range results {
-		fmt.Println(v.Target)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/prepare_rename.go b/gopls/internal/lsp/cmd/prepare_rename.go
--- a/gopls/internal/lsp/cmd/prepare_rename.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/prepare_rename.go	1969-12-31 16:00:00
@@ -1,84 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"errors"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// prepareRename implements the prepare_rename verb for gopls.
-type prepareRename struct {
-	app *Application
-}
-
-func (r *prepareRename) Name() string      { return "prepare_rename" }
-func (r *prepareRename) Parent() string    { return r.app.Name() }
-func (r *prepareRename) Usage() string     { return "<position>" }
-func (r *prepareRename) ShortHelp() string { return "test validity of a rename operation at location" }
-func (r *prepareRename) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls prepare_rename helper/helper.go:8:6
-	$ gopls prepare_rename helper/helper.go:#53
-`)
-	printFlagDefaults(f)
-}
-
-// ErrInvalidRenamePosition is returned when prepareRename is run at a position that
-// is not a candidate for renaming.
-var ErrInvalidRenamePosition = errors.New("request is not valid at the given position")
-
-func (r *prepareRename) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("prepare_rename expects 1 argument (file)")
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-	p := protocol.PrepareRenameParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-			Position:     loc.Range.Start,
-		},
-	}
-	result, err := conn.PrepareRename(ctx, &p)
-	if err != nil {
-		return fmt.Errorf("prepare_rename failed: %w", err)
-	}
-	if result == nil {
-		return ErrInvalidRenamePosition
-	}
-
-	l := protocol.Location{Range: result.Range}
-	s, err := file.mapper.Span(l)
-	if err != nil {
-		return err
-	}
-
-	fmt.Println(s)
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/references.go b/gopls/internal/lsp/cmd/references.go
--- a/gopls/internal/lsp/cmd/references.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/references.go	1969-12-31 16:00:00
@@ -1,92 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// references implements the references verb for gopls
-type references struct {
-	IncludeDeclaration bool `flag:"d,declaration" help:"include the declaration of the specified identifier in the results"`
-
-	app *Application
-}
-
-func (r *references) Name() string      { return "references" }
-func (r *references) Parent() string    { return r.app.Name() }
-func (r *references) Usage() string     { return "[references-flags] <position>" }
-func (r *references) ShortHelp() string { return "display selected identifier's references" }
-func (r *references) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls references helper/helper.go:8:6
-	$ gopls references helper/helper.go:#53
-
-references-flags:
-`)
-	printFlagDefaults(f)
-}
-
-func (r *references) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("references expects 1 argument (position)")
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-	p := protocol.ReferenceParams{
-		Context: protocol.ReferenceContext{
-			IncludeDeclaration: r.IncludeDeclaration,
-		},
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-			Position:     loc.Range.Start,
-		},
-	}
-	locations, err := conn.References(ctx, &p)
-	if err != nil {
-		return err
-	}
-	var spans []string
-	for _, l := range locations {
-		f := conn.openFile(ctx, fileURI(l.URI))
-		// convert location to span for user-friendly 1-indexed line
-		// and column numbers
-		span, err := f.mapper.Span(l)
-		if err != nil {
-			return err
-		}
-		spans = append(spans, fmt.Sprint(span))
-	}
-
-	sort.Strings(spans)
-	for _, s := range spans {
-		fmt.Println(s)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/remote.go b/gopls/internal/lsp/cmd/remote.go
--- a/gopls/internal/lsp/cmd/remote.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/remote.go	1969-12-31 16:00:00
@@ -1,164 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"encoding/json"
-	"errors"
-	"flag"
-	"fmt"
-	"log"
-	"os"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-)
-
-type remote struct {
-	app *Application
-	subcommands
-
-	// For backward compatibility, allow aliasing this command (it was previously
-	// called 'inspect').
-	//
-	// TODO(rFindley): delete this after allowing some transition time in case
-	//                 there were any users of 'inspect' (I suspect not).
-	alias string
-}
-
-func newRemote(app *Application, alias string) *remote {
-	return &remote{
-		app: app,
-		subcommands: subcommands{
-			&listSessions{app: app},
-			&startDebugging{app: app},
-		},
-		alias: alias,
-	}
-}
-
-func (r *remote) Name() string {
-	if r.alias != "" {
-		return r.alias
-	}
-	return "remote"
-}
-
-func (r *remote) Parent() string { return r.app.Name() }
-
-func (r *remote) ShortHelp() string {
-	short := "interact with the gopls daemon"
-	if r.alias != "" {
-		short += " (deprecated: use 'remote')"
-	}
-	return short
-}
-
-// listSessions is an inspect subcommand to list current sessions.
-type listSessions struct {
-	app *Application
-}
-
-func (c *listSessions) Name() string   { return "sessions" }
-func (c *listSessions) Parent() string { return c.app.Name() }
-func (c *listSessions) Usage() string  { return "" }
-func (c *listSessions) ShortHelp() string {
-	return "print information about current gopls sessions"
-}
-
-const listSessionsExamples = `
-Examples:
-
-1) list sessions for the default daemon:
-
-$ gopls -remote=auto remote sessions
-or just
-$ gopls remote sessions
-
-2) list sessions for a specific daemon:
-
-$ gopls -remote=localhost:8082 remote sessions
-`
-
-func (c *listSessions) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), listSessionsExamples)
-	printFlagDefaults(f)
-}
-
-func (c *listSessions) Run(ctx context.Context, args ...string) error {
-	remote := c.app.Remote
-	if remote == "" {
-		remote = "auto"
-	}
-	state, err := lsprpc.QueryServerState(ctx, remote)
-	if err != nil {
-		return err
-	}
-	v, err := json.MarshalIndent(state, "", "\t")
-	if err != nil {
-		log.Fatal(err)
-	}
-	os.Stdout.Write(v)
-	return nil
-}
-
-type startDebugging struct {
-	app *Application
-}
-
-func (c *startDebugging) Name() string  { return "debug" }
-func (c *startDebugging) Usage() string { return "[host:port]" }
-func (c *startDebugging) ShortHelp() string {
-	return "start the debug server"
-}
-
-const startDebuggingExamples = `
-Examples:
-
-1) start a debug server for the default daemon, on an arbitrary port:
-
-$ gopls -remote=auto remote debug
-or just
-$ gopls remote debug
-
-2) start for a specific daemon, on a specific port:
-
-$ gopls -remote=localhost:8082 remote debug localhost:8083
-`
-
-func (c *startDebugging) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), startDebuggingExamples)
-	printFlagDefaults(f)
-}
-
-func (c *startDebugging) Run(ctx context.Context, args ...string) error {
-	if len(args) > 1 {
-		fmt.Fprintln(os.Stderr, c.Usage())
-		return errors.New("invalid usage")
-	}
-	remote := c.app.Remote
-	if remote == "" {
-		remote = "auto"
-	}
-	debugAddr := ""
-	if len(args) > 0 {
-		debugAddr = args[0]
-	}
-	debugArgs := command.DebuggingArgs{
-		Addr: debugAddr,
-	}
-	var result command.DebuggingResult
-	if err := lsprpc.ExecuteCommand(ctx, remote, command.StartDebugging.ID(), debugArgs, &result); err != nil {
-		return err
-	}
-	if len(result.URLs) == 0 {
-		return errors.New("no debugging URLs")
-	}
-	for _, url := range result.URLs {
-		fmt.Printf("debugging on %s\n", url)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/rename.go b/gopls/internal/lsp/cmd/rename.go
--- a/gopls/internal/lsp/cmd/rename.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/rename.go	1969-12-31 16:00:00
@@ -1,130 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/tool"
-)
-
-// rename implements the rename verb for gopls.
-type rename struct {
-	Diff     bool `flag:"d,diff" help:"display diffs instead of rewriting files"`
-	Write    bool `flag:"w,write" help:"write result to (source) file instead of stdout"`
-	Preserve bool `flag:"preserve" help:"preserve original files"`
-
-	app *Application
-}
-
-func (r *rename) Name() string      { return "rename" }
-func (r *rename) Parent() string    { return r.app.Name() }
-func (r *rename) Usage() string     { return "[rename-flags] <position> <name>" }
-func (r *rename) ShortHelp() string { return "rename selected identifier" }
-func (r *rename) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-based location (:line:column or :#position) of the thing to change
-	$ gopls rename helper/helper.go:8:6 Foo
-	$ gopls rename helper/helper.go:#53 Foo
-
-rename-flags:
-`)
-	printFlagDefaults(f)
-}
-
-// Run renames the specified identifier and either;
-// - if -w is specified, updates the file(s) in place;
-// - if -d is specified, prints out unified diffs of the changes; or
-// - otherwise, prints the new versions to stdout.
-func (r *rename) Run(ctx context.Context, args ...string) error {
-	if len(args) != 2 {
-		return tool.CommandLineErrorf("definition expects 2 arguments (position, new name)")
-	}
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-	p := protocol.RenameParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-		NewName:      args[1],
-	}
-	edit, err := conn.Rename(ctx, &p)
-	if err != nil {
-		return err
-	}
-	var orderedURIs []string
-	edits := map[span.URI][]protocol.TextEdit{}
-	for _, c := range edit.DocumentChanges {
-		if c.TextDocumentEdit != nil {
-			uri := fileURI(c.TextDocumentEdit.TextDocument.URI)
-			edits[uri] = append(edits[uri], c.TextDocumentEdit.Edits...)
-			orderedURIs = append(orderedURIs, string(uri))
-		}
-	}
-	sort.Strings(orderedURIs)
-	changeCount := len(orderedURIs)
-
-	for _, u := range orderedURIs {
-		uri := span.URIFromURI(u)
-		cmdFile := conn.openFile(ctx, uri)
-		filename := cmdFile.uri.Filename()
-
-		newContent, renameEdits, err := source.ApplyProtocolEdits(cmdFile.mapper, edits[uri])
-		if err != nil {
-			return fmt.Errorf("%v: %v", edits, err)
-		}
-
-		switch {
-		case r.Write:
-			fmt.Fprintln(os.Stderr, filename)
-			if r.Preserve {
-				if err := os.Rename(filename, filename+".orig"); err != nil {
-					return fmt.Errorf("%v: %v", edits, err)
-				}
-			}
-			ioutil.WriteFile(filename, []byte(newContent), 0644)
-		case r.Diff:
-			unified, err := diff.ToUnified(filename+".orig", filename, string(cmdFile.mapper.Content), renameEdits)
-			if err != nil {
-				return err
-			}
-			fmt.Print(unified)
-		default:
-			if len(orderedURIs) > 1 {
-				fmt.Printf("%s:\n", filepath.Base(filename))
-			}
-			fmt.Print(string(newContent))
-			if changeCount > 1 { // if this wasn't last change, print newline
-				fmt.Println()
-			}
-			changeCount -= 1
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/semantictokens.go b/gopls/internal/lsp/cmd/semantictokens.go
--- a/gopls/internal/lsp/cmd/semantictokens.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/semantictokens.go	1969-12-31 16:00:00
@@ -1,225 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"bytes"
-	"context"
-	"flag"
-	"fmt"
-	"go/parser"
-	"go/token"
-	"io/ioutil"
-	"log"
-	"os"
-	"unicode/utf8"
-
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// generate semantic tokens and interpolate them in the file
-
-// The output is the input file decorated with comments showing the
-// syntactic tokens. The comments are stylized:
-//   /*<arrow><length>,<token type>,[<modifiers]*/
-// For most occurrences, the comment comes just before the token it
-// describes, and arrow is a right arrow. If the token is inside a string
-// the comment comes just after the string, and the arrow is a left arrow.
-// <length> is the length of the token in runes, <token type> is one
-// of the supported semantic token types, and <modifiers. is a
-// (possibly empty) list of token type modifiers.
-
-// There are 3 coordinate systems for lines and character offsets in lines
-// LSP (what's returned from semanticTokens()):
-//    0-based: the first line is line 0, the first character of a line
-//      is character 0, and characters are counted as UTF-16 code points
-// gopls (and Go error messages):
-//    1-based: the first line is line1, the first chararcter of a line
-//      is character 0, and characters are counted as bytes
-// internal (as used in marks, and lines:=bytes.Split(buf, '\n'))
-//    0-based: lines and character positions are 1 less than in
-//      the gopls coordinate system
-
-type semtok struct {
-	app *Application
-}
-
-var colmap *protocol.ColumnMapper
-
-func (c *semtok) Name() string      { return "semtok" }
-func (c *semtok) Parent() string    { return c.app.Name() }
-func (c *semtok) Usage() string     { return "<filename>" }
-func (c *semtok) ShortHelp() string { return "show semantic tokens for the specified file" }
-func (c *semtok) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example: show the semantic tokens for this file:
-
-	$ gopls semtok internal/lsp/cmd/semtok.go
-`)
-	printFlagDefaults(f)
-}
-
-// Run performs the semtok on the files specified by args and prints the
-// results to stdout in the format described above.
-func (c *semtok) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return fmt.Errorf("expected one file name, got %d", len(args))
-	}
-	// perhaps simpler if app had just had a FlagSet member
-	origOptions := c.app.options
-	c.app.options = func(opts *source.Options) {
-		origOptions(opts)
-		opts.SemanticTokens = true
-	}
-	conn, err := c.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-	uri := span.URIFromPath(args[0])
-	file := conn.openFile(ctx, uri)
-	if file.err != nil {
-		return file.err
-	}
-
-	buf, err := ioutil.ReadFile(args[0])
-	if err != nil {
-		return err
-	}
-	lines := bytes.Split(buf, []byte{'\n'})
-	p := &protocol.SemanticTokensRangeParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Range: protocol.Range{Start: protocol.Position{Line: 0, Character: 0},
-			End: protocol.Position{
-				Line:      uint32(len(lines) - 1),
-				Character: uint32(len(lines[len(lines)-1]))},
-		},
-	}
-	resp, err := conn.semanticTokens(ctx, p)
-	if err != nil {
-		return err
-	}
-	fset := token.NewFileSet()
-	f, err := parser.ParseFile(fset, args[0], buf, 0)
-	if err != nil {
-		log.Printf("parsing %s failed %v", args[0], err)
-		return err
-	}
-	tok := fset.File(f.Pos())
-	if tok == nil {
-		// can't happen; just parsed this file
-		return fmt.Errorf("can't find %s in fset", args[0])
-	}
-	colmap = protocol.NewColumnMapper(uri, buf)
-	err = decorate(file.uri.Filename(), resp.Data)
-	if err != nil {
-		return err
-	}
-	return nil
-}
-
-type mark struct {
-	line, offset int // 1-based, from RangeSpan
-	len          int // bytes, not runes
-	typ          string
-	mods         []string
-}
-
-// prefixes for semantic token comments
-const (
-	SemanticLeft  = "/*⇐"
-	SemanticRight = "/*⇒"
-)
-
-func markLine(m mark, lines [][]byte) {
-	l := lines[m.line-1] // mx is 1-based
-	length := utf8.RuneCount(l[m.offset-1 : m.offset-1+m.len])
-	splitAt := m.offset - 1
-	insert := ""
-	if m.typ == "namespace" && m.offset-1+m.len < len(l) && l[m.offset-1+m.len] == '"' {
-		// it is the last component of an import spec
-		// cannot put a comment inside a string
-		insert = fmt.Sprintf("%s%d,namespace,[]*/", SemanticLeft, length)
-		splitAt = m.offset + m.len
-	} else {
-		// be careful not to generate //*
-		spacer := ""
-		if splitAt-1 >= 0 && l[splitAt-1] == '/' {
-			spacer = " "
-		}
-		insert = fmt.Sprintf("%s%s%d,%s,%v*/", spacer, SemanticRight, length, m.typ, m.mods)
-	}
-	x := append([]byte(insert), l[splitAt:]...)
-	l = append(l[:splitAt], x...)
-	lines[m.line-1] = l
-}
-
-func decorate(file string, result []uint32) error {
-	buf, err := ioutil.ReadFile(file)
-	if err != nil {
-		return err
-	}
-	marks := newMarks(result)
-	if len(marks) == 0 {
-		return nil
-	}
-	lines := bytes.Split(buf, []byte{'\n'})
-	for i := len(marks) - 1; i >= 0; i-- {
-		mx := marks[i]
-		markLine(mx, lines)
-	}
-	os.Stdout.Write(bytes.Join(lines, []byte{'\n'}))
-	return nil
-}
-
-func newMarks(d []uint32) []mark {
-	ans := []mark{}
-	// the following two loops could be merged, at the cost
-	// of making the logic slightly more complicated to understand
-	// first, convert from deltas to absolute, in LSP coordinates
-	lspLine := make([]uint32, len(d)/5)
-	lspChar := make([]uint32, len(d)/5)
-	var line, char uint32
-	for i := 0; 5*i < len(d); i++ {
-		lspLine[i] = line + d[5*i+0]
-		if d[5*i+0] > 0 {
-			char = 0
-		}
-		lspChar[i] = char + d[5*i+1]
-		char = lspChar[i]
-		line = lspLine[i]
-	}
-	// second, convert to gopls coordinates
-	for i := 0; 5*i < len(d); i++ {
-		pr := protocol.Range{
-			Start: protocol.Position{
-				Line:      lspLine[i],
-				Character: lspChar[i],
-			},
-			End: protocol.Position{
-				Line:      lspLine[i],
-				Character: lspChar[i] + d[5*i+2],
-			},
-		}
-		spn, err := colmap.RangeSpan(pr)
-		if err != nil {
-			log.Fatal(err)
-		}
-		m := mark{
-			line:   spn.Start().Line(),
-			offset: spn.Start().Column(),
-			len:    spn.End().Column() - spn.Start().Column(),
-			typ:    lsp.SemType(int(d[5*i+3])),
-			mods:   lsp.SemMods(int(d[5*i+4])),
-		}
-		ans = append(ans, m)
-	}
-	return ans
-}
diff -urN a/gopls/internal/lsp/cmd/serve.go b/gopls/internal/lsp/cmd/serve.go
--- a/gopls/internal/lsp/cmd/serve.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/serve.go	1969-12-31 16:00:00
@@ -1,130 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"errors"
-	"flag"
-	"fmt"
-	"io"
-	"log"
-	"os"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/fakenet"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/tool"
-)
-
-// Serve is a struct that exposes the configurable parts of the LSP server as
-// flags, in the right form for tool.Main to consume.
-type Serve struct {
-	Logfile     string        `flag:"logfile" help:"filename to log to. if value is \"auto\", then logging to a default output file is enabled"`
-	Mode        string        `flag:"mode" help:"no effect"`
-	Port        int           `flag:"port" help:"port on which to run gopls for debugging purposes"`
-	Address     string        `flag:"listen" help:"address on which to listen for remote connections. If prefixed by 'unix;', the subsequent address is assumed to be a unix domain socket. Otherwise, TCP is used."`
-	IdleTimeout time.Duration `flag:"listen.timeout" help:"when used with -listen, shut down the server when there are no connected clients for this duration"`
-	Trace       bool          `flag:"rpc.trace" help:"print the full rpc trace in lsp inspector format"`
-	Debug       string        `flag:"debug" help:"serve debug information on the supplied address"`
-
-	RemoteListenTimeout time.Duration `flag:"remote.listen.timeout" help:"when used with -remote=auto, the -listen.timeout value used to start the daemon"`
-	RemoteDebug         string        `flag:"remote.debug" help:"when used with -remote=auto, the -debug value used to start the daemon"`
-	RemoteLogfile       string        `flag:"remote.logfile" help:"when used with -remote=auto, the -logfile value used to start the daemon"`
-
-	app *Application
-}
-
-func (s *Serve) Name() string   { return "serve" }
-func (s *Serve) Parent() string { return s.app.Name() }
-func (s *Serve) Usage() string  { return "[server-flags]" }
-func (s *Serve) ShortHelp() string {
-	return "run a server for Go code using the Language Server Protocol"
-}
-func (s *Serve) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `  gopls [flags] [server-flags]
-
-The server communicates using JSONRPC2 on stdin and stdout, and is intended to be run directly as
-a child of an editor process.
-
-server-flags:
-`)
-	printFlagDefaults(f)
-}
-
-func (s *Serve) remoteArgs(network, address string) []string {
-	args := []string{"serve",
-		"-listen", fmt.Sprintf(`%s;%s`, network, address),
-	}
-	if s.RemoteDebug != "" {
-		args = append(args, "-debug", s.RemoteDebug)
-	}
-	if s.RemoteListenTimeout != 0 {
-		args = append(args, "-listen.timeout", s.RemoteListenTimeout.String())
-	}
-	if s.RemoteLogfile != "" {
-		args = append(args, "-logfile", s.RemoteLogfile)
-	}
-	return args
-}
-
-// Run configures a server based on the flags, and then runs it.
-// It blocks until the server shuts down.
-func (s *Serve) Run(ctx context.Context, args ...string) error {
-	if len(args) > 0 {
-		return tool.CommandLineErrorf("server does not take arguments, got %v", args)
-	}
-
-	di := debug.GetInstance(ctx)
-	isDaemon := s.Address != "" || s.Port != 0
-	if di != nil {
-		closeLog, err := di.SetLogFile(s.Logfile, isDaemon)
-		if err != nil {
-			return err
-		}
-		defer closeLog()
-		di.ServerAddress = s.Address
-		di.MonitorMemory(ctx)
-		di.Serve(ctx, s.Debug)
-	}
-	var ss jsonrpc2.StreamServer
-	if s.app.Remote != "" {
-		var err error
-		ss, err = lsprpc.NewForwarder(s.app.Remote, s.remoteArgs)
-		if err != nil {
-			return fmt.Errorf("creating forwarder: %w", err)
-		}
-	} else {
-		ss = lsprpc.NewStreamServer(cache.New(nil, nil), isDaemon, s.app.options)
-	}
-
-	var network, addr string
-	if s.Address != "" {
-		network, addr = lsprpc.ParseAddr(s.Address)
-	}
-	if s.Port != 0 {
-		network = "tcp"
-		addr = fmt.Sprintf(":%v", s.Port)
-	}
-	if addr != "" {
-		log.Printf("Gopls daemon: listening on %s network, address %s...", network, addr)
-		defer log.Printf("Gopls daemon: exiting")
-		return jsonrpc2.ListenAndServe(ctx, network, addr, ss, s.IdleTimeout)
-	}
-	stream := jsonrpc2.NewHeaderStream(fakenet.NewConn("stdio", os.Stdin, os.Stdout))
-	if s.Trace && di != nil {
-		stream = protocol.LoggingStream(stream, di.LogWriter)
-	}
-	conn := jsonrpc2.NewConn(stream)
-	err := ss.ServeStream(ctx, conn)
-	if errors.Is(err, io.EOF) {
-		return nil
-	}
-	return err
-}
diff -urN a/gopls/internal/lsp/cmd/signature.go b/gopls/internal/lsp/cmd/signature.go
--- a/gopls/internal/lsp/cmd/signature.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/signature.go	1969-12-31 16:00:00
@@ -1,87 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// signature implements the signature verb for gopls
-type signature struct {
-	app *Application
-}
-
-func (r *signature) Name() string      { return "signature" }
-func (r *signature) Parent() string    { return r.app.Name() }
-func (r *signature) Usage() string     { return "<position>" }
-func (r *signature) ShortHelp() string { return "display selected identifier's signature" }
-func (r *signature) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls signature helper/helper.go:8:6
-	$ gopls signature helper/helper.go:#53
-`)
-	printFlagDefaults(f)
-}
-
-func (r *signature) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("signature expects 1 argument (position)")
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	file := conn.openFile(ctx, from.URI())
-	if file.err != nil {
-		return file.err
-	}
-
-	loc, err := file.mapper.Location(from)
-	if err != nil {
-		return err
-	}
-
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(from.URI()),
-		},
-		Position: loc.Range.Start,
-	}
-	p := protocol.SignatureHelpParams{
-		TextDocumentPositionParams: tdpp,
-	}
-
-	s, err := conn.SignatureHelp(ctx, &p)
-	if err != nil {
-		return err
-	}
-
-	if s == nil || len(s.Signatures) == 0 {
-		return tool.CommandLineErrorf("%v: not a function", from)
-	}
-
-	// there is only ever one possible signature,
-	// see toProtocolSignatureHelp in lsp/signature_help.go
-	signature := s.Signatures[0]
-	fmt.Printf("%s\n", signature.Label)
-	if signature.Documentation != "" {
-		fmt.Printf("\n%s\n", signature.Documentation)
-	}
-
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/subcommands.go b/gopls/internal/lsp/cmd/subcommands.go
--- a/gopls/internal/lsp/cmd/subcommands.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/subcommands.go	1969-12-31 16:00:00
@@ -1,59 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"text/tabwriter"
-
-	"golang.org/x/tools/internal/tool"
-)
-
-// subcommands is a helper that may be embedded for commands that delegate to
-// subcommands.
-type subcommands []tool.Application
-
-func (s subcommands) DetailedHelp(f *flag.FlagSet) {
-	w := tabwriter.NewWriter(f.Output(), 0, 0, 2, ' ', 0)
-	defer w.Flush()
-	fmt.Fprint(w, "\nSubcommand:\n")
-	for _, c := range s {
-		fmt.Fprintf(w, "  %s\t%s\n", c.Name(), c.ShortHelp())
-	}
-	printFlagDefaults(f)
-}
-
-func (s subcommands) Usage() string { return "<subcommand> [arg]..." }
-
-func (s subcommands) Run(ctx context.Context, args ...string) error {
-	if len(args) == 0 {
-		return tool.CommandLineErrorf("must provide subcommand")
-	}
-	command, args := args[0], args[1:]
-	for _, c := range s {
-		if c.Name() == command {
-			s := flag.NewFlagSet(c.Name(), flag.ExitOnError)
-			return tool.Run(ctx, s, c, args)
-		}
-	}
-	return tool.CommandLineErrorf("unknown subcommand %v", command)
-}
-
-func (s subcommands) Commands() []tool.Application { return s }
-
-// getSubcommands returns the subcommands of a given Application.
-func getSubcommands(a tool.Application) []tool.Application {
-	// This interface is satisfied both by tool.Applications
-	// that embed subcommands, and by *cmd.Application.
-	type hasCommands interface {
-		Commands() []tool.Application
-	}
-	if sub, ok := a.(hasCommands); ok {
-		return sub.Commands()
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/suggested_fix.go b/gopls/internal/lsp/cmd/suggested_fix.go
--- a/gopls/internal/lsp/cmd/suggested_fix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/suggested_fix.go	1969-12-31 16:00:00
@@ -1,166 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"io/ioutil"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/tool"
-)
-
-// suggestedFix implements the fix verb for gopls.
-type suggestedFix struct {
-	Diff  bool `flag:"d,diff" help:"display diffs instead of rewriting files"`
-	Write bool `flag:"w,write" help:"write result to (source) file instead of stdout"`
-	All   bool `flag:"a,all" help:"apply all fixes, not just preferred fixes"`
-
-	app *Application
-}
-
-func (s *suggestedFix) Name() string      { return "fix" }
-func (s *suggestedFix) Parent() string    { return s.app.Name() }
-func (s *suggestedFix) Usage() string     { return "[fix-flags] <filename>" }
-func (s *suggestedFix) ShortHelp() string { return "apply suggested fixes" }
-func (s *suggestedFix) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprintf(f.Output(), `
-Example: apply suggested fixes for this file
-	$ gopls fix -w internal/lsp/cmd/check.go
-
-fix-flags:
-`)
-	printFlagDefaults(f)
-}
-
-// Run performs diagnostic checks on the file specified and either;
-// - if -w is specified, updates the file in place;
-// - if -d is specified, prints out unified diffs of the changes; or
-// - otherwise, prints the new versions to stdout.
-func (s *suggestedFix) Run(ctx context.Context, args ...string) error {
-	if len(args) < 1 {
-		return tool.CommandLineErrorf("fix expects at least 1 argument")
-	}
-	conn, err := s.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	uri := from.URI()
-	file := conn.openFile(ctx, uri)
-	if file.err != nil {
-		return file.err
-	}
-
-	if err := conn.diagnoseFiles(ctx, []span.URI{uri}); err != nil {
-		return err
-	}
-	conn.Client.filesMu.Lock()
-	defer conn.Client.filesMu.Unlock()
-
-	codeActionKinds := []protocol.CodeActionKind{protocol.QuickFix}
-	if len(args) > 1 {
-		codeActionKinds = []protocol.CodeActionKind{}
-		for _, k := range args[1:] {
-			codeActionKinds = append(codeActionKinds, protocol.CodeActionKind(k))
-		}
-	}
-
-	rng, err := file.mapper.Range(from)
-	if err != nil {
-		return err
-	}
-	p := protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Context: protocol.CodeActionContext{
-			Only:        codeActionKinds,
-			Diagnostics: file.diagnostics,
-		},
-		Range: rng,
-	}
-	actions, err := conn.CodeAction(ctx, &p)
-	if err != nil {
-		return fmt.Errorf("%v: %v", from, err)
-	}
-	var edits []protocol.TextEdit
-	for _, a := range actions {
-		if a.Command != nil {
-			return fmt.Errorf("ExecuteCommand is not yet supported on the command line")
-		}
-		if !a.IsPreferred && !s.All {
-			continue
-		}
-		if !from.HasPosition() {
-			for _, c := range a.Edit.DocumentChanges {
-				if c.TextDocumentEdit != nil {
-					if fileURI(c.TextDocumentEdit.TextDocument.URI) == uri {
-						edits = append(edits, c.TextDocumentEdit.Edits...)
-					}
-				}
-			}
-			continue
-		}
-		// If the span passed in has a position, then we need to find
-		// the codeaction that has the same range as the passed in span.
-		for _, diag := range a.Diagnostics {
-			spn, err := file.mapper.RangeSpan(diag.Range)
-			if err != nil {
-				continue
-			}
-			if span.ComparePoint(from.Start(), spn.Start()) == 0 {
-				for _, c := range a.Edit.DocumentChanges {
-					if c.TextDocumentEdit != nil {
-						if fileURI(c.TextDocumentEdit.TextDocument.URI) == uri {
-							edits = append(edits, c.TextDocumentEdit.Edits...)
-						}
-					}
-				}
-				break
-			}
-		}
-
-		// If suggested fix is not a diagnostic, still must collect edits.
-		if len(a.Diagnostics) == 0 {
-			for _, c := range a.Edit.DocumentChanges {
-				if c.TextDocumentEdit != nil {
-					if fileURI(c.TextDocumentEdit.TextDocument.URI) == uri {
-						edits = append(edits, c.TextDocumentEdit.Edits...)
-					}
-				}
-			}
-		}
-	}
-
-	newContent, sedits, err := source.ApplyProtocolEdits(file.mapper, edits)
-	if err != nil {
-		return fmt.Errorf("%v: %v", edits, err)
-	}
-
-	filename := file.uri.Filename()
-	switch {
-	case s.Write:
-		if len(edits) > 0 {
-			ioutil.WriteFile(filename, []byte(newContent), 0644)
-		}
-	case s.Diff:
-		diffs, err := diff.ToUnified(filename+".orig", filename, string(file.mapper.Content), sedits)
-		if err != nil {
-			return err
-		}
-		fmt.Print(diffs)
-	default:
-		fmt.Print(string(newContent))
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/symbols.go b/gopls/internal/lsp/cmd/symbols.go
--- a/gopls/internal/lsp/cmd/symbols.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/symbols.go	1969-12-31 16:00:00
@@ -1,116 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/tool"
-)
-
-// symbols implements the symbols verb for gopls
-type symbols struct {
-	app *Application
-}
-
-func (r *symbols) Name() string      { return "symbols" }
-func (r *symbols) Parent() string    { return r.app.Name() }
-func (r *symbols) Usage() string     { return "<file>" }
-func (r *symbols) ShortHelp() string { return "display selected file's symbols" }
-func (r *symbols) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-	$ gopls symbols helper/helper.go
-`)
-	printFlagDefaults(f)
-}
-func (r *symbols) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("symbols expects 1 argument (position)")
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	from := span.Parse(args[0])
-	p := protocol.DocumentSymbolParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(from.URI()),
-		},
-	}
-	symbols, err := conn.DocumentSymbol(ctx, &p)
-	if err != nil {
-		return err
-	}
-	for _, s := range symbols {
-		if m, ok := s.(map[string]interface{}); ok {
-			s, err = mapToSymbol(m)
-			if err != nil {
-				return err
-			}
-		}
-		switch t := s.(type) {
-		case protocol.DocumentSymbol:
-			printDocumentSymbol(t)
-		case protocol.SymbolInformation:
-			printSymbolInformation(t)
-		}
-	}
-	return nil
-}
-
-func mapToSymbol(m map[string]interface{}) (interface{}, error) {
-	b, err := json.Marshal(m)
-	if err != nil {
-		return nil, err
-	}
-
-	if _, ok := m["selectionRange"]; ok {
-		var s protocol.DocumentSymbol
-		if err := json.Unmarshal(b, &s); err != nil {
-			return nil, err
-		}
-		return s, nil
-	}
-
-	var s protocol.SymbolInformation
-	if err := json.Unmarshal(b, &s); err != nil {
-		return nil, err
-	}
-	return s, nil
-}
-
-func printDocumentSymbol(s protocol.DocumentSymbol) {
-	fmt.Printf("%s %s %s\n", s.Name, s.Kind, positionToString(s.SelectionRange))
-	// Sort children for consistency
-	sort.Slice(s.Children, func(i, j int) bool {
-		return s.Children[i].Name < s.Children[j].Name
-	})
-	for _, c := range s.Children {
-		fmt.Printf("\t%s %s %s\n", c.Name, c.Kind, positionToString(c.SelectionRange))
-	}
-}
-
-func printSymbolInformation(s protocol.SymbolInformation) {
-	fmt.Printf("%s %s %s\n", s.Name, s.Kind, positionToString(s.Location.Range))
-}
-
-func positionToString(r protocol.Range) string {
-	return fmt.Sprintf("%v:%v-%v:%v",
-		r.Start.Line+1,
-		r.Start.Character+1,
-		r.End.Line+1,
-		r.End.Character+1,
-	)
-}
diff -urN a/gopls/internal/lsp/cmd/test/call_hierarchy.go b/gopls/internal/lsp/cmd/test/call_hierarchy.go
--- a/gopls/internal/lsp/cmd/test/call_hierarchy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/call_hierarchy.go	1969-12-31 16:00:00
@@ -1,85 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"sort"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) CallHierarchy(t *testing.T, spn span.Span, expectedCalls *tests.CallHierarchyResult) {
-	collectCallSpansString := func(callItems []protocol.CallHierarchyItem) string {
-		var callSpans []string
-		for _, call := range callItems {
-			mapper, err := r.data.Mapper(call.URI.SpanURI())
-			if err != nil {
-				t.Fatal(err)
-			}
-			callSpan, err := mapper.Span(protocol.Location{URI: call.URI, Range: call.Range})
-			if err != nil {
-				t.Fatal(err)
-			}
-			callSpans = append(callSpans, fmt.Sprint(callSpan))
-		}
-		// to make tests deterministic
-		sort.Strings(callSpans)
-		return r.Normalize(strings.Join(callSpans, "\n"))
-	}
-
-	expectIn, expectOut := collectCallSpansString(expectedCalls.IncomingCalls), collectCallSpansString(expectedCalls.OutgoingCalls)
-	expectIdent := r.Normalize(fmt.Sprint(spn))
-
-	uri := spn.URI()
-	filename := uri.Filename()
-	target := filename + fmt.Sprintf(":%v:%v", spn.Start().Line(), spn.Start().Column())
-
-	got, stderr := r.NormalizeGoplsCmd(t, "call_hierarchy", target)
-	if stderr != "" {
-		t.Fatalf("call_hierarchy failed for %s: %s", target, stderr)
-	}
-
-	gotIn, gotIdent, gotOut := cleanCallHierarchyCmdResult(got)
-	if expectIn != gotIn {
-		t.Errorf("incoming calls call_hierarchy failed for %s expected:\n%s\ngot:\n%s", target, expectIn, gotIn)
-	}
-	if expectIdent != gotIdent {
-		t.Errorf("call_hierarchy failed for %s expected:\n%s\ngot:\n%s", target, expectIdent, gotIdent)
-	}
-	if expectOut != gotOut {
-		t.Errorf("outgoing calls call_hierarchy failed for %s expected:\n%s\ngot:\n%s", target, expectOut, gotOut)
-	}
-
-}
-
-// parses function URI and Range from call hierarchy cmd output to
-// incoming, identifier and outgoing calls (returned in that order)
-// ex: "identifier: function d at .../callhierarchy/callhierarchy.go:19:6-7" -> ".../callhierarchy/callhierarchy.go:19:6-7"
-func cleanCallHierarchyCmdResult(output string) (incoming, ident, outgoing string) {
-	var incomingCalls, outgoingCalls []string
-	for _, out := range strings.Split(output, "\n") {
-		if out == "" {
-			continue
-		}
-
-		callLocation := out[strings.LastIndex(out, " ")+1:]
-		if strings.HasPrefix(out, "caller") {
-			incomingCalls = append(incomingCalls, callLocation)
-		} else if strings.HasPrefix(out, "callee") {
-			outgoingCalls = append(outgoingCalls, callLocation)
-		} else {
-			ident = callLocation
-		}
-	}
-	sort.Strings(incomingCalls)
-	sort.Strings(outgoingCalls)
-	incoming, outgoing = strings.Join(incomingCalls, "\n"), strings.Join(outgoingCalls, "\n")
-	return
-}
diff -urN a/gopls/internal/lsp/cmd/test/check.go b/gopls/internal/lsp/cmd/test/check.go
--- a/gopls/internal/lsp/cmd/test/check.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/check.go	1969-12-31 16:00:00
@@ -1,63 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"io/ioutil"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// Diagnostics runs the "gopls check" command on a single file, parses
-// its diagnostics, and compares against the expectations defined by
-// markers in the source file.
-func (r *runner) Diagnostics(t *testing.T, uri span.URI, want []*source.Diagnostic) {
-	out, _ := r.runGoplsCmd(t, "check", uri.Filename())
-
-	content, err := ioutil.ReadFile(uri.Filename())
-	if err != nil {
-		t.Fatal(err)
-	}
-	mapper := protocol.NewColumnMapper(uri, content)
-
-	// Parse command output into a set of diagnostics.
-	var got []*source.Diagnostic
-	for _, line := range strings.Split(out, "\n") {
-		if line == "" {
-			continue // skip blank
-		}
-		parts := strings.SplitN(line, ": ", 2) // "span: message"
-		if len(parts) != 2 {
-			t.Fatalf("output line not of form 'span: message': %q", line)
-		}
-		spn, message := span.Parse(parts[0]), parts[1]
-		rng, err := mapper.Range(spn)
-		if err != nil {
-			t.Fatal(err)
-		}
-		// Set only the fields needed by DiffDiagnostics.
-		got = append(got, &source.Diagnostic{
-			URI:     uri,
-			Range:   rng,
-			Message: message,
-		})
-	}
-
-	// Don't expect fields that we can't populate from the command output.
-	for _, diag := range want {
-		if diag.Source == "no_diagnostics" {
-			continue // see DiffDiagnostics
-		}
-		diag.Source = ""
-		diag.Severity = 0
-	}
-
-	tests.CompareDiagnostics(t, uri, want, got)
-}
diff -urN a/gopls/internal/lsp/cmd/test/cmdtest.go b/gopls/internal/lsp/cmd/test/cmdtest.go
--- a/gopls/internal/lsp/cmd/test/cmdtest.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/cmdtest.go	1969-12-31 16:00:00
@@ -1,176 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package cmdtest contains the test suite for the command line behavior of gopls.
-package cmdtest
-
-import (
-	"bytes"
-	"context"
-	"flag"
-	"fmt"
-	"io"
-	"os"
-	"runtime"
-	"sync"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/cmd"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-	"golang.org/x/tools/internal/tool"
-)
-
-type runner struct {
-	data        *tests.Data
-	ctx         context.Context
-	options     func(*source.Options)
-	normalizers []tests.Normalizer
-	remote      string
-}
-
-func TestCommandLine(t *testing.T, testdata string, options func(*source.Options)) {
-	// On Android, the testdata directory is not copied to the runner.
-	if runtime.GOOS == "android" {
-		t.Skip("testdata directory not present on android")
-	}
-	tests.RunTests(t, testdata, false, func(t *testing.T, datum *tests.Data) {
-		ctx := tests.Context(t)
-		ts := NewTestServer(ctx, options)
-		tests.Run(t, NewRunner(datum, ctx, ts.Addr, options), datum)
-		cmd.CloseTestConnections(ctx)
-	})
-}
-
-func NewTestServer(ctx context.Context, options func(*source.Options)) *servertest.TCPServer {
-	ctx = debug.WithInstance(ctx, "", "")
-	cache := cache.New(nil, nil)
-	ss := lsprpc.NewStreamServer(cache, false, options)
-	return servertest.NewTCPServer(ctx, ss, nil)
-}
-
-func NewRunner(data *tests.Data, ctx context.Context, remote string, options func(*source.Options)) *runner {
-	return &runner{
-		data:        data,
-		ctx:         ctx,
-		options:     options,
-		normalizers: tests.CollectNormalizers(data.Exported),
-		remote:      remote,
-	}
-}
-
-func (r *runner) CodeLens(t *testing.T, uri span.URI, want []protocol.CodeLens) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) Completion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) CompletionSnippet(t *testing.T, src span.Span, expected tests.CompletionSnippet, placeholders bool, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) UnimportedCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) DeepCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) FuzzyCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) CaseSensitiveCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) RankCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	//TODO: add command line completions tests when it works
-}
-
-func (r *runner) FunctionExtraction(t *testing.T, start span.Span, end span.Span) {
-	//TODO: function extraction not supported on command line
-}
-
-func (r *runner) MethodExtraction(t *testing.T, start span.Span, end span.Span) {
-	//TODO: function extraction not supported on command line
-}
-
-func (r *runner) AddImport(t *testing.T, uri span.URI, expectedImport string) {
-	//TODO: import addition not supported on command line
-}
-
-func (r *runner) Hover(t *testing.T, spn span.Span, info string) {
-	//TODO: hovering not supported on command line
-}
-
-func (r *runner) InlayHints(t *testing.T, spn span.Span) {
-	// TODO: inlayHints not supported on command line
-}
-
-func (r *runner) SelectionRanges(t *testing.T, spn span.Span) {}
-
-func (r *runner) runGoplsCmd(t testing.TB, args ...string) (string, string) {
-	rStdout, wStdout, err := os.Pipe()
-	if err != nil {
-		t.Fatal(err)
-	}
-	oldStdout := os.Stdout
-	rStderr, wStderr, err := os.Pipe()
-	if err != nil {
-		t.Fatal(err)
-	}
-	oldStderr := os.Stderr
-	stdout, stderr := &bytes.Buffer{}, &bytes.Buffer{}
-	var wg sync.WaitGroup
-	wg.Add(2)
-	go func() {
-		io.Copy(stdout, rStdout)
-		wg.Done()
-	}()
-	go func() {
-		io.Copy(stderr, rStderr)
-		wg.Done()
-	}()
-	os.Stdout, os.Stderr = wStdout, wStderr
-	app := cmd.New("gopls-test", r.data.Config.Dir, r.data.Exported.Config.Env, r.options)
-	remote := r.remote
-	s := flag.NewFlagSet(app.Name(), flag.ExitOnError)
-	err = tool.Run(tests.Context(t), s,
-		app,
-		append([]string{fmt.Sprintf("-remote=internal@%s", remote)}, args...))
-	if err != nil {
-		fmt.Fprint(os.Stderr, err)
-	}
-	wStdout.Close()
-	wStderr.Close()
-	wg.Wait()
-	os.Stdout, os.Stderr = oldStdout, oldStderr
-	rStdout.Close()
-	rStderr.Close()
-	return stdout.String(), stderr.String()
-}
-
-// NormalizeGoplsCmd runs the gopls command and normalizes its output.
-func (r *runner) NormalizeGoplsCmd(t testing.TB, args ...string) (string, string) {
-	stdout, stderr := r.runGoplsCmd(t, args...)
-	return r.Normalize(stdout), r.Normalize(stderr)
-}
-
-func (r *runner) Normalize(s string) string {
-	return tests.Normalize(s, r.normalizers)
-}
-
-func (r *runner) NormalizePrefix(s string) string {
-	return tests.NormalizePrefix(s, r.normalizers)
-}
diff -urN a/gopls/internal/lsp/cmd/test/definition.go b/gopls/internal/lsp/cmd/test/definition.go
--- a/gopls/internal/lsp/cmd/test/definition.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/definition.go	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"runtime"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-type godefMode int
-
-const (
-	plainGodef = godefMode(1 << iota)
-	jsonGoDef
-)
-
-var godefModes = []godefMode{
-	plainGodef,
-	jsonGoDef,
-}
-
-func (r *runner) Definition(t *testing.T, spn span.Span, d tests.Definition) {
-	if d.IsType || d.OnlyHover {
-		// TODO: support type definition, hover queries
-		return
-	}
-	d.Src = span.New(d.Src.URI(), span.NewPoint(0, 0, d.Src.Start().Offset()), span.Point{})
-	for _, mode := range godefModes {
-		args := []string{"definition", "-markdown"}
-		tag := d.Name + "-definition"
-		if mode&jsonGoDef != 0 {
-			tag += "-json"
-			args = append(args, "-json")
-		}
-		uri := d.Src.URI()
-		args = append(args, fmt.Sprint(d.Src))
-		got, _ := r.NormalizeGoplsCmd(t, args...)
-		if mode&jsonGoDef != 0 && runtime.GOOS == "windows" {
-			got = strings.Replace(got, "file:///", "file://", -1)
-		}
-		expect := strings.TrimSpace(string(r.data.Golden(t, tag, uri.Filename(), func() ([]byte, error) {
-			return []byte(got), nil
-		})))
-		if expect != "" && !strings.HasPrefix(got, expect) {
-			tests.CheckSameMarkdown(t, got, expect)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/folding_range.go b/gopls/internal/lsp/cmd/test/folding_range.go
--- a/gopls/internal/lsp/cmd/test/folding_range.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/folding_range.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) FoldingRanges(t *testing.T, spn span.Span) {
-	goldenTag := "foldingRange-cmd"
-	uri := spn.URI()
-	filename := uri.Filename()
-	got, _ := r.NormalizeGoplsCmd(t, "folding_ranges", filename)
-	expect := string(r.data.Golden(t, goldenTag, filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-
-	if expect != got {
-		t.Errorf("folding_ranges failed failed for %s expected:\n%s\ngot:\n%s", filename, expect, got)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/format.go b/gopls/internal/lsp/cmd/test/format.go
--- a/gopls/internal/lsp/cmd/test/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/format.go	1969-12-31 16:00:00
@@ -1,87 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"bytes"
-	"io/ioutil"
-	"os"
-	"regexp"
-	"strings"
-	"testing"
-
-	exec "golang.org/x/sys/execabs"
-
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func (r *runner) Format(t *testing.T, spn span.Span) {
-	tag := "gofmt"
-	uri := spn.URI()
-	filename := uri.Filename()
-	expect := string(r.data.Golden(t, tag, filename, func() ([]byte, error) {
-		cmd := exec.Command("gofmt", filename)
-		contents, _ := cmd.Output() // ignore error, sometimes we have intentionally ungofmt-able files
-		contents = []byte(r.Normalize(fixFileHeader(string(contents))))
-		return contents, nil
-	}))
-	if expect == "" {
-		//TODO: our error handling differs, for now just skip unformattable files
-		t.Skip("Unformattable file")
-	}
-	got, _ := r.NormalizeGoplsCmd(t, "format", filename)
-	if expect != got {
-		t.Errorf("format failed for %s expected:\n%s\ngot:\n%s", filename, expect, got)
-	}
-	// now check we can build a valid unified diff
-	unified, _ := r.NormalizeGoplsCmd(t, "format", "-d", filename)
-	checkUnified(t, filename, expect, unified)
-}
-
-var unifiedHeader = regexp.MustCompile(`^diff -u.*\n(---\s+\S+\.go\.orig)\s+[\d-:. ]+(\n\+\+\+\s+\S+\.go)\s+[\d-:. ]+(\n@@)`)
-
-func fixFileHeader(s string) string {
-	match := unifiedHeader.FindStringSubmatch(s)
-	if match == nil {
-		return s
-	}
-	return strings.Join(append(match[1:], s[len(match[0]):]), "")
-}
-
-func checkUnified(t *testing.T, filename string, expect string, patch string) {
-	testenv.NeedsTool(t, "patch")
-	if strings.Count(patch, "\n+++ ") > 1 {
-		// TODO(golang/go/#34580)
-		t.Skip("multi-file patch tests not supported yet")
-	}
-	applied := ""
-	if patch == "" {
-		applied = expect
-	} else {
-		temp, err := ioutil.TempFile("", "applied")
-		if err != nil {
-			t.Fatal(err)
-		}
-		temp.Close()
-		defer os.Remove(temp.Name())
-		cmd := exec.Command("patch", "-u", "-p0", "-o", temp.Name(), filename)
-		cmd.Stdin = bytes.NewBuffer([]byte(patch))
-		msg, err := cmd.CombinedOutput()
-		if err != nil {
-			t.Errorf("failed applying patch to %s: %v\ngot:\n%s\npatch:\n%s", filename, err, msg, patch)
-			return
-		}
-		out, err := ioutil.ReadFile(temp.Name())
-		if err != nil {
-			t.Errorf("failed reading patched output for %s: %v\n", filename, err)
-			return
-		}
-		applied = string(out)
-	}
-	if expect != applied {
-		t.Errorf("apply unified gave wrong result for %s expected:\n%s\ngot:\n%s\npatch:\n%s", filename, expect, applied, patch)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/highlight.go b/gopls/internal/lsp/cmd/test/highlight.go
--- a/gopls/internal/lsp/cmd/test/highlight.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/highlight.go	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"testing"
-
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) Highlight(t *testing.T, spn span.Span, spans []span.Span) {
-	var expect string
-	for _, l := range spans {
-		expect += fmt.Sprintln(l)
-	}
-	expect = r.Normalize(expect)
-
-	uri := spn.URI()
-	filename := uri.Filename()
-	target := filename + ":" + fmt.Sprint(spn.Start().Line()) + ":" + fmt.Sprint(spn.Start().Column())
-	got, _ := r.NormalizeGoplsCmd(t, "highlight", target)
-	if expect != got {
-		t.Errorf("highlight failed for %s expected:\n%s\ngot:\n%s", target, expect, got)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/implementation.go b/gopls/internal/lsp/cmd/test/implementation.go
--- a/gopls/internal/lsp/cmd/test/implementation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/implementation.go	1969-12-31 16:00:00
@@ -1,37 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"sort"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) Implementation(t *testing.T, spn span.Span, imps []span.Span) {
-	var itemStrings []string
-	for _, i := range imps {
-		itemStrings = append(itemStrings, fmt.Sprint(i))
-	}
-	sort.Strings(itemStrings)
-	var expect string
-	for _, i := range itemStrings {
-		expect += i + "\n"
-	}
-	expect = r.Normalize(expect)
-
-	uri := spn.URI()
-	filename := uri.Filename()
-	target := filename + fmt.Sprintf(":%v:%v", spn.Start().Line(), spn.Start().Column())
-
-	got, stderr := r.NormalizeGoplsCmd(t, "implementation", target)
-	if stderr != "" {
-		t.Errorf("implementation failed for %s: %s", target, stderr)
-	} else if expect != got {
-		t.Errorf("implementation failed for %s expected:\n%s\ngot:\n%s", target, expect, got)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/imports.go b/gopls/internal/lsp/cmd/test/imports.go
--- a/gopls/internal/lsp/cmd/test/imports.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/imports.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/diff"
-)
-
-func (r *runner) Import(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	got, _ := r.NormalizeGoplsCmd(t, "imports", filename)
-	want := string(r.data.Golden(t, "goimports", filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if want != got {
-		unified := diff.Unified("want", "got", want, got)
-		t.Errorf("imports failed for %s, expected:\n%s", filename, unified)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/links.go b/gopls/internal/lsp/cmd/test/links.go
--- a/gopls/internal/lsp/cmd/test/links.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/links.go	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"encoding/json"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) Link(t *testing.T, uri span.URI, wantLinks []tests.Link) {
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	out, _ := r.NormalizeGoplsCmd(t, "links", "-json", uri.Filename())
-	var got []protocol.DocumentLink
-	err = json.Unmarshal([]byte(out), &got)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if diff := tests.DiffLinks(m, wantLinks, got); diff != "" {
-		t.Error(diff)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/prepare_rename.go b/gopls/internal/lsp/cmd/test/prepare_rename.go
--- a/gopls/internal/lsp/cmd/test/prepare_rename.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/prepare_rename.go	1969-12-31 16:00:00
@@ -1,46 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/cmd"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) PrepareRename(t *testing.T, src span.Span, want *source.PrepareItem) {
-	m, err := r.data.Mapper(src.URI())
-	if err != nil {
-		t.Errorf("prepare_rename failed: %v", err)
-	}
-
-	var (
-		target         = fmt.Sprintf("%v", src)
-		args           = []string{"prepare_rename", target}
-		stdOut, stdErr = r.NormalizeGoplsCmd(t, args...)
-		expect         string
-	)
-
-	if want.Text == "" {
-		if stdErr != "" && stdErr != cmd.ErrInvalidRenamePosition.Error() {
-			t.Errorf("prepare_rename failed for %s,\nexpected:\n`%v`\ngot:\n`%v`", target, expect, stdErr)
-		}
-		return
-	}
-
-	ws, err := m.Span(protocol.Location{Range: want.Range})
-	if err != nil {
-		t.Errorf("prepare_rename failed: %v", err)
-	}
-
-	expect = r.Normalize(fmt.Sprintln(ws))
-	if expect != stdOut {
-		t.Errorf("prepare_rename failed for %s expected:\n`%s`\ngot:\n`%s`\n", target, expect, stdOut)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/references.go b/gopls/internal/lsp/cmd/test/references.go
--- a/gopls/internal/lsp/cmd/test/references.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/references.go	1969-12-31 16:00:00
@@ -1,49 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"sort"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) References(t *testing.T, spn span.Span, itemList []span.Span) {
-	for _, includeDeclaration := range []bool{true, false} {
-		t.Run(fmt.Sprintf("refs-declaration-%v", includeDeclaration), func(t *testing.T) {
-			var itemStrings []string
-			for i, s := range itemList {
-				// We don't want the first result if we aren't including the declaration.
-				if i == 0 && !includeDeclaration {
-					continue
-				}
-				itemStrings = append(itemStrings, fmt.Sprint(s))
-			}
-			sort.Strings(itemStrings)
-			var expect string
-			for _, s := range itemStrings {
-				expect += s + "\n"
-			}
-			expect = r.Normalize(expect)
-
-			uri := spn.URI()
-			filename := uri.Filename()
-			target := filename + fmt.Sprintf(":%v:%v", spn.Start().Line(), spn.Start().Column())
-			args := []string{"references"}
-			if includeDeclaration {
-				args = append(args, "-d")
-			}
-			args = append(args, target)
-			got, stderr := r.NormalizeGoplsCmd(t, args...)
-			if stderr != "" {
-				t.Errorf("references failed for %s: %s", target, stderr)
-			} else if expect != got {
-				t.Errorf("references failed for %s expected:\n%s\ngot:\n%s", target, expect, got)
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/rename.go b/gopls/internal/lsp/cmd/test/rename.go
--- a/gopls/internal/lsp/cmd/test/rename.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/rename.go	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) Rename(t *testing.T, spn span.Span, newText string) {
-	filename := spn.URI().Filename()
-	goldenTag := newText + "-rename"
-	loc := fmt.Sprintf("%v", spn)
-	got, err := r.NormalizeGoplsCmd(t, "rename", loc, newText)
-	got += err
-	want := string(r.data.Golden(t, goldenTag, filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if diff := compare.Text(want, got); diff != "" {
-		t.Errorf("rename failed with %v %v (-want +got):\n%s", loc, newText, diff)
-	}
-	// now check we can build a valid unified diff
-	unified, _ := r.NormalizeGoplsCmd(t, "rename", "-d", loc, newText)
-	checkUnified(t, filename, want, unified)
-}
diff -urN a/gopls/internal/lsp/cmd/test/semanticdriver.go b/gopls/internal/lsp/cmd/test/semanticdriver.go
--- a/gopls/internal/lsp/cmd/test/semanticdriver.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/semanticdriver.go	1969-12-31 16:00:00
@@ -1,36 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) SemanticTokens(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	got, stderr := r.NormalizeGoplsCmd(t, "semtok", filename)
-	if stderr != "" {
-		t.Fatalf("%s: %q", filename, stderr)
-	}
-	want := string(r.data.Golden(t, "semantic", filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if want != got {
-		lwant := strings.Split(want, "\n")
-		lgot := strings.Split(got, "\n")
-		t.Errorf("want(%d-%d) != got(%d-%d) for %s", len(want), len(lwant), len(got), len(lgot), r.Normalize(filename))
-		for i := 0; i < len(lwant) && i < len(lgot); i++ {
-			if lwant[i] != lgot[i] {
-				// This is the line number in the golden file.
-				// It is one larger than the line number in the source file.
-				t.Errorf("line %d:\nwant%q\ngot %q\n", i+2, lwant[i], lgot[i])
-			}
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/signature.go b/gopls/internal/lsp/cmd/test/signature.go
--- a/gopls/internal/lsp/cmd/test/signature.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/signature.go	1969-12-31 16:00:00
@@ -1,34 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) SignatureHelp(t *testing.T, spn span.Span, want *protocol.SignatureHelp) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	target := filename + fmt.Sprintf(":%v:%v", spn.Start().Line(), spn.Start().Column())
-	got, _ := r.NormalizeGoplsCmd(t, "signature", target)
-	if want == nil {
-		if got != "" {
-			t.Fatalf("want nil, but got %s", got)
-		}
-		return
-	}
-	goldenTag := want.Signatures[0].Label + "-signature"
-	expect := string(r.data.Golden(t, goldenTag, filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if tests.NormalizeAny(expect) != tests.NormalizeAny(got) {
-		t.Errorf("signature failed for %s expected:\n%q\ngot:\n%q'", filename, expect, got)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/suggested_fix.go b/gopls/internal/lsp/cmd/test/suggested_fix.go
--- a/gopls/internal/lsp/cmd/test/suggested_fix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/suggested_fix.go	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) SuggestedFix(t *testing.T, spn span.Span, suggestedFixes []tests.SuggestedFix, expectedActions int) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	args := []string{"fix", "-a", fmt.Sprintf("%s", spn)}
-	var actionKinds []string
-	for _, sf := range suggestedFixes {
-		if sf.ActionKind == "refactor.rewrite" {
-			t.Skip("refactor.rewrite is not yet supported on the command line")
-		}
-		actionKinds = append(actionKinds, sf.ActionKind)
-	}
-	args = append(args, actionKinds...)
-	got, stderr := r.NormalizeGoplsCmd(t, args...)
-	if stderr == "ExecuteCommand is not yet supported on the command line" {
-		return // don't skip to keep the summary counts correct
-	}
-	want := string(r.data.Golden(t, "suggestedfix_"+tests.SpanName(spn), filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if want != got {
-		t.Errorf("suggested fixes failed for %s:\n%s", filename, compare.Text(want, got))
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/symbols.go b/gopls/internal/lsp/cmd/test/symbols.go
--- a/gopls/internal/lsp/cmd/test/symbols.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/symbols.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) Symbols(t *testing.T, uri span.URI, expectedSymbols []protocol.DocumentSymbol) {
-	filename := uri.Filename()
-	got, _ := r.NormalizeGoplsCmd(t, "symbols", filename)
-	expect := string(r.data.Golden(t, "symbols", filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if diff := compare.Text(expect, got); diff != "" {
-		t.Errorf("symbols differ from expected:\n%s", diff)
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/test/workspace_symbol.go b/gopls/internal/lsp/cmd/test/workspace_symbol.go
--- a/gopls/internal/lsp/cmd/test/workspace_symbol.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/test/workspace_symbol.go	1969-12-31 16:00:00
@@ -1,54 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmdtest
-
-import (
-	"fmt"
-	"path/filepath"
-	"sort"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) WorkspaceSymbols(t *testing.T, uri span.URI, query string, typ tests.WorkspaceSymbolsTestType) {
-	var matcher string
-	switch typ {
-	case tests.WorkspaceSymbolsFuzzy:
-		matcher = "fuzzy"
-	case tests.WorkspaceSymbolsCaseSensitive:
-		matcher = "caseSensitive"
-	case tests.WorkspaceSymbolsDefault:
-		matcher = "caseInsensitive"
-	}
-	r.runWorkspaceSymbols(t, uri, matcher, query)
-}
-
-func (r *runner) runWorkspaceSymbols(t *testing.T, uri span.URI, matcher, query string) {
-	t.Helper()
-
-	out, _ := r.runGoplsCmd(t, "workspace_symbol", "-matcher", matcher, query)
-	var filtered []string
-	dir := filepath.Dir(uri.Filename())
-	for _, line := range strings.Split(out, "\n") {
-		if source.InDir(dir, line) {
-			filtered = append(filtered, filepath.ToSlash(line))
-		}
-	}
-	sort.Strings(filtered)
-	got := r.Normalize(strings.Join(filtered, "\n") + "\n")
-
-	expect := string(r.data.Golden(t, fmt.Sprintf("workspace_symbol-%s-%s", strings.ToLower(string(matcher)), query), uri.Filename(), func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-
-	if expect != got {
-		t.Errorf("workspace_symbol failed for %s:\n%s", query, compare.Text(expect, got))
-	}
-}
diff -urN a/gopls/internal/lsp/cmd/usage/api-json.hlp b/gopls/internal/lsp/cmd/usage/api-json.hlp
--- a/gopls/internal/lsp/cmd/usage/api-json.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/api-json.hlp	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
-print json describing gopls API
-
-Usage:
-  gopls [flags] api-json
diff -urN a/gopls/internal/lsp/cmd/usage/bug.hlp b/gopls/internal/lsp/cmd/usage/bug.hlp
--- a/gopls/internal/lsp/cmd/usage/bug.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/bug.hlp	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
-report a bug in gopls
-
-Usage:
-  gopls [flags] bug
diff -urN a/gopls/internal/lsp/cmd/usage/call_hierarchy.hlp b/gopls/internal/lsp/cmd/usage/call_hierarchy.hlp
--- a/gopls/internal/lsp/cmd/usage/call_hierarchy.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/call_hierarchy.hlp	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-display selected identifier's call hierarchy
-
-Usage:
-  gopls [flags] call_hierarchy <position>
-
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls call_hierarchy helper/helper.go:8:6
-	$ gopls call_hierarchy helper/helper.go:#53
diff -urN a/gopls/internal/lsp/cmd/usage/check.hlp b/gopls/internal/lsp/cmd/usage/check.hlp
--- a/gopls/internal/lsp/cmd/usage/check.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/check.hlp	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-show diagnostic results for the specified file
-
-Usage:
-  gopls [flags] check <filename>
-
-Example: show the diagnostic results of this file:
-
-	$ gopls check internal/lsp/cmd/check.go
diff -urN a/gopls/internal/lsp/cmd/usage/definition.hlp b/gopls/internal/lsp/cmd/usage/definition.hlp
--- a/gopls/internal/lsp/cmd/usage/definition.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/definition.hlp	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-show declaration of selected identifier
-
-Usage:
-  gopls [flags] definition [definition-flags] <position>
-
-Example: show the definition of the identifier at syntax at offset 44 in this file (flag.FlagSet):
-
-	$ gopls definition internal/lsp/cmd/definition.go:44:47
-	$ gopls definition internal/lsp/cmd/definition.go:#1270
-
-definition-flags:
-  -json
-    	emit output in JSON format
-  -markdown
-    	support markdown in responses
diff -urN a/gopls/internal/lsp/cmd/usage/fix.hlp b/gopls/internal/lsp/cmd/usage/fix.hlp
--- a/gopls/internal/lsp/cmd/usage/fix.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/fix.hlp	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-apply suggested fixes
-
-Usage:
-  gopls [flags] fix [fix-flags] <filename>
-
-Example: apply suggested fixes for this file
-	$ gopls fix -w internal/lsp/cmd/check.go
-
-fix-flags:
-  -a,-all
-    	apply all fixes, not just preferred fixes
-  -d,-diff
-    	display diffs instead of rewriting files
-  -w,-write
-    	write result to (source) file instead of stdout
diff -urN a/gopls/internal/lsp/cmd/usage/folding_ranges.hlp b/gopls/internal/lsp/cmd/usage/folding_ranges.hlp
--- a/gopls/internal/lsp/cmd/usage/folding_ranges.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/folding_ranges.hlp	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-display selected file's folding ranges
-
-Usage:
-  gopls [flags] folding_ranges <file>
-
-Example:
-
-	$ gopls folding_ranges helper/helper.go
diff -urN a/gopls/internal/lsp/cmd/usage/format.hlp b/gopls/internal/lsp/cmd/usage/format.hlp
--- a/gopls/internal/lsp/cmd/usage/format.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/format.hlp	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-format the code according to the go standard
-
-Usage:
-  gopls [flags] format [format-flags] <filerange>
-
-The arguments supplied may be simple file names, or ranges within files.
-
-Example: reformat this file:
-
-	$ gopls format -w internal/lsp/cmd/check.go
-
-format-flags:
-  -d,-diff
-    	display diffs instead of rewriting files
-  -l,-list
-    	list files whose formatting differs from gofmt's
-  -w,-write
-    	write result to (source) file instead of stdout
diff -urN a/gopls/internal/lsp/cmd/usage/help.hlp b/gopls/internal/lsp/cmd/usage/help.hlp
--- a/gopls/internal/lsp/cmd/usage/help.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/help.hlp	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-print usage information for subcommands
-
-Usage:
-  gopls [flags] help
-
-
-Examples:
-$ gopls help                         # main gopls help message
-$ gopls help remote                  # help on 'remote' command
-$ gopls help remote sessions         # help on 'remote sessions' subcommand
diff -urN a/gopls/internal/lsp/cmd/usage/highlight.hlp b/gopls/internal/lsp/cmd/usage/highlight.hlp
--- a/gopls/internal/lsp/cmd/usage/highlight.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/highlight.hlp	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-display selected identifier's highlights
-
-Usage:
-  gopls [flags] highlight <position>
-
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls highlight helper/helper.go:8:6
-	$ gopls highlight helper/helper.go:#53
diff -urN a/gopls/internal/lsp/cmd/usage/implementation.hlp b/gopls/internal/lsp/cmd/usage/implementation.hlp
--- a/gopls/internal/lsp/cmd/usage/implementation.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/implementation.hlp	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-display selected identifier's implementation
-
-Usage:
-  gopls [flags] implementation <position>
-
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls implementation helper/helper.go:8:6
-	$ gopls implementation helper/helper.go:#53
diff -urN a/gopls/internal/lsp/cmd/usage/imports.hlp b/gopls/internal/lsp/cmd/usage/imports.hlp
--- a/gopls/internal/lsp/cmd/usage/imports.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/imports.hlp	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-updates import statements
-
-Usage:
-  gopls [flags] imports [imports-flags] <filename>
-
-Example: update imports statements in a file:
-
-	$ gopls imports -w internal/lsp/cmd/check.go
-
-imports-flags:
-  -d,-diff
-    	display diffs instead of rewriting files
-  -w,-write
-    	write result to (source) file instead of stdout
diff -urN a/gopls/internal/lsp/cmd/usage/inspect.hlp b/gopls/internal/lsp/cmd/usage/inspect.hlp
--- a/gopls/internal/lsp/cmd/usage/inspect.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/inspect.hlp	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-interact with the gopls daemon (deprecated: use 'remote')
-
-Usage:
-  gopls [flags] inspect <subcommand> [arg]...
-
-Subcommand:
-  sessions  print information about current gopls sessions
-  debug     start the debug server
diff -urN a/gopls/internal/lsp/cmd/usage/licenses.hlp b/gopls/internal/lsp/cmd/usage/licenses.hlp
--- a/gopls/internal/lsp/cmd/usage/licenses.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/licenses.hlp	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
-print licenses of included software
-
-Usage:
-  gopls [flags] licenses
diff -urN a/gopls/internal/lsp/cmd/usage/links.hlp b/gopls/internal/lsp/cmd/usage/links.hlp
--- a/gopls/internal/lsp/cmd/usage/links.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/links.hlp	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-list links in a file
-
-Usage:
-  gopls [flags] links [links-flags] <filename>
-
-Example: list links contained within a file:
-
-	$ gopls links internal/lsp/cmd/check.go
-
-links-flags:
-  -json
-    	emit document links in JSON format
diff -urN a/gopls/internal/lsp/cmd/usage/prepare_rename.hlp b/gopls/internal/lsp/cmd/usage/prepare_rename.hlp
--- a/gopls/internal/lsp/cmd/usage/prepare_rename.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/prepare_rename.hlp	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-test validity of a rename operation at location
-
-Usage:
-  gopls [flags] prepare_rename <position>
-
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls prepare_rename helper/helper.go:8:6
-	$ gopls prepare_rename helper/helper.go:#53
diff -urN a/gopls/internal/lsp/cmd/usage/references.hlp b/gopls/internal/lsp/cmd/usage/references.hlp
--- a/gopls/internal/lsp/cmd/usage/references.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/references.hlp	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-display selected identifier's references
-
-Usage:
-  gopls [flags] references [references-flags] <position>
-
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls references helper/helper.go:8:6
-	$ gopls references helper/helper.go:#53
-
-references-flags:
-  -d,-declaration
-    	include the declaration of the specified identifier in the results
diff -urN a/gopls/internal/lsp/cmd/usage/remote.hlp b/gopls/internal/lsp/cmd/usage/remote.hlp
--- a/gopls/internal/lsp/cmd/usage/remote.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/remote.hlp	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-interact with the gopls daemon
-
-Usage:
-  gopls [flags] remote <subcommand> [arg]...
-
-Subcommand:
-  sessions  print information about current gopls sessions
-  debug     start the debug server
diff -urN a/gopls/internal/lsp/cmd/usage/rename.hlp b/gopls/internal/lsp/cmd/usage/rename.hlp
--- a/gopls/internal/lsp/cmd/usage/rename.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/rename.hlp	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-rename selected identifier
-
-Usage:
-  gopls [flags] rename [rename-flags] <position> <name>
-
-Example:
-
-	$ # 1-based location (:line:column or :#position) of the thing to change
-	$ gopls rename helper/helper.go:8:6 Foo
-	$ gopls rename helper/helper.go:#53 Foo
-
-rename-flags:
-  -d,-diff
-    	display diffs instead of rewriting files
-  -preserve
-    	preserve original files
-  -w,-write
-    	write result to (source) file instead of stdout
diff -urN a/gopls/internal/lsp/cmd/usage/semtok.hlp b/gopls/internal/lsp/cmd/usage/semtok.hlp
--- a/gopls/internal/lsp/cmd/usage/semtok.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/semtok.hlp	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-show semantic tokens for the specified file
-
-Usage:
-  gopls [flags] semtok <filename>
-
-Example: show the semantic tokens for this file:
-
-	$ gopls semtok internal/lsp/cmd/semtok.go
diff -urN a/gopls/internal/lsp/cmd/usage/serve.hlp b/gopls/internal/lsp/cmd/usage/serve.hlp
--- a/gopls/internal/lsp/cmd/usage/serve.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/serve.hlp	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-run a server for Go code using the Language Server Protocol
-
-Usage:
-  gopls [flags] serve [server-flags]
-  gopls [flags] [server-flags]
-
-The server communicates using JSONRPC2 on stdin and stdout, and is intended to be run directly as
-a child of an editor process.
-
-server-flags:
-  -debug=string
-    	serve debug information on the supplied address
-  -listen=string
-    	address on which to listen for remote connections. If prefixed by 'unix;', the subsequent address is assumed to be a unix domain socket. Otherwise, TCP is used.
-  -listen.timeout=duration
-    	when used with -listen, shut down the server when there are no connected clients for this duration
-  -logfile=string
-    	filename to log to. if value is "auto", then logging to a default output file is enabled
-  -mode=string
-    	no effect
-  -port=int
-    	port on which to run gopls for debugging purposes
-  -remote.debug=string
-    	when used with -remote=auto, the -debug value used to start the daemon
-  -remote.listen.timeout=duration
-    	when used with -remote=auto, the -listen.timeout value used to start the daemon (default 1m0s)
-  -remote.logfile=string
-    	when used with -remote=auto, the -logfile value used to start the daemon
-  -rpc.trace
-    	print the full rpc trace in lsp inspector format
diff -urN a/gopls/internal/lsp/cmd/usage/signature.hlp b/gopls/internal/lsp/cmd/usage/signature.hlp
--- a/gopls/internal/lsp/cmd/usage/signature.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/signature.hlp	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-display selected identifier's signature
-
-Usage:
-  gopls [flags] signature <position>
-
-Example:
-
-	$ # 1-indexed location (:line:column or :#offset) of the target identifier
-	$ gopls signature helper/helper.go:8:6
-	$ gopls signature helper/helper.go:#53
diff -urN a/gopls/internal/lsp/cmd/usage/symbols.hlp b/gopls/internal/lsp/cmd/usage/symbols.hlp
--- a/gopls/internal/lsp/cmd/usage/symbols.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/symbols.hlp	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-display selected file's symbols
-
-Usage:
-  gopls [flags] symbols <file>
-
-Example:
-	$ gopls symbols helper/helper.go
diff -urN a/gopls/internal/lsp/cmd/usage/usage.hlp b/gopls/internal/lsp/cmd/usage/usage.hlp
--- a/gopls/internal/lsp/cmd/usage/usage.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/usage.hlp	1969-12-31 16:00:00
@@ -1,78 +0,0 @@
-
-gopls is a Go language server.
-
-It is typically used with an editor to provide language features. When no
-command is specified, gopls will default to the 'serve' command. The language
-features can also be accessed via the gopls command-line interface.
-
-Usage:
-  gopls help [<subject>]
-
-Command:
-
-Main                
-  serve             run a server for Go code using the Language Server Protocol
-  version           print the gopls version information
-  bug               report a bug in gopls
-  help              print usage information for subcommands
-  api-json          print json describing gopls API
-  licenses          print licenses of included software
-                    
-Features            
-  call_hierarchy    display selected identifier's call hierarchy
-  check             show diagnostic results for the specified file
-  definition        show declaration of selected identifier
-  folding_ranges    display selected file's folding ranges
-  format            format the code according to the go standard
-  highlight         display selected identifier's highlights
-  implementation    display selected identifier's implementation
-  imports           updates import statements
-  remote            interact with the gopls daemon
-  inspect           interact with the gopls daemon (deprecated: use 'remote')
-  links             list links in a file
-  prepare_rename    test validity of a rename operation at location
-  references        display selected identifier's references
-  rename            rename selected identifier
-  semtok            show semantic tokens for the specified file
-  signature         display selected identifier's signature
-  fix               apply suggested fixes
-  symbols           display selected file's symbols
-  workspace         manage the gopls workspace (experimental: under development)
-  workspace_symbol  search symbols in workspace
-  vulncheck         run experimental vulncheck analysis (experimental: under development)
-
-flags:
-  -debug=string
-    	serve debug information on the supplied address
-  -listen=string
-    	address on which to listen for remote connections. If prefixed by 'unix;', the subsequent address is assumed to be a unix domain socket. Otherwise, TCP is used.
-  -listen.timeout=duration
-    	when used with -listen, shut down the server when there are no connected clients for this duration
-  -logfile=string
-    	filename to log to. if value is "auto", then logging to a default output file is enabled
-  -mode=string
-    	no effect
-  -ocagent=string
-    	the address of the ocagent (e.g. http://localhost:55678), or off (default "off")
-  -port=int
-    	port on which to run gopls for debugging purposes
-  -profile.cpu=string
-    	write CPU profile to this file
-  -profile.mem=string
-    	write memory profile to this file
-  -profile.trace=string
-    	write trace log to this file
-  -remote=string
-    	forward all commands to a remote lsp specified by this flag. With no special prefix, this is assumed to be a TCP address. If prefixed by 'unix;', the subsequent address is assumed to be a unix domain socket. If 'auto', or prefixed by 'auto;', the remote address is automatically resolved based on the executing environment.
-  -remote.debug=string
-    	when used with -remote=auto, the -debug value used to start the daemon
-  -remote.listen.timeout=duration
-    	when used with -remote=auto, the -listen.timeout value used to start the daemon (default 1m0s)
-  -remote.logfile=string
-    	when used with -remote=auto, the -logfile value used to start the daemon
-  -rpc.trace
-    	print the full rpc trace in lsp inspector format
-  -v,-verbose
-    	verbose output
-  -vv,-veryverbose
-    	very verbose output
diff -urN a/gopls/internal/lsp/cmd/usage/version.hlp b/gopls/internal/lsp/cmd/usage/version.hlp
--- a/gopls/internal/lsp/cmd/usage/version.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/version.hlp	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-print the gopls version information
-
-Usage:
-  gopls [flags] version
-  -json
-    	outputs in json format.
diff -urN a/gopls/internal/lsp/cmd/usage/vulncheck.hlp b/gopls/internal/lsp/cmd/usage/vulncheck.hlp
--- a/gopls/internal/lsp/cmd/usage/vulncheck.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/vulncheck.hlp	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-run experimental vulncheck analysis (experimental: under development)
-
-Usage:
-  gopls [flags] vulncheck
-
-	WARNING: this command is experimental.
-
-	By default, the command outputs a JSON-encoded
-	golang.org/x/tools/gopls/internal/lsp/command.VulncheckResult
-	message.
-	Example:
-	$ gopls vulncheck <packages>
-
-  -config
-    	If true, the command reads a JSON-encoded package load configuration from stdin
-  -summary
-    	If true, outputs a JSON-encoded govulnchecklib.Summary JSON
diff -urN a/gopls/internal/lsp/cmd/usage/workspace.hlp b/gopls/internal/lsp/cmd/usage/workspace.hlp
--- a/gopls/internal/lsp/cmd/usage/workspace.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/workspace.hlp	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-manage the gopls workspace (experimental: under development)
-
-Usage:
-  gopls [flags] workspace <subcommand> [arg]...
-
-Subcommand:
-  generate  generate a gopls.mod file for a workspace
diff -urN a/gopls/internal/lsp/cmd/usage/workspace_symbol.hlp b/gopls/internal/lsp/cmd/usage/workspace_symbol.hlp
--- a/gopls/internal/lsp/cmd/usage/workspace_symbol.hlp	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/usage/workspace_symbol.hlp	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-search symbols in workspace
-
-Usage:
-  gopls [flags] workspace_symbol [workspace_symbol-flags] <query>
-
-Example:
-
-	$ gopls workspace_symbol -matcher fuzzy 'wsymbols'
-
-workspace_symbol-flags:
-  -matcher=string
-    	specifies the type of matcher: fuzzy, caseSensitive, or caseInsensitive.
-    	The default is caseInsensitive.
diff -urN a/gopls/internal/lsp/cmd/vulncheck.go b/gopls/internal/lsp/cmd/vulncheck.go
--- a/gopls/internal/lsp/cmd/vulncheck.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/vulncheck.go	1969-12-31 16:00:00
@@ -1,84 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"encoding/json"
-	"flag"
-	"fmt"
-	"os"
-
-	"golang.org/x/tools/go/packages"
-	vulnchecklib "golang.org/x/tools/gopls/internal/vulncheck"
-	"golang.org/x/tools/internal/tool"
-)
-
-// vulncheck implements the vulncheck command.
-type vulncheck struct {
-	Config    bool `flag:"config" help:"If true, the command reads a JSON-encoded package load configuration from stdin"`
-	AsSummary bool `flag:"summary" help:"If true, outputs a JSON-encoded govulnchecklib.Summary JSON"`
-	app       *Application
-}
-
-type pkgLoadConfig struct {
-	// BuildFlags is a list of command-line flags to be passed through to
-	// the build system's query tool.
-	BuildFlags []string
-
-	// If Tests is set, the loader includes related test packages.
-	Tests bool
-}
-
-// TODO(hyangah): document pkgLoadConfig
-
-func (v *vulncheck) Name() string   { return "vulncheck" }
-func (v *vulncheck) Parent() string { return v.app.Name() }
-func (v *vulncheck) Usage() string  { return "" }
-func (v *vulncheck) ShortHelp() string {
-	return "run experimental vulncheck analysis (experimental: under development)"
-}
-func (v *vulncheck) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-	WARNING: this command is experimental.
-
-	By default, the command outputs a JSON-encoded
-	golang.org/x/tools/gopls/internal/lsp/command.VulncheckResult
-	message.
-	Example:
-	$ gopls vulncheck <packages>
-
-`)
-	printFlagDefaults(f)
-}
-
-func (v *vulncheck) Run(ctx context.Context, args ...string) error {
-	if vulnchecklib.Main == nil {
-		return fmt.Errorf("vulncheck command is available only in gopls compiled with go1.18 or newer")
-	}
-
-	// TODO(hyangah): what's wrong with allowing multiple targets?
-	if len(args) > 1 {
-		return tool.CommandLineErrorf("vulncheck accepts at most one package pattern")
-	}
-	var cfg pkgLoadConfig
-	if v.Config {
-		if err := json.NewDecoder(os.Stdin).Decode(&cfg); err != nil {
-			return tool.CommandLineErrorf("failed to parse cfg: %v", err)
-		}
-	}
-	loadCfg := packages.Config{
-		Context:    ctx,
-		Tests:      cfg.Tests,
-		BuildFlags: cfg.BuildFlags,
-		// inherit the current process's cwd and env.
-	}
-
-	if err := vulnchecklib.Main(loadCfg, args...); err != nil {
-		fmt.Fprintln(os.Stderr, err)
-		os.Exit(1)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/workspace.go b/gopls/internal/lsp/cmd/workspace.go
--- a/gopls/internal/lsp/cmd/workspace.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/workspace.go	1969-12-31 16:00:00
@@ -1,77 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-// workspace is a top-level command for working with the gopls workspace. This
-// is experimental and subject to change. The idea is that subcommands could be
-// used for manipulating the workspace mod file, rather than editing it
-// manually.
-type workspace struct {
-	app *Application
-	subcommands
-}
-
-func newWorkspace(app *Application) *workspace {
-	return &workspace{
-		app: app,
-		subcommands: subcommands{
-			&generateWorkspaceMod{app: app},
-		},
-	}
-}
-
-func (w *workspace) Name() string   { return "workspace" }
-func (w *workspace) Parent() string { return w.app.Name() }
-func (w *workspace) ShortHelp() string {
-	return "manage the gopls workspace (experimental: under development)"
-}
-
-// generateWorkspaceMod (re)generates the gopls.mod file for the current
-// workspace.
-type generateWorkspaceMod struct {
-	app *Application
-}
-
-func (c *generateWorkspaceMod) Name() string  { return "generate" }
-func (c *generateWorkspaceMod) Usage() string { return "" }
-func (c *generateWorkspaceMod) ShortHelp() string {
-	return "generate a gopls.mod file for a workspace"
-}
-
-func (c *generateWorkspaceMod) DetailedHelp(f *flag.FlagSet) {
-	printFlagDefaults(f)
-}
-
-func (c *generateWorkspaceMod) Run(ctx context.Context, args ...string) error {
-	origOptions := c.app.options
-	c.app.options = func(opts *source.Options) {
-		origOptions(opts)
-		opts.ExperimentalWorkspaceModule = true
-	}
-	conn, err := c.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-	cmd, err := command.NewGenerateGoplsModCommand("", command.URIArg{})
-	if err != nil {
-		return err
-	}
-	params := &protocol.ExecuteCommandParams{Command: cmd.Command, Arguments: cmd.Arguments}
-	if _, err := conn.ExecuteCommand(ctx, params); err != nil {
-		return fmt.Errorf("executing server command: %v", err)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/cmd/workspace_symbol.go b/gopls/internal/lsp/cmd/workspace_symbol.go
--- a/gopls/internal/lsp/cmd/workspace_symbol.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/cmd/workspace_symbol.go	1969-12-31 16:00:00
@@ -1,85 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package cmd
-
-import (
-	"context"
-	"flag"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/tool"
-)
-
-// workspaceSymbol implements the workspace_symbol verb for gopls.
-type workspaceSymbol struct {
-	Matcher string `flag:"matcher" help:"specifies the type of matcher: fuzzy, caseSensitive, or caseInsensitive.\nThe default is caseInsensitive."`
-
-	app *Application
-}
-
-func (r *workspaceSymbol) Name() string      { return "workspace_symbol" }
-func (r *workspaceSymbol) Parent() string    { return r.app.Name() }
-func (r *workspaceSymbol) Usage() string     { return "[workspace_symbol-flags] <query>" }
-func (r *workspaceSymbol) ShortHelp() string { return "search symbols in workspace" }
-func (r *workspaceSymbol) DetailedHelp(f *flag.FlagSet) {
-	fmt.Fprint(f.Output(), `
-Example:
-
-	$ gopls workspace_symbol -matcher fuzzy 'wsymbols'
-
-workspace_symbol-flags:
-`)
-	printFlagDefaults(f)
-}
-
-func (r *workspaceSymbol) Run(ctx context.Context, args ...string) error {
-	if len(args) != 1 {
-		return tool.CommandLineErrorf("workspace_symbol expects 1 argument")
-	}
-
-	opts := r.app.options
-	r.app.options = func(o *source.Options) {
-		if opts != nil {
-			opts(o)
-		}
-		switch r.Matcher {
-		case "fuzzy":
-			o.SymbolMatcher = source.SymbolFuzzy
-		case "caseSensitive":
-			o.SymbolMatcher = source.SymbolCaseSensitive
-		case "fastfuzzy":
-			o.SymbolMatcher = source.SymbolFastFuzzy
-		default:
-			o.SymbolMatcher = source.SymbolCaseInsensitive
-		}
-	}
-
-	conn, err := r.app.connect(ctx)
-	if err != nil {
-		return err
-	}
-	defer conn.terminate(ctx)
-
-	p := protocol.WorkspaceSymbolParams{
-		Query: args[0],
-	}
-
-	symbols, err := conn.Symbol(ctx, &p)
-	if err != nil {
-		return err
-	}
-	for _, s := range symbols {
-		f := conn.openFile(ctx, fileURI(s.Location.URI))
-		span, err := f.mapper.Span(s.Location)
-		if err != nil {
-			return err
-		}
-		fmt.Printf("%s %s %s\n", span, s.Name, s.Kind)
-	}
-
-	return nil
-}
diff -urN a/gopls/internal/lsp/code_action.go b/gopls/internal/lsp/code_action.go
--- a/gopls/internal/lsp/code_action.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/code_action.go	1969-12-31 16:00:00
@@ -1,487 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"fmt"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/mod"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/imports"
-)
-
-func (s *Server) codeAction(ctx context.Context, params *protocol.CodeActionParams) ([]protocol.CodeAction, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	uri := fh.URI()
-
-	// Determine the supported actions for this file kind.
-	kind := snapshot.View().FileKind(fh)
-	supportedCodeActions, ok := snapshot.View().Options().SupportedCodeActions[kind]
-	if !ok {
-		return nil, fmt.Errorf("no supported code actions for %v file kind", kind)
-	}
-
-	// The Only field of the context specifies which code actions the client wants.
-	// If Only is empty, assume that the client wants all of the non-explicit code actions.
-	var wanted map[protocol.CodeActionKind]bool
-
-	// Explicit Code Actions are opt-in and shouldn't be returned to the client unless
-	// requested using Only.
-	// TODO: Add other CodeLenses such as GoGenerate, RegenerateCgo, etc..
-	explicit := map[protocol.CodeActionKind]bool{
-		protocol.GoTest: true,
-	}
-
-	if len(params.Context.Only) == 0 {
-		wanted = supportedCodeActions
-	} else {
-		wanted = make(map[protocol.CodeActionKind]bool)
-		for _, only := range params.Context.Only {
-			for k, v := range supportedCodeActions {
-				if only == k || strings.HasPrefix(string(k), string(only)+".") {
-					wanted[k] = wanted[k] || v
-				}
-			}
-			wanted[only] = wanted[only] || explicit[only]
-		}
-	}
-	if len(supportedCodeActions) == 0 {
-		return nil, nil // not an error if there are none supported
-	}
-	if len(wanted) == 0 {
-		return nil, fmt.Errorf("no supported code action to execute for %s, wanted %v", uri, params.Context.Only)
-	}
-
-	var codeActions []protocol.CodeAction
-	switch kind {
-	case source.Mod:
-		if diagnostics := params.Context.Diagnostics; len(diagnostics) > 0 {
-			diags, err := mod.ModDiagnostics(ctx, snapshot, fh)
-			if source.IsNonFatalGoModError(err) {
-				return nil, nil
-			}
-			if err != nil {
-				return nil, err
-			}
-			udiags, err := mod.ModUpgradeDiagnostics(ctx, snapshot, fh)
-			if err != nil {
-				return nil, err
-			}
-			quickFixes, err := codeActionsMatchingDiagnostics(ctx, snapshot, diagnostics, append(diags, udiags...))
-			if err != nil {
-				return nil, err
-			}
-			codeActions = append(codeActions, quickFixes...)
-
-			vdiags, err := mod.ModVulnerabilityDiagnostics(ctx, snapshot, fh)
-			if err != nil {
-				return nil, err
-			}
-			// Group vulnerabilities by location and then limit which code actions we return
-			// for each location.
-			m := make(map[protocol.Range][]*source.Diagnostic)
-			for _, v := range vdiags {
-				m[v.Range] = append(m[v.Range], v)
-			}
-			for _, sdiags := range m {
-				quickFixes, err = codeActionsMatchingDiagnostics(ctx, snapshot, diagnostics, sdiags)
-				if err != nil {
-					return nil, err
-				}
-				quickFixes = mod.SelectUpgradeCodeActions(quickFixes)
-				codeActions = append(codeActions, quickFixes...)
-			}
-		}
-	case source.Go:
-		// Don't suggest fixes for generated files, since they are generally
-		// not useful and some editors may apply them automatically on save.
-		if source.IsGenerated(ctx, snapshot, uri) {
-			return nil, nil
-		}
-		diagnostics := params.Context.Diagnostics
-
-		// First, process any missing imports and pair them with the
-		// diagnostics they fix.
-		if wantQuickFixes := wanted[protocol.QuickFix] && len(diagnostics) > 0; wantQuickFixes || wanted[protocol.SourceOrganizeImports] {
-			importEdits, importEditsPerFix, err := source.AllImportsFixes(ctx, snapshot, fh)
-			if err != nil {
-				event.Error(ctx, "imports fixes", err, tag.File.Of(fh.URI().Filename()))
-			}
-			// Separate this into a set of codeActions per diagnostic, where
-			// each action is the addition, removal, or renaming of one import.
-			if wantQuickFixes {
-				for _, importFix := range importEditsPerFix {
-					fixes := importDiagnostics(importFix.Fix, diagnostics)
-					if len(fixes) == 0 {
-						continue
-					}
-					codeActions = append(codeActions, protocol.CodeAction{
-						Title: importFixTitle(importFix.Fix),
-						Kind:  protocol.QuickFix,
-						Edit: protocol.WorkspaceEdit{
-							DocumentChanges: documentChanges(fh, importFix.Edits),
-						},
-						Diagnostics: fixes,
-					})
-				}
-			}
-
-			// Send all of the import edits as one code action if the file is
-			// being organized.
-			if wanted[protocol.SourceOrganizeImports] && len(importEdits) > 0 {
-				codeActions = append(codeActions, protocol.CodeAction{
-					Title: "Organize Imports",
-					Kind:  protocol.SourceOrganizeImports,
-					Edit: protocol.WorkspaceEdit{
-						DocumentChanges: documentChanges(fh, importEdits),
-					},
-				})
-			}
-		}
-		if ctx.Err() != nil {
-			return nil, ctx.Err()
-		}
-
-		// Type-check the package and also run analysis,
-		// then combine their diagnostics.
-		pkg, _, err := source.PackageForFile(ctx, snapshot, fh.URI(), source.TypecheckFull, source.WidestPackage)
-		if err != nil {
-			return nil, err
-		}
-		analysisDiags, err := source.Analyze(ctx, snapshot, pkg.ID(), true)
-		if err != nil {
-			return nil, err
-		}
-		var fileDiags []*source.Diagnostic
-		source.CombineDiagnostics(pkg, fh.URI(), analysisDiags, &fileDiags, &fileDiags)
-
-		// Split diagnostics into fixes, which must match incoming diagnostics,
-		// and non-fixes, which must match the requested range. Build actions
-		// for all of them.
-		var fixDiags, nonFixDiags []*source.Diagnostic
-		for _, d := range fileDiags {
-			if len(d.SuggestedFixes) == 0 {
-				continue
-			}
-			var isFix bool
-			for _, fix := range d.SuggestedFixes {
-				if fix.ActionKind == protocol.QuickFix || fix.ActionKind == protocol.SourceFixAll {
-					isFix = true
-					break
-				}
-			}
-			if isFix {
-				fixDiags = append(fixDiags, d)
-			} else {
-				nonFixDiags = append(nonFixDiags, d)
-			}
-		}
-
-		fixActions, err := codeActionsMatchingDiagnostics(ctx, snapshot, diagnostics, fixDiags)
-		if err != nil {
-			return nil, err
-		}
-		codeActions = append(codeActions, fixActions...)
-
-		for _, nonfix := range nonFixDiags {
-			// For now, only show diagnostics for matching lines. Maybe we should
-			// alter this behavior in the future, depending on the user experience.
-			if !protocol.Intersect(nonfix.Range, params.Range) {
-				continue
-			}
-			actions, err := codeActionsForDiagnostic(ctx, snapshot, nonfix, nil)
-			if err != nil {
-				return nil, err
-			}
-			codeActions = append(codeActions, actions...)
-		}
-
-		if wanted[protocol.RefactorExtract] {
-			fixes, err := extractionFixes(ctx, snapshot, uri, params.Range)
-			if err != nil {
-				return nil, err
-			}
-			codeActions = append(codeActions, fixes...)
-		}
-
-		if wanted[protocol.GoTest] {
-			fixes, err := goTest(ctx, snapshot, uri, params.Range)
-			if err != nil {
-				return nil, err
-			}
-			codeActions = append(codeActions, fixes...)
-		}
-
-	default:
-		// Unsupported file kind for a code action.
-		return nil, nil
-	}
-
-	var filtered []protocol.CodeAction
-	for _, action := range codeActions {
-		if wanted[action.Kind] {
-			filtered = append(filtered, action)
-		}
-	}
-	return filtered, nil
-}
-
-func (s *Server) getSupportedCodeActions() []protocol.CodeActionKind {
-	allCodeActionKinds := make(map[protocol.CodeActionKind]struct{})
-	for _, kinds := range s.session.Options().SupportedCodeActions {
-		for kind := range kinds {
-			allCodeActionKinds[kind] = struct{}{}
-		}
-	}
-	var result []protocol.CodeActionKind
-	for kind := range allCodeActionKinds {
-		result = append(result, kind)
-	}
-	sort.Slice(result, func(i, j int) bool {
-		return result[i] < result[j]
-	})
-	return result
-}
-
-func importFixTitle(fix *imports.ImportFix) string {
-	var str string
-	switch fix.FixType {
-	case imports.AddImport:
-		str = fmt.Sprintf("Add import: %s %q", fix.StmtInfo.Name, fix.StmtInfo.ImportPath)
-	case imports.DeleteImport:
-		str = fmt.Sprintf("Delete import: %s %q", fix.StmtInfo.Name, fix.StmtInfo.ImportPath)
-	case imports.SetImportName:
-		str = fmt.Sprintf("Rename import: %s %q", fix.StmtInfo.Name, fix.StmtInfo.ImportPath)
-	}
-	return str
-}
-
-func importDiagnostics(fix *imports.ImportFix, diagnostics []protocol.Diagnostic) (results []protocol.Diagnostic) {
-	for _, diagnostic := range diagnostics {
-		switch {
-		// "undeclared name: X" may be an unresolved import.
-		case strings.HasPrefix(diagnostic.Message, "undeclared name: "):
-			ident := strings.TrimPrefix(diagnostic.Message, "undeclared name: ")
-			if ident == fix.IdentName {
-				results = append(results, diagnostic)
-			}
-		// "undefined: X" may be an unresolved import at Go 1.20+.
-		case strings.HasPrefix(diagnostic.Message, "undefined: "):
-			ident := strings.TrimPrefix(diagnostic.Message, "undefined: ")
-			if ident == fix.IdentName {
-				results = append(results, diagnostic)
-			}
-		// "could not import: X" may be an invalid import.
-		case strings.HasPrefix(diagnostic.Message, "could not import: "):
-			ident := strings.TrimPrefix(diagnostic.Message, "could not import: ")
-			if ident == fix.IdentName {
-				results = append(results, diagnostic)
-			}
-		// "X imported but not used" is an unused import.
-		// "X imported but not used as Y" is an unused import.
-		case strings.Contains(diagnostic.Message, " imported but not used"):
-			idx := strings.Index(diagnostic.Message, " imported but not used")
-			importPath := diagnostic.Message[:idx]
-			if importPath == fmt.Sprintf("%q", fix.StmtInfo.ImportPath) {
-				results = append(results, diagnostic)
-			}
-		}
-	}
-	return results
-}
-
-func extractionFixes(ctx context.Context, snapshot source.Snapshot, uri span.URI, rng protocol.Range) ([]protocol.CodeAction, error) {
-	if rng.Start == rng.End {
-		return nil, nil
-	}
-	fh, err := snapshot.GetFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	pgf, err := snapshot.ParseGo(ctx, fh, source.ParseFull)
-	if err != nil {
-		return nil, fmt.Errorf("getting file for Identifier: %w", err)
-	}
-	srng, err := pgf.Mapper.RangeToSpanRange(rng)
-	if err != nil {
-		return nil, err
-	}
-	puri := protocol.URIFromSpanURI(uri)
-	var commands []protocol.Command
-	if _, ok, methodOk, _ := source.CanExtractFunction(pgf.Tok, srng, pgf.Src, pgf.File); ok {
-		cmd, err := command.NewApplyFixCommand("Extract function", command.ApplyFixArgs{
-			URI:   puri,
-			Fix:   source.ExtractFunction,
-			Range: rng,
-		})
-		if err != nil {
-			return nil, err
-		}
-		commands = append(commands, cmd)
-		if methodOk {
-			cmd, err := command.NewApplyFixCommand("Extract method", command.ApplyFixArgs{
-				URI:   puri,
-				Fix:   source.ExtractMethod,
-				Range: rng,
-			})
-			if err != nil {
-				return nil, err
-			}
-			commands = append(commands, cmd)
-		}
-	}
-	if _, _, ok, _ := source.CanExtractVariable(srng, pgf.File); ok {
-		cmd, err := command.NewApplyFixCommand("Extract variable", command.ApplyFixArgs{
-			URI:   puri,
-			Fix:   source.ExtractVariable,
-			Range: rng,
-		})
-		if err != nil {
-			return nil, err
-		}
-		commands = append(commands, cmd)
-	}
-	var actions []protocol.CodeAction
-	for i := range commands {
-		actions = append(actions, protocol.CodeAction{
-			Title:   commands[i].Title,
-			Kind:    protocol.RefactorExtract,
-			Command: &commands[i],
-		})
-	}
-	return actions, nil
-}
-
-func documentChanges(fh source.VersionedFileHandle, edits []protocol.TextEdit) []protocol.DocumentChanges {
-	return []protocol.DocumentChanges{
-		{
-			TextDocumentEdit: &protocol.TextDocumentEdit{
-				TextDocument: protocol.OptionalVersionedTextDocumentIdentifier{
-					Version: fh.Version(),
-					TextDocumentIdentifier: protocol.TextDocumentIdentifier{
-						URI: protocol.URIFromSpanURI(fh.URI()),
-					},
-				},
-				Edits: edits,
-			},
-		},
-	}
-}
-
-func codeActionsMatchingDiagnostics(ctx context.Context, snapshot source.Snapshot, pdiags []protocol.Diagnostic, sdiags []*source.Diagnostic) ([]protocol.CodeAction, error) {
-	var actions []protocol.CodeAction
-	for _, sd := range sdiags {
-		var diag *protocol.Diagnostic
-		for _, pd := range pdiags {
-			if sameDiagnostic(pd, sd) {
-				diag = &pd
-				break
-			}
-		}
-		if diag == nil {
-			continue
-		}
-		diagActions, err := codeActionsForDiagnostic(ctx, snapshot, sd, diag)
-		if err != nil {
-			return nil, err
-		}
-		actions = append(actions, diagActions...)
-
-	}
-	return actions, nil
-}
-
-func codeActionsForDiagnostic(ctx context.Context, snapshot source.Snapshot, sd *source.Diagnostic, pd *protocol.Diagnostic) ([]protocol.CodeAction, error) {
-	var actions []protocol.CodeAction
-	for _, fix := range sd.SuggestedFixes {
-		var changes []protocol.DocumentChanges
-		for uri, edits := range fix.Edits {
-			fh, err := snapshot.GetVersionedFile(ctx, uri)
-			if err != nil {
-				return nil, err
-			}
-			changes = append(changes, protocol.DocumentChanges{
-				TextDocumentEdit: &protocol.TextDocumentEdit{
-					TextDocument: protocol.OptionalVersionedTextDocumentIdentifier{
-						Version: fh.Version(),
-						TextDocumentIdentifier: protocol.TextDocumentIdentifier{
-							URI: protocol.URIFromSpanURI(fh.URI()),
-						},
-					},
-					Edits: edits,
-				},
-			})
-		}
-		action := protocol.CodeAction{
-			Title: fix.Title,
-			Kind:  fix.ActionKind,
-			Edit: protocol.WorkspaceEdit{
-				DocumentChanges: changes,
-			},
-			Command: fix.Command,
-		}
-		if pd != nil {
-			action.Diagnostics = []protocol.Diagnostic{*pd}
-		}
-		actions = append(actions, action)
-	}
-	return actions, nil
-}
-
-func sameDiagnostic(pd protocol.Diagnostic, sd *source.Diagnostic) bool {
-	return pd.Message == strings.TrimSpace(sd.Message) && // extra space may have been trimmed when converting to protocol.Diagnostic
-		protocol.CompareRange(pd.Range, sd.Range) == 0 && pd.Source == string(sd.Source)
-}
-
-func goTest(ctx context.Context, snapshot source.Snapshot, uri span.URI, rng protocol.Range) ([]protocol.CodeAction, error) {
-	fh, err := snapshot.GetFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	fns, err := source.TestsAndBenchmarks(ctx, snapshot, fh)
-	if err != nil {
-		return nil, err
-	}
-
-	var tests, benchmarks []string
-	for _, fn := range fns.Tests {
-		if !protocol.Intersect(fn.Rng, rng) {
-			continue
-		}
-		tests = append(tests, fn.Name)
-	}
-	for _, fn := range fns.Benchmarks {
-		if !protocol.Intersect(fn.Rng, rng) {
-			continue
-		}
-		benchmarks = append(benchmarks, fn.Name)
-	}
-
-	if len(tests) == 0 && len(benchmarks) == 0 {
-		return nil, nil
-	}
-
-	cmd, err := command.NewTestCommand("Run tests and benchmarks", protocol.URIFromSpanURI(uri), tests, benchmarks)
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.CodeAction{{
-		Title:   cmd.Title,
-		Kind:    protocol.GoTest,
-		Command: &cmd,
-	}}, nil
-}
diff -urN a/gopls/internal/lsp/code_lens.go b/gopls/internal/lsp/code_lens.go
--- a/gopls/internal/lsp/code_lens.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/code_lens.go	1969-12-31 16:00:00
@@ -1,57 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"fmt"
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/mod"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-func (s *Server) codeLens(ctx context.Context, params *protocol.CodeLensParams) ([]protocol.CodeLens, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	var lenses map[command.Command]source.LensFunc
-	switch snapshot.View().FileKind(fh) {
-	case source.Mod:
-		lenses = mod.LensFuncs()
-	case source.Go:
-		lenses = source.LensFuncs()
-	default:
-		// Unsupported file kind for a code lens.
-		return nil, nil
-	}
-	var result []protocol.CodeLens
-	for cmd, lf := range lenses {
-		if !snapshot.View().Options().Codelenses[string(cmd)] {
-			continue
-		}
-		added, err := lf(ctx, snapshot, fh)
-		// Code lens is called on every keystroke, so we should just operate in
-		// a best-effort mode, ignoring errors.
-		if err != nil {
-			event.Error(ctx, fmt.Sprintf("code lens %s failed", cmd), err)
-			continue
-		}
-		result = append(result, added...)
-	}
-	sort.Slice(result, func(i, j int) bool {
-		a, b := result[i], result[j]
-		if cmp := protocol.CompareRange(a.Range, b.Range); cmp != 0 {
-			return cmp < 0
-		}
-		return a.Command.Command < b.Command.Command
-	})
-	return result, nil
-}
diff -urN a/gopls/internal/lsp/command/command_gen.go b/gopls/internal/lsp/command/command_gen.go
--- a/gopls/internal/lsp/command/command_gen.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/command_gen.go	1969-12-31 16:00:00
@@ -1,513 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Don't include this file during code generation, or it will break the build
-// if existing interface methods have been modified.
-//go:build !generate
-// +build !generate
-
-package command
-
-// Code generated by generate.go. DO NOT EDIT.
-
-import (
-	"context"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-const (
-	AddDependency         Command = "add_dependency"
-	AddImport             Command = "add_import"
-	ApplyFix              Command = "apply_fix"
-	CheckUpgrades         Command = "check_upgrades"
-	EditGoDirective       Command = "edit_go_directive"
-	FetchVulncheckResult  Command = "fetch_vulncheck_result"
-	GCDetails             Command = "gc_details"
-	Generate              Command = "generate"
-	GenerateGoplsMod      Command = "generate_gopls_mod"
-	GoGetPackage          Command = "go_get_package"
-	ListImports           Command = "list_imports"
-	ListKnownPackages     Command = "list_known_packages"
-	RegenerateCgo         Command = "regenerate_cgo"
-	RemoveDependency      Command = "remove_dependency"
-	ResetGoModDiagnostics Command = "reset_go_mod_diagnostics"
-	RunGovulncheck        Command = "run_govulncheck"
-	RunTests              Command = "run_tests"
-	StartDebugging        Command = "start_debugging"
-	Test                  Command = "test"
-	Tidy                  Command = "tidy"
-	ToggleGCDetails       Command = "toggle_gc_details"
-	UpdateGoSum           Command = "update_go_sum"
-	UpgradeDependency     Command = "upgrade_dependency"
-	Vendor                Command = "vendor"
-)
-
-var Commands = []Command{
-	AddDependency,
-	AddImport,
-	ApplyFix,
-	CheckUpgrades,
-	EditGoDirective,
-	FetchVulncheckResult,
-	GCDetails,
-	Generate,
-	GenerateGoplsMod,
-	GoGetPackage,
-	ListImports,
-	ListKnownPackages,
-	RegenerateCgo,
-	RemoveDependency,
-	ResetGoModDiagnostics,
-	RunGovulncheck,
-	RunTests,
-	StartDebugging,
-	Test,
-	Tidy,
-	ToggleGCDetails,
-	UpdateGoSum,
-	UpgradeDependency,
-	Vendor,
-}
-
-func Dispatch(ctx context.Context, params *protocol.ExecuteCommandParams, s Interface) (interface{}, error) {
-	switch params.Command {
-	case "gopls.add_dependency":
-		var a0 DependencyArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.AddDependency(ctx, a0)
-	case "gopls.add_import":
-		var a0 AddImportArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.AddImport(ctx, a0)
-	case "gopls.apply_fix":
-		var a0 ApplyFixArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.ApplyFix(ctx, a0)
-	case "gopls.check_upgrades":
-		var a0 CheckUpgradesArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.CheckUpgrades(ctx, a0)
-	case "gopls.edit_go_directive":
-		var a0 EditGoDirectiveArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.EditGoDirective(ctx, a0)
-	case "gopls.fetch_vulncheck_result":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return s.FetchVulncheckResult(ctx, a0)
-	case "gopls.gc_details":
-		var a0 protocol.DocumentURI
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.GCDetails(ctx, a0)
-	case "gopls.generate":
-		var a0 GenerateArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.Generate(ctx, a0)
-	case "gopls.generate_gopls_mod":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.GenerateGoplsMod(ctx, a0)
-	case "gopls.go_get_package":
-		var a0 GoGetPackageArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.GoGetPackage(ctx, a0)
-	case "gopls.list_imports":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return s.ListImports(ctx, a0)
-	case "gopls.list_known_packages":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return s.ListKnownPackages(ctx, a0)
-	case "gopls.regenerate_cgo":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.RegenerateCgo(ctx, a0)
-	case "gopls.remove_dependency":
-		var a0 RemoveDependencyArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.RemoveDependency(ctx, a0)
-	case "gopls.reset_go_mod_diagnostics":
-		var a0 ResetGoModDiagnosticsArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.ResetGoModDiagnostics(ctx, a0)
-	case "gopls.run_govulncheck":
-		var a0 VulncheckArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return s.RunGovulncheck(ctx, a0)
-	case "gopls.run_tests":
-		var a0 RunTestsArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.RunTests(ctx, a0)
-	case "gopls.start_debugging":
-		var a0 DebuggingArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return s.StartDebugging(ctx, a0)
-	case "gopls.test":
-		var a0 protocol.DocumentURI
-		var a1 []string
-		var a2 []string
-		if err := UnmarshalArgs(params.Arguments, &a0, &a1, &a2); err != nil {
-			return nil, err
-		}
-		return nil, s.Test(ctx, a0, a1, a2)
-	case "gopls.tidy":
-		var a0 URIArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.Tidy(ctx, a0)
-	case "gopls.toggle_gc_details":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.ToggleGCDetails(ctx, a0)
-	case "gopls.update_go_sum":
-		var a0 URIArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.UpdateGoSum(ctx, a0)
-	case "gopls.upgrade_dependency":
-		var a0 DependencyArgs
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.UpgradeDependency(ctx, a0)
-	case "gopls.vendor":
-		var a0 URIArg
-		if err := UnmarshalArgs(params.Arguments, &a0); err != nil {
-			return nil, err
-		}
-		return nil, s.Vendor(ctx, a0)
-	}
-	return nil, fmt.Errorf("unsupported command %q", params.Command)
-}
-
-func NewAddDependencyCommand(title string, a0 DependencyArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.add_dependency",
-		Arguments: args,
-	}, nil
-}
-
-func NewAddImportCommand(title string, a0 AddImportArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.add_import",
-		Arguments: args,
-	}, nil
-}
-
-func NewApplyFixCommand(title string, a0 ApplyFixArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.apply_fix",
-		Arguments: args,
-	}, nil
-}
-
-func NewCheckUpgradesCommand(title string, a0 CheckUpgradesArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.check_upgrades",
-		Arguments: args,
-	}, nil
-}
-
-func NewEditGoDirectiveCommand(title string, a0 EditGoDirectiveArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.edit_go_directive",
-		Arguments: args,
-	}, nil
-}
-
-func NewFetchVulncheckResultCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.fetch_vulncheck_result",
-		Arguments: args,
-	}, nil
-}
-
-func NewGCDetailsCommand(title string, a0 protocol.DocumentURI) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.gc_details",
-		Arguments: args,
-	}, nil
-}
-
-func NewGenerateCommand(title string, a0 GenerateArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.generate",
-		Arguments: args,
-	}, nil
-}
-
-func NewGenerateGoplsModCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.generate_gopls_mod",
-		Arguments: args,
-	}, nil
-}
-
-func NewGoGetPackageCommand(title string, a0 GoGetPackageArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.go_get_package",
-		Arguments: args,
-	}, nil
-}
-
-func NewListImportsCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.list_imports",
-		Arguments: args,
-	}, nil
-}
-
-func NewListKnownPackagesCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.list_known_packages",
-		Arguments: args,
-	}, nil
-}
-
-func NewRegenerateCgoCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.regenerate_cgo",
-		Arguments: args,
-	}, nil
-}
-
-func NewRemoveDependencyCommand(title string, a0 RemoveDependencyArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.remove_dependency",
-		Arguments: args,
-	}, nil
-}
-
-func NewResetGoModDiagnosticsCommand(title string, a0 ResetGoModDiagnosticsArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.reset_go_mod_diagnostics",
-		Arguments: args,
-	}, nil
-}
-
-func NewRunGovulncheckCommand(title string, a0 VulncheckArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.run_govulncheck",
-		Arguments: args,
-	}, nil
-}
-
-func NewRunTestsCommand(title string, a0 RunTestsArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.run_tests",
-		Arguments: args,
-	}, nil
-}
-
-func NewStartDebuggingCommand(title string, a0 DebuggingArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.start_debugging",
-		Arguments: args,
-	}, nil
-}
-
-func NewTestCommand(title string, a0 protocol.DocumentURI, a1 []string, a2 []string) (protocol.Command, error) {
-	args, err := MarshalArgs(a0, a1, a2)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.test",
-		Arguments: args,
-	}, nil
-}
-
-func NewTidyCommand(title string, a0 URIArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.tidy",
-		Arguments: args,
-	}, nil
-}
-
-func NewToggleGCDetailsCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.toggle_gc_details",
-		Arguments: args,
-	}, nil
-}
-
-func NewUpdateGoSumCommand(title string, a0 URIArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.update_go_sum",
-		Arguments: args,
-	}, nil
-}
-
-func NewUpgradeDependencyCommand(title string, a0 DependencyArgs) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.upgrade_dependency",
-		Arguments: args,
-	}, nil
-}
-
-func NewVendorCommand(title string, a0 URIArg) (protocol.Command, error) {
-	args, err := MarshalArgs(a0)
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title:     title,
-		Command:   "gopls.vendor",
-		Arguments: args,
-	}, nil
-}
diff -urN a/gopls/internal/lsp/command/commandmeta/meta.go b/gopls/internal/lsp/command/commandmeta/meta.go
--- a/gopls/internal/lsp/command/commandmeta/meta.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/commandmeta/meta.go	1969-12-31 16:00:00
@@ -1,259 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package commandmeta provides metadata about LSP commands, by analyzing the
-// command.Interface type.
-package commandmeta
-
-import (
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"reflect"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-)
-
-type Command struct {
-	MethodName string
-	Name       string
-	// TODO(rFindley): I think Title can actually be eliminated. In all cases
-	// where we use it, there is probably a more appropriate contextual title.
-	Title  string
-	Doc    string
-	Args   []*Field
-	Result *Field
-}
-
-func (c *Command) ID() string {
-	return command.ID(c.Name)
-}
-
-type Field struct {
-	Name     string
-	Doc      string
-	JSONTag  string
-	Type     types.Type
-	FieldMod string
-	// In some circumstances, we may want to recursively load additional field
-	// descriptors for fields of struct types, documenting their internals.
-	Fields []*Field
-}
-
-func Load() (*packages.Package, []*Command, error) {
-	pkgs, err := packages.Load(
-		&packages.Config{
-			Mode:       packages.NeedTypes | packages.NeedTypesInfo | packages.NeedSyntax | packages.NeedImports | packages.NeedDeps,
-			BuildFlags: []string{"-tags=generate"},
-		},
-		"golang.org/x/tools/gopls/internal/lsp/command",
-	)
-	if err != nil {
-		return nil, nil, fmt.Errorf("packages.Load: %v", err)
-	}
-	pkg := pkgs[0]
-	if len(pkg.Errors) > 0 {
-		return pkg, nil, pkg.Errors[0]
-	}
-
-	// For a bit of type safety, use reflection to get the interface name within
-	// the package scope.
-	it := reflect.TypeOf((*command.Interface)(nil)).Elem()
-	obj := pkg.Types.Scope().Lookup(it.Name()).Type().Underlying().(*types.Interface)
-
-	// Load command metadata corresponding to each interface method.
-	var commands []*Command
-	loader := fieldLoader{make(map[types.Object]*Field)}
-	for i := 0; i < obj.NumMethods(); i++ {
-		m := obj.Method(i)
-		c, err := loader.loadMethod(pkg, m)
-		if err != nil {
-			return nil, nil, fmt.Errorf("loading %s: %v", m.Name(), err)
-		}
-		commands = append(commands, c)
-	}
-	return pkg, commands, nil
-}
-
-// fieldLoader loads field information, memoizing results to prevent infinite
-// recursion.
-type fieldLoader struct {
-	loaded map[types.Object]*Field
-}
-
-var universeError = types.Universe.Lookup("error").Type()
-
-func (l *fieldLoader) loadMethod(pkg *packages.Package, m *types.Func) (*Command, error) {
-	node, err := findField(pkg, m.Pos())
-	if err != nil {
-		return nil, err
-	}
-	title, doc := splitDoc(node.Doc.Text())
-	c := &Command{
-		MethodName: m.Name(),
-		Name:       lspName(m.Name()),
-		Doc:        doc,
-		Title:      title,
-	}
-	sig := m.Type().Underlying().(*types.Signature)
-	rlen := sig.Results().Len()
-	if rlen > 2 || rlen == 0 {
-		return nil, fmt.Errorf("must have 1 or 2 returns, got %d", rlen)
-	}
-	finalResult := sig.Results().At(rlen - 1)
-	if !types.Identical(finalResult.Type(), universeError) {
-		return nil, fmt.Errorf("final return must be error")
-	}
-	if rlen == 2 {
-		obj := sig.Results().At(0)
-		c.Result, err = l.loadField(pkg, obj, "", "")
-		if err != nil {
-			return nil, err
-		}
-	}
-	for i := 0; i < sig.Params().Len(); i++ {
-		obj := sig.Params().At(i)
-		fld, err := l.loadField(pkg, obj, "", "")
-		if err != nil {
-			return nil, err
-		}
-		if i == 0 {
-			// Lazy check that the first argument is a context. We could relax this,
-			// but then the generated code gets more complicated.
-			if named, ok := fld.Type.(*types.Named); !ok || named.Obj().Name() != "Context" || named.Obj().Pkg().Path() != "context" {
-				return nil, fmt.Errorf("first method parameter must be context.Context")
-			}
-			// Skip the context argument, as it is implied.
-			continue
-		}
-		c.Args = append(c.Args, fld)
-	}
-	return c, nil
-}
-
-func (l *fieldLoader) loadField(pkg *packages.Package, obj *types.Var, doc, tag string) (*Field, error) {
-	if existing, ok := l.loaded[obj]; ok {
-		return existing, nil
-	}
-	fld := &Field{
-		Name:    obj.Name(),
-		Doc:     strings.TrimSpace(doc),
-		Type:    obj.Type(),
-		JSONTag: reflect.StructTag(tag).Get("json"),
-	}
-	under := fld.Type.Underlying()
-	// Quick-and-dirty handling for various underlying types.
-	switch p := under.(type) {
-	case *types.Pointer:
-		under = p.Elem().Underlying()
-	case *types.Array:
-		under = p.Elem().Underlying()
-		fld.FieldMod = fmt.Sprintf("[%d]", p.Len())
-	case *types.Slice:
-		under = p.Elem().Underlying()
-		fld.FieldMod = "[]"
-	}
-
-	if s, ok := under.(*types.Struct); ok {
-		for i := 0; i < s.NumFields(); i++ {
-			obj2 := s.Field(i)
-			pkg2 := pkg
-			if obj2.Pkg() != pkg2.Types {
-				pkg2, ok = pkg.Imports[obj2.Pkg().Path()]
-				if !ok {
-					return nil, fmt.Errorf("missing import for %q: %q", pkg.ID, obj2.Pkg().Path())
-				}
-			}
-			node, err := findField(pkg2, obj2.Pos())
-			if err != nil {
-				return nil, err
-			}
-			tag := s.Tag(i)
-			structField, err := l.loadField(pkg2, obj2, node.Doc.Text(), tag)
-			if err != nil {
-				return nil, err
-			}
-			fld.Fields = append(fld.Fields, structField)
-		}
-	}
-	return fld, nil
-}
-
-// splitDoc parses a command doc string to separate the title from normal
-// documentation.
-//
-// The doc comment should be of the form: "MethodName: Title\nDocumentation"
-func splitDoc(text string) (title, doc string) {
-	docParts := strings.SplitN(text, "\n", 2)
-	titleParts := strings.SplitN(docParts[0], ":", 2)
-	if len(titleParts) > 1 {
-		title = strings.TrimSpace(titleParts[1])
-	}
-	if len(docParts) > 1 {
-		doc = strings.TrimSpace(docParts[1])
-	}
-	return title, doc
-}
-
-// lspName returns the normalized command name to use in the LSP.
-func lspName(methodName string) string {
-	words := splitCamel(methodName)
-	for i := range words {
-		words[i] = strings.ToLower(words[i])
-	}
-	return strings.Join(words, "_")
-}
-
-// splitCamel splits s into words, according to camel-case word boundaries.
-// Initialisms are grouped as a single word.
-//
-// For example:
-//
-//	"RunTests" -> []string{"Run", "Tests"}
-//	"GCDetails" -> []string{"GC", "Details"}
-func splitCamel(s string) []string {
-	var words []string
-	for len(s) > 0 {
-		last := strings.LastIndexFunc(s, unicode.IsUpper)
-		if last < 0 {
-			last = 0
-		}
-		if last == len(s)-1 {
-			// Group initialisms as a single word.
-			last = 1 + strings.LastIndexFunc(s[:last], func(r rune) bool { return !unicode.IsUpper(r) })
-		}
-		words = append(words, s[last:])
-		s = s[:last]
-	}
-	for i := 0; i < len(words)/2; i++ {
-		j := len(words) - i - 1
-		words[i], words[j] = words[j], words[i]
-	}
-	return words
-}
-
-// findField finds the struct field or interface method positioned at pos,
-// within the AST.
-func findField(pkg *packages.Package, pos token.Pos) (*ast.Field, error) {
-	fset := pkg.Fset
-	var file *ast.File
-	for _, f := range pkg.Syntax {
-		if fset.File(f.Pos()).Name() == fset.File(pos).Name() {
-			file = f
-			break
-		}
-	}
-	if file == nil {
-		return nil, fmt.Errorf("no file for pos %v", pos)
-	}
-	path, _ := astutil.PathEnclosingInterval(file, pos, pos)
-	// This is fragile, but in the cases we care about, the field will be in
-	// path[1].
-	return path[1].(*ast.Field), nil
-}
diff -urN a/gopls/internal/lsp/command/gen/gen.go b/gopls/internal/lsp/command/gen/gen.go
--- a/gopls/internal/lsp/command/gen/gen.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/gen/gen.go	1969-12-31 16:00:00
@@ -1,155 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package gen is used to generate command bindings from the gopls command
-// interface.
-package gen
-
-import (
-	"bytes"
-	"fmt"
-	"go/types"
-	"text/template"
-
-	"golang.org/x/tools/internal/imports"
-	"golang.org/x/tools/gopls/internal/lsp/command/commandmeta"
-)
-
-const src = `// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Don't include this file during code generation, or it will break the build
-// if existing interface methods have been modified.
-//go:build !generate
-// +build !generate
-
-package command
-
-// Code generated by generate.go. DO NOT EDIT.
-
-import (
-	{{range $k, $v := .Imports -}}
-	"{{$k}}"
-	{{end}}
-)
-
-const (
-{{- range .Commands}}
-	{{.MethodName}} Command = "{{.Name}}"
-{{- end}}
-)
-
-var Commands = []Command {
-{{- range .Commands}}
-	{{.MethodName}},
-{{- end}}
-}
-
-func Dispatch(ctx context.Context, params *protocol.ExecuteCommandParams, s Interface) (interface{}, error) {
-	switch params.Command {
-	{{- range .Commands}}
-	case "{{.ID}}":
-		{{- if .Args -}}
-			{{- range $i, $v := .Args}}
-		var a{{$i}} {{typeString $v.Type}}
-			{{- end}}
-		if err := UnmarshalArgs(params.Arguments{{range $i, $v := .Args}}, &a{{$i}}{{end}}); err != nil {
-			return nil, err
-		}
-		{{end -}}
-		return {{if not .Result}}nil, {{end}}s.{{.MethodName}}(ctx{{range $i, $v := .Args}}, a{{$i}}{{end}})
-	{{- end}}
-	}
-	return nil, fmt.Errorf("unsupported command %q", params.Command)
-}
-{{- range .Commands}}
-
-func New{{.MethodName}}Command(title string, {{range $i, $v := .Args}}{{if $i}}, {{end}}a{{$i}} {{typeString $v.Type}}{{end}}) (protocol.Command, error) {
-	args, err := MarshalArgs({{range $i, $v := .Args}}{{if $i}}, {{end}}a{{$i}}{{end}})
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return protocol.Command{
-		Title: title,
-		Command: "{{.ID}}",
-		Arguments: args,
-	}, nil
-}
-{{end}}
-`
-
-type data struct {
-	Imports  map[string]bool
-	Commands []*commandmeta.Command
-}
-
-func Generate() ([]byte, error) {
-	pkg, cmds, err := commandmeta.Load()
-	if err != nil {
-		return nil, fmt.Errorf("loading command data: %v", err)
-	}
-	qf := func(p *types.Package) string {
-		if p == pkg.Types {
-			return ""
-		}
-		return p.Name()
-	}
-	tmpl, err := template.New("").Funcs(template.FuncMap{
-		"typeString": func(t types.Type) string {
-			return types.TypeString(t, qf)
-		},
-	}).Parse(src)
-	if err != nil {
-		return nil, err
-	}
-	d := data{
-		Commands: cmds,
-		Imports: map[string]bool{
-			"context": true,
-			"fmt":     true,
-			"golang.org/x/tools/gopls/internal/lsp/protocol": true,
-		},
-	}
-	const thispkg = "golang.org/x/tools/gopls/internal/lsp/command"
-	for _, c := range d.Commands {
-		for _, arg := range c.Args {
-			pth := pkgPath(arg.Type)
-			if pth != "" && pth != thispkg {
-				d.Imports[pth] = true
-			}
-		}
-		if c.Result != nil {
-			pth := pkgPath(c.Result.Type)
-			if pth != "" && pth != thispkg {
-				d.Imports[pth] = true
-			}
-		}
-	}
-
-	var buf bytes.Buffer
-	if err := tmpl.Execute(&buf, d); err != nil {
-		return nil, fmt.Errorf("executing: %v", err)
-	}
-
-	opts := &imports.Options{
-		AllErrors:  true,
-		FormatOnly: true,
-		Comments:   true,
-	}
-	content, err := imports.Process("", buf.Bytes(), opts)
-	if err != nil {
-		return nil, fmt.Errorf("goimports: %v", err)
-	}
-	return content, nil
-}
-
-func pkgPath(t types.Type) string {
-	if n, ok := t.(*types.Named); ok {
-		if pkg := n.Obj().Pkg(); pkg != nil {
-			return pkg.Path()
-		}
-	}
-	return ""
-}
diff -urN a/gopls/internal/lsp/command/generate.go b/gopls/internal/lsp/command/generate.go
--- a/gopls/internal/lsp/command/generate.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/generate.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build ignore
-// +build ignore
-
-package main
-
-import (
-	"fmt"
-	"io/ioutil"
-	"os"
-
-	"golang.org/x/tools/gopls/internal/lsp/command/gen"
-)
-
-func main() {
-	content, err := gen.Generate()
-	if err != nil {
-		fmt.Fprintf(os.Stderr, "%v\n", err)
-		os.Exit(1)
-	}
-	ioutil.WriteFile("command_gen.go", content, 0644)
-}
diff -urN a/gopls/internal/lsp/command/interface.go b/gopls/internal/lsp/command/interface.go
--- a/gopls/internal/lsp/command/interface.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/interface.go	1969-12-31 16:00:00
@@ -1,401 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package command defines the interface provided by gopls for the
-// workspace/executeCommand LSP request.
-//
-// This interface is fully specified by the Interface type, provided it
-// conforms to the restrictions outlined in its doc string.
-//
-// Bindings for server-side command dispatch and client-side serialization are
-// also provided by this package, via code generation.
-package command
-
-//go:generate go run -tags=generate generate.go
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// Interface defines the interface gopls exposes for the
-// workspace/executeCommand request.
-//
-// This interface is used to generate marshaling/unmarshaling code, dispatch,
-// and documentation, and so has some additional restrictions:
-//  1. All method arguments must be JSON serializable.
-//  2. Methods must return either error or (T, error), where T is a
-//     JSON serializable type.
-//  3. The first line of the doc string is special. Everything after the colon
-//     is considered the command 'Title'.
-//     TODO(rFindley): reconsider this -- Title may be unnecessary.
-type Interface interface {
-	// ApplyFix: Apply a fix
-	//
-	// Applies a fix to a region of source code.
-	ApplyFix(context.Context, ApplyFixArgs) error
-	// Test: Run test(s) (legacy)
-	//
-	// Runs `go test` for a specific set of test or benchmark functions.
-	Test(context.Context, protocol.DocumentURI, []string, []string) error
-
-	// TODO: deprecate Test in favor of RunTests below.
-
-	// Test: Run test(s)
-	//
-	// Runs `go test` for a specific set of test or benchmark functions.
-	RunTests(context.Context, RunTestsArgs) error
-
-	// Generate: Run go generate
-	//
-	// Runs `go generate` for a given directory.
-	Generate(context.Context, GenerateArgs) error
-
-	// RegenerateCgo: Regenerate cgo
-	//
-	// Regenerates cgo definitions.
-	RegenerateCgo(context.Context, URIArg) error
-
-	// Tidy: Run go mod tidy
-	//
-	// Runs `go mod tidy` for a module.
-	Tidy(context.Context, URIArgs) error
-
-	// Vendor: Run go mod vendor
-	//
-	// Runs `go mod vendor` for a module.
-	Vendor(context.Context, URIArg) error
-
-	// EditGoDirective: Run go mod edit -go=version
-	//
-	// Runs `go mod edit -go=version` for a module.
-	EditGoDirective(context.Context, EditGoDirectiveArgs) error
-
-	// UpdateGoSum: Update go.sum
-	//
-	// Updates the go.sum file for a module.
-	UpdateGoSum(context.Context, URIArgs) error
-
-	// CheckUpgrades: Check for upgrades
-	//
-	// Checks for module upgrades.
-	CheckUpgrades(context.Context, CheckUpgradesArgs) error
-
-	// AddDependency: Add a dependency
-	//
-	// Adds a dependency to the go.mod file for a module.
-	AddDependency(context.Context, DependencyArgs) error
-
-	// UpgradeDependency: Upgrade a dependency
-	//
-	// Upgrades a dependency in the go.mod file for a module.
-	UpgradeDependency(context.Context, DependencyArgs) error
-
-	// RemoveDependency: Remove a dependency
-	//
-	// Removes a dependency from the go.mod file of a module.
-	RemoveDependency(context.Context, RemoveDependencyArgs) error
-
-	// ResetGoModDiagnostics: Reset go.mod diagnostics
-	//
-	// Reset diagnostics in the go.mod file of a module.
-	ResetGoModDiagnostics(context.Context, ResetGoModDiagnosticsArgs) error
-
-	// GoGetPackage: go get a package
-	//
-	// Runs `go get` to fetch a package.
-	GoGetPackage(context.Context, GoGetPackageArgs) error
-
-	// GCDetails: Toggle gc_details
-	//
-	// Toggle the calculation of gc annotations.
-	GCDetails(context.Context, protocol.DocumentURI) error
-
-	// TODO: deprecate GCDetails in favor of ToggleGCDetails below.
-
-	// ToggleGCDetails: Toggle gc_details
-	//
-	// Toggle the calculation of gc annotations.
-	ToggleGCDetails(context.Context, URIArg) error
-
-	// GenerateGoplsMod: Generate gopls.mod
-	//
-	// (Re)generate the gopls.mod file for a workspace.
-	GenerateGoplsMod(context.Context, URIArg) error
-
-	// ListKnownPackages: List known packages
-	//
-	// Retrieve a list of packages that are importable from the given URI.
-	ListKnownPackages(context.Context, URIArg) (ListKnownPackagesResult, error)
-
-	// ListImports: List imports of a file and its package
-	//
-	// Retrieve a list of imports in the given Go file, and the package it
-	// belongs to.
-	ListImports(context.Context, URIArg) (ListImportsResult, error)
-
-	// AddImport: Add an import
-	//
-	// Ask the server to add an import path to a given Go file.  The method will
-	// call applyEdit on the client so that clients don't have to apply the edit
-	// themselves.
-	AddImport(context.Context, AddImportArgs) error
-
-	// StartDebugging: Start the gopls debug server
-	//
-	// Start the gopls debug server if it isn't running, and return the debug
-	// address.
-	StartDebugging(context.Context, DebuggingArgs) (DebuggingResult, error)
-
-	// RunGovulncheck: Run govulncheck.
-	//
-	// Run vulnerability check (`govulncheck`).
-	RunGovulncheck(context.Context, VulncheckArgs) (RunVulncheckResult, error)
-
-	// FetchVulncheckResult: Get known vulncheck result
-	//
-	// Fetch the result of latest vulnerability check (`govulncheck`).
-	FetchVulncheckResult(context.Context, URIArg) (map[protocol.DocumentURI]*govulncheck.Result, error)
-}
-
-type RunTestsArgs struct {
-	// The test file containing the tests to run.
-	URI protocol.DocumentURI
-
-	// Specific test names to run, e.g. TestFoo.
-	Tests []string
-
-	// Specific benchmarks to run, e.g. BenchmarkFoo.
-	Benchmarks []string
-}
-
-type GenerateArgs struct {
-	// URI for the directory to generate.
-	Dir protocol.DocumentURI
-
-	// Whether to generate recursively (go generate ./...)
-	Recursive bool
-}
-
-// TODO(rFindley): document the rest of these once the docgen is fleshed out.
-
-type ApplyFixArgs struct {
-	// The fix to apply.
-	Fix string
-	// The file URI for the document to fix.
-	URI protocol.DocumentURI
-	// The document range to scan for fixes.
-	Range protocol.Range
-}
-
-type URIArg struct {
-	// The file URI.
-	URI protocol.DocumentURI
-}
-
-type URIArgs struct {
-	// The file URIs.
-	URIs []protocol.DocumentURI
-}
-
-type CheckUpgradesArgs struct {
-	// The go.mod file URI.
-	URI protocol.DocumentURI
-	// The modules to check.
-	Modules []string
-}
-
-type DependencyArgs struct {
-	// The go.mod file URI.
-	URI protocol.DocumentURI
-	// Additional args to pass to the go command.
-	GoCmdArgs []string
-	// Whether to add a require directive.
-	AddRequire bool
-}
-
-type RemoveDependencyArgs struct {
-	// The go.mod file URI.
-	URI protocol.DocumentURI
-	// The module path to remove.
-	ModulePath     string
-	OnlyDiagnostic bool
-}
-
-type EditGoDirectiveArgs struct {
-	// Any document URI within the relevant module.
-	URI protocol.DocumentURI
-	// The version to pass to `go mod edit -go`.
-	Version string
-}
-
-type GoGetPackageArgs struct {
-	// Any document URI within the relevant module.
-	URI protocol.DocumentURI
-	// The package to go get.
-	Pkg        string
-	AddRequire bool
-}
-
-type AddImportArgs struct {
-	// ImportPath is the target import path that should
-	// be added to the URI file
-	ImportPath string
-	// URI is the file that the ImportPath should be
-	// added to
-	URI protocol.DocumentURI
-}
-
-type ListKnownPackagesResult struct {
-	// Packages is a list of packages relative
-	// to the URIArg passed by the command request.
-	// In other words, it omits paths that are already
-	// imported or cannot be imported due to compiler
-	// restrictions.
-	Packages []string
-}
-
-type ListImportsResult struct {
-	// Imports is a list of imports in the requested file.
-	Imports []FileImport
-
-	// PackageImports is a list of all imports in the requested file's package.
-	PackageImports []PackageImport
-}
-
-type FileImport struct {
-	// Path is the import path of the import.
-	Path string
-	// Name is the name of the import, e.g. `foo` in `import foo "strings"`.
-	Name string
-}
-
-type PackageImport struct {
-	// Path is the import path of the import.
-	Path string
-}
-
-type DebuggingArgs struct {
-	// Optional: the address (including port) for the debug server to listen on.
-	// If not provided, the debug server will bind to "localhost:0", and the
-	// full debug URL will be contained in the result.
-	//
-	// If there is more than one gopls instance along the serving path (i.e. you
-	// are using a daemon), each gopls instance will attempt to start debugging.
-	// If Addr specifies a port, only the daemon will be able to bind to that
-	// port, and each intermediate gopls instance will fail to start debugging.
-	// For this reason it is recommended not to specify a port (or equivalently,
-	// to specify ":0").
-	//
-	// If the server was already debugging this field has no effect, and the
-	// result will contain the previously configured debug URL(s).
-	Addr string
-}
-
-type DebuggingResult struct {
-	// The URLs to use to access the debug servers, for all gopls instances in
-	// the serving path. For the common case of a single gopls instance (i.e. no
-	// daemon), this will be exactly one address.
-	//
-	// In the case of one or more gopls instances forwarding the LSP to a daemon,
-	// URLs will contain debug addresses for each server in the serving path, in
-	// serving order. The daemon debug address will be the last entry in the
-	// slice. If any intermediate gopls instance fails to start debugging, no
-	// error will be returned but the debug URL for that server in the URLs slice
-	// will be empty.
-	URLs []string
-}
-
-type ResetGoModDiagnosticsArgs struct {
-	URIArg
-
-	// Optional: source of the diagnostics to reset.
-	// If not set, all resettable go.mod diagnostics will be cleared.
-	DiagnosticSource string
-}
-
-type VulncheckArgs struct {
-	// Any document in the directory from which govulncheck will run.
-	URI protocol.DocumentURI
-
-	// Package pattern. E.g. "", ".", "./...".
-	Pattern string
-
-	// TODO: -tests
-}
-
-// RunVulncheckResult holds the result of asynchronously starting the vulncheck
-// command.
-type RunVulncheckResult struct {
-	// Token holds the progress token for LSP workDone reporting of the vulncheck
-	// invocation.
-	Token protocol.ProgressToken
-}
-
-type VulncheckResult struct {
-	Vuln []Vuln
-
-	// TODO: Text string format output?
-}
-
-// CallStack models a trace of function calls starting
-// with a client function or method and ending with a
-// call to a vulnerable symbol.
-type CallStack []StackEntry
-
-// StackEntry models an element of a call stack.
-type StackEntry struct {
-	// See golang.org/x/exp/vulncheck.StackEntry.
-
-	// User-friendly representation of function/method names.
-	// e.g. package.funcName, package.(recvType).methodName, ...
-	Name string
-	URI  protocol.DocumentURI
-	Pos  protocol.Position // Start position. (0-based. Column is always 0)
-}
-
-// Vuln models an osv.Entry and representative call stacks.
-// TODO: deprecate
-type Vuln struct {
-	// ID is the vulnerability ID (osv.Entry.ID).
-	// https://ossf.github.io/osv-schema/#id-modified-fields
-	ID string
-	// Details is the description of the vulnerability (osv.Entry.Details).
-	// https://ossf.github.io/osv-schema/#summary-details-fields
-	Details string `json:",omitempty"`
-	// Aliases are alternative IDs of the vulnerability.
-	// https://ossf.github.io/osv-schema/#aliases-field
-	Aliases []string `json:",omitempty"`
-
-	// Symbol is the name of the detected vulnerable function or method.
-	// Can be empty if the vulnerability exists in required modules, but no vulnerable symbols are used.
-	Symbol string `json:",omitempty"`
-	// PkgPath is the package path of the detected Symbol.
-	// Can be empty if the vulnerability exists in required modules, but no vulnerable packages are used.
-	PkgPath string `json:",omitempty"`
-	// ModPath is the module path corresponding to PkgPath.
-	// TODO: how do we specify standard library's vulnerability?
-	ModPath string `json:",omitempty"`
-
-	// URL is the URL for more info about the information.
-	// Either the database specific URL or the one of the URLs
-	// included in osv.Entry.References.
-	URL string `json:",omitempty"`
-
-	// Current is the current module version.
-	CurrentVersion string `json:",omitempty"`
-
-	// Fixed is the minimum module version that contains the fix.
-	FixedVersion string `json:",omitempty"`
-
-	// Example call stacks.
-	CallStacks []CallStack `json:",omitempty"`
-
-	// Short description of each call stack in CallStacks.
-	CallStackSummaries []string `json:",omitempty"`
-
-	// TODO: import graph & module graph.
-}
diff -urN a/gopls/internal/lsp/command/interface_test.go b/gopls/internal/lsp/command/interface_test.go
--- a/gopls/internal/lsp/command/interface_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/interface_test.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package command_test
-
-import (
-	"bytes"
-	"io/ioutil"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/command/gen"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestGenerated(t *testing.T) {
-	testenv.NeedsGoBuild(t) // This is a lie. We actually need the source code.
-
-	onDisk, err := ioutil.ReadFile("command_gen.go")
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	generated, err := gen.Generate()
-	if err != nil {
-		t.Fatal(err)
-	}
-	if !bytes.Equal(onDisk, generated) {
-		t.Error("command_gen.go is stale -- regenerate")
-	}
-}
diff -urN a/gopls/internal/lsp/command/util.go b/gopls/internal/lsp/command/util.go
--- a/gopls/internal/lsp/command/util.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command/util.go	1969-12-31 16:00:00
@@ -1,63 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package command
-
-import (
-	"encoding/json"
-	"fmt"
-)
-
-// ID returns the command name for use in the LSP.
-func ID(name string) string {
-	return "gopls." + name
-}
-
-type Command string
-
-func (c Command) ID() string {
-	return ID(string(c))
-}
-
-// MarshalArgs encodes the given arguments to json.RawMessages. This function
-// is used to construct arguments to a protocol.Command.
-//
-// Example usage:
-//
-//	jsonArgs, err := MarshalArgs(1, "hello", true, StructuredArg{42, 12.6})
-func MarshalArgs(args ...interface{}) ([]json.RawMessage, error) {
-	var out []json.RawMessage
-	for _, arg := range args {
-		argJSON, err := json.Marshal(arg)
-		if err != nil {
-			return nil, err
-		}
-		out = append(out, argJSON)
-	}
-	return out, nil
-}
-
-// UnmarshalArgs decodes the given json.RawMessages to the variables provided
-// by args. Each element of args should be a pointer.
-//
-// Example usage:
-//
-//	var (
-//	    num int
-//	    str string
-//	    bul bool
-//	    structured StructuredArg
-//	)
-//	err := UnmarshalArgs(args, &num, &str, &bul, &structured)
-func UnmarshalArgs(jsonArgs []json.RawMessage, args ...interface{}) error {
-	if len(args) != len(jsonArgs) {
-		return fmt.Errorf("DecodeArgs: expected %d input arguments, got %d JSON arguments", len(args), len(jsonArgs))
-	}
-	for i, arg := range args {
-		if err := json.Unmarshal(jsonArgs[i], arg); err != nil {
-			return err
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/command.go b/gopls/internal/lsp/command.go
--- a/gopls/internal/lsp/command.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/command.go	1969-12-31 16:00:00
@@ -1,974 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"errors"
-	"fmt"
-	"io"
-	"io/ioutil"
-	"os"
-	"os/exec"
-	"path/filepath"
-	"sort"
-	"strings"
-	"time"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/progress"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/gopls/internal/vulncheck"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-func (s *Server) executeCommand(ctx context.Context, params *protocol.ExecuteCommandParams) (interface{}, error) {
-	var found bool
-	for _, name := range s.session.Options().SupportedCommands {
-		if name == params.Command {
-			found = true
-			break
-		}
-	}
-	if !found {
-		return nil, fmt.Errorf("%s is not a supported command", params.Command)
-	}
-
-	handler := &commandHandler{
-		s:      s,
-		params: params,
-	}
-	return command.Dispatch(ctx, params, handler)
-}
-
-type commandHandler struct {
-	s      *Server
-	params *protocol.ExecuteCommandParams
-}
-
-// commandConfig configures common command set-up and execution.
-type commandConfig struct {
-	async       bool                 // whether to run the command asynchronously. Async commands can only return errors.
-	requireSave bool                 // whether all files must be saved for the command to work
-	progress    string               // title to use for progress reporting. If empty, no progress will be reported.
-	forURI      protocol.DocumentURI // URI to resolve to a snapshot. If unset, snapshot will be nil.
-}
-
-// commandDeps is evaluated from a commandConfig. Note that not all fields may
-// be populated, depending on which configuration is set. See comments in-line
-// for details.
-type commandDeps struct {
-	snapshot source.Snapshot            // present if cfg.forURI was set
-	fh       source.VersionedFileHandle // present if cfg.forURI was set
-	work     *progress.WorkDone         // present cfg.progress was set
-}
-
-type commandFunc func(context.Context, commandDeps) error
-
-// run performs command setup for command execution, and invokes the given run
-// function. If cfg.async is set, run executes the given func in a separate
-// goroutine, and returns as soon as setup is complete and the goroutine is
-// scheduled.
-//
-// Invariant: if the resulting error is non-nil, the given run func will
-// (eventually) be executed exactly once.
-func (c *commandHandler) run(ctx context.Context, cfg commandConfig, run commandFunc) (err error) {
-	if cfg.requireSave {
-		var unsaved []string
-		for _, overlay := range c.s.session.Overlays() {
-			if !overlay.Saved() {
-				unsaved = append(unsaved, overlay.URI().Filename())
-			}
-		}
-		if len(unsaved) > 0 {
-			return fmt.Errorf("All files must be saved first (unsaved: %v).", unsaved)
-		}
-	}
-	var deps commandDeps
-	if cfg.forURI != "" {
-		var ok bool
-		var release func()
-		deps.snapshot, deps.fh, ok, release, err = c.s.beginFileRequest(ctx, cfg.forURI, source.UnknownKind)
-		defer release()
-		if !ok {
-			if err != nil {
-				return err
-			}
-			return fmt.Errorf("invalid file URL: %v", cfg.forURI)
-		}
-	}
-	ctx, cancel := context.WithCancel(xcontext.Detach(ctx))
-	if cfg.progress != "" {
-		deps.work = c.s.progress.Start(ctx, cfg.progress, "Running...", c.params.WorkDoneToken, cancel)
-	}
-	runcmd := func() error {
-		defer cancel()
-		err := run(ctx, deps)
-		if deps.work != nil {
-			switch {
-			case errors.Is(err, context.Canceled):
-				deps.work.End(ctx, "canceled")
-			case err != nil:
-				event.Error(ctx, "command error", err)
-				deps.work.End(ctx, "failed")
-			default:
-				deps.work.End(ctx, "completed")
-			}
-		}
-		return err
-	}
-	if cfg.async {
-		go func() {
-			if err := runcmd(); err != nil {
-				if showMessageErr := c.s.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-					Type:    protocol.Error,
-					Message: err.Error(),
-				}); showMessageErr != nil {
-					event.Error(ctx, fmt.Sprintf("failed to show message: %q", err.Error()), showMessageErr)
-				}
-			}
-		}()
-		return nil
-	}
-	return runcmd()
-}
-
-func (c *commandHandler) ApplyFix(ctx context.Context, args command.ApplyFixArgs) error {
-	return c.run(ctx, commandConfig{
-		// Note: no progress here. Applying fixes should be quick.
-		forURI: args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		edits, err := source.ApplyFix(ctx, args.Fix, deps.snapshot, deps.fh, args.Range)
-		if err != nil {
-			return err
-		}
-		var changes []protocol.DocumentChanges
-		for _, edit := range edits {
-			changes = append(changes, protocol.DocumentChanges{
-				TextDocumentEdit: &edit,
-			})
-		}
-		r, err := c.s.client.ApplyEdit(ctx, &protocol.ApplyWorkspaceEditParams{
-			Edit: protocol.WorkspaceEdit{
-				DocumentChanges: changes,
-			},
-		})
-		if err != nil {
-			return err
-		}
-		if !r.Applied {
-			return errors.New(r.FailureReason)
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) RegenerateCgo(ctx context.Context, args command.URIArg) error {
-	return c.run(ctx, commandConfig{
-		progress: "Regenerating Cgo",
-	}, func(ctx context.Context, deps commandDeps) error {
-		mod := source.FileModification{
-			URI:    args.URI.SpanURI(),
-			Action: source.InvalidateMetadata,
-		}
-		return c.s.didModifyFiles(ctx, []source.FileModification{mod}, FromRegenerateCgo)
-	})
-}
-
-func (c *commandHandler) CheckUpgrades(ctx context.Context, args command.CheckUpgradesArgs) error {
-	return c.run(ctx, commandConfig{
-		forURI:   args.URI,
-		progress: "Checking for upgrades",
-	}, func(ctx context.Context, deps commandDeps) error {
-		upgrades, err := c.s.getUpgrades(ctx, deps.snapshot, args.URI.SpanURI(), args.Modules)
-		if err != nil {
-			return err
-		}
-		deps.snapshot.View().RegisterModuleUpgrades(args.URI.SpanURI(), upgrades)
-		// Re-diagnose the snapshot to publish the new module diagnostics.
-		c.s.diagnoseSnapshot(deps.snapshot, nil, false)
-		return nil
-	})
-}
-
-func (c *commandHandler) AddDependency(ctx context.Context, args command.DependencyArgs) error {
-	return c.GoGetModule(ctx, args)
-}
-
-func (c *commandHandler) UpgradeDependency(ctx context.Context, args command.DependencyArgs) error {
-	return c.GoGetModule(ctx, args)
-}
-
-func (c *commandHandler) ResetGoModDiagnostics(ctx context.Context, args command.ResetGoModDiagnosticsArgs) error {
-	return c.run(ctx, commandConfig{
-		forURI: args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		// Clear all diagnostics coming from the upgrade check source and vulncheck.
-		// This will clear the diagnostics in all go.mod files, but they
-		// will be re-calculated when the snapshot is diagnosed again.
-		if args.DiagnosticSource == "" || args.DiagnosticSource == string(source.UpgradeNotification) {
-			deps.snapshot.View().ClearModuleUpgrades(args.URI.SpanURI())
-			c.s.clearDiagnosticSource(modCheckUpgradesSource)
-		}
-
-		if args.DiagnosticSource == "" || args.DiagnosticSource == string(source.Vulncheck) {
-			deps.snapshot.View().SetVulnerabilities(args.URI.SpanURI(), nil)
-			c.s.clearDiagnosticSource(modVulncheckSource)
-		}
-
-		// Re-diagnose the snapshot to remove the diagnostics.
-		c.s.diagnoseSnapshot(deps.snapshot, nil, false)
-		return nil
-	})
-}
-
-func (c *commandHandler) GoGetModule(ctx context.Context, args command.DependencyArgs) error {
-	return c.run(ctx, commandConfig{
-		progress: "Running go get",
-		forURI:   args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		return c.s.runGoModUpdateCommands(ctx, deps.snapshot, args.URI.SpanURI(), func(invoke func(...string) (*bytes.Buffer, error)) error {
-			return runGoGetModule(invoke, args.AddRequire, args.GoCmdArgs)
-		})
-	})
-}
-
-// TODO(rFindley): UpdateGoSum, Tidy, and Vendor could probably all be one command.
-func (c *commandHandler) UpdateGoSum(ctx context.Context, args command.URIArgs) error {
-	return c.run(ctx, commandConfig{
-		progress: "Updating go.sum",
-	}, func(ctx context.Context, deps commandDeps) error {
-		for _, uri := range args.URIs {
-			snapshot, fh, ok, release, err := c.s.beginFileRequest(ctx, uri, source.UnknownKind)
-			defer release()
-			if !ok {
-				return err
-			}
-			if err := c.s.runGoModUpdateCommands(ctx, snapshot, fh.URI(), func(invoke func(...string) (*bytes.Buffer, error)) error {
-				_, err := invoke("list", "all")
-				return err
-			}); err != nil {
-				return err
-			}
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) Tidy(ctx context.Context, args command.URIArgs) error {
-	return c.run(ctx, commandConfig{
-		requireSave: true,
-		progress:    "Running go mod tidy",
-	}, func(ctx context.Context, deps commandDeps) error {
-		for _, uri := range args.URIs {
-			snapshot, fh, ok, release, err := c.s.beginFileRequest(ctx, uri, source.UnknownKind)
-			defer release()
-			if !ok {
-				return err
-			}
-			if err := c.s.runGoModUpdateCommands(ctx, snapshot, fh.URI(), func(invoke func(...string) (*bytes.Buffer, error)) error {
-				_, err := invoke("mod", "tidy")
-				return err
-			}); err != nil {
-				return err
-			}
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) Vendor(ctx context.Context, args command.URIArg) error {
-	return c.run(ctx, commandConfig{
-		requireSave: true,
-		progress:    "Running go mod vendor",
-		forURI:      args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		// Use RunGoCommandPiped here so that we don't compete with any other go
-		// command invocations. go mod vendor deletes modules.txt before recreating
-		// it, and therefore can run into file locking issues on Windows if that
-		// file is in use by another process, such as go list.
-		//
-		// If golang/go#44119 is resolved, go mod vendor will instead modify
-		// modules.txt in-place. In that case we could theoretically allow this
-		// command to run concurrently.
-		err := deps.snapshot.RunGoCommandPiped(ctx, source.Normal|source.AllowNetwork, &gocommand.Invocation{
-			Verb:       "mod",
-			Args:       []string{"vendor"},
-			WorkingDir: filepath.Dir(args.URI.SpanURI().Filename()),
-		}, &bytes.Buffer{}, &bytes.Buffer{})
-		return err
-	})
-}
-
-func (c *commandHandler) EditGoDirective(ctx context.Context, args command.EditGoDirectiveArgs) error {
-	return c.run(ctx, commandConfig{
-		requireSave: true, // if go.mod isn't saved it could cause a problem
-		forURI:      args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		snapshot, fh, ok, release, err := c.s.beginFileRequest(ctx, args.URI, source.UnknownKind)
-		defer release()
-		if !ok {
-			return err
-		}
-		if err := c.s.runGoModUpdateCommands(ctx, snapshot, fh.URI(), func(invoke func(...string) (*bytes.Buffer, error)) error {
-			_, err := invoke("mod", "edit", "-go", args.Version)
-			return err
-		}); err != nil {
-			return err
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) RemoveDependency(ctx context.Context, args command.RemoveDependencyArgs) error {
-	return c.run(ctx, commandConfig{
-		progress: "Removing dependency",
-		forURI:   args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		// If the module is tidied apart from the one unused diagnostic, we can
-		// run `go get module@none`, and then run `go mod tidy`. Otherwise, we
-		// must make textual edits.
-		// TODO(rstambler): In Go 1.17+, we will be able to use the go command
-		// without checking if the module is tidy.
-		if args.OnlyDiagnostic {
-			return c.s.runGoModUpdateCommands(ctx, deps.snapshot, args.URI.SpanURI(), func(invoke func(...string) (*bytes.Buffer, error)) error {
-				if err := runGoGetModule(invoke, false, []string{args.ModulePath + "@none"}); err != nil {
-					return err
-				}
-				_, err := invoke("mod", "tidy")
-				return err
-			})
-		}
-		pm, err := deps.snapshot.ParseMod(ctx, deps.fh)
-		if err != nil {
-			return err
-		}
-		edits, err := dropDependency(deps.snapshot, pm, args.ModulePath)
-		if err != nil {
-			return err
-		}
-		response, err := c.s.client.ApplyEdit(ctx, &protocol.ApplyWorkspaceEditParams{
-			Edit: protocol.WorkspaceEdit{
-				DocumentChanges: []protocol.DocumentChanges{
-					{
-						TextDocumentEdit: &protocol.TextDocumentEdit{
-							TextDocument: protocol.OptionalVersionedTextDocumentIdentifier{
-								Version: deps.fh.Version(),
-								TextDocumentIdentifier: protocol.TextDocumentIdentifier{
-									URI: protocol.URIFromSpanURI(deps.fh.URI()),
-								},
-							},
-							Edits: edits,
-						},
-					},
-				},
-			},
-		})
-		if err != nil {
-			return err
-		}
-		if !response.Applied {
-			return fmt.Errorf("edits not applied because of %s", response.FailureReason)
-		}
-		return nil
-	})
-}
-
-// dropDependency returns the edits to remove the given require from the go.mod
-// file.
-func dropDependency(snapshot source.Snapshot, pm *source.ParsedModule, modulePath string) ([]protocol.TextEdit, error) {
-	// We need a private copy of the parsed go.mod file, since we're going to
-	// modify it.
-	copied, err := modfile.Parse("", pm.Mapper.Content, nil)
-	if err != nil {
-		return nil, err
-	}
-	if err := copied.DropRequire(modulePath); err != nil {
-		return nil, err
-	}
-	copied.Cleanup()
-	newContent, err := copied.Format()
-	if err != nil {
-		return nil, err
-	}
-	// Calculate the edits to be made due to the change.
-	diff := snapshot.View().Options().ComputeEdits(string(pm.Mapper.Content), string(newContent))
-	return source.ToProtocolEdits(pm.Mapper, diff)
-}
-
-func (c *commandHandler) Test(ctx context.Context, uri protocol.DocumentURI, tests, benchmarks []string) error {
-	return c.RunTests(ctx, command.RunTestsArgs{
-		URI:        uri,
-		Tests:      tests,
-		Benchmarks: benchmarks,
-	})
-}
-
-func (c *commandHandler) RunTests(ctx context.Context, args command.RunTestsArgs) error {
-	return c.run(ctx, commandConfig{
-		async:       true,
-		progress:    "Running go test",
-		requireSave: true,
-		forURI:      args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		if err := c.runTests(ctx, deps.snapshot, deps.work, args.URI, args.Tests, args.Benchmarks); err != nil {
-			return fmt.Errorf("running tests failed: %w", err)
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) runTests(ctx context.Context, snapshot source.Snapshot, work *progress.WorkDone, uri protocol.DocumentURI, tests, benchmarks []string) error {
-	// TODO: fix the error reporting when this runs async.
-	metas, err := snapshot.MetadataForFile(ctx, uri.SpanURI())
-	if err != nil {
-		return err
-	}
-	metas = source.RemoveIntermediateTestVariants(metas)
-	if len(metas) == 0 {
-		return fmt.Errorf("package could not be found for file: %s", uri.SpanURI().Filename())
-	}
-	pkgPath := string(metas[0].ForTest)
-
-	// create output
-	buf := &bytes.Buffer{}
-	ew := progress.NewEventWriter(ctx, "test")
-	out := io.MultiWriter(ew, progress.NewWorkDoneWriter(ctx, work), buf)
-
-	// Run `go test -run Func` on each test.
-	var failedTests int
-	for _, funcName := range tests {
-		inv := &gocommand.Invocation{
-			Verb:       "test",
-			Args:       []string{pkgPath, "-v", "-count=1", "-run", fmt.Sprintf("^%s$", funcName)},
-			WorkingDir: filepath.Dir(uri.SpanURI().Filename()),
-		}
-		if err := snapshot.RunGoCommandPiped(ctx, source.Normal, inv, out, out); err != nil {
-			if errors.Is(err, context.Canceled) {
-				return err
-			}
-			failedTests++
-		}
-	}
-
-	// Run `go test -run=^$ -bench Func` on each test.
-	var failedBenchmarks int
-	for _, funcName := range benchmarks {
-		inv := &gocommand.Invocation{
-			Verb:       "test",
-			Args:       []string{pkgPath, "-v", "-run=^$", "-bench", fmt.Sprintf("^%s$", funcName)},
-			WorkingDir: filepath.Dir(uri.SpanURI().Filename()),
-		}
-		if err := snapshot.RunGoCommandPiped(ctx, source.Normal, inv, out, out); err != nil {
-			if errors.Is(err, context.Canceled) {
-				return err
-			}
-			failedBenchmarks++
-		}
-	}
-
-	var title string
-	if len(tests) > 0 && len(benchmarks) > 0 {
-		title = "tests and benchmarks"
-	} else if len(tests) > 0 {
-		title = "tests"
-	} else if len(benchmarks) > 0 {
-		title = "benchmarks"
-	} else {
-		return errors.New("No functions were provided")
-	}
-	message := fmt.Sprintf("all %s passed", title)
-	if failedTests > 0 && failedBenchmarks > 0 {
-		message = fmt.Sprintf("%d / %d tests failed and %d / %d benchmarks failed", failedTests, len(tests), failedBenchmarks, len(benchmarks))
-	} else if failedTests > 0 {
-		message = fmt.Sprintf("%d / %d tests failed", failedTests, len(tests))
-	} else if failedBenchmarks > 0 {
-		message = fmt.Sprintf("%d / %d benchmarks failed", failedBenchmarks, len(benchmarks))
-	}
-	if failedTests > 0 || failedBenchmarks > 0 {
-		message += "\n" + buf.String()
-	}
-
-	return c.s.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-		Type:    protocol.Info,
-		Message: message,
-	})
-}
-
-func (c *commandHandler) Generate(ctx context.Context, args command.GenerateArgs) error {
-	title := "Running go generate ."
-	if args.Recursive {
-		title = "Running go generate ./..."
-	}
-	return c.run(ctx, commandConfig{
-		requireSave: true,
-		progress:    title,
-		forURI:      args.Dir,
-	}, func(ctx context.Context, deps commandDeps) error {
-		er := progress.NewEventWriter(ctx, "generate")
-
-		pattern := "."
-		if args.Recursive {
-			pattern = "./..."
-		}
-		inv := &gocommand.Invocation{
-			Verb:       "generate",
-			Args:       []string{"-x", pattern},
-			WorkingDir: args.Dir.SpanURI().Filename(),
-		}
-		stderr := io.MultiWriter(er, progress.NewWorkDoneWriter(ctx, deps.work))
-		if err := deps.snapshot.RunGoCommandPiped(ctx, source.Normal, inv, er, stderr); err != nil {
-			return err
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) GoGetPackage(ctx context.Context, args command.GoGetPackageArgs) error {
-	return c.run(ctx, commandConfig{
-		forURI:   args.URI,
-		progress: "Running go get",
-	}, func(ctx context.Context, deps commandDeps) error {
-		// Run on a throwaway go.mod, otherwise it'll write to the real one.
-		stdout, err := deps.snapshot.RunGoCommandDirect(ctx, source.WriteTemporaryModFile|source.AllowNetwork, &gocommand.Invocation{
-			Verb:       "list",
-			Args:       []string{"-f", "{{.Module.Path}}@{{.Module.Version}}", args.Pkg},
-			WorkingDir: filepath.Dir(args.URI.SpanURI().Filename()),
-		})
-		if err != nil {
-			return err
-		}
-		ver := strings.TrimSpace(stdout.String())
-		return c.s.runGoModUpdateCommands(ctx, deps.snapshot, args.URI.SpanURI(), func(invoke func(...string) (*bytes.Buffer, error)) error {
-			if args.AddRequire {
-				if err := addModuleRequire(invoke, []string{ver}); err != nil {
-					return err
-				}
-			}
-			_, err := invoke(append([]string{"get", "-d"}, args.Pkg)...)
-			return err
-		})
-	})
-}
-
-func (s *Server) runGoModUpdateCommands(ctx context.Context, snapshot source.Snapshot, uri span.URI, run func(invoke func(...string) (*bytes.Buffer, error)) error) error {
-	tmpModfile, newModBytes, newSumBytes, err := snapshot.RunGoCommands(ctx, true, filepath.Dir(uri.Filename()), run)
-	if err != nil {
-		return err
-	}
-	if !tmpModfile {
-		return nil
-	}
-	modURI := snapshot.GoModForFile(uri)
-	sumURI := span.URIFromPath(strings.TrimSuffix(modURI.Filename(), ".mod") + ".sum")
-	modEdits, err := applyFileEdits(ctx, snapshot, modURI, newModBytes)
-	if err != nil {
-		return err
-	}
-	sumEdits, err := applyFileEdits(ctx, snapshot, sumURI, newSumBytes)
-	if err != nil {
-		return err
-	}
-	changes := append(sumEdits, modEdits...)
-	if len(changes) == 0 {
-		return nil
-	}
-	var documentChanges []protocol.DocumentChanges
-	for _, change := range changes {
-		documentChanges = append(documentChanges, protocol.DocumentChanges{
-			TextDocumentEdit: &change,
-		})
-	}
-	response, err := s.client.ApplyEdit(ctx, &protocol.ApplyWorkspaceEditParams{
-		Edit: protocol.WorkspaceEdit{
-			DocumentChanges: documentChanges,
-		},
-	})
-	if err != nil {
-		return err
-	}
-	if !response.Applied {
-		return fmt.Errorf("edits not applied because of %s", response.FailureReason)
-	}
-	return nil
-}
-
-func applyFileEdits(ctx context.Context, snapshot source.Snapshot, uri span.URI, newContent []byte) ([]protocol.TextDocumentEdit, error) {
-	fh, err := snapshot.GetVersionedFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	oldContent, err := fh.Read()
-	if err != nil && !os.IsNotExist(err) {
-		return nil, err
-	}
-	if bytes.Equal(oldContent, newContent) {
-		return nil, nil
-	}
-
-	// Sending a workspace edit to a closed file causes VS Code to open the
-	// file and leave it unsaved. We would rather apply the changes directly,
-	// especially to go.sum, which should be mostly invisible to the user.
-	if !snapshot.IsOpen(uri) {
-		err := ioutil.WriteFile(uri.Filename(), newContent, 0666)
-		return nil, err
-	}
-
-	m := protocol.NewColumnMapper(fh.URI(), oldContent)
-	diff := snapshot.View().Options().ComputeEdits(string(oldContent), string(newContent))
-	edits, err := source.ToProtocolEdits(m, diff)
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.TextDocumentEdit{{
-		TextDocument: protocol.OptionalVersionedTextDocumentIdentifier{
-			Version: fh.Version(),
-			TextDocumentIdentifier: protocol.TextDocumentIdentifier{
-				URI: protocol.URIFromSpanURI(uri),
-			},
-		},
-		Edits: edits,
-	}}, nil
-}
-
-func runGoGetModule(invoke func(...string) (*bytes.Buffer, error), addRequire bool, args []string) error {
-	if addRequire {
-		if err := addModuleRequire(invoke, args); err != nil {
-			return err
-		}
-	}
-	_, err := invoke(append([]string{"get", "-d"}, args...)...)
-	return err
-}
-
-func addModuleRequire(invoke func(...string) (*bytes.Buffer, error), args []string) error {
-	// Using go get to create a new dependency results in an
-	// `// indirect` comment we may not want. The only way to avoid it
-	// is to add the require as direct first. Then we can use go get to
-	// update go.sum and tidy up.
-	_, err := invoke(append([]string{"mod", "edit", "-require"}, args...)...)
-	return err
-}
-
-func (s *Server) getUpgrades(ctx context.Context, snapshot source.Snapshot, uri span.URI, modules []string) (map[string]string, error) {
-	stdout, err := snapshot.RunGoCommandDirect(ctx, source.Normal|source.AllowNetwork, &gocommand.Invocation{
-		Verb:       "list",
-		Args:       append([]string{"-m", "-u", "-json"}, modules...),
-		WorkingDir: filepath.Dir(uri.Filename()),
-		ModFlag:    "readonly",
-	})
-	if err != nil {
-		return nil, err
-	}
-
-	upgrades := map[string]string{}
-	for dec := json.NewDecoder(stdout); dec.More(); {
-		mod := &gocommand.ModuleJSON{}
-		if err := dec.Decode(mod); err != nil {
-			return nil, err
-		}
-		if mod.Update == nil {
-			continue
-		}
-		upgrades[mod.Path] = mod.Update.Version
-	}
-	return upgrades, nil
-}
-
-func (c *commandHandler) GCDetails(ctx context.Context, uri protocol.DocumentURI) error {
-	return c.ToggleGCDetails(ctx, command.URIArg{URI: uri})
-}
-
-func (c *commandHandler) ToggleGCDetails(ctx context.Context, args command.URIArg) error {
-	return c.run(ctx, commandConfig{
-		requireSave: true,
-		progress:    "Toggling GC Details",
-		forURI:      args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		metas, err := deps.snapshot.MetadataForFile(ctx, deps.fh.URI())
-		if err != nil {
-			return err
-		}
-		id := metas[0].ID // 0 => narrowest package
-		c.s.gcOptimizationDetailsMu.Lock()
-		if _, ok := c.s.gcOptimizationDetails[id]; ok {
-			delete(c.s.gcOptimizationDetails, id)
-			c.s.clearDiagnosticSource(gcDetailsSource)
-		} else {
-			c.s.gcOptimizationDetails[id] = struct{}{}
-		}
-		c.s.gcOptimizationDetailsMu.Unlock()
-		c.s.diagnoseSnapshot(deps.snapshot, nil, false)
-		return nil
-	})
-}
-
-func (c *commandHandler) GenerateGoplsMod(ctx context.Context, args command.URIArg) error {
-	// TODO: go back to using URI
-	return c.run(ctx, commandConfig{
-		requireSave: true,
-		progress:    "Generating gopls.mod",
-	}, func(ctx context.Context, deps commandDeps) error {
-		views := c.s.session.Views()
-		if len(views) != 1 {
-			return fmt.Errorf("cannot resolve view: have %d views", len(views))
-		}
-		v := views[0]
-		snapshot, release := v.Snapshot(ctx)
-		defer release()
-		modFile, err := snapshot.BuildGoplsMod(ctx)
-		if err != nil {
-			return fmt.Errorf("getting workspace mod file: %w", err)
-		}
-		content, err := modFile.Format()
-		if err != nil {
-			return fmt.Errorf("formatting mod file: %w", err)
-		}
-		filename := filepath.Join(v.Folder().Filename(), "gopls.mod")
-		if err := ioutil.WriteFile(filename, content, 0644); err != nil {
-			return fmt.Errorf("writing mod file: %w", err)
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) ListKnownPackages(ctx context.Context, args command.URIArg) (command.ListKnownPackagesResult, error) {
-	var result command.ListKnownPackagesResult
-	err := c.run(ctx, commandConfig{
-		progress: "Listing packages",
-		forURI:   args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		pkgs, err := source.KnownPackagePaths(ctx, deps.snapshot, deps.fh)
-		for _, pkg := range pkgs {
-			result.Packages = append(result.Packages, string(pkg))
-		}
-		return err
-	})
-	return result, err
-}
-
-func (c *commandHandler) ListImports(ctx context.Context, args command.URIArg) (command.ListImportsResult, error) {
-	var result command.ListImportsResult
-	err := c.run(ctx, commandConfig{
-		forURI: args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		fh, err := deps.snapshot.GetFile(ctx, args.URI.SpanURI())
-		if err != nil {
-			return err
-		}
-		pgf, err := deps.snapshot.ParseGo(ctx, fh, source.ParseHeader)
-		if err != nil {
-			return err
-		}
-		for _, group := range astutil.Imports(deps.snapshot.FileSet(), pgf.File) {
-			for _, imp := range group {
-				if imp.Path == nil {
-					continue
-				}
-				var name string
-				if imp.Name != nil {
-					name = imp.Name.Name
-				}
-				result.Imports = append(result.Imports, command.FileImport{
-					Path: string(source.UnquoteImportPath(imp)),
-					Name: name,
-				})
-			}
-		}
-		metas, err := deps.snapshot.MetadataForFile(ctx, args.URI.SpanURI())
-		if err != nil {
-			return err // e.g. cancelled
-		}
-		if len(metas) == 0 {
-			return fmt.Errorf("no package containing %v", args.URI.SpanURI())
-		}
-		for pkgPath := range metas[0].DepsByPkgPath { // 0 => narrowest package
-			result.PackageImports = append(result.PackageImports,
-				command.PackageImport{Path: string(pkgPath)})
-		}
-		sort.Slice(result.PackageImports, func(i, j int) bool {
-			return result.PackageImports[i].Path < result.PackageImports[j].Path
-		})
-		return nil
-	})
-	return result, err
-}
-
-func (c *commandHandler) AddImport(ctx context.Context, args command.AddImportArgs) error {
-	return c.run(ctx, commandConfig{
-		progress: "Adding import",
-		forURI:   args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		edits, err := source.AddImport(ctx, deps.snapshot, deps.fh, args.ImportPath)
-		if err != nil {
-			return fmt.Errorf("could not add import: %v", err)
-		}
-		if _, err := c.s.client.ApplyEdit(ctx, &protocol.ApplyWorkspaceEditParams{
-			Edit: protocol.WorkspaceEdit{
-				DocumentChanges: documentChanges(deps.fh, edits),
-			},
-		}); err != nil {
-			return fmt.Errorf("could not apply import edits: %v", err)
-		}
-		return nil
-	})
-}
-
-func (c *commandHandler) StartDebugging(ctx context.Context, args command.DebuggingArgs) (result command.DebuggingResult, _ error) {
-	addr := args.Addr
-	if addr == "" {
-		addr = "localhost:0"
-	}
-	di := debug.GetInstance(ctx)
-	if di == nil {
-		return result, errors.New("internal error: server has no debugging instance")
-	}
-	listenedAddr, err := di.Serve(ctx, addr)
-	if err != nil {
-		return result, fmt.Errorf("starting debug server: %w", err)
-	}
-	result.URLs = []string{"http://" + listenedAddr}
-	return result, nil
-}
-
-// Copy of pkgLoadConfig defined in internal/lsp/cmd/vulncheck.go
-// TODO(hyangah): decide where to define this.
-type pkgLoadConfig struct {
-	// BuildFlags is a list of command-line flags to be passed through to
-	// the build system's query tool.
-	BuildFlags []string
-
-	// If Tests is set, the loader includes related test packages.
-	Tests bool
-}
-
-func (c *commandHandler) FetchVulncheckResult(ctx context.Context, arg command.URIArg) (map[protocol.DocumentURI]*govulncheck.Result, error) {
-	ret := map[protocol.DocumentURI]*govulncheck.Result{}
-	err := c.run(ctx, commandConfig{forURI: arg.URI}, func(ctx context.Context, deps commandDeps) error {
-		if deps.snapshot.View().Options().Vulncheck == source.ModeVulncheckImports {
-			for _, modfile := range deps.snapshot.ModFiles() {
-				res, err := deps.snapshot.ModVuln(ctx, modfile)
-				if err != nil {
-					return err
-				}
-				ret[protocol.URIFromSpanURI(modfile)] = res
-			}
-		}
-		// Overwrite if there is any govulncheck-based result.
-		for modfile, result := range deps.snapshot.View().Vulnerabilities() {
-			ret[protocol.URIFromSpanURI(modfile)] = result
-		}
-		return nil
-	})
-	return ret, err
-}
-
-func (c *commandHandler) RunGovulncheck(ctx context.Context, args command.VulncheckArgs) (command.RunVulncheckResult, error) {
-	if args.URI == "" {
-		return command.RunVulncheckResult{}, errors.New("VulncheckArgs is missing URI field")
-	}
-
-	// Return the workdone token so that clients can identify when this
-	// vulncheck invocation is complete.
-	//
-	// Since the run function executes asynchronously, we use a channel to
-	// synchronize the start of the run and return the token.
-	tokenChan := make(chan protocol.ProgressToken, 1)
-	err := c.run(ctx, commandConfig{
-		async:       true, // need to be async to be cancellable
-		progress:    "govulncheck",
-		requireSave: true,
-		forURI:      args.URI,
-	}, func(ctx context.Context, deps commandDeps) error {
-		tokenChan <- deps.work.Token()
-
-		view := deps.snapshot.View()
-		opts := view.Options()
-		// quickly test if gopls is compiled to support govulncheck
-		// by checking vulncheck.Main. Alternatively, we can continue and
-		// let the `gopls vulncheck` command fail. This is lighter-weight.
-		if vulncheck.Main == nil {
-			return errors.New("vulncheck feature is not available")
-		}
-
-		cmd := exec.CommandContext(ctx, os.Args[0], "vulncheck", "-config", args.Pattern)
-		cmd.Dir = filepath.Dir(args.URI.SpanURI().Filename())
-
-		var viewEnv []string
-		if e := opts.EnvSlice(); e != nil {
-			viewEnv = append(os.Environ(), e...)
-		}
-		cmd.Env = viewEnv
-
-		// stdin: gopls vulncheck expects JSON-encoded configuration from STDIN when -config flag is set.
-		var stdin bytes.Buffer
-		cmd.Stdin = &stdin
-
-		if err := json.NewEncoder(&stdin).Encode(pkgLoadConfig{
-			BuildFlags: opts.BuildFlags,
-			// TODO(hyangah): add `tests` flag in command.VulncheckArgs
-		}); err != nil {
-			return fmt.Errorf("failed to pass package load config: %v", err)
-		}
-
-		// stderr: stream gopls vulncheck's STDERR as progress reports
-		er := progress.NewEventWriter(ctx, "vulncheck")
-		stderr := io.MultiWriter(er, progress.NewWorkDoneWriter(ctx, deps.work))
-		cmd.Stderr = stderr
-		// TODO: can we stream stdout?
-		stdout, err := cmd.Output()
-		if err != nil {
-			return fmt.Errorf("failed to run govulncheck: %v", err)
-		}
-
-		var result govulncheck.Result
-		if err := json.Unmarshal(stdout, &result); err != nil {
-			// TODO: for easy debugging, log the failed stdout somewhere?
-			return fmt.Errorf("failed to parse govulncheck output: %v", err)
-		}
-		result.Mode = govulncheck.ModeGovulncheck
-		result.AsOf = time.Now()
-		deps.snapshot.View().SetVulnerabilities(args.URI.SpanURI(), &result)
-
-		c.s.diagnoseSnapshot(deps.snapshot, nil, false)
-		vulns := result.Vulns
-		affecting := make([]string, 0, len(vulns))
-		for _, v := range vulns {
-			if v.IsCalled() {
-				affecting = append(affecting, v.OSV.ID)
-			}
-		}
-		if len(affecting) == 0 {
-			return c.s.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-				Type:    protocol.Info,
-				Message: "No vulnerabilities found",
-			})
-		}
-		sort.Strings(affecting)
-		return c.s.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-			Type:    protocol.Warning,
-			Message: fmt.Sprintf("Found %v", strings.Join(affecting, ", ")),
-		})
-	})
-	if err != nil {
-		return command.RunVulncheckResult{}, err
-	}
-	select {
-	case <-ctx.Done():
-		return command.RunVulncheckResult{}, ctx.Err()
-	case token := <-tokenChan:
-		return command.RunVulncheckResult{Token: token}, nil
-	}
-}
diff -urN a/gopls/internal/lsp/completion.go b/gopls/internal/lsp/completion.go
--- a/gopls/internal/lsp/completion.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/completion.go	1969-12-31 16:00:00
@@ -1,142 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"fmt"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/source/completion"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-	"golang.org/x/tools/gopls/internal/lsp/work"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-func (s *Server) completion(ctx context.Context, params *protocol.CompletionParams) (*protocol.CompletionList, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	var candidates []completion.CompletionItem
-	var surrounding *completion.Selection
-	switch snapshot.View().FileKind(fh) {
-	case source.Go:
-		candidates, surrounding, err = completion.Completion(ctx, snapshot, fh, params.Position, params.Context)
-	case source.Mod:
-		candidates, surrounding = nil, nil
-	case source.Work:
-		cl, err := work.Completion(ctx, snapshot, fh, params.Position)
-		if err != nil {
-			break
-		}
-		return cl, nil
-	case source.Tmpl:
-		var cl *protocol.CompletionList
-		cl, err = template.Completion(ctx, snapshot, fh, params.Position, params.Context)
-		if err != nil {
-			break // use common error handling, candidates==nil
-		}
-		return cl, nil
-	}
-	if err != nil {
-		event.Error(ctx, "no completions found", err, tag.Position.Of(params.Position))
-	}
-	if candidates == nil {
-		return &protocol.CompletionList{
-			IsIncomplete: true,
-			Items:        []protocol.CompletionItem{},
-		}, nil
-	}
-
-	// Map positions to LSP positions using the original content, rather than
-	// internal/span, as the latter treats end of file as the beginning of the
-	// next line, even when it's not newline-terminated. See golang/go#41029 for
-	// more details.
-	src, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	srng := surrounding.Range()
-	tf := snapshot.FileSet().File(srng.Start) // not same as srng.TokFile due to //line
-	rng, err := lsppos.NewTokenMapper(src, tf).Range(srng.Start, srng.End)
-	if err != nil {
-		return nil, err
-	}
-
-	// When using deep completions/fuzzy matching, report results as incomplete so
-	// client fetches updated completions after every key stroke.
-	options := snapshot.View().Options()
-	incompleteResults := options.DeepCompletion || options.Matcher == source.Fuzzy
-
-	items := toProtocolCompletionItems(candidates, rng, options)
-
-	return &protocol.CompletionList{
-		IsIncomplete: incompleteResults,
-		Items:        items,
-	}, nil
-}
-
-func toProtocolCompletionItems(candidates []completion.CompletionItem, rng protocol.Range, options *source.Options) []protocol.CompletionItem {
-	var (
-		items                  = make([]protocol.CompletionItem, 0, len(candidates))
-		numDeepCompletionsSeen int
-	)
-	for i, candidate := range candidates {
-		// Limit the number of deep completions to not overwhelm the user in cases
-		// with dozens of deep completion matches.
-		if candidate.Depth > 0 {
-			if !options.DeepCompletion {
-				continue
-			}
-			if numDeepCompletionsSeen >= completion.MaxDeepCompletions {
-				continue
-			}
-			numDeepCompletionsSeen++
-		}
-		insertText := candidate.InsertText
-		if options.InsertTextFormat == protocol.SnippetTextFormat {
-			insertText = candidate.Snippet()
-		}
-
-		// This can happen if the client has snippets disabled but the
-		// candidate only supports snippet insertion.
-		if insertText == "" {
-			continue
-		}
-
-		item := protocol.CompletionItem{
-			Label:  candidate.Label,
-			Detail: candidate.Detail,
-			Kind:   candidate.Kind,
-			TextEdit: &protocol.TextEdit{
-				NewText: insertText,
-				Range:   rng,
-			},
-			InsertTextFormat:    options.InsertTextFormat,
-			AdditionalTextEdits: candidate.AdditionalTextEdits,
-			// This is a hack so that the client sorts completion results in the order
-			// according to their score. This can be removed upon the resolution of
-			// https://github.com/Microsoft/language-server-protocol/issues/348.
-			SortText: fmt.Sprintf("%05d", i),
-
-			// Trim operators (VSCode doesn't like weird characters in
-			// filterText).
-			FilterText: strings.TrimLeft(candidate.InsertText, "&*"),
-
-			Preselect:     i == 0,
-			Documentation: candidate.Documentation,
-			Tags:          candidate.Tags,
-			Deprecated:    candidate.Deprecated,
-		}
-		items = append(items, item)
-	}
-	return items
-}
diff -urN a/gopls/internal/lsp/completion_test.go b/gopls/internal/lsp/completion_test.go
--- a/gopls/internal/lsp/completion_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/completion_test.go	1969-12-31 16:00:00
@@ -1,154 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (r *runner) Completion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = false
-		opts.Matcher = source.CaseInsensitive
-		opts.CompleteUnimported = false
-		opts.InsertTextFormat = protocol.SnippetTextFormat
-		opts.LiteralCompletions = strings.Contains(string(src.URI()), "literal")
-		opts.ExperimentalPostfixCompletions = strings.Contains(string(src.URI()), "postfix")
-	})
-	got = tests.FilterBuiltins(src, got)
-	want := expected(t, test, items)
-	if diff := tests.DiffCompletionItems(want, got); diff != "" {
-		t.Errorf("%s", diff)
-	}
-}
-
-func (r *runner) CompletionSnippet(t *testing.T, src span.Span, expected tests.CompletionSnippet, placeholders bool, items tests.CompletionItems) {
-	list := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.UsePlaceholders = placeholders
-		opts.DeepCompletion = true
-		opts.Matcher = source.Fuzzy
-		opts.CompleteUnimported = false
-	})
-	got := tests.FindItem(list, *items[expected.CompletionItem])
-	want := expected.PlainSnippet
-	if placeholders {
-		want = expected.PlaceholderSnippet
-	}
-	if diff := tests.DiffSnippets(want, got); diff != "" {
-		t.Errorf("%s", diff)
-	}
-}
-
-func (r *runner) UnimportedCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	got := r.callCompletion(t, src, func(opts *source.Options) {})
-	got = tests.FilterBuiltins(src, got)
-	want := expected(t, test, items)
-	if diff := tests.CheckCompletionOrder(want, got, false); diff != "" {
-		t.Errorf("%s", diff)
-	}
-}
-
-func (r *runner) DeepCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = true
-		opts.Matcher = source.CaseInsensitive
-		opts.CompleteUnimported = false
-	})
-	got = tests.FilterBuiltins(src, got)
-	want := expected(t, test, items)
-	if msg := tests.DiffCompletionItems(want, got); msg != "" {
-		t.Errorf("%s", msg)
-	}
-}
-
-func (r *runner) FuzzyCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = true
-		opts.Matcher = source.Fuzzy
-		opts.CompleteUnimported = false
-	})
-	got = tests.FilterBuiltins(src, got)
-	want := expected(t, test, items)
-	if msg := tests.DiffCompletionItems(want, got); msg != "" {
-		t.Errorf("%s", msg)
-	}
-}
-
-func (r *runner) CaseSensitiveCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.Matcher = source.CaseSensitive
-		opts.CompleteUnimported = false
-	})
-	got = tests.FilterBuiltins(src, got)
-	want := expected(t, test, items)
-	if msg := tests.DiffCompletionItems(want, got); msg != "" {
-		t.Errorf("%s", msg)
-	}
-}
-
-func (r *runner) RankCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = true
-		opts.Matcher = source.Fuzzy
-		opts.CompleteUnimported = false
-		opts.LiteralCompletions = true
-		opts.ExperimentalPostfixCompletions = true
-	})
-	want := expected(t, test, items)
-	if msg := tests.CheckCompletionOrder(want, got, true); msg != "" {
-		t.Errorf("%s", msg)
-	}
-}
-
-func expected(t *testing.T, test tests.Completion, items tests.CompletionItems) []protocol.CompletionItem {
-	t.Helper()
-
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		item := items[pos]
-		want = append(want, tests.ToProtocolCompletionItem(*item))
-	}
-	return want
-}
-
-func (r *runner) callCompletion(t *testing.T, src span.Span, options func(*source.Options)) []protocol.CompletionItem {
-	t.Helper()
-
-	view, err := r.server.session.ViewOf(src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	original := view.Options()
-	modified := view.Options().Clone()
-	options(modified)
-	view, err = r.server.session.SetViewOptions(r.ctx, view, modified)
-	if err != nil {
-		t.Error(err)
-		return nil
-	}
-	defer r.server.session.SetViewOptions(r.ctx, view, original)
-
-	list, err := r.server.Completion(r.ctx, &protocol.CompletionParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{
-				URI: protocol.URIFromSpanURI(src.URI()),
-			},
-			Position: protocol.Position{
-				Line:      uint32(src.Start().Line() - 1),
-				Character: uint32(src.Start().Column() - 1),
-			},
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	return list.Items
-}
diff -urN a/gopls/internal/lsp/debounce.go b/gopls/internal/lsp/debounce.go
--- a/gopls/internal/lsp/debounce.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debounce.go	1969-12-31 16:00:00
@@ -1,71 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"sync"
-	"time"
-)
-
-type debounceEvent struct {
-	order uint64
-	done  chan struct{}
-}
-
-type debouncer struct {
-	mu     sync.Mutex
-	events map[string]*debounceEvent
-}
-
-func newDebouncer() *debouncer {
-	return &debouncer{
-		events: make(map[string]*debounceEvent),
-	}
-}
-
-// debounce returns a channel that receives a boolean reporting whether,
-// by the time the delay channel receives a value, this call is (or will be)
-// the most recent call with the highest order number for its key.
-func (d *debouncer) debounce(key string, order uint64, delay <-chan time.Time) <-chan bool {
-	okc := make(chan bool, 1)
-
-	d.mu.Lock()
-	if prev, ok := d.events[key]; ok {
-		if prev.order > order {
-			// If we have a logical ordering of events (as is the case for snapshots),
-			// don't overwrite a later event with an earlier event.
-			d.mu.Unlock()
-			okc <- false
-			return okc
-		}
-		close(prev.done)
-	}
-	done := make(chan struct{})
-	next := &debounceEvent{
-		order: order,
-		done:  done,
-	}
-	d.events[key] = next
-	d.mu.Unlock()
-
-	go func() {
-		ok := false
-		select {
-		case <-delay:
-			d.mu.Lock()
-			if d.events[key] == next {
-				ok = true
-				delete(d.events, key)
-			} else {
-				// The event was superseded before we acquired d.mu.
-			}
-			d.mu.Unlock()
-		case <-done:
-		}
-		okc <- ok
-	}()
-
-	return okc
-}
diff -urN a/gopls/internal/lsp/debounce_test.go b/gopls/internal/lsp/debounce_test.go
--- a/gopls/internal/lsp/debounce_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debounce_test.go	1969-12-31 16:00:00
@@ -1,81 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"testing"
-	"time"
-)
-
-func TestDebouncer(t *testing.T) {
-	t.Parallel()
-
-	type event struct {
-		key       string
-		order     uint64
-		wantFired bool
-	}
-	tests := []struct {
-		label  string
-		events []*event
-	}{
-		{
-			label: "overridden",
-			events: []*event{
-				{key: "a", order: 1, wantFired: false},
-				{key: "a", order: 2, wantFired: true},
-			},
-		},
-		{
-			label: "distinct labels",
-			events: []*event{
-				{key: "a", order: 1, wantFired: true},
-				{key: "b", order: 2, wantFired: true},
-			},
-		},
-		{
-			label: "reverse order",
-			events: []*event{
-				{key: "a", order: 2, wantFired: true},
-				{key: "a", order: 1, wantFired: false},
-			},
-		},
-		{
-			label: "multiple overrides",
-			events: []*event{
-				{key: "a", order: 1, wantFired: false},
-				{key: "a", order: 2, wantFired: false},
-				{key: "a", order: 3, wantFired: false},
-				{key: "a", order: 4, wantFired: false},
-				{key: "a", order: 5, wantFired: true},
-			},
-		},
-	}
-	for _, test := range tests {
-		test := test
-		t.Run(test.label, func(t *testing.T) {
-			d := newDebouncer()
-
-			delays := make([]chan time.Time, len(test.events))
-			okcs := make([]<-chan bool, len(test.events))
-
-			// Register the events in deterministic order, synchronously.
-			for i, e := range test.events {
-				delays[i] = make(chan time.Time, 1)
-				okcs[i] = d.debounce(e.key, e.order, delays[i])
-			}
-
-			// Now see which event fired.
-			for i, okc := range okcs {
-				event := test.events[i]
-				delays[i] <- time.Now()
-				fired := <-okc
-				if fired != event.wantFired {
-					t.Errorf("[key: %q, order: %d]: fired = %t, want %t", event.key, event.order, fired, event.wantFired)
-				}
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/debug/buildinfo_go1.12.go b/gopls/internal/lsp/debug/buildinfo_go1.12.go
--- a/gopls/internal/lsp/debug/buildinfo_go1.12.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/buildinfo_go1.12.go	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.18
-// +build !go1.18
-
-package debug
-
-import (
-	"runtime"
-	"runtime/debug"
-)
-
-type BuildInfo struct {
-	debug.BuildInfo
-	GoVersion string // Version of Go that produced this binary
-}
-
-func readBuildInfo() (*BuildInfo, bool) {
-	rinfo, ok := debug.ReadBuildInfo()
-	if !ok {
-		return nil, false
-	}
-	return &BuildInfo{
-		GoVersion: runtime.Version(),
-		BuildInfo: *rinfo,
-	}, true
-}
diff -urN a/gopls/internal/lsp/debug/buildinfo_go1.18.go b/gopls/internal/lsp/debug/buildinfo_go1.18.go
--- a/gopls/internal/lsp/debug/buildinfo_go1.18.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/buildinfo_go1.18.go	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package debug
-
-import (
-	"runtime/debug"
-)
-
-type BuildInfo debug.BuildInfo
-
-func readBuildInfo() (*BuildInfo, bool) {
-	info, ok := debug.ReadBuildInfo()
-	return (*BuildInfo)(info), ok
-}
diff -urN a/gopls/internal/lsp/debug/info.go b/gopls/internal/lsp/debug/info.go
--- a/gopls/internal/lsp/debug/info.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/info.go	1969-12-31 16:00:00
@@ -1,254 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package debug exports debug information for gopls.
-package debug
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"io"
-	"reflect"
-	"runtime"
-	"runtime/debug"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-type PrintMode int
-
-const (
-	PlainText = PrintMode(iota)
-	Markdown
-	HTML
-	JSON
-)
-
-// Version is a manually-updated mechanism for tracking versions.
-const Version = "master"
-
-// ServerVersion is the format used by gopls to report its version to the
-// client. This format is structured so that the client can parse it easily.
-type ServerVersion struct {
-	*BuildInfo
-	Version string
-}
-
-// VersionInfo returns the build info for the gopls process. If it was not
-// built in module mode, we return a GOPATH-specific message with the
-// hardcoded version.
-func VersionInfo() *ServerVersion {
-	if info, ok := readBuildInfo(); ok {
-		return getVersion(info)
-	}
-	buildInfo := &BuildInfo{}
-	// go1.17 or earlier, part of s.BuildInfo are embedded fields.
-	buildInfo.Path = "gopls, built in GOPATH mode"
-	buildInfo.GoVersion = runtime.Version()
-	return &ServerVersion{
-		Version:   Version,
-		BuildInfo: buildInfo,
-	}
-}
-
-func getVersion(info *BuildInfo) *ServerVersion {
-	return &ServerVersion{
-		Version:   Version,
-		BuildInfo: info,
-	}
-}
-
-// PrintServerInfo writes HTML debug info to w for the Instance.
-func (i *Instance) PrintServerInfo(ctx context.Context, w io.Writer) {
-	section(w, HTML, "Server Instance", func() {
-		fmt.Fprintf(w, "Start time: %v\n", i.StartTime)
-		fmt.Fprintf(w, "LogFile: %s\n", i.Logfile)
-		fmt.Fprintf(w, "Working directory: %s\n", i.Workdir)
-		fmt.Fprintf(w, "Address: %s\n", i.ServerAddress)
-		fmt.Fprintf(w, "Debug address: %s\n", i.DebugAddress())
-	})
-	PrintVersionInfo(ctx, w, true, HTML)
-	section(w, HTML, "Command Line", func() {
-		fmt.Fprintf(w, "<a href=/debug/pprof/cmdline>cmdline</a>")
-	})
-}
-
-// PrintVersionInfo writes version information to w, using the output format
-// specified by mode. verbose controls whether additional information is
-// written, including section headers.
-func PrintVersionInfo(_ context.Context, w io.Writer, verbose bool, mode PrintMode) error {
-	info := VersionInfo()
-	if mode == JSON {
-		return printVersionInfoJSON(w, info)
-	}
-
-	if !verbose {
-		printBuildInfo(w, info, false, mode)
-		return nil
-	}
-	section(w, mode, "Build info", func() {
-		printBuildInfo(w, info, true, mode)
-	})
-	return nil
-}
-
-func printVersionInfoJSON(w io.Writer, info *ServerVersion) error {
-	js, err := json.MarshalIndent(info, "", "\t")
-	if err != nil {
-		return err
-	}
-	_, err = fmt.Fprint(w, string(js))
-	return err
-}
-
-func section(w io.Writer, mode PrintMode, title string, body func()) {
-	switch mode {
-	case PlainText:
-		fmt.Fprintln(w, title)
-		fmt.Fprintln(w, strings.Repeat("-", len(title)))
-		body()
-	case Markdown:
-		fmt.Fprintf(w, "#### %s\n\n```\n", title)
-		body()
-		fmt.Fprintf(w, "```\n")
-	case HTML:
-		fmt.Fprintf(w, "<h3>%s</h3>\n<pre>\n", title)
-		body()
-		fmt.Fprint(w, "</pre>\n")
-	}
-}
-
-func printBuildInfo(w io.Writer, info *ServerVersion, verbose bool, mode PrintMode) {
-	fmt.Fprintf(w, "%v %v\n", info.Path, Version)
-	printModuleInfo(w, info.Main, mode)
-	if !verbose {
-		return
-	}
-	for _, dep := range info.Deps {
-		printModuleInfo(w, *dep, mode)
-	}
-	fmt.Fprintf(w, "go: %v\n", info.GoVersion)
-}
-
-func printModuleInfo(w io.Writer, m debug.Module, _ PrintMode) {
-	fmt.Fprintf(w, "    %s@%s", m.Path, m.Version)
-	if m.Sum != "" {
-		fmt.Fprintf(w, " %s", m.Sum)
-	}
-	if m.Replace != nil {
-		fmt.Fprintf(w, " => %v", m.Replace.Path)
-	}
-	fmt.Fprintf(w, "\n")
-}
-
-type field struct {
-	index []int
-}
-
-var fields []field
-
-// find all the options. The presumption is that the Options are nested structs
-// and that pointers don't need to be dereferenced
-func swalk(t reflect.Type, ix []int, indent string) {
-	switch t.Kind() {
-	case reflect.Struct:
-		for i := 0; i < t.NumField(); i++ {
-			fld := t.Field(i)
-			ixx := append(append([]int{}, ix...), i)
-			swalk(fld.Type, ixx, indent+". ")
-		}
-	default:
-		// everything is either a struct or a field (that's an assumption about Options)
-		fields = append(fields, field{ix})
-	}
-}
-
-type sessionOption struct {
-	Name    string
-	Type    string
-	Current string
-	Default string
-}
-
-func showOptions(o *source.Options) []sessionOption {
-	var out []sessionOption
-	t := reflect.TypeOf(*o)
-	swalk(t, []int{}, "")
-	v := reflect.ValueOf(*o)
-	do := reflect.ValueOf(*source.DefaultOptions())
-	for _, f := range fields {
-		val := v.FieldByIndex(f.index)
-		def := do.FieldByIndex(f.index)
-		tx := t.FieldByIndex(f.index)
-		is := strVal(val)
-		was := strVal(def)
-		out = append(out, sessionOption{
-			Name:    tx.Name,
-			Type:    tx.Type.String(),
-			Current: is,
-			Default: was,
-		})
-	}
-	sort.Slice(out, func(i, j int) bool {
-		rd := out[i].Current == out[i].Default
-		ld := out[j].Current == out[j].Default
-		if rd != ld {
-			return ld
-		}
-		return out[i].Name < out[j].Name
-	})
-	return out
-}
-
-func strVal(val reflect.Value) string {
-	switch val.Kind() {
-	case reflect.Bool:
-		return fmt.Sprintf("%v", val.Interface())
-	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:
-		return fmt.Sprintf("%v", val.Interface())
-	case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:
-		return fmt.Sprintf("%v", val.Interface())
-	case reflect.Uintptr, reflect.UnsafePointer:
-		return fmt.Sprintf("0x%x", val.Pointer())
-	case reflect.Complex64, reflect.Complex128:
-		return fmt.Sprintf("%v", val.Complex())
-	case reflect.Array, reflect.Slice:
-		ans := []string{}
-		for i := 0; i < val.Len(); i++ {
-			ans = append(ans, strVal(val.Index(i)))
-		}
-		sort.Strings(ans)
-		return fmt.Sprintf("%v", ans)
-	case reflect.Chan, reflect.Func, reflect.Ptr:
-		return val.Kind().String()
-	case reflect.Struct:
-		var x source.Analyzer
-		if val.Type() != reflect.TypeOf(x) {
-			return val.Kind().String()
-		}
-		// this is sort of ugly, but usable
-		str := val.FieldByName("Analyzer").Elem().FieldByName("Doc").String()
-		ix := strings.Index(str, "\n")
-		if ix == -1 {
-			ix = len(str)
-		}
-		return str[:ix]
-	case reflect.String:
-		return fmt.Sprintf("%q", val.Interface())
-	case reflect.Map:
-		ans := []string{}
-		iter := val.MapRange()
-		for iter.Next() {
-			k := iter.Key()
-			v := iter.Value()
-			ans = append(ans, fmt.Sprintf("%s:%s, ", strVal(k), strVal(v)))
-		}
-		sort.Strings(ans)
-		return fmt.Sprintf("%v", ans)
-	}
-	return fmt.Sprintf("??%s??", val.Type())
-}
diff -urN a/gopls/internal/lsp/debug/info_test.go b/gopls/internal/lsp/debug/info_test.go
--- a/gopls/internal/lsp/debug/info_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/info_test.go	1969-12-31 16:00:00
@@ -1,47 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package debug exports debug information for gopls.
-package debug
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"runtime"
-	"testing"
-)
-
-func TestPrintVersionInfoJSON(t *testing.T) {
-	buf := new(bytes.Buffer)
-	if err := PrintVersionInfo(context.Background(), buf, true, JSON); err != nil {
-		t.Fatalf("PrintVersionInfo failed: %v", err)
-	}
-	res := buf.Bytes()
-
-	var got ServerVersion
-	if err := json.Unmarshal(res, &got); err != nil {
-		t.Fatalf("unexpected output: %v\n%s", err, res)
-	}
-	if g, w := got.GoVersion, runtime.Version(); g != w {
-		t.Errorf("go version = %v, want %v", g, w)
-	}
-	if g, w := got.Version, Version; g != w {
-		t.Errorf("gopls version = %v, want %v", g, w)
-	}
-	// Other fields of BuildInfo may not be available during test.
-}
-
-func TestPrintVersionInfoPlainText(t *testing.T) {
-	buf := new(bytes.Buffer)
-	if err := PrintVersionInfo(context.Background(), buf, true, PlainText); err != nil {
-		t.Fatalf("PrintVersionInfo failed: %v", err)
-	}
-	res := buf.Bytes()
-
-	// Other fields of BuildInfo may not be available during test.
-	if !bytes.Contains(res, []byte(Version)) || !bytes.Contains(res, []byte(runtime.Version())) {
-		t.Errorf("plaintext output = %q,\nwant (version: %v, go: %v)", res, Version, runtime.Version())
-	}
-}
diff -urN a/gopls/internal/lsp/debug/log/log.go b/gopls/internal/lsp/debug/log/log.go
--- a/gopls/internal/lsp/debug/log/log.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/log/log.go	1969-12-31 16:00:00
@@ -1,43 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package log provides helper methods for exporting log events to the
-// internal/event package.
-package log
-
-import (
-	"context"
-	"fmt"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/label"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-// Level parameterizes log severity.
-type Level int
-
-const (
-	_ Level = iota
-	Error
-	Warning
-	Info
-	Debug
-	Trace
-)
-
-// Log exports a log event labeled with level l.
-func (l Level) Log(ctx context.Context, msg string) {
-	event.Log(ctx, msg, tag.Level.Of(int(l)))
-}
-
-// Logf formats and exports a log event labeled with level l.
-func (l Level) Logf(ctx context.Context, format string, args ...interface{}) {
-	l.Log(ctx, fmt.Sprintf(format, args...))
-}
-
-// LabeledLevel extracts the labeled log l
-func LabeledLevel(lm label.Map) Level {
-	return Level(tag.Level.Get(lm))
-}
diff -urN a/gopls/internal/lsp/debug/metrics.go b/gopls/internal/lsp/debug/metrics.go
--- a/gopls/internal/lsp/debug/metrics.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/metrics.go	1969-12-31 16:00:00
@@ -1,58 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package debug
-
-import (
-	"golang.org/x/tools/internal/event/export/metric"
-	"golang.org/x/tools/internal/event/label"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-var (
-	// the distributions we use for histograms
-	bytesDistribution        = []int64{1 << 10, 1 << 11, 1 << 12, 1 << 14, 1 << 16, 1 << 20}
-	millisecondsDistribution = []float64{0.1, 0.5, 1, 2, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000}
-
-	receivedBytes = metric.HistogramInt64{
-		Name:        "received_bytes",
-		Description: "Distribution of received bytes, by method.",
-		Keys:        []label.Key{tag.RPCDirection, tag.Method},
-		Buckets:     bytesDistribution,
-	}
-
-	sentBytes = metric.HistogramInt64{
-		Name:        "sent_bytes",
-		Description: "Distribution of sent bytes, by method.",
-		Keys:        []label.Key{tag.RPCDirection, tag.Method},
-		Buckets:     bytesDistribution,
-	}
-
-	latency = metric.HistogramFloat64{
-		Name:        "latency",
-		Description: "Distribution of latency in milliseconds, by method.",
-		Keys:        []label.Key{tag.RPCDirection, tag.Method},
-		Buckets:     millisecondsDistribution,
-	}
-
-	started = metric.Scalar{
-		Name:        "started",
-		Description: "Count of RPCs started by method.",
-		Keys:        []label.Key{tag.RPCDirection, tag.Method},
-	}
-
-	completed = metric.Scalar{
-		Name:        "completed",
-		Description: "Count of RPCs completed by method and status.",
-		Keys:        []label.Key{tag.RPCDirection, tag.Method, tag.StatusCode},
-	}
-)
-
-func registerMetrics(m *metric.Config) {
-	receivedBytes.Record(m, tag.ReceivedBytes)
-	sentBytes.Record(m, tag.SentBytes)
-	latency.Record(m, tag.Latency)
-	started.Count(m, tag.Started)
-	completed.Count(m, tag.Latency)
-}
diff -urN a/gopls/internal/lsp/debug/rpc.go b/gopls/internal/lsp/debug/rpc.go
--- a/gopls/internal/lsp/debug/rpc.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/rpc.go	1969-12-31 16:00:00
@@ -1,239 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package debug
-
-import (
-	"context"
-	"fmt"
-	"html/template"
-	"net/http"
-	"sort"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/core"
-	"golang.org/x/tools/internal/event/export"
-	"golang.org/x/tools/internal/event/label"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-var RPCTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}RPC Information{{end}}
-{{define "body"}}
-	<H2>Inbound</H2>
-	{{template "rpcSection" .Inbound}}
-	<H2>Outbound</H2>
-	{{template "rpcSection" .Outbound}}
-{{end}}
-{{define "rpcSection"}}
-	{{range .}}<P>
-		<b>{{.Method}}</b> {{.Started}} <a href="/trace/{{.Method}}">traces</a> ({{.InProgress}} in progress)
-		<br>
-		<i>Latency</i> {{with .Latency}}{{.Mean}} ({{.Min}}<{{.Max}}){{end}}
-		<i>By bucket</i> 0s {{range .Latency.Values}}{{if gt .Count 0}}<b>{{.Count}}</b> {{.Limit}} {{end}}{{end}}
-		<br>
-		<i>Received</i> {{.Received}} (avg. {{.ReceivedMean}})
-		<i>Sent</i> {{.Sent}} (avg. {{.SentMean}})
-		<br>
-		<i>Result codes</i> {{range .Codes}}{{.Key}}={{.Count}} {{end}}
-		</P>
-	{{end}}
-{{end}}
-`))
-
-type Rpcs struct { // exported for testing
-	mu       sync.Mutex
-	Inbound  []*rpcStats // stats for incoming lsp rpcs sorted by method name
-	Outbound []*rpcStats // stats for outgoing lsp rpcs sorted by method name
-}
-
-type rpcStats struct {
-	Method    string
-	Started   int64
-	Completed int64
-
-	Latency  rpcTimeHistogram
-	Received byteUnits
-	Sent     byteUnits
-	Codes    []*rpcCodeBucket
-}
-
-type rpcTimeHistogram struct {
-	Sum    timeUnits
-	Count  int64
-	Min    timeUnits
-	Max    timeUnits
-	Values []rpcTimeBucket
-}
-
-type rpcTimeBucket struct {
-	Limit timeUnits
-	Count int64
-}
-
-type rpcCodeBucket struct {
-	Key   string
-	Count int64
-}
-
-func (r *Rpcs) ProcessEvent(ctx context.Context, ev core.Event, lm label.Map) context.Context {
-	r.mu.Lock()
-	defer r.mu.Unlock()
-	switch {
-	case event.IsStart(ev):
-		if _, stats := r.getRPCSpan(ctx, ev); stats != nil {
-			stats.Started++
-		}
-	case event.IsEnd(ev):
-		span, stats := r.getRPCSpan(ctx, ev)
-		if stats != nil {
-			endRPC(ctx, ev, span, stats)
-		}
-	case event.IsMetric(ev):
-		sent := byteUnits(tag.SentBytes.Get(lm))
-		rec := byteUnits(tag.ReceivedBytes.Get(lm))
-		if sent != 0 || rec != 0 {
-			if _, stats := r.getRPCSpan(ctx, ev); stats != nil {
-				stats.Sent += sent
-				stats.Received += rec
-			}
-		}
-	}
-	return ctx
-}
-
-func endRPC(ctx context.Context, ev core.Event, span *export.Span, stats *rpcStats) {
-	// update the basic counts
-	stats.Completed++
-
-	// get and record the status code
-	if status := getStatusCode(span); status != "" {
-		var b *rpcCodeBucket
-		for c, entry := range stats.Codes {
-			if entry.Key == status {
-				b = stats.Codes[c]
-				break
-			}
-		}
-		if b == nil {
-			b = &rpcCodeBucket{Key: status}
-			stats.Codes = append(stats.Codes, b)
-			sort.Slice(stats.Codes, func(i int, j int) bool {
-				return stats.Codes[i].Key < stats.Codes[j].Key
-			})
-		}
-		b.Count++
-	}
-
-	// calculate latency if this was an rpc span
-	elapsedTime := span.Finish().At().Sub(span.Start().At())
-	latencyMillis := timeUnits(elapsedTime) / timeUnits(time.Millisecond)
-	if stats.Latency.Count == 0 {
-		stats.Latency.Min = latencyMillis
-		stats.Latency.Max = latencyMillis
-	} else {
-		if stats.Latency.Min > latencyMillis {
-			stats.Latency.Min = latencyMillis
-		}
-		if stats.Latency.Max < latencyMillis {
-			stats.Latency.Max = latencyMillis
-		}
-	}
-	stats.Latency.Count++
-	stats.Latency.Sum += latencyMillis
-	for i := range stats.Latency.Values {
-		if stats.Latency.Values[i].Limit > latencyMillis {
-			stats.Latency.Values[i].Count++
-			break
-		}
-	}
-}
-
-func (r *Rpcs) getRPCSpan(ctx context.Context, ev core.Event) (*export.Span, *rpcStats) {
-	// get the span
-	span := export.GetSpan(ctx)
-	if span == nil {
-		return nil, nil
-	}
-	// use the span start event look up the correct stats block
-	// we do this because it prevents us matching a sub span
-	return span, r.getRPCStats(span.Start())
-}
-
-func (r *Rpcs) getRPCStats(lm label.Map) *rpcStats {
-	method := tag.Method.Get(lm)
-	if method == "" {
-		return nil
-	}
-	set := &r.Inbound
-	if tag.RPCDirection.Get(lm) != tag.Inbound {
-		set = &r.Outbound
-	}
-	// get the record for this method
-	index := sort.Search(len(*set), func(i int) bool {
-		return (*set)[i].Method >= method
-	})
-
-	if index < len(*set) && (*set)[index].Method == method {
-		return (*set)[index]
-	}
-
-	old := *set
-	*set = make([]*rpcStats, len(old)+1)
-	copy(*set, old[:index])
-	copy((*set)[index+1:], old[index:])
-	stats := &rpcStats{Method: method}
-	stats.Latency.Values = make([]rpcTimeBucket, len(millisecondsDistribution))
-	for i, m := range millisecondsDistribution {
-		stats.Latency.Values[i].Limit = timeUnits(m)
-	}
-	(*set)[index] = stats
-	return stats
-}
-
-func (s *rpcStats) InProgress() int64       { return s.Started - s.Completed }
-func (s *rpcStats) SentMean() byteUnits     { return s.Sent / byteUnits(s.Started) }
-func (s *rpcStats) ReceivedMean() byteUnits { return s.Received / byteUnits(s.Started) }
-
-func (h *rpcTimeHistogram) Mean() timeUnits { return h.Sum / timeUnits(h.Count) }
-
-func getStatusCode(span *export.Span) string {
-	for _, ev := range span.Events() {
-		if status := tag.StatusCode.Get(ev); status != "" {
-			return status
-		}
-	}
-	return ""
-}
-
-func (r *Rpcs) getData(req *http.Request) interface{} {
-	return r
-}
-
-func units(v float64, suffixes []string) string {
-	s := ""
-	for _, s = range suffixes {
-		n := v / 1000
-		if n < 1 {
-			break
-		}
-		v = n
-	}
-	return fmt.Sprintf("%.2f%s", v, s)
-}
-
-type timeUnits float64
-
-func (v timeUnits) String() string {
-	v = v * 1000 * 1000
-	return units(float64(v), []string{"ns", "μs", "ms", "s"})
-}
-
-type byteUnits float64
-
-func (v byteUnits) String() string {
-	return units(float64(v), []string{"B", "KB", "MB", "GB", "TB"})
-}
diff -urN a/gopls/internal/lsp/debug/serve.go b/gopls/internal/lsp/debug/serve.go
--- a/gopls/internal/lsp/debug/serve.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/serve.go	1969-12-31 16:00:00
@@ -1,912 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package debug
-
-import (
-	"archive/zip"
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"html/template"
-	"io"
-	stdlog "log"
-	"net"
-	"net/http"
-	"net/http/pprof"
-	"os"
-	"path"
-	"path/filepath"
-	"runtime"
-	rpprof "runtime/pprof"
-	"strconv"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug/log"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/core"
-	"golang.org/x/tools/internal/event/export"
-	"golang.org/x/tools/internal/event/export/metric"
-	"golang.org/x/tools/internal/event/export/ocagent"
-	"golang.org/x/tools/internal/event/export/prometheus"
-	"golang.org/x/tools/internal/event/keys"
-	"golang.org/x/tools/internal/event/label"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-type contextKeyType int
-
-const (
-	instanceKey contextKeyType = iota
-	traceKey
-)
-
-// An Instance holds all debug information associated with a gopls instance.
-type Instance struct {
-	Logfile       string
-	StartTime     time.Time
-	ServerAddress string
-	Workdir       string
-	OCAgentConfig string
-
-	LogWriter io.Writer
-
-	exporter event.Exporter
-
-	ocagent    *ocagent.Exporter
-	prometheus *prometheus.Exporter
-	rpcs       *Rpcs
-	traces     *traces
-	State      *State
-
-	serveMu              sync.Mutex
-	debugAddress         string
-	listenedDebugAddress string
-}
-
-// State holds debugging information related to the server state.
-type State struct {
-	mu      sync.Mutex
-	clients []*Client
-	servers []*Server
-}
-
-func (st *State) Bugs() []bug.Bug {
-	return bug.List()
-}
-
-// Caches returns the set of Cache objects currently being served.
-func (st *State) Caches() []*cache.Cache {
-	var caches []*cache.Cache
-	seen := make(map[string]struct{})
-	for _, client := range st.Clients() {
-		cache := client.Session.Cache()
-		if _, found := seen[cache.ID()]; found {
-			continue
-		}
-		seen[cache.ID()] = struct{}{}
-		caches = append(caches, cache)
-	}
-	return caches
-}
-
-// Cache returns the Cache that matches the supplied id.
-func (st *State) Cache(id string) *cache.Cache {
-	for _, c := range st.Caches() {
-		if c.ID() == id {
-			return c
-		}
-	}
-	return nil
-}
-
-// Sessions returns the set of Session objects currently being served.
-func (st *State) Sessions() []*cache.Session {
-	var sessions []*cache.Session
-	for _, client := range st.Clients() {
-		sessions = append(sessions, client.Session)
-	}
-	return sessions
-}
-
-// Session returns the Session that matches the supplied id.
-func (st *State) Session(id string) *cache.Session {
-	for _, s := range st.Sessions() {
-		if s.ID() == id {
-			return s
-		}
-	}
-	return nil
-}
-
-// Views returns the set of View objects currently being served.
-func (st *State) Views() []*cache.View {
-	var views []*cache.View
-	for _, s := range st.Sessions() {
-		views = append(views, s.Views()...)
-	}
-	return views
-}
-
-// View returns the View that matches the supplied id.
-func (st *State) View(id string) *cache.View {
-	for _, v := range st.Views() {
-		if v.ID() == id {
-			return v
-		}
-	}
-	return nil
-}
-
-// Clients returns the set of Clients currently being served.
-func (st *State) Clients() []*Client {
-	st.mu.Lock()
-	defer st.mu.Unlock()
-	clients := make([]*Client, len(st.clients))
-	copy(clients, st.clients)
-	return clients
-}
-
-// Client returns the Client matching the supplied id.
-func (st *State) Client(id string) *Client {
-	for _, c := range st.Clients() {
-		if c.Session.ID() == id {
-			return c
-		}
-	}
-	return nil
-}
-
-// Servers returns the set of Servers the instance is currently connected to.
-func (st *State) Servers() []*Server {
-	st.mu.Lock()
-	defer st.mu.Unlock()
-	servers := make([]*Server, len(st.servers))
-	copy(servers, st.servers)
-	return servers
-}
-
-// A Client is an incoming connection from a remote client.
-type Client struct {
-	Session      *cache.Session
-	DebugAddress string
-	Logfile      string
-	GoplsPath    string
-	ServerID     string
-	Service      protocol.Server
-}
-
-// A Server is an outgoing connection to a remote LSP server.
-type Server struct {
-	ID           string
-	DebugAddress string
-	Logfile      string
-	GoplsPath    string
-	ClientID     string
-}
-
-// AddClient adds a client to the set being served.
-func (st *State) addClient(session *cache.Session) {
-	st.mu.Lock()
-	defer st.mu.Unlock()
-	st.clients = append(st.clients, &Client{Session: session})
-}
-
-// DropClient removes a client from the set being served.
-func (st *State) dropClient(session *cache.Session) {
-	st.mu.Lock()
-	defer st.mu.Unlock()
-	for i, c := range st.clients {
-		if c.Session == session {
-			copy(st.clients[i:], st.clients[i+1:])
-			st.clients[len(st.clients)-1] = nil
-			st.clients = st.clients[:len(st.clients)-1]
-			return
-		}
-	}
-}
-
-// AddServer adds a server to the set being queried. In practice, there should
-// be at most one remote server.
-func (st *State) updateServer(server *Server) {
-	st.mu.Lock()
-	defer st.mu.Unlock()
-	for i, existing := range st.servers {
-		if existing.ID == server.ID {
-			// Replace, rather than mutate, to avoid a race.
-			newServers := make([]*Server, len(st.servers))
-			copy(newServers, st.servers[:i])
-			newServers[i] = server
-			copy(newServers[i+1:], st.servers[i+1:])
-			st.servers = newServers
-			return
-		}
-	}
-	st.servers = append(st.servers, server)
-}
-
-// DropServer drops a server from the set being queried.
-func (st *State) dropServer(id string) {
-	st.mu.Lock()
-	defer st.mu.Unlock()
-	for i, s := range st.servers {
-		if s.ID == id {
-			copy(st.servers[i:], st.servers[i+1:])
-			st.servers[len(st.servers)-1] = nil
-			st.servers = st.servers[:len(st.servers)-1]
-			return
-		}
-	}
-}
-
-// an http.ResponseWriter that filters writes
-type filterResponse struct {
-	w    http.ResponseWriter
-	edit func([]byte) []byte
-}
-
-func (c filterResponse) Header() http.Header {
-	return c.w.Header()
-}
-
-func (c filterResponse) Write(buf []byte) (int, error) {
-	ans := c.edit(buf)
-	return c.w.Write(ans)
-}
-
-func (c filterResponse) WriteHeader(n int) {
-	c.w.WriteHeader(n)
-}
-
-// replace annoying nuls by spaces
-func cmdline(w http.ResponseWriter, r *http.Request) {
-	fake := filterResponse{
-		w: w,
-		edit: func(buf []byte) []byte {
-			return bytes.ReplaceAll(buf, []byte{0}, []byte{' '})
-		},
-	}
-	pprof.Cmdline(fake, r)
-}
-
-func (i *Instance) getCache(r *http.Request) interface{} {
-	return i.State.Cache(path.Base(r.URL.Path))
-}
-
-func (i *Instance) getSession(r *http.Request) interface{} {
-	return i.State.Session(path.Base(r.URL.Path))
-}
-
-func (i *Instance) getClient(r *http.Request) interface{} {
-	return i.State.Client(path.Base(r.URL.Path))
-}
-
-func (i *Instance) getServer(r *http.Request) interface{} {
-	i.State.mu.Lock()
-	defer i.State.mu.Unlock()
-	id := path.Base(r.URL.Path)
-	for _, s := range i.State.servers {
-		if s.ID == id {
-			return s
-		}
-	}
-	return nil
-}
-
-func (i *Instance) getView(r *http.Request) interface{} {
-	return i.State.View(path.Base(r.URL.Path))
-}
-
-func (i *Instance) getFile(r *http.Request) interface{} {
-	identifier := path.Base(r.URL.Path)
-	sid := path.Base(path.Dir(r.URL.Path))
-	s := i.State.Session(sid)
-	if s == nil {
-		return nil
-	}
-	for _, o := range s.Overlays() {
-		// TODO(adonovan): understand and document this comparison.
-		if o.FileIdentity().Hash.String() == identifier {
-			return o
-		}
-	}
-	return nil
-}
-
-func (i *Instance) getInfo(r *http.Request) interface{} {
-	buf := &bytes.Buffer{}
-	i.PrintServerInfo(r.Context(), buf)
-	return template.HTML(buf.String())
-}
-
-func (i *Instance) AddService(s protocol.Server, session *cache.Session) {
-	for _, c := range i.State.clients {
-		if c.Session == session {
-			c.Service = s
-			return
-		}
-	}
-	stdlog.Printf("unable to find a Client to add the protocol.Server to")
-}
-
-func getMemory(_ *http.Request) interface{} {
-	var m runtime.MemStats
-	runtime.ReadMemStats(&m)
-	return m
-}
-
-func init() {
-	event.SetExporter(makeGlobalExporter(os.Stderr))
-}
-
-func GetInstance(ctx context.Context) *Instance {
-	if ctx == nil {
-		return nil
-	}
-	v := ctx.Value(instanceKey)
-	if v == nil {
-		return nil
-	}
-	return v.(*Instance)
-}
-
-// WithInstance creates debug instance ready for use using the supplied
-// configuration and stores it in the returned context.
-func WithInstance(ctx context.Context, workdir, agent string) context.Context {
-	i := &Instance{
-		StartTime:     time.Now(),
-		Workdir:       workdir,
-		OCAgentConfig: agent,
-	}
-	i.LogWriter = os.Stderr
-	ocConfig := ocagent.Discover()
-	//TODO: we should not need to adjust the discovered configuration
-	ocConfig.Address = i.OCAgentConfig
-	i.ocagent = ocagent.Connect(ocConfig)
-	i.prometheus = prometheus.New()
-	i.rpcs = &Rpcs{}
-	i.traces = &traces{}
-	i.State = &State{}
-	i.exporter = makeInstanceExporter(i)
-	return context.WithValue(ctx, instanceKey, i)
-}
-
-// SetLogFile sets the logfile for use with this instance.
-func (i *Instance) SetLogFile(logfile string, isDaemon bool) (func(), error) {
-	// TODO: probably a better solution for deferring closure to the caller would
-	// be for the debug instance to itself be closed, but this fixes the
-	// immediate bug of logs not being captured.
-	closeLog := func() {}
-	if logfile != "" {
-		if logfile == "auto" {
-			if isDaemon {
-				logfile = filepath.Join(os.TempDir(), fmt.Sprintf("gopls-daemon-%d.log", os.Getpid()))
-			} else {
-				logfile = filepath.Join(os.TempDir(), fmt.Sprintf("gopls-%d.log", os.Getpid()))
-			}
-		}
-		f, err := os.Create(logfile)
-		if err != nil {
-			return nil, fmt.Errorf("unable to create log file: %w", err)
-		}
-		closeLog = func() {
-			defer f.Close()
-		}
-		stdlog.SetOutput(io.MultiWriter(os.Stderr, f))
-		i.LogWriter = f
-	}
-	i.Logfile = logfile
-	return closeLog, nil
-}
-
-// Serve starts and runs a debug server in the background on the given addr.
-// It also logs the port the server starts on, to allow for :0 auto assigned
-// ports.
-func (i *Instance) Serve(ctx context.Context, addr string) (string, error) {
-	stdlog.SetFlags(stdlog.Lshortfile)
-	if addr == "" {
-		return "", nil
-	}
-	i.serveMu.Lock()
-	defer i.serveMu.Unlock()
-
-	if i.listenedDebugAddress != "" {
-		// Already serving. Return the bound address.
-		return i.listenedDebugAddress, nil
-	}
-
-	i.debugAddress = addr
-	listener, err := net.Listen("tcp", i.debugAddress)
-	if err != nil {
-		return "", err
-	}
-	i.listenedDebugAddress = listener.Addr().String()
-
-	port := listener.Addr().(*net.TCPAddr).Port
-	if strings.HasSuffix(i.debugAddress, ":0") {
-		stdlog.Printf("debug server listening at http://localhost:%d", port)
-	}
-	event.Log(ctx, "Debug serving", tag.Port.Of(port))
-	go func() {
-		mux := http.NewServeMux()
-		mux.HandleFunc("/", render(MainTmpl, func(*http.Request) interface{} { return i }))
-		mux.HandleFunc("/debug/", render(DebugTmpl, nil))
-		mux.HandleFunc("/debug/pprof/", pprof.Index)
-		mux.HandleFunc("/debug/pprof/cmdline", cmdline)
-		mux.HandleFunc("/debug/pprof/profile", pprof.Profile)
-		mux.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
-		mux.HandleFunc("/debug/pprof/trace", pprof.Trace)
-		if i.prometheus != nil {
-			mux.HandleFunc("/metrics/", i.prometheus.Serve)
-		}
-		if i.rpcs != nil {
-			mux.HandleFunc("/rpc/", render(RPCTmpl, i.rpcs.getData))
-		}
-		if i.traces != nil {
-			mux.HandleFunc("/trace/", render(TraceTmpl, i.traces.getData))
-		}
-		mux.HandleFunc("/cache/", render(CacheTmpl, i.getCache))
-		mux.HandleFunc("/session/", render(SessionTmpl, i.getSession))
-		mux.HandleFunc("/view/", render(ViewTmpl, i.getView))
-		mux.HandleFunc("/client/", render(ClientTmpl, i.getClient))
-		mux.HandleFunc("/server/", render(ServerTmpl, i.getServer))
-		mux.HandleFunc("/file/", render(FileTmpl, i.getFile))
-		mux.HandleFunc("/info", render(InfoTmpl, i.getInfo))
-		mux.HandleFunc("/memory", render(MemoryTmpl, getMemory))
-
-		mux.HandleFunc("/_makeabug", func(w http.ResponseWriter, r *http.Request) {
-			bug.Report("bug here", nil)
-			http.Error(w, "made a bug", http.StatusOK)
-		})
-
-		if err := http.Serve(listener, mux); err != nil {
-			event.Error(ctx, "Debug server failed", err)
-			return
-		}
-		event.Log(ctx, "Debug server finished")
-	}()
-	return i.listenedDebugAddress, nil
-}
-
-func (i *Instance) DebugAddress() string {
-	i.serveMu.Lock()
-	defer i.serveMu.Unlock()
-	return i.debugAddress
-}
-
-func (i *Instance) ListenedDebugAddress() string {
-	i.serveMu.Lock()
-	defer i.serveMu.Unlock()
-	return i.listenedDebugAddress
-}
-
-// MonitorMemory starts recording memory statistics each second.
-func (i *Instance) MonitorMemory(ctx context.Context) {
-	tick := time.NewTicker(time.Second)
-	nextThresholdGiB := uint64(1)
-	go func() {
-		for {
-			<-tick.C
-			var mem runtime.MemStats
-			runtime.ReadMemStats(&mem)
-			if mem.HeapAlloc < nextThresholdGiB*1<<30 {
-				continue
-			}
-			if err := i.writeMemoryDebug(nextThresholdGiB, true); err != nil {
-				event.Error(ctx, "writing memory debug info", err)
-			}
-			if err := i.writeMemoryDebug(nextThresholdGiB, false); err != nil {
-				event.Error(ctx, "writing memory debug info", err)
-			}
-			event.Log(ctx, fmt.Sprintf("Wrote memory usage debug info to %v", os.TempDir()))
-			nextThresholdGiB++
-		}
-	}()
-}
-
-func (i *Instance) writeMemoryDebug(threshold uint64, withNames bool) error {
-	suffix := "withnames"
-	if !withNames {
-		suffix = "nonames"
-	}
-
-	filename := fmt.Sprintf("gopls.%d-%dGiB-%s.zip", os.Getpid(), threshold, suffix)
-	zipf, err := os.OpenFile(filepath.Join(os.TempDir(), filename), os.O_CREATE|os.O_RDWR, 0644)
-	if err != nil {
-		return err
-	}
-	zipw := zip.NewWriter(zipf)
-
-	f, err := zipw.Create("heap.pb.gz")
-	if err != nil {
-		return err
-	}
-	if err := rpprof.Lookup("heap").WriteTo(f, 0); err != nil {
-		return err
-	}
-
-	f, err = zipw.Create("goroutines.txt")
-	if err != nil {
-		return err
-	}
-	if err := rpprof.Lookup("goroutine").WriteTo(f, 1); err != nil {
-		return err
-	}
-
-	for _, cache := range i.State.Caches() {
-		cf, err := zipw.Create(fmt.Sprintf("cache-%v.html", cache.ID()))
-		if err != nil {
-			return err
-		}
-		if _, err := cf.Write([]byte(cache.PackageStats(withNames))); err != nil {
-			return err
-		}
-	}
-
-	if err := zipw.Close(); err != nil {
-		return err
-	}
-	return zipf.Close()
-}
-
-func makeGlobalExporter(stderr io.Writer) event.Exporter {
-	p := export.Printer{}
-	var pMu sync.Mutex
-	return func(ctx context.Context, ev core.Event, lm label.Map) context.Context {
-		i := GetInstance(ctx)
-
-		if event.IsLog(ev) {
-			// Don't log context cancellation errors.
-			if err := keys.Err.Get(ev); errors.Is(err, context.Canceled) {
-				return ctx
-			}
-			// Make sure any log messages without an instance go to stderr.
-			if i == nil {
-				pMu.Lock()
-				p.WriteEvent(stderr, ev, lm)
-				pMu.Unlock()
-			}
-			level := log.LabeledLevel(lm)
-			// Exclude trace logs from LSP logs.
-			if level < log.Trace {
-				ctx = protocol.LogEvent(ctx, ev, lm, messageType(level))
-			}
-		}
-		if i == nil {
-			return ctx
-		}
-		return i.exporter(ctx, ev, lm)
-	}
-}
-
-func messageType(l log.Level) protocol.MessageType {
-	switch l {
-	case log.Error:
-		return protocol.Error
-	case log.Warning:
-		return protocol.Warning
-	case log.Debug:
-		return protocol.Log
-	}
-	return protocol.Info
-}
-
-func makeInstanceExporter(i *Instance) event.Exporter {
-	exporter := func(ctx context.Context, ev core.Event, lm label.Map) context.Context {
-		if i.ocagent != nil {
-			ctx = i.ocagent.ProcessEvent(ctx, ev, lm)
-		}
-		if i.prometheus != nil {
-			ctx = i.prometheus.ProcessEvent(ctx, ev, lm)
-		}
-		if i.rpcs != nil {
-			ctx = i.rpcs.ProcessEvent(ctx, ev, lm)
-		}
-		if i.traces != nil {
-			ctx = i.traces.ProcessEvent(ctx, ev, lm)
-		}
-		if event.IsLog(ev) {
-			if s := cache.KeyCreateSession.Get(ev); s != nil {
-				i.State.addClient(s)
-			}
-			if sid := tag.NewServer.Get(ev); sid != "" {
-				i.State.updateServer(&Server{
-					ID:           sid,
-					Logfile:      tag.Logfile.Get(ev),
-					DebugAddress: tag.DebugAddress.Get(ev),
-					GoplsPath:    tag.GoplsPath.Get(ev),
-					ClientID:     tag.ClientID.Get(ev),
-				})
-			}
-			if s := cache.KeyShutdownSession.Get(ev); s != nil {
-				i.State.dropClient(s)
-			}
-			if sid := tag.EndServer.Get(ev); sid != "" {
-				i.State.dropServer(sid)
-			}
-			if s := cache.KeyUpdateSession.Get(ev); s != nil {
-				if c := i.State.Client(s.ID()); c != nil {
-					c.DebugAddress = tag.DebugAddress.Get(ev)
-					c.Logfile = tag.Logfile.Get(ev)
-					c.ServerID = tag.ServerID.Get(ev)
-					c.GoplsPath = tag.GoplsPath.Get(ev)
-				}
-			}
-		}
-		return ctx
-	}
-	// StdTrace must be above export.Spans below (by convention, export
-	// middleware applies its wrapped exporter last).
-	exporter = StdTrace(exporter)
-	metrics := metric.Config{}
-	registerMetrics(&metrics)
-	exporter = metrics.Exporter(exporter)
-	exporter = export.Spans(exporter)
-	exporter = export.Labels(exporter)
-	return exporter
-}
-
-type dataFunc func(*http.Request) interface{}
-
-func render(tmpl *template.Template, fun dataFunc) func(http.ResponseWriter, *http.Request) {
-	return func(w http.ResponseWriter, r *http.Request) {
-		var data interface{}
-		if fun != nil {
-			data = fun(r)
-		}
-		if err := tmpl.Execute(w, data); err != nil {
-			event.Error(context.Background(), "", err)
-			http.Error(w, err.Error(), http.StatusInternalServerError)
-		}
-	}
-}
-
-func commas(s string) string {
-	for i := len(s); i > 3; {
-		i -= 3
-		s = s[:i] + "," + s[i:]
-	}
-	return s
-}
-
-func fuint64(v uint64) string {
-	return commas(strconv.FormatUint(v, 10))
-}
-
-func fuint32(v uint32) string {
-	return commas(strconv.FormatUint(uint64(v), 10))
-}
-
-func fcontent(v []byte) string {
-	return string(v)
-}
-
-var BaseTemplate = template.Must(template.New("").Parse(`
-<html>
-<head>
-<title>{{template "title" .}}</title>
-<style>
-.profile-name{
-	display:inline-block;
-	width:6rem;
-}
-td.value {
-  text-align: right;
-}
-ul.events {
-	list-style-type: none;
-}
-
-</style>
-{{block "head" .}}{{end}}
-</head>
-<body>
-<a href="/">Main</a>
-<a href="/info">Info</a>
-<a href="/memory">Memory</a>
-<a href="/metrics">Metrics</a>
-<a href="/rpc">RPC</a>
-<a href="/trace">Trace</a>
-<hr>
-<h1>{{template "title" .}}</h1>
-{{block "body" .}}
-Unknown page
-{{end}}
-</body>
-</html>
-
-{{define "cachelink"}}<a href="/cache/{{.}}">Cache {{.}}</a>{{end}}
-{{define "clientlink"}}<a href="/client/{{.}}">Client {{.}}</a>{{end}}
-{{define "serverlink"}}<a href="/server/{{.}}">Server {{.}}</a>{{end}}
-{{define "sessionlink"}}<a href="/session/{{.}}">Session {{.}}</a>{{end}}
-{{define "viewlink"}}<a href="/view/{{.}}">View {{.}}</a>{{end}}
-{{define "filelink"}}<a href="/file/{{.Session}}/{{.FileIdentity.Hash}}">{{.FileIdentity.URI}}</a>{{end}}
-`)).Funcs(template.FuncMap{
-	"fuint64":  fuint64,
-	"fuint32":  fuint32,
-	"fcontent": fcontent,
-	"localAddress": func(s string) string {
-		// Try to translate loopback addresses to localhost, both for cosmetics and
-		// because unspecified ipv6 addresses can break links on Windows.
-		//
-		// TODO(rfindley): In the future, it would be better not to assume the
-		// server is running on localhost, and instead construct this address using
-		// the remote host.
-		host, port, err := net.SplitHostPort(s)
-		if err != nil {
-			return s
-		}
-		ip := net.ParseIP(host)
-		if ip == nil {
-			return s
-		}
-		if ip.IsLoopback() || ip.IsUnspecified() {
-			return "localhost:" + port
-		}
-		return s
-	},
-	"options": func(s *cache.Session) []sessionOption {
-		return showOptions(s.Options())
-	},
-})
-
-var MainTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}GoPls server information{{end}}
-{{define "body"}}
-<h2>Caches</h2>
-<ul>{{range .State.Caches}}<li>{{template "cachelink" .ID}}</li>{{end}}</ul>
-<h2>Sessions</h2>
-<ul>{{range .State.Sessions}}<li>{{template "sessionlink" .ID}} from {{template "cachelink" .Cache.ID}}</li>{{end}}</ul>
-<h2>Clients</h2>
-<ul>{{range .State.Clients}}<li>{{template "clientlink" .Session.ID}}</li>{{end}}</ul>
-<h2>Servers</h2>
-<ul>{{range .State.Servers}}<li>{{template "serverlink" .ID}}</li>{{end}}</ul>
-<h2>Bug reports</h2>
-<dl>{{range .State.Bugs}}<dt>{{.Key}}</dt><dd>{{.Description}}</dd>{{end}}</dl>
-{{end}}
-`))
-
-var InfoTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}GoPls version information{{end}}
-{{define "body"}}
-{{.}}
-{{end}}
-`))
-
-var MemoryTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}GoPls memory usage{{end}}
-{{define "head"}}<meta http-equiv="refresh" content="5">{{end}}
-{{define "body"}}
-<h2>Stats</h2>
-<table>
-<tr><td class="label">Allocated bytes</td><td class="value">{{fuint64 .HeapAlloc}}</td></tr>
-<tr><td class="label">Total allocated bytes</td><td class="value">{{fuint64 .TotalAlloc}}</td></tr>
-<tr><td class="label">System bytes</td><td class="value">{{fuint64 .Sys}}</td></tr>
-<tr><td class="label">Heap system bytes</td><td class="value">{{fuint64 .HeapSys}}</td></tr>
-<tr><td class="label">Malloc calls</td><td class="value">{{fuint64 .Mallocs}}</td></tr>
-<tr><td class="label">Frees</td><td class="value">{{fuint64 .Frees}}</td></tr>
-<tr><td class="label">Idle heap bytes</td><td class="value">{{fuint64 .HeapIdle}}</td></tr>
-<tr><td class="label">In use bytes</td><td class="value">{{fuint64 .HeapInuse}}</td></tr>
-<tr><td class="label">Released to system bytes</td><td class="value">{{fuint64 .HeapReleased}}</td></tr>
-<tr><td class="label">Heap object count</td><td class="value">{{fuint64 .HeapObjects}}</td></tr>
-<tr><td class="label">Stack in use bytes</td><td class="value">{{fuint64 .StackInuse}}</td></tr>
-<tr><td class="label">Stack from system bytes</td><td class="value">{{fuint64 .StackSys}}</td></tr>
-<tr><td class="label">Bucket hash bytes</td><td class="value">{{fuint64 .BuckHashSys}}</td></tr>
-<tr><td class="label">GC metadata bytes</td><td class="value">{{fuint64 .GCSys}}</td></tr>
-<tr><td class="label">Off heap bytes</td><td class="value">{{fuint64 .OtherSys}}</td></tr>
-</table>
-<h2>By size</h2>
-<table>
-<tr><th>Size</th><th>Mallocs</th><th>Frees</th></tr>
-{{range .BySize}}<tr><td class="value">{{fuint32 .Size}}</td><td class="value">{{fuint64 .Mallocs}}</td><td class="value">{{fuint64 .Frees}}</td></tr>{{end}}
-</table>
-{{end}}
-`))
-
-var DebugTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}GoPls Debug pages{{end}}
-{{define "body"}}
-<a href="/debug/pprof">Profiling</a>
-{{end}}
-`))
-
-var CacheTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}Cache {{.ID}}{{end}}
-{{define "body"}}
-<h2>memoize.Store entries</h2>
-<ul>{{range $k,$v := .MemStats}}<li>{{$k}} - {{$v}}</li>{{end}}</ul>
-<h2>Per-package usage - not accurate, for guidance only</h2>
-{{.PackageStats true}}
-{{end}}
-`))
-
-var ClientTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}Client {{.Session.ID}}{{end}}
-{{define "body"}}
-Using session: <b>{{template "sessionlink" .Session.ID}}</b><br>
-{{if .DebugAddress}}Debug this client at: <a href="http://{{localAddress .DebugAddress}}">{{localAddress .DebugAddress}}</a><br>{{end}}
-Logfile: {{.Logfile}}<br>
-Gopls Path: {{.GoplsPath}}<br>
-<h2>Diagnostics</h2>
-{{/*Service: []protocol.Server; each server has map[uri]fileReports;
-	each fileReport: map[diagnosticSoure]diagnosticReport
-	diagnosticSource is one of 5 source
-	diagnosticReport: snapshotID and map[hash]*source.Diagnostic
-	sourceDiagnostic: struct {
-		Range    protocol.Range
-		Message  string
-		Source   string
-		Code     string
-		CodeHref string
-		Severity protocol.DiagnosticSeverity
-		Tags     []protocol.DiagnosticTag
-
-		Related []RelatedInformation
-	}
-	RelatedInformation: struct {
-		URI     span.URI
-		Range   protocol.Range
-		Message string
-	}
-	*/}}
-<ul>{{range $k, $v := .Service.Diagnostics}}<li>{{$k}}:<ol>{{range $v}}<li>{{.}}</li>{{end}}</ol></li>{{end}}</ul>
-{{end}}
-`))
-
-var ServerTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}Server {{.ID}}{{end}}
-{{define "body"}}
-{{if .DebugAddress}}Debug this server at: <a href="http://{{localAddress .DebugAddress}}">{{localAddress .DebugAddress}}</a><br>{{end}}
-Logfile: {{.Logfile}}<br>
-Gopls Path: {{.GoplsPath}}<br>
-{{end}}
-`))
-
-var SessionTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}Session {{.ID}}{{end}}
-{{define "body"}}
-From: <b>{{template "cachelink" .Cache.ID}}</b><br>
-<h2>Views</h2>
-<ul>{{range .Views}}<li>{{.Name}} is {{template "viewlink" .ID}} in {{.Folder}}</li>{{end}}</ul>
-<h2>Overlays</h2>
-<ul>{{range .Overlays}}<li>{{template "filelink" .}}</li>{{end}}</ul>
-<h2>Options</h2>
-{{range options .}}
-<p><b>{{.Name}}</b> {{.Type}}</p>
-<p><i>default:</i> {{.Default}}</p>
-{{if ne .Default .Current}}<p><i>current:</i> {{.Current}}</p>{{end}}
-{{end}}
-{{end}}
-`))
-
-var ViewTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}View {{.ID}}{{end}}
-{{define "body"}}
-Name: <b>{{.Name}}</b><br>
-Folder: <b>{{.Folder}}</b><br>
-<h2>Environment</h2>
-<ul>{{range .Options.Env}}<li>{{.}}</li>{{end}}</ul>
-{{end}}
-`))
-
-var FileTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}Overlay {{.FileIdentity.Hash}}{{end}}
-{{define "body"}}
-{{with .}}
-	From: <b>{{template "sessionlink" .Session}}</b><br>
-	URI: <b>{{.URI}}</b><br>
-	Identifier: <b>{{.FileIdentity.Hash}}</b><br>
-	Version: <b>{{.Version}}</b><br>
-	Kind: <b>{{.Kind}}</b><br>
-{{end}}
-<h3>Contents</h3>
-<pre>{{fcontent .Read}}</pre>
-{{end}}
-`))
diff -urN a/gopls/internal/lsp/debug/trace.go b/gopls/internal/lsp/debug/trace.go
--- a/gopls/internal/lsp/debug/trace.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/debug/trace.go	1969-12-31 16:00:00
@@ -1,233 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package debug
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"html/template"
-	"net/http"
-	"runtime/trace"
-	"sort"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/core"
-	"golang.org/x/tools/internal/event/export"
-	"golang.org/x/tools/internal/event/label"
-)
-
-var TraceTmpl = template.Must(template.Must(BaseTemplate.Clone()).Parse(`
-{{define "title"}}Trace Information{{end}}
-{{define "body"}}
-	{{range .Traces}}<a href="/trace/{{.Name}}">{{.Name}}</a> last: {{.Last.Duration}}, longest: {{.Longest.Duration}}<br>{{end}}
-	{{if .Selected}}
-		<H2>{{.Selected.Name}}</H2>
-		{{if .Selected.Last}}<H3>Last</H3><ul>{{template "details" .Selected.Last}}</ul>{{end}}
-		{{if .Selected.Longest}}<H3>Longest</H3><ul>{{template "details" .Selected.Longest}}</ul>{{end}}
-	{{end}}
-{{end}}
-{{define "details"}}
-	<li>{{.Offset}} {{.Name}} {{.Duration}} {{.Tags}}</li>
-	{{if .Events}}<ul class=events>{{range .Events}}<li>{{.Offset}} {{.Tags}}</li>{{end}}</ul>{{end}}
-	{{if .Children}}<ul>{{range .Children}}{{template "details" .}}{{end}}</ul>{{end}}
-{{end}}
-`))
-
-type traces struct {
-	mu         sync.Mutex
-	sets       map[string]*traceSet
-	unfinished map[export.SpanContext]*traceData
-}
-
-type TraceResults struct { // exported for testing
-	Traces   []*traceSet
-	Selected *traceSet
-}
-
-type traceSet struct {
-	Name    string
-	Last    *traceData
-	Longest *traceData
-}
-
-type traceData struct {
-	TraceID  export.TraceID
-	SpanID   export.SpanID
-	ParentID export.SpanID
-	Name     string
-	Start    time.Time
-	Finish   time.Time
-	Offset   time.Duration
-	Duration time.Duration
-	Tags     string
-	Events   []traceEvent
-	Children []*traceData
-}
-
-type traceEvent struct {
-	Time   time.Time
-	Offset time.Duration
-	Tags   string
-}
-
-func StdTrace(exporter event.Exporter) event.Exporter {
-	return func(ctx context.Context, ev core.Event, lm label.Map) context.Context {
-		span := export.GetSpan(ctx)
-		if span == nil {
-			return exporter(ctx, ev, lm)
-		}
-		switch {
-		case event.IsStart(ev):
-			if span.ParentID.IsValid() {
-				region := trace.StartRegion(ctx, span.Name)
-				ctx = context.WithValue(ctx, traceKey, region)
-			} else {
-				var task *trace.Task
-				ctx, task = trace.NewTask(ctx, span.Name)
-				ctx = context.WithValue(ctx, traceKey, task)
-			}
-			// Log the start event as it may contain useful labels.
-			msg := formatEvent(ctx, ev, lm)
-			trace.Log(ctx, "start", msg)
-		case event.IsLog(ev):
-			category := ""
-			if event.IsError(ev) {
-				category = "error"
-			}
-			msg := formatEvent(ctx, ev, lm)
-			trace.Log(ctx, category, msg)
-		case event.IsEnd(ev):
-			if v := ctx.Value(traceKey); v != nil {
-				v.(interface{ End() }).End()
-			}
-		}
-		return exporter(ctx, ev, lm)
-	}
-}
-
-func formatEvent(ctx context.Context, ev core.Event, lm label.Map) string {
-	buf := &bytes.Buffer{}
-	p := export.Printer{}
-	p.WriteEvent(buf, ev, lm)
-	return buf.String()
-}
-
-func (t *traces) ProcessEvent(ctx context.Context, ev core.Event, lm label.Map) context.Context {
-	span := export.GetSpan(ctx)
-	if span == nil {
-		return ctx
-	}
-
-	switch {
-	case event.IsStart(ev):
-		// Just starting: add it to the unfinished map.
-		// Allocate before the critical section.
-		td := &traceData{
-			TraceID:  span.ID.TraceID,
-			SpanID:   span.ID.SpanID,
-			ParentID: span.ParentID,
-			Name:     span.Name,
-			Start:    span.Start().At(),
-			Tags:     renderLabels(span.Start()),
-		}
-
-		t.mu.Lock()
-		defer t.mu.Unlock()
-		if t.sets == nil {
-			t.sets = make(map[string]*traceSet)
-			t.unfinished = make(map[export.SpanContext]*traceData)
-		}
-		t.unfinished[span.ID] = td
-		// and wire up parents if we have them
-		if !span.ParentID.IsValid() {
-			return ctx
-		}
-		parentID := export.SpanContext{TraceID: span.ID.TraceID, SpanID: span.ParentID}
-		parent, found := t.unfinished[parentID]
-		if !found {
-			// trace had an invalid parent, so it cannot itself be valid
-			return ctx
-		}
-		parent.Children = append(parent.Children, td)
-
-	case event.IsEnd(ev):
-		// Finishing: must be already in the map.
-		// Allocate events before the critical section.
-		events := span.Events()
-		tdEvents := make([]traceEvent, len(events))
-		for i, event := range events {
-			tdEvents[i] = traceEvent{
-				Time: event.At(),
-				Tags: renderLabels(event),
-			}
-		}
-
-		t.mu.Lock()
-		defer t.mu.Unlock()
-		td, found := t.unfinished[span.ID]
-		if !found {
-			return ctx // if this happens we are in a bad place
-		}
-		delete(t.unfinished, span.ID)
-
-		td.Finish = span.Finish().At()
-		td.Duration = span.Finish().At().Sub(span.Start().At())
-		td.Events = tdEvents
-
-		set, ok := t.sets[span.Name]
-		if !ok {
-			set = &traceSet{Name: span.Name}
-			t.sets[span.Name] = set
-		}
-		set.Last = td
-		if set.Longest == nil || set.Last.Duration > set.Longest.Duration {
-			set.Longest = set.Last
-		}
-		if !td.ParentID.IsValid() {
-			fillOffsets(td, td.Start)
-		}
-	}
-	return ctx
-}
-
-func (t *traces) getData(req *http.Request) interface{} {
-	if len(t.sets) == 0 {
-		return nil
-	}
-	data := TraceResults{}
-	data.Traces = make([]*traceSet, 0, len(t.sets))
-	for _, set := range t.sets {
-		data.Traces = append(data.Traces, set)
-	}
-	sort.Slice(data.Traces, func(i, j int) bool { return data.Traces[i].Name < data.Traces[j].Name })
-	if bits := strings.SplitN(req.URL.Path, "/trace/", 2); len(bits) > 1 {
-		data.Selected = t.sets[bits[1]]
-	}
-	return data
-}
-
-func fillOffsets(td *traceData, start time.Time) {
-	td.Offset = td.Start.Sub(start)
-	for i := range td.Events {
-		td.Events[i].Offset = td.Events[i].Time.Sub(start)
-	}
-	for _, child := range td.Children {
-		fillOffsets(child, start)
-	}
-}
-
-func renderLabels(labels label.List) string {
-	buf := &bytes.Buffer{}
-	for index := 0; labels.Valid(index); index++ {
-		if l := labels.Label(index); l.Valid() {
-			fmt.Fprintf(buf, "%v ", l)
-		}
-	}
-	return buf.String()
-}
diff -urN a/gopls/internal/lsp/definition.go b/gopls/internal/lsp/definition.go
--- a/gopls/internal/lsp/definition.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/definition.go	1969-12-31 16:00:00
@@ -1,71 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-)
-
-func (s *Server) definition(ctx context.Context, params *protocol.DefinitionParams) ([]protocol.Location, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	if snapshot.View().FileKind(fh) == source.Tmpl {
-		return template.Definition(snapshot, fh, params.Position)
-	}
-	ident, err := source.Identifier(ctx, snapshot, fh, params.Position)
-	if err != nil {
-		return nil, err
-	}
-	if ident.IsImport() && !snapshot.View().Options().ImportShortcut.ShowDefinition() {
-		return nil, nil
-	}
-	var locations []protocol.Location
-	for _, ref := range ident.Declaration.MappedRange {
-		decRange, err := ref.Range()
-		if err != nil {
-			return nil, err
-		}
-
-		locations = append(locations, protocol.Location{
-			URI:   protocol.URIFromSpanURI(ref.URI()),
-			Range: decRange,
-		})
-	}
-
-	return locations, nil
-}
-
-func (s *Server) typeDefinition(ctx context.Context, params *protocol.TypeDefinitionParams) ([]protocol.Location, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	ident, err := source.Identifier(ctx, snapshot, fh, params.Position)
-	if err != nil {
-		return nil, err
-	}
-	if ident.Type.Object == nil {
-		return nil, fmt.Errorf("no type definition for %s", ident.Name)
-	}
-	identRange, err := ident.Type.Range()
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.Location{
-		{
-			URI:   protocol.URIFromSpanURI(ident.Type.URI()),
-			Range: identRange,
-		},
-	}, nil
-}
diff -urN a/gopls/internal/lsp/diagnostics.go b/gopls/internal/lsp/diagnostics.go
--- a/gopls/internal/lsp/diagnostics.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/diagnostics.go	1969-12-31 16:00:00
@@ -1,773 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"crypto/sha256"
-	"errors"
-	"fmt"
-	"os"
-	"path/filepath"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/sync/errgroup"
-	"golang.org/x/tools/gopls/internal/lsp/debug/log"
-	"golang.org/x/tools/gopls/internal/lsp/mod"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-	"golang.org/x/tools/gopls/internal/lsp/work"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// diagnosticSource differentiates different sources of diagnostics.
-type diagnosticSource int
-
-const (
-	modSource diagnosticSource = iota
-	gcDetailsSource
-	analysisSource
-	typeCheckSource
-	orphanedSource
-	workSource
-	modCheckUpgradesSource
-	modVulncheckSource
-)
-
-// A diagnosticReport holds results for a single diagnostic source.
-type diagnosticReport struct {
-	snapshotID    source.GlobalSnapshotID // global snapshot ID on which the report was computed
-	publishedHash string                  // last published hash for this (URI, source)
-	diags         map[string]*source.Diagnostic
-}
-
-// fileReports holds a collection of diagnostic reports for a single file, as
-// well as the hash of the last published set of diagnostics.
-type fileReports struct {
-	// publishedSnapshotID is the last snapshot ID for which we have "published"
-	// diagnostics (though the publishDiagnostics notification may not have
-	// actually been sent, if nothing changed).
-	//
-	// Specifically, publishedSnapshotID is updated to a later snapshot ID when
-	// we either:
-	//  (1) publish diagnostics for the file for a snapshot, or
-	//  (2) determine that published diagnostics are valid for a new snapshot.
-	//
-	// Notably publishedSnapshotID may not match the snapshot id on individual reports in
-	// the reports map:
-	// - we may have published partial diagnostics from only a subset of
-	//   diagnostic sources for which new results have been computed, or
-	// - we may have started computing reports for an even new snapshot, but not
-	//   yet published.
-	//
-	// This prevents gopls from publishing stale diagnostics.
-	publishedSnapshotID source.GlobalSnapshotID
-
-	// publishedHash is a hash of the latest diagnostics published for the file.
-	publishedHash string
-
-	// If set, mustPublish marks diagnostics as needing publication, independent
-	// of whether their publishedHash has changed.
-	mustPublish bool
-
-	// The last stored diagnostics for each diagnostic source.
-	reports map[diagnosticSource]diagnosticReport
-}
-
-func (d diagnosticSource) String() string {
-	switch d {
-	case modSource:
-		return "FromSource"
-	case gcDetailsSource:
-		return "FromGCDetails"
-	case analysisSource:
-		return "FromAnalysis"
-	case typeCheckSource:
-		return "FromTypeChecking"
-	case orphanedSource:
-		return "FromOrphans"
-	case workSource:
-		return "FromGoWork"
-	case modCheckUpgradesSource:
-		return "FromCheckForUpgrades"
-	case modVulncheckSource:
-		return "FromModVulncheck"
-	default:
-		return fmt.Sprintf("From?%d?", d)
-	}
-}
-
-// hashDiagnostics computes a hash to identify diags.
-func hashDiagnostics(diags ...*source.Diagnostic) string {
-	source.SortDiagnostics(diags)
-	h := sha256.New()
-	for _, d := range diags {
-		for _, t := range d.Tags {
-			fmt.Fprintf(h, "%s", t)
-		}
-		for _, r := range d.Related {
-			fmt.Fprintf(h, "%s%s%s", r.URI, r.Message, r.Range)
-		}
-		fmt.Fprintf(h, "%s%s%s%s", d.Message, d.Range, d.Severity, d.Source)
-	}
-	return fmt.Sprintf("%x", h.Sum(nil))
-}
-
-func (s *Server) diagnoseDetached(snapshot source.Snapshot) {
-	ctx := snapshot.BackgroundContext()
-	ctx = xcontext.Detach(ctx)
-	s.diagnose(ctx, snapshot, false)
-	s.publishDiagnostics(ctx, true, snapshot)
-}
-
-func (s *Server) diagnoseSnapshots(snapshots map[source.Snapshot][]span.URI, onDisk bool) {
-	var diagnosticWG sync.WaitGroup
-	for snapshot, uris := range snapshots {
-		diagnosticWG.Add(1)
-		go func(snapshot source.Snapshot, uris []span.URI) {
-			defer diagnosticWG.Done()
-			s.diagnoseSnapshot(snapshot, uris, onDisk)
-		}(snapshot, uris)
-	}
-	diagnosticWG.Wait()
-}
-
-func (s *Server) diagnoseSnapshot(snapshot source.Snapshot, changedURIs []span.URI, onDisk bool) {
-	ctx := snapshot.BackgroundContext()
-	ctx, done := event.Start(ctx, "Server.diagnoseSnapshot", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	delay := snapshot.View().Options().DiagnosticsDelay
-	if delay > 0 {
-		// 2-phase diagnostics.
-		//
-		// The first phase just parses and type-checks (but
-		// does not analyze) packages directly affected by
-		// file modifications.
-		//
-		// The second phase runs analysis on the entire snapshot,
-		// and is debounced by the configured delay.
-		s.diagnoseChangedFiles(ctx, snapshot, changedURIs, onDisk)
-		s.publishDiagnostics(ctx, false, snapshot)
-
-		// We debounce diagnostics separately for each view, using the snapshot
-		// local ID as logical ordering.
-		//
-		// TODO(rfindley): it would be cleaner to simply put the diagnostic
-		// debouncer on the view, and remove the "key" argument to debouncing.
-		if ok := <-s.diagDebouncer.debounce(snapshot.View().Name(), snapshot.SequenceID(), time.After(delay)); ok {
-			s.diagnose(ctx, snapshot, false)
-			s.publishDiagnostics(ctx, true, snapshot)
-		}
-		return
-	}
-
-	// Ignore possible workspace configuration warnings in the normal flow.
-	s.diagnose(ctx, snapshot, false)
-	s.publishDiagnostics(ctx, true, snapshot)
-}
-
-func (s *Server) diagnoseChangedFiles(ctx context.Context, snapshot source.Snapshot, uris []span.URI, onDisk bool) {
-	ctx, done := event.Start(ctx, "Server.diagnoseChangedFiles", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	// TODO(adonovan): safety: refactor so that group.Go is called
-	// in a second loop, so that if we should later add an early
-	// return to the first loop, we don't leak goroutines.
-	var group errgroup.Group
-	seen := make(map[*source.Metadata]bool)
-	for _, uri := range uris {
-		// If the change is only on-disk and the file is not open, don't
-		// directly request its package. It may not be a workspace package.
-		if onDisk && !snapshot.IsOpen(uri) {
-			continue
-		}
-		// If the file is not known to the snapshot (e.g., if it was deleted),
-		// don't diagnose it.
-		if snapshot.FindFile(uri) == nil {
-			continue
-		}
-
-		// Don't request type-checking for builtin.go: it's not a real package.
-		if snapshot.IsBuiltin(ctx, uri) {
-			continue
-		}
-
-		// Find all packages that include this file and diagnose them in parallel.
-		metas, err := snapshot.MetadataForFile(ctx, uri)
-		if err != nil {
-			// TODO(findleyr): we should probably do something with the error here,
-			// but as of now this can fail repeatedly if load fails, so can be too
-			// noisy to log (and we'll handle things later in the slow pass).
-			continue
-		}
-		for _, m := range metas {
-			if m.IsIntermediateTestVariant() {
-				continue
-			}
-			if !seen[m] {
-				seen[m] = true
-				m := m
-				group.Go(func() error {
-					s.diagnosePkg(ctx, snapshot, m, false)
-					return nil // error result is ignored
-				})
-			}
-		}
-	}
-	group.Wait() // ignore error
-}
-
-// diagnose is a helper function for running diagnostics with a given context.
-// Do not call it directly. forceAnalysis is only true for testing purposes.
-func (s *Server) diagnose(ctx context.Context, snapshot source.Snapshot, forceAnalysis bool) {
-	ctx, done := event.Start(ctx, "Server.diagnose", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	// Wait for a free diagnostics slot.
-	// TODO(adonovan): opt: shouldn't it be the analysis implementation's
-	// job to de-dup and limit resource consumption? In any case this
-	// this function spends most its time waiting for awaitLoaded, at
-	// least initially.
-	select {
-	case <-ctx.Done():
-		return
-	case s.diagnosticsSema <- struct{}{}:
-	}
-	defer func() {
-		<-s.diagnosticsSema
-	}()
-
-	// common code for dispatching diagnostics
-	store := func(dsource diagnosticSource, operation string, diagsByFileID map[source.VersionedFileIdentity][]*source.Diagnostic, err error, merge bool) {
-		if err != nil {
-			event.Error(ctx, "warning: while "+operation, err, source.SnapshotLabels(snapshot)...)
-		}
-		for id, diags := range diagsByFileID {
-			if id.URI == "" {
-				event.Error(ctx, "missing URI while "+operation, fmt.Errorf("empty URI"), tag.Directory.Of(snapshot.View().Folder().Filename()))
-				continue
-			}
-			s.storeDiagnostics(snapshot, id.URI, dsource, diags, merge)
-		}
-	}
-
-	// Diagnose go.mod upgrades.
-	upgradeReports, upgradeErr := mod.UpgradeDiagnostics(ctx, snapshot)
-	if ctx.Err() != nil {
-		log.Trace.Log(ctx, "diagnose cancelled")
-		return
-	}
-	store(modCheckUpgradesSource, "diagnosing go.mod upgrades", upgradeReports, upgradeErr, true)
-
-	// Diagnose go.work file.
-	workReports, workErr := work.Diagnostics(ctx, snapshot)
-	if ctx.Err() != nil {
-		log.Trace.Log(ctx, "diagnose cancelled")
-		return
-	}
-	store(workSource, "diagnosing go.work file", workReports, workErr, true)
-
-	// Diagnose go.mod file.
-	// (This step demands type checking of all active packages:
-	// the bottleneck in the startup sequence for a big workspace.)
-	modReports, modErr := mod.Diagnostics(ctx, snapshot)
-	if ctx.Err() != nil {
-		log.Trace.Log(ctx, "diagnose cancelled")
-		return
-	}
-	store(modSource, "diagnosing go.mod file", modReports, modErr, true)
-
-	// Diagnose vulnerabilities.
-	vulnReports, vulnErr := mod.VulnerabilityDiagnostics(ctx, snapshot)
-	if ctx.Err() != nil {
-		log.Trace.Log(ctx, "diagnose cancelled")
-		return
-	}
-	store(modVulncheckSource, "diagnosing vulnerabilities", vulnReports, vulnErr, false)
-
-	activeMetas, activeErr := snapshot.ActiveMetadata(ctx)
-	if s.shouldIgnoreError(ctx, snapshot, activeErr) {
-		return
-	}
-	criticalErr := snapshot.GetCriticalError(ctx)
-	if ctx.Err() != nil { // must check ctx after GetCriticalError
-		return
-	}
-
-	// Show the error as a progress error report so that it appears in the
-	// status bar. If a client doesn't support progress reports, the error
-	// will still be shown as a ShowMessage. If there is no error, any running
-	// error progress reports will be closed.
-	s.showCriticalErrorStatus(ctx, snapshot, criticalErr)
-
-	// Diagnose template (.tmpl) files.
-	for _, f := range snapshot.Templates() {
-		diags := template.Diagnose(f)
-		s.storeDiagnostics(snapshot, f.URI(), typeCheckSource, diags, true)
-	}
-
-	// If there are no workspace packages, there is nothing to diagnose and
-	// there are no orphaned files.
-	if len(activeMetas) == 0 {
-		return
-	}
-
-	// Run go/analysis diagnosis of packages in parallel.
-	// TODO(adonovan): opt: it may be more efficient to
-	// have diagnosePkg take a set of packages.
-	//
-	// TODO(adonovan): opt: since the new analysis driver does its
-	// own type checking, we could strength-reduce pkg to
-	// PackageID and get this step started as soon as the set of
-	// active package IDs are known, without waiting for them to load.
-	var (
-		wg   sync.WaitGroup
-		seen = map[span.URI]struct{}{}
-	)
-	for _, m := range activeMetas {
-		for _, uri := range m.CompiledGoFiles {
-			seen[uri] = struct{}{}
-		}
-
-		wg.Add(1)
-		go func(m *source.Metadata) {
-			defer wg.Done()
-			s.diagnosePkg(ctx, snapshot, m, forceAnalysis)
-		}(m)
-	}
-	wg.Wait()
-
-	// Orphaned files.
-	// Confirm that every opened file belongs to a package (if any exist in
-	// the workspace). Otherwise, add a diagnostic to the file.
-	for _, o := range s.session.Overlays() {
-		if _, ok := seen[o.URI()]; ok {
-			continue
-		}
-		diagnostic := s.checkForOrphanedFile(ctx, snapshot, o)
-		if diagnostic == nil {
-			continue
-		}
-		s.storeDiagnostics(snapshot, o.URI(), orphanedSource, []*source.Diagnostic{diagnostic}, true)
-	}
-}
-
-func (s *Server) diagnosePkg(ctx context.Context, snapshot source.Snapshot, m *source.Metadata, alwaysAnalyze bool) {
-	ctx, done := event.Start(ctx, "Server.diagnosePkg", append(source.SnapshotLabels(snapshot), tag.Package.Of(string(m.ID)))...)
-	defer done()
-	enableDiagnostics := false
-	includeAnalysis := alwaysAnalyze // only run analyses for packages with open files
-	for _, uri := range m.CompiledGoFiles {
-		enableDiagnostics = enableDiagnostics || !snapshot.IgnoredFile(uri)
-		includeAnalysis = includeAnalysis || snapshot.IsOpen(uri)
-	}
-	// Don't show any diagnostics on ignored files.
-	if !enableDiagnostics {
-		return
-	}
-
-	pkgs, err := snapshot.TypeCheck(ctx, source.TypecheckFull, m.ID)
-	if err != nil {
-		event.Error(ctx, "warning: typecheck failed", err, append(source.SnapshotLabels(snapshot), tag.Package.Of(string(m.ID)))...)
-		return
-	}
-	pkg := pkgs[0]
-
-	// Get diagnostics from analysis framework.
-	// This includes type-error analyzers, which suggest fixes to compiler errors.
-	var analysisDiags map[span.URI][]*source.Diagnostic
-	if includeAnalysis {
-		diags, err := source.Analyze(ctx, snapshot, m.ID, false)
-		if err != nil {
-			event.Error(ctx, "warning: analyzing package", err, append(source.SnapshotLabels(snapshot), tag.Package.Of(string(m.ID)))...)
-			return
-		}
-		analysisDiags = diags
-	}
-
-	// For each file, update the server's diagnostics state.
-	for _, cgf := range pkg.CompiledGoFiles() {
-		// builtin.go exists only for documentation purposes and
-		// is not valid Go code. Don't report distracting errors.
-		if snapshot.IsBuiltin(ctx, cgf.URI) {
-			continue
-		}
-		var tdiags, adiags []*source.Diagnostic
-		source.CombineDiagnostics(pkg, cgf.URI, analysisDiags, &tdiags, &adiags)
-		s.storeDiagnostics(snapshot, cgf.URI, typeCheckSource, tdiags, true)
-		s.storeDiagnostics(snapshot, cgf.URI, analysisSource, adiags, true)
-	}
-
-	// If gc optimization details are requested, add them to the
-	// diagnostic reports.
-	s.gcOptimizationDetailsMu.Lock()
-	_, enableGCDetails := s.gcOptimizationDetails[m.ID]
-	s.gcOptimizationDetailsMu.Unlock()
-	if enableGCDetails {
-		gcReports, err := source.GCOptimizationDetails(ctx, snapshot, m)
-		if err != nil {
-			event.Error(ctx, "warning: gc details", err, append(source.SnapshotLabels(snapshot), tag.Package.Of(string(m.ID)))...)
-		}
-		s.gcOptimizationDetailsMu.Lock()
-		_, enableGCDetails := s.gcOptimizationDetails[m.ID]
-
-		// NOTE(golang/go#44826): hold the gcOptimizationDetails lock, and re-check
-		// whether gc optimization details are enabled, while storing gc_details
-		// results. This ensures that the toggling of GC details and clearing of
-		// diagnostics does not race with storing the results here.
-		if enableGCDetails {
-			for id, diags := range gcReports {
-				fh := snapshot.FindFile(id.URI)
-				// Don't publish gc details for unsaved buffers, since the underlying
-				// logic operates on the file on disk.
-				if fh == nil || !fh.Saved() {
-					continue
-				}
-				s.storeDiagnostics(snapshot, id.URI, gcDetailsSource, diags, true)
-			}
-		}
-		s.gcOptimizationDetailsMu.Unlock()
-	}
-}
-
-// mustPublishDiagnostics marks the uri as needing publication, independent of
-// whether the published contents have changed.
-//
-// This can be used for ensuring gopls publishes diagnostics after certain file
-// events.
-func (s *Server) mustPublishDiagnostics(uri span.URI) {
-	s.diagnosticsMu.Lock()
-	defer s.diagnosticsMu.Unlock()
-
-	if s.diagnostics[uri] == nil {
-		s.diagnostics[uri] = &fileReports{
-			publishedHash: hashDiagnostics(), // Hash for 0 diagnostics.
-			reports:       map[diagnosticSource]diagnosticReport{},
-		}
-	}
-	s.diagnostics[uri].mustPublish = true
-}
-
-// storeDiagnostics stores results from a single diagnostic source. If merge is
-// true, it merges results into any existing results for this snapshot.
-//
-// TODO(hyangah): investigate whether we can unconditionally overwrite previous report.diags
-// with the new diags and eliminate the need for the `merge` flag.
-func (s *Server) storeDiagnostics(snapshot source.Snapshot, uri span.URI, dsource diagnosticSource, diags []*source.Diagnostic, merge bool) {
-	// Safeguard: ensure that the file actually exists in the snapshot
-	// (see golang.org/issues/38602).
-	fh := snapshot.FindFile(uri)
-	if fh == nil {
-		return
-	}
-
-	s.diagnosticsMu.Lock()
-	defer s.diagnosticsMu.Unlock()
-	if s.diagnostics[uri] == nil {
-		s.diagnostics[uri] = &fileReports{
-			publishedHash: hashDiagnostics(), // Hash for 0 diagnostics.
-			reports:       map[diagnosticSource]diagnosticReport{},
-		}
-	}
-	report := s.diagnostics[uri].reports[dsource]
-	// Don't set obsolete diagnostics.
-	if report.snapshotID > snapshot.GlobalID() {
-		return
-	}
-	if report.diags == nil || report.snapshotID != snapshot.GlobalID() || !merge {
-		report.diags = map[string]*source.Diagnostic{}
-	}
-	report.snapshotID = snapshot.GlobalID()
-	for _, d := range diags {
-		report.diags[hashDiagnostics(d)] = d
-	}
-	s.diagnostics[uri].reports[dsource] = report
-}
-
-// clearDiagnosticSource clears all diagnostics for a given source type. It is
-// necessary for cases where diagnostics have been invalidated by something
-// other than a snapshot change, for example when gc_details is toggled.
-func (s *Server) clearDiagnosticSource(dsource diagnosticSource) {
-	s.diagnosticsMu.Lock()
-	defer s.diagnosticsMu.Unlock()
-	for _, reports := range s.diagnostics {
-		delete(reports.reports, dsource)
-	}
-}
-
-const WorkspaceLoadFailure = "Error loading workspace"
-
-// showCriticalErrorStatus shows the error as a progress report.
-// If the error is nil, it clears any existing error progress report.
-func (s *Server) showCriticalErrorStatus(ctx context.Context, snapshot source.Snapshot, err *source.CriticalError) {
-	s.criticalErrorStatusMu.Lock()
-	defer s.criticalErrorStatusMu.Unlock()
-
-	// Remove all newlines so that the error message can be formatted in a
-	// status bar.
-	var errMsg string
-	if err != nil {
-		event.Error(ctx, "errors loading workspace", err.MainError, source.SnapshotLabels(snapshot)...)
-		for _, d := range err.Diagnostics {
-			s.storeDiagnostics(snapshot, d.URI, modSource, []*source.Diagnostic{d}, true)
-		}
-		errMsg = strings.ReplaceAll(err.MainError.Error(), "\n", " ")
-	}
-
-	if s.criticalErrorStatus == nil {
-		if errMsg != "" {
-			s.criticalErrorStatus = s.progress.Start(ctx, WorkspaceLoadFailure, errMsg, nil, nil)
-		}
-		return
-	}
-
-	// If an error is already shown to the user, update it or mark it as
-	// resolved.
-	if errMsg == "" {
-		s.criticalErrorStatus.End(ctx, "Done.")
-		s.criticalErrorStatus = nil
-	} else {
-		s.criticalErrorStatus.Report(ctx, errMsg, 0)
-	}
-}
-
-// checkForOrphanedFile checks that the given URIs can be mapped to packages.
-// If they cannot and the workspace is not otherwise unloaded, it also surfaces
-// a warning, suggesting that the user check the file for build tags.
-func (s *Server) checkForOrphanedFile(ctx context.Context, snapshot source.Snapshot, fh source.VersionedFileHandle) *source.Diagnostic {
-	// TODO(rfindley): this function may fail to produce a diagnostic for a
-	// variety of reasons, some of which should probably not be ignored. For
-	// example, should this function be tolerant of the case where fh does not
-	// exist, or does not have a package name?
-	//
-	// It would be better to panic or report a bug in several of the cases below,
-	// so that we can move toward guaranteeing we show the user a meaningful
-	// error whenever it makes sense.
-	if snapshot.View().FileKind(fh) != source.Go {
-		return nil
-	}
-	// builtin files won't have a package, but they are never orphaned.
-	if snapshot.IsBuiltin(ctx, fh.URI()) {
-		return nil
-	}
-
-	// This call has the effect of inserting fh into snapshot.files,
-	// where for better or worse (actually: just worse) it influences
-	// the sets of open, known, and orphaned files.
-	snapshot.GetFile(ctx, fh.URI())
-
-	metas, _ := snapshot.MetadataForFile(ctx, fh.URI())
-	if len(metas) > 0 || ctx.Err() != nil {
-		return nil // no package, or cancelled
-	}
-	// Inv: file does not belong to a package we know about.
-	pgf, err := snapshot.ParseGo(ctx, fh, source.ParseHeader)
-	if err != nil {
-		return nil
-	}
-	if !pgf.File.Name.Pos().IsValid() {
-		return nil
-	}
-	rng, err := pgf.Mapper.PosRange(pgf.File.Name.Pos(), pgf.File.Name.End())
-	if err != nil {
-		return nil
-	}
-	// If the file no longer has a name ending in .go, this diagnostic is wrong
-	if filepath.Ext(fh.URI().Filename()) != ".go" {
-		return nil
-	}
-	// TODO(rstambler): We should be able to parse the build tags in the
-	// file and show a more specific error message. For now, put the diagnostic
-	// on the package declaration.
-	return &source.Diagnostic{
-		URI:      fh.URI(),
-		Range:    rng,
-		Severity: protocol.SeverityWarning,
-		Source:   source.ListError,
-		Message: fmt.Sprintf(`No packages found for open file %s: %v.
-If this file contains build tags, try adding "-tags=<build tag>" to your gopls "buildFlags" configuration (see (https://github.com/golang/tools/blob/master/gopls/doc/settings.md#buildflags-string).
-Otherwise, see the troubleshooting guidelines for help investigating (https://github.com/golang/tools/blob/master/gopls/doc/troubleshooting.md).
-`, fh.URI().Filename(), err),
-	}
-}
-
-// publishDiagnostics collects and publishes any unpublished diagnostic reports.
-func (s *Server) publishDiagnostics(ctx context.Context, final bool, snapshot source.Snapshot) {
-	ctx, done := event.Start(ctx, "Server.publishDiagnostics", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	s.diagnosticsMu.Lock()
-	defer s.diagnosticsMu.Unlock()
-
-	for uri, r := range s.diagnostics {
-		// Global snapshot IDs are monotonic, so we use them to enforce an ordering
-		// for diagnostics.
-		//
-		// If we've already delivered diagnostics for a future snapshot for this
-		// file, do not deliver them. See golang/go#42837 for an example of why
-		// this is necessary.
-		//
-		// TODO(rfindley): even using a global snapshot ID, this mechanism is
-		// potentially racy: elsewhere in the code (e.g. invalidateContent) we
-		// allow for multiple views track a given file. In this case, we should
-		// either only report diagnostics for snapshots from the "best" view of a
-		// URI, or somehow merge diagnostics from multiple views.
-		if r.publishedSnapshotID > snapshot.GlobalID() {
-			continue
-		}
-
-		anyReportsChanged := false
-		reportHashes := map[diagnosticSource]string{}
-		var diags []*source.Diagnostic
-		for dsource, report := range r.reports {
-			if report.snapshotID != snapshot.GlobalID() {
-				continue
-			}
-			var reportDiags []*source.Diagnostic
-			for _, d := range report.diags {
-				diags = append(diags, d)
-				reportDiags = append(reportDiags, d)
-			}
-			hash := hashDiagnostics(reportDiags...)
-			if hash != report.publishedHash {
-				anyReportsChanged = true
-			}
-			reportHashes[dsource] = hash
-		}
-
-		if !final && !anyReportsChanged {
-			// Don't invalidate existing reports on the client if we haven't got any
-			// new information.
-			continue
-		}
-
-		source.SortDiagnostics(diags)
-		hash := hashDiagnostics(diags...)
-		if hash == r.publishedHash && !r.mustPublish {
-			// Update snapshotID to be the latest snapshot for which this diagnostic
-			// hash is valid.
-			r.publishedSnapshotID = snapshot.GlobalID()
-			continue
-		}
-		var version int32
-		if fh := snapshot.FindFile(uri); fh != nil { // file may have been deleted
-			version = fh.Version()
-		}
-		if err := s.client.PublishDiagnostics(ctx, &protocol.PublishDiagnosticsParams{
-			Diagnostics: toProtocolDiagnostics(diags),
-			URI:         protocol.URIFromSpanURI(uri),
-			Version:     version,
-		}); err == nil {
-			r.publishedHash = hash
-			r.mustPublish = false // diagnostics have been successfully published
-			r.publishedSnapshotID = snapshot.GlobalID()
-			for dsource, hash := range reportHashes {
-				report := r.reports[dsource]
-				report.publishedHash = hash
-				r.reports[dsource] = report
-			}
-		} else {
-			if ctx.Err() != nil {
-				// Publish may have failed due to a cancelled context.
-				log.Trace.Log(ctx, "publish cancelled")
-				return
-			}
-			event.Error(ctx, "publishReports: failed to deliver diagnostic", err, tag.URI.Of(uri))
-		}
-	}
-}
-
-func toProtocolDiagnostics(diagnostics []*source.Diagnostic) []protocol.Diagnostic {
-	reports := []protocol.Diagnostic{}
-	for _, diag := range diagnostics {
-		related := make([]protocol.DiagnosticRelatedInformation, 0, len(diag.Related))
-		for _, rel := range diag.Related {
-			related = append(related, protocol.DiagnosticRelatedInformation{
-				Location: protocol.Location{
-					URI:   protocol.URIFromSpanURI(rel.URI),
-					Range: rel.Range,
-				},
-				Message: rel.Message,
-			})
-		}
-		pdiag := protocol.Diagnostic{
-			// diag.Message might start with \n or \t
-			Message:            strings.TrimSpace(diag.Message),
-			Range:              diag.Range,
-			Severity:           diag.Severity,
-			Source:             string(diag.Source),
-			Tags:               diag.Tags,
-			RelatedInformation: related,
-		}
-		if diag.Code != "" {
-			pdiag.Code = diag.Code
-		}
-		if diag.CodeHref != "" {
-			pdiag.CodeDescription = &protocol.CodeDescription{Href: diag.CodeHref}
-		}
-		reports = append(reports, pdiag)
-	}
-	return reports
-}
-
-func (s *Server) shouldIgnoreError(ctx context.Context, snapshot source.Snapshot, err error) bool {
-	if err == nil { // if there is no error at all
-		return false
-	}
-	if errors.Is(err, context.Canceled) {
-		return true
-	}
-	// If the folder has no Go code in it, we shouldn't spam the user with a warning.
-	var hasGo bool
-	_ = filepath.Walk(snapshot.View().Folder().Filename(), func(path string, info os.FileInfo, err error) error {
-		if err != nil {
-			return err
-		}
-		if !strings.HasSuffix(info.Name(), ".go") {
-			return nil
-		}
-		hasGo = true
-		return errors.New("done")
-	})
-	return !hasGo
-}
-
-// Diagnostics formattedfor the debug server
-// (all the relevant fields of Server are private)
-// (The alternative is to export them)
-func (s *Server) Diagnostics() map[string][]string {
-	ans := make(map[string][]string)
-	s.diagnosticsMu.Lock()
-	defer s.diagnosticsMu.Unlock()
-	for k, v := range s.diagnostics {
-		fn := k.Filename()
-		for typ, d := range v.reports {
-			if len(d.diags) == 0 {
-				continue
-			}
-			for _, dx := range d.diags {
-				ans[fn] = append(ans[fn], auxStr(dx, d, typ))
-			}
-		}
-	}
-	return ans
-}
-
-func auxStr(v *source.Diagnostic, d diagnosticReport, typ diagnosticSource) string {
-	// Tags? RelatedInformation?
-	msg := fmt.Sprintf("(%s)%q(source:%q,code:%q,severity:%s,snapshot:%d,type:%s)",
-		v.Range, v.Message, v.Source, v.Code, v.Severity, d.snapshotID, typ)
-	for _, r := range v.Related {
-		msg += fmt.Sprintf(" [%s:%s,%q]", r.URI.Filename(), r.Range, r.Message)
-	}
-	return msg
-}
diff -urN a/gopls/internal/lsp/fake/client.go b/gopls/internal/lsp/fake/client.go
--- a/gopls/internal/lsp/fake/client.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/client.go	1969-12-31 16:00:00
@@ -1,133 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"context"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// ClientHooks are called to handle the corresponding client LSP method.
-type ClientHooks struct {
-	OnLogMessage             func(context.Context, *protocol.LogMessageParams) error
-	OnDiagnostics            func(context.Context, *protocol.PublishDiagnosticsParams) error
-	OnWorkDoneProgressCreate func(context.Context, *protocol.WorkDoneProgressCreateParams) error
-	OnProgress               func(context.Context, *protocol.ProgressParams) error
-	OnShowMessage            func(context.Context, *protocol.ShowMessageParams) error
-	OnShowMessageRequest     func(context.Context, *protocol.ShowMessageRequestParams) error
-	OnRegistration           func(context.Context, *protocol.RegistrationParams) error
-	OnUnregistration         func(context.Context, *protocol.UnregistrationParams) error
-}
-
-// Client is an adapter that converts an *Editor into an LSP Client. It mosly
-// delegates functionality to hooks that can be configured by tests.
-type Client struct {
-	editor *Editor
-	hooks  ClientHooks
-}
-
-func (c *Client) CodeLensRefresh(context.Context) error { return nil }
-
-func (c *Client) LogTrace(context.Context, *protocol.LogTraceParams) error { return nil }
-
-func (c *Client) ShowMessage(ctx context.Context, params *protocol.ShowMessageParams) error {
-	if c.hooks.OnShowMessage != nil {
-		return c.hooks.OnShowMessage(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) ShowMessageRequest(ctx context.Context, params *protocol.ShowMessageRequestParams) (*protocol.MessageActionItem, error) {
-	if c.hooks.OnShowMessageRequest != nil {
-		if err := c.hooks.OnShowMessageRequest(ctx, params); err != nil {
-			return nil, err
-		}
-	}
-	if len(params.Actions) == 0 || len(params.Actions) > 1 {
-		return nil, fmt.Errorf("fake editor cannot handle multiple action items")
-	}
-	return &params.Actions[0], nil
-}
-
-func (c *Client) LogMessage(ctx context.Context, params *protocol.LogMessageParams) error {
-	if c.hooks.OnLogMessage != nil {
-		return c.hooks.OnLogMessage(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) Event(ctx context.Context, event *interface{}) error {
-	return nil
-}
-
-func (c *Client) PublishDiagnostics(ctx context.Context, params *protocol.PublishDiagnosticsParams) error {
-	if c.hooks.OnDiagnostics != nil {
-		return c.hooks.OnDiagnostics(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) WorkspaceFolders(context.Context) ([]protocol.WorkspaceFolder, error) {
-	return []protocol.WorkspaceFolder{}, nil
-}
-
-func (c *Client) Configuration(_ context.Context, p *protocol.ParamConfiguration) ([]interface{}, error) {
-	results := make([]interface{}, len(p.Items))
-	for i, item := range p.Items {
-		if item.Section == "gopls" {
-			c.editor.mu.Lock()
-			results[i] = c.editor.settingsLocked()
-			c.editor.mu.Unlock()
-		}
-	}
-	return results, nil
-}
-
-func (c *Client) RegisterCapability(ctx context.Context, params *protocol.RegistrationParams) error {
-	if c.hooks.OnRegistration != nil {
-		return c.hooks.OnRegistration(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) UnregisterCapability(ctx context.Context, params *protocol.UnregistrationParams) error {
-	if c.hooks.OnUnregistration != nil {
-		return c.hooks.OnUnregistration(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) Progress(ctx context.Context, params *protocol.ProgressParams) error {
-	if c.hooks.OnProgress != nil {
-		return c.hooks.OnProgress(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) WorkDoneProgressCreate(ctx context.Context, params *protocol.WorkDoneProgressCreateParams) error {
-	if c.hooks.OnWorkDoneProgressCreate != nil {
-		return c.hooks.OnWorkDoneProgressCreate(ctx, params)
-	}
-	return nil
-}
-
-func (c *Client) ShowDocument(context.Context, *protocol.ShowDocumentParams) (*protocol.ShowDocumentResult, error) {
-	return nil, nil
-}
-
-// ApplyEdit applies edits sent from the server.
-func (c *Client) ApplyEdit(ctx context.Context, params *protocol.ApplyWorkspaceEditParams) (*protocol.ApplyWorkspaceEditResult, error) {
-	if len(params.Edit.Changes) != 0 {
-		return &protocol.ApplyWorkspaceEditResult{FailureReason: "Edit.Changes is unsupported"}, nil
-	}
-	for _, change := range params.Edit.DocumentChanges {
-		if err := c.editor.applyDocumentChange(ctx, change); err != nil {
-			return nil, err
-		}
-	}
-	return &protocol.ApplyWorkspaceEditResult{Applied: true}, nil
-}
diff -urN a/gopls/internal/lsp/fake/doc.go b/gopls/internal/lsp/fake/doc.go
--- a/gopls/internal/lsp/fake/doc.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/doc.go	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package fake provides fake implementations of a text editor, LSP client
-// plugin, and Sandbox environment for use in tests.
-//
-// The Editor type provides a high level API for text editor operations
-// (open/modify/save/close a buffer, jump to definition, etc.), and the Client
-// type exposes an LSP client for the editor that can be connected to a
-// language server. By default, the Editor and Client should be compliant with
-// the LSP spec: their intended use is to verify server compliance with the
-// spec in a variety of environment. Possible future enhancements of these
-// types may allow them to misbehave in configurable ways, but that is not
-// their primary use.
-//
-// The Sandbox type provides a facility for executing tests with a temporary
-// directory, module proxy, and GOPATH.
-package fake
diff -urN a/gopls/internal/lsp/fake/edit.go b/gopls/internal/lsp/fake/edit.go
--- a/gopls/internal/lsp/fake/edit.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/edit.go	1969-12-31 16:00:00
@@ -1,157 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"fmt"
-	"strings"
-	"unicode/utf8"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/diff"
-)
-
-// Pos represents a position in a text buffer.
-// Both Line and Column are 0-indexed.
-// Column counts runes.
-type Pos struct {
-	Line, Column int
-}
-
-func (p Pos) String() string {
-	return fmt.Sprintf("%v:%v", p.Line, p.Column)
-}
-
-// Range corresponds to protocol.Range, but uses the editor friend Pos
-// instead of UTF-16 oriented protocol.Position
-type Range struct {
-	Start Pos
-	End   Pos
-}
-
-func (p Pos) ToProtocolPosition() protocol.Position {
-	return protocol.Position{
-		Line:      uint32(p.Line),
-		Character: uint32(p.Column),
-	}
-}
-
-func fromProtocolPosition(pos protocol.Position) Pos {
-	return Pos{
-		Line:   int(pos.Line),
-		Column: int(pos.Character),
-	}
-}
-
-// Edit represents a single (contiguous) buffer edit.
-type Edit struct {
-	Start, End Pos
-	Text       string
-}
-
-// Location is the editor friendly equivalent of protocol.Location
-type Location struct {
-	Path  string
-	Range Range
-}
-
-// SymbolInformation is an editor friendly version of
-// protocol.SymbolInformation, with location information transformed to byte
-// offsets. Field names correspond to the protocol type.
-type SymbolInformation struct {
-	Name     string
-	Kind     protocol.SymbolKind
-	Location Location
-}
-
-// NewEdit creates an edit replacing all content between
-// (startLine, startColumn) and (endLine, endColumn) with text.
-func NewEdit(startLine, startColumn, endLine, endColumn int, text string) Edit {
-	return Edit{
-		Start: Pos{Line: startLine, Column: startColumn},
-		End:   Pos{Line: endLine, Column: endColumn},
-		Text:  text,
-	}
-}
-
-func (e Edit) toProtocolChangeEvent() protocol.TextDocumentContentChangeEvent {
-	return protocol.TextDocumentContentChangeEvent{
-		Range: &protocol.Range{
-			Start: e.Start.ToProtocolPosition(),
-			End:   e.End.ToProtocolPosition(),
-		},
-		Text: e.Text,
-	}
-}
-
-func fromProtocolTextEdit(textEdit protocol.TextEdit) Edit {
-	return Edit{
-		Start: fromProtocolPosition(textEdit.Range.Start),
-		End:   fromProtocolPosition(textEdit.Range.End),
-		Text:  textEdit.NewText,
-	}
-}
-
-// inText reports whether p is a valid position in the text buffer.
-func inText(p Pos, content []string) bool {
-	if p.Line < 0 || p.Line >= len(content) {
-		return false
-	}
-	// Note the strict right bound: the column indexes character _separators_,
-	// not characters.
-	if p.Column < 0 || p.Column > len([]rune(content[p.Line])) {
-		return false
-	}
-	return true
-}
-
-// applyEdits applies the edits to a file with the specified lines,
-// and returns a new slice containing the lines of the patched file.
-// It is a wrapper around diff.Apply; see that function for preconditions.
-func applyEdits(lines []string, edits []Edit) ([]string, error) {
-	src := strings.Join(lines, "\n")
-
-	// Build a table of byte offset of start of each line.
-	lineOffset := make([]int, len(lines)+1)
-	offset := 0
-	for i, line := range lines {
-		lineOffset[i] = offset
-		offset += len(line) + len("\n")
-	}
-	lineOffset[len(lines)] = offset // EOF
-
-	var badCol error
-	posToOffset := func(pos Pos) int {
-		offset := lineOffset[pos.Line]
-		// Convert pos.Column (runes) to a UTF-8 byte offset.
-		if pos.Line < len(lines) {
-			for i := 0; i < pos.Column; i++ {
-				r, sz := utf8.DecodeRuneInString(src[offset:])
-				if r == '\n' && badCol == nil {
-					badCol = fmt.Errorf("bad column")
-				}
-				offset += sz
-			}
-		}
-		return offset
-	}
-
-	// Convert fake.Edits to diff.Edits
-	diffEdits := make([]diff.Edit, len(edits))
-	for i, edit := range edits {
-		diffEdits[i] = diff.Edit{
-			Start: posToOffset(edit.Start),
-			End:   posToOffset(edit.End),
-			New:   edit.Text,
-		}
-	}
-
-	patched, err := diff.Apply(src, diffEdits)
-	if err != nil {
-		return nil, err
-	}
-
-	return strings.Split(patched, "\n"), badCol
-}
diff -urN a/gopls/internal/lsp/fake/edit_test.go b/gopls/internal/lsp/fake/edit_test.go
--- a/gopls/internal/lsp/fake/edit_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/edit_test.go	1969-12-31 16:00:00
@@ -1,97 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"strings"
-	"testing"
-)
-
-func TestApplyEdits(t *testing.T) {
-	tests := []struct {
-		label   string
-		content string
-		edits   []Edit
-		want    string
-		wantErr bool
-	}{
-		{
-			label: "empty content",
-		},
-		{
-			label:   "empty edit",
-			content: "hello",
-			edits:   []Edit{},
-			want:    "hello",
-		},
-		{
-			label:   "unicode edit",
-			content: "hello, 日本語",
-			edits: []Edit{{
-				Start: Pos{Line: 0, Column: 7},
-				End:   Pos{Line: 0, Column: 10},
-				Text:  "world",
-			}},
-			want: "hello, world",
-		},
-		{
-			label:   "range edit",
-			content: "ABC\nDEF\nGHI\nJKL",
-			edits: []Edit{{
-				Start: Pos{Line: 1, Column: 1},
-				End:   Pos{Line: 2, Column: 3},
-				Text:  "12\n345",
-			}},
-			want: "ABC\nD12\n345\nJKL",
-		},
-		{
-			label:   "end before start",
-			content: "ABC\nDEF\nGHI\nJKL",
-			edits: []Edit{{
-				End:   Pos{Line: 1, Column: 1},
-				Start: Pos{Line: 2, Column: 3},
-				Text:  "12\n345",
-			}},
-			wantErr: true,
-		},
-		{
-			label:   "out of bounds line",
-			content: "ABC\nDEF\nGHI\nJKL",
-			edits: []Edit{{
-				Start: Pos{Line: 1, Column: 1},
-				End:   Pos{Line: 4, Column: 3},
-				Text:  "12\n345",
-			}},
-			wantErr: true,
-		},
-		{
-			label:   "out of bounds column",
-			content: "ABC\nDEF\nGHI\nJKL",
-			edits: []Edit{{
-				Start: Pos{Line: 1, Column: 4},
-				End:   Pos{Line: 2, Column: 3},
-				Text:  "12\n345",
-			}},
-			wantErr: true,
-		},
-	}
-
-	for _, test := range tests {
-		test := test
-		t.Run(test.label, func(t *testing.T) {
-			lines := strings.Split(test.content, "\n")
-			newLines, err := applyEdits(lines, test.edits)
-			if (err != nil) != test.wantErr {
-				t.Errorf("got err %v, want error: %t", err, test.wantErr)
-			}
-			if err != nil {
-				return
-			}
-			if got := strings.Join(newLines, "\n"); got != test.want {
-				t.Errorf("got %q, want %q", got, test.want)
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/fake/editor.go b/gopls/internal/lsp/fake/editor.go
--- a/gopls/internal/lsp/fake/editor.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/editor.go	1969-12-31 16:00:00
@@ -1,1484 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"bufio"
-	"context"
-	"errors"
-	"fmt"
-	"os"
-	"path"
-	"path/filepath"
-	"regexp"
-	"strings"
-	"sync"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// Editor is a fake editor client.  It keeps track of client state and can be
-// used for writing LSP tests.
-type Editor struct {
-
-	// Server, client, and sandbox are concurrency safe and written only
-	// at construction time, so do not require synchronization.
-	Server     protocol.Server
-	cancelConn func()
-	serverConn jsonrpc2.Conn
-	client     *Client
-	sandbox    *Sandbox
-	defaultEnv map[string]string
-
-	mu                 sync.Mutex                  // guards config, buffers, serverCapabilities
-	config             EditorConfig                // editor configuration
-	buffers            map[string]buffer           // open buffers (relative path -> buffer content)
-	serverCapabilities protocol.ServerCapabilities // capabilities / options
-
-	// Call metrics for the purpose of expectations. This is done in an ad-hoc
-	// manner for now. Perhaps in the future we should do something more
-	// systematic. Guarded with a separate mutex as calls may need to be accessed
-	// asynchronously via callbacks into the Editor.
-	callsMu sync.Mutex
-	calls   CallCounts
-}
-
-// CallCounts tracks the number of protocol notifications of different types.
-type CallCounts struct {
-	DidOpen, DidChange, DidSave, DidChangeWatchedFiles, DidClose uint64
-}
-
-// buffer holds information about an open buffer in the editor.
-type buffer struct {
-	windowsLineEndings bool     // use windows line endings when merging lines
-	version            int      // monotonic version; incremented on edits
-	path               string   // relative path in the workspace
-	lines              []string // line content
-	dirty              bool     // if true, content is unsaved (TODO(rfindley): rename this field)
-}
-
-func (b buffer) text() string {
-	eol := "\n"
-	if b.windowsLineEndings {
-		eol = "\r\n"
-	}
-	return strings.Join(b.lines, eol)
-}
-
-// EditorConfig configures the editor's LSP session. This is similar to
-// source.UserOptions, but we use a separate type here so that we expose only
-// that configuration which we support.
-//
-// The zero value for EditorConfig should correspond to its defaults.
-type EditorConfig struct {
-	// Env holds environment variables to apply on top of the default editor
-	// environment. When applying these variables, the special string
-	// $SANDBOX_WORKDIR is replaced by the absolute path to the sandbox working
-	// directory.
-	Env map[string]string
-
-	// WorkspaceFolders is the workspace folders to configure on the LSP server,
-	// relative to the sandbox workdir.
-	//
-	// As a special case, if WorkspaceFolders is nil the editor defaults to
-	// configuring a single workspace folder corresponding to the workdir root.
-	// To explicitly send no workspace folders, use an empty (non-nil) slice.
-	WorkspaceFolders []string
-
-	// Whether to edit files with windows line endings.
-	WindowsLineEndings bool
-
-	// Map of language ID -> regexp to match, used to set the file type of new
-	// buffers. Applied as an overlay on top of the following defaults:
-	//  "go" -> ".*\.go"
-	//  "go.mod" -> "go\.mod"
-	//  "go.sum" -> "go\.sum"
-	//  "gotmpl" -> ".*tmpl"
-	FileAssociations map[string]string
-
-	// Settings holds user-provided configuration for the LSP server.
-	Settings map[string]interface{}
-}
-
-// NewEditor Creates a new Editor.
-func NewEditor(sandbox *Sandbox, config EditorConfig) *Editor {
-	return &Editor{
-		buffers:    make(map[string]buffer),
-		sandbox:    sandbox,
-		defaultEnv: sandbox.GoEnv(),
-		config:     config,
-	}
-}
-
-// Connect configures the editor to communicate with an LSP server on conn. It
-// is not concurrency safe, and should be called at most once, before using the
-// editor.
-//
-// It returns the editor, so that it may be called as follows:
-//
-//	editor, err := NewEditor(s).Connect(ctx, conn, hooks)
-func (e *Editor) Connect(ctx context.Context, connector servertest.Connector, hooks ClientHooks) (*Editor, error) {
-	bgCtx, cancelConn := context.WithCancel(xcontext.Detach(ctx))
-	conn := connector.Connect(bgCtx)
-	e.cancelConn = cancelConn
-
-	e.serverConn = conn
-	e.Server = protocol.ServerDispatcher(conn)
-	e.client = &Client{editor: e, hooks: hooks}
-	conn.Go(bgCtx,
-		protocol.Handlers(
-			protocol.ClientHandler(e.client,
-				jsonrpc2.MethodNotFound)))
-
-	if err := e.initialize(ctx); err != nil {
-		return nil, err
-	}
-	e.sandbox.Workdir.AddWatcher(e.onFileChanges)
-	return e, nil
-}
-
-func (e *Editor) Stats() CallCounts {
-	e.callsMu.Lock()
-	defer e.callsMu.Unlock()
-	return e.calls
-}
-
-// Shutdown issues the 'shutdown' LSP notification.
-func (e *Editor) Shutdown(ctx context.Context) error {
-	if e.Server != nil {
-		if err := e.Server.Shutdown(ctx); err != nil {
-			return fmt.Errorf("Shutdown: %w", err)
-		}
-	}
-	return nil
-}
-
-// Exit issues the 'exit' LSP notification.
-func (e *Editor) Exit(ctx context.Context) error {
-	if e.Server != nil {
-		// Not all LSP clients issue the exit RPC, but we do so here to ensure that
-		// we gracefully handle it on multi-session servers.
-		if err := e.Server.Exit(ctx); err != nil {
-			return fmt.Errorf("Exit: %w", err)
-		}
-	}
-	return nil
-}
-
-// Close issues the shutdown and exit sequence an editor should.
-func (e *Editor) Close(ctx context.Context) error {
-	if err := e.Shutdown(ctx); err != nil {
-		return err
-	}
-	if err := e.Exit(ctx); err != nil {
-		return err
-	}
-	defer func() {
-		e.cancelConn()
-	}()
-
-	// called close on the editor should result in the connection closing
-	select {
-	case <-e.serverConn.Done():
-		// connection closed itself
-		return nil
-	case <-ctx.Done():
-		return fmt.Errorf("connection not closed: %w", ctx.Err())
-	}
-}
-
-// Client returns the LSP client for this editor.
-func (e *Editor) Client() *Client {
-	return e.client
-}
-
-// settingsLocked builds the settings map for use in LSP settings RPCs.
-//
-// e.mu must be held while calling this function.
-func (e *Editor) settingsLocked() map[string]interface{} {
-	env := make(map[string]string)
-	for k, v := range e.defaultEnv {
-		env[k] = v
-	}
-	for k, v := range e.config.Env {
-		env[k] = v
-	}
-	for k, v := range env {
-		v = strings.ReplaceAll(v, "$SANDBOX_WORKDIR", e.sandbox.Workdir.RootURI().SpanURI().Filename())
-		env[k] = v
-	}
-
-	settings := map[string]interface{}{
-		"env": env,
-
-		// Use verbose progress reporting so that regtests can assert on
-		// asynchronous operations being completed (such as diagnosing a snapshot).
-		"verboseWorkDoneProgress": true,
-
-		// Set a generous completion budget, so that tests don't flake because
-		// completions are too slow.
-		"completionBudget": "10s",
-
-		// Shorten the diagnostic delay to speed up test execution (else we'd add
-		// the default delay to each assertion about diagnostics)
-		"diagnosticsDelay": "10ms",
-	}
-
-	for k, v := range e.config.Settings {
-		if k == "env" {
-			panic("must not provide env via the EditorConfig.Settings field: use the EditorConfig.Env field instead")
-		}
-		settings[k] = v
-	}
-
-	return settings
-}
-
-func (e *Editor) initialize(ctx context.Context) error {
-	params := &protocol.ParamInitialize{}
-	params.ClientInfo.Name = "fakeclient"
-	params.ClientInfo.Version = "v1.0.0"
-	e.mu.Lock()
-	params.WorkspaceFolders = e.makeWorkspaceFoldersLocked()
-	params.InitializationOptions = e.settingsLocked()
-	e.mu.Unlock()
-	params.Capabilities.Workspace.Configuration = true
-	params.Capabilities.Window.WorkDoneProgress = true
-
-	// TODO: set client capabilities
-	params.Capabilities.TextDocument.Completion.CompletionItem.TagSupport.ValueSet = []protocol.CompletionItemTag{protocol.ComplDeprecated}
-
-	params.Capabilities.TextDocument.Completion.CompletionItem.SnippetSupport = true
-	params.Capabilities.TextDocument.SemanticTokens.Requests.Full = true
-	// copied from lsp/semantic.go to avoid import cycle in tests
-	params.Capabilities.TextDocument.SemanticTokens.TokenTypes = []string{
-		"namespace", "type", "class", "enum", "interface",
-		"struct", "typeParameter", "parameter", "variable", "property", "enumMember",
-		"event", "function", "method", "macro", "keyword", "modifier", "comment",
-		"string", "number", "regexp", "operator",
-	}
-	params.Capabilities.TextDocument.SemanticTokens.TokenModifiers = []string{
-		"declaration", "definition", "readonly", "static",
-		"deprecated", "abstract", "async", "modification", "documentation", "defaultLibrary",
-	}
-
-	// This is a bit of a hack, since the fake editor doesn't actually support
-	// watching changed files that match a specific glob pattern. However, the
-	// editor does send didChangeWatchedFiles notifications, so set this to
-	// true.
-	params.Capabilities.Workspace.DidChangeWatchedFiles.DynamicRegistration = true
-	params.Capabilities.Workspace.WorkspaceEdit = &protocol.WorkspaceEditClientCapabilities{
-		ResourceOperations: []protocol.ResourceOperationKind{
-			"rename",
-		},
-	}
-
-	params.Trace = "messages"
-	// TODO: support workspace folders.
-	if e.Server != nil {
-		resp, err := e.Server.Initialize(ctx, params)
-		if err != nil {
-			return fmt.Errorf("initialize: %w", err)
-		}
-		e.mu.Lock()
-		e.serverCapabilities = resp.Capabilities
-		e.mu.Unlock()
-
-		if err := e.Server.Initialized(ctx, &protocol.InitializedParams{}); err != nil {
-			return fmt.Errorf("initialized: %w", err)
-		}
-	}
-	// TODO: await initial configuration here, or expect gopls to manage that?
-	return nil
-}
-
-// makeWorkspaceFoldersLocked creates a slice of workspace folders to use for
-// this editing session, based on the editor configuration.
-//
-// e.mu must be held while calling this function.
-func (e *Editor) makeWorkspaceFoldersLocked() (folders []protocol.WorkspaceFolder) {
-	paths := e.config.WorkspaceFolders
-	if len(paths) == 0 {
-		paths = append(paths, string(e.sandbox.Workdir.RelativeTo))
-	}
-
-	for _, path := range paths {
-		uri := string(e.sandbox.Workdir.URI(path))
-		folders = append(folders, protocol.WorkspaceFolder{
-			URI:  uri,
-			Name: filepath.Base(uri),
-		})
-	}
-
-	return folders
-}
-
-// onFileChanges is registered to be called by the Workdir on any writes that
-// go through the Workdir API. It is called synchronously by the Workdir.
-func (e *Editor) onFileChanges(ctx context.Context, evts []protocol.FileEvent) {
-	if e.Server == nil {
-		return
-	}
-
-	// e may be locked when onFileChanges is called, but it is important that we
-	// synchronously increment this counter so that we can subsequently assert on
-	// the number of expected DidChangeWatchedFiles calls.
-	e.callsMu.Lock()
-	e.calls.DidChangeWatchedFiles++
-	e.callsMu.Unlock()
-
-	// Since e may be locked, we must run this mutation asynchronously.
-	go func() {
-		e.mu.Lock()
-		defer e.mu.Unlock()
-		for _, evt := range evts {
-			// Always send an on-disk change, even for events that seem useless
-			// because they're shadowed by an open buffer.
-			path := e.sandbox.Workdir.URIToPath(evt.URI)
-			if buf, ok := e.buffers[path]; ok {
-				// Following VS Code, don't honor deletions or changes to dirty buffers.
-				if buf.dirty || evt.Type == protocol.Deleted {
-					continue
-				}
-
-				content, err := e.sandbox.Workdir.ReadFile(path)
-				if err != nil {
-					continue // A race with some other operation.
-				}
-				// No need to update if the buffer content hasn't changed.
-				if content == buf.text() {
-					continue
-				}
-				// During shutdown, this call will fail. Ignore the error.
-				_ = e.setBufferContentLocked(ctx, path, false, lines(content), nil)
-			}
-		}
-		e.Server.DidChangeWatchedFiles(ctx, &protocol.DidChangeWatchedFilesParams{
-			Changes: evts,
-		})
-	}()
-}
-
-// OpenFile creates a buffer for the given workdir-relative file.
-//
-// If the file is already open, it is a no-op.
-func (e *Editor) OpenFile(ctx context.Context, path string) error {
-	if e.HasBuffer(path) {
-		return nil
-	}
-	content, err := e.sandbox.Workdir.ReadFile(path)
-	if err != nil {
-		return err
-	}
-	return e.createBuffer(ctx, path, false, content)
-}
-
-// CreateBuffer creates a new unsaved buffer corresponding to the workdir path,
-// containing the given textual content.
-func (e *Editor) CreateBuffer(ctx context.Context, path, content string) error {
-	return e.createBuffer(ctx, path, true, content)
-}
-
-func (e *Editor) createBuffer(ctx context.Context, path string, dirty bool, content string) error {
-	e.mu.Lock()
-
-	if _, ok := e.buffers[path]; ok {
-		e.mu.Unlock()
-		return fmt.Errorf("buffer %q already exists", path)
-	}
-
-	buf := buffer{
-		windowsLineEndings: e.config.WindowsLineEndings,
-		version:            1,
-		path:               path,
-		lines:              lines(content),
-		dirty:              dirty,
-	}
-	e.buffers[path] = buf
-
-	item := e.textDocumentItem(buf)
-	e.mu.Unlock()
-
-	return e.sendDidOpen(ctx, item)
-}
-
-// textDocumentItem builds a protocol.TextDocumentItem for the given buffer.
-//
-// Precondition: e.mu must be held.
-func (e *Editor) textDocumentItem(buf buffer) protocol.TextDocumentItem {
-	return protocol.TextDocumentItem{
-		URI:        e.sandbox.Workdir.URI(buf.path),
-		LanguageID: languageID(buf.path, e.config.FileAssociations),
-		Version:    int32(buf.version),
-		Text:       buf.text(),
-	}
-}
-
-func (e *Editor) sendDidOpen(ctx context.Context, item protocol.TextDocumentItem) error {
-	if e.Server != nil {
-		if err := e.Server.DidOpen(ctx, &protocol.DidOpenTextDocumentParams{
-			TextDocument: item,
-		}); err != nil {
-			return fmt.Errorf("DidOpen: %w", err)
-		}
-		e.callsMu.Lock()
-		e.calls.DidOpen++
-		e.callsMu.Unlock()
-	}
-	return nil
-}
-
-var defaultFileAssociations = map[string]*regexp.Regexp{
-	"go":      regexp.MustCompile(`^.*\.go$`), // '$' is important: don't match .gotmpl!
-	"go.mod":  regexp.MustCompile(`^go\.mod$`),
-	"go.sum":  regexp.MustCompile(`^go(\.work)?\.sum$`),
-	"go.work": regexp.MustCompile(`^go\.work$`),
-	"gotmpl":  regexp.MustCompile(`^.*tmpl$`),
-}
-
-// languageID returns the language identifier for the path p given the user
-// configured fileAssociations.
-func languageID(p string, fileAssociations map[string]string) string {
-	base := path.Base(p)
-	for lang, re := range fileAssociations {
-		re := regexp.MustCompile(re)
-		if re.MatchString(base) {
-			return lang
-		}
-	}
-	for lang, re := range defaultFileAssociations {
-		if re.MatchString(base) {
-			return lang
-		}
-	}
-	return ""
-}
-
-// lines returns line-ending agnostic line representation of content.
-func lines(content string) []string {
-	lines := strings.Split(content, "\n")
-	for i, l := range lines {
-		lines[i] = strings.TrimSuffix(l, "\r")
-	}
-	return lines
-}
-
-// CloseBuffer removes the current buffer (regardless of whether it is saved).
-func (e *Editor) CloseBuffer(ctx context.Context, path string) error {
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	if !ok {
-		e.mu.Unlock()
-		return ErrUnknownBuffer
-	}
-	delete(e.buffers, path)
-	e.mu.Unlock()
-
-	return e.sendDidClose(ctx, e.TextDocumentIdentifier(path))
-}
-
-func (e *Editor) sendDidClose(ctx context.Context, doc protocol.TextDocumentIdentifier) error {
-	if e.Server != nil {
-		if err := e.Server.DidClose(ctx, &protocol.DidCloseTextDocumentParams{
-			TextDocument: doc,
-		}); err != nil {
-			return fmt.Errorf("DidClose: %w", err)
-		}
-		e.callsMu.Lock()
-		e.calls.DidClose++
-		e.callsMu.Unlock()
-	}
-	return nil
-}
-
-func (e *Editor) TextDocumentIdentifier(path string) protocol.TextDocumentIdentifier {
-	return protocol.TextDocumentIdentifier{
-		URI: e.sandbox.Workdir.URI(path),
-	}
-}
-
-// SaveBuffer writes the content of the buffer specified by the given path to
-// the filesystem.
-func (e *Editor) SaveBuffer(ctx context.Context, path string) error {
-	if err := e.OrganizeImports(ctx, path); err != nil {
-		return fmt.Errorf("organizing imports before save: %w", err)
-	}
-	if err := e.FormatBuffer(ctx, path); err != nil {
-		return fmt.Errorf("formatting before save: %w", err)
-	}
-	return e.SaveBufferWithoutActions(ctx, path)
-}
-
-func (e *Editor) SaveBufferWithoutActions(ctx context.Context, path string) error {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	buf, ok := e.buffers[path]
-	if !ok {
-		return fmt.Errorf(fmt.Sprintf("unknown buffer: %q", path))
-	}
-	content := buf.text()
-	includeText := false
-	syncOptions, ok := e.serverCapabilities.TextDocumentSync.(protocol.TextDocumentSyncOptions)
-	if ok {
-		includeText = syncOptions.Save.IncludeText
-	}
-
-	docID := e.TextDocumentIdentifier(buf.path)
-	if e.Server != nil {
-		if err := e.Server.WillSave(ctx, &protocol.WillSaveTextDocumentParams{
-			TextDocument: docID,
-			Reason:       protocol.Manual,
-		}); err != nil {
-			return fmt.Errorf("WillSave: %w", err)
-		}
-	}
-	if err := e.sandbox.Workdir.WriteFile(ctx, path, content); err != nil {
-		return fmt.Errorf("writing %q: %w", path, err)
-	}
-
-	buf.dirty = false
-	e.buffers[path] = buf
-
-	if e.Server != nil {
-		params := &protocol.DidSaveTextDocumentParams{
-			TextDocument: docID,
-		}
-		if includeText {
-			params.Text = &content
-		}
-		if err := e.Server.DidSave(ctx, params); err != nil {
-			return fmt.Errorf("DidSave: %w", err)
-		}
-		e.callsMu.Lock()
-		e.calls.DidSave++
-		e.callsMu.Unlock()
-	}
-	return nil
-}
-
-// contentPosition returns the (Line, Column) position corresponding to offset
-// in the buffer referenced by path.
-func contentPosition(content string, offset int) (Pos, error) {
-	scanner := bufio.NewScanner(strings.NewReader(content))
-	start := 0
-	line := 0
-	for scanner.Scan() {
-		end := start + len([]rune(scanner.Text())) + 1
-		if offset < end {
-			return Pos{Line: line, Column: offset - start}, nil
-		}
-		start = end
-		line++
-	}
-	if err := scanner.Err(); err != nil {
-		return Pos{}, fmt.Errorf("scanning content: %w", err)
-	}
-	// Scan() will drop the last line if it is empty. Correct for this.
-	if (strings.HasSuffix(content, "\n") || content == "") && offset == start {
-		return Pos{Line: line, Column: 0}, nil
-	}
-	return Pos{}, fmt.Errorf("position %d out of bounds in %q (line = %d, start = %d)", offset, content, line, start)
-}
-
-// ErrNoMatch is returned if a regexp search fails.
-var (
-	ErrNoMatch       = errors.New("no match")
-	ErrUnknownBuffer = errors.New("unknown buffer")
-)
-
-// regexpRange returns the start and end of the first occurrence of either re
-// or its singular subgroup. It returns ErrNoMatch if the regexp doesn't match.
-func regexpRange(content, re string) (Pos, Pos, error) {
-	content = normalizeEOL(content)
-	var start, end int
-	rec, err := regexp.Compile(re)
-	if err != nil {
-		return Pos{}, Pos{}, err
-	}
-	indexes := rec.FindStringSubmatchIndex(content)
-	if indexes == nil {
-		return Pos{}, Pos{}, ErrNoMatch
-	}
-	switch len(indexes) {
-	case 2:
-		// no subgroups: return the range of the regexp expression
-		start, end = indexes[0], indexes[1]
-	case 4:
-		// one subgroup: return its range
-		start, end = indexes[2], indexes[3]
-	default:
-		return Pos{}, Pos{}, fmt.Errorf("invalid search regexp %q: expect either 0 or 1 subgroups, got %d", re, len(indexes)/2-1)
-	}
-	startPos, err := contentPosition(content, start)
-	if err != nil {
-		return Pos{}, Pos{}, err
-	}
-	endPos, err := contentPosition(content, end)
-	if err != nil {
-		return Pos{}, Pos{}, err
-	}
-	return startPos, endPos, nil
-}
-
-func normalizeEOL(content string) string {
-	return strings.Join(lines(content), "\n")
-}
-
-// RegexpRange returns the first range in the buffer bufName matching re. See
-// RegexpSearch for more information on matching.
-func (e *Editor) RegexpRange(bufName, re string) (Pos, Pos, error) {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	buf, ok := e.buffers[bufName]
-	if !ok {
-		return Pos{}, Pos{}, ErrUnknownBuffer
-	}
-	return regexpRange(buf.text(), re)
-}
-
-// RegexpSearch returns the position of the first match for re in the buffer
-// bufName. For convenience, RegexpSearch supports the following two modes:
-//  1. If re has no subgroups, return the position of the match for re itself.
-//  2. If re has one subgroup, return the position of the first subgroup.
-//
-// It returns an error re is invalid, has more than one subgroup, or doesn't
-// match the buffer.
-func (e *Editor) RegexpSearch(bufName, re string) (Pos, error) {
-	start, _, err := e.RegexpRange(bufName, re)
-	return start, err
-}
-
-// RegexpReplace edits the buffer corresponding to path by replacing the first
-// instance of re, or its first subgroup, with the replace text. See
-// RegexpSearch for more explanation of these two modes.
-// It returns an error if re is invalid, has more than one subgroup, or doesn't
-// match the buffer.
-func (e *Editor) RegexpReplace(ctx context.Context, path, re, replace string) error {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	buf, ok := e.buffers[path]
-	if !ok {
-		return ErrUnknownBuffer
-	}
-	content := buf.text()
-	start, end, err := regexpRange(content, re)
-	if err != nil {
-		return err
-	}
-	return e.editBufferLocked(ctx, path, []Edit{{
-		Start: start,
-		End:   end,
-		Text:  replace,
-	}})
-}
-
-// EditBuffer applies the given test edits to the buffer identified by path.
-func (e *Editor) EditBuffer(ctx context.Context, path string, edits []Edit) error {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	return e.editBufferLocked(ctx, path, edits)
-}
-
-func (e *Editor) SetBufferContent(ctx context.Context, path, content string) error {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	lines := lines(content)
-	return e.setBufferContentLocked(ctx, path, true, lines, nil)
-}
-
-// HasBuffer reports whether the file name is open in the editor.
-func (e *Editor) HasBuffer(name string) bool {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	_, ok := e.buffers[name]
-	return ok
-}
-
-// BufferText returns the content of the buffer with the given name, or "" if
-// the file at that path is not open. The second return value reports whether
-// the file is open.
-func (e *Editor) BufferText(name string) (string, bool) {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	buf, ok := e.buffers[name]
-	if !ok {
-		return "", false
-	}
-	return buf.text(), true
-}
-
-// BufferVersion returns the current version of the buffer corresponding to
-// name (or 0 if it is not being edited).
-func (e *Editor) BufferVersion(name string) int {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	return e.buffers[name].version
-}
-
-func (e *Editor) editBufferLocked(ctx context.Context, path string, edits []Edit) error {
-	buf, ok := e.buffers[path]
-	if !ok {
-		return fmt.Errorf("unknown buffer %q", path)
-	}
-	content, err := applyEdits(buf.lines, edits)
-	if err != nil {
-		return fmt.Errorf("editing %q: %v; edits:\n%v", path, err, edits)
-	}
-	return e.setBufferContentLocked(ctx, path, true, content, edits)
-}
-
-func (e *Editor) setBufferContentLocked(ctx context.Context, path string, dirty bool, content []string, fromEdits []Edit) error {
-	buf, ok := e.buffers[path]
-	if !ok {
-		return fmt.Errorf("unknown buffer %q", path)
-	}
-	buf.lines = content
-	buf.version++
-	buf.dirty = dirty
-	e.buffers[path] = buf
-	// A simple heuristic: if there is only one edit, send it incrementally.
-	// Otherwise, send the entire content.
-	var evts []protocol.TextDocumentContentChangeEvent
-	if len(fromEdits) == 1 {
-		evts = append(evts, fromEdits[0].toProtocolChangeEvent())
-	} else {
-		evts = append(evts, protocol.TextDocumentContentChangeEvent{
-			Text: buf.text(),
-		})
-	}
-	params := &protocol.DidChangeTextDocumentParams{
-		TextDocument: protocol.VersionedTextDocumentIdentifier{
-			Version:                int32(buf.version),
-			TextDocumentIdentifier: e.TextDocumentIdentifier(buf.path),
-		},
-		ContentChanges: evts,
-	}
-	if e.Server != nil {
-		if err := e.Server.DidChange(ctx, params); err != nil {
-			return fmt.Errorf("DidChange: %w", err)
-		}
-		e.callsMu.Lock()
-		e.calls.DidChange++
-		e.callsMu.Unlock()
-	}
-	return nil
-}
-
-// GoToDefinition jumps to the definition of the symbol at the given position
-// in an open buffer. It returns the path and position of the resulting jump.
-func (e *Editor) GoToDefinition(ctx context.Context, path string, pos Pos) (string, Pos, error) {
-	if err := e.checkBufferPosition(path, pos); err != nil {
-		return "", Pos{}, err
-	}
-	params := &protocol.DefinitionParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	params.Position = pos.ToProtocolPosition()
-
-	resp, err := e.Server.Definition(ctx, params)
-	if err != nil {
-		return "", Pos{}, fmt.Errorf("definition: %w", err)
-	}
-	return e.extractFirstPathAndPos(ctx, resp)
-}
-
-// GoToTypeDefinition jumps to the type definition of the symbol at the given position
-// in an open buffer.
-func (e *Editor) GoToTypeDefinition(ctx context.Context, path string, pos Pos) (string, Pos, error) {
-	if err := e.checkBufferPosition(path, pos); err != nil {
-		return "", Pos{}, err
-	}
-	params := &protocol.TypeDefinitionParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	params.Position = pos.ToProtocolPosition()
-
-	resp, err := e.Server.TypeDefinition(ctx, params)
-	if err != nil {
-		return "", Pos{}, fmt.Errorf("type definition: %w", err)
-	}
-	return e.extractFirstPathAndPos(ctx, resp)
-}
-
-// extractFirstPathAndPos returns the path and the position of the first location.
-// It opens the file if needed.
-func (e *Editor) extractFirstPathAndPos(ctx context.Context, locs []protocol.Location) (string, Pos, error) {
-	if len(locs) == 0 {
-		return "", Pos{}, nil
-	}
-
-	newPath := e.sandbox.Workdir.URIToPath(locs[0].URI)
-	newPos := fromProtocolPosition(locs[0].Range.Start)
-	if !e.HasBuffer(newPath) {
-		if err := e.OpenFile(ctx, newPath); err != nil {
-			return "", Pos{}, fmt.Errorf("OpenFile: %w", err)
-		}
-	}
-	return newPath, newPos, nil
-}
-
-// Symbol performs a workspace symbol search using query
-func (e *Editor) Symbol(ctx context.Context, query string) ([]SymbolInformation, error) {
-	params := &protocol.WorkspaceSymbolParams{}
-	params.Query = query
-
-	resp, err := e.Server.Symbol(ctx, params)
-	if err != nil {
-		return nil, fmt.Errorf("symbol: %w", err)
-	}
-	var res []SymbolInformation
-	for _, si := range resp {
-		ploc := si.Location
-		path := e.sandbox.Workdir.URIToPath(ploc.URI)
-		start := fromProtocolPosition(ploc.Range.Start)
-		end := fromProtocolPosition(ploc.Range.End)
-		rnge := Range{
-			Start: start,
-			End:   end,
-		}
-		loc := Location{
-			Path:  path,
-			Range: rnge,
-		}
-		res = append(res, SymbolInformation{
-			Name:     si.Name,
-			Kind:     si.Kind,
-			Location: loc,
-		})
-	}
-	return res, nil
-}
-
-// OrganizeImports requests and performs the source.organizeImports codeAction.
-func (e *Editor) OrganizeImports(ctx context.Context, path string) error {
-	_, err := e.applyCodeActions(ctx, path, nil, nil, protocol.SourceOrganizeImports)
-	return err
-}
-
-// RefactorRewrite requests and performs the source.refactorRewrite codeAction.
-func (e *Editor) RefactorRewrite(ctx context.Context, path string, rng *protocol.Range) error {
-	applied, err := e.applyCodeActions(ctx, path, rng, nil, protocol.RefactorRewrite)
-	if err != nil {
-		return err
-	}
-	if applied == 0 {
-		return fmt.Errorf("no refactorings were applied")
-	}
-	return nil
-}
-
-// ApplyQuickFixes requests and performs the quickfix codeAction.
-func (e *Editor) ApplyQuickFixes(ctx context.Context, path string, rng *protocol.Range, diagnostics []protocol.Diagnostic) error {
-	applied, err := e.applyCodeActions(ctx, path, rng, diagnostics, protocol.SourceFixAll, protocol.QuickFix)
-	if applied == 0 {
-		return fmt.Errorf("no quick fixes were applied")
-	}
-	return err
-}
-
-// ApplyCodeAction applies the given code action.
-func (e *Editor) ApplyCodeAction(ctx context.Context, action protocol.CodeAction) error {
-	for _, change := range action.Edit.DocumentChanges {
-		if change.TextDocumentEdit != nil {
-			path := e.sandbox.Workdir.URIToPath(change.TextDocumentEdit.TextDocument.URI)
-			if int32(e.buffers[path].version) != change.TextDocumentEdit.TextDocument.Version {
-				// Skip edits for old versions.
-				continue
-			}
-			edits := convertEdits(change.TextDocumentEdit.Edits)
-			if err := e.EditBuffer(ctx, path, edits); err != nil {
-				return fmt.Errorf("editing buffer %q: %w", path, err)
-			}
-		}
-	}
-	// Execute any commands. The specification says that commands are
-	// executed after edits are applied.
-	if action.Command != nil {
-		if _, err := e.ExecuteCommand(ctx, &protocol.ExecuteCommandParams{
-			Command:   action.Command.Command,
-			Arguments: action.Command.Arguments,
-		}); err != nil {
-			return err
-		}
-	}
-	// Some commands may edit files on disk.
-	return e.sandbox.Workdir.CheckForFileChanges(ctx)
-}
-
-// GetQuickFixes returns the available quick fix code actions.
-func (e *Editor) GetQuickFixes(ctx context.Context, path string, rng *protocol.Range, diagnostics []protocol.Diagnostic) ([]protocol.CodeAction, error) {
-	return e.getCodeActions(ctx, path, rng, diagnostics, protocol.QuickFix, protocol.SourceFixAll)
-}
-
-func (e *Editor) applyCodeActions(ctx context.Context, path string, rng *protocol.Range, diagnostics []protocol.Diagnostic, only ...protocol.CodeActionKind) (int, error) {
-	actions, err := e.getCodeActions(ctx, path, rng, diagnostics, only...)
-	if err != nil {
-		return 0, err
-	}
-	applied := 0
-	for _, action := range actions {
-		if action.Title == "" {
-			return 0, fmt.Errorf("empty title for code action")
-		}
-		var match bool
-		for _, o := range only {
-			if action.Kind == o {
-				match = true
-				break
-			}
-		}
-		if !match {
-			continue
-		}
-		applied++
-		if err := e.ApplyCodeAction(ctx, action); err != nil {
-			return 0, err
-		}
-	}
-	return applied, nil
-}
-
-func (e *Editor) getCodeActions(ctx context.Context, path string, rng *protocol.Range, diagnostics []protocol.Diagnostic, only ...protocol.CodeActionKind) ([]protocol.CodeAction, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	params := &protocol.CodeActionParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	params.Context.Only = only
-	if diagnostics != nil {
-		params.Context.Diagnostics = diagnostics
-	}
-	if rng != nil {
-		params.Range = *rng
-	}
-	return e.Server.CodeAction(ctx, params)
-}
-
-func (e *Editor) ExecuteCommand(ctx context.Context, params *protocol.ExecuteCommandParams) (interface{}, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	var match bool
-	// Ensure that this command was actually listed as a supported command.
-	for _, command := range e.serverCapabilities.ExecuteCommandProvider.Commands {
-		if command == params.Command {
-			match = true
-			break
-		}
-	}
-	if !match {
-		return nil, fmt.Errorf("unsupported command %q", params.Command)
-	}
-	result, err := e.Server.ExecuteCommand(ctx, params)
-	if err != nil {
-		return nil, err
-	}
-	// Some commands use the go command, which writes directly to disk.
-	// For convenience, check for those changes.
-	if err := e.sandbox.Workdir.CheckForFileChanges(ctx); err != nil {
-		return nil, err
-	}
-	return result, nil
-}
-
-func convertEdits(protocolEdits []protocol.TextEdit) []Edit {
-	var edits []Edit
-	for _, lspEdit := range protocolEdits {
-		edits = append(edits, fromProtocolTextEdit(lspEdit))
-	}
-	return edits
-}
-
-// FormatBuffer gofmts a Go file.
-func (e *Editor) FormatBuffer(ctx context.Context, path string) error {
-	if e.Server == nil {
-		return nil
-	}
-	e.mu.Lock()
-	version := e.buffers[path].version
-	e.mu.Unlock()
-	params := &protocol.DocumentFormattingParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	resp, err := e.Server.Formatting(ctx, params)
-	if err != nil {
-		return fmt.Errorf("textDocument/formatting: %w", err)
-	}
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	if versionAfter := e.buffers[path].version; versionAfter != version {
-		return fmt.Errorf("before receipt of formatting edits, buffer version changed from %d to %d", version, versionAfter)
-	}
-	edits := convertEdits(resp)
-	if len(edits) == 0 {
-		return nil
-	}
-	return e.editBufferLocked(ctx, path, edits)
-}
-
-func (e *Editor) checkBufferPosition(path string, pos Pos) error {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	buf, ok := e.buffers[path]
-	if !ok {
-		return fmt.Errorf("buffer %q is not open", path)
-	}
-	if !inText(pos, buf.lines) {
-		return fmt.Errorf("position %v is invalid in buffer %q", pos, path)
-	}
-	return nil
-}
-
-// RunGenerate runs `go generate` non-recursively in the workdir-relative dir
-// path. It does not report any resulting file changes as a watched file
-// change, so must be followed by a call to Workdir.CheckForFileChanges once
-// the generate command has completed.
-// TODO(rFindley): this shouldn't be necessary anymore. Delete it.
-func (e *Editor) RunGenerate(ctx context.Context, dir string) error {
-	if e.Server == nil {
-		return nil
-	}
-	absDir := e.sandbox.Workdir.AbsPath(dir)
-	cmd, err := command.NewGenerateCommand("", command.GenerateArgs{
-		Dir:       protocol.URIFromSpanURI(span.URIFromPath(absDir)),
-		Recursive: false,
-	})
-	if err != nil {
-		return err
-	}
-	params := &protocol.ExecuteCommandParams{
-		Command:   cmd.Command,
-		Arguments: cmd.Arguments,
-	}
-	if _, err := e.ExecuteCommand(ctx, params); err != nil {
-		return fmt.Errorf("running generate: %v", err)
-	}
-	// Unfortunately we can't simply poll the workdir for file changes here,
-	// because server-side command may not have completed. In regtests, we can
-	// Await this state change, but here we must delegate that responsibility to
-	// the caller.
-	return nil
-}
-
-// CodeLens executes a codelens request on the server.
-func (e *Editor) CodeLens(ctx context.Context, path string) ([]protocol.CodeLens, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	e.mu.Unlock()
-	if !ok {
-		return nil, fmt.Errorf("buffer %q is not open", path)
-	}
-	params := &protocol.CodeLensParams{
-		TextDocument: e.TextDocumentIdentifier(path),
-	}
-	lens, err := e.Server.CodeLens(ctx, params)
-	if err != nil {
-		return nil, err
-	}
-	return lens, nil
-}
-
-// Completion executes a completion request on the server.
-func (e *Editor) Completion(ctx context.Context, path string, pos Pos) (*protocol.CompletionList, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	e.mu.Unlock()
-	if !ok {
-		return nil, fmt.Errorf("buffer %q is not open", path)
-	}
-	params := &protocol.CompletionParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: e.TextDocumentIdentifier(path),
-			Position:     pos.ToProtocolPosition(),
-		},
-	}
-	completions, err := e.Server.Completion(ctx, params)
-	if err != nil {
-		return nil, err
-	}
-	return completions, nil
-}
-
-// AcceptCompletion accepts a completion for the given item at the given
-// position.
-func (e *Editor) AcceptCompletion(ctx context.Context, path string, pos Pos, item protocol.CompletionItem) error {
-	if e.Server == nil {
-		return nil
-	}
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	_, ok := e.buffers[path]
-	if !ok {
-		return fmt.Errorf("buffer %q is not open", path)
-	}
-	return e.editBufferLocked(ctx, path, convertEdits(append([]protocol.TextEdit{
-		*item.TextEdit,
-	}, item.AdditionalTextEdits...)))
-}
-
-// Symbols executes a workspace/symbols request on the server.
-func (e *Editor) Symbols(ctx context.Context, sym string) ([]protocol.SymbolInformation, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	params := &protocol.WorkspaceSymbolParams{Query: sym}
-	ans, err := e.Server.Symbol(ctx, params)
-	return ans, err
-}
-
-// CodeLens executes a codelens request on the server.
-func (e *Editor) InlayHint(ctx context.Context, path string) ([]protocol.InlayHint, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	e.mu.Unlock()
-	if !ok {
-		return nil, fmt.Errorf("buffer %q is not open", path)
-	}
-	params := &protocol.InlayHintParams{
-		TextDocument: e.TextDocumentIdentifier(path),
-	}
-	hints, err := e.Server.InlayHint(ctx, params)
-	if err != nil {
-		return nil, err
-	}
-	return hints, nil
-}
-
-// References returns references to the object at (path, pos), as returned by
-// the connected LSP server. If no server is connected, it returns (nil, nil).
-func (e *Editor) References(ctx context.Context, path string, pos Pos) ([]protocol.Location, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	e.mu.Unlock()
-	if !ok {
-		return nil, fmt.Errorf("buffer %q is not open", path)
-	}
-	params := &protocol.ReferenceParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: e.TextDocumentIdentifier(path),
-			Position:     pos.ToProtocolPosition(),
-		},
-		Context: protocol.ReferenceContext{
-			IncludeDeclaration: true,
-		},
-	}
-	locations, err := e.Server.References(ctx, params)
-	if err != nil {
-		return nil, err
-	}
-	return locations, nil
-}
-
-// Rename performs a rename of the object at (path, pos) to newName, using the
-// connected LSP server. If no server is connected, it returns nil.
-func (e *Editor) Rename(ctx context.Context, path string, pos Pos, newName string) error {
-	if e.Server == nil {
-		return nil
-	}
-
-	// Verify that PrepareRename succeeds.
-	prepareParams := &protocol.PrepareRenameParams{}
-	prepareParams.TextDocument = e.TextDocumentIdentifier(path)
-	prepareParams.Position = pos.ToProtocolPosition()
-	if _, err := e.Server.PrepareRename(ctx, prepareParams); err != nil {
-		return fmt.Errorf("preparing rename: %v", err)
-	}
-
-	params := &protocol.RenameParams{
-		TextDocument: e.TextDocumentIdentifier(path),
-		Position:     pos.ToProtocolPosition(),
-		NewName:      newName,
-	}
-	wsEdits, err := e.Server.Rename(ctx, params)
-	if err != nil {
-		return err
-	}
-	for _, change := range wsEdits.DocumentChanges {
-		if err := e.applyDocumentChange(ctx, change); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-// Implementations returns implementations for the object at (path, pos), as
-// returned by the connected LSP server. If no server is connected, it returns
-// (nil, nil).
-func (e *Editor) Implementations(ctx context.Context, path string, pos Pos) ([]protocol.Location, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	e.mu.Unlock()
-	if !ok {
-		return nil, fmt.Errorf("buffer %q is not open", path)
-	}
-	params := &protocol.ImplementationParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: e.TextDocumentIdentifier(path),
-			Position:     pos.ToProtocolPosition(),
-		},
-	}
-	return e.Server.Implementation(ctx, params)
-}
-
-func (e *Editor) RenameFile(ctx context.Context, oldPath, newPath string) error {
-	closed, opened, err := e.renameBuffers(ctx, oldPath, newPath)
-	if err != nil {
-		return err
-	}
-
-	for _, c := range closed {
-		if err := e.sendDidClose(ctx, c); err != nil {
-			return err
-		}
-	}
-	for _, o := range opened {
-		if err := e.sendDidOpen(ctx, o); err != nil {
-			return err
-		}
-	}
-
-	// Finally, perform the renaming on disk.
-	if err := e.sandbox.Workdir.RenameFile(ctx, oldPath, newPath); err != nil {
-		return fmt.Errorf("renaming sandbox file: %w", err)
-	}
-	return nil
-}
-
-// renameBuffers renames in-memory buffers affected by the renaming of
-// oldPath->newPath, returning the resulting text documents that must be closed
-// and opened over the LSP.
-func (e *Editor) renameBuffers(ctx context.Context, oldPath, newPath string) (closed []protocol.TextDocumentIdentifier, opened []protocol.TextDocumentItem, _ error) {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-
-	// In case either oldPath or newPath is absolute, convert to absolute paths
-	// before checking for containment.
-	oldAbs := e.sandbox.Workdir.AbsPath(oldPath)
-	newAbs := e.sandbox.Workdir.AbsPath(newPath)
-
-	// Collect buffers that are affected by the given file or directory renaming.
-	buffersToRename := make(map[string]string) // old path -> new path
-
-	for path := range e.buffers {
-		abs := e.sandbox.Workdir.AbsPath(path)
-		if oldAbs == abs || source.InDir(oldAbs, abs) {
-			rel, err := filepath.Rel(oldAbs, abs)
-			if err != nil {
-				return nil, nil, fmt.Errorf("filepath.Rel(%q, %q): %v", oldAbs, abs, err)
-			}
-			nabs := filepath.Join(newAbs, rel)
-			newPath := e.sandbox.Workdir.RelPath(nabs)
-			buffersToRename[path] = newPath
-		}
-	}
-
-	// Update buffers, and build protocol changes.
-	for old, new := range buffersToRename {
-		buf := e.buffers[old]
-		delete(e.buffers, old)
-		buf.version = 1
-		buf.path = new
-		e.buffers[new] = buf
-
-		closed = append(closed, e.TextDocumentIdentifier(old))
-		opened = append(opened, e.textDocumentItem(buf))
-	}
-
-	return closed, opened, nil
-}
-
-func (e *Editor) applyDocumentChange(ctx context.Context, change protocol.DocumentChanges) error {
-	if change.RenameFile != nil {
-		oldPath := e.sandbox.Workdir.URIToPath(change.RenameFile.OldURI)
-		newPath := e.sandbox.Workdir.URIToPath(change.RenameFile.NewURI)
-
-		return e.RenameFile(ctx, oldPath, newPath)
-	}
-	if change.TextDocumentEdit != nil {
-		return e.applyTextDocumentEdit(ctx, *change.TextDocumentEdit)
-	}
-	panic("Internal error: one of RenameFile or TextDocumentEdit must be set")
-}
-
-func (e *Editor) applyTextDocumentEdit(ctx context.Context, change protocol.TextDocumentEdit) error {
-	path := e.sandbox.Workdir.URIToPath(change.TextDocument.URI)
-	if ver := int32(e.BufferVersion(path)); ver != change.TextDocument.Version {
-		return fmt.Errorf("buffer versions for %q do not match: have %d, editing %d", path, ver, change.TextDocument.Version)
-	}
-	if !e.HasBuffer(path) {
-		err := e.OpenFile(ctx, path)
-		if os.IsNotExist(err) {
-			// TODO: it's unclear if this is correct. Here we create the buffer (with
-			// version 1), then apply edits. Perhaps we should apply the edits before
-			// sending the didOpen notification.
-			e.CreateBuffer(ctx, path, "")
-			err = nil
-		}
-		if err != nil {
-			return err
-		}
-	}
-	fakeEdits := convertEdits(change.Edits)
-	return e.EditBuffer(ctx, path, fakeEdits)
-}
-
-// Config returns the current editor configuration.
-func (e *Editor) Config() EditorConfig {
-	e.mu.Lock()
-	defer e.mu.Unlock()
-	return e.config
-}
-
-// ChangeConfiguration sets the new editor configuration, and if applicable
-// sends a didChangeConfiguration notification.
-//
-// An error is returned if the change notification failed to send.
-func (e *Editor) ChangeConfiguration(ctx context.Context, newConfig EditorConfig) error {
-	e.mu.Lock()
-	e.config = newConfig
-	e.mu.Unlock() // don't hold e.mu during server calls
-	if e.Server != nil {
-		var params protocol.DidChangeConfigurationParams // empty: gopls ignores the Settings field
-		if err := e.Server.DidChangeConfiguration(ctx, &params); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-// ChangeWorkspaceFolders sets the new workspace folders, and sends a
-// didChangeWorkspaceFolders notification to the server.
-//
-// The given folders must all be unique.
-func (e *Editor) ChangeWorkspaceFolders(ctx context.Context, folders []string) error {
-	// capture existing folders so that we can compute the change.
-	e.mu.Lock()
-	oldFolders := e.makeWorkspaceFoldersLocked()
-	e.config.WorkspaceFolders = folders
-	newFolders := e.makeWorkspaceFoldersLocked()
-	e.mu.Unlock()
-
-	if e.Server == nil {
-		return nil
-	}
-
-	var params protocol.DidChangeWorkspaceFoldersParams
-
-	// Keep track of old workspace folders that must be removed.
-	toRemove := make(map[protocol.URI]protocol.WorkspaceFolder)
-	for _, folder := range oldFolders {
-		toRemove[folder.URI] = folder
-	}
-
-	// Sanity check: if we see a folder twice the algorithm below doesn't work,
-	// so track seen folders to ensure that we panic in that case.
-	seen := make(map[protocol.URI]protocol.WorkspaceFolder)
-	for _, folder := range newFolders {
-		if _, ok := seen[folder.URI]; ok {
-			panic(fmt.Sprintf("folder %s seen twice", folder.URI))
-		}
-
-		// If this folder already exists, we don't want to remove it.
-		// Otherwise, we need to add it.
-		if _, ok := toRemove[folder.URI]; ok {
-			delete(toRemove, folder.URI)
-		} else {
-			params.Event.Added = append(params.Event.Added, folder)
-		}
-	}
-
-	for _, v := range toRemove {
-		params.Event.Removed = append(params.Event.Removed, v)
-	}
-
-	return e.Server.DidChangeWorkspaceFolders(ctx, &params)
-}
-
-// CodeAction executes a codeAction request on the server.
-func (e *Editor) CodeAction(ctx context.Context, path string, rng *protocol.Range, diagnostics []protocol.Diagnostic) ([]protocol.CodeAction, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	e.mu.Lock()
-	_, ok := e.buffers[path]
-	e.mu.Unlock()
-	if !ok {
-		return nil, fmt.Errorf("buffer %q is not open", path)
-	}
-	params := &protocol.CodeActionParams{
-		TextDocument: e.TextDocumentIdentifier(path),
-		Context: protocol.CodeActionContext{
-			Diagnostics: diagnostics,
-		},
-	}
-	if rng != nil {
-		params.Range = *rng
-	}
-	lens, err := e.Server.CodeAction(ctx, params)
-	if err != nil {
-		return nil, err
-	}
-	return lens, nil
-}
-
-// Hover triggers a hover at the given position in an open buffer.
-func (e *Editor) Hover(ctx context.Context, path string, pos Pos) (*protocol.MarkupContent, Pos, error) {
-	if err := e.checkBufferPosition(path, pos); err != nil {
-		return nil, Pos{}, err
-	}
-	params := &protocol.HoverParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	params.Position = pos.ToProtocolPosition()
-
-	resp, err := e.Server.Hover(ctx, params)
-	if err != nil {
-		return nil, Pos{}, fmt.Errorf("hover: %w", err)
-	}
-	if resp == nil {
-		return nil, Pos{}, nil
-	}
-	return &resp.Contents, fromProtocolPosition(resp.Range.Start), nil
-}
-
-func (e *Editor) DocumentLink(ctx context.Context, path string) ([]protocol.DocumentLink, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	params := &protocol.DocumentLinkParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	return e.Server.DocumentLink(ctx, params)
-}
-
-func (e *Editor) DocumentHighlight(ctx context.Context, path string, pos Pos) ([]protocol.DocumentHighlight, error) {
-	if e.Server == nil {
-		return nil, nil
-	}
-	if err := e.checkBufferPosition(path, pos); err != nil {
-		return nil, err
-	}
-	params := &protocol.DocumentHighlightParams{}
-	params.TextDocument.URI = e.sandbox.Workdir.URI(path)
-	params.Position = pos.ToProtocolPosition()
-
-	return e.Server.DocumentHighlight(ctx, params)
-}
diff -urN a/gopls/internal/lsp/fake/editor_test.go b/gopls/internal/lsp/fake/editor_test.go
--- a/gopls/internal/lsp/fake/editor_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/editor_test.go	1969-12-31 16:00:00
@@ -1,82 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"context"
-	"testing"
-)
-
-func TestContentPosition(t *testing.T) {
-	content := "foo\n😀\nbar"
-	tests := []struct {
-		offset, wantLine, wantColumn int
-	}{
-		{0, 0, 0},
-		{3, 0, 3},
-		{4, 1, 0},
-		{5, 1, 1},
-		{6, 2, 0},
-	}
-	for _, test := range tests {
-		pos, err := contentPosition(content, test.offset)
-		if err != nil {
-			t.Fatal(err)
-		}
-		if pos.Line != test.wantLine {
-			t.Errorf("contentPosition(%q, %d): Line = %d, want %d", content, test.offset, pos.Line, test.wantLine)
-		}
-		if pos.Column != test.wantColumn {
-			t.Errorf("contentPosition(%q, %d): Column = %d, want %d", content, test.offset, pos.Column, test.wantColumn)
-		}
-	}
-}
-
-const exampleProgram = `
--- go.mod --
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hello World.")
-}
-`
-
-func TestClientEditing(t *testing.T) {
-	ws, err := NewSandbox(&SandboxConfig{Files: UnpackTxt(exampleProgram)})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer ws.Close()
-	ctx := context.Background()
-	editor := NewEditor(ws, EditorConfig{})
-	if err := editor.OpenFile(ctx, "main.go"); err != nil {
-		t.Fatal(err)
-	}
-	if err := editor.EditBuffer(ctx, "main.go", []Edit{
-		{
-			Start: Pos{5, 14},
-			End:   Pos{5, 26},
-			Text:  "Hola, mundo.",
-		},
-	}); err != nil {
-		t.Fatal(err)
-	}
-	got := editor.buffers["main.go"].text()
-	want := `package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hola, mundo.")
-}
-`
-	if got != want {
-		t.Errorf("got text %q, want %q", got, want)
-	}
-}
diff -urN a/gopls/internal/lsp/fake/proxy.go b/gopls/internal/lsp/fake/proxy.go
--- a/gopls/internal/lsp/fake/proxy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/proxy.go	1969-12-31 16:00:00
@@ -1,35 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"fmt"
-
-	"golang.org/x/tools/internal/proxydir"
-)
-
-// WriteProxy creates a new proxy file tree using the txtar-encoded content,
-// and returns its URL.
-func WriteProxy(tmpdir string, files map[string][]byte) (string, error) {
-	type moduleVersion struct {
-		modulePath, version string
-	}
-	// Transform into the format expected by the proxydir package.
-	filesByModule := make(map[moduleVersion]map[string][]byte)
-	for name, data := range files {
-		modulePath, version, suffix := splitModuleVersionPath(name)
-		mv := moduleVersion{modulePath, version}
-		if _, ok := filesByModule[mv]; !ok {
-			filesByModule[mv] = make(map[string][]byte)
-		}
-		filesByModule[mv][suffix] = data
-	}
-	for mv, files := range filesByModule {
-		if err := proxydir.WriteModuleVersion(tmpdir, mv.modulePath, mv.version, files); err != nil {
-			return "", fmt.Errorf("error writing %s@%s: %v", mv.modulePath, mv.version, err)
-		}
-	}
-	return proxydir.ToURL(tmpdir), nil
-}
diff -urN a/gopls/internal/lsp/fake/sandbox.go b/gopls/internal/lsp/fake/sandbox.go
--- a/gopls/internal/lsp/fake/sandbox.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/sandbox.go	1969-12-31 16:00:00
@@ -1,296 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"strings"
-
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/robustio"
-	"golang.org/x/tools/internal/testenv"
-	"golang.org/x/tools/txtar"
-)
-
-// Sandbox holds a collection of temporary resources to use for working with Go
-// code in tests.
-type Sandbox struct {
-	gopath          string
-	rootdir         string
-	goproxy         string
-	Workdir         *Workdir
-	goCommandRunner gocommand.Runner
-}
-
-// SandboxConfig controls the behavior of a test sandbox. The zero value
-// defines a reasonable default.
-type SandboxConfig struct {
-	// RootDir sets the base directory to use when creating temporary
-	// directories. If not specified, defaults to a new temporary directory.
-	RootDir string
-	// Files holds a txtar-encoded archive of files to populate the initial state
-	// of the working directory.
-	//
-	// For convenience, the special substring "$SANDBOX_WORKDIR" is replaced with
-	// the sandbox's resolved working directory before writing files.
-	Files map[string][]byte
-	// InGoPath specifies that the working directory should be within the
-	// temporary GOPATH.
-	InGoPath bool
-	// Workdir configures the working directory of the Sandbox. It behaves as
-	// follows:
-	//  - if set to an absolute path, use that path as the working directory.
-	//  - if set to a relative path, create and use that path relative to the
-	//    sandbox.
-	//  - if unset, default to a the 'work' subdirectory of the sandbox.
-	//
-	// This option is incompatible with InGoPath or Files.
-	Workdir string
-	// ProxyFiles holds a txtar-encoded archive of files to populate a file-based
-	// Go proxy.
-	ProxyFiles map[string][]byte
-	// GOPROXY is the explicit GOPROXY value that should be used for the sandbox.
-	//
-	// This option is incompatible with ProxyFiles.
-	GOPROXY string
-}
-
-// NewSandbox creates a collection of named temporary resources, with a
-// working directory populated by the txtar-encoded content in srctxt, and a
-// file-based module proxy populated with the txtar-encoded content in
-// proxytxt.
-//
-// If rootDir is non-empty, it will be used as the root of temporary
-// directories created for the sandbox. Otherwise, a new temporary directory
-// will be used as root.
-//
-// TODO(rfindley): the sandbox abstraction doesn't seem to carry its weight.
-// Sandboxes should be composed out of their building-blocks, rather than via a
-// monolithic configuration.
-func NewSandbox(config *SandboxConfig) (_ *Sandbox, err error) {
-	if config == nil {
-		config = new(SandboxConfig)
-	}
-	if err := validateConfig(*config); err != nil {
-		return nil, fmt.Errorf("invalid SandboxConfig: %v", err)
-	}
-
-	sb := &Sandbox{}
-	defer func() {
-		// Clean up if we fail at any point in this constructor.
-		if err != nil {
-			sb.Close()
-		}
-	}()
-
-	rootDir := config.RootDir
-	if rootDir == "" {
-		rootDir, err = ioutil.TempDir(config.RootDir, "gopls-sandbox-")
-		if err != nil {
-			return nil, fmt.Errorf("creating temporary workdir: %v", err)
-		}
-	}
-	sb.rootdir = rootDir
-	sb.gopath = filepath.Join(sb.rootdir, "gopath")
-	if err := os.Mkdir(sb.gopath, 0755); err != nil {
-		return nil, err
-	}
-	if config.GOPROXY != "" {
-		sb.goproxy = config.GOPROXY
-	} else {
-		proxydir := filepath.Join(sb.rootdir, "proxy")
-		if err := os.Mkdir(proxydir, 0755); err != nil {
-			return nil, err
-		}
-		sb.goproxy, err = WriteProxy(proxydir, config.ProxyFiles)
-		if err != nil {
-			return nil, err
-		}
-	}
-	// Short-circuit writing the workdir if we're given an absolute path, since
-	// this is used for running in an existing directory.
-	// TODO(findleyr): refactor this to be less of a workaround.
-	if filepath.IsAbs(config.Workdir) {
-		sb.Workdir = NewWorkdir(config.Workdir)
-		return sb, nil
-	}
-	var workdir string
-	if config.Workdir == "" {
-		if config.InGoPath {
-			// Set the working directory as $GOPATH/src.
-			workdir = filepath.Join(sb.gopath, "src")
-		} else if workdir == "" {
-			workdir = filepath.Join(sb.rootdir, "work")
-		}
-	} else {
-		// relative path
-		workdir = filepath.Join(sb.rootdir, config.Workdir)
-	}
-	if err := os.MkdirAll(workdir, 0755); err != nil {
-		return nil, err
-	}
-	sb.Workdir = NewWorkdir(workdir)
-	if err := sb.Workdir.writeInitialFiles(config.Files); err != nil {
-		return nil, err
-	}
-	return sb, nil
-}
-
-// Tempdir creates a new temp directory with the given txtar-encoded files. It
-// is the responsibility of the caller to call os.RemoveAll on the returned
-// file path when it is no longer needed.
-func Tempdir(files map[string][]byte) (string, error) {
-	dir, err := ioutil.TempDir("", "gopls-tempdir-")
-	if err != nil {
-		return "", err
-	}
-	for name, data := range files {
-		if err := writeFileData(name, data, RelativeTo(dir)); err != nil {
-			return "", fmt.Errorf("writing to tempdir: %w", err)
-		}
-	}
-	return dir, nil
-}
-
-func UnpackTxt(txt string) map[string][]byte {
-	dataMap := make(map[string][]byte)
-	archive := txtar.Parse([]byte(txt))
-	for _, f := range archive.Files {
-		if _, ok := dataMap[f.Name]; ok {
-			panic(fmt.Sprintf("found file %q twice", f.Name))
-		}
-		dataMap[f.Name] = f.Data
-	}
-	return dataMap
-}
-
-func validateConfig(config SandboxConfig) error {
-	if filepath.IsAbs(config.Workdir) && (len(config.Files) > 0 || config.InGoPath) {
-		return errors.New("absolute Workdir cannot be set in conjunction with Files or InGoPath")
-	}
-	if config.Workdir != "" && config.InGoPath {
-		return errors.New("Workdir cannot be set in conjunction with InGoPath")
-	}
-	if config.GOPROXY != "" && config.ProxyFiles != nil {
-		return errors.New("GOPROXY cannot be set in conjunction with ProxyFiles")
-	}
-	return nil
-}
-
-// splitModuleVersionPath extracts module information from files stored in the
-// directory structure modulePath@version/suffix.
-// For example:
-//
-//	splitModuleVersionPath("mod.com@v1.2.3/package") = ("mod.com", "v1.2.3", "package")
-func splitModuleVersionPath(path string) (modulePath, version, suffix string) {
-	parts := strings.Split(path, "/")
-	var modulePathParts []string
-	for i, p := range parts {
-		if strings.Contains(p, "@") {
-			mv := strings.SplitN(p, "@", 2)
-			modulePathParts = append(modulePathParts, mv[0])
-			return strings.Join(modulePathParts, "/"), mv[1], strings.Join(parts[i+1:], "/")
-		}
-		modulePathParts = append(modulePathParts, p)
-	}
-	// Default behavior: this is just a module path.
-	return path, "", ""
-}
-
-func (sb *Sandbox) RootDir() string {
-	return sb.rootdir
-}
-
-// GOPATH returns the value of the Sandbox GOPATH.
-func (sb *Sandbox) GOPATH() string {
-	return sb.gopath
-}
-
-// GoEnv returns the default environment variables that can be used for
-// invoking Go commands in the sandbox.
-func (sb *Sandbox) GoEnv() map[string]string {
-	vars := map[string]string{
-		"GOPATH":           sb.GOPATH(),
-		"GOPROXY":          sb.goproxy,
-		"GO111MODULE":      "",
-		"GOSUMDB":          "off",
-		"GOPACKAGESDRIVER": "off",
-	}
-	if testenv.Go1Point() >= 5 {
-		vars["GOMODCACHE"] = ""
-	}
-	return vars
-}
-
-// goCommandInvocation returns a new gocommand.Invocation initialized with the
-// sandbox environment variables and working directory.
-func (sb *Sandbox) goCommandInvocation() gocommand.Invocation {
-	var vars []string
-	for k, v := range sb.GoEnv() {
-		vars = append(vars, fmt.Sprintf("%s=%s", k, v))
-	}
-	inv := gocommand.Invocation{
-		Env: vars,
-	}
-	// sb.Workdir may be nil if we exited the constructor with errors (we call
-	// Close to clean up any partial state from the constructor, which calls
-	// RunGoCommand).
-	if sb.Workdir != nil {
-		inv.WorkingDir = string(sb.Workdir.RelativeTo)
-	}
-	return inv
-}
-
-// RunGoCommand executes a go command in the sandbox. If checkForFileChanges is
-// true, the sandbox scans the working directory and emits file change events
-// for any file changes it finds.
-func (sb *Sandbox) RunGoCommand(ctx context.Context, dir, verb string, args []string, checkForFileChanges bool) error {
-	inv := sb.goCommandInvocation()
-	inv.Verb = verb
-	inv.Args = args
-	if dir != "" {
-		inv.WorkingDir = sb.Workdir.AbsPath(dir)
-	}
-	stdout, stderr, _, err := sb.goCommandRunner.RunRaw(ctx, inv)
-	if err != nil {
-		return fmt.Errorf("go command failed (stdout: %s) (stderr: %s): %v", stdout.String(), stderr.String(), err)
-	}
-	// Since running a go command may result in changes to workspace files,
-	// check if we need to send any any "watched" file events.
-	//
-	// TODO(rFindley): this side-effect can impact the usability of the sandbox
-	//                 for benchmarks. Consider refactoring.
-	if sb.Workdir != nil && checkForFileChanges {
-		if err := sb.Workdir.CheckForFileChanges(ctx); err != nil {
-			return fmt.Errorf("checking for file changes: %w", err)
-		}
-	}
-	return nil
-}
-
-// GoVersion checks the version of the go command.
-// It returns the X in Go 1.X.
-func (sb *Sandbox) GoVersion(ctx context.Context) (int, error) {
-	inv := sb.goCommandInvocation()
-	return gocommand.GoVersion(ctx, inv, &sb.goCommandRunner)
-}
-
-// Close removes all state associated with the sandbox.
-func (sb *Sandbox) Close() error {
-	var goCleanErr error
-	if sb.gopath != "" {
-		goCleanErr = sb.RunGoCommand(context.Background(), "", "clean", []string{"-modcache"}, false)
-	}
-	err := robustio.RemoveAll(sb.rootdir)
-	if err != nil || goCleanErr != nil {
-		return fmt.Errorf("error(s) cleaning sandbox: cleaning modcache: %v; removing files: %v", goCleanErr, err)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/fake/workdir.go b/gopls/internal/lsp/fake/workdir.go
--- a/gopls/internal/lsp/fake/workdir.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/workdir.go	1969-12-31 16:00:00
@@ -1,449 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"bytes"
-	"context"
-	"crypto/sha256"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"runtime"
-	"sort"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/robustio"
-)
-
-// RelativeTo is a helper for operations relative to a given directory.
-type RelativeTo string
-
-// AbsPath returns an absolute filesystem path for the workdir-relative path.
-func (r RelativeTo) AbsPath(path string) string {
-	fp := filepath.FromSlash(path)
-	if filepath.IsAbs(fp) {
-		return fp
-	}
-	return filepath.Join(string(r), filepath.FromSlash(path))
-}
-
-// RelPath returns a '/'-encoded path relative to the working directory (or an
-// absolute path if the file is outside of workdir)
-func (r RelativeTo) RelPath(fp string) string {
-	root := string(r)
-	if rel, err := filepath.Rel(root, fp); err == nil && !strings.HasPrefix(rel, "..") {
-		return filepath.ToSlash(rel)
-	}
-	return filepath.ToSlash(fp)
-}
-
-// writeFileData writes content to the relative path, replacing the special
-// token $SANDBOX_WORKDIR with the relative root given by rel. It does not
-// trigger any file events.
-func writeFileData(path string, content []byte, rel RelativeTo) error {
-	content = bytes.ReplaceAll(content, []byte("$SANDBOX_WORKDIR"), []byte(rel))
-	fp := rel.AbsPath(path)
-	if err := os.MkdirAll(filepath.Dir(fp), 0755); err != nil {
-		return fmt.Errorf("creating nested directory: %w", err)
-	}
-	backoff := 1 * time.Millisecond
-	for {
-		err := ioutil.WriteFile(fp, []byte(content), 0644)
-		if err != nil {
-			// This lock file violation is not handled by the robustio package, as it
-			// indicates a real race condition that could be avoided.
-			if isWindowsErrLockViolation(err) {
-				time.Sleep(backoff)
-				backoff *= 2
-				continue
-			}
-			return fmt.Errorf("writing %q: %w", path, err)
-		}
-		return nil
-	}
-}
-
-// isWindowsErrLockViolation reports whether err is ERROR_LOCK_VIOLATION
-// on Windows.
-var isWindowsErrLockViolation = func(err error) bool { return false }
-
-// Workdir is a temporary working directory for tests. It exposes file
-// operations in terms of relative paths, and fakes file watching by triggering
-// events on file operations.
-type Workdir struct {
-	RelativeTo
-
-	watcherMu sync.Mutex
-	watchers  []func(context.Context, []protocol.FileEvent)
-
-	fileMu sync.Mutex
-	// File identities we know about, for the purpose of detecting changes.
-	//
-	// Since files is only used for detecting _changes_, we are tolerant of
-	// fileIDs that may have hash and mtime coming from different states of the
-	// file: if either are out of sync, then the next poll should detect a
-	// discrepancy. It is OK if we detect too many changes, but not OK if we miss
-	// changes.
-	//
-	// For that matter, this mechanism for detecting changes can still be flaky
-	// on platforms where mtime is very coarse (such as older versions of WSL).
-	// It would be much better to use a proper fs event library, but we can't
-	// currently import those into x/tools.
-	//
-	// TODO(golang/go#52284): replace this polling mechanism with a
-	// cross-platform library for filesystem notifications.
-	files map[string]fileID
-}
-
-// fileID is a file identity for the purposes of detecting on-disk
-// modifications.
-type fileID struct {
-	hash  string
-	mtime time.Time
-}
-
-// NewWorkdir writes the txtar-encoded file data in txt to dir, and returns a
-// Workir for operating on these files using
-func NewWorkdir(dir string) *Workdir {
-	return &Workdir{RelativeTo: RelativeTo(dir)}
-}
-
-func hashFile(data []byte) string {
-	return fmt.Sprintf("%x", sha256.Sum256(data))
-}
-
-func (w *Workdir) writeInitialFiles(files map[string][]byte) error {
-	w.files = map[string]fileID{}
-	for name, data := range files {
-		if err := writeFileData(name, data, w.RelativeTo); err != nil {
-			return fmt.Errorf("writing to workdir: %w", err)
-		}
-		fp := w.AbsPath(name)
-
-		// We need the mtime of the file just written for the purposes of tracking
-		// file identity. Calling Stat here could theoretically return an mtime
-		// that is inconsistent with the file contents represented by the hash, but
-		// since we "own" this file we assume that the mtime is correct.
-		//
-		// Furthermore, see the documentation for Workdir.files for why mismatches
-		// between identifiers are considered to be benign.
-		fi, err := os.Stat(fp)
-		if err != nil {
-			return fmt.Errorf("reading file info: %v", err)
-		}
-
-		w.files[name] = fileID{
-			hash:  hashFile(data),
-			mtime: fi.ModTime(),
-		}
-	}
-	return nil
-}
-
-// RootURI returns the root URI for this working directory of this scratch
-// environment.
-func (w *Workdir) RootURI() protocol.DocumentURI {
-	return toURI(string(w.RelativeTo))
-}
-
-// AddWatcher registers the given func to be called on any file change.
-func (w *Workdir) AddWatcher(watcher func(context.Context, []protocol.FileEvent)) {
-	w.watcherMu.Lock()
-	w.watchers = append(w.watchers, watcher)
-	w.watcherMu.Unlock()
-}
-
-// URI returns the URI to a the workdir-relative path.
-func (w *Workdir) URI(path string) protocol.DocumentURI {
-	return toURI(w.AbsPath(path))
-}
-
-// URIToPath converts a uri to a workdir-relative path (or an absolute path,
-// if the uri is outside of the workdir).
-func (w *Workdir) URIToPath(uri protocol.DocumentURI) string {
-	fp := uri.SpanURI().Filename()
-	return w.RelPath(fp)
-}
-
-func toURI(fp string) protocol.DocumentURI {
-	return protocol.DocumentURI(span.URIFromPath(fp))
-}
-
-// ReadFile reads a text file specified by a workdir-relative path.
-func (w *Workdir) ReadFile(path string) (string, error) {
-	backoff := 1 * time.Millisecond
-	for {
-		b, err := ioutil.ReadFile(w.AbsPath(path))
-		if err != nil {
-			if runtime.GOOS == "plan9" && strings.HasSuffix(err.Error(), " exclusive use file already open") {
-				// Plan 9 enforces exclusive access to locked files.
-				// Give the owner time to unlock it and retry.
-				time.Sleep(backoff)
-				backoff *= 2
-				continue
-			}
-			return "", err
-		}
-		return string(b), nil
-	}
-}
-
-func (w *Workdir) RegexpRange(path, re string) (Pos, Pos, error) {
-	content, err := w.ReadFile(path)
-	if err != nil {
-		return Pos{}, Pos{}, err
-	}
-	return regexpRange(content, re)
-}
-
-// RegexpSearch searches the file corresponding to path for the first position
-// matching re.
-func (w *Workdir) RegexpSearch(path string, re string) (Pos, error) {
-	content, err := w.ReadFile(path)
-	if err != nil {
-		return Pos{}, err
-	}
-	start, _, err := regexpRange(content, re)
-	return start, err
-}
-
-// RemoveFile removes a workdir-relative file path and notifies watchers of the
-// change.
-func (w *Workdir) RemoveFile(ctx context.Context, path string) error {
-	fp := w.AbsPath(path)
-	if err := robustio.RemoveAll(fp); err != nil {
-		return fmt.Errorf("removing %q: %w", path, err)
-	}
-
-	return w.CheckForFileChanges(ctx)
-}
-
-// WriteFiles writes the text file content to workdir-relative paths and
-// notifies watchers of the changes.
-func (w *Workdir) WriteFiles(ctx context.Context, files map[string]string) error {
-	for path, content := range files {
-		fp := w.AbsPath(path)
-		_, err := os.Stat(fp)
-		if err != nil && !os.IsNotExist(err) {
-			return fmt.Errorf("checking if %q exists: %w", path, err)
-		}
-		if err := writeFileData(path, []byte(content), w.RelativeTo); err != nil {
-			return err
-		}
-	}
-	return w.CheckForFileChanges(ctx)
-}
-
-// WriteFile writes text file content to a workdir-relative path and notifies
-// watchers of the change.
-func (w *Workdir) WriteFile(ctx context.Context, path, content string) error {
-	return w.WriteFiles(ctx, map[string]string{path: content})
-}
-
-func (w *Workdir) fileEvent(path string, changeType protocol.FileChangeType) protocol.FileEvent {
-	return protocol.FileEvent{
-		URI:  w.URI(path),
-		Type: changeType,
-	}
-}
-
-// RenameFile performs an on disk-renaming of the workdir-relative oldPath to
-// workdir-relative newPath, and notifies watchers of the changes.
-//
-// oldPath must either be a regular file or in the same directory as newPath.
-func (w *Workdir) RenameFile(ctx context.Context, oldPath, newPath string) error {
-	oldAbs := w.AbsPath(oldPath)
-	newAbs := w.AbsPath(newPath)
-
-	// For os.Rename, “OS-specific restrictions may apply when oldpath and newpath
-	// are in different directories.” If that applies here, we may fall back to
-	// ReadFile, WriteFile, and RemoveFile to perform the rename non-atomically.
-	//
-	// However, the fallback path only works for regular files: renaming a
-	// directory would be much more complex and isn't needed for our tests.
-	fallbackOk := false
-	if filepath.Dir(oldAbs) != filepath.Dir(newAbs) {
-		fi, err := os.Stat(oldAbs)
-		if err == nil && !fi.Mode().IsRegular() {
-			return &os.PathError{
-				Op:   "RenameFile",
-				Path: oldPath,
-				Err:  fmt.Errorf("%w: file is not regular and not in the same directory as %s", os.ErrInvalid, newPath),
-			}
-		}
-		fallbackOk = true
-	}
-
-	var renameErr error
-	const debugFallback = false
-	if fallbackOk && debugFallback {
-		renameErr = fmt.Errorf("%w: debugging fallback path", os.ErrInvalid)
-	} else {
-		renameErr = robustio.Rename(oldAbs, newAbs)
-	}
-	if renameErr != nil {
-		if !fallbackOk {
-			return renameErr // The OS-specific Rename restrictions do not apply.
-		}
-
-		content, err := w.ReadFile(oldPath)
-		if err != nil {
-			// If we can't even read the file, the error from Rename may be accurate.
-			return renameErr
-		}
-		fi, err := os.Stat(newAbs)
-		if err == nil {
-			if fi.IsDir() {
-				// “If newpath already exists and is not a directory, Rename replaces it.”
-				// But if it is a directory, maybe not?
-				return renameErr
-			}
-			// On most platforms, Rename replaces the named file with a new file,
-			// rather than overwriting the existing file it in place. Mimic that
-			// behavior here.
-			if err := robustio.RemoveAll(newAbs); err != nil {
-				// Maybe we don't have permission to replace newPath?
-				return renameErr
-			}
-		} else if !os.IsNotExist(err) {
-			// If the destination path already exists or there is some problem with it,
-			// the error from Rename may be accurate.
-			return renameErr
-		}
-		if writeErr := writeFileData(newPath, []byte(content), w.RelativeTo); writeErr != nil {
-			// At this point we have tried to actually write the file.
-			// If it still doesn't exist, assume that the error from Rename was accurate:
-			// for example, maybe we don't have permission to create the new path.
-			// Otherwise, return the error from the write, which may indicate some
-			// other problem (such as a full disk).
-			if _, statErr := os.Stat(newAbs); !os.IsNotExist(statErr) {
-				return writeErr
-			}
-			return renameErr
-		}
-		if err := robustio.RemoveAll(oldAbs); err != nil {
-			// If we failed to remove the old file, that may explain the Rename error too.
-			// Make a best effort to back out the write to the new path.
-			robustio.RemoveAll(newAbs)
-			return renameErr
-		}
-	}
-
-	return w.CheckForFileChanges(ctx)
-}
-
-// ListFiles returns a new sorted list of the relative paths of files in dir,
-// recursively.
-func (w *Workdir) ListFiles(dir string) ([]string, error) {
-	m, err := w.listFiles(dir)
-	if err != nil {
-		return nil, err
-	}
-
-	var paths []string
-	for p := range m {
-		paths = append(paths, p)
-	}
-	sort.Strings(paths)
-	return paths, nil
-}
-
-// listFiles lists files in the given directory, returning a map of relative
-// path to contents and modification time.
-func (w *Workdir) listFiles(dir string) (map[string]fileID, error) {
-	files := make(map[string]fileID)
-	absDir := w.AbsPath(dir)
-	if err := filepath.Walk(absDir, func(fp string, info os.FileInfo, err error) error {
-		if err != nil {
-			return err
-		}
-		if info.IsDir() {
-			return nil
-		}
-		path := w.RelPath(fp)
-
-		data, err := ioutil.ReadFile(fp)
-		if err != nil {
-			return err
-		}
-		// The content returned by ioutil.ReadFile could be inconsistent with
-		// info.ModTime(), due to a subsequent modification. See the documentation
-		// for w.files for why we consider this to be benign.
-		files[path] = fileID{
-			hash:  hashFile(data),
-			mtime: info.ModTime(),
-		}
-		return nil
-	}); err != nil {
-		return nil, err
-	}
-	return files, nil
-}
-
-// CheckForFileChanges walks the working directory and checks for any files
-// that have changed since the last poll.
-func (w *Workdir) CheckForFileChanges(ctx context.Context) error {
-	evts, err := w.pollFiles()
-	if err != nil {
-		return err
-	}
-	if len(evts) == 0 {
-		return nil
-	}
-	w.watcherMu.Lock()
-	watchers := make([]func(context.Context, []protocol.FileEvent), len(w.watchers))
-	copy(watchers, w.watchers)
-	w.watcherMu.Unlock()
-	for _, w := range watchers {
-		w(ctx, evts)
-	}
-	return nil
-}
-
-// pollFiles updates w.files and calculates FileEvents corresponding to file
-// state changes since the last poll. It does not call sendEvents.
-func (w *Workdir) pollFiles() ([]protocol.FileEvent, error) {
-	w.fileMu.Lock()
-	defer w.fileMu.Unlock()
-
-	files, err := w.listFiles(".")
-	if err != nil {
-		return nil, err
-	}
-	var evts []protocol.FileEvent
-	// Check which files have been added or modified.
-	for path, id := range files {
-		oldID, ok := w.files[path]
-		delete(w.files, path)
-		var typ protocol.FileChangeType
-		switch {
-		case !ok:
-			typ = protocol.Created
-		case oldID != id:
-			typ = protocol.Changed
-		default:
-			continue
-		}
-		evts = append(evts, protocol.FileEvent{
-			URI:  w.URI(path),
-			Type: typ,
-		})
-	}
-	// Any remaining files must have been deleted.
-	for path := range w.files {
-		evts = append(evts, protocol.FileEvent{
-			URI:  w.URI(path),
-			Type: protocol.Deleted,
-		})
-	}
-	w.files = files
-	return evts, nil
-}
diff -urN a/gopls/internal/lsp/fake/workdir_test.go b/gopls/internal/lsp/fake/workdir_test.go
--- a/gopls/internal/lsp/fake/workdir_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/workdir_test.go	1969-12-31 16:00:00
@@ -1,250 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"context"
-	"io/ioutil"
-	"os"
-	"sort"
-	"sync"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-const sharedData = `
--- go.mod --
-go 1.12
--- nested/README.md --
-Hello World!
-`
-
-// newWorkdir sets up a temporary Workdir with the given txtar-encoded content.
-// It also configures an eventBuffer to receive file event notifications. These
-// notifications are sent synchronously for each operation, such that once a
-// workdir file operation has returned the caller can expect that any relevant
-// file notifications are present in the buffer.
-//
-// It is the caller's responsibility to call the returned cleanup function.
-func newWorkdir(t *testing.T, txt string) (*Workdir, *eventBuffer, func()) {
-	t.Helper()
-
-	tmpdir, err := ioutil.TempDir("", "goplstest-workdir-")
-	if err != nil {
-		t.Fatal(err)
-	}
-	wd := NewWorkdir(tmpdir)
-	if err := wd.writeInitialFiles(UnpackTxt(txt)); err != nil {
-		t.Fatal(err)
-	}
-	cleanup := func() {
-		if err := os.RemoveAll(tmpdir); err != nil {
-			t.Error(err)
-		}
-	}
-
-	buf := new(eventBuffer)
-	wd.AddWatcher(buf.onEvents)
-	return wd, buf, cleanup
-}
-
-// eventBuffer collects events from a file watcher.
-type eventBuffer struct {
-	mu     sync.Mutex
-	events []protocol.FileEvent
-}
-
-// onEvents collects adds events to the buffer; to be used with Workdir.AddWatcher.
-func (c *eventBuffer) onEvents(_ context.Context, events []protocol.FileEvent) {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-
-	c.events = append(c.events, events...)
-}
-
-// take empties the buffer, returning its previous contents.
-func (c *eventBuffer) take() []protocol.FileEvent {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-
-	evts := c.events
-	c.events = nil
-	return evts
-}
-
-func TestWorkdir_ReadFile(t *testing.T) {
-	wd, _, cleanup := newWorkdir(t, sharedData)
-	defer cleanup()
-
-	got, err := wd.ReadFile("nested/README.md")
-	if err != nil {
-		t.Fatal(err)
-	}
-	want := "Hello World!\n"
-	if got != want {
-		t.Errorf("reading workdir file, got %q, want %q", got, want)
-	}
-}
-
-func TestWorkdir_WriteFile(t *testing.T) {
-	wd, events, cleanup := newWorkdir(t, sharedData)
-	defer cleanup()
-	ctx := context.Background()
-
-	tests := []struct {
-		path     string
-		wantType protocol.FileChangeType
-	}{
-		{"data.txt", protocol.Created},
-		{"nested/README.md", protocol.Changed},
-	}
-
-	for _, test := range tests {
-		if err := wd.WriteFile(ctx, test.path, "42"); err != nil {
-			t.Fatal(err)
-		}
-		es := events.take()
-		if got := len(es); got != 1 {
-			t.Fatalf("len(events) = %d, want 1", got)
-		}
-		path := wd.URIToPath(es[0].URI)
-		if path != test.path {
-			t.Errorf("event path = %q, want %q", path, test.path)
-		}
-		if es[0].Type != test.wantType {
-			t.Errorf("event type = %v, want %v", es[0].Type, test.wantType)
-		}
-		got, err := wd.ReadFile(test.path)
-		if err != nil {
-			t.Fatal(err)
-		}
-		want := "42"
-		if got != want {
-			t.Errorf("ws.ReadFile(%q) = %q, want %q", test.path, got, want)
-		}
-	}
-}
-
-// Test for file notifications following file operations.
-func TestWorkdir_FileWatching(t *testing.T) {
-	wd, events, cleanup := newWorkdir(t, "")
-	defer cleanup()
-	ctx := context.Background()
-
-	must := func(err error) {
-		if err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	type changeMap map[string]protocol.FileChangeType
-	checkEvent := func(wantChanges changeMap) {
-		gotChanges := make(changeMap)
-		for _, e := range events.take() {
-			gotChanges[wd.URIToPath(e.URI)] = e.Type
-		}
-		if diff := cmp.Diff(wantChanges, gotChanges); diff != "" {
-			t.Errorf("mismatching file events (-want +got):\n%s", diff)
-		}
-	}
-
-	must(wd.WriteFile(ctx, "foo.go", "package foo"))
-	checkEvent(changeMap{"foo.go": protocol.Created})
-
-	must(wd.RenameFile(ctx, "foo.go", "bar.go"))
-	checkEvent(changeMap{"foo.go": protocol.Deleted, "bar.go": protocol.Created})
-
-	must(wd.RemoveFile(ctx, "bar.go"))
-	checkEvent(changeMap{"bar.go": protocol.Deleted})
-}
-
-func TestWorkdir_ListFiles(t *testing.T) {
-	wd, _, cleanup := newWorkdir(t, sharedData)
-	defer cleanup()
-
-	checkFiles := func(dir string, want []string) {
-		files, err := wd.listFiles(dir)
-		if err != nil {
-			t.Fatal(err)
-		}
-		sort.Strings(want)
-		var got []string
-		for p := range files {
-			got = append(got, p)
-		}
-		sort.Strings(got)
-		if len(got) != len(want) {
-			t.Fatalf("ListFiles(): len = %d, want %d; got=%v; want=%v", len(got), len(want), got, want)
-		}
-		for i, f := range got {
-			if f != want[i] {
-				t.Errorf("ListFiles()[%d] = %s, want %s", i, f, want[i])
-			}
-		}
-	}
-
-	checkFiles(".", []string{"go.mod", "nested/README.md"})
-	checkFiles("nested", []string{"nested/README.md"})
-}
-
-func TestWorkdir_CheckForFileChanges(t *testing.T) {
-	t.Skip("broken on darwin-amd64-10_12")
-	wd, events, cleanup := newWorkdir(t, sharedData)
-	defer cleanup()
-	ctx := context.Background()
-
-	checkChange := func(wantPath string, wantType protocol.FileChangeType) {
-		if err := wd.CheckForFileChanges(ctx); err != nil {
-			t.Fatal(err)
-		}
-		ev := events.take()
-		if len(ev) == 0 {
-			t.Fatal("no file events received")
-		}
-		gotEvt := ev[0]
-		gotPath := wd.URIToPath(gotEvt.URI)
-		// Only check relative path and Type
-		if gotPath != wantPath || gotEvt.Type != wantType {
-			t.Errorf("file events: got %v, want {Path: %s, Type: %v}", gotEvt, wantPath, wantType)
-		}
-	}
-	// Sleep some positive amount of time to ensure a distinct mtime.
-	if err := writeFileData("go.mod", []byte("module foo.test\n"), wd.RelativeTo); err != nil {
-		t.Fatal(err)
-	}
-	checkChange("go.mod", protocol.Changed)
-	if err := writeFileData("newFile", []byte("something"), wd.RelativeTo); err != nil {
-		t.Fatal(err)
-	}
-	checkChange("newFile", protocol.Created)
-	fp := wd.AbsPath("newFile")
-	if err := os.Remove(fp); err != nil {
-		t.Fatal(err)
-	}
-	checkChange("newFile", protocol.Deleted)
-}
-
-func TestSplitModuleVersionPath(t *testing.T) {
-	tests := []struct {
-		path                                string
-		wantModule, wantVersion, wantSuffix string
-	}{
-		{"foo.com@v1.2.3/bar", "foo.com", "v1.2.3", "bar"},
-		{"foo.com/module@v1.2.3/bar", "foo.com/module", "v1.2.3", "bar"},
-		{"foo.com@v1.2.3", "foo.com", "v1.2.3", ""},
-		{"std@v1.14.0", "std", "v1.14.0", ""},
-		{"another/module/path", "another/module/path", "", ""},
-	}
-
-	for _, test := range tests {
-		module, version, suffix := splitModuleVersionPath(test.path)
-		if module != test.wantModule || version != test.wantVersion || suffix != test.wantSuffix {
-			t.Errorf("splitModuleVersionPath(%q) =\n\t(%q, %q, %q)\nwant\n\t(%q, %q, %q)",
-				test.path, module, version, suffix, test.wantModule, test.wantVersion, test.wantSuffix)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/fake/workdir_windows.go b/gopls/internal/lsp/fake/workdir_windows.go
--- a/gopls/internal/lsp/fake/workdir_windows.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/fake/workdir_windows.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fake
-
-import (
-	"errors"
-	"syscall"
-)
-
-func init() {
-	// constants copied from GOROOT/src/internal/syscall/windows/syscall_windows.go
-	const (
-		ERROR_LOCK_VIOLATION syscall.Errno = 33
-	)
-
-	isWindowsErrLockViolation = func(err error) bool {
-		return errors.Is(err, ERROR_LOCK_VIOLATION)
-	}
-}
diff -urN a/gopls/internal/lsp/filecache/filecache.go b/gopls/internal/lsp/filecache/filecache.go
--- a/gopls/internal/lsp/filecache/filecache.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/filecache/filecache.go	1969-12-31 16:00:00
@@ -1,272 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// The filecache package provides a file-based shared durable blob cache.
-//
-// The cache is a machine-global mapping from (kind string, key
-// [32]byte) to []byte, where kind is an identifier describing the
-// namespace or purpose (e.g. "analysis"), and key is a SHA-256 digest
-// of the recipe of the value. (It need not be the digest of the value
-// itself, so you can query the cache without knowing what value the
-// recipe would produce.)
-//
-// The space budget of the cache can be controlled by [SetBudget].
-// Cache entries may be evicted at any time or in any order.
-//
-// The Get and Set operations are concurrency-safe.
-package filecache
-
-import (
-	"crypto/sha256"
-	"errors"
-	"fmt"
-	"io"
-	"log"
-	"math/rand"
-	"os"
-	"path/filepath"
-	"sort"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"golang.org/x/tools/internal/robustio"
-)
-
-// Get retrieves from the cache and returns a newly allocated
-// copy of the value most recently supplied to Set(kind, key),
-// possibly by another process.
-// Get returns ErrNotFound if the value was not found.
-func Get(kind string, key [32]byte) ([]byte, error) {
-	name := filename(kind, key)
-	data, err := robustio.ReadFile(name)
-	if err != nil {
-		if errors.Is(err, os.ErrNotExist) {
-			return nil, ErrNotFound
-		}
-		return nil, err
-	}
-
-	// Update file time for use by LRU eviction.
-	// (This turns every read into a write operation.
-	// If this is a performance problem, we should
-	// touch the files aynchronously.)
-	now := time.Now()
-	if err := setFileTime(name, now, now); err != nil {
-		return nil, fmt.Errorf("failed to update access time: %w", err)
-	}
-
-	return data, nil
-}
-
-// ErrNotFound is the distinguished error
-// returned by Get when the key is not found.
-var ErrNotFound = fmt.Errorf("not found")
-
-// Set updates the value in the cache.
-func Set(kind string, key [32]byte, value []byte) error {
-	name := filename(kind, key)
-	if err := os.MkdirAll(filepath.Dir(name), 0700); err != nil {
-		return err
-	}
-
-	// The sequence below uses rename to achieve atomic cache
-	// updates even with concurrent processes.
-	var cause error
-	for try := 0; try < 3; try++ {
-		tmpname := fmt.Sprintf("%s.tmp.%d", name, rand.Int())
-		tmp, err := os.OpenFile(tmpname, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0600)
-		if err != nil {
-			if os.IsExist(err) {
-				// Create raced with another thread (or stale file).
-				// Try again.
-				cause = err
-				continue
-			}
-			return err
-		}
-
-		_, err = tmp.Write(value)
-		if closeErr := tmp.Close(); err == nil {
-			err = closeErr // prefer error from write over close
-		}
-		if err != nil {
-			os.Remove(tmp.Name()) // ignore error
-			return err
-		}
-
-		err = robustio.Rename(tmp.Name(), name)
-		if err == nil {
-			return nil // success
-		}
-		cause = err
-
-		// Rename raced with another thread. Try again.
-		os.Remove(tmp.Name()) // ignore error
-	}
-	return cause
-}
-
-var budget int64 = 1e9 // 1GB
-
-// SetBudget sets a soft limit on disk usage of the cache (in bytes)
-// and returns the previous value. Supplying a negative value queries
-// the current value without changing it.
-//
-// If two gopls processes have different budgets, the one with the
-// lower budget will collect garbage more actively, but both will
-// observe the effect.
-func SetBudget(new int64) (old int64) {
-	if new < 0 {
-		return atomic.LoadInt64(&budget)
-	}
-	return atomic.SwapInt64(&budget, new)
-}
-
-// --- implementation ----
-
-// filename returns the cache entry of the specified kind and key.
-//
-// A typical cache entry is a file name such as:
-//
-//	$HOME/Library/Caches / gopls / VVVVVVVV / kind / KK / KKKK...KKKK
-//
-// The portions separated by spaces are as follows:
-// - The user's preferred cache directory; the default value varies by OS.
-// - The constant "gopls".
-// - The "version", 32 bits of the digest of the gopls executable.
-// - The kind or purpose of this cache subtree (e.g. "analysis").
-// - The first 8 bits of the key, to avoid huge directories.
-// - The full 256 bits of the key.
-//
-// Once a file is written its contents are never modified, though it
-// may be atomically replaced or removed.
-//
-// New versions of gopls are free to reorganize the contents of the
-// version directory as needs evolve.  But all versions of gopls must
-// in perpetuity treat the "gopls" directory in a common fashion.
-//
-// In particular, each gopls process attempts to garbage collect
-// the entire gopls directory so that newer binaries can clean up
-// after older ones: in the development cycle especially, new
-// new versions may be created frequently.
-func filename(kind string, key [32]byte) string {
-	hex := fmt.Sprintf("%x", key)
-	return filepath.Join(getCacheDir(), kind, hex[:2], hex)
-}
-
-// getCacheDir returns the persistent cache directory of all processes
-// running this version of the gopls executable.
-//
-// It must incorporate the hash of the executable so that we needn't
-// worry about incompatible changes to the file format or changes to
-// the algorithm that produced the index.
-func getCacheDir() string {
-	cacheDirOnce.Do(func() {
-		// Use user's preferred cache directory.
-		userDir := os.Getenv("GOPLS_CACHE")
-		if userDir == "" {
-			var err error
-			userDir, err = os.UserCacheDir()
-			if err != nil {
-				userDir = os.TempDir()
-			}
-		}
-		goplsDir := filepath.Join(userDir, "gopls")
-
-		// Start the garbage collector.
-		go gc(goplsDir)
-
-		// Compute the hash of this executable (~20ms) and create a subdirectory.
-		hash, err := hashExecutable()
-		if err != nil {
-			log.Fatalf("can't hash gopls executable: %v", err)
-		}
-		// Use only 32 bits of the digest to avoid unwieldy filenames.
-		// It's not an adversarial situation.
-		cacheDir = filepath.Join(goplsDir, fmt.Sprintf("%x", hash[:4]))
-		if err := os.MkdirAll(cacheDir, 0700); err != nil {
-			log.Fatalf("can't create cache: %v", err)
-		}
-	})
-	return cacheDir
-}
-
-var (
-	cacheDirOnce sync.Once
-	cacheDir     string // only accessed by getCacheDir
-)
-
-func hashExecutable() (hash [32]byte, err error) {
-	exe, err := os.Executable()
-	if err != nil {
-		return hash, err
-	}
-	f, err := os.Open(exe)
-	if err != nil {
-		return hash, err
-	}
-	defer f.Close()
-	h := sha256.New()
-	if _, err := io.Copy(h, f); err != nil {
-		return hash, fmt.Errorf("can't read executable: %w", err)
-	}
-	h.Sum(hash[:0])
-	return hash, nil
-}
-
-// gc runs forever, periodically deleting files from the gopls
-// directory until the space budget is no longer exceeded, and also
-// deleting files older than the maximum age, regardless of budget.
-//
-// One gopls process may delete garbage created by a different gopls
-// process, possibly running a different version of gopls, possibly
-// running concurrently.
-func gc(goplsDir string) {
-	const period = 1 * time.Minute         // period between collections
-	const statDelay = 1 * time.Millisecond // delay between stats to smooth out I/O
-	const maxAge = 7 * 24 * time.Hour      // max time since last access before file is deleted
-
-	for {
-		// Enumerate all files in the cache.
-		type item struct {
-			path string
-			stat os.FileInfo
-		}
-		var files []item
-		var total int64 // bytes
-		_ = filepath.Walk(goplsDir, func(path string, stat os.FileInfo, err error) error {
-			// TODO(adonovan): opt: also collect empty directories,
-			// as they typically occupy around 1KB.
-			if err == nil && !stat.IsDir() {
-				files = append(files, item{path, stat})
-				total += stat.Size()
-				time.Sleep(statDelay)
-			}
-			return nil
-		})
-
-		// Sort oldest files first.
-		sort.Slice(files, func(i, j int) bool {
-			return files[i].stat.ModTime().Before(files[j].stat.ModTime())
-		})
-
-		// Delete oldest files until we're under budget.
-		// Unconditionally delete files we haven't used in ages.
-		budget := atomic.LoadInt64(&budget)
-		for _, file := range files {
-			age := time.Since(file.stat.ModTime())
-			if total > budget || age > maxAge {
-				if false { // debugging
-					log.Printf("deleting stale file %s (%dB, age %v)",
-						file.path, file.stat.Size(), age)
-				}
-				os.Remove(filepath.Join(goplsDir, file.path)) // ignore error
-				total -= file.stat.Size()
-			}
-		}
-
-		time.Sleep(period)
-	}
-}
diff -urN a/gopls/internal/lsp/filecache/filecache_test.go b/gopls/internal/lsp/filecache/filecache_test.go
--- a/gopls/internal/lsp/filecache/filecache_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/filecache/filecache_test.go	1969-12-31 16:00:00
@@ -1,189 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package filecache_test
-
-// This file defines tests of the API of the filecache package.
-//
-// Some properties (e.g. garbage collection) cannot be exercised
-// through the API, so this test does not attempt to do so.
-
-import (
-	"bytes"
-	cryptorand "crypto/rand"
-	"fmt"
-	"log"
-	mathrand "math/rand"
-	"os"
-	"os/exec"
-	"strconv"
-	"testing"
-
-	"golang.org/x/sync/errgroup"
-	"golang.org/x/tools/gopls/internal/lsp/filecache"
-)
-
-func TestBasics(t *testing.T) {
-	const kind = "TestBasics"
-	key := uniqueKey() // never used before
-	value := []byte("hello")
-
-	// Get of a never-seen key returns not found.
-	if _, err := filecache.Get(kind, key); err != filecache.ErrNotFound {
-		t.Errorf("Get of random key returned err=%q, want not found", err)
-	}
-
-	// Set of a never-seen key and a small value succeeds.
-	if err := filecache.Set(kind, key, value); err != nil {
-		t.Errorf("Set failed: %v", err)
-	}
-
-	// Get of the key returns a copy of the value.
-	if got, err := filecache.Get(kind, key); err != nil {
-		t.Errorf("Get after Set failed: %v", err)
-	} else if string(got) != string(value) {
-		t.Errorf("Get after Set returned different value: got %q, want %q", got, value)
-	}
-
-	// The kind is effectively part of the key.
-	if _, err := filecache.Get("different-kind", key); err != filecache.ErrNotFound {
-		t.Errorf("Get with wrong kind returned err=%q, want not found", err)
-	}
-}
-
-// TestConcurrency exercises concurrent access to the same entry.
-func TestConcurrency(t *testing.T) {
-	const kind = "TestConcurrency"
-	key := uniqueKey()
-	const N = 100 // concurrency level
-
-	// Construct N distinct values, each larger
-	// than a typical 4KB OS file buffer page.
-	var values [N][8192]byte
-	for i := range values {
-		if _, err := mathrand.Read(values[i][:]); err != nil {
-			t.Fatalf("rand: %v", err)
-		}
-	}
-
-	// get calls Get and verifies that the cache entry
-	// matches one of the values passed to Set.
-	get := func(mustBeFound bool) error {
-		got, err := filecache.Get(kind, key)
-		if err != nil {
-			if err == filecache.ErrNotFound && !mustBeFound {
-				return nil // not found
-			}
-			return err
-		}
-		for _, want := range values {
-			if bytes.Equal(want[:], got) {
-				return nil // a match
-			}
-		}
-		return fmt.Errorf("Get returned a value that was never Set")
-	}
-
-	// Perform N concurrent calls to Set and Get.
-	// All sets must succeed.
-	// All gets must return nothing, or one of the Set values;
-	// there is no third possibility.
-	var group errgroup.Group
-	for i := range values {
-		i := i
-		group.Go(func() error { return filecache.Set(kind, key, values[i][:]) })
-		group.Go(func() error { return get(false) })
-	}
-	if err := group.Wait(); err != nil {
-		t.Fatal(err)
-	}
-
-	// A final Get must report one of the values that was Set.
-	if err := get(true); err != nil {
-		t.Fatalf("final Get failed: %v", err)
-	}
-}
-
-const (
-	testIPCKind   = "TestIPC"
-	testIPCValueA = "hello"
-	testIPCValueB = "world"
-)
-
-// TestIPC exercises interprocess communication through the cache.
-// It calls Set(A) in the parent, { Get(A); Set(B) } in the child
-// process, then Get(B) in the parent.
-func TestIPC(t *testing.T) {
-	keyA := uniqueKey()
-	keyB := uniqueKey()
-	value := []byte(testIPCValueA)
-
-	// Set keyA.
-	if err := filecache.Set(testIPCKind, keyA, value); err != nil {
-		t.Fatalf("Set: %v", err)
-	}
-
-	// Call ipcChild in a child process,
-	// passing it the keys in the environment
-	// (quoted, to avoid NUL termination of C strings).
-	// It will Get(A) then Set(B).
-	cmd := exec.Command(os.Args[0], os.Args[1:]...)
-	cmd.Env = append(os.Environ(),
-		"ENTRYPOINT=ipcChild",
-		fmt.Sprintf("KEYA=%q", keyA),
-		fmt.Sprintf("KEYB=%q", keyB))
-	cmd.Stdout = os.Stderr
-	cmd.Stderr = os.Stderr
-	if err := cmd.Run(); err != nil {
-		t.Fatal(err)
-	}
-
-	// Verify keyB.
-	got, err := filecache.Get(testIPCKind, keyB)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if string(got) != "world" {
-		t.Fatalf("Get(keyB) = %q, want %q", got, "world")
-	}
-}
-
-// We define our own main function so that portions of
-// some tests can run in a separate (child) process.
-func TestMain(m *testing.M) {
-	switch os.Getenv("ENTRYPOINT") {
-	case "ipcChild":
-		ipcChild()
-	default:
-		os.Exit(m.Run())
-	}
-}
-
-// ipcChild is the portion of TestIPC that runs in a child process.
-func ipcChild() {
-	getenv := func(name string) (key [32]byte) {
-		s, _ := strconv.Unquote(os.Getenv(name))
-		copy(key[:], []byte(s))
-		return
-	}
-
-	// Verify key A.
-	got, err := filecache.Get(testIPCKind, getenv("KEYA"))
-	if err != nil || string(got) != testIPCValueA {
-		log.Fatalf("child: Get(key) = %q, %v; want %q", got, err, testIPCValueA)
-	}
-
-	// Set key B.
-	if err := filecache.Set(testIPCKind, getenv("KEYB"), []byte(testIPCValueB)); err != nil {
-		log.Fatalf("child: Set(keyB) failed: %v", err)
-	}
-}
-
-// uniqueKey returns a key that has never been used before.
-func uniqueKey() (key [32]byte) {
-	if _, err := cryptorand.Read(key[:]); err != nil {
-		log.Fatalf("rand: %v", err)
-	}
-	return
-}
diff -urN a/gopls/internal/lsp/filecache/setfiletime_unix.go b/gopls/internal/lsp/filecache/setfiletime_unix.go
--- a/gopls/internal/lsp/filecache/setfiletime_unix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/filecache/setfiletime_unix.go	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !windows
-// +build !windows
-
-// TODO(adonovan): use 'unix' tag when we can rely on newer go command.
-
-package filecache
-
-import (
-	"syscall"
-	"time"
-)
-
-// setFileTime updates the access and modification times of a file.
-//
-// (Traditionally the access time would be updated automatically, but
-// for efficiency most POSIX systems have for many years set the
-// noatime mount option to avoid every open or read operation
-// entailing a metadata write.)
-func setFileTime(filename string, atime, mtime time.Time) error {
-	return syscall.Utimes(filename, []syscall.Timeval{
-		syscall.NsecToTimeval(atime.UnixNano()),
-		syscall.NsecToTimeval(mtime.UnixNano()),
-	})
-}
diff -urN a/gopls/internal/lsp/filecache/setfiletime_windows.go b/gopls/internal/lsp/filecache/setfiletime_windows.go
--- a/gopls/internal/lsp/filecache/setfiletime_windows.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/filecache/setfiletime_windows.go	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build windows
-// +build windows
-
-package filecache
-
-import (
-	"syscall"
-	"time"
-)
-
-// setFileTime updates the access and modification times of a file.
-func setFileTime(filename string, atime, mtime time.Time) error {
-	// Latency of this function was measured on the builder
-	// at median=1.9ms 90%=6.8ms 95%=12ms.
-
-	filename16, err := syscall.UTF16PtrFromString(filename)
-	if err != nil {
-		return err
-	}
-	// See https://learn.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-setfiletime
-	h, err := syscall.CreateFile(filename16, syscall.FILE_WRITE_ATTRIBUTES, syscall.FILE_SHARE_WRITE, nil, syscall.OPEN_EXISTING, 0, 0)
-	if err != nil {
-		return err
-	}
-	defer syscall.Close(h) // ignore error
-	afiletime := syscall.NsecToFiletime(atime.UnixNano())
-	mfiletime := syscall.NsecToFiletime(mtime.UnixNano())
-	return syscall.SetFileTime(h, nil, &afiletime, &mfiletime)
-}
diff -urN a/gopls/internal/lsp/folding_range.go b/gopls/internal/lsp/folding_range.go
--- a/gopls/internal/lsp/folding_range.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/folding_range.go	1969-12-31 16:00:00
@@ -1,44 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func (s *Server) foldingRange(ctx context.Context, params *protocol.FoldingRangeParams) ([]protocol.FoldingRange, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-
-	ranges, err := source.FoldingRange(ctx, snapshot, fh, snapshot.View().Options().LineFoldingOnly)
-	if err != nil {
-		return nil, err
-	}
-	return toProtocolFoldingRanges(ranges)
-}
-
-func toProtocolFoldingRanges(ranges []*source.FoldingRangeInfo) ([]protocol.FoldingRange, error) {
-	result := make([]protocol.FoldingRange, 0, len(ranges))
-	for _, info := range ranges {
-		rng, err := info.Range()
-		if err != nil {
-			return nil, err
-		}
-		result = append(result, protocol.FoldingRange{
-			StartLine:      rng.Start.Line,
-			StartCharacter: rng.Start.Character,
-			EndLine:        rng.End.Line,
-			EndCharacter:   rng.End.Character,
-			Kind:           string(info.Kind),
-		})
-	}
-	return result, nil
-}
diff -urN a/gopls/internal/lsp/format.go b/gopls/internal/lsp/format.go
--- a/gopls/internal/lsp/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/format.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/mod"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/work"
-)
-
-func (s *Server) formatting(ctx context.Context, params *protocol.DocumentFormattingParams) ([]protocol.TextEdit, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	switch snapshot.View().FileKind(fh) {
-	case source.Mod:
-		return mod.Format(ctx, snapshot, fh)
-	case source.Go:
-		return source.Format(ctx, snapshot, fh)
-	case source.Work:
-		return work.Format(ctx, snapshot, fh)
-	}
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/general.go b/gopls/internal/lsp/general.go
--- a/gopls/internal/lsp/general.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/general.go	1969-12-31 16:00:00
@@ -1,610 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"log"
-	"os"
-	"path"
-	"path/filepath"
-	"sort"
-	"strings"
-	"sync"
-
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/jsonrpc2"
-)
-
-func (s *Server) initialize(ctx context.Context, params *protocol.ParamInitialize) (*protocol.InitializeResult, error) {
-	s.stateMu.Lock()
-	if s.state >= serverInitializing {
-		defer s.stateMu.Unlock()
-		return nil, fmt.Errorf("%w: initialize called while server in %v state", jsonrpc2.ErrInvalidRequest, s.state)
-	}
-	s.state = serverInitializing
-	s.stateMu.Unlock()
-
-	// For uniqueness, use the gopls PID rather than params.ProcessID (the client
-	// pid). Some clients might start multiple gopls servers, though they
-	// probably shouldn't.
-	pid := os.Getpid()
-	s.tempDir = filepath.Join(os.TempDir(), fmt.Sprintf("gopls-%d.%s", pid, s.session.ID()))
-	err := os.Mkdir(s.tempDir, 0700)
-	if err != nil {
-		// MkdirTemp could fail due to permissions issues. This is a problem with
-		// the user's environment, but should not block gopls otherwise behaving.
-		// All usage of s.tempDir should be predicated on having a non-empty
-		// s.tempDir.
-		event.Error(ctx, "creating temp dir", err)
-		s.tempDir = ""
-	}
-	s.progress.SetSupportsWorkDoneProgress(params.Capabilities.Window.WorkDoneProgress)
-
-	options := s.session.Options()
-	defer func() { s.session.SetOptions(options) }()
-
-	if err := s.handleOptionResults(ctx, source.SetOptions(options, params.InitializationOptions)); err != nil {
-		return nil, err
-	}
-	options.ForClientCapabilities(params.Capabilities)
-
-	if options.ShowBugReports {
-		// Report the next bug that occurs on the server.
-		bugCh := bug.Notify()
-		go func() {
-			b := <-bugCh
-			msg := &protocol.ShowMessageParams{
-				Type:    protocol.Error,
-				Message: fmt.Sprintf("A bug occurred on the server: %s\nLocation:%s", b.Description, b.Key),
-			}
-			if err := s.eventuallyShowMessage(context.Background(), msg); err != nil {
-				log.Printf("error showing bug: %v", err)
-			}
-		}()
-	}
-
-	folders := params.WorkspaceFolders
-	if len(folders) == 0 {
-		if params.RootURI != "" {
-			folders = []protocol.WorkspaceFolder{{
-				URI:  string(params.RootURI),
-				Name: path.Base(params.RootURI.SpanURI().Filename()),
-			}}
-		}
-	}
-	for _, folder := range folders {
-		uri := span.URIFromURI(folder.URI)
-		if !uri.IsFile() {
-			continue
-		}
-		s.pendingFolders = append(s.pendingFolders, folder)
-	}
-	// gopls only supports URIs with a file:// scheme, so if we have no
-	// workspace folders with a supported scheme, fail to initialize.
-	if len(folders) > 0 && len(s.pendingFolders) == 0 {
-		return nil, fmt.Errorf("unsupported URI schemes: %v (gopls only supports file URIs)", folders)
-	}
-
-	var codeActionProvider interface{} = true
-	if ca := params.Capabilities.TextDocument.CodeAction; len(ca.CodeActionLiteralSupport.CodeActionKind.ValueSet) > 0 {
-		// If the client has specified CodeActionLiteralSupport,
-		// send the code actions we support.
-		//
-		// Using CodeActionOptions is only valid if codeActionLiteralSupport is set.
-		codeActionProvider = &protocol.CodeActionOptions{
-			CodeActionKinds: s.getSupportedCodeActions(),
-		}
-	}
-	var renameOpts interface{} = true
-	if r := params.Capabilities.TextDocument.Rename; r.PrepareSupport {
-		renameOpts = protocol.RenameOptions{
-			PrepareProvider: r.PrepareSupport,
-		}
-	}
-
-	versionInfo := debug.VersionInfo()
-
-	// golang/go#45732: Warn users who've installed sergi/go-diff@v1.2.0, since
-	// it will corrupt the formatting of their files.
-	for _, dep := range versionInfo.Deps {
-		if dep.Path == "github.com/sergi/go-diff" && dep.Version == "v1.2.0" {
-			if err := s.eventuallyShowMessage(ctx, &protocol.ShowMessageParams{
-				Message: `It looks like you have a bad gopls installation.
-Please reinstall gopls by running 'GO111MODULE=on go install golang.org/x/tools/gopls@latest'.
-See https://github.com/golang/go/issues/45732 for more information.`,
-				Type: protocol.Error,
-			}); err != nil {
-				return nil, err
-			}
-		}
-	}
-
-	goplsVersion, err := json.Marshal(versionInfo)
-	if err != nil {
-		return nil, err
-	}
-
-	return &protocol.InitializeResult{
-		Capabilities: protocol.ServerCapabilities{
-			CallHierarchyProvider: true,
-			CodeActionProvider:    codeActionProvider,
-			CodeLensProvider:      &protocol.CodeLensOptions{}, // must be non-nil to enable the code lens capability
-			CompletionProvider: protocol.CompletionOptions{
-				TriggerCharacters: []string{"."},
-			},
-			DefinitionProvider:         true,
-			TypeDefinitionProvider:     true,
-			ImplementationProvider:     true,
-			DocumentFormattingProvider: true,
-			DocumentSymbolProvider:     true,
-			WorkspaceSymbolProvider:    true,
-			ExecuteCommandProvider: protocol.ExecuteCommandOptions{
-				Commands: options.SupportedCommands,
-			},
-			FoldingRangeProvider:      true,
-			HoverProvider:             true,
-			DocumentHighlightProvider: true,
-			DocumentLinkProvider:      protocol.DocumentLinkOptions{},
-			InlayHintProvider:         protocol.InlayHintOptions{},
-			ReferencesProvider:        true,
-			RenameProvider:            renameOpts,
-			SelectionRangeProvider:    protocol.SelectionRangeRegistrationOptions{},
-			SignatureHelpProvider: protocol.SignatureHelpOptions{
-				TriggerCharacters: []string{"(", ","},
-			},
-			TextDocumentSync: &protocol.TextDocumentSyncOptions{
-				Change:    protocol.Incremental,
-				OpenClose: true,
-				Save: protocol.SaveOptions{
-					IncludeText: false,
-				},
-			},
-			Workspace: protocol.Workspace6Gn{
-				WorkspaceFolders: protocol.WorkspaceFolders5Gn{
-					Supported:           true,
-					ChangeNotifications: "workspace/didChangeWorkspaceFolders",
-				},
-			},
-		},
-		ServerInfo: protocol.PServerInfoMsg_initialize{
-			Name:    "gopls",
-			Version: string(goplsVersion),
-		},
-	}, nil
-}
-
-func (s *Server) initialized(ctx context.Context, params *protocol.InitializedParams) error {
-	s.stateMu.Lock()
-	if s.state >= serverInitialized {
-		defer s.stateMu.Unlock()
-		return fmt.Errorf("%w: initialized called while server in %v state", jsonrpc2.ErrInvalidRequest, s.state)
-	}
-	s.state = serverInitialized
-	s.stateMu.Unlock()
-
-	for _, not := range s.notifications {
-		s.client.ShowMessage(ctx, not)
-	}
-	s.notifications = nil
-
-	options := s.session.Options()
-	defer func() { s.session.SetOptions(options) }()
-
-	if err := s.addFolders(ctx, s.pendingFolders); err != nil {
-		return err
-	}
-	s.pendingFolders = nil
-	s.checkViewGoVersions()
-
-	var registrations []protocol.Registration
-	if options.ConfigurationSupported && options.DynamicConfigurationSupported {
-		registrations = append(registrations, protocol.Registration{
-			ID:     "workspace/didChangeConfiguration",
-			Method: "workspace/didChangeConfiguration",
-		})
-	}
-	if options.SemanticTokens && options.DynamicRegistrationSemanticTokensSupported {
-		registrations = append(registrations, semanticTokenRegistration(options.SemanticTypes, options.SemanticMods))
-	}
-	if len(registrations) > 0 {
-		if err := s.client.RegisterCapability(ctx, &protocol.RegistrationParams{
-			Registrations: registrations,
-		}); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-// GoVersionTable maps Go versions to the gopls version in which support will
-// be deprecated, and the final gopls version supporting them without warnings.
-// Keep this in sync with gopls/README.md
-//
-// Must be sorted in ascending order of Go version.
-//
-// Mutable for testing.
-var GoVersionTable = []GoVersionSupport{
-	{12, "", "v0.7.5"},
-	{15, "v0.11.0", "v0.9.5"},
-}
-
-// GoVersionSupport holds information about end-of-life Go version support.
-type GoVersionSupport struct {
-	GoVersion           int
-	DeprecatedVersion   string // if unset, the version is already deprecated
-	InstallGoplsVersion string
-}
-
-// OldestSupportedGoVersion is the last X in Go 1.X that this version of gopls
-// supports.
-func OldestSupportedGoVersion() int {
-	return GoVersionTable[len(GoVersionTable)-1].GoVersion + 1
-}
-
-// versionMessage returns the warning/error message to display if the user is
-// on the given Go version, if any. The goVersion variable is the X in Go 1.X.
-//
-// If goVersion is invalid (< 0), it returns "", 0.
-func versionMessage(goVersion int) (string, protocol.MessageType) {
-	if goVersion < 0 {
-		return "", 0
-	}
-
-	for _, v := range GoVersionTable {
-		if goVersion <= v.GoVersion {
-			var msgBuilder strings.Builder
-
-			mType := protocol.Error
-			fmt.Fprintf(&msgBuilder, "Found Go version 1.%d", goVersion)
-			if v.DeprecatedVersion != "" {
-				// not deprecated yet, just a warning
-				fmt.Fprintf(&msgBuilder, ", which will be unsupported by gopls %s. ", v.DeprecatedVersion)
-				mType = protocol.Warning
-			} else {
-				fmt.Fprint(&msgBuilder, ", which is not supported by this version of gopls. ")
-			}
-			fmt.Fprintf(&msgBuilder, "Please upgrade to Go 1.%d or later and reinstall gopls. ", OldestSupportedGoVersion())
-			fmt.Fprintf(&msgBuilder, "If you can't upgrade and want this message to go away, please install gopls %s. ", v.InstallGoplsVersion)
-			fmt.Fprint(&msgBuilder, "See https://go.dev/s/gopls-support-policy for more details.")
-
-			return msgBuilder.String(), mType
-		}
-	}
-	return "", 0
-}
-
-// checkViewGoVersions checks whether any Go version used by a view is too old,
-// raising a showMessage notification if so.
-//
-// It should be called after views change.
-func (s *Server) checkViewGoVersions() {
-	oldestVersion := -1
-	for _, view := range s.session.Views() {
-		viewVersion := view.GoVersion()
-		if oldestVersion == -1 || viewVersion < oldestVersion {
-			oldestVersion = viewVersion
-		}
-	}
-
-	if msg, mType := versionMessage(oldestVersion); msg != "" {
-		s.eventuallyShowMessage(context.Background(), &protocol.ShowMessageParams{
-			Type:    mType,
-			Message: msg,
-		})
-	}
-}
-
-func (s *Server) addFolders(ctx context.Context, folders []protocol.WorkspaceFolder) error {
-	originalViews := len(s.session.Views())
-	viewErrors := make(map[span.URI]error)
-
-	var ndiagnose sync.WaitGroup // number of unfinished diagnose calls
-	if s.session.Options().VerboseWorkDoneProgress {
-		work := s.progress.Start(ctx, DiagnosticWorkTitle(FromInitialWorkspaceLoad), "Calculating diagnostics for initial workspace load...", nil, nil)
-		defer func() {
-			go func() {
-				ndiagnose.Wait()
-				work.End(ctx, "Done.")
-			}()
-		}()
-	}
-	// Only one view gets to have a workspace.
-	var nsnapshots sync.WaitGroup // number of unfinished snapshot initializations
-	for _, folder := range folders {
-		uri := span.URIFromURI(folder.URI)
-		// Ignore non-file URIs.
-		if !uri.IsFile() {
-			continue
-		}
-		work := s.progress.Start(ctx, "Setting up workspace", "Loading packages...", nil, nil)
-		snapshot, release, err := s.addView(ctx, folder.Name, uri)
-		if err != nil {
-			if err == source.ErrViewExists {
-				continue
-			}
-			viewErrors[uri] = err
-			work.End(ctx, fmt.Sprintf("Error loading packages: %s", err))
-			continue
-		}
-		// Inv: release() must be called once.
-
-		// Initialize snapshot asynchronously.
-		initialized := make(chan struct{})
-		nsnapshots.Add(1)
-		go func() {
-			snapshot.AwaitInitialized(ctx)
-			work.End(ctx, "Finished loading packages.")
-			nsnapshots.Done()
-			close(initialized) // signal
-		}()
-
-		// Diagnose the newly created view asynchronously.
-		ndiagnose.Add(1)
-		go func() {
-			s.diagnoseDetached(snapshot)
-			<-initialized
-			release()
-			ndiagnose.Done()
-		}()
-	}
-
-	// Wait for snapshots to be initialized so that all files are known.
-	// (We don't need to wait for diagnosis to finish.)
-	nsnapshots.Wait()
-
-	// Register for file watching notifications, if they are supported.
-	if err := s.updateWatchedDirectories(ctx); err != nil {
-		event.Error(ctx, "failed to register for file watching notifications", err)
-	}
-
-	if len(viewErrors) > 0 {
-		errMsg := fmt.Sprintf("Error loading workspace folders (expected %v, got %v)\n", len(folders), len(s.session.Views())-originalViews)
-		for uri, err := range viewErrors {
-			errMsg += fmt.Sprintf("failed to load view for %s: %v\n", uri, err)
-		}
-		return s.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-			Type:    protocol.Error,
-			Message: errMsg,
-		})
-	}
-	return nil
-}
-
-// updateWatchedDirectories compares the current set of directories to watch
-// with the previously registered set of directories. If the set of directories
-// has changed, we unregister and re-register for file watching notifications.
-// updatedSnapshots is the set of snapshots that have been updated.
-func (s *Server) updateWatchedDirectories(ctx context.Context) error {
-	patterns := s.session.FileWatchingGlobPatterns(ctx)
-
-	s.watchedGlobPatternsMu.Lock()
-	defer s.watchedGlobPatternsMu.Unlock()
-
-	// Nothing to do if the set of workspace directories is unchanged.
-	if equalURISet(s.watchedGlobPatterns, patterns) {
-		return nil
-	}
-
-	// If the set of directories to watch has changed, register the updates and
-	// unregister the previously watched directories. This ordering avoids a
-	// period where no files are being watched. Still, if a user makes on-disk
-	// changes before these updates are complete, we may miss them for the new
-	// directories.
-	prevID := s.watchRegistrationCount - 1
-	if err := s.registerWatchedDirectoriesLocked(ctx, patterns); err != nil {
-		return err
-	}
-	if prevID >= 0 {
-		return s.client.UnregisterCapability(ctx, &protocol.UnregistrationParams{
-			Unregisterations: []protocol.Unregistration{{
-				ID:     watchedFilesCapabilityID(prevID),
-				Method: "workspace/didChangeWatchedFiles",
-			}},
-		})
-	}
-	return nil
-}
-
-func watchedFilesCapabilityID(id int) string {
-	return fmt.Sprintf("workspace/didChangeWatchedFiles-%d", id)
-}
-
-func equalURISet(m1, m2 map[string]struct{}) bool {
-	if len(m1) != len(m2) {
-		return false
-	}
-	for k := range m1 {
-		_, ok := m2[k]
-		if !ok {
-			return false
-		}
-	}
-	return true
-}
-
-// registerWatchedDirectoriesLocked sends the workspace/didChangeWatchedFiles
-// registrations to the client and updates s.watchedDirectories.
-func (s *Server) registerWatchedDirectoriesLocked(ctx context.Context, patterns map[string]struct{}) error {
-	if !s.session.Options().DynamicWatchedFilesSupported {
-		return nil
-	}
-	for k := range s.watchedGlobPatterns {
-		delete(s.watchedGlobPatterns, k)
-	}
-	var watchers []protocol.FileSystemWatcher
-	for pattern := range patterns {
-		watchers = append(watchers, protocol.FileSystemWatcher{
-			GlobPattern: pattern,
-			Kind:        uint32(protocol.WatchChange + protocol.WatchDelete + protocol.WatchCreate),
-		})
-	}
-
-	if err := s.client.RegisterCapability(ctx, &protocol.RegistrationParams{
-		Registrations: []protocol.Registration{{
-			ID:     watchedFilesCapabilityID(s.watchRegistrationCount),
-			Method: "workspace/didChangeWatchedFiles",
-			RegisterOptions: protocol.DidChangeWatchedFilesRegistrationOptions{
-				Watchers: watchers,
-			},
-		}},
-	}); err != nil {
-		return err
-	}
-	s.watchRegistrationCount++
-
-	for k, v := range patterns {
-		s.watchedGlobPatterns[k] = v
-	}
-	return nil
-}
-
-func (s *Server) fetchConfig(ctx context.Context, name string, folder span.URI, o *source.Options) error {
-	if !s.session.Options().ConfigurationSupported {
-		return nil
-	}
-	configs, err := s.client.Configuration(ctx, &protocol.ParamConfiguration{
-		Items: []protocol.ConfigurationItem{{
-			ScopeURI: string(folder),
-			Section:  "gopls",
-		}},
-	},
-	)
-	if err != nil {
-		return fmt.Errorf("failed to get workspace configuration from client (%s): %v", folder, err)
-	}
-	for _, config := range configs {
-		if err := s.handleOptionResults(ctx, source.SetOptions(o, config)); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-func (s *Server) eventuallyShowMessage(ctx context.Context, msg *protocol.ShowMessageParams) error {
-	s.stateMu.Lock()
-	defer s.stateMu.Unlock()
-	if s.state == serverInitialized {
-		return s.client.ShowMessage(ctx, msg)
-	}
-	s.notifications = append(s.notifications, msg)
-	return nil
-}
-
-func (s *Server) handleOptionResults(ctx context.Context, results source.OptionResults) error {
-	var warnings, errors []string
-	for _, result := range results {
-		switch result.Error.(type) {
-		case nil:
-			// nothing to do
-		case *source.SoftError:
-			warnings = append(warnings, result.Error.Error())
-		default:
-			errors = append(errors, result.Error.Error())
-		}
-	}
-
-	// Sort messages, but put errors first.
-	//
-	// Having stable content for the message allows clients to de-duplicate. This
-	// matters because we may send duplicate warnings for clients that support
-	// dynamic configuration: one for the initial settings, and then more for the
-	// individual view settings.
-	var msgs []string
-	msgType := protocol.Warning
-	if len(errors) > 0 {
-		msgType = protocol.Error
-		sort.Strings(errors)
-		msgs = append(msgs, errors...)
-	}
-	if len(warnings) > 0 {
-		sort.Strings(warnings)
-		msgs = append(msgs, warnings...)
-	}
-
-	if len(msgs) > 0 {
-		// Settings
-		combined := "Invalid settings: " + strings.Join(msgs, "; ")
-		params := &protocol.ShowMessageParams{
-			Type:    msgType,
-			Message: combined,
-		}
-		return s.eventuallyShowMessage(ctx, params)
-	}
-
-	return nil
-}
-
-// beginFileRequest checks preconditions for a file-oriented request and routes
-// it to a snapshot.
-// We don't want to return errors for benign conditions like wrong file type,
-// so callers should do if !ok { return err } rather than if err != nil.
-// The returned cleanup function is non-nil even in case of false/error result.
-func (s *Server) beginFileRequest(ctx context.Context, pURI protocol.DocumentURI, expectKind source.FileKind) (source.Snapshot, source.VersionedFileHandle, bool, func(), error) {
-	uri := pURI.SpanURI()
-	if !uri.IsFile() {
-		// Not a file URI. Stop processing the request, but don't return an error.
-		return nil, nil, false, func() {}, nil
-	}
-	view, err := s.session.ViewOf(uri)
-	if err != nil {
-		return nil, nil, false, func() {}, err
-	}
-	snapshot, release := view.Snapshot(ctx)
-	fh, err := snapshot.GetVersionedFile(ctx, uri)
-	if err != nil {
-		release()
-		return nil, nil, false, func() {}, err
-	}
-	if expectKind != source.UnknownKind && view.FileKind(fh) != expectKind {
-		// Wrong kind of file. Nothing to do.
-		release()
-		return nil, nil, false, func() {}, nil
-	}
-	return snapshot, fh, true, release, nil
-}
-
-// shutdown implements the 'shutdown' LSP handler. It releases resources
-// associated with the server and waits for all ongoing work to complete.
-func (s *Server) shutdown(ctx context.Context) error {
-	s.stateMu.Lock()
-	defer s.stateMu.Unlock()
-	if s.state < serverInitialized {
-		event.Log(ctx, "server shutdown without initialization")
-	}
-	if s.state != serverShutDown {
-		// drop all the active views
-		s.session.Shutdown(ctx)
-		s.state = serverShutDown
-		if s.tempDir != "" {
-			if err := os.RemoveAll(s.tempDir); err != nil {
-				event.Error(ctx, "removing temp dir", err)
-			}
-		}
-	}
-	return nil
-}
-
-func (s *Server) exit(ctx context.Context) error {
-	s.stateMu.Lock()
-	defer s.stateMu.Unlock()
-
-	s.client.Close()
-
-	if s.state != serverShutDown {
-		// TODO: We should be able to do better than this.
-		os.Exit(1)
-	}
-	// we don't terminate the process on a normal exit, we just allow it to
-	// close naturally if needed after the connection is closed.
-	return nil
-}
diff -urN a/gopls/internal/lsp/general_test.go b/gopls/internal/lsp/general_test.go
--- a/gopls/internal/lsp/general_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/general_test.go	1969-12-31 16:00:00
@@ -1,44 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func TestVersionMessage(t *testing.T) {
-	tests := []struct {
-		goVersion    int
-		wantContains []string // string fragments that we expect to see
-		wantType     protocol.MessageType
-	}{
-		{-1, nil, 0},
-		{12, []string{"1.12", "not supported", "upgrade to Go 1.16", "install gopls v0.7.5"}, protocol.Error},
-		{13, []string{"1.13", "will be unsupported by gopls v0.11.0", "upgrade to Go 1.16", "install gopls v0.9.5"}, protocol.Warning},
-		{15, []string{"1.15", "will be unsupported by gopls v0.11.0", "upgrade to Go 1.16", "install gopls v0.9.5"}, protocol.Warning},
-		{16, nil, 0},
-	}
-
-	for _, test := range tests {
-		gotMsg, gotType := versionMessage(test.goVersion)
-
-		if len(test.wantContains) == 0 && gotMsg != "" {
-			t.Errorf("versionMessage(%d) = %q, want \"\"", test.goVersion, gotMsg)
-		}
-
-		for _, want := range test.wantContains {
-			if !strings.Contains(gotMsg, want) {
-				t.Errorf("versionMessage(%d) = %q, want containing %q", test.goVersion, gotMsg, want)
-			}
-		}
-
-		if gotType != test.wantType {
-			t.Errorf("versionMessage(%d) = returned message type %d, want %d", test.goVersion, gotType, test.wantType)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/helper/README.md b/gopls/internal/lsp/helper/README.md
--- a/gopls/internal/lsp/helper/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/helper/README.md	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-# Generate server_gen.go
-
-`helper` generates boilerplate code for server.go by processing the
-generated code in `protocol/tsserver.go`.
-
-First, build `helper` in this directory (`go build .`).
-
-In directory `lsp`, executing `go generate server.go` generates the stylized file
-`server_gen.go` that contains stubs for type `Server`.
-
-It decides what stubs are needed and their signatures
-by looking at the `Server` interface (`-t` flag). These all look somewhat like
-`Resolve(context.Context, *CompletionItem) (*CompletionItem, error)`.
-
-It then parses the `lsp` directory (`-u` flag) to see if there is a corresponding
-implementation function (which in this case would be named `resolve`). If so
-it discovers the parameter names needed, and generates (in `server_gen.go`) code
-like
-
-``` go
-func (s *Server) resolve(ctx context.Context, params *protocol.CompletionItem) (*protocol.CompletionItem, error) {
-    return s.resolve(ctx, params)
-}
-```
-
-If `resolve` is not defined (and it is not), then the body of the generated function is
-
-```go
-    return nil, notImplemented("resolve")
-```
-
-So to add a capability currently not implemented, just define it somewhere in `lsp`.
-In this case, just define `func (s *Server) resolve(...)` and re-generate `server_gen.go`.
diff -urN a/gopls/internal/lsp/helper/helper.go b/gopls/internal/lsp/helper/helper.go
--- a/gopls/internal/lsp/helper/helper.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/helper/helper.go	1969-12-31 16:00:00
@@ -1,258 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Invoke with //go:generate helper/helper -t Server -d protocol/tsserver.go -u lsp -o server_gen.go
-// invoke in internal/lsp
-package main
-
-import (
-	"bytes"
-	"flag"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/parser"
-	"go/token"
-	"log"
-	"os"
-	"sort"
-	"strings"
-	"text/template"
-)
-
-var (
-	typ = flag.String("t", "Server", "generate code for this type")
-	def = flag.String("d", "", "the file the type is defined in") // this relies on punning
-	use = flag.String("u", "", "look for uses in this package")
-	out = flag.String("o", "", "where to write the generated file")
-)
-
-func main() {
-	log.SetFlags(log.Lshortfile)
-	flag.Parse()
-	if *typ == "" || *def == "" || *use == "" || *out == "" {
-		flag.PrintDefaults()
-		return
-	}
-	// read the type definition and see what methods we're looking for
-	doTypes()
-
-	// parse the package and see which methods are defined
-	doUses()
-
-	output()
-}
-
-// replace "\\\n" with nothing before using
-var tmpl = `// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-// code generated by helper. DO NOT EDIT.
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-{{range $key, $v := .Stuff}}
-func (s *{{$.Type}}) {{$v.Name}}({{.Param}}) {{.Result}} {
-	{{if ne .Found ""}} return s.{{.Internal}}({{.Invoke}})\
-	{{else}}return {{if lt 1 (len .Results)}}nil, {{end}}notImplemented("{{.Name}}"){{end}}
-}
-{{end}}
-`
-
-func output() {
-	// put in empty param names as needed
-	for _, t := range types {
-		if t.paramnames == nil {
-			t.paramnames = make([]string, len(t.paramtypes))
-		}
-		for i, p := range t.paramtypes {
-			cm := ""
-			if i > 0 {
-				cm = ", "
-			}
-			t.Param += fmt.Sprintf("%s%s %s", cm, t.paramnames[i], p)
-			this := t.paramnames[i]
-			if this == "_" {
-				this = "nil"
-			}
-			t.Invoke += fmt.Sprintf("%s%s", cm, this)
-		}
-		if len(t.Results) > 1 {
-			t.Result = "("
-		}
-		for i, r := range t.Results {
-			cm := ""
-			if i > 0 {
-				cm = ", "
-			}
-			t.Result += fmt.Sprintf("%s%s", cm, r)
-		}
-		if len(t.Results) > 1 {
-			t.Result += ")"
-		}
-	}
-
-	fd, err := os.Create(*out)
-	if err != nil {
-		log.Fatal(err)
-	}
-	t, err := template.New("foo").Parse(tmpl)
-	if err != nil {
-		log.Fatal(err)
-	}
-	type par struct {
-		Type  string
-		Stuff []*Function
-	}
-	p := par{*typ, types}
-	if false { // debugging the template
-		t.Execute(os.Stderr, &p)
-	}
-	buf := bytes.NewBuffer(nil)
-	err = t.Execute(buf, &p)
-	if err != nil {
-		log.Fatal(err)
-	}
-	ans, err := format.Source(bytes.Replace(buf.Bytes(), []byte("\\\n"), []byte{}, -1))
-	if err != nil {
-		log.Fatal(err)
-	}
-	fd.Write(ans)
-}
-
-func doUses() {
-	fset := token.NewFileSet()
-	pkgs, err := parser.ParseDir(fset, *use, nil, 0)
-	if err != nil {
-		log.Fatalf("%q:%v", *use, err)
-	}
-	pkg := pkgs["lsp"] // CHECK
-	files := pkg.Files
-	for fname, f := range files {
-		for _, d := range f.Decls {
-			fd, ok := d.(*ast.FuncDecl)
-			if !ok {
-				continue
-			}
-			nm := fd.Name.String()
-			if ast.IsExported(nm) {
-				// we're looking for things like didChange
-				continue
-			}
-			if fx, ok := byname[nm]; ok {
-				if fx.Found != "" {
-					log.Fatalf("found %s in %s and %s", fx.Internal, fx.Found, fname)
-				}
-				fx.Found = fname
-				// and the Paramnames
-				ft := fd.Type
-				for _, f := range ft.Params.List {
-					nm := ""
-					if len(f.Names) > 0 {
-						nm = f.Names[0].String()
-						if nm == "_" {
-							nm = "_gen"
-						}
-					}
-					fx.paramnames = append(fx.paramnames, nm)
-				}
-			}
-		}
-	}
-	if false {
-		for i, f := range types {
-			log.Printf("%d %s %s", i, f.Internal, f.Found)
-		}
-	}
-}
-
-type Function struct {
-	Name       string
-	Internal   string // first letter lower case
-	paramtypes []string
-	paramnames []string
-	Results    []string
-	Param      string
-	Result     string // do it in code, easier than in a template
-	Invoke     string
-	Found      string // file it was found in
-}
-
-var types []*Function
-var byname = map[string]*Function{} // internal names
-
-func doTypes() {
-	fset := token.NewFileSet()
-	f, err := parser.ParseFile(fset, *def, nil, 0)
-	if err != nil {
-		log.Fatal(err)
-	}
-	fd, err := os.Create("/tmp/ast")
-	if err != nil {
-		log.Fatal(err)
-	}
-	ast.Fprint(fd, fset, f, ast.NotNilFilter)
-	ast.Inspect(f, inter)
-	sort.Slice(types, func(i, j int) bool { return types[i].Name < types[j].Name })
-	if false {
-		for i, f := range types {
-			log.Printf("%d %s(%v) %v", i, f.Name, f.paramtypes, f.Results)
-		}
-	}
-}
-
-func inter(n ast.Node) bool {
-	x, ok := n.(*ast.TypeSpec)
-	if !ok || x.Name.Name != *typ {
-		return true
-	}
-	m := x.Type.(*ast.InterfaceType).Methods.List
-	for _, fld := range m {
-		fn := fld.Type.(*ast.FuncType)
-		p := fn.Params.List
-		r := fn.Results.List
-		fx := &Function{
-			Name: fld.Names[0].String(),
-		}
-		fx.Internal = strings.ToLower(fx.Name[:1]) + fx.Name[1:]
-		for _, f := range p {
-			fx.paramtypes = append(fx.paramtypes, whatis(f.Type))
-		}
-		for _, f := range r {
-			fx.Results = append(fx.Results, whatis(f.Type))
-		}
-		types = append(types, fx)
-		byname[fx.Internal] = fx
-	}
-	return false
-}
-
-func whatis(x ast.Expr) string {
-	switch n := x.(type) {
-	case *ast.SelectorExpr:
-		return whatis(n.X) + "." + n.Sel.String()
-	case *ast.StarExpr:
-		return "*" + whatis(n.X)
-	case *ast.Ident:
-		if ast.IsExported(n.Name) {
-			// these are from package protocol
-			return "protocol." + n.Name
-		}
-		return n.Name
-	case *ast.ArrayType:
-		return "[]" + whatis(n.Elt)
-	case *ast.InterfaceType:
-		return "interface{}"
-	default:
-		log.Fatalf("Fatal %T", x)
-		return fmt.Sprintf("%T", x)
-	}
-}
diff -urN a/gopls/internal/lsp/highlight.go b/gopls/internal/lsp/highlight.go
--- a/gopls/internal/lsp/highlight.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/highlight.go	1969-12-31 16:00:00
@@ -1,45 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-)
-
-func (s *Server) documentHighlight(ctx context.Context, params *protocol.DocumentHighlightParams) ([]protocol.DocumentHighlight, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-
-	if snapshot.View().FileKind(fh) == source.Tmpl {
-		return template.Highlight(ctx, snapshot, fh, params.Position)
-	}
-
-	rngs, err := source.Highlight(ctx, snapshot, fh, params.Position)
-	if err != nil {
-		event.Error(ctx, "no highlight", err, tag.URI.Of(params.TextDocument.URI))
-	}
-	return toProtocolHighlight(rngs), nil
-}
-
-func toProtocolHighlight(rngs []protocol.Range) []protocol.DocumentHighlight {
-	result := make([]protocol.DocumentHighlight, 0, len(rngs))
-	kind := protocol.Text
-	for _, rng := range rngs {
-		result = append(result, protocol.DocumentHighlight{
-			Kind:  kind,
-			Range: rng,
-		})
-	}
-	return result
-}
diff -urN a/gopls/internal/lsp/hover.go b/gopls/internal/lsp/hover.go
--- a/gopls/internal/lsp/hover.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/hover.go	1969-12-31 16:00:00
@@ -1,34 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/mod"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-	"golang.org/x/tools/gopls/internal/lsp/work"
-)
-
-func (s *Server) hover(ctx context.Context, params *protocol.HoverParams) (*protocol.Hover, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	switch snapshot.View().FileKind(fh) {
-	case source.Mod:
-		return mod.Hover(ctx, snapshot, fh, params.Position)
-	case source.Go:
-		return source.Hover(ctx, snapshot, fh, params.Position)
-	case source.Tmpl:
-		return template.Hover(ctx, snapshot, fh, params.Position)
-	case source.Work:
-		return work.Hover(ctx, snapshot, fh, params.Position)
-	}
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/implementation.go b/gopls/internal/lsp/implementation.go
--- a/gopls/internal/lsp/implementation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/implementation.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func (s *Server) implementation(ctx context.Context, params *protocol.ImplementationParams) ([]protocol.Location, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	return source.Implementation(ctx, snapshot, fh, params.Position)
-}
diff -urN a/gopls/internal/lsp/inlay_hint.go b/gopls/internal/lsp/inlay_hint.go
--- a/gopls/internal/lsp/inlay_hint.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/inlay_hint.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func (s *Server) inlayHint(ctx context.Context, params *protocol.InlayHintParams) ([]protocol.InlayHint, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	return source.InlayHint(ctx, snapshot, fh, params.Range)
-}
diff -urN a/gopls/internal/lsp/link.go b/gopls/internal/lsp/link.go
--- a/gopls/internal/lsp/link.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/link.go	1969-12-31 16:00:00
@@ -1,282 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"net/url"
-	"regexp"
-	"strings"
-	"sync"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-func (s *Server) documentLink(ctx context.Context, params *protocol.DocumentLinkParams) (links []protocol.DocumentLink, err error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	switch snapshot.View().FileKind(fh) {
-	case source.Mod:
-		links, err = modLinks(ctx, snapshot, fh)
-	case source.Go:
-		links, err = goLinks(ctx, snapshot, fh)
-	}
-	// Don't return errors for document links.
-	if err != nil {
-		event.Error(ctx, "failed to compute document links", err, tag.URI.Of(fh.URI()))
-		return nil, nil
-	}
-	return links, nil
-}
-
-func modLinks(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.DocumentLink, error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		return nil, err
-	}
-	tokFile := pm.Mapper.TokFile
-
-	var links []protocol.DocumentLink
-	for _, req := range pm.File.Require {
-		if req.Syntax == nil {
-			continue
-		}
-		// See golang/go#36998: don't link to modules matching GOPRIVATE.
-		if snapshot.View().IsGoPrivatePath(req.Mod.Path) {
-			continue
-		}
-		dep := []byte(req.Mod.Path)
-		s, e := req.Syntax.Start.Byte, req.Syntax.End.Byte
-		i := bytes.Index(pm.Mapper.Content[s:e], dep)
-		if i == -1 {
-			continue
-		}
-		// Shift the start position to the location of the
-		// dependency within the require statement.
-		start, end := tokFile.Pos(s+i), tokFile.Pos(s+i+len(dep))
-		target := source.BuildLink(snapshot.View().Options().LinkTarget, "mod/"+req.Mod.String(), "")
-		l, err := toProtocolLink(tokFile, pm.Mapper, target, start, end)
-		if err != nil {
-			return nil, err
-		}
-		links = append(links, l)
-	}
-	// TODO(ridersofrohan): handle links for replace and exclude directives.
-	if syntax := pm.File.Syntax; syntax == nil {
-		return links, nil
-	}
-
-	// Get all the links that are contained in the comments of the file.
-	urlRegexp := snapshot.View().Options().URLRegexp
-	for _, expr := range pm.File.Syntax.Stmt {
-		comments := expr.Comment()
-		if comments == nil {
-			continue
-		}
-		for _, section := range [][]modfile.Comment{comments.Before, comments.Suffix, comments.After} {
-			for _, comment := range section {
-				start := tokFile.Pos(comment.Start.Byte)
-				l, err := findLinksInString(urlRegexp, comment.Token, start, tokFile, pm.Mapper)
-				if err != nil {
-					return nil, err
-				}
-				links = append(links, l...)
-			}
-		}
-	}
-	return links, nil
-}
-
-// goLinks returns the set of hyperlink annotations for the specified Go file.
-func goLinks(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.DocumentLink, error) {
-	view := snapshot.View()
-
-	pgf, err := snapshot.ParseGo(ctx, fh, source.ParseFull)
-	if err != nil {
-		return nil, err
-	}
-
-	var links []protocol.DocumentLink
-
-	// Create links for import specs.
-	if view.Options().ImportShortcut.ShowLinks() {
-
-		// If links are to pkg.go.dev, append module version suffixes.
-		// This requires the import map from the package metadata. Ignore errors.
-		var depsByImpPath map[source.ImportPath]source.PackageID
-		if strings.ToLower(view.Options().LinkTarget) == "pkg.go.dev" {
-			if metas, _ := snapshot.MetadataForFile(ctx, fh.URI()); len(metas) > 0 {
-				depsByImpPath = metas[0].DepsByImpPath // 0 => narrowest package
-			}
-		}
-
-		for _, imp := range pgf.File.Imports {
-			importPath := source.UnquoteImportPath(imp)
-			if importPath == "" {
-				continue // bad import
-			}
-			// See golang/go#36998: don't link to modules matching GOPRIVATE.
-			if view.IsGoPrivatePath(string(importPath)) {
-				continue
-			}
-
-			urlPath := string(importPath)
-
-			// For pkg.go.dev, append module version suffix to package import path.
-			if m := snapshot.Metadata(depsByImpPath[importPath]); m != nil &&
-				m.Module != nil &&
-				m.Module.Path != "" &&
-				m.Module.Version != "" &&
-				!source.IsWorkspaceModuleVersion(m.Module.Version) {
-				urlPath = strings.Replace(urlPath, m.Module.Path, m.Module.Path+"@"+m.Module.Version, 1)
-			}
-
-			// Account for the quotation marks in the positions.
-			start := imp.Path.Pos() + 1
-			end := imp.Path.End() - 1
-			targetURL := source.BuildLink(view.Options().LinkTarget, urlPath, "")
-			l, err := toProtocolLink(pgf.Tok, pgf.Mapper, targetURL, start, end)
-			if err != nil {
-				return nil, err
-			}
-			links = append(links, l)
-		}
-	}
-
-	urlRegexp := snapshot.View().Options().URLRegexp
-
-	// Gather links found in string literals.
-	var str []*ast.BasicLit
-	ast.Inspect(pgf.File, func(node ast.Node) bool {
-		switch n := node.(type) {
-		case *ast.ImportSpec:
-			return false // don't process import strings again
-		case *ast.BasicLit:
-			if n.Kind == token.STRING {
-				str = append(str, n)
-			}
-		}
-		return true
-	})
-	for _, s := range str {
-		l, err := findLinksInString(urlRegexp, s.Value, s.Pos(), pgf.Tok, pgf.Mapper)
-		if err != nil {
-			return nil, err
-		}
-		links = append(links, l...)
-	}
-
-	// Gather links found in comments.
-	for _, commentGroup := range pgf.File.Comments {
-		for _, comment := range commentGroup.List {
-			l, err := findLinksInString(urlRegexp, comment.Text, comment.Pos(), pgf.Tok, pgf.Mapper)
-			if err != nil {
-				return nil, err
-			}
-			links = append(links, l...)
-		}
-	}
-
-	return links, nil
-}
-
-// acceptedSchemes controls the schemes that URLs must have to be shown to the
-// user. Other schemes can't be opened by LSP clients, so linkifying them is
-// distracting. See golang/go#43990.
-var acceptedSchemes = map[string]bool{
-	"http":  true,
-	"https": true,
-}
-
-// urlRegexp is the user-supplied regular expression to match URL.
-// tokFile may be a throwaway File for non-Go files.
-func findLinksInString(urlRegexp *regexp.Regexp, src string, pos token.Pos, tokFile *token.File, m *protocol.ColumnMapper) ([]protocol.DocumentLink, error) {
-	var links []protocol.DocumentLink
-	for _, index := range urlRegexp.FindAllIndex([]byte(src), -1) {
-		start, end := index[0], index[1]
-		startPos := token.Pos(int(pos) + start)
-		endPos := token.Pos(int(pos) + end)
-		link := src[start:end]
-		linkURL, err := url.Parse(link)
-		// Fallback: Linkify IP addresses as suggested in golang/go#18824.
-		if err != nil {
-			linkURL, err = url.Parse("//" + link)
-			// Not all potential links will be valid, so don't return this error.
-			if err != nil {
-				continue
-			}
-		}
-		// If the URL has no scheme, use https.
-		if linkURL.Scheme == "" {
-			linkURL.Scheme = "https"
-		}
-		if !acceptedSchemes[linkURL.Scheme] {
-			continue
-		}
-		l, err := toProtocolLink(tokFile, m, linkURL.String(), startPos, endPos)
-		if err != nil {
-			return nil, err
-		}
-		links = append(links, l)
-	}
-	// Handle golang/go#1234-style links.
-	r := getIssueRegexp()
-	for _, index := range r.FindAllIndex([]byte(src), -1) {
-		start, end := index[0], index[1]
-		startPos := token.Pos(int(pos) + start)
-		endPos := token.Pos(int(pos) + end)
-		matches := r.FindStringSubmatch(src)
-		if len(matches) < 4 {
-			continue
-		}
-		org, repo, number := matches[1], matches[2], matches[3]
-		targetURL := fmt.Sprintf("https://github.com/%s/%s/issues/%s", org, repo, number)
-		l, err := toProtocolLink(tokFile, m, targetURL, startPos, endPos)
-		if err != nil {
-			return nil, err
-		}
-		links = append(links, l)
-	}
-	return links, nil
-}
-
-func getIssueRegexp() *regexp.Regexp {
-	once.Do(func() {
-		issueRegexp = regexp.MustCompile(`(\w+)/([\w-]+)#([0-9]+)`)
-	})
-	return issueRegexp
-}
-
-var (
-	once        sync.Once
-	issueRegexp *regexp.Regexp
-)
-
-func toProtocolLink(tokFile *token.File, m *protocol.ColumnMapper, targetURL string, start, end token.Pos) (protocol.DocumentLink, error) {
-	spn, err := span.NewRange(tokFile, start, end).Span()
-	if err != nil {
-		return protocol.DocumentLink{}, err
-	}
-	rng, err := m.Range(spn)
-	if err != nil {
-		return protocol.DocumentLink{}, err
-	}
-	return protocol.DocumentLink{
-		Range:  rng,
-		Target: targetURL,
-	}, nil
-}
diff -urN a/gopls/internal/lsp/lsp_test.go b/gopls/internal/lsp/lsp_test.go
--- a/gopls/internal/lsp/lsp_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsp_test.go	1969-12-31 16:00:00
@@ -1,1407 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"fmt"
-	"go/token"
-	"os"
-	"os/exec"
-	"path/filepath"
-	"sort"
-	"strings"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"github.com/google/go-cmp/cmp/cmpopts"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	testenv.ExitIfSmallMachine()
-
-	// Set the global exporter to nil so that we don't log to stderr. This avoids
-	// a lot of misleading noise in test output.
-	//
-	// TODO(rfindley): investigate whether we can/should capture logs scoped to
-	// individual tests by passing in a context with a local exporter.
-	event.SetExporter(nil)
-
-	os.Exit(m.Run())
-}
-
-func TestLSP(t *testing.T) {
-	tests.RunTests(t, "testdata", true, testLSP)
-}
-
-type runner struct {
-	server      *Server
-	data        *tests.Data
-	diagnostics map[span.URI][]*source.Diagnostic
-	ctx         context.Context
-	normalizers []tests.Normalizer
-	editRecv    chan map[span.URI]string
-}
-
-func testLSP(t *testing.T, datum *tests.Data) {
-	ctx := tests.Context(t)
-
-	session := cache.NewSession(ctx, cache.New(nil, nil), nil)
-	options := source.DefaultOptions().Clone()
-	tests.DefaultOptions(options)
-	session.SetOptions(options)
-	options.SetEnvSlice(datum.Config.Env)
-	view, snapshot, release, err := session.NewView(ctx, datum.Config.Dir, span.URIFromPath(datum.Config.Dir), options)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	defer session.RemoveView(view)
-
-	// Enable type error analyses for tests.
-	// TODO(golang/go#38212): Delete this once they are enabled by default.
-	tests.EnableAllAnalyzers(options)
-	session.SetViewOptions(ctx, view, options)
-
-	// Enable all inlay hints for tests.
-	tests.EnableAllInlayHints(options)
-
-	// Only run the -modfile specific tests in module mode with Go 1.14 or above.
-	datum.ModfileFlagAvailable = len(snapshot.ModFiles()) > 0 && testenv.Go1Point() >= 14
-	release()
-
-	var modifications []source.FileModification
-	for filename, content := range datum.Config.Overlay {
-		if filepath.Ext(filename) != ".go" {
-			continue
-		}
-		modifications = append(modifications, source.FileModification{
-			URI:        span.URIFromPath(filename),
-			Action:     source.Open,
-			Version:    -1,
-			Text:       content,
-			LanguageID: "go",
-		})
-	}
-	if err := session.ModifyFiles(ctx, modifications); err != nil {
-		t.Fatal(err)
-	}
-	r := &runner{
-		data:        datum,
-		ctx:         ctx,
-		normalizers: tests.CollectNormalizers(datum.Exported),
-		editRecv:    make(chan map[span.URI]string, 1),
-	}
-
-	r.server = NewServer(session, testClient{runner: r})
-	tests.Run(t, r, datum)
-}
-
-// testClient stubs any client functions that may be called by LSP functions.
-type testClient struct {
-	protocol.Client
-	runner *runner
-}
-
-func (c testClient) Close() error {
-	return nil
-}
-
-// Trivially implement PublishDiagnostics so that we can call
-// server.publishReports below to de-dup sent diagnostics.
-func (c testClient) PublishDiagnostics(context.Context, *protocol.PublishDiagnosticsParams) error {
-	return nil
-}
-
-func (c testClient) ShowMessage(context.Context, *protocol.ShowMessageParams) error {
-	return nil
-}
-
-func (c testClient) ApplyEdit(ctx context.Context, params *protocol.ApplyWorkspaceEditParams) (*protocol.ApplyWorkspaceEditResult, error) {
-	res, err := applyTextDocumentEdits(c.runner, params.Edit.DocumentChanges)
-	if err != nil {
-		return nil, err
-	}
-	c.runner.editRecv <- res
-	return &protocol.ApplyWorkspaceEditResult{Applied: true}, nil
-}
-
-func (r *runner) CallHierarchy(t *testing.T, spn span.Span, expectedCalls *tests.CallHierarchyResult) {
-	mapper, err := r.data.Mapper(spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := mapper.Location(spn)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-
-	params := &protocol.CallHierarchyPrepareParams{
-		TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-			TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-			Position:     loc.Range.Start,
-		},
-	}
-
-	items, err := r.server.PrepareCallHierarchy(r.ctx, params)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if len(items) == 0 {
-		t.Fatalf("expected call hierarchy item to be returned for identifier at %v\n", loc.Range)
-	}
-
-	callLocation := protocol.Location{
-		URI:   items[0].URI,
-		Range: items[0].Range,
-	}
-	if callLocation != loc {
-		t.Fatalf("expected server.PrepareCallHierarchy to return identifier at %v but got %v\n", loc, callLocation)
-	}
-
-	incomingCalls, err := r.server.IncomingCalls(r.ctx, &protocol.CallHierarchyIncomingCallsParams{Item: items[0]})
-	if err != nil {
-		t.Error(err)
-	}
-	var incomingCallItems []protocol.CallHierarchyItem
-	for _, item := range incomingCalls {
-		incomingCallItems = append(incomingCallItems, item.From)
-	}
-	msg := tests.DiffCallHierarchyItems(incomingCallItems, expectedCalls.IncomingCalls)
-	if msg != "" {
-		t.Error(fmt.Sprintf("incoming calls: %s", msg))
-	}
-
-	outgoingCalls, err := r.server.OutgoingCalls(r.ctx, &protocol.CallHierarchyOutgoingCallsParams{Item: items[0]})
-	if err != nil {
-		t.Error(err)
-	}
-	var outgoingCallItems []protocol.CallHierarchyItem
-	for _, item := range outgoingCalls {
-		outgoingCallItems = append(outgoingCallItems, item.To)
-	}
-	msg = tests.DiffCallHierarchyItems(outgoingCallItems, expectedCalls.OutgoingCalls)
-	if msg != "" {
-		t.Error(fmt.Sprintf("outgoing calls: %s", msg))
-	}
-}
-
-func (r *runner) CodeLens(t *testing.T, uri span.URI, want []protocol.CodeLens) {
-	if !strings.HasSuffix(uri.Filename(), "go.mod") {
-		return
-	}
-	got, err := r.server.codeLens(r.ctx, &protocol.CodeLensParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.DocumentURI(uri),
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	if diff := tests.DiffCodeLens(uri, want, got); diff != "" {
-		t.Errorf("%s: %s", uri, diff)
-	}
-}
-
-func (r *runner) Diagnostics(t *testing.T, uri span.URI, want []*source.Diagnostic) {
-	// Get the diagnostics for this view if we have not done it before.
-	v := r.server.session.View(r.data.Config.Dir)
-	r.collectDiagnostics(v)
-	got := append([]*source.Diagnostic(nil), r.diagnostics[uri]...) // copy
-	tests.CompareDiagnostics(t, uri, want, got)
-}
-
-func (r *runner) FoldingRanges(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	view, err := r.server.session.ViewOf(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	original := view.Options()
-	modified := original
-	defer r.server.session.SetViewOptions(r.ctx, view, original)
-
-	// Test all folding ranges.
-	modified.LineFoldingOnly = false
-	view, err = r.server.session.SetViewOptions(r.ctx, view, modified)
-	if err != nil {
-		t.Error(err)
-		return
-	}
-	ranges, err := r.server.FoldingRange(r.ctx, &protocol.FoldingRangeParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		t.Error(err)
-		return
-	}
-	r.foldingRanges(t, "foldingRange", uri, ranges)
-
-	// Test folding ranges with lineFoldingOnly = true.
-	modified.LineFoldingOnly = true
-	view, err = r.server.session.SetViewOptions(r.ctx, view, modified)
-	if err != nil {
-		t.Error(err)
-		return
-	}
-	ranges, err = r.server.FoldingRange(r.ctx, &protocol.FoldingRangeParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		t.Error(err)
-		return
-	}
-	r.foldingRanges(t, "foldingRange-lineFolding", uri, ranges)
-}
-
-func (r *runner) foldingRanges(t *testing.T, prefix string, uri span.URI, ranges []protocol.FoldingRange) {
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	// Fold all ranges.
-	nonOverlapping := nonOverlappingRanges(ranges)
-	for i, rngs := range nonOverlapping {
-		got, err := foldRanges(m, string(m.Content), rngs)
-		if err != nil {
-			t.Error(err)
-			continue
-		}
-		tag := fmt.Sprintf("%s-%d", prefix, i)
-		want := string(r.data.Golden(t, tag, uri.Filename(), func() ([]byte, error) {
-			return []byte(got), nil
-		}))
-
-		if want != got {
-			t.Errorf("%s: foldingRanges failed for %s, expected:\n%v\ngot:\n%v", tag, uri.Filename(), want, got)
-		}
-	}
-
-	// Filter by kind.
-	kinds := []protocol.FoldingRangeKind{protocol.Imports, protocol.Comment}
-	for _, kind := range kinds {
-		var kindOnly []protocol.FoldingRange
-		for _, fRng := range ranges {
-			if fRng.Kind == string(kind) {
-				kindOnly = append(kindOnly, fRng)
-			}
-		}
-
-		nonOverlapping := nonOverlappingRanges(kindOnly)
-		for i, rngs := range nonOverlapping {
-			got, err := foldRanges(m, string(m.Content), rngs)
-			if err != nil {
-				t.Error(err)
-				continue
-			}
-			tag := fmt.Sprintf("%s-%s-%d", prefix, kind, i)
-			want := string(r.data.Golden(t, tag, uri.Filename(), func() ([]byte, error) {
-				return []byte(got), nil
-			}))
-
-			if want != got {
-				t.Errorf("%s: foldingRanges failed for %s, expected:\n%v\ngot:\n%v", tag, uri.Filename(), want, got)
-			}
-		}
-
-	}
-}
-
-func nonOverlappingRanges(ranges []protocol.FoldingRange) (res [][]protocol.FoldingRange) {
-	for _, fRng := range ranges {
-		setNum := len(res)
-		for i := 0; i < len(res); i++ {
-			canInsert := true
-			for _, rng := range res[i] {
-				if conflict(rng, fRng) {
-					canInsert = false
-					break
-				}
-			}
-			if canInsert {
-				setNum = i
-				break
-			}
-		}
-		if setNum == len(res) {
-			res = append(res, []protocol.FoldingRange{})
-		}
-		res[setNum] = append(res[setNum], fRng)
-	}
-	return res
-}
-
-func conflict(a, b protocol.FoldingRange) bool {
-	// a start position is <= b start positions
-	return (a.StartLine < b.StartLine || (a.StartLine == b.StartLine && a.StartCharacter <= b.StartCharacter)) &&
-		(a.EndLine > b.StartLine || (a.EndLine == b.StartLine && a.EndCharacter > b.StartCharacter))
-}
-
-func foldRanges(m *protocol.ColumnMapper, contents string, ranges []protocol.FoldingRange) (string, error) {
-	foldedText := "<>"
-	res := contents
-	// Apply the edits from the end of the file forward
-	// to preserve the offsets
-	// TODO(adonovan): factor to use diff.ApplyEdits, which validates the input.
-	for i := len(ranges) - 1; i >= 0; i-- {
-		r := ranges[i]
-		start, err := m.Point(protocol.Position{Line: r.StartLine, Character: r.StartCharacter})
-		if err != nil {
-			return "", err
-		}
-		end, err := m.Point(protocol.Position{Line: r.EndLine, Character: r.EndCharacter})
-		if err != nil {
-			return "", err
-		}
-		res = res[:start.Offset()] + foldedText + res[end.Offset():]
-	}
-	return res, nil
-}
-
-func (r *runner) Format(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	gofmted := string(r.data.Golden(t, "gofmt", filename, func() ([]byte, error) {
-		cmd := exec.Command("gofmt", filename)
-		out, _ := cmd.Output() // ignore error, sometimes we have intentionally ungofmt-able files
-		return out, nil
-	}))
-
-	edits, err := r.server.Formatting(r.ctx, &protocol.DocumentFormattingParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		if gofmted != "" {
-			t.Error(err)
-		}
-		return
-	}
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, _, err := source.ApplyProtocolEdits(m, edits)
-	if err != nil {
-		t.Error(err)
-	}
-	if diff := compare.Text(gofmted, got); diff != "" {
-		t.Errorf("format failed for %s (-want +got):\n%s", filename, diff)
-	}
-}
-
-func (r *runner) SemanticTokens(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	// this is called solely for coverage in semantic.go
-	_, err := r.server.semanticTokensFull(r.ctx, &protocol.SemanticTokensParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		t.Errorf("%v for %s", err, filename)
-	}
-	_, err = r.server.semanticTokensRange(r.ctx, &protocol.SemanticTokensRangeParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		// any legal range. Just to exercise the call.
-		Range: protocol.Range{
-			Start: protocol.Position{
-				Line:      0,
-				Character: 0,
-			},
-			End: protocol.Position{
-				Line:      2,
-				Character: 0,
-			},
-		},
-	})
-	if err != nil {
-		t.Errorf("%v for Range %s", err, filename)
-	}
-}
-
-func (r *runner) Import(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	filename := uri.Filename()
-	actions, err := r.server.CodeAction(r.ctx, &protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got := string(m.Content)
-	if len(actions) > 0 {
-		res, err := applyTextDocumentEdits(r, actions[0].Edit.DocumentChanges)
-		if err != nil {
-			t.Fatal(err)
-		}
-		got = res[uri]
-	}
-	want := string(r.data.Golden(t, "goimports", filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-
-	if d := compare.Text(want, got); d != "" {
-		t.Errorf("import failed for %s:\n%s", filename, d)
-	}
-}
-
-func (r *runner) SuggestedFix(t *testing.T, spn span.Span, actionKinds []tests.SuggestedFix, expectedActions int) {
-	uri := spn.URI()
-	view, err := r.server.session.ViewOf(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	rng, err := m.Range(spn)
-	if err != nil {
-		t.Fatal(err)
-	}
-	// Get the diagnostics for this view if we have not done it before.
-	r.collectDiagnostics(view)
-	var diagnostics []protocol.Diagnostic
-	for _, d := range r.diagnostics[uri] {
-		// Compare the start positions rather than the entire range because
-		// some diagnostics have a range with the same start and end position (8:1-8:1).
-		// The current marker functionality prevents us from having a range of 0 length.
-		if protocol.ComparePosition(d.Range.Start, rng.Start) == 0 {
-			diagnostics = append(diagnostics, toProtocolDiagnostics([]*source.Diagnostic{d})...)
-			break
-		}
-	}
-	var codeActionKinds []protocol.CodeActionKind
-	for _, k := range actionKinds {
-		codeActionKinds = append(codeActionKinds, protocol.CodeActionKind(k.ActionKind))
-	}
-	allActions, err := r.server.CodeAction(r.ctx, &protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Range: rng,
-		Context: protocol.CodeActionContext{
-			Only:        codeActionKinds,
-			Diagnostics: diagnostics,
-		},
-	})
-	if err != nil {
-		t.Fatalf("CodeAction %s failed: %v", spn, err)
-	}
-	var actions []protocol.CodeAction
-	for _, action := range allActions {
-		for _, fix := range actionKinds {
-			if strings.Contains(action.Title, fix.Title) {
-				actions = append(actions, action)
-				break
-			}
-		}
-
-	}
-	if len(actions) != expectedActions {
-		var summaries []string
-		for _, a := range actions {
-			summaries = append(summaries, fmt.Sprintf("%q (%s)", a.Title, a.Kind))
-		}
-		t.Fatalf("CodeAction(...): got %d code actions (%v), want %d", len(actions), summaries, expectedActions)
-	}
-	action := actions[0]
-	var match bool
-	for _, k := range codeActionKinds {
-		if action.Kind == k {
-			match = true
-			break
-		}
-	}
-	if !match {
-		t.Fatalf("unexpected kind for code action %s, got %v, want one of %v", action.Title, action.Kind, codeActionKinds)
-	}
-	var res map[span.URI]string
-	if cmd := action.Command; cmd != nil {
-		_, err := r.server.ExecuteCommand(r.ctx, &protocol.ExecuteCommandParams{
-			Command:   action.Command.Command,
-			Arguments: action.Command.Arguments,
-		})
-		if err != nil {
-			t.Fatalf("error converting command %q to edits: %v", action.Command.Command, err)
-		}
-		res = <-r.editRecv
-	} else {
-		res, err = applyTextDocumentEdits(r, action.Edit.DocumentChanges)
-		if err != nil {
-			t.Fatal(err)
-		}
-	}
-	for u, got := range res {
-		want := string(r.data.Golden(t, "suggestedfix_"+tests.SpanName(spn), u.Filename(), func() ([]byte, error) {
-			return []byte(got), nil
-		}))
-		if want != got {
-			t.Errorf("suggested fixes failed for %s:\n%s", u.Filename(), compare.Text(want, got))
-		}
-	}
-}
-
-func (r *runner) FunctionExtraction(t *testing.T, start span.Span, end span.Span) {
-	uri := start.URI()
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	spn := span.New(start.URI(), start.Start(), end.End())
-	rng, err := m.Range(spn)
-	if err != nil {
-		t.Fatal(err)
-	}
-	actionsRaw, err := r.server.CodeAction(r.ctx, &protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Range: rng,
-		Context: protocol.CodeActionContext{
-			Only: []protocol.CodeActionKind{"refactor.extract"},
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	var actions []protocol.CodeAction
-	for _, action := range actionsRaw {
-		if action.Command.Title == "Extract function" {
-			actions = append(actions, action)
-		}
-	}
-	// Hack: We assume that we only get one code action per range.
-	// TODO(rstambler): Support multiple code actions per test.
-	if len(actions) == 0 || len(actions) > 1 {
-		t.Fatalf("unexpected number of code actions, want 1, got %v", len(actions))
-	}
-	_, err = r.server.ExecuteCommand(r.ctx, &protocol.ExecuteCommandParams{
-		Command:   actions[0].Command.Command,
-		Arguments: actions[0].Command.Arguments,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	res := <-r.editRecv
-	for u, got := range res {
-		want := string(r.data.Golden(t, "functionextraction_"+tests.SpanName(spn), u.Filename(), func() ([]byte, error) {
-			return []byte(got), nil
-		}))
-		if want != got {
-			t.Errorf("function extraction failed for %s:\n%s", u.Filename(), compare.Text(want, got))
-		}
-	}
-}
-
-func (r *runner) MethodExtraction(t *testing.T, start span.Span, end span.Span) {
-	uri := start.URI()
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	spn := span.New(start.URI(), start.Start(), end.End())
-	rng, err := m.Range(spn)
-	if err != nil {
-		t.Fatal(err)
-	}
-	actionsRaw, err := r.server.CodeAction(r.ctx, &protocol.CodeActionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Range: rng,
-		Context: protocol.CodeActionContext{
-			Only: []protocol.CodeActionKind{"refactor.extract"},
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	var actions []protocol.CodeAction
-	for _, action := range actionsRaw {
-		if action.Command.Title == "Extract method" {
-			actions = append(actions, action)
-		}
-	}
-	// Hack: We assume that we only get one matching code action per range.
-	// TODO(rstambler): Support multiple code actions per test.
-	if len(actions) == 0 || len(actions) > 1 {
-		t.Fatalf("unexpected number of code actions, want 1, got %v", len(actions))
-	}
-	_, err = r.server.ExecuteCommand(r.ctx, &protocol.ExecuteCommandParams{
-		Command:   actions[0].Command.Command,
-		Arguments: actions[0].Command.Arguments,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	res := <-r.editRecv
-	for u, got := range res {
-		want := string(r.data.Golden(t, "methodextraction_"+tests.SpanName(spn), u.Filename(), func() ([]byte, error) {
-			return []byte(got), nil
-		}))
-		if want != got {
-			t.Errorf("method extraction failed for %s:\n%s", u.Filename(), compare.Text(want, got))
-		}
-	}
-}
-
-func (r *runner) Definition(t *testing.T, spn span.Span, d tests.Definition) {
-	sm, err := r.data.Mapper(d.Src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := sm.Location(d.Src)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", d.Src, err)
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-	}
-	var locs []protocol.Location
-	var hover *protocol.Hover
-	if d.IsType {
-		params := &protocol.TypeDefinitionParams{
-			TextDocumentPositionParams: tdpp,
-		}
-		locs, err = r.server.TypeDefinition(r.ctx, params)
-	} else {
-		params := &protocol.DefinitionParams{
-			TextDocumentPositionParams: tdpp,
-		}
-		locs, err = r.server.Definition(r.ctx, params)
-		if err != nil {
-			t.Fatalf("failed for %v: %+v", d.Src, err)
-		}
-		v := &protocol.HoverParams{
-			TextDocumentPositionParams: tdpp,
-		}
-		hover, err = r.server.Hover(r.ctx, v)
-	}
-	if err != nil {
-		t.Fatalf("failed for %v: %v", d.Src, err)
-	}
-	if len(locs) != 1 {
-		t.Errorf("got %d locations for definition, expected 1", len(locs))
-	}
-	didSomething := false
-	if hover != nil {
-		didSomething = true
-		tag := fmt.Sprintf("%s-hoverdef", d.Name)
-		expectHover := string(r.data.Golden(t, tag, d.Src.URI().Filename(), func() ([]byte, error) {
-			return []byte(hover.Contents.Value), nil
-		}))
-		got := tests.StripSubscripts(hover.Contents.Value)
-		expectHover = tests.StripSubscripts(expectHover)
-		if got != expectHover {
-			tests.CheckSameMarkdown(t, got, expectHover)
-		}
-	}
-	if !d.OnlyHover {
-		didSomething = true
-		locURI := locs[0].URI.SpanURI()
-		lm, err := r.data.Mapper(locURI)
-		if err != nil {
-			t.Fatal(err)
-		}
-		if def, err := lm.Span(locs[0]); err != nil {
-			t.Fatalf("failed for %v: %v", locs[0], err)
-		} else if def != d.Def {
-			t.Errorf("for %v got %v want %v", d.Src, def, d.Def)
-		}
-	}
-	if !didSomething {
-		t.Errorf("no tests ran for %s", d.Src.URI())
-	}
-}
-
-func (r *runner) Implementation(t *testing.T, spn span.Span, impls []span.Span) {
-	sm, err := r.data.Mapper(spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := sm.Location(spn)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-	}
-	var locs []protocol.Location
-	params := &protocol.ImplementationParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	locs, err = r.server.Implementation(r.ctx, params)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-	if len(locs) != len(impls) {
-		t.Fatalf("got %d locations for implementation, expected %d", len(locs), len(impls))
-	}
-
-	var results []span.Span
-	for i := range locs {
-		locURI := locs[i].URI.SpanURI()
-		lm, err := r.data.Mapper(locURI)
-		if err != nil {
-			t.Fatal(err)
-		}
-		imp, err := lm.Span(locs[i])
-		if err != nil {
-			t.Fatalf("failed for %v: %v", locs[i], err)
-		}
-		results = append(results, imp)
-	}
-	span.SortSpans(results) // to make tests
-	span.SortSpans(impls)   // deterministic
-
-	for i := range results {
-		if results[i] != impls[i] {
-			t.Errorf("for %dth implementation of %v got %v want %v", i, spn, results[i], impls[i])
-		}
-	}
-}
-
-func (r *runner) Highlight(t *testing.T, src span.Span, locations []span.Span) {
-	m, err := r.data.Mapper(src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := m.Location(src)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", locations[0], err)
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-	}
-	params := &protocol.DocumentHighlightParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	highlights, err := r.server.DocumentHighlight(r.ctx, params)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if len(highlights) != len(locations) {
-		t.Fatalf("got %d highlights for highlight at %v:%v:%v, expected %d", len(highlights), src.URI().Filename(), src.Start().Line(), src.Start().Column(), len(locations))
-	}
-	// Check to make sure highlights have a valid range.
-	var results []span.Span
-	for i := range highlights {
-		h, err := m.RangeSpan(highlights[i].Range)
-		if err != nil {
-			t.Fatalf("failed for %v: %v", highlights[i], err)
-		}
-		results = append(results, h)
-	}
-	// Sort results to make tests deterministic since DocumentHighlight uses a map.
-	span.SortSpans(results)
-	// Check to make sure all the expected highlights are found.
-	for i := range results {
-		if results[i] != locations[i] {
-			t.Errorf("want %v, got %v\n", locations[i], results[i])
-		}
-	}
-}
-
-func (r *runner) Hover(t *testing.T, src span.Span, text string) {
-	m, err := r.data.Mapper(src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := m.Location(src)
-	if err != nil {
-		t.Fatalf("failed for %v", err)
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-	}
-	params := &protocol.HoverParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	hover, err := r.server.Hover(r.ctx, params)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if text == "" {
-		if hover != nil {
-			t.Errorf("want nil, got %v\n", hover)
-		}
-	} else {
-		if hover == nil {
-			t.Fatalf("want hover result to include %s, but got nil", text)
-		}
-		if got := hover.Contents.Value; got != text {
-			t.Errorf("want %v, got %v\n", text, got)
-		}
-		if want, got := loc.Range, hover.Range; want != got {
-			t.Errorf("want range %v, got %v instead", want, got)
-		}
-	}
-}
-
-func (r *runner) References(t *testing.T, src span.Span, itemList []span.Span) {
-	sm, err := r.data.Mapper(src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := sm.Location(src)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", src, err)
-	}
-	for _, includeDeclaration := range []bool{true, false} {
-		t.Run(fmt.Sprintf("refs-declaration-%v", includeDeclaration), func(t *testing.T) {
-			want := make(map[protocol.Location]bool)
-			for i, pos := range itemList {
-				// We don't want the first result if we aren't including the declaration.
-				if i == 0 && !includeDeclaration {
-					continue
-				}
-				m, err := r.data.Mapper(pos.URI())
-				if err != nil {
-					t.Fatal(err)
-				}
-				loc, err := m.Location(pos)
-				if err != nil {
-					t.Fatalf("failed for %v: %v", src, err)
-				}
-				want[loc] = true
-			}
-			params := &protocol.ReferenceParams{
-				TextDocumentPositionParams: protocol.TextDocumentPositionParams{
-					TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-					Position:     loc.Range.Start,
-				},
-				Context: protocol.ReferenceContext{
-					IncludeDeclaration: includeDeclaration,
-				},
-			}
-			got, err := r.server.References(r.ctx, params)
-			if err != nil {
-				t.Fatalf("failed for %v: %v", src, err)
-			}
-			if len(got) != len(want) {
-				t.Errorf("references failed: different lengths got %v want %v", len(got), len(want))
-			}
-			for _, loc := range got {
-				if !want[loc] {
-					t.Errorf("references failed: incorrect references got %v want %v", loc, want)
-				}
-			}
-		})
-	}
-}
-
-func (r *runner) InlayHints(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	filename := uri.Filename()
-
-	hints, err := r.server.InlayHint(r.ctx, &protocol.InlayHintParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		// TODO: add Range
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	// Map inlay hints to text edits.
-	edits := make([]protocol.TextEdit, len(hints))
-	for i, hint := range hints {
-		var paddingLeft, paddingRight string
-		if hint.PaddingLeft {
-			paddingLeft = " "
-		}
-		if hint.PaddingRight {
-			paddingRight = " "
-		}
-		edits[i] = protocol.TextEdit{
-			Range:   protocol.Range{Start: *hint.Position, End: *hint.Position},
-			NewText: fmt.Sprintf("<%s%s%s>", paddingLeft, hint.Label[0].Value, paddingRight),
-		}
-	}
-
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, _, err := source.ApplyProtocolEdits(m, edits)
-	if err != nil {
-		t.Error(err)
-	}
-
-	withinlayHints := string(r.data.Golden(t, "inlayHint", filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-
-	if withinlayHints != got {
-		t.Errorf("inlay hints failed for %s, expected:\n%v\ngot:\n%v", filename, withinlayHints, got)
-	}
-}
-
-func (r *runner) Rename(t *testing.T, spn span.Span, newText string) {
-	tag := fmt.Sprintf("%s-rename", newText)
-
-	uri := spn.URI()
-	filename := uri.Filename()
-	sm, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := sm.Location(spn)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-
-	wedit, err := r.server.Rename(r.ctx, &protocol.RenameParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Position: loc.Range.Start,
-		NewName:  newText,
-	})
-	if err != nil {
-		renamed := string(r.data.Golden(t, tag, filename, func() ([]byte, error) {
-			return []byte(err.Error()), nil
-		}))
-		if err.Error() != renamed {
-			t.Errorf("rename failed for %s, expected:\n%v\ngot:\n%v\n", newText, renamed, err)
-		}
-		return
-	}
-	res, err := applyTextDocumentEdits(r, wedit.DocumentChanges)
-	if err != nil {
-		t.Fatal(err)
-	}
-	var orderedURIs []string
-	for uri := range res {
-		orderedURIs = append(orderedURIs, string(uri))
-	}
-	sort.Strings(orderedURIs)
-
-	var got string
-	for i := 0; i < len(res); i++ {
-		if i != 0 {
-			got += "\n"
-		}
-		uri := span.URIFromURI(orderedURIs[i])
-		if len(res) > 1 {
-			got += filepath.Base(uri.Filename()) + ":\n"
-		}
-		val := res[uri]
-		got += val
-	}
-	want := string(r.data.Golden(t, tag, filename, func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if want != got {
-		t.Errorf("rename failed for %s:\n%s", newText, compare.Text(want, got))
-	}
-}
-
-func (r *runner) PrepareRename(t *testing.T, src span.Span, want *source.PrepareItem) {
-	m, err := r.data.Mapper(src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := m.Location(src)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", src, err)
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{URI: loc.URI},
-		Position:     loc.Range.Start,
-	}
-	params := &protocol.PrepareRenameParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	got, err := r.server.PrepareRename(context.Background(), params)
-	if err != nil {
-		t.Errorf("prepare rename failed for %v: got error: %v", src, err)
-		return
-	}
-
-	// TODO(rfindley): can we consolidate on a single representation for
-	// PrepareRename results, and use cmp.Diff here?
-
-	// PrepareRename may fail with no error if there was no object found at the
-	// position.
-	if got == nil {
-		if want.Text != "" { // expected an ident.
-			t.Errorf("prepare rename failed for %v: got nil", src)
-		}
-		return
-	}
-	if got.Range.Start == got.Range.End {
-		// Special case for 0-length ranges. Marks can't specify a 0-length range,
-		// so just compare the start.
-		if got.Range.Start != want.Range.Start {
-			t.Errorf("prepare rename failed: incorrect point, got %v want %v", got.Range.Start, want.Range.Start)
-		}
-	} else {
-		if got.Range != want.Range {
-			t.Errorf("prepare rename failed: incorrect range got %v want %v", got.Range, want.Range)
-		}
-	}
-	if got.Placeholder != want.Text {
-		t.Errorf("prepare rename failed: incorrect text got %v want %v", got.Placeholder, want.Text)
-	}
-}
-
-func applyTextDocumentEdits(r *runner, edits []protocol.DocumentChanges) (map[span.URI]string, error) {
-	res := map[span.URI]string{}
-	for _, docEdits := range edits {
-		if docEdits.TextDocumentEdit != nil {
-			uri := docEdits.TextDocumentEdit.TextDocument.URI.SpanURI()
-			var m *protocol.ColumnMapper
-			// If we have already edited this file, we use the edited version (rather than the
-			// file in its original state) so that we preserve our initial changes.
-			if content, ok := res[uri]; ok {
-				m = protocol.NewColumnMapper(uri, []byte(content))
-			} else {
-				var err error
-				if m, err = r.data.Mapper(uri); err != nil {
-					return nil, err
-				}
-			}
-			patched, _, err := source.ApplyProtocolEdits(m, docEdits.TextDocumentEdit.Edits)
-			if err != nil {
-				return nil, err
-			}
-			res[uri] = patched
-		}
-	}
-	return res, nil
-}
-
-func (r *runner) Symbols(t *testing.T, uri span.URI, expectedSymbols []protocol.DocumentSymbol) {
-	params := &protocol.DocumentSymbolParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	}
-	got, err := r.server.DocumentSymbol(r.ctx, params)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	symbols := make([]protocol.DocumentSymbol, len(got))
-	for i, s := range got {
-		s, ok := s.(protocol.DocumentSymbol)
-		if !ok {
-			t.Fatalf("%v: wanted []DocumentSymbols but got %v", uri, got)
-		}
-		symbols[i] = s
-	}
-
-	// Sort by position to make it easier to find errors.
-	sortSymbols := func(s []protocol.DocumentSymbol) {
-		sort.Slice(s, func(i, j int) bool {
-			return protocol.CompareRange(s[i].SelectionRange, s[j].SelectionRange) < 0
-		})
-	}
-	sortSymbols(expectedSymbols)
-	sortSymbols(symbols)
-
-	// Ignore 'Range' here as it is difficult (impossible?) to express
-	// multi-line ranges in the packagestest framework.
-	ignoreRange := cmpopts.IgnoreFields(protocol.DocumentSymbol{}, "Range")
-	if diff := cmp.Diff(expectedSymbols, symbols, ignoreRange); diff != "" {
-		t.Errorf("mismatching symbols (-want +got)\n%s", diff)
-	}
-}
-
-func (r *runner) WorkspaceSymbols(t *testing.T, uri span.URI, query string, typ tests.WorkspaceSymbolsTestType) {
-	matcher := tests.WorkspaceSymbolsTestTypeToMatcher(typ)
-
-	original := r.server.session.Options()
-	modified := original
-	modified.SymbolMatcher = matcher
-	r.server.session.SetOptions(modified)
-	defer r.server.session.SetOptions(original)
-
-	params := &protocol.WorkspaceSymbolParams{
-		Query: query,
-	}
-	gotSymbols, err := r.server.Symbol(r.ctx, params)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, err := tests.WorkspaceSymbolsString(r.ctx, r.data, uri, gotSymbols)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got = filepath.ToSlash(tests.Normalize(got, r.normalizers))
-	want := string(r.data.Golden(t, fmt.Sprintf("workspace_symbol-%s-%s", strings.ToLower(string(matcher)), query), uri.Filename(), func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if diff := compare.Text(want, got); diff != "" {
-		t.Error(diff)
-	}
-}
-
-func (r *runner) SignatureHelp(t *testing.T, spn span.Span, want *protocol.SignatureHelp) {
-	m, err := r.data.Mapper(spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := m.Location(spn)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", loc, err)
-	}
-	tdpp := protocol.TextDocumentPositionParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(spn.URI()),
-		},
-		Position: loc.Range.Start,
-	}
-	params := &protocol.SignatureHelpParams{
-		TextDocumentPositionParams: tdpp,
-	}
-	got, err := r.server.SignatureHelp(r.ctx, params)
-	if err != nil {
-		// Only fail if we got an error we did not expect.
-		if want != nil {
-			t.Fatal(err)
-		}
-		return
-	}
-	if want == nil {
-		if got != nil {
-			t.Errorf("expected no signature, got %v", got)
-		}
-		return
-	}
-	if got == nil {
-		t.Fatalf("expected %v, got nil", want)
-	}
-	if diff := tests.DiffSignatures(spn, want, got); diff != "" {
-		t.Error(diff)
-	}
-}
-
-func (r *runner) Link(t *testing.T, uri span.URI, wantLinks []tests.Link) {
-	m, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, err := r.server.DocumentLink(r.ctx, &protocol.DocumentLinkParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	if diff := tests.DiffLinks(m, wantLinks, got); diff != "" {
-		t.Error(diff)
-	}
-}
-
-func (r *runner) AddImport(t *testing.T, uri span.URI, expectedImport string) {
-	cmd, err := command.NewListKnownPackagesCommand("List Known Packages", command.URIArg{
-		URI: protocol.URIFromSpanURI(uri),
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	resp, err := r.server.executeCommand(r.ctx, &protocol.ExecuteCommandParams{
-		Command:   cmd.Command,
-		Arguments: cmd.Arguments,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	res := resp.(command.ListKnownPackagesResult)
-	var hasPkg bool
-	for _, p := range res.Packages {
-		if p == expectedImport {
-			hasPkg = true
-			break
-		}
-	}
-	if !hasPkg {
-		t.Fatalf("%s: got %v packages\nwant contains %q", command.ListKnownPackages, res.Packages, expectedImport)
-	}
-	cmd, err = command.NewAddImportCommand("Add Imports", command.AddImportArgs{
-		URI:        protocol.URIFromSpanURI(uri),
-		ImportPath: expectedImport,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	_, err = r.server.executeCommand(r.ctx, &protocol.ExecuteCommandParams{
-		Command:   cmd.Command,
-		Arguments: cmd.Arguments,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	got := (<-r.editRecv)[uri]
-	want := r.data.Golden(t, "addimport", uri.Filename(), func() ([]byte, error) {
-		return []byte(got), nil
-	})
-	if want == nil {
-		t.Fatalf("golden file %q not found", uri.Filename())
-	}
-	if diff := compare.Text(got, string(want)); diff != "" {
-		t.Errorf("%s mismatch\n%s", command.AddImport, diff)
-	}
-}
-
-func (r *runner) SelectionRanges(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-	sm, err := r.data.Mapper(uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := sm.Location(spn)
-	if err != nil {
-		t.Error(err)
-	}
-
-	ranges, err := r.server.selectionRange(r.ctx, &protocol.SelectionRangeParams{
-		TextDocument: protocol.TextDocumentIdentifier{
-			URI: protocol.URIFromSpanURI(uri),
-		},
-		Positions: []protocol.Position{loc.Range.Start},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	sb := &strings.Builder{}
-	for i, path := range ranges {
-		fmt.Fprintf(sb, "Ranges %d: ", i)
-		rng := path
-		for {
-			s, err := sm.Offset(rng.Range.Start)
-			if err != nil {
-				t.Error(err)
-			}
-			e, err := sm.Offset(rng.Range.End)
-			if err != nil {
-				t.Error(err)
-			}
-
-			var snippet string
-			if e-s < 30 {
-				snippet = string(sm.Content[s:e])
-			} else {
-				snippet = string(sm.Content[s:s+15]) + "..." + string(sm.Content[e-15:e])
-			}
-
-			fmt.Fprintf(sb, "\n\t%v %q", rng.Range, strings.ReplaceAll(snippet, "\n", "\\n"))
-
-			if rng.Parent == nil {
-				break
-			}
-			rng = *rng.Parent
-		}
-		sb.WriteRune('\n')
-	}
-	got := sb.String()
-
-	testName := "selectionrange_" + tests.SpanName(spn)
-	want := r.data.Golden(t, testName, uri.Filename(), func() ([]byte, error) {
-		return []byte(got), nil
-	})
-	if want == nil {
-		t.Fatalf("golden file %q not found", uri.Filename())
-	}
-	if diff := compare.Text(got, string(want)); diff != "" {
-		t.Errorf("%s mismatch\n%s", testName, diff)
-	}
-}
-
-func TestBytesOffset(t *testing.T) {
-	tests := []struct {
-		text string
-		pos  protocol.Position
-		want int
-	}{
-		{text: `a𐐀b`, pos: protocol.Position{Line: 0, Character: 0}, want: 0},
-		{text: `a𐐀b`, pos: protocol.Position{Line: 0, Character: 1}, want: 1},
-		{text: `a𐐀b`, pos: protocol.Position{Line: 0, Character: 2}, want: 1},
-		{text: `a𐐀b`, pos: protocol.Position{Line: 0, Character: 3}, want: 5},
-		{text: `a𐐀b`, pos: protocol.Position{Line: 0, Character: 4}, want: 6},
-		{text: `a𐐀b`, pos: protocol.Position{Line: 0, Character: 5}, want: -1},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 0, Character: 3}, want: 3},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 0, Character: 4}, want: 3},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 1, Character: 0}, want: 4},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 1, Character: 3}, want: 7},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 1, Character: 4}, want: 7},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 2, Character: 0}, want: 8},
-		{text: "aaa\nbbb\n", pos: protocol.Position{Line: 2, Character: 1}, want: -1},
-		{text: "aaa\nbbb\n\n", pos: protocol.Position{Line: 2, Character: 0}, want: 8},
-	}
-
-	for i, test := range tests {
-		fname := fmt.Sprintf("test %d", i)
-		fset := token.NewFileSet()
-		f := fset.AddFile(fname, -1, len(test.text))
-		f.SetLinesForContent([]byte(test.text))
-		uri := span.URIFromPath(fname)
-		mapper := protocol.NewColumnMapper(uri, []byte(test.text))
-		got, err := mapper.Point(test.pos)
-		if err != nil && test.want != -1 {
-			t.Errorf("unexpected error: %v", err)
-		}
-		if err == nil && got.Offset() != test.want {
-			t.Errorf("want %d for %q(Line:%d,Character:%d), but got %d", test.want, test.text, int(test.pos.Line), int(test.pos.Character), got.Offset())
-		}
-	}
-}
-
-func (r *runner) collectDiagnostics(view *cache.View) {
-	if r.diagnostics != nil {
-		return
-	}
-	r.diagnostics = make(map[span.URI][]*source.Diagnostic)
-
-	snapshot, release := view.Snapshot(r.ctx)
-	defer release()
-
-	// Always run diagnostics with analysis.
-	r.server.diagnose(r.ctx, snapshot, true)
-	for uri, reports := range r.server.diagnostics {
-		for _, report := range reports.reports {
-			for _, d := range report.diags {
-				r.diagnostics[uri] = append(r.diagnostics[uri], d)
-			}
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/lsppos/lsppos.go b/gopls/internal/lsp/lsppos/lsppos.go
--- a/gopls/internal/lsp/lsppos/lsppos.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsppos/lsppos.go	1969-12-31 16:00:00
@@ -1,134 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package lsppos provides utilities for working with LSP positions. Much of
-// this functionality is duplicated from the internal/span package, but this
-// package is simpler and more accurate with respect to newline terminated
-// content.
-//
-// See https://microsoft.github.io/language-server-protocol/specification#textDocuments
-// for a description of LSP positions. Notably:
-//   - Positions are specified by a 0-based line count and 0-based utf-16
-//     character offset.
-//   - Positions are line-ending agnostic: there is no way to specify \r|\n or
-//     \n|. Instead the former maps to the end of the current line, and the
-//     latter to the start of the next line.
-package lsppos
-
-import (
-	"bytes"
-	"errors"
-	"sort"
-	"unicode/utf8"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// Mapper maps utf-8 byte offsets to LSP positions for a single file.
-type Mapper struct {
-	nonASCII bool
-	content  []byte
-
-	// Start-of-line positions. If src is newline-terminated, the final entry
-	// will be len(content).
-	lines []int
-}
-
-// NewMapper creates a new Mapper for the given content.
-func NewMapper(content []byte) *Mapper {
-	nlines := bytes.Count(content, []byte("\n"))
-	m := &Mapper{
-		content: content,
-		lines:   make([]int, 1, nlines+1), // initially []int{0}
-	}
-	for offset, b := range content {
-		if b == '\n' {
-			m.lines = append(m.lines, offset+1)
-		}
-		if b >= utf8.RuneSelf {
-			m.nonASCII = true
-		}
-	}
-	return m
-}
-
-// LineColUTF16 returns the 0-based UTF-16 line and character index for the
-// given offset. It returns -1, -1 if offset is out of bounds for the file
-// being mapped.
-func (m *Mapper) LineColUTF16(offset int) (line, char int) {
-	if offset < 0 || offset > len(m.content) {
-		return -1, -1
-	}
-	nextLine := sort.Search(len(m.lines), func(i int) bool {
-		return offset < m.lines[i]
-	})
-	if nextLine == 0 {
-		return -1, -1
-	}
-	line = nextLine - 1
-	start := m.lines[line]
-	var charOffset int
-	if m.nonASCII {
-		charOffset = UTF16len(m.content[start:offset])
-	} else {
-		charOffset = offset - start
-	}
-
-	var eol int
-	if line == len(m.lines)-1 {
-		eol = len(m.content)
-	} else {
-		eol = m.lines[line+1] - 1
-	}
-
-	// Adjustment for line-endings: \r|\n is the same as |\r\n.
-	if offset == eol && offset > 0 && m.content[offset-1] == '\r' {
-		charOffset--
-	}
-
-	return line, charOffset
-}
-
-// Position returns the protocol position corresponding to the given offset. It
-// returns false if offset is out of bounds for the file being mapped.
-func (m *Mapper) Position(offset int) (protocol.Position, bool) {
-	l, c := m.LineColUTF16(offset)
-	if l < 0 {
-		return protocol.Position{}, false
-	}
-	return protocol.Position{
-		Line:      uint32(l),
-		Character: uint32(c),
-	}, true
-}
-
-// Range returns the protocol range corresponding to the given start and end
-// offsets.
-func (m *Mapper) Range(start, end int) (protocol.Range, error) {
-	startPos, ok := m.Position(start)
-	if !ok {
-		return protocol.Range{}, errors.New("invalid start position")
-	}
-	endPos, ok := m.Position(end)
-	if !ok {
-		return protocol.Range{}, errors.New("invalid end position")
-	}
-
-	return protocol.Range{Start: startPos, End: endPos}, nil
-}
-
-// UTF16len returns the UTF-16 length of the UTF-8 encoded content, were it to
-// be re-encoded as UTF-16.
-func UTF16len(buf []byte) int {
-	// This function copies buf, but microbenchmarks showed it to be faster than
-	// using utf8.DecodeRune due to inlining and avoiding bounds checks.
-	cnt := 0
-	for _, r := range string(buf) {
-		cnt++
-		if r >= 1<<16 {
-			cnt++
-		}
-	}
-	return cnt
-}
diff -urN a/gopls/internal/lsp/lsppos/lsppos_test.go b/gopls/internal/lsp/lsppos/lsppos_test.go
--- a/gopls/internal/lsp/lsppos/lsppos_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsppos/lsppos_test.go	1969-12-31 16:00:00
@@ -1,107 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsppos_test
-
-import (
-	"fmt"
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-type testCase struct {
-	content            string      // input text
-	substrOrOffset     interface{} // explicit integer offset, or a substring
-	wantLine, wantChar int         // expected LSP position information
-}
-
-// offset returns the test case byte offset
-func (c testCase) offset() int {
-	switch x := c.substrOrOffset.(type) {
-	case int:
-		return x
-	case string:
-		i := strings.Index(c.content, x)
-		if i < 0 {
-			panic(fmt.Sprintf("%q does not contain substring %q", c.content, x))
-		}
-		return i
-	}
-	panic("substrOrIndex must be an integer or string")
-}
-
-var tests = []testCase{
-	{"a𐐀b", "a", 0, 0},
-	{"a𐐀b", "𐐀", 0, 1},
-	{"a𐐀b", "b", 0, 3},
-	{"a𐐀b\n", "\n", 0, 4},
-	{"a𐐀b\r\n", "\n", 0, 4}, // \r|\n is not a valid position, so we move back to the end of the first line.
-	{"a𐐀b\r\nx", "x", 1, 0},
-	{"a𐐀b\r\nx\ny", "y", 2, 0},
-
-	// Testing EOL and EOF positions
-	{"", 0, 0, 0}, // 0th position of an empty buffer is (0, 0)
-	{"abc", "c", 0, 2},
-	{"abc", 3, 0, 3},
-	{"abc\n", "\n", 0, 3},
-	{"abc\n", 4, 1, 0}, // position after a newline is on the next line
-}
-
-func TestLineChar(t *testing.T) {
-	for _, test := range tests {
-		m := NewMapper([]byte(test.content))
-		offset := test.offset()
-		gotLine, gotChar := m.LineColUTF16(offset)
-		if gotLine != test.wantLine || gotChar != test.wantChar {
-			t.Errorf("LineChar(%d) = (%d,%d), want (%d,%d)", offset, gotLine, gotChar, test.wantLine, test.wantChar)
-		}
-	}
-}
-
-func TestInvalidOffset(t *testing.T) {
-	content := []byte("a𐐀b\r\nx\ny")
-	m := NewMapper(content)
-	for _, offset := range []int{-1, 100} {
-		gotLine, gotChar := m.LineColUTF16(offset)
-		if gotLine != -1 {
-			t.Errorf("LineChar(%d) = (%d,%d), want (-1,-1)", offset, gotLine, gotChar)
-		}
-	}
-}
-
-func TestPosition(t *testing.T) {
-	for _, test := range tests {
-		m := NewMapper([]byte(test.content))
-		offset := test.offset()
-		got, ok := m.Position(offset)
-		if !ok {
-			t.Error("invalid position for", test.substrOrOffset)
-			continue
-		}
-		want := protocol.Position{Line: uint32(test.wantLine), Character: uint32(test.wantChar)}
-		if got != want {
-			t.Errorf("Position(%d) = %v, want %v", offset, got, want)
-		}
-	}
-}
-
-func TestRange(t *testing.T) {
-	for _, test := range tests {
-		m := NewMapper([]byte(test.content))
-		offset := test.offset()
-		got, err := m.Range(0, offset)
-		if err != nil {
-			t.Fatal(err)
-		}
-		want := protocol.Range{
-			End: protocol.Position{Line: uint32(test.wantLine), Character: uint32(test.wantChar)},
-		}
-		if got != want {
-			t.Errorf("Range(%d) = %v, want %v", offset, got, want)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/lsppos/token.go b/gopls/internal/lsp/lsppos/token.go
--- a/gopls/internal/lsp/lsppos/token.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsppos/token.go	1969-12-31 16:00:00
@@ -1,67 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsppos
-
-import (
-	"errors"
-	"go/ast"
-	"go/token"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-)
-
-// TokenMapper maps token.Pos to LSP positions for a single file.
-type TokenMapper struct {
-	// file is used for computing offsets.
-	file *token.File
-
-	// For now, just delegate to a Mapper for position calculation. As an
-	// optimization we could avoid building the mapper and just use the file, but
-	// then have to correctly adjust for newline-terminated files. It is easier
-	// to just delegate unless performance becomes a concern.
-	mapper *Mapper
-}
-
-// NewTokenMapper creates a new TokenMapper for the given content, using the
-// provided file to compute offsets.
-func NewTokenMapper(content []byte, file *token.File) *TokenMapper {
-	return &TokenMapper{
-		file:   file,
-		mapper: NewMapper(content),
-	}
-}
-
-// Position returns the protocol position corresponding to the given pos. It
-// returns false if pos is out of bounds for the file being mapped.
-func (m *TokenMapper) Position(pos token.Pos) (protocol.Position, bool) {
-	offset, err := safetoken.Offset(m.file, pos)
-	if err != nil {
-		return protocol.Position{}, false
-	}
-	return m.mapper.Position(offset)
-}
-
-// Range returns the protocol range corresponding to the given start and end
-// positions. It returns an error if start or end is out of bounds for the file
-// being mapped.
-func (m *TokenMapper) Range(start, end token.Pos) (protocol.Range, error) {
-	startPos, ok := m.Position(start)
-	if !ok {
-		return protocol.Range{}, errors.New("invalid start position")
-	}
-	endPos, ok := m.Position(end)
-	if !ok {
-		return protocol.Range{}, errors.New("invalid end position")
-	}
-
-	return protocol.Range{Start: startPos, End: endPos}, nil
-}
-
-// NodeRange returns the protocol range corresponding to the span of the given
-// node.
-func (m *TokenMapper) NodeRange(n ast.Node) (protocol.Range, error) {
-	return m.Range(n.Pos(), n.End())
-}
diff -urN a/gopls/internal/lsp/lsppos/token_test.go b/gopls/internal/lsp/lsppos/token_test.go
--- a/gopls/internal/lsp/lsppos/token_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsppos/token_test.go	1969-12-31 16:00:00
@@ -1,57 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsppos_test
-
-import (
-	"go/token"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func makeTokenMapper(content []byte) (*TokenMapper, *token.File) {
-	file := token.NewFileSet().AddFile("p.go", -1, len(content))
-	file.SetLinesForContent(content)
-	return NewTokenMapper(content, file), file
-}
-
-func TestInvalidPosition(t *testing.T) {
-	content := []byte("a𐐀b\r\nx\ny")
-	m, _ := makeTokenMapper(content)
-
-	for _, pos := range []token.Pos{-1, 100} {
-		posn, ok := m.Position(pos)
-		if ok {
-			t.Errorf("Position(%d) = %v, want error", pos, posn)
-		}
-	}
-}
-
-func TestTokenPosition(t *testing.T) {
-	for _, test := range tests {
-		m, f := makeTokenMapper([]byte(test.content))
-		pos := token.Pos(f.Base() + test.offset())
-		got, ok := m.Position(pos)
-		if !ok {
-			t.Error("invalid position for", test.substrOrOffset)
-			continue
-		}
-		want := protocol.Position{Line: uint32(test.wantLine), Character: uint32(test.wantChar)}
-		if got != want {
-			t.Errorf("Position(%d) = %v, want %v", pos, got, want)
-		}
-		gotRange, err := m.Range(token.Pos(f.Base()), pos)
-		if err != nil {
-			t.Fatal(err)
-		}
-		wantRange := protocol.Range{
-			End: want,
-		}
-		if gotRange != wantRange {
-			t.Errorf("Range(%d) = %v, want %v", pos, got, want)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/lsprpc/autostart_default.go b/gopls/internal/lsp/lsprpc/autostart_default.go
--- a/gopls/internal/lsp/lsprpc/autostart_default.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/autostart_default.go	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"fmt"
-
-	exec "golang.org/x/sys/execabs"
-)
-
-var (
-	daemonize             = func(*exec.Cmd) {}
-	autoNetworkAddress    = autoNetworkAddressDefault
-	verifyRemoteOwnership = verifyRemoteOwnershipDefault
-)
-
-func runRemote(cmd *exec.Cmd) error {
-	daemonize(cmd)
-	if err := cmd.Start(); err != nil {
-		return fmt.Errorf("starting remote gopls: %w", err)
-	}
-	return nil
-}
-
-// autoNetworkAddressDefault returns the default network and address for the
-// automatically-started gopls remote. See autostart_posix.go for more
-// information.
-func autoNetworkAddressDefault(goplsPath, id string) (network string, address string) {
-	if id != "" {
-		panic("identified remotes are not supported on windows")
-	}
-	return "tcp", "localhost:37374"
-}
-
-func verifyRemoteOwnershipDefault(network, address string) (bool, error) {
-	return true, nil
-}
diff -urN a/gopls/internal/lsp/lsprpc/autostart_posix.go b/gopls/internal/lsp/lsprpc/autostart_posix.go
--- a/gopls/internal/lsp/lsprpc/autostart_posix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/autostart_posix.go	1969-12-31 16:00:00
@@ -1,97 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build darwin || dragonfly || freebsd || linux || netbsd || openbsd || solaris
-// +build darwin dragonfly freebsd linux netbsd openbsd solaris
-
-package lsprpc
-
-import (
-	"crypto/sha256"
-	"errors"
-	"fmt"
-	"log"
-	"os"
-	"os/user"
-	"path/filepath"
-	"strconv"
-	"syscall"
-
-	exec "golang.org/x/sys/execabs"
-)
-
-func init() {
-	daemonize = daemonizePosix
-	autoNetworkAddress = autoNetworkAddressPosix
-	verifyRemoteOwnership = verifyRemoteOwnershipPosix
-}
-
-func daemonizePosix(cmd *exec.Cmd) {
-	cmd.SysProcAttr = &syscall.SysProcAttr{
-		Setsid: true,
-	}
-}
-
-// autoNetworkAddressPosix resolves an id on the 'auto' pseduo-network to a
-// real network and address. On unix, this uses unix domain sockets.
-func autoNetworkAddressPosix(goplsPath, id string) (network string, address string) {
-	// Especially when doing local development or testing, it's important that
-	// the remote gopls instance we connect to is running the same binary as our
-	// forwarder. So we encode a short hash of the binary path into the daemon
-	// socket name. If possible, we also include the buildid in this hash, to
-	// account for long-running processes where the binary has been subsequently
-	// rebuilt.
-	h := sha256.New()
-	cmd := exec.Command("go", "tool", "buildid", goplsPath)
-	cmd.Stdout = h
-	var pathHash []byte
-	if err := cmd.Run(); err == nil {
-		pathHash = h.Sum(nil)
-	} else {
-		log.Printf("error getting current buildid: %v", err)
-		sum := sha256.Sum256([]byte(goplsPath))
-		pathHash = sum[:]
-	}
-	shortHash := fmt.Sprintf("%x", pathHash)[:6]
-	user := os.Getenv("USER")
-	if user == "" {
-		user = "shared"
-	}
-	basename := filepath.Base(goplsPath)
-	idComponent := ""
-	if id != "" {
-		idComponent = "-" + id
-	}
-	runtimeDir := os.TempDir()
-	if xdg := os.Getenv("XDG_RUNTIME_DIR"); xdg != "" {
-		runtimeDir = xdg
-	}
-	return "unix", filepath.Join(runtimeDir, fmt.Sprintf("%s-%s-daemon.%s%s", basename, shortHash, user, idComponent))
-}
-
-func verifyRemoteOwnershipPosix(network, address string) (bool, error) {
-	if network != "unix" {
-		return true, nil
-	}
-	fi, err := os.Stat(address)
-	if err != nil {
-		if os.IsNotExist(err) {
-			return true, nil
-		}
-		return false, fmt.Errorf("checking socket owner: %w", err)
-	}
-	stat, ok := fi.Sys().(*syscall.Stat_t)
-	if !ok {
-		return false, errors.New("fi.Sys() is not a Stat_t")
-	}
-	user, err := user.Current()
-	if err != nil {
-		return false, fmt.Errorf("checking current user: %w", err)
-	}
-	uid, err := strconv.ParseUint(user.Uid, 10, 32)
-	if err != nil {
-		return false, fmt.Errorf("parsing current UID: %w", err)
-	}
-	return stat.Uid == uint32(uid), nil
-}
diff -urN a/gopls/internal/lsp/lsprpc/binder.go b/gopls/internal/lsp/lsprpc/binder.go
--- a/gopls/internal/lsp/lsprpc/binder.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/binder.go	1969-12-31 16:00:00
@@ -1,148 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// The BinderFunc type adapts a bind function to implement the jsonrpc2.Binder
-// interface.
-type BinderFunc func(ctx context.Context, conn *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions
-
-func (f BinderFunc) Bind(ctx context.Context, conn *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions {
-	return f(ctx, conn)
-}
-
-// Middleware defines a transformation of jsonrpc2 Binders, that may be
-// composed to build jsonrpc2 servers.
-type Middleware func(jsonrpc2_v2.Binder) jsonrpc2_v2.Binder
-
-// A ServerFunc is used to construct an LSP server for a given client.
-type ServerFunc func(context.Context, protocol.ClientCloser) protocol.Server
-
-// ServerBinder binds incoming connections to a new server.
-type ServerBinder struct {
-	newServer ServerFunc
-}
-
-func NewServerBinder(newServer ServerFunc) *ServerBinder {
-	return &ServerBinder{newServer: newServer}
-}
-
-func (b *ServerBinder) Bind(ctx context.Context, conn *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions {
-	client := protocol.ClientDispatcherV2(conn)
-	server := b.newServer(ctx, client)
-	serverHandler := protocol.ServerHandlerV2(server)
-	// Wrap the server handler to inject the client into each request context, so
-	// that log events are reflected back to the client.
-	wrapped := jsonrpc2_v2.HandlerFunc(func(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-		ctx = protocol.WithClient(ctx, client)
-		return serverHandler.Handle(ctx, req)
-	})
-	preempter := &canceler{
-		conn: conn,
-	}
-	return jsonrpc2_v2.ConnectionOptions{
-		Handler:   wrapped,
-		Preempter: preempter,
-	}
-}
-
-type canceler struct {
-	conn *jsonrpc2_v2.Connection
-}
-
-func (c *canceler) Preempt(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-	if req.Method != "$/cancelRequest" {
-		return nil, jsonrpc2_v2.ErrNotHandled
-	}
-	var params protocol.CancelParams
-	if err := json.Unmarshal(req.Params, &params); err != nil {
-		return nil, fmt.Errorf("%w: %v", jsonrpc2_v2.ErrParse, err)
-	}
-	var id jsonrpc2_v2.ID
-	switch raw := params.ID.(type) {
-	case float64:
-		id = jsonrpc2_v2.Int64ID(int64(raw))
-	case string:
-		id = jsonrpc2_v2.StringID(raw)
-	default:
-		return nil, fmt.Errorf("%w: invalid ID type %T", jsonrpc2_v2.ErrParse, params.ID)
-	}
-	c.conn.Cancel(id)
-	return nil, nil
-}
-
-type ForwardBinder struct {
-	dialer jsonrpc2_v2.Dialer
-	onBind func(*jsonrpc2_v2.Connection)
-}
-
-func NewForwardBinder(dialer jsonrpc2_v2.Dialer) *ForwardBinder {
-	return &ForwardBinder{
-		dialer: dialer,
-	}
-}
-
-func (b *ForwardBinder) Bind(ctx context.Context, conn *jsonrpc2_v2.Connection) (opts jsonrpc2_v2.ConnectionOptions) {
-	client := protocol.ClientDispatcherV2(conn)
-	clientBinder := NewClientBinder(func(context.Context, protocol.Server) protocol.Client { return client })
-
-	serverConn, err := jsonrpc2_v2.Dial(context.Background(), b.dialer, clientBinder)
-	if err != nil {
-		return jsonrpc2_v2.ConnectionOptions{
-			Handler: jsonrpc2_v2.HandlerFunc(func(context.Context, *jsonrpc2_v2.Request) (interface{}, error) {
-				return nil, fmt.Errorf("%w: %v", jsonrpc2_v2.ErrInternal, err)
-			}),
-		}
-	}
-
-	if b.onBind != nil {
-		b.onBind(serverConn)
-	}
-	server := protocol.ServerDispatcherV2(serverConn)
-	preempter := &canceler{
-		conn: conn,
-	}
-	detached := xcontext.Detach(ctx)
-	go func() {
-		conn.Wait()
-		if err := serverConn.Close(); err != nil {
-			event.Log(detached, fmt.Sprintf("closing remote connection: %v", err))
-		}
-	}()
-	return jsonrpc2_v2.ConnectionOptions{
-		Handler:   protocol.ServerHandlerV2(server),
-		Preempter: preempter,
-	}
-}
-
-// A ClientFunc is used to construct an LSP client for a given server.
-type ClientFunc func(context.Context, protocol.Server) protocol.Client
-
-// ClientBinder binds an LSP client to an incoming connection.
-type ClientBinder struct {
-	newClient ClientFunc
-}
-
-func NewClientBinder(newClient ClientFunc) *ClientBinder {
-	return &ClientBinder{newClient}
-}
-
-func (b *ClientBinder) Bind(ctx context.Context, conn *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions {
-	server := protocol.ServerDispatcherV2(conn)
-	client := b.newClient(ctx, server)
-	return jsonrpc2_v2.ConnectionOptions{
-		Handler: protocol.ClientHandlerV2(client),
-	}
-}
diff -urN a/gopls/internal/lsp/lsprpc/binder_test.go b/gopls/internal/lsp/lsprpc/binder_test.go
--- a/gopls/internal/lsp/lsprpc/binder_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/binder_test.go	1969-12-31 16:00:00
@@ -1,147 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc_test
-
-import (
-	"context"
-	"regexp"
-	"strings"
-	"testing"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-
-	. "golang.org/x/tools/gopls/internal/lsp/lsprpc"
-)
-
-type TestEnv struct {
-	Conns   []*jsonrpc2_v2.Connection
-	Servers []*jsonrpc2_v2.Server
-}
-
-func (e *TestEnv) Shutdown(t *testing.T) {
-	for _, s := range e.Servers {
-		s.Shutdown()
-	}
-	for _, c := range e.Conns {
-		if err := c.Close(); err != nil {
-			t.Error(err)
-		}
-	}
-	for _, s := range e.Servers {
-		if err := s.Wait(); err != nil {
-			t.Error(err)
-		}
-	}
-}
-
-func (e *TestEnv) serve(ctx context.Context, t *testing.T, server jsonrpc2_v2.Binder) (jsonrpc2_v2.Listener, *jsonrpc2_v2.Server) {
-	l, err := jsonrpc2_v2.NetPipeListener(ctx)
-	if err != nil {
-		t.Fatal(err)
-	}
-	s := jsonrpc2_v2.NewServer(ctx, l, server)
-	e.Servers = append(e.Servers, s)
-	return l, s
-}
-
-func (e *TestEnv) dial(ctx context.Context, t *testing.T, dialer jsonrpc2_v2.Dialer, client jsonrpc2_v2.Binder, forwarded bool) *jsonrpc2_v2.Connection {
-	if forwarded {
-		l, _ := e.serve(ctx, t, NewForwardBinder(dialer))
-		dialer = l.Dialer()
-	}
-	conn, err := jsonrpc2_v2.Dial(ctx, dialer, client)
-	if err != nil {
-		t.Fatal(err)
-	}
-	e.Conns = append(e.Conns, conn)
-	return conn
-}
-
-func staticClientBinder(client protocol.Client) jsonrpc2_v2.Binder {
-	f := func(context.Context, protocol.Server) protocol.Client { return client }
-	return NewClientBinder(f)
-}
-
-func staticServerBinder(server protocol.Server) jsonrpc2_v2.Binder {
-	f := func(ctx context.Context, client protocol.ClientCloser) protocol.Server {
-		return server
-	}
-	return NewServerBinder(f)
-}
-
-func TestClientLoggingV2(t *testing.T) {
-	ctx := context.Background()
-
-	for name, forwarded := range map[string]bool{
-		"forwarded":  true,
-		"standalone": false,
-	} {
-		t.Run(name, func(t *testing.T) {
-			client := FakeClient{Logs: make(chan string, 10)}
-			env := new(TestEnv)
-			defer env.Shutdown(t)
-			l, _ := env.serve(ctx, t, staticServerBinder(PingServer{}))
-			conn := env.dial(ctx, t, l.Dialer(), staticClientBinder(client), forwarded)
-
-			if err := protocol.ServerDispatcherV2(conn).DidOpen(ctx, &protocol.DidOpenTextDocumentParams{}); err != nil {
-				t.Errorf("DidOpen: %v", err)
-			}
-			select {
-			case got := <-client.Logs:
-				want := "ping"
-				matched, err := regexp.MatchString(want, got)
-				if err != nil {
-					t.Fatal(err)
-				}
-				if !matched {
-					t.Errorf("got log %q, want a log containing %q", got, want)
-				}
-			case <-time.After(1 * time.Second):
-				t.Error("timeout waiting for client log")
-			}
-		})
-	}
-}
-
-func TestRequestCancellationV2(t *testing.T) {
-	ctx := context.Background()
-
-	for name, forwarded := range map[string]bool{
-		"forwarded":  true,
-		"standalone": false,
-	} {
-		t.Run(name, func(t *testing.T) {
-			server := WaitableServer{
-				Started:   make(chan struct{}),
-				Completed: make(chan error),
-			}
-			env := new(TestEnv)
-			defer env.Shutdown(t)
-			l, _ := env.serve(ctx, t, staticServerBinder(server))
-			client := FakeClient{Logs: make(chan string, 10)}
-			conn := env.dial(ctx, t, l.Dialer(), staticClientBinder(client), forwarded)
-
-			sd := protocol.ServerDispatcherV2(conn)
-			ctx, cancel := context.WithCancel(ctx)
-
-			result := make(chan error)
-			go func() {
-				_, err := sd.Hover(ctx, &protocol.HoverParams{})
-				result <- err
-			}()
-			// Wait for the Hover request to start.
-			<-server.Started
-			cancel()
-			if err := <-result; err == nil {
-				t.Error("nil error for cancelled Hover(), want non-nil")
-			}
-			if err := <-server.Completed; err == nil || !strings.Contains(err.Error(), "cancelled hover") {
-				t.Errorf("Hover(): unexpected server-side error %v", err)
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/lsprpc/commandinterceptor.go b/gopls/internal/lsp/lsprpc/commandinterceptor.go
--- a/gopls/internal/lsp/lsprpc/commandinterceptor.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/commandinterceptor.go	1969-12-31 16:00:00
@@ -1,44 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"context"
-	"encoding/json"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-)
-
-// HandlerMiddleware is a middleware that only modifies the jsonrpc2 handler.
-type HandlerMiddleware func(jsonrpc2_v2.Handler) jsonrpc2_v2.Handler
-
-// BindHandler transforms a HandlerMiddleware into a Middleware.
-func BindHandler(hmw HandlerMiddleware) Middleware {
-	return Middleware(func(binder jsonrpc2_v2.Binder) jsonrpc2_v2.Binder {
-		return BinderFunc(func(ctx context.Context, conn *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions {
-			opts := binder.Bind(ctx, conn)
-			opts.Handler = hmw(opts.Handler)
-			return opts
-		})
-	})
-}
-
-func CommandInterceptor(command string, run func(*protocol.ExecuteCommandParams) (interface{}, error)) Middleware {
-	return BindHandler(func(delegate jsonrpc2_v2.Handler) jsonrpc2_v2.Handler {
-		return jsonrpc2_v2.HandlerFunc(func(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-			if req.Method == "workspace/executeCommand" {
-				var params protocol.ExecuteCommandParams
-				if err := json.Unmarshal(req.Params, &params); err == nil {
-					if params.Command == command {
-						return run(&params)
-					}
-				}
-			}
-
-			return delegate.Handle(ctx, req)
-		})
-	})
-}
diff -urN a/gopls/internal/lsp/lsprpc/commandinterceptor_test.go b/gopls/internal/lsp/lsprpc/commandinterceptor_test.go
--- a/gopls/internal/lsp/lsprpc/commandinterceptor_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/commandinterceptor_test.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc_test
-
-import (
-	"context"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-
-	. "golang.org/x/tools/gopls/internal/lsp/lsprpc"
-)
-
-func TestCommandInterceptor(t *testing.T) {
-	const command = "foo"
-	caught := false
-	intercept := func(_ *protocol.ExecuteCommandParams) (interface{}, error) {
-		caught = true
-		return map[string]interface{}{}, nil
-	}
-
-	ctx := context.Background()
-	env := new(TestEnv)
-	defer env.Shutdown(t)
-	mw := CommandInterceptor(command, intercept)
-	l, _ := env.serve(ctx, t, mw(noopBinder))
-	conn := env.dial(ctx, t, l.Dialer(), noopBinder, false)
-
-	params := &protocol.ExecuteCommandParams{
-		Command: command,
-	}
-	var res interface{}
-	err := conn.Call(ctx, "workspace/executeCommand", params).Await(ctx, &res)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if !caught {
-		t.Errorf("workspace/executeCommand was not intercepted")
-	}
-}
diff -urN a/gopls/internal/lsp/lsprpc/dialer.go b/gopls/internal/lsp/lsprpc/dialer.go
--- a/gopls/internal/lsp/lsprpc/dialer.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/dialer.go	1969-12-31 16:00:00
@@ -1,114 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"context"
-	"fmt"
-	"io"
-	"net"
-	"os"
-	"time"
-
-	exec "golang.org/x/sys/execabs"
-	"golang.org/x/tools/internal/event"
-)
-
-// AutoNetwork is the pseudo network type used to signal that gopls should use
-// automatic discovery to resolve a remote address.
-const AutoNetwork = "auto"
-
-// An AutoDialer is a jsonrpc2 dialer that understands the 'auto' network.
-type AutoDialer struct {
-	network, addr string // the 'real' network and address
-	isAuto        bool   // whether the server is on the 'auto' network
-
-	executable string
-	argFunc    func(network, addr string) []string
-}
-
-func NewAutoDialer(rawAddr string, argFunc func(network, addr string) []string) (*AutoDialer, error) {
-	d := AutoDialer{
-		argFunc: argFunc,
-	}
-	d.network, d.addr = ParseAddr(rawAddr)
-	if d.network == AutoNetwork {
-		d.isAuto = true
-		bin, err := os.Executable()
-		if err != nil {
-			return nil, fmt.Errorf("getting executable: %w", err)
-		}
-		d.executable = bin
-		d.network, d.addr = autoNetworkAddress(bin, d.addr)
-	}
-	return &d, nil
-}
-
-// Dial implements the jsonrpc2.Dialer interface.
-func (d *AutoDialer) Dial(ctx context.Context) (io.ReadWriteCloser, error) {
-	conn, err := d.dialNet(ctx)
-	return conn, err
-}
-
-// TODO(rFindley): remove this once we no longer need to integrate with v1 of
-// the jsonrpc2 package.
-func (d *AutoDialer) dialNet(ctx context.Context) (net.Conn, error) {
-	// Attempt to verify that we own the remote. This is imperfect, but if we can
-	// determine that the remote is owned by a different user, we should fail.
-	ok, err := verifyRemoteOwnership(d.network, d.addr)
-	if err != nil {
-		// If the ownership check itself failed, we fail open but log an error to
-		// the user.
-		event.Error(ctx, "unable to check daemon socket owner, failing open", err)
-	} else if !ok {
-		// We successfully checked that the socket is not owned by us, we fail
-		// closed.
-		return nil, fmt.Errorf("socket %q is owned by a different user", d.addr)
-	}
-	const dialTimeout = 1 * time.Second
-	// Try dialing our remote once, in case it is already running.
-	netConn, err := net.DialTimeout(d.network, d.addr, dialTimeout)
-	if err == nil {
-		return netConn, nil
-	}
-	if d.isAuto && d.argFunc != nil {
-		if d.network == "unix" {
-			// Sometimes the socketfile isn't properly cleaned up when the server
-			// shuts down. Since we have already tried and failed to dial this
-			// address, it should *usually* be safe to remove the socket before
-			// binding to the address.
-			// TODO(rfindley): there is probably a race here if multiple server
-			// instances are simultaneously starting up.
-			if _, err := os.Stat(d.addr); err == nil {
-				if err := os.Remove(d.addr); err != nil {
-					return nil, fmt.Errorf("removing remote socket file: %w", err)
-				}
-			}
-		}
-		args := d.argFunc(d.network, d.addr)
-		cmd := exec.Command(d.executable, args...)
-		if err := runRemote(cmd); err != nil {
-			return nil, err
-		}
-	}
-
-	const retries = 5
-	// It can take some time for the newly started server to bind to our address,
-	// so we retry for a bit.
-	for retry := 0; retry < retries; retry++ {
-		startDial := time.Now()
-		netConn, err = net.DialTimeout(d.network, d.addr, dialTimeout)
-		if err == nil {
-			return netConn, nil
-		}
-		event.Log(ctx, fmt.Sprintf("failed attempt #%d to connect to remote: %v\n", retry+2, err))
-		// In case our failure was a fast-failure, ensure we wait at least
-		// f.dialTimeout before trying again.
-		if retry != retries-1 {
-			time.Sleep(dialTimeout - time.Since(startDial))
-		}
-	}
-	return nil, fmt.Errorf("dialing remote: %w", err)
-}
diff -urN a/gopls/internal/lsp/lsprpc/goenv.go b/gopls/internal/lsp/lsprpc/goenv.go
--- a/gopls/internal/lsp/lsprpc/goenv.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/goenv.go	1969-12-31 16:00:00
@@ -1,96 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"os"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/gocommand"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func GoEnvMiddleware() (Middleware, error) {
-	return BindHandler(func(delegate jsonrpc2_v2.Handler) jsonrpc2_v2.Handler {
-		return jsonrpc2_v2.HandlerFunc(func(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-			if req.Method == "initialize" {
-				if err := addGoEnvToInitializeRequestV2(ctx, req); err != nil {
-					event.Error(ctx, "adding go env to initialize", err)
-				}
-			}
-			return delegate.Handle(ctx, req)
-		})
-	}), nil
-}
-
-func addGoEnvToInitializeRequestV2(ctx context.Context, req *jsonrpc2_v2.Request) error {
-	var params protocol.ParamInitialize
-	if err := json.Unmarshal(req.Params, &params); err != nil {
-		return err
-	}
-	var opts map[string]interface{}
-	switch v := params.InitializationOptions.(type) {
-	case nil:
-		opts = make(map[string]interface{})
-	case map[string]interface{}:
-		opts = v
-	default:
-		return fmt.Errorf("unexpected type for InitializationOptions: %T", v)
-	}
-	envOpt, ok := opts["env"]
-	if !ok {
-		envOpt = make(map[string]interface{})
-	}
-	env, ok := envOpt.(map[string]interface{})
-	if !ok {
-		return fmt.Errorf("env option is %T, expected a map", envOpt)
-	}
-	goenv, err := getGoEnv(ctx, env)
-	if err != nil {
-		return err
-	}
-	// We don't want to propagate GOWORK unless explicitly set since that could mess with
-	// path inference during cmd/go invocations, see golang/go#51825.
-	_, goworkSet := os.LookupEnv("GOWORK")
-	for govar, value := range goenv {
-		if govar == "GOWORK" && !goworkSet {
-			continue
-		}
-		env[govar] = value
-	}
-	opts["env"] = env
-	params.InitializationOptions = opts
-	raw, err := json.Marshal(params)
-	if err != nil {
-		return fmt.Errorf("marshaling updated options: %v", err)
-	}
-	req.Params = json.RawMessage(raw)
-	return nil
-}
-
-func getGoEnv(ctx context.Context, env map[string]interface{}) (map[string]string, error) {
-	var runEnv []string
-	for k, v := range env {
-		runEnv = append(runEnv, fmt.Sprintf("%s=%s", k, v))
-	}
-	runner := gocommand.Runner{}
-	output, err := runner.Run(ctx, gocommand.Invocation{
-		Verb: "env",
-		Args: []string{"-json"},
-		Env:  runEnv,
-	})
-	if err != nil {
-		return nil, err
-	}
-	envmap := make(map[string]string)
-	if err := json.Unmarshal(output.Bytes(), &envmap); err != nil {
-		return nil, err
-	}
-	return envmap, nil
-}
diff -urN a/gopls/internal/lsp/lsprpc/goenv_test.go b/gopls/internal/lsp/lsprpc/goenv_test.go
--- a/gopls/internal/lsp/lsprpc/goenv_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/goenv_test.go	1969-12-31 16:00:00
@@ -1,65 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc_test
-
-import (
-	"context"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-
-	. "golang.org/x/tools/gopls/internal/lsp/lsprpc"
-)
-
-type initServer struct {
-	protocol.Server
-
-	params *protocol.ParamInitialize
-}
-
-func (s *initServer) Initialize(ctx context.Context, params *protocol.ParamInitialize) (*protocol.InitializeResult, error) {
-	s.params = params
-	return &protocol.InitializeResult{}, nil
-}
-
-func TestGoEnvMiddleware(t *testing.T) {
-	ctx := context.Background()
-
-	server := &initServer{}
-	env := new(TestEnv)
-	defer env.Shutdown(t)
-	l, _ := env.serve(ctx, t, staticServerBinder(server))
-	mw, err := GoEnvMiddleware()
-	if err != nil {
-		t.Fatal(err)
-	}
-	binder := mw(NewForwardBinder(l.Dialer()))
-	l, _ = env.serve(ctx, t, binder)
-	conn := env.dial(ctx, t, l.Dialer(), noopBinder, true)
-	dispatch := protocol.ServerDispatcherV2(conn)
-	initParams := &protocol.ParamInitialize{}
-	initParams.InitializationOptions = map[string]interface{}{
-		"env": map[string]interface{}{
-			"GONOPROXY": "example.com",
-		},
-	}
-	if _, err := dispatch.Initialize(ctx, initParams); err != nil {
-		t.Fatal(err)
-	}
-
-	if server.params == nil {
-		t.Fatalf("initialize params are unset")
-	}
-	envOpts := server.params.InitializationOptions.(map[string]interface{})["env"].(map[string]interface{})
-
-	// Check for an arbitrary Go variable. It should be set.
-	if _, ok := envOpts["GOPRIVATE"]; !ok {
-		t.Errorf("Go environment variable GOPRIVATE unset in initialization options")
-	}
-	// Check that the variable present in our user config was not overwritten.
-	if got, want := envOpts["GONOPROXY"], "example.com"; got != want {
-		t.Errorf("GONOPROXY=%q, want %q", got, want)
-	}
-}
diff -urN a/gopls/internal/lsp/lsprpc/lsprpc.go b/gopls/internal/lsp/lsprpc/lsprpc.go
--- a/gopls/internal/lsp/lsprpc/lsprpc.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/lsprpc.go	1969-12-31 16:00:00
@@ -1,543 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package lsprpc implements a jsonrpc2.StreamServer that may be used to
-// serve the LSP on a jsonrpc2 channel.
-package lsprpc
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"log"
-	"net"
-	"os"
-	"strconv"
-	"strings"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/jsonrpc2"
-)
-
-// Unique identifiers for client/server.
-var serverIndex int64
-
-// The StreamServer type is a jsonrpc2.StreamServer that handles incoming
-// streams as a new LSP session, using a shared cache.
-type StreamServer struct {
-	cache *cache.Cache
-	// daemon controls whether or not to log new connections.
-	daemon bool
-
-	// optionsOverrides is passed to newly created sessions.
-	optionsOverrides func(*source.Options)
-
-	// serverForTest may be set to a test fake for testing.
-	serverForTest protocol.Server
-}
-
-// NewStreamServer creates a StreamServer using the shared cache. If
-// withTelemetry is true, each session is instrumented with telemetry that
-// records RPC statistics.
-func NewStreamServer(cache *cache.Cache, daemon bool, optionsFunc func(*source.Options)) *StreamServer {
-	return &StreamServer{cache: cache, daemon: daemon, optionsOverrides: optionsFunc}
-}
-
-func (s *StreamServer) Binder() *ServerBinder {
-	newServer := func(ctx context.Context, client protocol.ClientCloser) protocol.Server {
-		session := cache.NewSession(ctx, s.cache, s.optionsOverrides)
-		server := s.serverForTest
-		if server == nil {
-			server = lsp.NewServer(session, client)
-			if instance := debug.GetInstance(ctx); instance != nil {
-				instance.AddService(server, session)
-			}
-		}
-		return server
-	}
-	return NewServerBinder(newServer)
-}
-
-// ServeStream implements the jsonrpc2.StreamServer interface, by handling
-// incoming streams using a new lsp server.
-func (s *StreamServer) ServeStream(ctx context.Context, conn jsonrpc2.Conn) error {
-	client := protocol.ClientDispatcher(conn)
-	session := cache.NewSession(ctx, s.cache, s.optionsOverrides)
-	server := s.serverForTest
-	if server == nil {
-		server = lsp.NewServer(session, client)
-		if instance := debug.GetInstance(ctx); instance != nil {
-			instance.AddService(server, session)
-		}
-	}
-	// Clients may or may not send a shutdown message. Make sure the server is
-	// shut down.
-	// TODO(rFindley): this shutdown should perhaps be on a disconnected context.
-	defer func() {
-		if err := server.Shutdown(ctx); err != nil {
-			event.Error(ctx, "error shutting down", err)
-		}
-	}()
-	executable, err := os.Executable()
-	if err != nil {
-		log.Printf("error getting gopls path: %v", err)
-		executable = ""
-	}
-	ctx = protocol.WithClient(ctx, client)
-	conn.Go(ctx,
-		protocol.Handlers(
-			handshaker(session, executable, s.daemon,
-				protocol.ServerHandler(server,
-					jsonrpc2.MethodNotFound))))
-	if s.daemon {
-		log.Printf("Session %s: connected", session.ID())
-		defer log.Printf("Session %s: exited", session.ID())
-	}
-	<-conn.Done()
-	return conn.Err()
-}
-
-// A Forwarder is a jsonrpc2.StreamServer that handles an LSP stream by
-// forwarding it to a remote. This is used when the gopls process started by
-// the editor is in the `-remote` mode, which means it finds and connects to a
-// separate gopls daemon. In these cases, we still want the forwarder gopls to
-// be instrumented with telemetry, and want to be able to in some cases hijack
-// the jsonrpc2 connection with the daemon.
-type Forwarder struct {
-	dialer *AutoDialer
-
-	mu sync.Mutex
-	// Hold on to the server connection so that we can redo the handshake if any
-	// information changes.
-	serverConn jsonrpc2.Conn
-	serverID   string
-}
-
-// NewForwarder creates a new Forwarder, ready to forward connections to the
-// remote server specified by rawAddr. If provided and rawAddr indicates an
-// 'automatic' address (starting with 'auto;'), argFunc may be used to start a
-// remote server for the auto-discovered address.
-func NewForwarder(rawAddr string, argFunc func(network, address string) []string) (*Forwarder, error) {
-	dialer, err := NewAutoDialer(rawAddr, argFunc)
-	if err != nil {
-		return nil, err
-	}
-	fwd := &Forwarder{
-		dialer: dialer,
-	}
-	return fwd, nil
-}
-
-// QueryServerState queries the server state of the current server.
-func QueryServerState(ctx context.Context, addr string) (*ServerState, error) {
-	serverConn, err := dialRemote(ctx, addr)
-	if err != nil {
-		return nil, err
-	}
-	var state ServerState
-	if err := protocol.Call(ctx, serverConn, sessionsMethod, nil, &state); err != nil {
-		return nil, fmt.Errorf("querying server state: %w", err)
-	}
-	return &state, nil
-}
-
-// dialRemote is used for making calls into the gopls daemon. addr should be a
-// URL, possibly on the synthetic 'auto' network (e.g. tcp://..., unix://...,
-// or auto://...).
-func dialRemote(ctx context.Context, addr string) (jsonrpc2.Conn, error) {
-	network, address := ParseAddr(addr)
-	if network == AutoNetwork {
-		gp, err := os.Executable()
-		if err != nil {
-			return nil, fmt.Errorf("getting gopls path: %w", err)
-		}
-		network, address = autoNetworkAddress(gp, address)
-	}
-	netConn, err := net.DialTimeout(network, address, 5*time.Second)
-	if err != nil {
-		return nil, fmt.Errorf("dialing remote: %w", err)
-	}
-	serverConn := jsonrpc2.NewConn(jsonrpc2.NewHeaderStream(netConn))
-	serverConn.Go(ctx, jsonrpc2.MethodNotFound)
-	return serverConn, nil
-}
-
-func ExecuteCommand(ctx context.Context, addr string, id string, request, result interface{}) error {
-	serverConn, err := dialRemote(ctx, addr)
-	if err != nil {
-		return err
-	}
-	args, err := command.MarshalArgs(request)
-	if err != nil {
-		return err
-	}
-	params := protocol.ExecuteCommandParams{
-		Command:   id,
-		Arguments: args,
-	}
-	return protocol.Call(ctx, serverConn, "workspace/executeCommand", params, result)
-}
-
-// ServeStream dials the forwarder remote and binds the remote to serve the LSP
-// on the incoming stream.
-func (f *Forwarder) ServeStream(ctx context.Context, clientConn jsonrpc2.Conn) error {
-	client := protocol.ClientDispatcher(clientConn)
-
-	netConn, err := f.dialer.dialNet(ctx)
-	if err != nil {
-		return fmt.Errorf("forwarder: connecting to remote: %w", err)
-	}
-	serverConn := jsonrpc2.NewConn(jsonrpc2.NewHeaderStream(netConn))
-	server := protocol.ServerDispatcher(serverConn)
-
-	// Forward between connections.
-	serverConn.Go(ctx,
-		protocol.Handlers(
-			protocol.ClientHandler(client,
-				jsonrpc2.MethodNotFound)))
-
-	// Don't run the clientConn yet, so that we can complete the handshake before
-	// processing any client messages.
-
-	// Do a handshake with the server instance to exchange debug information.
-	index := atomic.AddInt64(&serverIndex, 1)
-	f.mu.Lock()
-	f.serverConn = serverConn
-	f.serverID = strconv.FormatInt(index, 10)
-	f.mu.Unlock()
-	f.handshake(ctx)
-	clientConn.Go(ctx,
-		protocol.Handlers(
-			f.handler(
-				protocol.ServerHandler(server,
-					jsonrpc2.MethodNotFound))))
-
-	select {
-	case <-serverConn.Done():
-		clientConn.Close()
-	case <-clientConn.Done():
-		serverConn.Close()
-	}
-
-	err = nil
-	if serverConn.Err() != nil {
-		err = fmt.Errorf("remote disconnected: %v", serverConn.Err())
-	} else if clientConn.Err() != nil {
-		err = fmt.Errorf("client disconnected: %v", clientConn.Err())
-	}
-	event.Log(ctx, fmt.Sprintf("forwarder: exited with error: %v", err))
-	return err
-}
-
-// TODO(rfindley): remove this handshaking in favor of middleware.
-func (f *Forwarder) handshake(ctx context.Context) {
-	// This call to os.Execuable is redundant, and will be eliminated by the
-	// transition to the V2 API.
-	goplsPath, err := os.Executable()
-	if err != nil {
-		event.Error(ctx, "getting executable for handshake", err)
-		goplsPath = ""
-	}
-	var (
-		hreq = handshakeRequest{
-			ServerID:  f.serverID,
-			GoplsPath: goplsPath,
-		}
-		hresp handshakeResponse
-	)
-	if di := debug.GetInstance(ctx); di != nil {
-		hreq.Logfile = di.Logfile
-		hreq.DebugAddr = di.ListenedDebugAddress()
-	}
-	if err := protocol.Call(ctx, f.serverConn, handshakeMethod, hreq, &hresp); err != nil {
-		// TODO(rfindley): at some point in the future we should return an error
-		// here.  Handshakes have become functional in nature.
-		event.Error(ctx, "forwarder: gopls handshake failed", err)
-	}
-	if hresp.GoplsPath != goplsPath {
-		event.Error(ctx, "", fmt.Errorf("forwarder: gopls path mismatch: forwarder is %q, remote is %q", goplsPath, hresp.GoplsPath))
-	}
-	event.Log(ctx, "New server",
-		tag.NewServer.Of(f.serverID),
-		tag.Logfile.Of(hresp.Logfile),
-		tag.DebugAddress.Of(hresp.DebugAddr),
-		tag.GoplsPath.Of(hresp.GoplsPath),
-		tag.ClientID.Of(hresp.SessionID),
-	)
-}
-
-func ConnectToRemote(ctx context.Context, addr string) (net.Conn, error) {
-	dialer, err := NewAutoDialer(addr, nil)
-	if err != nil {
-		return nil, err
-	}
-	return dialer.dialNet(ctx)
-}
-
-// handler intercepts messages to the daemon to enrich them with local
-// information.
-func (f *Forwarder) handler(handler jsonrpc2.Handler) jsonrpc2.Handler {
-	return func(ctx context.Context, reply jsonrpc2.Replier, r jsonrpc2.Request) error {
-		// Intercept certain messages to add special handling.
-		switch r.Method() {
-		case "initialize":
-			if newr, err := addGoEnvToInitializeRequest(ctx, r); err == nil {
-				r = newr
-			} else {
-				log.Printf("unable to add local env to initialize request: %v", err)
-			}
-		case "workspace/executeCommand":
-			var params protocol.ExecuteCommandParams
-			if err := json.Unmarshal(r.Params(), &params); err == nil {
-				if params.Command == command.StartDebugging.ID() {
-					var args command.DebuggingArgs
-					if err := command.UnmarshalArgs(params.Arguments, &args); err == nil {
-						reply = f.replyWithDebugAddress(ctx, reply, args)
-					} else {
-						event.Error(ctx, "unmarshaling debugging args", err)
-					}
-				}
-			} else {
-				event.Error(ctx, "intercepting executeCommand request", err)
-			}
-		}
-		// The gopls workspace environment defaults to the process environment in
-		// which gopls daemon was started. To avoid discrepancies in Go environment
-		// between the editor and daemon, inject any unset variables in `go env`
-		// into the options sent by initialize.
-		//
-		// See also golang.org/issue/37830.
-		return handler(ctx, reply, r)
-	}
-}
-
-// addGoEnvToInitializeRequest builds a new initialize request in which we set
-// any environment variables output by `go env` and not already present in the
-// request.
-//
-// It returns an error if r is not an initialize request, or is otherwise
-// malformed.
-func addGoEnvToInitializeRequest(ctx context.Context, r jsonrpc2.Request) (jsonrpc2.Request, error) {
-	var params protocol.ParamInitialize
-	if err := json.Unmarshal(r.Params(), &params); err != nil {
-		return nil, err
-	}
-	var opts map[string]interface{}
-	switch v := params.InitializationOptions.(type) {
-	case nil:
-		opts = make(map[string]interface{})
-	case map[string]interface{}:
-		opts = v
-	default:
-		return nil, fmt.Errorf("unexpected type for InitializationOptions: %T", v)
-	}
-	envOpt, ok := opts["env"]
-	if !ok {
-		envOpt = make(map[string]interface{})
-	}
-	env, ok := envOpt.(map[string]interface{})
-	if !ok {
-		return nil, fmt.Errorf(`env option is %T, expected a map`, envOpt)
-	}
-	goenv, err := getGoEnv(ctx, env)
-	if err != nil {
-		return nil, err
-	}
-	// We don't want to propagate GOWORK unless explicitly set since that could mess with
-	// path inference during cmd/go invocations, see golang/go#51825.
-	_, goworkSet := os.LookupEnv("GOWORK")
-	for govar, value := range goenv {
-		if govar == "GOWORK" && !goworkSet {
-			continue
-		}
-		env[govar] = value
-	}
-	opts["env"] = env
-	params.InitializationOptions = opts
-	call, ok := r.(*jsonrpc2.Call)
-	if !ok {
-		return nil, fmt.Errorf("%T is not a *jsonrpc2.Call", r)
-	}
-	return jsonrpc2.NewCall(call.ID(), "initialize", params)
-}
-
-func (f *Forwarder) replyWithDebugAddress(outerCtx context.Context, r jsonrpc2.Replier, args command.DebuggingArgs) jsonrpc2.Replier {
-	di := debug.GetInstance(outerCtx)
-	if di == nil {
-		event.Log(outerCtx, "no debug instance to start")
-		return r
-	}
-	return func(ctx context.Context, result interface{}, outerErr error) error {
-		if outerErr != nil {
-			return r(ctx, result, outerErr)
-		}
-		// Enrich the result with our own debugging information. Since we're an
-		// intermediary, the jsonrpc2 package has deserialized the result into
-		// maps, by default. Re-do the unmarshalling.
-		raw, err := json.Marshal(result)
-		if err != nil {
-			event.Error(outerCtx, "marshaling intermediate command result", err)
-			return r(ctx, result, err)
-		}
-		var modified command.DebuggingResult
-		if err := json.Unmarshal(raw, &modified); err != nil {
-			event.Error(outerCtx, "unmarshaling intermediate command result", err)
-			return r(ctx, result, err)
-		}
-		addr := args.Addr
-		if addr == "" {
-			addr = "localhost:0"
-		}
-		addr, err = di.Serve(outerCtx, addr)
-		if err != nil {
-			event.Error(outerCtx, "starting debug server", err)
-			return r(ctx, result, outerErr)
-		}
-		urls := []string{"http://" + addr}
-		modified.URLs = append(urls, modified.URLs...)
-		go f.handshake(ctx)
-		return r(ctx, modified, nil)
-	}
-}
-
-// A handshakeRequest identifies a client to the LSP server.
-type handshakeRequest struct {
-	// ServerID is the ID of the server on the client. This should usually be 0.
-	ServerID string `json:"serverID"`
-	// Logfile is the location of the clients log file.
-	Logfile string `json:"logfile"`
-	// DebugAddr is the client debug address.
-	DebugAddr string `json:"debugAddr"`
-	// GoplsPath is the path to the Gopls binary running the current client
-	// process.
-	GoplsPath string `json:"goplsPath"`
-}
-
-// A handshakeResponse is returned by the LSP server to tell the LSP client
-// information about its session.
-type handshakeResponse struct {
-	// SessionID is the server session associated with the client.
-	SessionID string `json:"sessionID"`
-	// Logfile is the location of the server logs.
-	Logfile string `json:"logfile"`
-	// DebugAddr is the server debug address.
-	DebugAddr string `json:"debugAddr"`
-	// GoplsPath is the path to the Gopls binary running the current server
-	// process.
-	GoplsPath string `json:"goplsPath"`
-}
-
-// ClientSession identifies a current client LSP session on the server. Note
-// that it looks similar to handshakeResposne, but in fact 'Logfile' and
-// 'DebugAddr' now refer to the client.
-type ClientSession struct {
-	SessionID string `json:"sessionID"`
-	Logfile   string `json:"logfile"`
-	DebugAddr string `json:"debugAddr"`
-}
-
-// ServerState holds information about the gopls daemon process, including its
-// debug information and debug information of all of its current connected
-// clients.
-type ServerState struct {
-	Logfile         string          `json:"logfile"`
-	DebugAddr       string          `json:"debugAddr"`
-	GoplsPath       string          `json:"goplsPath"`
-	CurrentClientID string          `json:"currentClientID"`
-	Clients         []ClientSession `json:"clients"`
-}
-
-const (
-	handshakeMethod = "gopls/handshake"
-	sessionsMethod  = "gopls/sessions"
-)
-
-func handshaker(session *cache.Session, goplsPath string, logHandshakes bool, handler jsonrpc2.Handler) jsonrpc2.Handler {
-	return func(ctx context.Context, reply jsonrpc2.Replier, r jsonrpc2.Request) error {
-		switch r.Method() {
-		case handshakeMethod:
-			// We log.Printf in this handler, rather than event.Log when we want logs
-			// to go to the daemon log rather than being reflected back to the
-			// client.
-			var req handshakeRequest
-			if err := json.Unmarshal(r.Params(), &req); err != nil {
-				if logHandshakes {
-					log.Printf("Error processing handshake for session %s: %v", session.ID(), err)
-				}
-				sendError(ctx, reply, err)
-				return nil
-			}
-			if logHandshakes {
-				log.Printf("Session %s: got handshake. Logfile: %q, Debug addr: %q", session.ID(), req.Logfile, req.DebugAddr)
-			}
-			event.Log(ctx, "Handshake session update",
-				cache.KeyUpdateSession.Of(session),
-				tag.DebugAddress.Of(req.DebugAddr),
-				tag.Logfile.Of(req.Logfile),
-				tag.ServerID.Of(req.ServerID),
-				tag.GoplsPath.Of(req.GoplsPath),
-			)
-			resp := handshakeResponse{
-				SessionID: session.ID(),
-				GoplsPath: goplsPath,
-			}
-			if di := debug.GetInstance(ctx); di != nil {
-				resp.Logfile = di.Logfile
-				resp.DebugAddr = di.ListenedDebugAddress()
-			}
-			return reply(ctx, resp, nil)
-
-		case sessionsMethod:
-			resp := ServerState{
-				GoplsPath:       goplsPath,
-				CurrentClientID: session.ID(),
-			}
-			if di := debug.GetInstance(ctx); di != nil {
-				resp.Logfile = di.Logfile
-				resp.DebugAddr = di.ListenedDebugAddress()
-				for _, c := range di.State.Clients() {
-					resp.Clients = append(resp.Clients, ClientSession{
-						SessionID: c.Session.ID(),
-						Logfile:   c.Logfile,
-						DebugAddr: c.DebugAddress,
-					})
-				}
-			}
-			return reply(ctx, resp, nil)
-		}
-		return handler(ctx, reply, r)
-	}
-}
-
-func sendError(ctx context.Context, reply jsonrpc2.Replier, err error) {
-	err = fmt.Errorf("%v: %w", err, jsonrpc2.ErrParse)
-	if err := reply(ctx, nil, err); err != nil {
-		event.Error(ctx, "", err)
-	}
-}
-
-// ParseAddr parses the address of a gopls remote.
-// TODO(rFindley): further document this syntax, and allow URI-style remote
-// addresses such as "auto://...".
-func ParseAddr(listen string) (network string, address string) {
-	// Allow passing just -remote=auto, as a shorthand for using automatic remote
-	// resolution.
-	if listen == AutoNetwork {
-		return AutoNetwork, ""
-	}
-	if parts := strings.SplitN(listen, ";", 2); len(parts) == 2 {
-		return parts[0], parts[1]
-	}
-	return "tcp", listen
-}
diff -urN a/gopls/internal/lsp/lsprpc/lsprpc_test.go b/gopls/internal/lsp/lsprpc/lsprpc_test.go
--- a/gopls/internal/lsp/lsprpc/lsprpc_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/lsprpc_test.go	1969-12-31 16:00:00
@@ -1,344 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"context"
-	"errors"
-	"regexp"
-	"strings"
-	"testing"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-)
-
-type FakeClient struct {
-	protocol.Client
-
-	Logs chan string
-}
-
-func (c FakeClient) LogMessage(ctx context.Context, params *protocol.LogMessageParams) error {
-	c.Logs <- params.Message
-	return nil
-}
-
-// fakeServer is intended to be embedded in the test fakes below, to trivially
-// implement Shutdown.
-type fakeServer struct {
-	protocol.Server
-}
-
-func (fakeServer) Shutdown(ctx context.Context) error {
-	return nil
-}
-
-type PingServer struct{ fakeServer }
-
-func (s PingServer) DidOpen(ctx context.Context, params *protocol.DidOpenTextDocumentParams) error {
-	event.Log(ctx, "ping")
-	return nil
-}
-
-func TestClientLogging(t *testing.T) {
-	ctx, cancel := context.WithCancel(context.Background())
-	defer cancel()
-
-	server := PingServer{}
-	client := FakeClient{Logs: make(chan string, 10)}
-
-	ctx = debug.WithInstance(ctx, "", "")
-	ss := NewStreamServer(cache.New(nil, nil), false, nil)
-	ss.serverForTest = server
-	ts := servertest.NewPipeServer(ss, nil)
-	defer checkClose(t, ts.Close)
-	cc := ts.Connect(ctx)
-	cc.Go(ctx, protocol.ClientHandler(client, jsonrpc2.MethodNotFound))
-
-	if err := protocol.ServerDispatcher(cc).DidOpen(ctx, &protocol.DidOpenTextDocumentParams{}); err != nil {
-		t.Errorf("DidOpen: %v", err)
-	}
-
-	select {
-	case got := <-client.Logs:
-		want := "ping"
-		matched, err := regexp.MatchString(want, got)
-		if err != nil {
-			t.Fatal(err)
-		}
-		if !matched {
-			t.Errorf("got log %q, want a log containing %q", got, want)
-		}
-	case <-time.After(1 * time.Second):
-		t.Error("timeout waiting for client log")
-	}
-}
-
-// WaitableServer instruments LSP request so that we can control their timing.
-// The requests chosen are arbitrary: we simply needed one that blocks, and
-// another that doesn't.
-type WaitableServer struct {
-	fakeServer
-
-	Started   chan struct{}
-	Completed chan error
-}
-
-func (s WaitableServer) Hover(ctx context.Context, _ *protocol.HoverParams) (_ *protocol.Hover, err error) {
-	s.Started <- struct{}{}
-	defer func() {
-		s.Completed <- err
-	}()
-	select {
-	case <-ctx.Done():
-		return nil, errors.New("cancelled hover")
-	case <-time.After(10 * time.Second):
-	}
-	return &protocol.Hover{}, nil
-}
-
-func (s WaitableServer) ResolveCompletionItem(_ context.Context, item *protocol.CompletionItem) (*protocol.CompletionItem, error) {
-	return item, nil
-}
-
-func checkClose(t *testing.T, closer func() error) {
-	t.Helper()
-	if err := closer(); err != nil {
-		t.Errorf("closing: %v", err)
-	}
-}
-
-func setupForwarding(ctx context.Context, t *testing.T, s protocol.Server) (direct, forwarded servertest.Connector, cleanup func()) {
-	t.Helper()
-	serveCtx := debug.WithInstance(ctx, "", "")
-	ss := NewStreamServer(cache.New(nil, nil), false, nil)
-	ss.serverForTest = s
-	tsDirect := servertest.NewTCPServer(serveCtx, ss, nil)
-
-	forwarder, err := NewForwarder("tcp;"+tsDirect.Addr, nil)
-	if err != nil {
-		t.Fatal(err)
-	}
-	tsForwarded := servertest.NewPipeServer(forwarder, nil)
-	return tsDirect, tsForwarded, func() {
-		checkClose(t, tsDirect.Close)
-		checkClose(t, tsForwarded.Close)
-	}
-}
-
-func TestRequestCancellation(t *testing.T) {
-	ctx := context.Background()
-	server := WaitableServer{
-		Started:   make(chan struct{}),
-		Completed: make(chan error),
-	}
-	tsDirect, tsForwarded, cleanup := setupForwarding(ctx, t, server)
-	defer cleanup()
-	tests := []struct {
-		serverType string
-		ts         servertest.Connector
-	}{
-		{"direct", tsDirect},
-		{"forwarder", tsForwarded},
-	}
-
-	for _, test := range tests {
-		t.Run(test.serverType, func(t *testing.T) {
-			cc := test.ts.Connect(ctx)
-			sd := protocol.ServerDispatcher(cc)
-			cc.Go(ctx,
-				protocol.Handlers(
-					jsonrpc2.MethodNotFound))
-
-			ctx := context.Background()
-			ctx, cancel := context.WithCancel(ctx)
-
-			result := make(chan error)
-			go func() {
-				_, err := sd.Hover(ctx, &protocol.HoverParams{})
-				result <- err
-			}()
-			// Wait for the Hover request to start.
-			<-server.Started
-			cancel()
-			if err := <-result; err == nil {
-				t.Error("nil error for cancelled Hover(), want non-nil")
-			}
-			if err := <-server.Completed; err == nil || !strings.Contains(err.Error(), "cancelled hover") {
-				t.Errorf("Hover(): unexpected server-side error %v", err)
-			}
-		})
-	}
-}
-
-const exampleProgram = `
--- go.mod --
-module mod
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hello World.")
-}`
-
-func TestDebugInfoLifecycle(t *testing.T) {
-	sb, err := fake.NewSandbox(&fake.SandboxConfig{Files: fake.UnpackTxt(exampleProgram)})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer func() {
-		if err := sb.Close(); err != nil {
-			// TODO(golang/go#38490): we can't currently make this an error because
-			// it fails on Windows: the workspace directory is still locked by a
-			// separate Go process.
-			// Once we have a reliable way to wait for proper shutdown, make this an
-			// error.
-			t.Logf("closing workspace failed: %v", err)
-		}
-	}()
-
-	baseCtx, cancel := context.WithCancel(context.Background())
-	defer cancel()
-	clientCtx := debug.WithInstance(baseCtx, "", "")
-	serverCtx := debug.WithInstance(baseCtx, "", "")
-
-	cache := cache.New(nil, nil)
-	ss := NewStreamServer(cache, false, nil)
-	tsBackend := servertest.NewTCPServer(serverCtx, ss, nil)
-
-	forwarder, err := NewForwarder("tcp;"+tsBackend.Addr, nil)
-	if err != nil {
-		t.Fatal(err)
-	}
-	tsForwarder := servertest.NewPipeServer(forwarder, nil)
-
-	ed1, err := fake.NewEditor(sb, fake.EditorConfig{}).Connect(clientCtx, tsForwarder, fake.ClientHooks{})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer ed1.Close(clientCtx)
-	ed2, err := fake.NewEditor(sb, fake.EditorConfig{}).Connect(baseCtx, tsBackend, fake.ClientHooks{})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer ed2.Close(baseCtx)
-
-	serverDebug := debug.GetInstance(serverCtx)
-	if got, want := len(serverDebug.State.Clients()), 2; got != want {
-		t.Errorf("len(server:Clients) = %d, want %d", got, want)
-	}
-	if got, want := len(serverDebug.State.Sessions()), 2; got != want {
-		t.Errorf("len(server:Sessions) = %d, want %d", got, want)
-	}
-	clientDebug := debug.GetInstance(clientCtx)
-	if got, want := len(clientDebug.State.Servers()), 1; got != want {
-		t.Errorf("len(client:Servers) = %d, want %d", got, want)
-	}
-	// Close one of the connections to verify that the client and session were
-	// dropped.
-	if err := ed1.Close(clientCtx); err != nil {
-		t.Fatal(err)
-	}
-	/*TODO: at this point we have verified the editor is closed
-	However there is no way currently to wait for all associated go routines to
-	go away, and we need to wait for those to trigger the client drop
-	for now we just give it a little bit of time, but we need to fix this
-	in a principled way
-	*/
-	start := time.Now()
-	delay := time.Millisecond
-	const maxWait = time.Second
-	for len(serverDebug.State.Clients()) > 1 {
-		if time.Since(start) > maxWait {
-			break
-		}
-		time.Sleep(delay)
-		delay *= 2
-	}
-	if got, want := len(serverDebug.State.Clients()), 1; got != want {
-		t.Errorf("len(server:Clients) = %d, want %d", got, want)
-	}
-	if got, want := len(serverDebug.State.Sessions()), 1; got != want {
-		t.Errorf("len(server:Sessions()) = %d, want %d", got, want)
-	}
-}
-
-type initServer struct {
-	fakeServer
-
-	params *protocol.ParamInitialize
-}
-
-func (s *initServer) Initialize(ctx context.Context, params *protocol.ParamInitialize) (*protocol.InitializeResult, error) {
-	s.params = params
-	return &protocol.InitializeResult{}, nil
-}
-
-func TestEnvForwarding(t *testing.T) {
-	ctx := context.Background()
-
-	server := &initServer{}
-	_, tsForwarded, cleanup := setupForwarding(ctx, t, server)
-	defer cleanup()
-
-	conn := tsForwarded.Connect(ctx)
-	conn.Go(ctx, jsonrpc2.MethodNotFound)
-	dispatch := protocol.ServerDispatcher(conn)
-	initParams := &protocol.ParamInitialize{}
-	initParams.InitializationOptions = map[string]interface{}{
-		"env": map[string]interface{}{
-			"GONOPROXY": "example.com",
-		},
-	}
-	_, err := dispatch.Initialize(ctx, initParams)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if server.params == nil {
-		t.Fatalf("initialize params are unset")
-	}
-	env := server.params.InitializationOptions.(map[string]interface{})["env"].(map[string]interface{})
-
-	// Check for an arbitrary Go variable. It should be set.
-	if _, ok := env["GOPRIVATE"]; !ok {
-		t.Errorf("Go environment variable GOPRIVATE unset in initialization options")
-	}
-	// Check that the variable present in our user config was not overwritten.
-	if v := env["GONOPROXY"]; v != "example.com" {
-		t.Errorf("GONOPROXY environment variable was overwritten")
-	}
-}
-
-func TestListenParsing(t *testing.T) {
-	tests := []struct {
-		input, wantNetwork, wantAddr string
-	}{
-		{"127.0.0.1:0", "tcp", "127.0.0.1:0"},
-		{"unix;/tmp/sock", "unix", "/tmp/sock"},
-		{"auto", "auto", ""},
-		{"auto;foo", "auto", "foo"},
-	}
-
-	for _, test := range tests {
-		gotNetwork, gotAddr := ParseAddr(test.input)
-		if gotNetwork != test.wantNetwork {
-			t.Errorf("network = %q, want %q", gotNetwork, test.wantNetwork)
-		}
-		if gotAddr != test.wantAddr {
-			t.Errorf("addr = %q, want %q", gotAddr, test.wantAddr)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/lsprpc/middleware.go b/gopls/internal/lsp/lsprpc/middleware.go
--- a/gopls/internal/lsp/lsprpc/middleware.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/middleware.go	1969-12-31 16:00:00
@@ -1,142 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"sync"
-
-	"golang.org/x/tools/internal/event"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-)
-
-// Metadata holds arbitrary data transferred between jsonrpc2 peers.
-type Metadata map[string]interface{}
-
-// PeerInfo holds information about a peering between jsonrpc2 servers.
-type PeerInfo struct {
-	// RemoteID is the identity of the current server on its peer.
-	RemoteID int64
-
-	// LocalID is the identity of the peer on the server.
-	LocalID int64
-
-	// IsClient reports whether the peer is a client. If false, the peer is a
-	// server.
-	IsClient bool
-
-	// Metadata holds arbitrary information provided by the peer.
-	Metadata Metadata
-}
-
-// Handshaker handles both server and client handshaking over jsonrpc2. To
-// instrument server-side handshaking, use Handshaker.Middleware. To instrument
-// client-side handshaking, call Handshaker.ClientHandshake for any new
-// client-side connections.
-type Handshaker struct {
-	// Metadata will be shared with peers via handshaking.
-	Metadata Metadata
-
-	mu     sync.Mutex
-	prevID int64
-	peers  map[int64]PeerInfo
-}
-
-// Peers returns the peer info this handshaker knows about by way of either the
-// server-side handshake middleware, or client-side handshakes.
-func (h *Handshaker) Peers() []PeerInfo {
-	h.mu.Lock()
-	defer h.mu.Unlock()
-
-	var c []PeerInfo
-	for _, v := range h.peers {
-		c = append(c, v)
-	}
-	return c
-}
-
-// Middleware is a jsonrpc2 middleware function to augment connection binding
-// to handle the handshake method, and record disconnections.
-func (h *Handshaker) Middleware(inner jsonrpc2_v2.Binder) jsonrpc2_v2.Binder {
-	return BinderFunc(func(ctx context.Context, conn *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions {
-		opts := inner.Bind(ctx, conn)
-
-		localID := h.nextID()
-		info := &PeerInfo{
-			RemoteID: localID,
-			Metadata: h.Metadata,
-		}
-
-		// Wrap the delegated handler to accept the handshake.
-		delegate := opts.Handler
-		opts.Handler = jsonrpc2_v2.HandlerFunc(func(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-			if req.Method == handshakeMethod {
-				var peerInfo PeerInfo
-				if err := json.Unmarshal(req.Params, &peerInfo); err != nil {
-					return nil, fmt.Errorf("%w: unmarshaling client info: %v", jsonrpc2_v2.ErrInvalidParams, err)
-				}
-				peerInfo.LocalID = localID
-				peerInfo.IsClient = true
-				h.recordPeer(peerInfo)
-				return info, nil
-			}
-			return delegate.Handle(ctx, req)
-		})
-
-		// Record the dropped client.
-		go h.cleanupAtDisconnect(conn, localID)
-
-		return opts
-	})
-}
-
-// ClientHandshake performs a client-side handshake with the server at the
-// other end of conn, recording the server's peer info and watching for conn's
-// disconnection.
-func (h *Handshaker) ClientHandshake(ctx context.Context, conn *jsonrpc2_v2.Connection) {
-	localID := h.nextID()
-	info := &PeerInfo{
-		RemoteID: localID,
-		Metadata: h.Metadata,
-	}
-
-	call := conn.Call(ctx, handshakeMethod, info)
-	var serverInfo PeerInfo
-	if err := call.Await(ctx, &serverInfo); err != nil {
-		event.Error(ctx, "performing handshake", err)
-		return
-	}
-	serverInfo.LocalID = localID
-	h.recordPeer(serverInfo)
-
-	go h.cleanupAtDisconnect(conn, localID)
-}
-
-func (h *Handshaker) nextID() int64 {
-	h.mu.Lock()
-	defer h.mu.Unlock()
-
-	h.prevID++
-	return h.prevID
-}
-
-func (h *Handshaker) cleanupAtDisconnect(conn *jsonrpc2_v2.Connection, peerID int64) {
-	conn.Wait()
-
-	h.mu.Lock()
-	defer h.mu.Unlock()
-	delete(h.peers, peerID)
-}
-
-func (h *Handshaker) recordPeer(info PeerInfo) {
-	h.mu.Lock()
-	defer h.mu.Unlock()
-	if h.peers == nil {
-		h.peers = make(map[int64]PeerInfo)
-	}
-	h.peers[info.LocalID] = info
-}
diff -urN a/gopls/internal/lsp/lsprpc/middleware_test.go b/gopls/internal/lsp/lsprpc/middleware_test.go
--- a/gopls/internal/lsp/lsprpc/middleware_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/lsprpc/middleware_test.go	1969-12-31 16:00:00
@@ -1,93 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsprpc_test
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"testing"
-	"time"
-
-	. "golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-)
-
-var noopBinder = BinderFunc(func(context.Context, *jsonrpc2_v2.Connection) jsonrpc2_v2.ConnectionOptions {
-	return jsonrpc2_v2.ConnectionOptions{}
-})
-
-func TestHandshakeMiddleware(t *testing.T) {
-	sh := &Handshaker{
-		Metadata: Metadata{
-			"answer": 42,
-		},
-	}
-	ctx := context.Background()
-	env := new(TestEnv)
-	defer env.Shutdown(t)
-	l, _ := env.serve(ctx, t, sh.Middleware(noopBinder))
-	conn := env.dial(ctx, t, l.Dialer(), noopBinder, false)
-	ch := &Handshaker{
-		Metadata: Metadata{
-			"question": 6 * 9,
-		},
-	}
-
-	check := func(connected bool) error {
-		clients := sh.Peers()
-		servers := ch.Peers()
-		want := 0
-		if connected {
-			want = 1
-		}
-		if got := len(clients); got != want {
-			return fmt.Errorf("got %d clients on the server, want %d", got, want)
-		}
-		if got := len(servers); got != want {
-			return fmt.Errorf("got %d servers on the client, want %d", got, want)
-		}
-		if !connected {
-			return nil
-		}
-		client := clients[0]
-		server := servers[0]
-		if _, ok := client.Metadata["question"]; !ok {
-			return errors.New("no client metadata")
-		}
-		if _, ok := server.Metadata["answer"]; !ok {
-			return errors.New("no server metadata")
-		}
-		if client.LocalID != server.RemoteID {
-			return fmt.Errorf("client.LocalID == %d, server.PeerID == %d", client.LocalID, server.RemoteID)
-		}
-		if client.RemoteID != server.LocalID {
-			return fmt.Errorf("client.PeerID == %d, server.LocalID == %d", client.RemoteID, server.LocalID)
-		}
-		return nil
-	}
-
-	if err := check(false); err != nil {
-		t.Fatalf("before handshake: %v", err)
-	}
-	ch.ClientHandshake(ctx, conn)
-	if err := check(true); err != nil {
-		t.Fatalf("after handshake: %v", err)
-	}
-	conn.Close()
-	// Wait for up to ~2s for connections to get cleaned up.
-	delay := 25 * time.Millisecond
-	for retries := 3; retries >= 0; retries-- {
-		time.Sleep(delay)
-		err := check(false)
-		if err == nil {
-			return
-		}
-		if retries == 0 {
-			t.Fatalf("after closing connection: %v", err)
-		}
-		delay *= 4
-	}
-}
diff -urN a/gopls/internal/lsp/mod/code_lens.go b/gopls/internal/lsp/mod/code_lens.go
--- a/gopls/internal/lsp/mod/code_lens.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/code_lens.go	1969-12-31 16:00:00
@@ -1,191 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package mod
-
-import (
-	"context"
-	"fmt"
-	"os"
-	"path/filepath"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-// LensFuncs returns the supported lensFuncs for go.mod files.
-func LensFuncs() map[command.Command]source.LensFunc {
-	return map[command.Command]source.LensFunc{
-		command.UpgradeDependency: upgradeLenses,
-		command.Tidy:              tidyLens,
-		command.Vendor:            vendorLens,
-		command.RunGovulncheck:    vulncheckLenses,
-	}
-}
-
-func upgradeLenses(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.CodeLens, error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil || pm.File == nil {
-		return nil, err
-	}
-	uri := protocol.URIFromSpanURI(fh.URI())
-	reset, err := command.NewResetGoModDiagnosticsCommand("Reset go.mod diagnostics", command.ResetGoModDiagnosticsArgs{URIArg: command.URIArg{URI: uri}})
-	if err != nil {
-		return nil, err
-	}
-	// Put the `Reset go.mod diagnostics` codelens on the module statement.
-	modrng, err := moduleStmtRange(fh, pm)
-	if err != nil {
-		return nil, err
-	}
-	lenses := []protocol.CodeLens{{Range: modrng, Command: reset}}
-	if len(pm.File.Require) == 0 {
-		// Nothing to upgrade.
-		return lenses, nil
-	}
-	var requires []string
-	for _, req := range pm.File.Require {
-		requires = append(requires, req.Mod.Path)
-	}
-	checkUpgrade, err := command.NewCheckUpgradesCommand("Check for upgrades", command.CheckUpgradesArgs{
-		URI:     uri,
-		Modules: requires,
-	})
-	if err != nil {
-		return nil, err
-	}
-	upgradeTransitive, err := command.NewUpgradeDependencyCommand("Upgrade transitive dependencies", command.DependencyArgs{
-		URI:        uri,
-		AddRequire: false,
-		GoCmdArgs:  []string{"-d", "-u", "-t", "./..."},
-	})
-	if err != nil {
-		return nil, err
-	}
-	upgradeDirect, err := command.NewUpgradeDependencyCommand("Upgrade direct dependencies", command.DependencyArgs{
-		URI:        uri,
-		AddRequire: false,
-		GoCmdArgs:  append([]string{"-d"}, requires...),
-	})
-	if err != nil {
-		return nil, err
-	}
-
-	// Put the upgrade code lenses above the first require block or statement.
-	rng, err := firstRequireRange(fh, pm)
-	if err != nil {
-		return nil, err
-	}
-
-	return append(lenses, []protocol.CodeLens{
-		{Range: rng, Command: checkUpgrade},
-		{Range: rng, Command: upgradeTransitive},
-		{Range: rng, Command: upgradeDirect},
-	}...), nil
-}
-
-func tidyLens(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.CodeLens, error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil || pm.File == nil {
-		return nil, err
-	}
-	uri := protocol.URIFromSpanURI(fh.URI())
-	cmd, err := command.NewTidyCommand("Run go mod tidy", command.URIArgs{URIs: []protocol.DocumentURI{uri}})
-	if err != nil {
-		return nil, err
-	}
-	rng, err := moduleStmtRange(fh, pm)
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.CodeLens{{
-		Range:   rng,
-		Command: cmd,
-	}}, nil
-}
-
-func vendorLens(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.CodeLens, error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil || pm.File == nil {
-		return nil, err
-	}
-	if len(pm.File.Require) == 0 {
-		// Nothing to vendor.
-		return nil, nil
-	}
-	rng, err := moduleStmtRange(fh, pm)
-	if err != nil {
-		return nil, err
-	}
-	title := "Create vendor directory"
-	uri := protocol.URIFromSpanURI(fh.URI())
-	cmd, err := command.NewVendorCommand(title, command.URIArg{URI: uri})
-	if err != nil {
-		return nil, err
-	}
-	// Change the message depending on whether or not the module already has a
-	// vendor directory.
-	vendorDir := filepath.Join(filepath.Dir(fh.URI().Filename()), "vendor")
-	if info, _ := os.Stat(vendorDir); info != nil && info.IsDir() {
-		title = "Sync vendor directory"
-	}
-	return []protocol.CodeLens{{Range: rng, Command: cmd}}, nil
-}
-
-func moduleStmtRange(fh source.FileHandle, pm *source.ParsedModule) (protocol.Range, error) {
-	if pm.File == nil || pm.File.Module == nil || pm.File.Module.Syntax == nil {
-		return protocol.Range{}, fmt.Errorf("no module statement in %s", fh.URI())
-	}
-	syntax := pm.File.Module.Syntax
-	return pm.Mapper.OffsetRange(syntax.Start.Byte, syntax.End.Byte)
-}
-
-// firstRequireRange returns the range for the first "require" in the given
-// go.mod file. This is either a require block or an individual require line.
-func firstRequireRange(fh source.FileHandle, pm *source.ParsedModule) (protocol.Range, error) {
-	if len(pm.File.Require) == 0 {
-		return protocol.Range{}, fmt.Errorf("no requires in the file %s", fh.URI())
-	}
-	var start, end modfile.Position
-	for _, stmt := range pm.File.Syntax.Stmt {
-		if b, ok := stmt.(*modfile.LineBlock); ok && len(b.Token) == 1 && b.Token[0] == "require" {
-			start, end = b.Span()
-			break
-		}
-	}
-
-	firstRequire := pm.File.Require[0].Syntax
-	if start.Byte == 0 || firstRequire.Start.Byte < start.Byte {
-		start, end = firstRequire.Start, firstRequire.End
-	}
-	return pm.Mapper.OffsetRange(start.Byte, end.Byte)
-}
-
-func vulncheckLenses(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.CodeLens, error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil || pm.File == nil {
-		return nil, err
-	}
-	// Place the codelenses near the module statement.
-	// A module may not have the require block,
-	// but vulnerabilities can exist in standard libraries.
-	uri := protocol.URIFromSpanURI(fh.URI())
-	rng, err := moduleStmtRange(fh, pm)
-	if err != nil {
-		return nil, err
-	}
-
-	vulncheck, err := command.NewRunGovulncheckCommand("Run govulncheck", command.VulncheckArgs{
-		URI:     uri,
-		Pattern: "./...",
-	})
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.CodeLens{
-		{Range: rng, Command: vulncheck},
-	}, nil
-}
diff -urN a/gopls/internal/lsp/mod/diagnostics.go b/gopls/internal/lsp/mod/diagnostics.go
--- a/gopls/internal/lsp/mod/diagnostics.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/diagnostics.go	1969-12-31 16:00:00
@@ -1,558 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package mod provides core features related to go.mod file
-// handling for use by Go editors and tools.
-package mod
-
-import (
-	"context"
-	"fmt"
-	"sort"
-	"strings"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/semver"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/vuln/osv"
-)
-
-// Diagnostics returns diagnostics for the modules in the workspace.
-//
-// It waits for completion of type-checking of all active packages.
-func Diagnostics(ctx context.Context, snapshot source.Snapshot) (map[source.VersionedFileIdentity][]*source.Diagnostic, error) {
-	ctx, done := event.Start(ctx, "mod.Diagnostics", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	return collectDiagnostics(ctx, snapshot, ModDiagnostics)
-}
-
-// UpgradeDiagnostics returns upgrade diagnostics for the modules in the
-// workspace with known upgrades.
-func UpgradeDiagnostics(ctx context.Context, snapshot source.Snapshot) (map[source.VersionedFileIdentity][]*source.Diagnostic, error) {
-	ctx, done := event.Start(ctx, "mod.UpgradeDiagnostics", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	return collectDiagnostics(ctx, snapshot, ModUpgradeDiagnostics)
-}
-
-// VulnerabilityDiagnostics returns vulnerability diagnostics for the active modules in the
-// workspace with known vulnerabilites.
-func VulnerabilityDiagnostics(ctx context.Context, snapshot source.Snapshot) (map[source.VersionedFileIdentity][]*source.Diagnostic, error) {
-	ctx, done := event.Start(ctx, "mod.VulnerabilityDiagnostics", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	return collectDiagnostics(ctx, snapshot, ModVulnerabilityDiagnostics)
-}
-
-func collectDiagnostics(ctx context.Context, snapshot source.Snapshot, diagFn func(context.Context, source.Snapshot, source.FileHandle) ([]*source.Diagnostic, error)) (map[source.VersionedFileIdentity][]*source.Diagnostic, error) {
-	reports := make(map[source.VersionedFileIdentity][]*source.Diagnostic)
-	for _, uri := range snapshot.ModFiles() {
-		fh, err := snapshot.GetVersionedFile(ctx, uri)
-		if err != nil {
-			return nil, err
-		}
-		reports[fh.VersionedFileIdentity()] = []*source.Diagnostic{}
-		diagnostics, err := diagFn(ctx, snapshot, fh)
-		if err != nil {
-			return nil, err
-		}
-		for _, d := range diagnostics {
-			fh, err := snapshot.GetVersionedFile(ctx, d.URI)
-			if err != nil {
-				return nil, err
-			}
-			reports[fh.VersionedFileIdentity()] = append(reports[fh.VersionedFileIdentity()], d)
-		}
-	}
-	return reports, nil
-}
-
-// ModDiagnostics waits for completion of type-checking of all active
-// packages, then returns diagnostics from diagnosing the packages in
-// the workspace and from tidying the go.mod file.
-func ModDiagnostics(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) (diagnostics []*source.Diagnostic, err error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		if pm == nil || len(pm.ParseErrors) == 0 {
-			return nil, err
-		}
-		return pm.ParseErrors, nil
-	}
-
-	// Packages in the workspace can contribute diagnostics to go.mod files.
-	// TODO(rfindley): Try to avoid type checking all packages in the workspace here,
-	// for every go.mod file. If gc_details is enabled, it looks like this could lead to extra
-	// go command invocations (as gc details is not memoized).
-	active, err := snapshot.ActiveMetadata(ctx)
-	if err != nil && !source.IsNonFatalGoModError(err) {
-		event.Error(ctx, fmt.Sprintf("workspace packages: diagnosing %s", pm.URI), err)
-	}
-	if err == nil {
-		// Type-check packages in parallel and gather list/parse/type errors.
-		// (This may be the first operation after the initial metadata load
-		// to demand type-checking of all active packages.)
-		ids := make([]source.PackageID, len(active))
-		for i, meta := range active {
-			ids[i] = meta.ID
-		}
-		pkgs, err := snapshot.TypeCheck(ctx, source.TypecheckFull, ids...)
-		if err != nil {
-			return nil, err
-		}
-		for _, pkg := range pkgs {
-			diagnostics = append(diagnostics, pkg.DiagnosticsForFile(fh.URI())...)
-		}
-	}
-
-	tidied, err := snapshot.ModTidy(ctx, pm)
-	if err != nil && !source.IsNonFatalGoModError(err) {
-		event.Error(ctx, fmt.Sprintf("tidy: diagnosing %s", pm.URI), err)
-	}
-	if err == nil {
-		for _, d := range tidied.Diagnostics {
-			if d.URI != fh.URI() {
-				continue
-			}
-			diagnostics = append(diagnostics, d)
-		}
-	}
-	return diagnostics, nil
-}
-
-// ModUpgradeDiagnostics adds upgrade quick fixes for individual modules if the upgrades
-// are recorded in the view.
-func ModUpgradeDiagnostics(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) (upgradeDiagnostics []*source.Diagnostic, err error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		// Don't return an error if there are parse error diagnostics to be shown, but also do not
-		// continue since we won't be able to show the upgrade diagnostics.
-		if pm != nil && len(pm.ParseErrors) != 0 {
-			return nil, nil
-		}
-		return nil, err
-	}
-
-	upgrades := snapshot.View().ModuleUpgrades(fh.URI())
-	for _, req := range pm.File.Require {
-		ver, ok := upgrades[req.Mod.Path]
-		if !ok || req.Mod.Version == ver {
-			continue
-		}
-		rng, err := pm.Mapper.OffsetRange(req.Syntax.Start.Byte, req.Syntax.End.Byte)
-		if err != nil {
-			return nil, err
-		}
-		// Upgrade to the exact version we offer the user, not the most recent.
-		title := fmt.Sprintf("%s%v", upgradeCodeActionPrefix, ver)
-		cmd, err := command.NewUpgradeDependencyCommand(title, command.DependencyArgs{
-			URI:        protocol.URIFromSpanURI(fh.URI()),
-			AddRequire: false,
-			GoCmdArgs:  []string{req.Mod.Path + "@" + ver},
-		})
-		if err != nil {
-			return nil, err
-		}
-		upgradeDiagnostics = append(upgradeDiagnostics, &source.Diagnostic{
-			URI:            fh.URI(),
-			Range:          rng,
-			Severity:       protocol.SeverityInformation,
-			Source:         source.UpgradeNotification,
-			Message:        fmt.Sprintf("%v can be upgraded", req.Mod.Path),
-			SuggestedFixes: []source.SuggestedFix{source.SuggestedFixFromCommand(cmd, protocol.QuickFix)},
-		})
-	}
-
-	return upgradeDiagnostics, nil
-}
-
-const upgradeCodeActionPrefix = "Upgrade to "
-
-// ModVulnerabilityDiagnostics adds diagnostics for vulnerabilities in individual modules
-// if the vulnerability is recorded in the view.
-func ModVulnerabilityDiagnostics(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) (vulnDiagnostics []*source.Diagnostic, err error) {
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		// Don't return an error if there are parse error diagnostics to be shown, but also do not
-		// continue since we won't be able to show the vulnerability diagnostics.
-		if pm != nil && len(pm.ParseErrors) != 0 {
-			return nil, nil
-		}
-		return nil, err
-	}
-
-	fromGovulncheck := true
-	vs := snapshot.View().Vulnerabilities(fh.URI())[fh.URI()]
-	if vs == nil && snapshot.View().Options().Vulncheck == source.ModeVulncheckImports {
-		vs, err = snapshot.ModVuln(ctx, fh.URI())
-		if err != nil {
-			return nil, err
-		}
-		fromGovulncheck = false
-	}
-	if vs == nil || len(vs.Vulns) == 0 {
-		return nil, nil
-	}
-
-	suggestRunOrResetGovulncheck, err := suggestGovulncheckAction(fromGovulncheck, fh.URI())
-	if err != nil {
-		// must not happen
-		return nil, err // TODO: bug report
-	}
-	type modVuln struct {
-		mod  *govulncheck.Module
-		vuln *govulncheck.Vuln
-	}
-	vulnsByModule := make(map[string][]modVuln)
-	for _, vuln := range vs.Vulns {
-		for _, mod := range vuln.Modules {
-			vulnsByModule[mod.Path] = append(vulnsByModule[mod.Path], modVuln{mod, vuln})
-		}
-	}
-
-	for _, req := range pm.File.Require {
-		vulns := vulnsByModule[req.Mod.Path]
-		if len(vulns) == 0 {
-			continue
-		}
-		// note: req.Syntax is the line corresponding to 'require', which means
-		// req.Syntax.Start can point to the beginning of the "require" keyword
-		// for a single line require (e.g. "require golang.org/x/mod v0.0.0").
-		start := req.Syntax.Start.Byte
-		if len(req.Syntax.Token) == 3 {
-			start += len("require ")
-		}
-		rng, err := pm.Mapper.OffsetRange(start, req.Syntax.End.Byte)
-		if err != nil {
-			return nil, err
-		}
-		// Map affecting vulns to 'warning' level diagnostics,
-		// others to 'info' level diagnostics.
-		// Fixes will include only the upgrades for warning level diagnostics.
-		var warningFixes, infoFixes []source.SuggestedFix
-		var warning, info []string
-		var relatedInfo []source.RelatedInformation
-		for _, mv := range vulns {
-			mod, vuln := mv.mod, mv.vuln
-			// It is possible that the source code was changed since the last
-			// govulncheck run and information in the `vulns` info is stale.
-			// For example, imagine that a user is in the middle of updating
-			// problematic modules detected by the govulncheck run by applying
-			// quick fixes. Stale diagnostics can be confusing and prevent the
-			// user from quickly locating the next module to fix.
-			// Ideally we should rerun the analysis with the updated module
-			// dependencies or any other code changes, but we are not yet
-			// in the position of automatically triggerring the analysis
-			// (govulncheck can take a while). We also don't know exactly what
-			// part of source code was changed since `vulns` was computed.
-			// As a heuristic, we assume that a user upgrades the affecting
-			// module to the version with the fix or the latest one, and if the
-			// version in the require statement is equal to or higher than the
-			// fixed version, skip generating a diagnostic about the vulnerability.
-			// Eventually, the user has to rerun govulncheck.
-			if mod.FixedVersion != "" && semver.IsValid(req.Mod.Version) && semver.Compare(mod.FixedVersion, req.Mod.Version) <= 0 {
-				continue
-			}
-			if !vuln.IsCalled() {
-				info = append(info, vuln.OSV.ID)
-			} else {
-				warning = append(warning, vuln.OSV.ID)
-				relatedInfo = append(relatedInfo, listRelatedInfo(ctx, snapshot, vuln)...)
-			}
-			// Upgrade to the exact version we offer the user, not the most recent.
-			if fixedVersion := mod.FixedVersion; semver.IsValid(fixedVersion) && semver.Compare(req.Mod.Version, fixedVersion) < 0 {
-				cmd, err := getUpgradeCodeAction(fh, req, fixedVersion)
-				if err != nil {
-					return nil, err // TODO: bug report
-				}
-				sf := source.SuggestedFixFromCommand(cmd, protocol.QuickFix)
-				if !vuln.IsCalled() {
-					infoFixes = append(infoFixes, sf)
-				} else {
-					warningFixes = append(warningFixes, sf)
-				}
-			}
-		}
-
-		if len(warning) == 0 && len(info) == 0 {
-			continue
-		}
-		// Add an upgrade for module@latest.
-		// TODO(suzmue): verify if latest is the same as fixedVersion.
-		latest, err := getUpgradeCodeAction(fh, req, "latest")
-		if err != nil {
-			return nil, err // TODO: bug report
-		}
-		sf := source.SuggestedFixFromCommand(latest, protocol.QuickFix)
-		if len(warningFixes) > 0 {
-			warningFixes = append(warningFixes, sf)
-		}
-		if len(infoFixes) > 0 {
-			infoFixes = append(infoFixes, sf)
-		}
-
-		sort.Strings(warning)
-		sort.Strings(info)
-
-		if len(warning) > 0 {
-			warningFixes = append(warningFixes, suggestRunOrResetGovulncheck)
-			vulnDiagnostics = append(vulnDiagnostics, &source.Diagnostic{
-				URI:            fh.URI(),
-				Range:          rng,
-				Severity:       protocol.SeverityWarning,
-				Source:         source.Vulncheck,
-				Message:        getVulnMessage(req.Mod.Path, warning, true, fromGovulncheck),
-				SuggestedFixes: warningFixes,
-				Related:        relatedInfo,
-			})
-		}
-		if len(info) > 0 {
-			infoFixes = append(infoFixes, suggestRunOrResetGovulncheck)
-			vulnDiagnostics = append(vulnDiagnostics, &source.Diagnostic{
-				URI:            fh.URI(),
-				Range:          rng,
-				Severity:       protocol.SeverityInformation,
-				Source:         source.Vulncheck,
-				Message:        getVulnMessage(req.Mod.Path, info, false, fromGovulncheck),
-				SuggestedFixes: infoFixes,
-				Related:        relatedInfo,
-			})
-		}
-	}
-
-	// TODO(hyangah): place this diagnostic on the `go` directive or `toolchain` directive
-	// after https://go.dev/issue/57001.
-	const diagnoseStdLib = false
-	if diagnoseStdLib {
-		// Add standard library vulnerabilities.
-		stdlibVulns := vulnsByModule["stdlib"]
-		if len(stdlibVulns) == 0 {
-			return vulnDiagnostics, nil
-		}
-
-		// Put the standard library diagnostic on the module declaration.
-		rng, err := pm.Mapper.OffsetRange(pm.File.Module.Syntax.Start.Byte, pm.File.Module.Syntax.End.Byte)
-		if err != nil {
-			return vulnDiagnostics, nil // TODO: bug report
-		}
-
-		stdlib := stdlibVulns[0].mod.FoundVersion
-		var warning, info []string
-		var relatedInfo []source.RelatedInformation
-		for _, mv := range stdlibVulns {
-			vuln := mv.vuln
-			stdlib = mv.mod.FoundVersion
-			if !vuln.IsCalled() {
-				info = append(info, vuln.OSV.ID)
-			} else {
-				warning = append(warning, vuln.OSV.ID)
-				relatedInfo = append(relatedInfo, listRelatedInfo(ctx, snapshot, vuln)...)
-			}
-		}
-		if len(warning) > 0 {
-			fixes := []source.SuggestedFix{suggestRunOrResetGovulncheck}
-			vulnDiagnostics = append(vulnDiagnostics, &source.Diagnostic{
-				URI:            fh.URI(),
-				Range:          rng,
-				Severity:       protocol.SeverityWarning,
-				Source:         source.Vulncheck,
-				Message:        getVulnMessage(stdlib, warning, true, fromGovulncheck),
-				SuggestedFixes: fixes,
-				Related:        relatedInfo,
-			})
-		}
-		if len(info) > 0 {
-			fixes := []source.SuggestedFix{suggestRunOrResetGovulncheck}
-			vulnDiagnostics = append(vulnDiagnostics, &source.Diagnostic{
-				URI:            fh.URI(),
-				Range:          rng,
-				Severity:       protocol.SeverityInformation,
-				Source:         source.Vulncheck,
-				Message:        getVulnMessage(stdlib, info, false, fromGovulncheck),
-				SuggestedFixes: fixes,
-				Related:        relatedInfo,
-			})
-		}
-	}
-
-	return vulnDiagnostics, nil
-}
-
-// suggestGovulncheckAction returns a code action that suggests either run govulncheck
-// for more accurate investigation (if the present vulncheck diagnostics are based on
-// analysis less accurate than govulncheck) or reset the existing govulncheck result
-// (if the present vulncheck diagnostics are already based on govulncheck run).
-func suggestGovulncheckAction(fromGovulncheck bool, uri span.URI) (source.SuggestedFix, error) {
-	if fromGovulncheck {
-		resetVulncheck, err := command.NewResetGoModDiagnosticsCommand("Reset govulncheck result", command.ResetGoModDiagnosticsArgs{
-			URIArg:           command.URIArg{URI: protocol.DocumentURI(uri)},
-			DiagnosticSource: string(source.Vulncheck),
-		})
-		if err != nil {
-			return source.SuggestedFix{}, err
-		}
-		return source.SuggestedFixFromCommand(resetVulncheck, protocol.QuickFix), nil
-	}
-	vulncheck, err := command.NewRunGovulncheckCommand("Run govulncheck to verify", command.VulncheckArgs{
-		URI:     protocol.DocumentURI(uri),
-		Pattern: "./...",
-	})
-	if err != nil {
-		return source.SuggestedFix{}, err
-	}
-	return source.SuggestedFixFromCommand(vulncheck, protocol.QuickFix), nil
-}
-
-func getVulnMessage(mod string, vulns []string, used, fromGovulncheck bool) string {
-	var b strings.Builder
-	if used {
-		switch len(vulns) {
-		case 1:
-			fmt.Fprintf(&b, "%v has a vulnerability used in the code: %v.", mod, vulns[0])
-		default:
-			fmt.Fprintf(&b, "%v has vulnerabilities used in the code: %v.", mod, strings.Join(vulns, ", "))
-		}
-	} else {
-		if fromGovulncheck {
-			switch len(vulns) {
-			case 1:
-				fmt.Fprintf(&b, "%v has a vulnerability %v that is not used in the code.", mod, vulns[0])
-			default:
-				fmt.Fprintf(&b, "%v has known vulnerabilities %v that are not used in the code.", mod, strings.Join(vulns, ", "))
-			}
-		} else {
-			switch len(vulns) {
-			case 1:
-				fmt.Fprintf(&b, "%v has a vulnerability %v.", mod, vulns[0])
-			default:
-				fmt.Fprintf(&b, "%v has known vulnerabilities %v.", mod, strings.Join(vulns, ", "))
-			}
-		}
-	}
-	return b.String()
-}
-
-func listRelatedInfo(ctx context.Context, snapshot source.Snapshot, vuln *govulncheck.Vuln) []source.RelatedInformation {
-	var ri []source.RelatedInformation
-	for _, m := range vuln.Modules {
-		for _, p := range m.Packages {
-			for _, c := range p.CallStacks {
-				if len(c.Frames) == 0 {
-					continue
-				}
-				entry := c.Frames[0]
-				pos := entry.Position
-				if pos.Filename == "" {
-					continue // token.Position Filename is an optional field.
-				}
-				uri := span.URIFromPath(pos.Filename)
-				startPos := protocol.Position{
-					Line: uint32(pos.Line) - 1,
-					// We need to read the file contents to precisesly map
-					// token.Position (pos) to the UTF16-based column offset
-					// protocol.Position requires. That can be expensive.
-					// We need this related info to just help users to open
-					// the entry points of the callstack and once the file is
-					// open, we will compute the precise location based on the
-					// open file contents. So, use the beginning of the line
-					// as the position here instead of precise UTF16-based
-					// position computation.
-					Character: 0,
-				}
-				ri = append(ri, source.RelatedInformation{
-					URI: uri,
-					Range: protocol.Range{
-						Start: startPos,
-						End:   startPos,
-					},
-					Message: fmt.Sprintf("[%v] %v -> %v.%v", vuln.OSV.ID, entry.Name(), p.Path, c.Symbol),
-				})
-			}
-		}
-	}
-	return ri
-}
-
-func formatMessage(v *govulncheck.Vuln) string {
-	details := []byte(v.OSV.Details)
-	// Remove any new lines that are not preceded or followed by a new line.
-	for i, r := range details {
-		if r == '\n' && i > 0 && details[i-1] != '\n' && i+1 < len(details) && details[i+1] != '\n' {
-			details[i] = ' '
-		}
-	}
-	return strings.TrimSpace(strings.Replace(string(details), "\n\n", "\n\n  ", -1))
-}
-
-// href returns the url for the vulnerability information.
-// Eventually we should retrieve the url embedded in the osv.Entry.
-// While vuln.go.dev is under development, this always returns
-// the page in pkg.go.dev.
-func href(vuln *osv.Entry) string {
-	return fmt.Sprintf("https://pkg.go.dev/vuln/%s", vuln.ID)
-}
-
-func getUpgradeCodeAction(fh source.FileHandle, req *modfile.Require, version string) (protocol.Command, error) {
-	cmd, err := command.NewUpgradeDependencyCommand(upgradeTitle(version), command.DependencyArgs{
-		URI:        protocol.URIFromSpanURI(fh.URI()),
-		AddRequire: false,
-		GoCmdArgs:  []string{req.Mod.Path + "@" + version},
-	})
-	if err != nil {
-		return protocol.Command{}, err
-	}
-	return cmd, nil
-}
-
-func upgradeTitle(fixedVersion string) string {
-	title := fmt.Sprintf("%s%v", upgradeCodeActionPrefix, fixedVersion)
-	return title
-}
-
-// SelectUpgradeCodeActions takes a list of code actions for a required module
-// and returns a more selective list of upgrade code actions,
-// where the code actions have been deduped. Code actions unrelated to upgrade
-// are deduplicated by the name.
-func SelectUpgradeCodeActions(actions []protocol.CodeAction) []protocol.CodeAction {
-	if len(actions) <= 1 {
-		return actions // return early if no sorting necessary
-	}
-	var others []protocol.CodeAction
-
-	seen := make(map[string]bool)
-
-	set := make(map[string]protocol.CodeAction)
-	for _, action := range actions {
-		if strings.HasPrefix(action.Title, upgradeCodeActionPrefix) {
-			set[action.Command.Title] = action
-		} else if !seen[action.Command.Title] {
-			seen[action.Command.Title] = true
-			others = append(others, action)
-		}
-	}
-	var upgrades []protocol.CodeAction
-	for _, action := range set {
-		upgrades = append(upgrades, action)
-	}
-	// Sort results by version number, latest first.
-	// There should be no duplicates at this point.
-	sort.Slice(upgrades, func(i, j int) bool {
-		vi, vj := getUpgradeVersion(upgrades[i]), getUpgradeVersion(upgrades[j])
-		return vi == "latest" || (vj != "latest" && semver.Compare(vi, vj) > 0)
-	})
-	// Choose at most one specific version and the latest.
-	if getUpgradeVersion(upgrades[0]) == "latest" {
-		return append(upgrades[:2], others...)
-	}
-	return append(upgrades[:1], others...)
-}
-
-func getUpgradeVersion(p protocol.CodeAction) string {
-	return strings.TrimPrefix(p.Title, upgradeCodeActionPrefix)
-}
diff -urN a/gopls/internal/lsp/mod/format.go b/gopls/internal/lsp/mod/format.go
--- a/gopls/internal/lsp/mod/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/format.go	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package mod
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-func Format(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.TextEdit, error) {
-	ctx, done := event.Start(ctx, "mod.Format")
-	defer done()
-
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		return nil, err
-	}
-	formatted, err := pm.File.Format()
-	if err != nil {
-		return nil, err
-	}
-	// Calculate the edits to be made due to the change.
-	diffs := snapshot.View().Options().ComputeEdits(string(pm.Mapper.Content), string(formatted))
-	return source.ToProtocolEdits(pm.Mapper, diffs)
-}
diff -urN a/gopls/internal/lsp/mod/hover.go b/gopls/internal/lsp/mod/hover.go
--- a/gopls/internal/lsp/mod/hover.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/hover.go	1969-12-31 16:00:00
@@ -1,354 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package mod
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"sort"
-	"strings"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/semver"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-func Hover(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, position protocol.Position) (*protocol.Hover, error) {
-	var found bool
-	for _, uri := range snapshot.ModFiles() {
-		if fh.URI() == uri {
-			found = true
-			break
-		}
-	}
-
-	// We only provide hover information for the view's go.mod files.
-	if !found {
-		return nil, nil
-	}
-
-	ctx, done := event.Start(ctx, "mod.Hover")
-	defer done()
-
-	// Get the position of the cursor.
-	pm, err := snapshot.ParseMod(ctx, fh)
-	if err != nil {
-		return nil, fmt.Errorf("getting modfile handle: %w", err)
-	}
-	offset, err := pm.Mapper.Offset(position)
-	if err != nil {
-		return nil, fmt.Errorf("computing cursor position: %w", err)
-	}
-
-	// If the cursor position is on a module statement
-	if hover, ok := hoverOnModuleStatement(ctx, pm, offset, snapshot, fh); ok {
-		return hover, nil
-	}
-	return hoverOnRequireStatement(ctx, pm, offset, snapshot, fh)
-}
-
-func hoverOnRequireStatement(ctx context.Context, pm *source.ParsedModule, offset int, snapshot source.Snapshot, fh source.FileHandle) (*protocol.Hover, error) {
-	// Confirm that the cursor is at the position of a require statement.
-	var req *modfile.Require
-	var startPos, endPos int
-	for _, r := range pm.File.Require {
-		dep := []byte(r.Mod.Path)
-		s, e := r.Syntax.Start.Byte, r.Syntax.End.Byte
-		i := bytes.Index(pm.Mapper.Content[s:e], dep)
-		if i == -1 {
-			continue
-		}
-		// Shift the start position to the location of the
-		// dependency within the require statement.
-		startPos, endPos = s+i, e
-		if startPos <= offset && offset <= endPos {
-			req = r
-			break
-		}
-	}
-	// TODO(hyangah): find position for info about vulnerabilities in Go
-
-	// The cursor position is not on a require statement.
-	if req == nil {
-		return nil, nil
-	}
-
-	// Get the vulnerability info.
-	fromGovulncheck := true
-	vs := snapshot.View().Vulnerabilities(fh.URI())[fh.URI()]
-	if vs == nil && snapshot.View().Options().Vulncheck == source.ModeVulncheckImports {
-		var err error
-		vs, err = snapshot.ModVuln(ctx, fh.URI())
-		if err != nil {
-			return nil, err
-		}
-		fromGovulncheck = false
-	}
-	affecting, nonaffecting := lookupVulns(vs, req.Mod.Path, req.Mod.Version)
-
-	// Get the `go mod why` results for the given file.
-	why, err := snapshot.ModWhy(ctx, fh)
-	if err != nil {
-		return nil, err
-	}
-	explanation, ok := why[req.Mod.Path]
-	if !ok {
-		return nil, nil
-	}
-
-	// Get the range to highlight for the hover.
-	// TODO(hyangah): adjust the hover range to include the version number
-	// to match the diagnostics' range.
-	rng, err := pm.Mapper.OffsetRange(startPos, endPos)
-	if err != nil {
-		return nil, err
-	}
-	options := snapshot.View().Options()
-	isPrivate := snapshot.View().IsGoPrivatePath(req.Mod.Path)
-	header := formatHeader(req.Mod.Path, options)
-	explanation = formatExplanation(explanation, req, options, isPrivate)
-	vulns := formatVulnerabilities(req.Mod.Path, affecting, nonaffecting, options, fromGovulncheck)
-
-	return &protocol.Hover{
-		Contents: protocol.MarkupContent{
-			Kind:  options.PreferredContentFormat,
-			Value: header + vulns + explanation,
-		},
-		Range: rng,
-	}, nil
-}
-
-func hoverOnModuleStatement(ctx context.Context, pm *source.ParsedModule, offset int, snapshot source.Snapshot, fh source.FileHandle) (*protocol.Hover, bool) {
-	if offset < pm.File.Module.Syntax.Start.Byte || offset > pm.File.Module.Syntax.End.Byte {
-		return nil, false
-	}
-
-	rng, err := pm.Mapper.OffsetRange(pm.File.Module.Syntax.Start.Byte, pm.File.Module.Syntax.End.Byte)
-	if err != nil {
-		return nil, false
-	}
-	fromGovulncheck := true
-	vs := snapshot.View().Vulnerabilities(fh.URI())[fh.URI()]
-
-	if vs == nil && snapshot.View().Options().Vulncheck == source.ModeVulncheckImports {
-		vs, err = snapshot.ModVuln(ctx, fh.URI())
-		if err != nil {
-			return nil, false
-		}
-		fromGovulncheck = false
-	}
-	modpath := "stdlib"
-	goVersion := snapshot.View().GoVersionString()
-	affecting, nonaffecting := lookupVulns(vs, modpath, goVersion)
-	options := snapshot.View().Options()
-	vulns := formatVulnerabilities(modpath, affecting, nonaffecting, options, fromGovulncheck)
-
-	return &protocol.Hover{
-		Contents: protocol.MarkupContent{
-			Kind:  options.PreferredContentFormat,
-			Value: vulns,
-		},
-		Range: rng,
-	}, true
-}
-
-func formatHeader(modpath string, options *source.Options) string {
-	var b strings.Builder
-	// Write the heading as an H3.
-	b.WriteString("#### " + modpath)
-	if options.PreferredContentFormat == protocol.Markdown {
-		b.WriteString("\n\n")
-	} else {
-		b.WriteRune('\n')
-	}
-	return b.String()
-}
-
-func lookupVulns(vulns *govulncheck.Result, modpath, version string) (affecting, nonaffecting []*govulncheck.Vuln) {
-	if vulns == nil {
-		return nil, nil
-	}
-	for _, vuln := range vulns.Vulns {
-		for _, mod := range vuln.Modules {
-			if mod.Path != modpath {
-				continue
-			}
-			// It is possible that the source code was changed since the last
-			// govulncheck run and information in the `vulns` info is stale.
-			// For example, imagine that a user is in the middle of updating
-			// problematic modules detected by the govulncheck run by applying
-			// quick fixes. Stale diagnostics can be confusing and prevent the
-			// user from quickly locating the next module to fix.
-			// Ideally we should rerun the analysis with the updated module
-			// dependencies or any other code changes, but we are not yet
-			// in the position of automatically triggerring the analysis
-			// (govulncheck can take a while). We also don't know exactly what
-			// part of source code was changed since `vulns` was computed.
-			// As a heuristic, we assume that a user upgrades the affecting
-			// module to the version with the fix or the latest one, and if the
-			// version in the require statement is equal to or higher than the
-			// fixed version, skip the vulnerability information in the hover.
-			// Eventually, the user has to rerun govulncheck.
-			if mod.FixedVersion != "" && semver.IsValid(version) && semver.Compare(mod.FixedVersion, version) <= 0 {
-				continue
-			}
-			if vuln.IsCalled() {
-				affecting = append(affecting, vuln)
-			} else {
-				nonaffecting = append(nonaffecting, vuln)
-			}
-		}
-	}
-	sort.Slice(nonaffecting, func(i, j int) bool { return nonaffecting[i].OSV.ID < nonaffecting[j].OSV.ID })
-	sort.Slice(affecting, func(i, j int) bool { return affecting[i].OSV.ID < affecting[j].OSV.ID })
-	return affecting, nonaffecting
-}
-
-func formatVulnerabilities(modPath string, affecting, nonaffecting []*govulncheck.Vuln, options *source.Options, fromGovulncheck bool) string {
-	if len(affecting) == 0 && len(nonaffecting) == 0 {
-		return ""
-	}
-
-	// TODO(hyangah): can we use go templates to generate hover messages?
-	// Then, we can use a different template for markdown case.
-	useMarkdown := options.PreferredContentFormat == protocol.Markdown
-
-	var b strings.Builder
-
-	if len(affecting) > 0 {
-		// TODO(hyangah): make the message more eyecatching (icon/codicon/color)
-		if len(affecting) == 1 {
-			b.WriteString(fmt.Sprintf("\n**WARNING:** Found %d reachable vulnerability.\n", len(affecting)))
-		} else {
-			b.WriteString(fmt.Sprintf("\n**WARNING:** Found %d reachable vulnerabilities.\n", len(affecting)))
-		}
-	}
-	for _, v := range affecting {
-		fix := fixedVersionInfo(v, modPath)
-		pkgs := vulnerablePkgsInfo(v, modPath, useMarkdown)
-
-		if useMarkdown {
-			fmt.Fprintf(&b, "- [**%v**](%v) %v%v%v\n", v.OSV.ID, href(v.OSV), formatMessage(v), pkgs, fix)
-		} else {
-			fmt.Fprintf(&b, "  - [%v] %v (%v) %v%v\n", v.OSV.ID, formatMessage(v), href(v.OSV), pkgs, fix)
-		}
-	}
-	if len(nonaffecting) > 0 {
-		if fromGovulncheck {
-			fmt.Fprintf(&b, "\n**Note:** The project imports packages with known vulnerabilities, but does not call the vulnerable code.\n")
-		} else {
-			fmt.Fprintf(&b, "\n**Note:** The project imports packages with known vulnerabilities. Use `govulncheck` to check if the project uses vulnerable symbols.\n")
-		}
-	}
-	for _, v := range nonaffecting {
-		fix := fixedVersionInfo(v, modPath)
-		pkgs := vulnerablePkgsInfo(v, modPath, useMarkdown)
-		if useMarkdown {
-			fmt.Fprintf(&b, "- [%v](%v) %v%v%v\n", v.OSV.ID, href(v.OSV), formatMessage(v), pkgs, fix)
-		} else {
-			fmt.Fprintf(&b, "  - [%v] %v (%v) %v%v\n", v.OSV.ID, formatMessage(v), href(v.OSV), pkgs, fix)
-		}
-	}
-	b.WriteString("\n")
-	return b.String()
-}
-
-func vulnerablePkgsInfo(v *govulncheck.Vuln, modPath string, useMarkdown bool) string {
-	var b bytes.Buffer
-	for _, m := range v.Modules {
-		if m.Path != modPath {
-			continue
-		}
-		if c := len(m.Packages); c == 1 {
-			b.WriteString("\n  Vulnerable package is:")
-		} else if c > 1 {
-			b.WriteString("\n  Vulnerable packages are:")
-		}
-		for _, pkg := range m.Packages {
-			if useMarkdown {
-				b.WriteString("\n  * `")
-			} else {
-				b.WriteString("\n    ")
-			}
-			b.WriteString(pkg.Path)
-			if useMarkdown {
-				b.WriteString("`")
-			}
-		}
-	}
-	if b.Len() == 0 {
-		return ""
-	}
-	return b.String()
-}
-func fixedVersionInfo(v *govulncheck.Vuln, modPath string) string {
-	fix := "\n\n  **No fix is available.**"
-	for _, m := range v.Modules {
-		if m.Path != modPath {
-			continue
-		}
-		if m.FixedVersion != "" {
-			fix = "\n\n  Fixed in " + m.FixedVersion + "."
-		}
-		break
-	}
-	return fix
-}
-
-func formatExplanation(text string, req *modfile.Require, options *source.Options, isPrivate bool) string {
-	text = strings.TrimSuffix(text, "\n")
-	splt := strings.Split(text, "\n")
-	length := len(splt)
-
-	var b strings.Builder
-
-	// If the explanation is 2 lines, then it is of the form:
-	// # golang.org/x/text/encoding
-	// (main module does not need package golang.org/x/text/encoding)
-	if length == 2 {
-		b.WriteString(splt[1])
-		return b.String()
-	}
-
-	imp := splt[length-1] // import path
-	reference := imp
-	// See golang/go#36998: don't link to modules matching GOPRIVATE.
-	if !isPrivate && options.PreferredContentFormat == protocol.Markdown {
-		target := imp
-		if strings.ToLower(options.LinkTarget) == "pkg.go.dev" {
-			target = strings.Replace(target, req.Mod.Path, req.Mod.String(), 1)
-		}
-		reference = fmt.Sprintf("[%s](%s)", imp, source.BuildLink(options.LinkTarget, target, ""))
-	}
-	b.WriteString("This module is necessary because " + reference + " is imported in")
-
-	// If the explanation is 3 lines, then it is of the form:
-	// # golang.org/x/tools
-	// modtest
-	// golang.org/x/tools/go/packages
-	if length == 3 {
-		msg := fmt.Sprintf(" `%s`.", splt[1])
-		b.WriteString(msg)
-		return b.String()
-	}
-
-	// If the explanation is more than 3 lines, then it is of the form:
-	// # golang.org/x/text/language
-	// rsc.io/quote
-	// rsc.io/sampler
-	// golang.org/x/text/language
-	b.WriteString(":\n```text")
-	dash := ""
-	for _, imp := range splt[1 : length-1] {
-		dash += "-"
-		b.WriteString("\n" + dash + " " + imp)
-	}
-	b.WriteString("\n```")
-	return b.String()
-}
diff -urN a/gopls/internal/lsp/mod/mod_test.go b/gopls/internal/lsp/mod/mod_test.go
--- a/gopls/internal/lsp/mod/mod_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/mod_test.go	1969-12-31 16:00:00
@@ -1,57 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package mod
-
-import (
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	testenv.ExitIfSmallMachine()
-	os.Exit(m.Run())
-}
-
-func TestModfileRemainsUnchanged(t *testing.T) {
-	ctx := tests.Context(t)
-	session := cache.NewSession(ctx, cache.New(nil, nil), nil)
-	options := source.DefaultOptions().Clone()
-	tests.DefaultOptions(options)
-	options.TempModfile = true
-	options.Env = map[string]string{"GOPACKAGESDRIVER": "off", "GOROOT": ""}
-
-	// Make sure to copy the test directory to a temporary directory so we do not
-	// modify the test code or add go.sum files when we run the tests.
-	folder, err := tests.CopyFolderToTempDir(filepath.Join("testdata", "unchanged"))
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(folder)
-
-	before, err := ioutil.ReadFile(filepath.Join(folder, "go.mod"))
-	if err != nil {
-		t.Fatal(err)
-	}
-	_, _, release, err := session.NewView(ctx, "diagnostics_test", span.URIFromPath(folder), options)
-	if err != nil {
-		t.Fatal(err)
-	}
-	release()
-	after, err := ioutil.ReadFile(filepath.Join(folder, "go.mod"))
-	if err != nil {
-		t.Fatal(err)
-	}
-	if string(before) != string(after) {
-		t.Errorf("the real go.mod file was changed even when tempModfile=true")
-	}
-}
diff -urN a/gopls/internal/lsp/mod/testdata/unchanged/go.mod b/gopls/internal/lsp/mod/testdata/unchanged/go.mod
--- a/gopls/internal/lsp/mod/testdata/unchanged/go.mod	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/testdata/unchanged/go.mod	1969-12-31 16:00:00
@@ -1 +0,0 @@
-module unchanged
diff -urN a/gopls/internal/lsp/mod/testdata/unchanged/main.go b/gopls/internal/lsp/mod/testdata/unchanged/main.go
--- a/gopls/internal/lsp/mod/testdata/unchanged/main.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/mod/testdata/unchanged/main.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-// Package unchanged does something
-package unchanged
-
-func Yo() {
-	println("yo")
-}
diff -urN a/gopls/internal/lsp/progress/progress.go b/gopls/internal/lsp/progress/progress.go
--- a/gopls/internal/lsp/progress/progress.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/progress/progress.go	1969-12-31 16:00:00
@@ -1,271 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package progress
-
-import (
-	"context"
-	"fmt"
-	"math/rand"
-	"strconv"
-	"strings"
-	"sync"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-type Tracker struct {
-	client                   protocol.Client
-	supportsWorkDoneProgress bool
-
-	mu         sync.Mutex
-	inProgress map[protocol.ProgressToken]*WorkDone
-}
-
-func NewTracker(client protocol.Client) *Tracker {
-	return &Tracker{
-		client:     client,
-		inProgress: make(map[protocol.ProgressToken]*WorkDone),
-	}
-}
-
-func (tracker *Tracker) SetSupportsWorkDoneProgress(b bool) {
-	tracker.supportsWorkDoneProgress = b
-}
-
-// Start notifies the client of work being done on the server. It uses either
-// ShowMessage RPCs or $/progress messages, depending on the capabilities of
-// the client.  The returned WorkDone handle may be used to report incremental
-// progress, and to report work completion. In particular, it is an error to
-// call start and not call end(...) on the returned WorkDone handle.
-//
-// If token is empty, a token will be randomly generated.
-//
-// The progress item is considered cancellable if the given cancel func is
-// non-nil. In this case, cancel is called when the work done
-//
-// Example:
-//
-//	func Generate(ctx) (err error) {
-//	  ctx, cancel := context.WithCancel(ctx)
-//	  defer cancel()
-//	  work := s.progress.start(ctx, "generate", "running go generate", cancel)
-//	  defer func() {
-//	    if err != nil {
-//	      work.end(ctx, fmt.Sprintf("generate failed: %v", err))
-//	    } else {
-//	      work.end(ctx, "done")
-//	    }
-//	  }()
-//	  // Do the work...
-//	}
-func (t *Tracker) Start(ctx context.Context, title, message string, token protocol.ProgressToken, cancel func()) *WorkDone {
-	ctx = xcontext.Detach(ctx) // progress messages should not be cancelled
-	wd := &WorkDone{
-		client: t.client,
-		token:  token,
-		cancel: cancel,
-	}
-	if !t.supportsWorkDoneProgress {
-		// Previous iterations of this fallback attempted to retain cancellation
-		// support by using ShowMessageCommand with a 'Cancel' button, but this is
-		// not ideal as the 'Cancel' dialog stays open even after the command
-		// completes.
-		//
-		// Just show a simple message. Clients can implement workDone progress
-		// reporting to get cancellation support.
-		if err := wd.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-			Type:    protocol.Log,
-			Message: message,
-		}); err != nil {
-			event.Error(ctx, "showing start message for "+title, err)
-		}
-		return wd
-	}
-	if wd.token == nil {
-		token = strconv.FormatInt(rand.Int63(), 10)
-		err := wd.client.WorkDoneProgressCreate(ctx, &protocol.WorkDoneProgressCreateParams{
-			Token: token,
-		})
-		if err != nil {
-			wd.err = err
-			event.Error(ctx, "starting work for "+title, err)
-			return wd
-		}
-		wd.token = token
-	}
-	// At this point we have a token that the client knows about. Store the token
-	// before starting work.
-	t.mu.Lock()
-	t.inProgress[wd.token] = wd
-	t.mu.Unlock()
-	wd.cleanup = func() {
-		t.mu.Lock()
-		delete(t.inProgress, token)
-		t.mu.Unlock()
-	}
-	err := wd.client.Progress(ctx, &protocol.ProgressParams{
-		Token: wd.token,
-		Value: &protocol.WorkDoneProgressBegin{
-			Kind:        "begin",
-			Cancellable: wd.cancel != nil,
-			Message:     message,
-			Title:       title,
-		},
-	})
-	if err != nil {
-		event.Error(ctx, "progress begin", err)
-	}
-	return wd
-}
-
-func (t *Tracker) Cancel(token protocol.ProgressToken) error {
-	t.mu.Lock()
-	defer t.mu.Unlock()
-	wd, ok := t.inProgress[token]
-	if !ok {
-		return fmt.Errorf("token %q not found in progress", token)
-	}
-	if wd.cancel == nil {
-		return fmt.Errorf("work %q is not cancellable", token)
-	}
-	wd.doCancel()
-	return nil
-}
-
-// WorkDone represents a unit of work that is reported to the client via the
-// progress API.
-type WorkDone struct {
-	client protocol.Client
-	// If token is nil, this workDone object uses the ShowMessage API, rather
-	// than $/progress.
-	token protocol.ProgressToken
-	// err is set if progress reporting is broken for some reason (for example,
-	// if there was an initial error creating a token).
-	err error
-
-	cancelMu  sync.Mutex
-	cancelled bool
-	cancel    func()
-
-	cleanup func()
-}
-
-func (wd *WorkDone) Token() protocol.ProgressToken {
-	return wd.token
-}
-
-func (wd *WorkDone) doCancel() {
-	wd.cancelMu.Lock()
-	defer wd.cancelMu.Unlock()
-	if !wd.cancelled {
-		wd.cancel()
-	}
-}
-
-// report reports an update on WorkDone report back to the client.
-func (wd *WorkDone) Report(ctx context.Context, message string, percentage float64) {
-	ctx = xcontext.Detach(ctx) // progress messages should not be cancelled
-	if wd == nil {
-		return
-	}
-	wd.cancelMu.Lock()
-	cancelled := wd.cancelled
-	wd.cancelMu.Unlock()
-	if cancelled {
-		return
-	}
-	if wd.err != nil || wd.token == nil {
-		// Not using the workDone API, so we do nothing. It would be far too spammy
-		// to send incremental messages.
-		return
-	}
-	message = strings.TrimSuffix(message, "\n")
-	err := wd.client.Progress(ctx, &protocol.ProgressParams{
-		Token: wd.token,
-		Value: &protocol.WorkDoneProgressReport{
-			Kind: "report",
-			// Note that in the LSP spec, the value of Cancellable may be changed to
-			// control whether the cancel button in the UI is enabled. Since we don't
-			// yet use this feature, the value is kept constant here.
-			Cancellable: wd.cancel != nil,
-			Message:     message,
-			Percentage:  uint32(percentage),
-		},
-	})
-	if err != nil {
-		event.Error(ctx, "reporting progress", err)
-	}
-}
-
-// end reports a workdone completion back to the client.
-func (wd *WorkDone) End(ctx context.Context, message string) {
-	ctx = xcontext.Detach(ctx) // progress messages should not be cancelled
-	if wd == nil {
-		return
-	}
-	var err error
-	switch {
-	case wd.err != nil:
-		// There is a prior error.
-	case wd.token == nil:
-		// We're falling back to message-based reporting.
-		err = wd.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-			Type:    protocol.Info,
-			Message: message,
-		})
-	default:
-		err = wd.client.Progress(ctx, &protocol.ProgressParams{
-			Token: wd.token,
-			Value: &protocol.WorkDoneProgressEnd{
-				Kind:    "end",
-				Message: message,
-			},
-		})
-	}
-	if err != nil {
-		event.Error(ctx, "ending work", err)
-	}
-	if wd.cleanup != nil {
-		wd.cleanup()
-	}
-}
-
-// EventWriter writes every incoming []byte to
-// event.Print with the operation=generate tag
-// to distinguish its logs from others.
-type EventWriter struct {
-	ctx       context.Context
-	operation string
-}
-
-func NewEventWriter(ctx context.Context, operation string) *EventWriter {
-	return &EventWriter{ctx: ctx, operation: operation}
-}
-
-func (ew *EventWriter) Write(p []byte) (n int, err error) {
-	event.Log(ew.ctx, string(p), tag.Operation.Of(ew.operation))
-	return len(p), nil
-}
-
-// WorkDoneWriter wraps a workDone handle to provide a Writer interface,
-// so that workDone reporting can more easily be hooked into commands.
-type WorkDoneWriter struct {
-	// In order to implement the io.Writer interface, we must close over ctx.
-	ctx context.Context
-	wd  *WorkDone
-}
-
-func NewWorkDoneWriter(ctx context.Context, wd *WorkDone) *WorkDoneWriter {
-	return &WorkDoneWriter{ctx: ctx, wd: wd}
-}
-
-func (wdw *WorkDoneWriter) Write(p []byte) (n int, err error) {
-	wdw.wd.Report(wdw.ctx, string(p), 0)
-	// Don't fail just because of a failure to report progress.
-	return len(p), nil
-}
diff -urN a/gopls/internal/lsp/progress/progress_test.go b/gopls/internal/lsp/progress/progress_test.go
--- a/gopls/internal/lsp/progress/progress_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/progress/progress_test.go	1969-12-31 16:00:00
@@ -1,161 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package progress
-
-import (
-	"context"
-	"fmt"
-	"sync"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-type fakeClient struct {
-	protocol.Client
-
-	token protocol.ProgressToken
-
-	mu                                        sync.Mutex
-	created, begun, reported, messages, ended int
-}
-
-func (c *fakeClient) checkToken(token protocol.ProgressToken) {
-	if token == nil {
-		panic("nil token in progress message")
-	}
-	if c.token != nil && c.token != token {
-		panic(fmt.Errorf("invalid token in progress message: got %v, want %v", token, c.token))
-	}
-}
-
-func (c *fakeClient) WorkDoneProgressCreate(ctx context.Context, params *protocol.WorkDoneProgressCreateParams) error {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	c.checkToken(params.Token)
-	c.created++
-	return nil
-}
-
-func (c *fakeClient) Progress(ctx context.Context, params *protocol.ProgressParams) error {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	c.checkToken(params.Token)
-	switch params.Value.(type) {
-	case *protocol.WorkDoneProgressBegin:
-		c.begun++
-	case *protocol.WorkDoneProgressReport:
-		c.reported++
-	case *protocol.WorkDoneProgressEnd:
-		c.ended++
-	default:
-		panic(fmt.Errorf("unknown progress value %T", params.Value))
-	}
-	return nil
-}
-
-func (c *fakeClient) ShowMessage(context.Context, *protocol.ShowMessageParams) error {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-	c.messages++
-	return nil
-}
-
-func setup(token protocol.ProgressToken) (context.Context, *Tracker, *fakeClient) {
-	c := &fakeClient{}
-	tracker := NewTracker(c)
-	tracker.SetSupportsWorkDoneProgress(true)
-	return context.Background(), tracker, c
-}
-
-func TestProgressTracker_Reporting(t *testing.T) {
-	for _, test := range []struct {
-		name                                            string
-		supported                                       bool
-		token                                           protocol.ProgressToken
-		wantReported, wantCreated, wantBegun, wantEnded int
-		wantMessages                                    int
-	}{
-		{
-			name:         "unsupported",
-			wantMessages: 2,
-		},
-		{
-			name:         "random token",
-			supported:    true,
-			wantCreated:  1,
-			wantBegun:    1,
-			wantReported: 1,
-			wantEnded:    1,
-		},
-		{
-			name:         "string token",
-			supported:    true,
-			token:        "token",
-			wantBegun:    1,
-			wantReported: 1,
-			wantEnded:    1,
-		},
-		{
-			name:         "numeric token",
-			supported:    true,
-			token:        1,
-			wantReported: 1,
-			wantBegun:    1,
-			wantEnded:    1,
-		},
-	} {
-		test := test
-		t.Run(test.name, func(t *testing.T) {
-			ctx, tracker, client := setup(test.token)
-			ctx, cancel := context.WithCancel(ctx)
-			defer cancel()
-			tracker.supportsWorkDoneProgress = test.supported
-			work := tracker.Start(ctx, "work", "message", test.token, nil)
-			client.mu.Lock()
-			gotCreated, gotBegun := client.created, client.begun
-			client.mu.Unlock()
-			if gotCreated != test.wantCreated {
-				t.Errorf("got %d created tokens, want %d", gotCreated, test.wantCreated)
-			}
-			if gotBegun != test.wantBegun {
-				t.Errorf("got %d work begun, want %d", gotBegun, test.wantBegun)
-			}
-			// Ignore errors: this is just testing the reporting behavior.
-			work.Report(ctx, "report", 50)
-			client.mu.Lock()
-			gotReported := client.reported
-			client.mu.Unlock()
-			if gotReported != test.wantReported {
-				t.Errorf("got %d progress reports, want %d", gotReported, test.wantCreated)
-			}
-			work.End(ctx, "done")
-			client.mu.Lock()
-			gotEnded, gotMessages := client.ended, client.messages
-			client.mu.Unlock()
-			if gotEnded != test.wantEnded {
-				t.Errorf("got %d ended reports, want %d", gotEnded, test.wantEnded)
-			}
-			if gotMessages != test.wantMessages {
-				t.Errorf("got %d messages, want %d", gotMessages, test.wantMessages)
-			}
-		})
-	}
-}
-
-func TestProgressTracker_Cancellation(t *testing.T) {
-	for _, token := range []protocol.ProgressToken{nil, 1, "a"} {
-		ctx, tracker, _ := setup(token)
-		var canceled bool
-		cancel := func() { canceled = true }
-		work := tracker.Start(ctx, "work", "message", token, cancel)
-		if err := tracker.Cancel(work.Token()); err != nil {
-			t.Fatal(err)
-		}
-		if !canceled {
-			t.Errorf("tracker.cancel(...): cancel not called")
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/protocol/codeactionkind.go b/gopls/internal/lsp/protocol/codeactionkind.go
--- a/gopls/internal/lsp/protocol/codeactionkind.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/codeactionkind.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-// Custom code actions that aren't explicitly stated in LSP
-const (
-	GoTest CodeActionKind = "goTest"
-	// TODO: Add GoGenerate, RegenerateCgo etc.
-)
diff -urN a/gopls/internal/lsp/protocol/context.go b/gopls/internal/lsp/protocol/context.go
--- a/gopls/internal/lsp/protocol/context.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/context.go	1969-12-31 16:00:00
@@ -1,43 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-import (
-	"bytes"
-	"context"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/core"
-	"golang.org/x/tools/internal/event/export"
-	"golang.org/x/tools/internal/event/label"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-type contextKey int
-
-const (
-	clientKey = contextKey(iota)
-)
-
-func WithClient(ctx context.Context, client Client) context.Context {
-	return context.WithValue(ctx, clientKey, client)
-}
-
-func LogEvent(ctx context.Context, ev core.Event, lm label.Map, mt MessageType) context.Context {
-	client, ok := ctx.Value(clientKey).(Client)
-	if !ok {
-		return ctx
-	}
-	buf := &bytes.Buffer{}
-	p := export.Printer{}
-	p.WriteEvent(buf, ev, lm)
-	msg := &LogMessageParams{Type: mt, Message: buf.String()}
-	// Handle messages generated via event.Error, which won't have a level Label.
-	if event.IsError(ev) {
-		msg.Type = Error
-	}
-	go client.LogMessage(xcontext.Detach(ctx), msg)
-	return ctx
-}
diff -urN a/gopls/internal/lsp/protocol/doc.go b/gopls/internal/lsp/protocol/doc.go
--- a/gopls/internal/lsp/protocol/doc.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/doc.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package protocol contains the structs that map directly to the wire format
-// of the "Language Server Protocol".
-//
-// It is a literal transcription, with unmodified comments, and only the changes
-// required to make it go code.
-// Names are uppercased to export them.
-// All fields have JSON tags added to correct the names.
-// Fields marked with a ? are also marked as "omitempty"
-// Fields that are "|| null" are made pointers
-// Fields that are string or number are left as string
-// Fields that are type "number" are made float64
-package protocol
diff -urN a/gopls/internal/lsp/protocol/enums.go b/gopls/internal/lsp/protocol/enums.go
--- a/gopls/internal/lsp/protocol/enums.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/enums.go	1969-12-31 16:00:00
@@ -1,231 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-import (
-	"fmt"
-)
-
-var (
-	namesTextDocumentSyncKind   [int(Incremental) + 1]string
-	namesMessageType            [int(Log) + 1]string
-	namesFileChangeType         [int(Deleted) + 1]string
-	namesWatchKind              [int(WatchDelete) + 1]string
-	namesCompletionTriggerKind  [int(TriggerForIncompleteCompletions) + 1]string
-	namesDiagnosticSeverity     [int(SeverityHint) + 1]string
-	namesDiagnosticTag          [int(Unnecessary) + 1]string
-	namesCompletionItemKind     [int(TypeParameterCompletion) + 1]string
-	namesInsertTextFormat       [int(SnippetTextFormat) + 1]string
-	namesDocumentHighlightKind  [int(Write) + 1]string
-	namesSymbolKind             [int(TypeParameter) + 1]string
-	namesTextDocumentSaveReason [int(FocusOut) + 1]string
-)
-
-func init() {
-	namesTextDocumentSyncKind[int(None)] = "None"
-	namesTextDocumentSyncKind[int(Full)] = "Full"
-	namesTextDocumentSyncKind[int(Incremental)] = "Incremental"
-
-	namesMessageType[int(Error)] = "Error"
-	namesMessageType[int(Warning)] = "Warning"
-	namesMessageType[int(Info)] = "Info"
-	namesMessageType[int(Log)] = "Log"
-
-	namesFileChangeType[int(Created)] = "Created"
-	namesFileChangeType[int(Changed)] = "Changed"
-	namesFileChangeType[int(Deleted)] = "Deleted"
-
-	namesWatchKind[int(WatchCreate)] = "WatchCreate"
-	namesWatchKind[int(WatchChange)] = "WatchChange"
-	namesWatchKind[int(WatchDelete)] = "WatchDelete"
-
-	namesCompletionTriggerKind[int(Invoked)] = "Invoked"
-	namesCompletionTriggerKind[int(TriggerCharacter)] = "TriggerCharacter"
-	namesCompletionTriggerKind[int(TriggerForIncompleteCompletions)] = "TriggerForIncompleteCompletions"
-
-	namesDiagnosticSeverity[int(SeverityError)] = "Error"
-	namesDiagnosticSeverity[int(SeverityWarning)] = "Warning"
-	namesDiagnosticSeverity[int(SeverityInformation)] = "Information"
-	namesDiagnosticSeverity[int(SeverityHint)] = "Hint"
-
-	namesDiagnosticTag[int(Unnecessary)] = "Unnecessary"
-
-	namesCompletionItemKind[int(TextCompletion)] = "text"
-	namesCompletionItemKind[int(MethodCompletion)] = "method"
-	namesCompletionItemKind[int(FunctionCompletion)] = "func"
-	namesCompletionItemKind[int(ConstructorCompletion)] = "constructor"
-	namesCompletionItemKind[int(FieldCompletion)] = "field"
-	namesCompletionItemKind[int(VariableCompletion)] = "var"
-	namesCompletionItemKind[int(ClassCompletion)] = "type"
-	namesCompletionItemKind[int(InterfaceCompletion)] = "interface"
-	namesCompletionItemKind[int(ModuleCompletion)] = "package"
-	namesCompletionItemKind[int(PropertyCompletion)] = "property"
-	namesCompletionItemKind[int(UnitCompletion)] = "unit"
-	namesCompletionItemKind[int(ValueCompletion)] = "value"
-	namesCompletionItemKind[int(EnumCompletion)] = "enum"
-	namesCompletionItemKind[int(KeywordCompletion)] = "keyword"
-	namesCompletionItemKind[int(SnippetCompletion)] = "snippet"
-	namesCompletionItemKind[int(ColorCompletion)] = "color"
-	namesCompletionItemKind[int(FileCompletion)] = "file"
-	namesCompletionItemKind[int(ReferenceCompletion)] = "reference"
-	namesCompletionItemKind[int(FolderCompletion)] = "folder"
-	namesCompletionItemKind[int(EnumMemberCompletion)] = "enumMember"
-	namesCompletionItemKind[int(ConstantCompletion)] = "const"
-	namesCompletionItemKind[int(StructCompletion)] = "struct"
-	namesCompletionItemKind[int(EventCompletion)] = "event"
-	namesCompletionItemKind[int(OperatorCompletion)] = "operator"
-	namesCompletionItemKind[int(TypeParameterCompletion)] = "typeParam"
-
-	namesInsertTextFormat[int(PlainTextTextFormat)] = "PlainText"
-	namesInsertTextFormat[int(SnippetTextFormat)] = "Snippet"
-
-	namesDocumentHighlightKind[int(Text)] = "Text"
-	namesDocumentHighlightKind[int(Read)] = "Read"
-	namesDocumentHighlightKind[int(Write)] = "Write"
-
-	namesSymbolKind[int(File)] = "File"
-	namesSymbolKind[int(Module)] = "Module"
-	namesSymbolKind[int(Namespace)] = "Namespace"
-	namesSymbolKind[int(Package)] = "Package"
-	namesSymbolKind[int(Class)] = "Class"
-	namesSymbolKind[int(Method)] = "Method"
-	namesSymbolKind[int(Property)] = "Property"
-	namesSymbolKind[int(Field)] = "Field"
-	namesSymbolKind[int(Constructor)] = "Constructor"
-	namesSymbolKind[int(Enum)] = "Enum"
-	namesSymbolKind[int(Interface)] = "Interface"
-	namesSymbolKind[int(Function)] = "Function"
-	namesSymbolKind[int(Variable)] = "Variable"
-	namesSymbolKind[int(Constant)] = "Constant"
-	namesSymbolKind[int(String)] = "String"
-	namesSymbolKind[int(Number)] = "Number"
-	namesSymbolKind[int(Boolean)] = "Boolean"
-	namesSymbolKind[int(Array)] = "Array"
-	namesSymbolKind[int(Object)] = "Object"
-	namesSymbolKind[int(Key)] = "Key"
-	namesSymbolKind[int(Null)] = "Null"
-	namesSymbolKind[int(EnumMember)] = "EnumMember"
-	namesSymbolKind[int(Struct)] = "Struct"
-	namesSymbolKind[int(Event)] = "Event"
-	namesSymbolKind[int(Operator)] = "Operator"
-	namesSymbolKind[int(TypeParameter)] = "TypeParameter"
-
-	namesTextDocumentSaveReason[int(Manual)] = "Manual"
-	namesTextDocumentSaveReason[int(AfterDelay)] = "AfterDelay"
-	namesTextDocumentSaveReason[int(FocusOut)] = "FocusOut"
-}
-
-func formatEnum(f fmt.State, c rune, i int, names []string, unknown string) {
-	s := ""
-	if i >= 0 && i < len(names) {
-		s = names[i]
-	}
-	if s != "" {
-		fmt.Fprint(f, s)
-	} else {
-		fmt.Fprintf(f, "%s(%d)", unknown, i)
-	}
-}
-
-func parseEnum(s string, names []string) int {
-	for i, name := range names {
-		if s == name {
-			return i
-		}
-	}
-	return 0
-}
-
-func (e TextDocumentSyncKind) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesTextDocumentSyncKind[:], "TextDocumentSyncKind")
-}
-
-func ParseTextDocumentSyncKind(s string) TextDocumentSyncKind {
-	return TextDocumentSyncKind(parseEnum(s, namesTextDocumentSyncKind[:]))
-}
-
-func (e MessageType) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesMessageType[:], "MessageType")
-}
-
-func ParseMessageType(s string) MessageType {
-	return MessageType(parseEnum(s, namesMessageType[:]))
-}
-
-func (e FileChangeType) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesFileChangeType[:], "FileChangeType")
-}
-
-func ParseFileChangeType(s string) FileChangeType {
-	return FileChangeType(parseEnum(s, namesFileChangeType[:]))
-}
-
-func ParseWatchKind(s string) WatchKind {
-	return WatchKind(parseEnum(s, namesWatchKind[:]))
-}
-
-func (e CompletionTriggerKind) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesCompletionTriggerKind[:], "CompletionTriggerKind")
-}
-
-func ParseCompletionTriggerKind(s string) CompletionTriggerKind {
-	return CompletionTriggerKind(parseEnum(s, namesCompletionTriggerKind[:]))
-}
-
-func (e DiagnosticSeverity) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesDiagnosticSeverity[:], "DiagnosticSeverity")
-}
-
-func ParseDiagnosticSeverity(s string) DiagnosticSeverity {
-	return DiagnosticSeverity(parseEnum(s, namesDiagnosticSeverity[:]))
-}
-
-func (e DiagnosticTag) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesDiagnosticTag[:], "DiagnosticTag")
-}
-
-func ParseDiagnosticTag(s string) DiagnosticTag {
-	return DiagnosticTag(parseEnum(s, namesDiagnosticTag[:]))
-}
-
-func (e CompletionItemKind) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesCompletionItemKind[:], "CompletionItemKind")
-}
-
-func ParseCompletionItemKind(s string) CompletionItemKind {
-	return CompletionItemKind(parseEnum(s, namesCompletionItemKind[:]))
-}
-
-func (e InsertTextFormat) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesInsertTextFormat[:], "InsertTextFormat")
-}
-
-func ParseInsertTextFormat(s string) InsertTextFormat {
-	return InsertTextFormat(parseEnum(s, namesInsertTextFormat[:]))
-}
-
-func (e DocumentHighlightKind) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesDocumentHighlightKind[:], "DocumentHighlightKind")
-}
-
-func ParseDocumentHighlightKind(s string) DocumentHighlightKind {
-	return DocumentHighlightKind(parseEnum(s, namesDocumentHighlightKind[:]))
-}
-
-func (e SymbolKind) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesSymbolKind[:], "SymbolKind")
-}
-
-func ParseSymbolKind(s string) SymbolKind {
-	return SymbolKind(parseEnum(s, namesSymbolKind[:]))
-}
-
-func (e TextDocumentSaveReason) Format(f fmt.State, c rune) {
-	formatEnum(f, c, int(e), namesTextDocumentSaveReason[:], "TextDocumentSaveReason")
-}
-
-func ParseTextDocumentSaveReason(s string) TextDocumentSaveReason {
-	return TextDocumentSaveReason(parseEnum(s, namesTextDocumentSaveReason[:]))
-}
diff -urN a/gopls/internal/lsp/protocol/generate/compare.go b/gopls/internal/lsp/protocol/generate/compare.go
--- a/gopls/internal/lsp/protocol/generate/compare.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/compare.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-// compare the generated files in two directories
diff -urN a/gopls/internal/lsp/protocol/generate/data.go b/gopls/internal/lsp/protocol/generate/data.go
--- a/gopls/internal/lsp/protocol/generate/data.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/data.go	1969-12-31 16:00:00
@@ -1,104 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-// various data tables
-
-// methodNames is a map from the method to the name of the function that handles it
-var methodNames = map[string]string{
-	"$/cancelRequest":                        "CancelRequest",
-	"$/logTrace":                             "LogTrace",
-	"$/progress":                             "Progress",
-	"$/setTrace":                             "SetTrace",
-	"callHierarchy/incomingCalls":            "IncomingCalls",
-	"callHierarchy/outgoingCalls":            "OutgoingCalls",
-	"client/registerCapability":              "RegisterCapability",
-	"client/unregisterCapability":            "UnregisterCapability",
-	"codeAction/resolve":                     "ResolveCodeAction",
-	"codeLens/resolve":                       "ResolveCodeLens",
-	"completionItem/resolve":                 "ResolveCompletionItem",
-	"documentLink/resolve":                   "ResolveDocumentLink",
-	"exit":                                   "Exit",
-	"initialize":                             "Initialize",
-	"initialized":                            "Initialized",
-	"inlayHint/resolve":                      "Resolve",
-	"notebookDocument/didChange":             "DidChangeNotebookDocument",
-	"notebookDocument/didClose":              "DidCloseNotebookDocument",
-	"notebookDocument/didOpen":               "DidOpenNotebookDocument",
-	"notebookDocument/didSave":               "DidSaveNotebookDocument",
-	"shutdown":                               "Shutdown",
-	"telemetry/event":                        "Event",
-	"textDocument/codeAction":                "CodeAction",
-	"textDocument/codeLens":                  "CodeLens",
-	"textDocument/colorPresentation":         "ColorPresentation",
-	"textDocument/completion":                "Completion",
-	"textDocument/declaration":               "Declaration",
-	"textDocument/definition":                "Definition",
-	"textDocument/diagnostic":                "Diagnostic",
-	"textDocument/didChange":                 "DidChange",
-	"textDocument/didClose":                  "DidClose",
-	"textDocument/didOpen":                   "DidOpen",
-	"textDocument/didSave":                   "DidSave",
-	"textDocument/documentColor":             "DocumentColor",
-	"textDocument/documentHighlight":         "DocumentHighlight",
-	"textDocument/documentLink":              "DocumentLink",
-	"textDocument/documentSymbol":            "DocumentSymbol",
-	"textDocument/foldingRange":              "FoldingRange",
-	"textDocument/formatting":                "Formatting",
-	"textDocument/hover":                     "Hover",
-	"textDocument/implementation":            "Implementation",
-	"textDocument/inlayHint":                 "InlayHint",
-	"textDocument/inlineValue":               "InlineValue",
-	"textDocument/linkedEditingRange":        "LinkedEditingRange",
-	"textDocument/moniker":                   "Moniker",
-	"textDocument/onTypeFormatting":          "OnTypeFormatting",
-	"textDocument/prepareCallHierarchy":      "PrepareCallHierarchy",
-	"textDocument/prepareRename":             "PrepareRename",
-	"textDocument/prepareTypeHierarchy":      "PrepareTypeHierarchy",
-	"textDocument/publishDiagnostics":        "PublishDiagnostics",
-	"textDocument/rangeFormatting":           "RangeFormatting",
-	"textDocument/references":                "References",
-	"textDocument/rename":                    "Rename",
-	"textDocument/selectionRange":            "SelectionRange",
-	"textDocument/semanticTokens/full":       "SemanticTokensFull",
-	"textDocument/semanticTokens/full/delta": "SemanticTokensFullDelta",
-	"textDocument/semanticTokens/range":      "SemanticTokensRange",
-	"textDocument/signatureHelp":             "SignatureHelp",
-	"textDocument/typeDefinition":            "TypeDefinition",
-	"textDocument/willSave":                  "WillSave",
-	"textDocument/willSaveWaitUntil":         "WillSaveWaitUntil",
-	"typeHierarchy/subtypes":                 "Subtypes",
-	"typeHierarchy/supertypes":               "Supertypes",
-	"window/logMessage":                      "LogMessage",
-	"window/showDocument":                    "ShowDocument",
-	"window/showMessage":                     "ShowMessage",
-	"window/showMessageRequest":              "ShowMessageRequest",
-	"window/workDoneProgress/cancel":         "WorkDoneProgressCancel",
-	"window/workDoneProgress/create":         "WorkDoneProgressCreate",
-	"workspace/applyEdit":                    "ApplyEdit",
-	"workspace/codeLens/refresh":             "CodeLensRefresh",
-	"workspace/configuration":                "Configuration",
-	"workspace/diagnostic":                   "DiagnosticWorkspace",
-	"workspace/diagnostic/refresh":           "DiagnosticRefresh",
-	"workspace/didChangeConfiguration":       "DidChangeConfiguration",
-	"workspace/didChangeWatchedFiles":        "DidChangeWatchedFiles",
-	"workspace/didChangeWorkspaceFolders":    "DidChangeWorkspaceFolders",
-	"workspace/didCreateFiles":               "DidCreateFiles",
-	"workspace/didDeleteFiles":               "DidDeleteFiles",
-	"workspace/didRenameFiles":               "DidRenameFiles",
-	"workspace/executeCommand":               "ExecuteCommand",
-	"workspace/inlayHint/refresh":            "InlayHintRefresh",
-	"workspace/inlineValue/refresh":          "InlineValueRefresh",
-	"workspace/semanticTokens/refresh":       "SemanticTokensRefresh",
-	"workspace/symbol":                       "Symbol",
-	"workspace/willCreateFiles":              "WillCreateFiles",
-	"workspace/willDeleteFiles":              "WillDeleteFiles",
-	"workspace/willRenameFiles":              "WillRenameFiles",
-	"workspace/workspaceFolders":             "WorkspaceFolders",
-	"workspaceSymbol/resolve":                "ResolveWorkspaceSymbol",
-}
diff -urN a/gopls/internal/lsp/protocol/generate/doc.go b/gopls/internal/lsp/protocol/generate/doc.go
--- a/gopls/internal/lsp/protocol/generate/doc.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/doc.go	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-/*
-GenLSP  generates the files tsprotocol.go, tsclient.go,
-tsserver.go, tsjson.go that support the language server protocol
-for gopls.
-
-Usage:
-
-	go run . [flags]
-
-The flags are:
-
-	-d <directory name>
-		The directory containing the vscode-languageserver-node repository.
-		(git clone https://github.com/microsoft/vscode-languageserver-node.git).
-		If not specified, the default is $HOME/vscode-languageserver-node.
-
-	-o <directory name>
-		The directory to write the generated files to. It must exist.
-		The default is "gen".
-
-	-c <directory name>
-		Compare the generated files to the files in the specified directory.
-		If this flag is not specified, no comparison is done.
-*/
-package main
diff -urN a/gopls/internal/lsp/protocol/generate/generate.go b/gopls/internal/lsp/protocol/generate/generate.go
--- a/gopls/internal/lsp/protocol/generate/generate.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/generate.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-// generate the Go code
diff -urN a/gopls/internal/lsp/protocol/generate/main.go b/gopls/internal/lsp/protocol/generate/main.go
--- a/gopls/internal/lsp/protocol/generate/main.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/main.go	1969-12-31 16:00:00
@@ -1,93 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-import (
-	"flag"
-	"fmt"
-	"log"
-	"os"
-)
-
-var (
-	// git clone https://github.com/microsoft/vscode-languageserver-node.git
-	repodir   = flag.String("d", "", "directory of vscode-languageserver-node")
-	outputdir = flag.String("o", "gen", "output directory")
-	cmpolder  = flag.String("c", "", "directory of older generated code")
-)
-
-func main() {
-	log.SetFlags(log.Lshortfile) // log file name and line number, not time
-	flag.Parse()
-
-	if *repodir == "" {
-		*repodir = fmt.Sprintf("%s/vscode-languageserver-node", os.Getenv("HOME"))
-	}
-	spec := parse(*repodir)
-
-	// index the information in the specification
-	spec.indexRPCInfo() // messages
-	spec.indexDefInfo() // named types
-
-}
-
-func (s *spec) indexRPCInfo() {
-	for _, r := range s.model.Requests {
-		r := r
-		s.byMethod[r.Method] = &r
-	}
-	for _, n := range s.model.Notifications {
-		n := n
-		if n.Method == "$/cancelRequest" {
-			// viewed as too confusing to generate
-			continue
-		}
-		s.byMethod[n.Method] = &n
-	}
-}
-
-func (sp *spec) indexDefInfo() {
-	for _, s := range sp.model.Structures {
-		s := s
-		sp.byName[s.Name] = &s
-	}
-	for _, e := range sp.model.Enumerations {
-		e := e
-		sp.byName[e.Name] = &e
-	}
-	for _, ta := range sp.model.TypeAliases {
-		ta := ta
-		sp.byName[ta.Name] = &ta
-	}
-
-	// some Structure and TypeAlias names need to be changed for Go
-	// so byName contains the name used in the .json file, and
-	// the Name field contains the Go version of the name.
-	v := sp.model.Structures
-	for i, s := range v {
-		switch s.Name {
-		case "_InitializeParams": // _ is not upper case
-			v[i].Name = "XInitializeParams"
-		case "ConfigurationParams": // gopls compatibility
-			v[i].Name = "ParamConfiguration"
-		case "InitializeParams": // gopls compatibility
-			v[i].Name = "ParamInitialize"
-		case "PreviousResultId": // Go naming convention
-			v[i].Name = "PreviousResultID"
-		case "WorkspaceFoldersServerCapabilities": // gopls compatibility
-			v[i].Name = "WorkspaceFolders5Gn"
-		}
-	}
-	w := sp.model.TypeAliases
-	for i, t := range w {
-		switch t.Name {
-		case "PrepareRenameResult": // gopls compatibility
-			w[i].Name = "PrepareRename2Gn"
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/protocol/generate/main_test.go b/gopls/internal/lsp/protocol/generate/main_test.go
--- a/gopls/internal/lsp/protocol/generate/main_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/main_test.go	1969-12-31 16:00:00
@@ -1,122 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-import (
-	"encoding/json"
-	"fmt"
-	"log"
-	"os"
-	"testing"
-)
-
-// this is not a test, but an easy way to invoke the debugger
-func TestAll(t *testing.T) {
-	t.Skip("run by hand")
-	log.SetFlags(log.Lshortfile)
-	main()
-}
-
-// this is not a test, but an easy way to invoke the debugger
-func TestCompare(t *testing.T) {
-	t.Skip("run by hand")
-	log.SetFlags(log.Lshortfile)
-	*cmpolder = "../lsp/gen" // instead use a directory containing the older generated files
-	main()
-}
-
-// check that the parsed file includes all the information
-// from the json file. This test will fail if the spec
-// introduces new fields. (one can test this test by
-// commenting out some special handling in parse.go.)
-func TestParseContents(t *testing.T) {
-	t.Skip("run by hand")
-	log.SetFlags(log.Lshortfile)
-
-	// compute our parse of the specification
-	dir := os.Getenv("HOME") + "/vscode-languageserver-node"
-	v := parse(dir)
-	out, err := json.Marshal(v.model)
-	if err != nil {
-		t.Fatal(err)
-	}
-	var our interface{}
-	if err := json.Unmarshal(out, &our); err != nil {
-		t.Fatal(err)
-	}
-
-	// process the json file
-	fname := dir + "/protocol/metaModel.json"
-	buf, err := os.ReadFile(fname)
-	if err != nil {
-		t.Fatalf("could not read metaModel.json: %v", err)
-	}
-	var raw interface{}
-	if err := json.Unmarshal(buf, &raw); err != nil {
-		t.Fatal(err)
-	}
-
-	// convert to strings showing the fields
-	them := flatten(raw)
-	us := flatten(our)
-
-	// everything in them should be in us
-	lesser := make(sortedMap[bool])
-	for _, s := range them {
-		lesser[s] = true
-	}
-	greater := make(sortedMap[bool]) // set of fields we have
-	for _, s := range us {
-		greater[s] = true
-	}
-	for _, k := range lesser.keys() { // set if fields they have
-		if !greater[k] {
-			t.Errorf("missing %s", k)
-		}
-	}
-}
-
-// flatten(nil) = "nil"
-// flatten(v string) = fmt.Sprintf("%q", v)
-// flatten(v float64)= fmt.Sprintf("%g", v)
-// flatten(v bool) = fmt.Sprintf("%v", v)
-// flatten(v []any) = []string{"[0]"flatten(v[0]), "[1]"flatten(v[1]), ...}
-// flatten(v map[string]any) = {"key1": flatten(v["key1"]), "key2": flatten(v["key2"]), ...}
-func flatten(x any) []string {
-	switch v := x.(type) {
-	case nil:
-		return []string{"nil"}
-	case string:
-		return []string{fmt.Sprintf("%q", v)}
-	case float64:
-		return []string{fmt.Sprintf("%g", v)}
-	case bool:
-		return []string{fmt.Sprintf("%v", v)}
-	case []any:
-		var ans []string
-		for i, x := range v {
-			idx := fmt.Sprintf("[%.3d]", i)
-			for _, s := range flatten(x) {
-				ans = append(ans, idx+s)
-			}
-		}
-		return ans
-	case map[string]any:
-		var ans []string
-		for k, x := range v {
-			idx := fmt.Sprintf("%q:", k)
-			for _, s := range flatten(x) {
-				ans = append(ans, idx+s)
-			}
-		}
-		return ans
-	default:
-		log.Fatalf("unexpected type %T", x)
-		return nil
-	}
-}
diff -urN a/gopls/internal/lsp/protocol/generate/naming.go b/gopls/internal/lsp/protocol/generate/naming.go
--- a/gopls/internal/lsp/protocol/generate/naming.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/naming.go	1969-12-31 16:00:00
@@ -1,64 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-// assign names to types. many types come with names, but names
-// have to be provided for "or", "and", "tuple", and "literal" types.
-// Only one tuple type occurs, so it poses no problem. Otherwise
-// the name cannot depend on the ordering of the components, as permuting
-// them doesn't change the type. One possibility is to build the name
-// of the type out of the names of its components, done in an
-// earlier version of this code, but rejected by code reviewers.
-// (the name would change if the components changed.)
-// An alternate is to use the definition context, which is what is done here
-// and works for the existing code. However, it cannot work in general.
-// (This easiest case is an "or" type with two "literal" components.
-// The components will get the same name, as their definition contexts
-// are identical.) spec.byName contains enough information to detect
-// such cases. (Note that sometimes giving the same name to different
-// types is correct, for instance when they involve stringLiterals.)
-
-import (
-	"strings"
-)
-
-// stacks contain information about the ancestry of a type
-// (spaces and initial capital letters are treated specially in stack.name())
-type stack []string
-
-func (s stack) push(v string) stack {
-	return append(s, v)
-}
-
-func (s stack) pop() {
-	s = s[:len(s)-1]
-}
-
-// generate a type name from the stack that contains its ancestry
-//
-// For instance, ["Result textDocument/implementation"] becomes "_textDocument_implementation"
-// which, after being returned, becomes "Or_textDocument_implementation",
-// which will become "[]Location" eventually (for gopls compatibility).
-func (s stack) name(prefix string) string {
-	var nm string
-	var seen int
-	// use the most recent 2 entries, if there are 2,
-	// or just the only one.
-	for i := len(s) - 1; i >= 0 && seen < 2; i-- {
-		x := s[i]
-		if x[0] <= 'Z' && x[0] >= 'A' {
-			// it may contain a message
-			if idx := strings.Index(x, " "); idx >= 0 {
-				x = prefix + strings.Replace(x[idx+1:], "/", "_", -1)
-			}
-			nm += x
-			seen++
-		}
-	}
-	return nm
-}
diff -urN a/gopls/internal/lsp/protocol/generate/output.go b/gopls/internal/lsp/protocol/generate/output.go
--- a/gopls/internal/lsp/protocol/generate/output.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/output.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-// Write the output
diff -urN a/gopls/internal/lsp/protocol/generate/parse.go b/gopls/internal/lsp/protocol/generate/parse.go
--- a/gopls/internal/lsp/protocol/generate/parse.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/parse.go	1969-12-31 16:00:00
@@ -1,174 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-import (
-	"bytes"
-	"encoding/json"
-	"fmt"
-	"log"
-	"os"
-	"path/filepath"
-	"time"
-)
-
-// a spec contains the specification of the protocol, and derived information.
-type spec struct {
-	model *Model
-
-	// combined Requests and Notifications, indexed by method (e.g., "textDocument/didOpen")
-	byMethod sortedMap[Message]
-
-	// Structures, Enumerations, and TypeAliases, indexed by name used in
-	// the .json specification file
-	// (Some Structure and Enumeration names need to be changed for Go,
-	// such as _Initialize)
-	byName sortedMap[Defined]
-
-	// computed type information
-	nameToTypes sortedMap[[]*Type] // all the uses of a type name
-
-	// remember which types are in a union type
-	orTypes sortedMap[sortedMap[bool]]
-
-	// information about the version of vscode-languageclient-node
-	githash string
-	modTime time.Time
-}
-
-// parse the specification file and return a spec.
-// (TestParseContents checks that the parse gets all the fields of the specification)
-func parse(dir string) *spec {
-	fname := filepath.Join(dir, "protocol", "metaModel.json")
-	buf, err := os.ReadFile(fname)
-	if err != nil {
-		log.Fatalf("could not read metaModel.json: %v", err)
-	}
-	// line numbers in the .json file occur as comments in tsprotocol.go
-	newbuf := addLineNumbers(buf)
-	var v Model
-	if err := json.Unmarshal(newbuf, &v); err != nil {
-		log.Fatalf("could not unmarshal metaModel.json: %v", err)
-	}
-
-	ans := &spec{
-		model:       &v,
-		byMethod:    make(sortedMap[Message]),
-		byName:      make(sortedMap[Defined]),
-		nameToTypes: make(sortedMap[[]*Type]),
-		orTypes:     make(sortedMap[sortedMap[bool]]),
-	}
-	ans.githash, ans.modTime = gitInfo(dir)
-	return ans
-}
-
-// gitInfo returns the git hash and modtime of the repository.
-func gitInfo(dir string) (string, time.Time) {
-	fname := dir + "/.git/HEAD"
-	buf, err := os.ReadFile(fname)
-	if err != nil {
-		log.Fatal(err)
-	}
-	buf = bytes.TrimSpace(buf)
-	var githash string
-	if len(buf) == 40 {
-		githash = string(buf[:40])
-	} else if bytes.HasPrefix(buf, []byte("ref: ")) {
-		fname = dir + "/.git/" + string(buf[5:])
-		buf, err = os.ReadFile(fname)
-		if err != nil {
-			log.Fatal(err)
-		}
-		githash = string(buf[:40])
-	} else {
-		log.Fatalf("githash cannot be recovered from %s", fname)
-	}
-	loadTime := time.Now()
-	return githash, loadTime
-}
-
-// addLineNumbers adds a "line" field to each object in the JSON.
-func addLineNumbers(buf []byte) []byte {
-	var ans []byte
-	// In the specification .json file, the delimiter '{' is
-	// always followed by a newline. There are other {s embedded in strings.
-	// json.Token does not return \n, or :, or , so using it would
-	// require parsing the json to reconstruct the missing information.
-	for linecnt, i := 1, 0; i < len(buf); i++ {
-		ans = append(ans, buf[i])
-		switch buf[i] {
-		case '{':
-			if buf[i+1] == '\n' {
-				ans = append(ans, fmt.Sprintf(`"line": %d, `, linecnt)...)
-				// warning: this would fail if the spec file had
-				// `"value": {\n}`, but it does not, as comma is a separator.
-			}
-		case '\n':
-			linecnt++
-		}
-	}
-	return ans
-}
-
-// Type.Value has to be treated specially for literals and maps
-func (t *Type) UnmarshalJSON(data []byte) error {
-	// First unmarshal only the unambiguous fields.
-	var x struct {
-		Kind    string  `json:"kind"`
-		Items   []*Type `json:"items"`
-		Element *Type   `json:"element"`
-		Name    string  `json:"name"`
-		Key     *Type   `json:"key"`
-		Value   any     `json:"value"`
-		Line    int     `json:"line"`
-	}
-	if err := json.Unmarshal(data, &x); err != nil {
-		return err
-	}
-	*t = Type{
-		Kind:    x.Kind,
-		Items:   x.Items,
-		Element: x.Element,
-		Name:    x.Name,
-		Value:   x.Value,
-		Line:    x.Line,
-	}
-
-	// Then unmarshal the 'value' field based on the kind.
-	// This depends on Unmarshal ignoring fields it doesn't know about.
-	switch x.Kind {
-	case "map":
-		var x struct {
-			Key   *Type `json:"key"`
-			Value *Type `json:"value"`
-		}
-		if err := json.Unmarshal(data, &x); err != nil {
-			return fmt.Errorf("Type.kind=map: %v", err)
-		}
-		t.Key = x.Key
-		t.Value = x.Value
-
-	case "literal":
-		var z struct {
-			Value ParseLiteral `json:"value"`
-		}
-
-		if err := json.Unmarshal(data, &z); err != nil {
-			return fmt.Errorf("Type.kind=literal: %v", err)
-		}
-		t.Value = z.Value
-
-	case "base", "reference", "array", "and", "or", "tuple",
-		"stringLiteral":
-		// nop. never seen integerLiteral or booleanLiteral.
-
-	default:
-		return fmt.Errorf("cannot decode Type.kind %q: %s", x.Kind, data)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/protocol/generate/types.go b/gopls/internal/lsp/protocol/generate/types.go
--- a/gopls/internal/lsp/protocol/generate/types.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/types.go	1969-12-31 16:00:00
@@ -1,173 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-import "sort"
-
-// Model contains the parsed version of the spec
-type Model struct {
-	Version       Metadata       `json:"metaData"`
-	Requests      []Request      `json:"requests"`
-	Notifications []Notification `json:"notifications"`
-	Structures    []Structure    `json:"structures"`
-	Enumerations  []Enumeration  `json:"enumerations"`
-	TypeAliases   []TypeAlias    `json:"typeAliases"`
-	Line          int            `json:"line"`
-}
-
-// Metadata is information about the version of the spec
-type Metadata struct {
-	Version string `json:"version"`
-	Line    int    `json:"line"`
-}
-
-// A Request is the parsed version of an LSP request
-type Request struct {
-	Documentation       string `json:"documentation"`
-	ErrorData           *Type  `json:"errorData"`
-	Direction           string `json:"messageDirection"`
-	Method              string `json:"method"`
-	Params              *Type  `json:"params"`
-	PartialResult       *Type  `json:"partialResult"`
-	Proposed            bool   `json:"proposed"`
-	RegistrationMethod  string `json:"registrationMethod"`
-	RegistrationOptions *Type  `json:"registrationOptions"`
-	Result              *Type  `json:"result"`
-	Since               string `json:"since"`
-	Line                int    `json:"line"`
-}
-
-// A Notificatin is the parsed version of an LSP notification
-type Notification struct {
-	Documentation       string `json:"documentation"`
-	Direction           string `json:"messageDirection"`
-	Method              string `json:"method"`
-	Params              *Type  `json:"params"`
-	Proposed            bool   `json:"proposed"`
-	RegistrationMethod  string `json:"registrationMethod"`
-	RegistrationOptions *Type  `json:"registrationOptions"`
-	Since               string `json:"since"`
-	Line                int    `json:"line"`
-}
-
-// A Structure is the parsed version of an LSP structure from the spec
-type Structure struct {
-	Documentation string     `json:"documentation"`
-	Extends       []*Type    `json:"extends"`
-	Mixins        []*Type    `json:"mixins"`
-	Name          string     `json:"name"`
-	Properties    []NameType `json:"properties"`
-	Proposed      bool       `json:"proposed"`
-	Since         string     `json:"since"`
-	Line          int        `json:"line"`
-}
-
-// An enumeration is the parsed version of an LSP enumeration from the spec
-type Enumeration struct {
-	Documentation        string      `json:"documentation"`
-	Name                 string      `json:"name"`
-	Proposed             bool        `json:"proposed"`
-	Since                string      `json:"since"`
-	SupportsCustomValues bool        `json:"supportsCustomValues"`
-	Type                 *Type       `json:"type"`
-	Values               []NameValue `json:"values"`
-	Line                 int         `json:"line"`
-}
-
-// A TypeAlias is the parsed version of an LSP type alias from the spec
-type TypeAlias struct {
-	Documentation string `json:"documentation"`
-	Name          string `json:"name"`
-	Proposed      bool   `json:"proposed"`
-	Since         string `json:"since"`
-	Type          *Type  `json:"type"`
-	Line          int    `json:"line"`
-}
-
-// A NameValue describes an enumeration constant
-type NameValue struct {
-	Documentation string `json:"documentation"`
-	Name          string `json:"name"`
-	Proposed      bool   `json:"proposed"`
-	Since         string `json:"since"`
-	Value         any    `json:"value"` // number or string
-	Line          int    `json:"line"`
-}
-
-// common to Request and Notification
-type Message interface {
-	direction() string
-}
-
-func (r Request) direction() string {
-	return r.Direction
-}
-
-func (n Notification) direction() string {
-	return n.Direction
-}
-
-// A Defined is one of Structure, Enumeration, TypeAlias, for type checking
-type Defined interface {
-	tag()
-}
-
-func (s Structure) tag() {
-}
-
-func (e Enumeration) tag() {
-}
-
-func (ta TypeAlias) tag() {
-}
-
-// A Type is the parsed version of an LSP type from the spec,
-// or a Type the code constructs
-type Type struct {
-	Kind    string  `json:"kind"`    // -- which kind goes with which field --
-	Items   []*Type `json:"items"`   // "and", "or", "tuple"
-	Element *Type   `json:"element"` // "array"
-	Name    string  `json:"name"`    // "base", "reference"
-	Key     *Type   `json:"key"`     // "map"
-	Value   any     `json:"value"`   // "map", "stringLiteral", "literal"
-	// used to tie generated code to the specification
-	Line int `json:"line"`
-
-	name     string // these are generated names, like Uint32
-	typeName string // these are actual type names, like uint32
-}
-
-// ParsedLiteral is Type.Value when Type.Kind is "literal"
-type ParseLiteral struct {
-	Properties `json:"properties"`
-}
-
-// A NameType represents the name and type of a structure element
-type NameType struct {
-	Name          string `json:"name"`
-	Type          *Type  `json:"type"`
-	Optional      bool   `json:"optional"`
-	Documentation string `json:"documentation"`
-	Since         string `json:"since"`
-	Proposed      bool   `json:"proposed"`
-	Line          int    `json:"line"`
-}
-
-// Properties are the collection of structure elements
-type Properties []NameType
-
-type sortedMap[T any] map[string]T
-
-func (s sortedMap[T]) keys() []string {
-	var keys []string
-	for k := range s {
-		keys = append(keys, k)
-	}
-	sort.Strings(keys)
-	return keys
-}
diff -urN a/gopls/internal/lsp/protocol/generate/utilities.go b/gopls/internal/lsp/protocol/generate/utilities.go
--- a/gopls/internal/lsp/protocol/generate/utilities.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/generate/utilities.go	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package main
-
-import (
-	"fmt"
-	"log"
-	"runtime"
-	"strings"
-	"time"
-)
-
-// goName returns the Go version of a name.
-func goName(s string) string {
-	if s == "" {
-		return s // doesn't happen
-	}
-	s = strings.ToUpper(s[:1]) + s[1:]
-	if rest := strings.TrimSuffix(s, "Uri"); rest != s {
-		s = rest + "URI"
-	}
-	if rest := strings.TrimSuffix(s, "Id"); rest != s {
-		s = rest + "ID"
-	}
-	return s
-}
-
-// the common header for all generated files
-func (s *spec) createHeader() string {
-	format := `// Copyright 2022 The Go Authors. All rights reserved.
-	// Use of this source code is governed by a BSD-style
-	// license that can be found in the LICENSE file.
-
-	// Code generated for LSP. DO NOT EDIT.
-
-	package protocol
-
-	// Code generated from version %s of protocol/metaModel.json.
-	// git hash %s (as of %s)
-
-	`
-	hdr := fmt.Sprintf(format, s.model.Version.Version, s.githash, s.modTime.Format(time.ANSIC))
-	return hdr
-}
-
-// useful in debugging
-func here() {
-	_, f, l, _ := runtime.Caller(1)
-	log.Printf("here: %s:%d", f, l)
-}
diff -urN a/gopls/internal/lsp/protocol/log.go b/gopls/internal/lsp/protocol/log.go
--- a/gopls/internal/lsp/protocol/log.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/log.go	1969-12-31 16:00:00
@@ -1,136 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-import (
-	"context"
-	"fmt"
-	"io"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/internal/jsonrpc2"
-)
-
-type loggingStream struct {
-	stream jsonrpc2.Stream
-	logMu  sync.Mutex
-	log    io.Writer
-}
-
-// LoggingStream returns a stream that does LSP protocol logging too
-func LoggingStream(str jsonrpc2.Stream, w io.Writer) jsonrpc2.Stream {
-	return &loggingStream{stream: str, log: w}
-}
-
-func (s *loggingStream) Read(ctx context.Context) (jsonrpc2.Message, int64, error) {
-	msg, count, err := s.stream.Read(ctx)
-	if err == nil {
-		s.logCommon(msg, true)
-	}
-	return msg, count, err
-}
-
-func (s *loggingStream) Write(ctx context.Context, msg jsonrpc2.Message) (int64, error) {
-	s.logCommon(msg, false)
-	count, err := s.stream.Write(ctx, msg)
-	return count, err
-}
-
-func (s *loggingStream) Close() error {
-	return s.stream.Close()
-}
-
-type req struct {
-	method string
-	start  time.Time
-}
-
-type mapped struct {
-	mu          sync.Mutex
-	clientCalls map[string]req
-	serverCalls map[string]req
-}
-
-var maps = &mapped{
-	sync.Mutex{},
-	make(map[string]req),
-	make(map[string]req),
-}
-
-// these 4 methods are each used exactly once, but it seemed
-// better to have the encapsulation rather than ad hoc mutex
-// code in 4 places
-func (m *mapped) client(id string) req {
-	m.mu.Lock()
-	defer m.mu.Unlock()
-	v := m.clientCalls[id]
-	delete(m.clientCalls, id)
-	return v
-}
-
-func (m *mapped) server(id string) req {
-	m.mu.Lock()
-	defer m.mu.Unlock()
-	v := m.serverCalls[id]
-	delete(m.serverCalls, id)
-	return v
-}
-
-func (m *mapped) setClient(id string, r req) {
-	m.mu.Lock()
-	defer m.mu.Unlock()
-	m.clientCalls[id] = r
-}
-
-func (m *mapped) setServer(id string, r req) {
-	m.mu.Lock()
-	defer m.mu.Unlock()
-	m.serverCalls[id] = r
-}
-
-const eor = "\r\n\r\n\r\n"
-
-func (s *loggingStream) logCommon(msg jsonrpc2.Message, isRead bool) {
-	s.logMu.Lock()
-	defer s.logMu.Unlock()
-	direction, pastTense := "Received", "Received"
-	get, set := maps.client, maps.setServer
-	if isRead {
-		direction, pastTense = "Sending", "Sent"
-		get, set = maps.server, maps.setClient
-	}
-	if msg == nil || s.log == nil {
-		return
-	}
-	tm := time.Now()
-	tmfmt := tm.Format("15:04:05.000 PM")
-
-	buf := strings.Builder{}
-	fmt.Fprintf(&buf, "[Trace - %s] ", tmfmt) // common beginning
-	switch msg := msg.(type) {
-	case *jsonrpc2.Call:
-		id := fmt.Sprint(msg.ID())
-		fmt.Fprintf(&buf, "%s request '%s - (%s)'.\n", direction, msg.Method(), id)
-		fmt.Fprintf(&buf, "Params: %s%s", msg.Params(), eor)
-		set(id, req{method: msg.Method(), start: tm})
-	case *jsonrpc2.Notification:
-		fmt.Fprintf(&buf, "%s notification '%s'.\n", direction, msg.Method())
-		fmt.Fprintf(&buf, "Params: %s%s", msg.Params(), eor)
-	case *jsonrpc2.Response:
-		id := fmt.Sprint(msg.ID())
-		if err := msg.Err(); err != nil {
-			fmt.Fprintf(s.log, "[Error - %s] %s #%s %s%s", pastTense, tmfmt, id, err, eor)
-			return
-		}
-		cc := get(id)
-		elapsed := tm.Sub(cc.start)
-		fmt.Fprintf(&buf, "%s response '%s - (%s)' in %dms.\n",
-			direction, cc.method, id, elapsed/time.Millisecond)
-		fmt.Fprintf(&buf, "Result: %s%s", msg.Result(), eor)
-	}
-	s.log.Write([]byte(buf.String()))
-}
diff -urN a/gopls/internal/lsp/protocol/protocol.go b/gopls/internal/lsp/protocol/protocol.go
--- a/gopls/internal/lsp/protocol/protocol.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/protocol.go	1969-12-31 16:00:00
@@ -1,284 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"io"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/jsonrpc2"
-	jsonrpc2_v2 "golang.org/x/tools/internal/jsonrpc2_v2"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-var (
-	// RequestCancelledError should be used when a request is cancelled early.
-	RequestCancelledError   = jsonrpc2.NewError(-32800, "JSON RPC cancelled")
-	RequestCancelledErrorV2 = jsonrpc2_v2.NewError(-32800, "JSON RPC cancelled")
-)
-
-type ClientCloser interface {
-	Client
-	io.Closer
-}
-
-type connSender interface {
-	io.Closer
-
-	Notify(ctx context.Context, method string, params interface{}) error
-	Call(ctx context.Context, method string, params, result interface{}) error
-}
-
-type clientDispatcher struct {
-	sender connSender
-}
-
-func (c *clientDispatcher) Close() error {
-	return c.sender.Close()
-}
-
-// ClientDispatcher returns a Client that dispatches LSP requests across the
-// given jsonrpc2 connection.
-func ClientDispatcher(conn jsonrpc2.Conn) ClientCloser {
-	return &clientDispatcher{sender: clientConn{conn}}
-}
-
-type clientConn struct {
-	conn jsonrpc2.Conn
-}
-
-func (c clientConn) Close() error {
-	return c.conn.Close()
-}
-
-func (c clientConn) Notify(ctx context.Context, method string, params interface{}) error {
-	return c.conn.Notify(ctx, method, params)
-}
-
-func (c clientConn) Call(ctx context.Context, method string, params interface{}, result interface{}) error {
-	id, err := c.conn.Call(ctx, method, params, result)
-	if ctx.Err() != nil {
-		cancelCall(ctx, c, id)
-	}
-	return err
-}
-
-func ClientDispatcherV2(conn *jsonrpc2_v2.Connection) ClientCloser {
-	return &clientDispatcher{clientConnV2{conn}}
-}
-
-type clientConnV2 struct {
-	conn *jsonrpc2_v2.Connection
-}
-
-func (c clientConnV2) Close() error {
-	return c.conn.Close()
-}
-
-func (c clientConnV2) Notify(ctx context.Context, method string, params interface{}) error {
-	return c.conn.Notify(ctx, method, params)
-}
-
-func (c clientConnV2) Call(ctx context.Context, method string, params interface{}, result interface{}) error {
-	call := c.conn.Call(ctx, method, params)
-	err := call.Await(ctx, result)
-	if ctx.Err() != nil {
-		detached := xcontext.Detach(ctx)
-		c.conn.Notify(detached, "$/cancelRequest", &CancelParams{ID: call.ID().Raw()})
-	}
-	return err
-}
-
-// ServerDispatcher returns a Server that dispatches LSP requests across the
-// given jsonrpc2 connection.
-func ServerDispatcher(conn jsonrpc2.Conn) Server {
-	return &serverDispatcher{sender: clientConn{conn}}
-}
-
-func ServerDispatcherV2(conn *jsonrpc2_v2.Connection) Server {
-	return &serverDispatcher{sender: clientConnV2{conn}}
-}
-
-type serverDispatcher struct {
-	sender connSender
-}
-
-func ClientHandler(client Client, handler jsonrpc2.Handler) jsonrpc2.Handler {
-	return func(ctx context.Context, reply jsonrpc2.Replier, req jsonrpc2.Request) error {
-		if ctx.Err() != nil {
-			ctx := xcontext.Detach(ctx)
-			return reply(ctx, nil, RequestCancelledError)
-		}
-		handled, err := clientDispatch(ctx, client, reply, req)
-		if handled || err != nil {
-			return err
-		}
-		return handler(ctx, reply, req)
-	}
-}
-
-func ClientHandlerV2(client Client) jsonrpc2_v2.Handler {
-	return jsonrpc2_v2.HandlerFunc(func(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-		if ctx.Err() != nil {
-			return nil, RequestCancelledErrorV2
-		}
-		req1 := req2to1(req)
-		var (
-			result interface{}
-			resErr error
-		)
-		replier := func(_ context.Context, res interface{}, err error) error {
-			if err != nil {
-				resErr = err
-				return nil
-			}
-			result = res
-			return nil
-		}
-		_, err := clientDispatch(ctx, client, replier, req1)
-		if err != nil {
-			return nil, err
-		}
-		return result, resErr
-	})
-}
-
-func ServerHandler(server Server, handler jsonrpc2.Handler) jsonrpc2.Handler {
-	return func(ctx context.Context, reply jsonrpc2.Replier, req jsonrpc2.Request) error {
-		if ctx.Err() != nil {
-			ctx := xcontext.Detach(ctx)
-			return reply(ctx, nil, RequestCancelledError)
-		}
-		handled, err := serverDispatch(ctx, server, reply, req)
-		if handled || err != nil {
-			return err
-		}
-		//TODO: This code is wrong, it ignores handler and assumes non standard
-		// request handles everything
-		// non standard request should just be a layered handler.
-		var params interface{}
-		if err := json.Unmarshal(req.Params(), &params); err != nil {
-			return sendParseError(ctx, reply, err)
-		}
-		resp, err := server.NonstandardRequest(ctx, req.Method(), params)
-		return reply(ctx, resp, err)
-
-	}
-}
-
-func ServerHandlerV2(server Server) jsonrpc2_v2.Handler {
-	return jsonrpc2_v2.HandlerFunc(func(ctx context.Context, req *jsonrpc2_v2.Request) (interface{}, error) {
-		if ctx.Err() != nil {
-			return nil, RequestCancelledErrorV2
-		}
-		req1 := req2to1(req)
-		var (
-			result interface{}
-			resErr error
-		)
-		replier := func(_ context.Context, res interface{}, err error) error {
-			if err != nil {
-				resErr = err
-				return nil
-			}
-			result = res
-			return nil
-		}
-		_, err := serverDispatch(ctx, server, replier, req1)
-		if err != nil {
-			return nil, err
-		}
-		return result, resErr
-	})
-}
-
-func req2to1(req2 *jsonrpc2_v2.Request) jsonrpc2.Request {
-	if req2.ID.IsValid() {
-		raw := req2.ID.Raw()
-		var idv1 jsonrpc2.ID
-		switch v := raw.(type) {
-		case int64:
-			idv1 = jsonrpc2.NewIntID(v)
-		case string:
-			idv1 = jsonrpc2.NewStringID(v)
-		default:
-			panic(fmt.Sprintf("unsupported ID type %T", raw))
-		}
-		req1, err := jsonrpc2.NewCall(idv1, req2.Method, req2.Params)
-		if err != nil {
-			panic(err)
-		}
-		return req1
-	}
-	req1, err := jsonrpc2.NewNotification(req2.Method, req2.Params)
-	if err != nil {
-		panic(err)
-	}
-	return req1
-}
-
-func Handlers(handler jsonrpc2.Handler) jsonrpc2.Handler {
-	return CancelHandler(
-		jsonrpc2.AsyncHandler(
-			jsonrpc2.MustReplyHandler(handler)))
-}
-
-func CancelHandler(handler jsonrpc2.Handler) jsonrpc2.Handler {
-	handler, canceller := jsonrpc2.CancelHandler(handler)
-	return func(ctx context.Context, reply jsonrpc2.Replier, req jsonrpc2.Request) error {
-		if req.Method() != "$/cancelRequest" {
-			// TODO(iancottrell): See if we can generate a reply for the request to be cancelled
-			// at the point of cancellation rather than waiting for gopls to naturally reply.
-			// To do that, we need to keep track of whether a reply has been sent already and
-			// be careful about racing between the two paths.
-			// TODO(iancottrell): Add a test that watches the stream and verifies the response
-			// for the cancelled request flows.
-			replyWithDetachedContext := func(ctx context.Context, resp interface{}, err error) error {
-				// https://microsoft.github.io/language-server-protocol/specifications/specification-current/#cancelRequest
-				if ctx.Err() != nil && err == nil {
-					err = RequestCancelledError
-				}
-				ctx = xcontext.Detach(ctx)
-				return reply(ctx, resp, err)
-			}
-			return handler(ctx, replyWithDetachedContext, req)
-		}
-		var params CancelParams
-		if err := json.Unmarshal(req.Params(), &params); err != nil {
-			return sendParseError(ctx, reply, err)
-		}
-		if n, ok := params.ID.(float64); ok {
-			canceller(jsonrpc2.NewIntID(int64(n)))
-		} else if s, ok := params.ID.(string); ok {
-			canceller(jsonrpc2.NewStringID(s))
-		} else {
-			return sendParseError(ctx, reply, fmt.Errorf("request ID %v malformed", params.ID))
-		}
-		return reply(ctx, nil, nil)
-	}
-}
-
-func Call(ctx context.Context, conn jsonrpc2.Conn, method string, params interface{}, result interface{}) error {
-	id, err := conn.Call(ctx, method, params, result)
-	if ctx.Err() != nil {
-		cancelCall(ctx, clientConn{conn}, id)
-	}
-	return err
-}
-
-func cancelCall(ctx context.Context, sender connSender, id jsonrpc2.ID) {
-	ctx = xcontext.Detach(ctx)
-	ctx, done := event.Start(ctx, "protocol.canceller")
-	defer done()
-	// Note that only *jsonrpc2.ID implements json.Marshaler.
-	sender.Notify(ctx, "$/cancelRequest", &CancelParams{ID: &id})
-}
-
-func sendParseError(ctx context.Context, reply jsonrpc2.Replier, err error) error {
-	return reply(ctx, nil, fmt.Errorf("%w: %s", jsonrpc2.ErrParse, err))
-}
diff -urN a/gopls/internal/lsp/protocol/span.go b/gopls/internal/lsp/protocol/span.go
--- a/gopls/internal/lsp/protocol/span.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/span.go	1969-12-31 16:00:00
@@ -1,326 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// this file contains protocol<->span converters
-
-// Here's a handy guide for your tour of the location zoo:
-//
-// Imports: source  --> lsppos  -->  protocol  -->  span  -->  token
-//
-// source.MappedRange = (span.Range, protocol.ColumnMapper)
-//
-// lsppos.TokenMapper = (token.File, lsppos.Mapper)
-// lsppos.Mapper = (line offset table, content)
-//
-// protocol.ColumnMapper = (URI, token.File, content)
-// protocol.Location = (URI, protocol.Range)
-// protocol.Range = (start, end Position)
-// protocol.Position = (line, char uint32) 0-based UTF-16
-//
-// span.Point = (line?, col?, offset?) 1-based UTF-8
-// span.Span = (uri URI, start, end span.Point)
-// span.Range = (file token.File, start, end token.Pos)
-//
-// token.Pos
-// token.FileSet
-// offset int
-//
-// TODO(adonovan): simplify this picture. Eliminate the optionality of
-// span.{Span,Point}'s position and offset fields: work internally in
-// terms of offsets (like span.Range), and require a mapper to convert
-// them to protocol (UTF-16) line/col form.
-
-package protocol
-
-import (
-	"bytes"
-	"fmt"
-	"go/token"
-	"path/filepath"
-	"strings"
-	"unicode/utf8"
-
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-)
-
-// A ColumnMapper maps between UTF-8 oriented positions (e.g. token.Pos,
-// span.Span) and the UTF-16 oriented positions used by the LSP.
-type ColumnMapper struct {
-	URI     span.URI
-	TokFile *token.File
-	Content []byte
-
-	// File content is only really needed for UTF-16 column
-	// computation, which could be be achieved more compactly.
-	// For example, one could record only the lines for which
-	// UTF-16 columns differ from the UTF-8 ones, or only the
-	// indices of the non-ASCII characters.
-	//
-	// TODO(adonovan): consider not retaining the entire file
-	// content, or at least not exposing the fact that we
-	// currently retain it.
-}
-
-// NewColumnMapper creates a new column mapper for the given uri and content.
-func NewColumnMapper(uri span.URI, content []byte) *ColumnMapper {
-	tf := span.NewTokenFile(uri.Filename(), content)
-	return &ColumnMapper{
-		URI:     uri,
-		TokFile: tf,
-		Content: content,
-	}
-}
-
-func URIFromSpanURI(uri span.URI) DocumentURI {
-	return DocumentURI(uri)
-}
-
-func URIFromPath(path string) DocumentURI {
-	return URIFromSpanURI(span.URIFromPath(path))
-}
-
-func (u DocumentURI) SpanURI() span.URI {
-	return span.URIFromURI(string(u))
-}
-
-func (m *ColumnMapper) Location(s span.Span) (Location, error) {
-	rng, err := m.Range(s)
-	if err != nil {
-		return Location{}, err
-	}
-	return Location{URI: URIFromSpanURI(s.URI()), Range: rng}, nil
-}
-
-func (m *ColumnMapper) Range(s span.Span) (Range, error) {
-	// Assert that we aren't using the wrong mapper.
-	// We check only the base name, and case insensitively,
-	// because we can't assume clean paths, no symbolic links,
-	// case-sensitive directories. The authoritative answer
-	// requires querying the file system, and we don't want
-	// to do that.
-	if !strings.EqualFold(filepath.Base(string(m.URI)), filepath.Base(string(s.URI()))) {
-		return Range{}, bug.Errorf("column mapper is for file %q instead of %q", m.URI, s.URI())
-	}
-
-	s, err := s.WithOffset(m.TokFile)
-	if err != nil {
-		return Range{}, err
-	}
-	start, err := m.Position(s.Start())
-	if err != nil {
-		return Range{}, err
-	}
-	end, err := m.Position(s.End())
-	if err != nil {
-		return Range{}, err
-	}
-	return Range{Start: start, End: end}, nil
-}
-
-// OffsetRange returns a Range for the byte-offset interval Content[start:end],
-func (m *ColumnMapper) OffsetRange(start, end int) (Range, error) {
-	startPosition, err := m.OffsetPosition(start)
-	if err != nil {
-		return Range{}, fmt.Errorf("start: %v", err)
-	}
-
-	endPosition, err := m.OffsetPosition(end)
-	if err != nil {
-		return Range{}, fmt.Errorf("end: %v", err)
-	}
-
-	return Range{Start: startPosition, End: endPosition}, nil
-}
-
-// PosRange returns a protocol Range for the token.Pos interval Content[start:end].
-func (m *ColumnMapper) PosRange(start, end token.Pos) (Range, error) {
-	startOffset, err := safetoken.Offset(m.TokFile, start)
-	if err != nil {
-		return Range{}, fmt.Errorf("start: %v", err)
-	}
-	endOffset, err := safetoken.Offset(m.TokFile, end)
-	if err != nil {
-		return Range{}, fmt.Errorf("end: %v", err)
-	}
-	return m.OffsetRange(startOffset, endOffset)
-}
-
-// Position returns the protocol position for the specified point,
-// which must have a byte offset.
-func (m *ColumnMapper) Position(p span.Point) (Position, error) {
-	if !p.HasOffset() {
-		return Position{}, fmt.Errorf("point is missing offset")
-	}
-	return m.OffsetPosition(p.Offset())
-}
-
-// OffsetPosition returns the protocol position of the specified
-// offset within m.Content.
-func (m *ColumnMapper) OffsetPosition(offset int) (Position, error) {
-	// We use span.ToPosition for its "line+1 at EOF" workaround.
-	line, _, err := span.ToPosition(m.TokFile, offset)
-	if err != nil {
-		return Position{}, fmt.Errorf("OffsetPosition: %v", err)
-	}
-	// If that workaround executed, skip the usual column computation.
-	char := 0
-	if offset != m.TokFile.Size() {
-		char = m.utf16Column(offset)
-	}
-	return Position{
-		Line:      uint32(line - 1),
-		Character: uint32(char),
-	}, nil
-}
-
-// utf16Column returns the zero-based column index of the
-// specified file offset, measured in UTF-16 codes.
-// Precondition: 0 <= offset <= len(m.Content).
-func (m *ColumnMapper) utf16Column(offset int) int {
-	s := m.Content[:offset]
-	if i := bytes.LastIndex(s, []byte("\n")); i >= 0 {
-		s = s[i+1:]
-	}
-	// s is the prefix of the line before offset.
-	return utf16len(s)
-}
-
-// utf16len returns the number of codes in the UTF-16 transcoding of s.
-func utf16len(s []byte) int {
-	var n int
-	for len(s) > 0 {
-		n++
-
-		// Fast path for ASCII.
-		if s[0] < 0x80 {
-			s = s[1:]
-			continue
-		}
-
-		r, size := utf8.DecodeRune(s)
-		if r >= 0x10000 {
-			n++ // surrogate pair
-		}
-		s = s[size:]
-	}
-	return n
-}
-
-func (m *ColumnMapper) Span(l Location) (span.Span, error) {
-	return m.RangeSpan(l.Range)
-}
-
-// RangeSpan converts a UTF-16 range to a Span with both the
-// position (line/col) and offset fields populated.
-func (m *ColumnMapper) RangeSpan(r Range) (span.Span, error) {
-	start, err := m.Point(r.Start)
-	if err != nil {
-		return span.Span{}, err
-	}
-	end, err := m.Point(r.End)
-	if err != nil {
-		return span.Span{}, err
-	}
-	return span.New(m.URI, start, end).WithAll(m.TokFile)
-}
-
-func (m *ColumnMapper) RangeToSpanRange(r Range) (span.Range, error) {
-	spn, err := m.RangeSpan(r)
-	if err != nil {
-		return span.Range{}, err
-	}
-	return spn.Range(m.TokFile)
-}
-
-// Pos returns the token.Pos of protocol position p within the mapped file.
-func (m *ColumnMapper) Pos(p Position) (token.Pos, error) {
-	start, err := m.Point(p)
-	if err != nil {
-		return token.NoPos, err
-	}
-	return safetoken.Pos(m.TokFile, start.Offset())
-}
-
-// Offset returns the utf-8 byte offset of p within the mapped file.
-func (m *ColumnMapper) Offset(p Position) (int, error) {
-	start, err := m.Point(p)
-	if err != nil {
-		return 0, err
-	}
-	return start.Offset(), nil
-}
-
-// Point returns a span.Point for the protocol position p within the mapped file.
-// The resulting point has a valid Position and Offset.
-func (m *ColumnMapper) Point(p Position) (span.Point, error) {
-	line := int(p.Line) + 1
-
-	// Find byte offset of start of containing line.
-	offset, err := span.ToOffset(m.TokFile, line, 1)
-	if err != nil {
-		return span.Point{}, err
-	}
-	lineStart := span.NewPoint(line, 1, offset)
-	return span.FromUTF16Column(lineStart, int(p.Character)+1, m.Content)
-}
-
-func IsPoint(r Range) bool {
-	return r.Start.Line == r.End.Line && r.Start.Character == r.End.Character
-}
-
-// CompareRange returns -1 if a is before b, 0 if a == b, and 1 if a is after
-// b.
-//
-// A range a is defined to be 'before' b if a.Start is before b.Start, or
-// a.Start == b.Start and a.End is before b.End.
-func CompareRange(a, b Range) int {
-	if r := ComparePosition(a.Start, b.Start); r != 0 {
-		return r
-	}
-	return ComparePosition(a.End, b.End)
-}
-
-// ComparePosition returns -1 if a is before b, 0 if a == b, and 1 if a is
-// after b.
-func ComparePosition(a, b Position) int {
-	if a.Line < b.Line {
-		return -1
-	}
-	if a.Line > b.Line {
-		return 1
-	}
-	if a.Character < b.Character {
-		return -1
-	}
-	if a.Character > b.Character {
-		return 1
-	}
-	return 0
-}
-
-func Intersect(a, b Range) bool {
-	if a.Start.Line > b.End.Line || a.End.Line < b.Start.Line {
-		return false
-	}
-	return !((a.Start.Line == b.End.Line) && a.Start.Character > b.End.Character ||
-		(a.End.Line == b.Start.Line) && a.End.Character < b.Start.Character)
-}
-
-// Format implements fmt.Formatter.
-//
-// Note: Formatter is implemented instead of Stringer (presumably) for
-// performance reasons, though it is not clear that it matters in practice.
-func (r Range) Format(f fmt.State, _ rune) {
-	fmt.Fprintf(f, "%v-%v", r.Start, r.End)
-}
-
-// Format implements fmt.Formatter.
-//
-// See Range.Format for discussion of why the Formatter interface is
-// implemented rather than Stringer.
-func (p Position) Format(f fmt.State, _ rune) {
-	fmt.Fprintf(f, "%v:%v", p.Line, p.Character)
-}
diff -urN a/gopls/internal/lsp/protocol/tsclient.go b/gopls/internal/lsp/protocol/tsclient.go
--- a/gopls/internal/lsp/protocol/tsclient.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/tsclient.go	1969-12-31 16:00:00
@@ -1,219 +0,0 @@
-// Copyright 2019-2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-// Code generated from version 3.17.0 of protocol/metaModel.json.
-// git hash 8de18faed635819dd2bc631d2c26ce4a18f7cf4a (as of Fri Sep 16 13:04:31 2022)
-// Code generated; DO NOT EDIT.
-
-import (
-	"context"
-	"encoding/json"
-
-	"golang.org/x/tools/internal/jsonrpc2"
-)
-
-type Client interface {
-	LogTrace(context.Context, *LogTraceParams) error                                           // $/logTrace
-	Progress(context.Context, *ProgressParams) error                                           // $/progress
-	RegisterCapability(context.Context, *RegistrationParams) error                             // client/registerCapability
-	UnregisterCapability(context.Context, *UnregistrationParams) error                         // client/unregisterCapability
-	Event(context.Context, *interface{}) error                                                 // telemetry/event
-	PublishDiagnostics(context.Context, *PublishDiagnosticsParams) error                       // textDocument/publishDiagnostics
-	LogMessage(context.Context, *LogMessageParams) error                                       // window/logMessage
-	ShowDocument(context.Context, *ShowDocumentParams) (*ShowDocumentResult, error)            // window/showDocument
-	ShowMessage(context.Context, *ShowMessageParams) error                                     // window/showMessage
-	ShowMessageRequest(context.Context, *ShowMessageRequestParams) (*MessageActionItem, error) // window/showMessageRequest
-	WorkDoneProgressCreate(context.Context, *WorkDoneProgressCreateParams) error               // window/workDoneProgress/create
-	ApplyEdit(context.Context, *ApplyWorkspaceEditParams) (*ApplyWorkspaceEditResult, error)   // workspace/applyEdit
-	CodeLensRefresh(context.Context) error                                                     // workspace/codeLens/refresh
-	Configuration(context.Context, *ParamConfiguration) ([]LSPAny, error)                      // workspace/configuration
-	WorkspaceFolders(context.Context) ([]WorkspaceFolder, error)                               // workspace/workspaceFolders
-}
-
-func clientDispatch(ctx context.Context, client Client, reply jsonrpc2.Replier, r jsonrpc2.Request) (bool, error) {
-	switch r.Method() {
-	case "$/logTrace":
-		var params LogTraceParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.LogTrace(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "$/progress":
-		var params ProgressParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.Progress(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "client/registerCapability":
-		var params RegistrationParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.RegisterCapability(ctx, &params)
-		return true, reply(ctx, nil, err) // 155
-	case "client/unregisterCapability":
-		var params UnregistrationParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.UnregisterCapability(ctx, &params)
-		return true, reply(ctx, nil, err) // 155
-	case "telemetry/event":
-		var params interface{}
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.Event(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "textDocument/publishDiagnostics":
-		var params PublishDiagnosticsParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.PublishDiagnostics(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "window/logMessage":
-		var params LogMessageParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.LogMessage(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "window/showDocument":
-		var params ShowDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := client.ShowDocument(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "window/showMessage":
-		var params ShowMessageParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.ShowMessage(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "window/showMessageRequest":
-		var params ShowMessageRequestParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := client.ShowMessageRequest(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "window/workDoneProgress/create":
-		var params WorkDoneProgressCreateParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := client.WorkDoneProgressCreate(ctx, &params)
-		return true, reply(ctx, nil, err) // 155
-	case "workspace/applyEdit":
-		var params ApplyWorkspaceEditParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := client.ApplyEdit(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/codeLens/refresh":
-		err := client.CodeLensRefresh(ctx)
-		return true, reply(ctx, nil, err) // 170
-	case "workspace/configuration":
-		var params ParamConfiguration
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := client.Configuration(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/workspaceFolders":
-		resp, err := client.WorkspaceFolders(ctx)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 165
-	default:
-		return false, nil
-	}
-}
-
-func (s *clientDispatcher) LogTrace(ctx context.Context, params *LogTraceParams) error {
-	return s.sender.Notify(ctx, "$/logTrace", params)
-} // 244
-func (s *clientDispatcher) Progress(ctx context.Context, params *ProgressParams) error {
-	return s.sender.Notify(ctx, "$/progress", params)
-} // 244
-func (s *clientDispatcher) RegisterCapability(ctx context.Context, params *RegistrationParams) error {
-	return s.sender.Call(ctx, "client/registerCapability", params, nil)
-} // 194
-func (s *clientDispatcher) UnregisterCapability(ctx context.Context, params *UnregistrationParams) error {
-	return s.sender.Call(ctx, "client/unregisterCapability", params, nil)
-} // 194
-func (s *clientDispatcher) Event(ctx context.Context, params *interface{}) error {
-	return s.sender.Notify(ctx, "telemetry/event", params)
-} // 244
-func (s *clientDispatcher) PublishDiagnostics(ctx context.Context, params *PublishDiagnosticsParams) error {
-	return s.sender.Notify(ctx, "textDocument/publishDiagnostics", params)
-} // 244
-func (s *clientDispatcher) LogMessage(ctx context.Context, params *LogMessageParams) error {
-	return s.sender.Notify(ctx, "window/logMessage", params)
-} // 244
-func (s *clientDispatcher) ShowDocument(ctx context.Context, params *ShowDocumentParams) (*ShowDocumentResult, error) {
-	var result *ShowDocumentResult
-	if err := s.sender.Call(ctx, "window/showDocument", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *clientDispatcher) ShowMessage(ctx context.Context, params *ShowMessageParams) error {
-	return s.sender.Notify(ctx, "window/showMessage", params)
-} // 244
-func (s *clientDispatcher) ShowMessageRequest(ctx context.Context, params *ShowMessageRequestParams) (*MessageActionItem, error) {
-	var result *MessageActionItem
-	if err := s.sender.Call(ctx, "window/showMessageRequest", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *clientDispatcher) WorkDoneProgressCreate(ctx context.Context, params *WorkDoneProgressCreateParams) error {
-	return s.sender.Call(ctx, "window/workDoneProgress/create", params, nil)
-} // 194
-func (s *clientDispatcher) ApplyEdit(ctx context.Context, params *ApplyWorkspaceEditParams) (*ApplyWorkspaceEditResult, error) {
-	var result *ApplyWorkspaceEditResult
-	if err := s.sender.Call(ctx, "workspace/applyEdit", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *clientDispatcher) CodeLensRefresh(ctx context.Context) error {
-	return s.sender.Call(ctx, "workspace/codeLens/refresh", nil, nil)
-} // 209
-func (s *clientDispatcher) Configuration(ctx context.Context, params *ParamConfiguration) ([]LSPAny, error) {
-	var result []LSPAny
-	if err := s.sender.Call(ctx, "workspace/configuration", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *clientDispatcher) WorkspaceFolders(ctx context.Context) ([]WorkspaceFolder, error) {
-	var result []WorkspaceFolder
-	if err := s.sender.Call(ctx, "workspace/workspaceFolders", nil, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 204
diff -urN a/gopls/internal/lsp/protocol/tsdocument_changes.go b/gopls/internal/lsp/protocol/tsdocument_changes.go
--- a/gopls/internal/lsp/protocol/tsdocument_changes.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/tsdocument_changes.go	1969-12-31 16:00:00
@@ -1,41 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package protocol
-
-import (
-	"encoding/json"
-	"fmt"
-)
-
-// DocumentChanges is a union of a file edit and directory rename operations
-// for package renaming feature. At most one field of this struct is non-nil.
-type DocumentChanges struct {
-	TextDocumentEdit *TextDocumentEdit
-	RenameFile       *RenameFile
-}
-
-func (d *DocumentChanges) UnmarshalJSON(data []byte) error {
-	var m map[string]interface{}
-
-	if err := json.Unmarshal(data, &m); err != nil {
-		return err
-	}
-
-	if _, ok := m["textDocument"]; ok {
-		d.TextDocumentEdit = new(TextDocumentEdit)
-		return json.Unmarshal(data, d.TextDocumentEdit)
-	}
-
-	d.RenameFile = new(RenameFile)
-	return json.Unmarshal(data, d.RenameFile)
-}
-
-func (d *DocumentChanges) MarshalJSON() ([]byte, error) {
-	if d.TextDocumentEdit != nil {
-		return json.Marshal(d.TextDocumentEdit)
-	} else if d.RenameFile != nil {
-		return json.Marshal(d.RenameFile)
-	}
-	return nil, fmt.Errorf("Empty DocumentChanges union value")
-}
diff -urN a/gopls/internal/lsp/protocol/tsjson.go b/gopls/internal/lsp/protocol/tsjson.go
--- a/gopls/internal/lsp/protocol/tsjson.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/tsjson.go	1969-12-31 16:00:00
@@ -1,440 +0,0 @@
-// Copyright 2019-2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-// Code generated from version 3.17.0 of protocol/metaModel.json.
-// git hash 8de18faed635819dd2bc631d2c26ce4a18f7cf4a (as of Fri Sep 16 13:04:31 2022)
-// Code generated; DO NOT EDIT.
-
-import "encoding/json"
-import "errors"
-import "fmt"
-
-func (t OrFEditRangePItemDefaults) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case FEditRangePItemDefaults:
-		return json.Marshal(x)
-	case Range:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [FEditRangePItemDefaults Range]", t)
-}
-
-func (t *OrFEditRangePItemDefaults) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 FEditRangePItemDefaults
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 Range
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [FEditRangePItemDefaults Range]")
-}
-
-func (t OrFNotebookPNotebookSelector) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case NotebookDocumentFilter:
-		return json.Marshal(x)
-	case string:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [NotebookDocumentFilter string]", t)
-}
-
-func (t *OrFNotebookPNotebookSelector) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 NotebookDocumentFilter
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 string
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [NotebookDocumentFilter string]")
-}
-
-func (t OrPLocation_workspace_symbol) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case Location:
-		return json.Marshal(x)
-	case PLocationMsg_workspace_symbol:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [Location PLocationMsg_workspace_symbol]", t)
-}
-
-func (t *OrPLocation_workspace_symbol) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 Location
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 PLocationMsg_workspace_symbol
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [Location PLocationMsg_workspace_symbol]")
-}
-
-func (t OrPSection_workspace_didChangeConfiguration) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case []string:
-		return json.Marshal(x)
-	case string:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [[]string string]", t)
-}
-
-func (t *OrPSection_workspace_didChangeConfiguration) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 []string
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 string
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [[]string string]")
-}
-
-func (t OrPTooltipPLabel) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case MarkupContent:
-		return json.Marshal(x)
-	case string:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [MarkupContent string]", t)
-}
-
-func (t *OrPTooltipPLabel) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 MarkupContent
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 string
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [MarkupContent string]")
-}
-
-func (t OrPTooltip_textDocument_inlayHint) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case MarkupContent:
-		return json.Marshal(x)
-	case string:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [MarkupContent string]", t)
-}
-
-func (t *OrPTooltip_textDocument_inlayHint) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 MarkupContent
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 string
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [MarkupContent string]")
-}
-
-func (t Or_Definition) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case Location:
-		return json.Marshal(x)
-	case []Location:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [Location []Location]", t)
-}
-
-func (t *Or_Definition) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 Location
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 []Location
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [Location []Location]")
-}
-
-func (t Or_DocumentDiagnosticReport) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case RelatedFullDocumentDiagnosticReport:
-		return json.Marshal(x)
-	case RelatedUnchangedDocumentDiagnosticReport:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [RelatedFullDocumentDiagnosticReport RelatedUnchangedDocumentDiagnosticReport]", t)
-}
-
-func (t *Or_DocumentDiagnosticReport) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 RelatedFullDocumentDiagnosticReport
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 RelatedUnchangedDocumentDiagnosticReport
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [RelatedFullDocumentDiagnosticReport RelatedUnchangedDocumentDiagnosticReport]")
-}
-
-func (t Or_DocumentFilter) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case NotebookCellTextDocumentFilter:
-		return json.Marshal(x)
-	case TextDocumentFilter:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [NotebookCellTextDocumentFilter TextDocumentFilter]", t)
-}
-
-func (t *Or_DocumentFilter) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 NotebookCellTextDocumentFilter
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 TextDocumentFilter
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [NotebookCellTextDocumentFilter TextDocumentFilter]")
-}
-
-func (t Or_InlineValue) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case InlineValueEvaluatableExpression:
-		return json.Marshal(x)
-	case InlineValueText:
-		return json.Marshal(x)
-	case InlineValueVariableLookup:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [InlineValueEvaluatableExpression InlineValueText InlineValueVariableLookup]", t)
-}
-
-func (t *Or_InlineValue) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 InlineValueEvaluatableExpression
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 InlineValueText
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	var h2 InlineValueVariableLookup
-	if err := json.Unmarshal(x, &h2); err == nil {
-		t.Value = h2
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [InlineValueEvaluatableExpression InlineValueText InlineValueVariableLookup]")
-}
-
-func (t Or_MarkedString) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case Msg_MarkedString:
-		return json.Marshal(x)
-	case string:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [Msg_MarkedString string]", t)
-}
-
-func (t *Or_MarkedString) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 Msg_MarkedString
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 string
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [Msg_MarkedString string]")
-}
-
-func (t Or_RelativePattern_baseUri) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case URI:
-		return json.Marshal(x)
-	case WorkspaceFolder:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [URI WorkspaceFolder]", t)
-}
-
-func (t *Or_RelativePattern_baseUri) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 URI
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 WorkspaceFolder
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [URI WorkspaceFolder]")
-}
-
-func (t Or_WorkspaceDocumentDiagnosticReport) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case WorkspaceFullDocumentDiagnosticReport:
-		return json.Marshal(x)
-	case WorkspaceUnchangedDocumentDiagnosticReport:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [WorkspaceFullDocumentDiagnosticReport WorkspaceUnchangedDocumentDiagnosticReport]", t)
-}
-
-func (t *Or_WorkspaceDocumentDiagnosticReport) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 WorkspaceFullDocumentDiagnosticReport
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 WorkspaceUnchangedDocumentDiagnosticReport
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [WorkspaceFullDocumentDiagnosticReport WorkspaceUnchangedDocumentDiagnosticReport]")
-}
-
-func (t Or_textDocument_declaration) MarshalJSON() ([]byte, error) {
-	switch x := t.Value.(type) {
-	case Declaration:
-		return json.Marshal(x)
-	case []DeclarationLink:
-		return json.Marshal(x)
-	case nil:
-		return []byte("null"), nil
-	}
-	return nil, fmt.Errorf("type %T not one of [Declaration []DeclarationLink]", t)
-}
-
-func (t *Or_textDocument_declaration) UnmarshalJSON(x []byte) error {
-	if string(x) == "null" {
-		t.Value = nil
-		return nil
-	}
-	var h0 Declaration
-	if err := json.Unmarshal(x, &h0); err == nil {
-		t.Value = h0
-		return nil
-	}
-	var h1 []DeclarationLink
-	if err := json.Unmarshal(x, &h1); err == nil {
-		t.Value = h1
-		return nil
-	}
-	return errors.New("unmarshal failed to match one of [Declaration []DeclarationLink]")
-}
diff -urN a/gopls/internal/lsp/protocol/tsprotocol.go b/gopls/internal/lsp/protocol/tsprotocol.go
--- a/gopls/internal/lsp/protocol/tsprotocol.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/tsprotocol.go	1969-12-31 16:00:00
@@ -1,6159 +0,0 @@
-// Copyright 2019-2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-// Code generated from version 3.17.0 of protocol/metaModel.json.
-// git hash 8de18faed635819dd2bc631d2c26ce4a18f7cf4a (as of Fri Sep 16 13:04:31 2022)
-// Code generated; DO NOT EDIT.
-
-import "encoding/json"
-
-/*
- * A special text edit with an additional change annotation.
- *
- * @since 3.16.0.
- */
-type AnnotatedTextEdit struct { // line 9392
-	// The actual identifier of the change annotation
-	AnnotationID ChangeAnnotationIdentifier `json:"annotationId"`
-	TextEdit
-}
-
-// The parameters passed via a apply workspace edit request.
-type ApplyWorkspaceEditParams struct { // line 6003
-	/*
-	 * An optional label of the workspace edit. This label is
-	 * presented in the user interface for example on an undo
-	 * stack to undo the workspace edit.
-	 */
-	Label string `json:"label,omitempty"`
-	// The edits to apply.
-	Edit WorkspaceEdit `json:"edit"`
-}
-
-/*
- * The result returned from the apply workspace edit request.
- *
- * @since 3.17 renamed from ApplyWorkspaceEditResponse
- */
-type ApplyWorkspaceEditResult struct { // line 6026
-	// Indicates whether the edit was applied or not.
-	Applied bool `json:"applied"`
-	/*
-	 * An optional textual description for why the edit was not applied.
-	 * This may be used by the server for diagnostic logging or to provide
-	 * a suitable error for a request that triggered the edit.
-	 */
-	FailureReason string `json:"failureReason,omitempty"`
-	/*
-	 * Depending on the client's failure handling strategy `failedChange` might
-	 * contain the index of the change that failed. This property is only available
-	 * if the client signals a `failureHandlingStrategy` in its client capabilities.
-	 */
-	FailedChange uint32 `json:"failedChange,omitempty"`
-}
-
-// A base for all symbol information.
-type BaseSymbolInformation struct { // line 8986
-	// The name of this symbol.
-	Name string `json:"name"`
-	// The kind of this symbol.
-	Kind SymbolKind `json:"kind"`
-	/*
-	 * Tags for this symbol.
-	 *
-	 * @since 3.16.0
-	 */
-	Tags []SymbolTag `json:"tags,omitempty"`
-	/*
-	 * The name of the symbol containing this symbol. This information is for
-	 * user interface purposes (e.g. to render a qualifier in the user interface
-	 * if necessary). It can't be used to re-infer a hierarchy for the document
-	 * symbols.
-	 */
-	ContainerName string `json:"containerName,omitempty"`
-}
-
-// @since 3.16.0
-type CallHierarchyClientCapabilities struct { // line 12167
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `(TextDocumentRegistrationOptions & StaticRegistrationOptions)`
-	 * return value for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-/*
- * Represents an incoming call, e.g. a caller of a method or constructor.
- *
- * @since 3.16.0
- */
-type CallHierarchyIncomingCall struct { // line 2801
-	// The item that makes the call.
-	From CallHierarchyItem `json:"from"`
-	/*
-	 * The ranges at which the calls appear. This is relative to the caller
-	 * denoted by [`this.from`](#CallHierarchyIncomingCall.from).
-	 */
-	FromRanges []Range `json:"fromRanges"`
-}
-
-/*
- * The parameter of a `callHierarchy/incomingCalls` request.
- *
- * @since 3.16.0
- */
-type CallHierarchyIncomingCallsParams struct { // line 2777
-	Item CallHierarchyItem `json:"item"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-/*
- * Represents programming constructs like functions or constructors in the context
- * of call hierarchy.
- *
- * @since 3.16.0
- */
-type CallHierarchyItem struct { // line 2678
-	// The name of this item.
-	Name string `json:"name"`
-	// The kind of this item.
-	Kind SymbolKind `json:"kind"`
-	// Tags for this item.
-	Tags []SymbolTag `json:"tags,omitempty"`
-	// More detail for this item, e.g. the signature of a function.
-	Detail string `json:"detail,omitempty"`
-	// The resource identifier of this item.
-	URI DocumentURI `json:"uri"`
-	// The range enclosing this symbol not including leading/trailing whitespace but everything else, e.g. comments and code.
-	Range Range `json:"range"`
-	/*
-	 * The range that should be selected and revealed when this symbol is being picked, e.g. the name of a function.
-	 * Must be contained by the [`range`](#CallHierarchyItem.range).
-	 */
-	SelectionRange Range `json:"selectionRange"`
-	/*
-	 * A data entry field that is preserved between a call hierarchy prepare and
-	 * incoming calls or outgoing calls requests.
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-/*
- * Call hierarchy options used during static registration.
- *
- * @since 3.16.0
- */
-type CallHierarchyOptions struct { // line 6539
-	WorkDoneProgressOptions
-}
-
-/*
- * Represents an outgoing call, e.g. calling a getter from a method or a method from a constructor etc.
- *
- * @since 3.16.0
- */
-type CallHierarchyOutgoingCall struct { // line 2851
-	// The item that is called.
-	To CallHierarchyItem `json:"to"`
-	/*
-	 * The range at which this item is called. This is the range relative to the caller, e.g the item
-	 * passed to [`provideCallHierarchyOutgoingCalls`](#CallHierarchyItemProvider.provideCallHierarchyOutgoingCalls)
-	 * and not [`this.to`](#CallHierarchyOutgoingCall.to).
-	 */
-	FromRanges []Range `json:"fromRanges"`
-}
-
-/*
- * The parameter of a `callHierarchy/outgoingCalls` request.
- *
- * @since 3.16.0
- */
-type CallHierarchyOutgoingCallsParams struct { // line 2827
-	Item CallHierarchyItem `json:"item"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-/*
- * The parameter of a `textDocument/prepareCallHierarchy` request.
- *
- * @since 3.16.0
- */
-type CallHierarchyPrepareParams struct { // line 2660
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-}
-
-/*
- * Call hierarchy options used during static or dynamic registration.
- *
- * @since 3.16.0
- */
-type CallHierarchyRegistrationOptions struct { // line 2755
-	TextDocumentRegistrationOptions
-	CallHierarchyOptions
-	StaticRegistrationOptions
-}
-type CancelParams struct { // line 6198
-	// The request id to cancel.
-	ID interface{} `json:"id"`
-}
-
-/*
- * Additional information that describes document changes.
- *
- * @since 3.16.0
- */
-type ChangeAnnotation struct { // line 6836
-	/*
-	 * A human-readable string describing the actual change. The string
-	 * is rendered prominent in the user interface.
-	 */
-	Label string `json:"label"`
-	/*
-	 * A flag which indicates that user confirmation is needed
-	 * before applying the change.
-	 */
-	NeedsConfirmation bool `json:"needsConfirmation,omitempty"`
-	/*
-	 * A human-readable string which is rendered less prominent in
-	 * the user interface.
-	 */
-	Description string `json:"description,omitempty"`
-}
-
-// An identifier to refer to a change annotation stored with a workspace edit.
-type ChangeAnnotationIdentifier = string // (alias) line 14002
-// Defines the capabilities provided by the client.
-type ClientCapabilities struct { // line 9700
-	// Workspace specific client capabilities.
-	Workspace WorkspaceClientCapabilities `json:"workspace,omitempty"`
-	// Text document specific client capabilities.
-	TextDocument TextDocumentClientCapabilities `json:"textDocument,omitempty"`
-	/*
-	 * Capabilities specific to the notebook document support.
-	 *
-	 * @since 3.17.0
-	 */
-	NotebookDocument *NotebookDocumentClientCapabilities `json:"notebookDocument,omitempty"`
-	// Window specific client capabilities.
-	Window WindowClientCapabilities `json:"window,omitempty"`
-	/*
-	 * General client capabilities.
-	 *
-	 * @since 3.16.0
-	 */
-	General *GeneralClientCapabilities `json:"general,omitempty"`
-	// Experimental client capabilities.
-	Experimental interface{} `json:"experimental,omitempty"`
-}
-
-/*
- * A code action represents a change that can be performed in code, e.g. to fix a problem or
- * to refactor code.
- *
- * A CodeAction must set either `edit` and/or a `command`. If both are supplied, the `edit` is applied first, then the `command` is executed.
- */
-type CodeAction struct { // line 5401
-	// A short, human-readable, title for this code action.
-	Title string `json:"title"`
-	/*
-	 * The kind of the code action.
-	 *
-	 * Used to filter code actions.
-	 */
-	Kind CodeActionKind `json:"kind,omitempty"`
-	// The diagnostics that this code action resolves.
-	Diagnostics []Diagnostic `json:"diagnostics,omitempty"`
-	/*
-	 * Marks this as a preferred action. Preferred actions are used by the `auto fix` command and can be targeted
-	 * by keybindings.
-	 *
-	 * A quick fix should be marked preferred if it properly addresses the underlying error.
-	 * A refactoring should be marked preferred if it is the most reasonable choice of actions to take.
-	 *
-	 * @since 3.15.0
-	 */
-	IsPreferred bool `json:"isPreferred,omitempty"`
-	/*
-	 * Marks that the code action cannot currently be applied.
-	 *
-	 * Clients should follow the following guidelines regarding disabled code actions:
-	 *
-	 *   - Disabled code actions are not shown in automatic [lightbulbs](https://code.visualstudio.com/docs/editor/editingevolved#_code-action)
-	 *     code action menus.
-	 *
-	 *   - Disabled actions are shown as faded out in the code action menu when the user requests a more specific type
-	 *     of code action, such as refactorings.
-	 *
-	 *   - If the user has a [keybinding](https://code.visualstudio.com/docs/editor/refactoring#_keybindings-for-code-actions)
-	 *     that auto applies a code action and only disabled code actions are returned, the client should show the user an
-	 *     error message with `reason` in the editor.
-	 *
-	 * @since 3.16.0
-	 */
-	Disabled *PDisabledMsg_textDocument_codeAction `json:"disabled,omitempty"`
-	// The workspace edit this code action performs.
-	Edit WorkspaceEdit `json:"edit,omitempty"`
-	/*
-	 * A command this code action executes. If a code action
-	 * provides an edit and a command, first the edit is
-	 * executed and then the command.
-	 */
-	Command *Command `json:"command,omitempty"`
-	/*
-	 * A data entry field that is preserved on a code action between
-	 * a `textDocument/codeAction` and a `codeAction/resolve` request.
-	 *
-	 * @since 3.16.0
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-// The Client Capabilities of a [CodeActionRequest](#CodeActionRequest).
-type CodeActionClientCapabilities struct { // line 11747
-	// Whether code action supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The client support code action literals of type `CodeAction` as a valid
-	 * response of the `textDocument/codeAction` request. If the property is not
-	 * set the request can only return `Command` literals.
-	 *
-	 * @since 3.8.0
-	 */
-	CodeActionLiteralSupport PCodeActionLiteralSupportPCodeAction `json:"codeActionLiteralSupport,omitempty"`
-	/*
-	 * Whether code action supports the `isPreferred` property.
-	 *
-	 * @since 3.15.0
-	 */
-	IsPreferredSupport bool `json:"isPreferredSupport,omitempty"`
-	/*
-	 * Whether code action supports the `disabled` property.
-	 *
-	 * @since 3.16.0
-	 */
-	DisabledSupport bool `json:"disabledSupport,omitempty"`
-	/*
-	 * Whether code action supports the `data` property which is
-	 * preserved between a `textDocument/codeAction` and a
-	 * `codeAction/resolve` request.
-	 *
-	 * @since 3.16.0
-	 */
-	DataSupport bool `json:"dataSupport,omitempty"`
-	/*
-	 * Whether the client supports resolving additional code action
-	 * properties via a separate `codeAction/resolve` request.
-	 *
-	 * @since 3.16.0
-	 */
-	ResolveSupport *PResolveSupportPCodeAction `json:"resolveSupport,omitempty"`
-	/*
-	 * Whether the client honors the change annotations in
-	 * text edits and resource operations returned via the
-	 * `CodeAction#edit` property by for example presenting
-	 * the workspace edit in the user interface and asking
-	 * for confirmation.
-	 *
-	 * @since 3.16.0
-	 */
-	HonorsChangeAnnotations bool `json:"honorsChangeAnnotations,omitempty"`
-}
-
-/*
- * Contains additional diagnostic information about the context in which
- * a [code action](#CodeActionProvider.provideCodeActions) is run.
- */
-type CodeActionContext struct { // line 9052
-	/*
-	 * An array of diagnostics known on the client side overlapping the range provided to the
-	 * `textDocument/codeAction` request. They are provided so that the server knows which
-	 * errors are currently presented to the user for the given range. There is no guarantee
-	 * that these accurately reflect the error state of the resource. The primary parameter
-	 * to compute code actions is the provided range.
-	 */
-	Diagnostics []Diagnostic `json:"diagnostics"`
-	/*
-	 * Requested kind of actions to return.
-	 *
-	 * Actions not of this kind are filtered out by the client before being shown. So servers
-	 * can omit computing them.
-	 */
-	Only []CodeActionKind `json:"only,omitempty"`
-	/*
-	 * The reason why code actions were requested.
-	 *
-	 * @since 3.17.0
-	 */
-	TriggerKind CodeActionTriggerKind `json:"triggerKind,omitempty"`
-}
-type CodeActionKind string // line 13352
-// Provider options for a [CodeActionRequest](#CodeActionRequest).
-type CodeActionOptions struct { // line 9091
-	/*
-	 * CodeActionKinds that this server may return.
-	 *
-	 * The list of kinds may be generic, such as `CodeActionKind.Refactor`, or the server
-	 * may list out every specific kind they provide.
-	 */
-	CodeActionKinds []CodeActionKind `json:"codeActionKinds,omitempty"`
-	/*
-	 * The server provides support to resolve additional
-	 * information for a code action.
-	 *
-	 * @since 3.16.0
-	 */
-	ResolveProvider bool `json:"resolveProvider,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [CodeActionRequest](#CodeActionRequest).
-type CodeActionParams struct { // line 5327
-	// The document in which the command was invoked.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The range for which the command was invoked.
-	Range Range `json:"range"`
-	// Context carrying additional information.
-	Context CodeActionContext `json:"context"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [CodeActionRequest](#CodeActionRequest).
-type CodeActionRegistrationOptions struct { // line 5495
-	TextDocumentRegistrationOptions
-	CodeActionOptions
-}
-type CodeActionTriggerKind uint32 // line 13632
-/*
- * Structure to capture a description for an error code.
- *
- * @since 3.16.0
- */
-type CodeDescription struct { // line 10052
-	// An URI to open with more information about the diagnostic error.
-	Href URI `json:"href"`
-}
-
-/*
- * A code lens represents a [command](#Command) that should be shown along with
- * source text, like the number of references, a way to run tests, etc.
- *
- * A code lens is _unresolved_ when no command is associated to it. For performance
- * reasons the creation of a code lens and resolving should be done in two stages.
- */
-type CodeLens struct { // line 5618
-	// The range in which this code lens is valid. Should only span a single line.
-	Range Range `json:"range"`
-	// The command this code lens represents.
-	Command Command `json:"command,omitempty"`
-	/*
-	 * A data entry field that is preserved on a code lens item between
-	 * a [CodeLensRequest](#CodeLensRequest) and a [CodeLensResolveRequest]
-	 * (#CodeLensResolveRequest)
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-// The client capabilities  of a [CodeLensRequest](#CodeLensRequest).
-type CodeLensClientCapabilities struct { // line 11861
-	// Whether code lens supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// Code Lens provider options of a [CodeLensRequest](#CodeLensRequest).
-type CodeLensOptions struct { // line 9147
-	// Code lens has a resolve provider as well.
-	ResolveProvider bool `json:"resolveProvider,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [CodeLensRequest](#CodeLensRequest).
-type CodeLensParams struct { // line 5594
-	// The document to request code lens for.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [CodeLensRequest](#CodeLensRequest).
-type CodeLensRegistrationOptions struct { // line 5650
-	TextDocumentRegistrationOptions
-	CodeLensOptions
-}
-
-// @since 3.16.0
-type CodeLensWorkspaceClientCapabilities struct { // line 11019
-	/*
-	 * Whether the client implementation supports a refresh request sent from the
-	 * server to the client.
-	 *
-	 * Note that this event is global and will force the client to refresh all
-	 * code lenses currently shown. It should be used with absolute care and is
-	 * useful for situation where a server for example detect a project wide
-	 * change that requires such a calculation.
-	 */
-	RefreshSupport bool `json:"refreshSupport,omitempty"`
-}
-
-// Represents a color in RGBA space.
-type Color struct { // line 6438
-	// The red component of this color in the range [0-1].
-	Red float64 `json:"red"`
-	// The green component of this color in the range [0-1].
-	Green float64 `json:"green"`
-	// The blue component of this color in the range [0-1].
-	Blue float64 `json:"blue"`
-	// The alpha component of this color in the range [0-1].
-	Alpha float64 `json:"alpha"`
-}
-
-// Represents a color range from a document.
-type ColorInformation struct { // line 2261
-	// The range in the document where this color appears.
-	Range Range `json:"range"`
-	// The actual color value for this color range.
-	Color Color `json:"color"`
-}
-type ColorPresentation struct { // line 2343
-	/*
-	 * The label of this color presentation. It will be shown on the color
-	 * picker header. By default this is also the text that is inserted when selecting
-	 * this color presentation.
-	 */
-	Label string `json:"label"`
-	/*
-	 * An [edit](#TextEdit) which is applied to a document when selecting
-	 * this presentation for the color.  When `falsy` the [label](#ColorPresentation.label)
-	 * is used.
-	 */
-	TextEdit *TextEdit `json:"textEdit,omitempty"`
-	/*
-	 * An optional array of additional [text edits](#TextEdit) that are applied when
-	 * selecting this color presentation. Edits must not overlap with the main [edit](#ColorPresentation.textEdit) nor with themselves.
-	 */
-	AdditionalTextEdits []TextEdit `json:"additionalTextEdits,omitempty"`
-}
-
-// Parameters for a [ColorPresentationRequest](#ColorPresentationRequest).
-type ColorPresentationParams struct { // line 2303
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The color to request presentations for.
-	Color Color `json:"color"`
-	// The range where the color would be inserted. Serves as a context.
-	Range Range `json:"range"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-/*
- * Represents a reference to a command. Provides a title which
- * will be used to represent a command in the UI and, optionally,
- * an array of arguments which will be passed to the command handler
- * function when invoked.
- */
-type Command struct { // line 5367
-	// Title of the command, like `save`.
-	Title string `json:"title"`
-	// The identifier of the actual command handler.
-	Command string `json:"command"`
-	/*
-	 * Arguments that the command handler should be
-	 * invoked with.
-	 */
-	Arguments []json.RawMessage `json:"arguments,omitempty"`
-}
-
-// Completion client capabilities
-type CompletionClientCapabilities struct { // line 11194
-	// Whether completion supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The client supports the following `CompletionItem` specific
-	 * capabilities.
-	 */
-	CompletionItem     PCompletionItemPCompletion      `json:"completionItem,omitempty"`
-	CompletionItemKind *PCompletionItemKindPCompletion `json:"completionItemKind,omitempty"`
-	/*
-	 * Defines how the client handles whitespace and indentation
-	 * when accepting a completion item that uses multi line
-	 * text in either `insertText` or `textEdit`.
-	 *
-	 * @since 3.17.0
-	 */
-	InsertTextMode InsertTextMode `json:"insertTextMode,omitempty"`
-	/*
-	 * The client supports to send additional context information for a
-	 * `textDocument/completion` request.
-	 */
-	ContextSupport bool `json:"contextSupport,omitempty"`
-	/*
-	 * The client supports the following `CompletionList` specific
-	 * capabilities.
-	 *
-	 * @since 3.17.0
-	 */
-	CompletionList *PCompletionListPCompletion `json:"completionList,omitempty"`
-}
-
-// Contains additional information about the context in which a completion request is triggered.
-type CompletionContext struct { // line 8648
-	// How the completion was triggered.
-	TriggerKind CompletionTriggerKind `json:"triggerKind"`
-	/*
-	 * The trigger character (a single character) that has trigger code complete.
-	 * Is undefined if `triggerKind !== CompletionTriggerKind.TriggerCharacter`
-	 */
-	TriggerCharacter string `json:"triggerCharacter,omitempty"`
-}
-
-/*
- * A completion item represents a text snippet that is
- * proposed to complete text that is being typed.
- */
-type CompletionItem struct { // line 4550
-	/*
-	 * The label of this completion item.
-	 *
-	 * The label property is also by default the text that
-	 * is inserted when selecting this completion.
-	 *
-	 * If label details are provided the label itself should
-	 * be an unqualified name of the completion item.
-	 */
-	Label string `json:"label"`
-	/*
-	 * Additional details for the label
-	 *
-	 * @since 3.17.0
-	 */
-	LabelDetails *CompletionItemLabelDetails `json:"labelDetails,omitempty"`
-	/*
-	 * The kind of this completion item. Based of the kind
-	 * an icon is chosen by the editor.
-	 */
-	Kind CompletionItemKind `json:"kind,omitempty"`
-	/*
-	 * Tags for this completion item.
-	 *
-	 * @since 3.15.0
-	 */
-	Tags []CompletionItemTag `json:"tags,omitempty"`
-	/*
-	 * A human-readable string with additional information
-	 * about this item, like type or symbol information.
-	 */
-	Detail string `json:"detail,omitempty"`
-	// A human-readable string that represents a doc-comment.
-	Documentation string `json:"documentation,omitempty"`
-	/*
-	 * Indicates if this item is deprecated.
-	 * @deprecated Use `tags` instead.
-	 */
-	Deprecated bool `json:"deprecated,omitempty"`
-	/*
-	 * Select this item when showing.
-	 *
-	 * *Note* that only one completion item can be selected and that the
-	 * tool / client decides which item that is. The rule is that the *first*
-	 * item of those that match best is selected.
-	 */
-	Preselect bool `json:"preselect,omitempty"`
-	/*
-	 * A string that should be used when comparing this item
-	 * with other items. When `falsy` the [label](#CompletionItem.label)
-	 * is used.
-	 */
-	SortText string `json:"sortText,omitempty"`
-	/*
-	 * A string that should be used when filtering a set of
-	 * completion items. When `falsy` the [label](#CompletionItem.label)
-	 * is used.
-	 */
-	FilterText string `json:"filterText,omitempty"`
-	/*
-	 * A string that should be inserted into a document when selecting
-	 * this completion. When `falsy` the [label](#CompletionItem.label)
-	 * is used.
-	 *
-	 * The `insertText` is subject to interpretation by the client side.
-	 * Some tools might not take the string literally. For example
-	 * VS Code when code complete is requested in this example
-	 * `con<cursor position>` and a completion item with an `insertText` of
-	 * `console` is provided it will only insert `sole`. Therefore it is
-	 * recommended to use `textEdit` instead since it avoids additional client
-	 * side interpretation.
-	 */
-	InsertText string `json:"insertText,omitempty"`
-	/*
-	 * The format of the insert text. The format applies to both the
-	 * `insertText` property and the `newText` property of a provided
-	 * `textEdit`. If omitted defaults to `InsertTextFormat.PlainText`.
-	 *
-	 * Please note that the insertTextFormat doesn't apply to
-	 * `additionalTextEdits`.
-	 */
-	InsertTextFormat InsertTextFormat `json:"insertTextFormat,omitempty"`
-	/*
-	 * How whitespace and indentation is handled during completion
-	 * item insertion. If not provided the clients default value depends on
-	 * the `textDocument.completion.insertTextMode` client capability.
-	 *
-	 * @since 3.16.0
-	 */
-	InsertTextMode InsertTextMode `json:"insertTextMode,omitempty"`
-	/*
-	 * An [edit](#TextEdit) which is applied to a document when selecting
-	 * this completion. When an edit is provided the value of
-	 * [insertText](#CompletionItem.insertText) is ignored.
-	 *
-	 * Most editors support two different operations when accepting a completion
-	 * item. One is to insert a completion text and the other is to replace an
-	 * existing text with a completion text. Since this can usually not be
-	 * predetermined by a server it can report both ranges. Clients need to
-	 * signal support for `InsertReplaceEdits` via the
-	 * `textDocument.completion.insertReplaceSupport` client capability
-	 * property.
-	 *
-	 * *Note 1:* The text edit's range as well as both ranges from an insert
-	 * replace edit must be a [single line] and they must contain the position
-	 * at which completion has been requested.
-	 * *Note 2:* If an `InsertReplaceEdit` is returned the edit's insert range
-	 * must be a prefix of the edit's replace range, that means it must be
-	 * contained and starting at the same position.
-	 *
-	 * @since 3.16.0 additional type `InsertReplaceEdit`
-	 */
-	TextEdit *TextEdit `json:"textEdit,omitempty"`
-	/*
-	 * The edit text used if the completion item is part of a CompletionList and
-	 * CompletionList defines an item default for the text edit range.
-	 *
-	 * Clients will only honor this property if they opt into completion list
-	 * item defaults using the capability `completionList.itemDefaults`.
-	 *
-	 * If not provided and a list's default range is provided the label
-	 * property is used as a text.
-	 *
-	 * @since 3.17.0
-	 */
-	TextEditText string `json:"textEditText,omitempty"`
-	/*
-	 * An optional array of additional [text edits](#TextEdit) that are applied when
-	 * selecting this completion. Edits must not overlap (including the same insert position)
-	 * with the main [edit](#CompletionItem.textEdit) nor with themselves.
-	 *
-	 * Additional text edits should be used to change text unrelated to the current cursor position
-	 * (for example adding an import statement at the top of the file if the completion item will
-	 * insert an unqualified type).
-	 */
-	AdditionalTextEdits []TextEdit `json:"additionalTextEdits,omitempty"`
-	/*
-	 * An optional set of characters that when pressed while this completion is active will accept it first and
-	 * then type that character. *Note* that all commit characters should have `length=1` and that superfluous
-	 * characters will be ignored.
-	 */
-	CommitCharacters []string `json:"commitCharacters,omitempty"`
-	/*
-	 * An optional [command](#Command) that is executed *after* inserting this completion. *Note* that
-	 * additional modifications to the current document should be described with the
-	 * [additionalTextEdits](#CompletionItem.additionalTextEdits)-property.
-	 */
-	Command *Command `json:"command,omitempty"`
-	/*
-	 * A data entry field that is preserved on a completion item between a
-	 * [CompletionRequest](#CompletionRequest) and a [CompletionResolveRequest](#CompletionResolveRequest).
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-type CompletionItemKind uint32 // line 13160
-/*
- * Additional details for a completion item label.
- *
- * @since 3.17.0
- */
-type CompletionItemLabelDetails struct { // line 8671
-	/*
-	 * An optional string which is rendered less prominently directly after {@link CompletionItem.label label},
-	 * without any spacing. Should be used for function signatures and type annotations.
-	 */
-	Detail string `json:"detail,omitempty"`
-	/*
-	 * An optional string which is rendered less prominently after {@link CompletionItem.detail}. Should be used
-	 * for fully qualified names and file paths.
-	 */
-	Description string `json:"description,omitempty"`
-}
-type CompletionItemTag uint32 // line 13270
-/*
- * Represents a collection of [completion items](#CompletionItem) to be presented
- * in the editor.
- */
-type CompletionList struct { // line 4758
-	/*
-	 * This list it not complete. Further typing results in recomputing this list.
-	 *
-	 * Recomputed lists have all their items replaced (not appended) in the
-	 * incomplete completion sessions.
-	 */
-	IsIncomplete bool `json:"isIncomplete"`
-	/*
-	 * In many cases the items of an actual completion result share the same
-	 * value for properties like `commitCharacters` or the range of a text
-	 * edit. A completion list can therefore define item defaults which will
-	 * be used if a completion item itself doesn't specify the value.
-	 *
-	 * If a completion list specifies a default value and a completion item
-	 * also specifies a corresponding value the one from the item is used.
-	 *
-	 * Servers are only allowed to return default values if the client
-	 * signals support for this via the `completionList.itemDefaults`
-	 * capability.
-	 *
-	 * @since 3.17.0
-	 */
-	ItemDefaults *PItemDefaultsMsg_textDocument_completion `json:"itemDefaults,omitempty"`
-	// The completion items.
-	Items []CompletionItem `json:"items"`
-}
-
-// Completion options.
-type CompletionOptions struct { // line 8727
-	/*
-	 * Most tools trigger completion request automatically without explicitly requesting
-	 * it using a keyboard shortcut (e.g. Ctrl+Space). Typically they do so when the user
-	 * starts to type an identifier. For example if the user types `c` in a JavaScript file
-	 * code complete will automatically pop up present `console` besides others as a
-	 * completion item. Characters that make up identifiers don't need to be listed here.
-	 *
-	 * If code complete should automatically be trigger on characters not being valid inside
-	 * an identifier (for example `.` in JavaScript) list them in `triggerCharacters`.
-	 */
-	TriggerCharacters []string `json:"triggerCharacters,omitempty"`
-	/*
-	 * The list of all possible characters that commit a completion. This field can be used
-	 * if clients don't support individual commit characters per completion item. See
-	 * `ClientCapabilities.textDocument.completion.completionItem.commitCharactersSupport`
-	 *
-	 * If a server provides both `allCommitCharacters` and commit characters on an individual
-	 * completion item the ones on the completion item win.
-	 *
-	 * @since 3.2.0
-	 */
-	AllCommitCharacters []string `json:"allCommitCharacters,omitempty"`
-	/*
-	 * The server provides support to resolve additional
-	 * information for a completion item.
-	 */
-	ResolveProvider bool `json:"resolveProvider,omitempty"`
-	/*
-	 * The server supports the following `CompletionItem` specific
-	 * capabilities.
-	 *
-	 * @since 3.17.0
-	 */
-	CompletionItem *PCompletionItemPCompletionProvider `json:"completionItem,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// Completion parameters
-type CompletionParams struct { // line 4519
-	/*
-	 * The completion context. This is only available it the client specifies
-	 * to send this using the client capability `textDocument.completion.contextSupport === true`
-	 */
-	Context CompletionContext `json:"context,omitempty"`
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [CompletionRequest](#CompletionRequest).
-type CompletionRegistrationOptions struct { // line 4875
-	TextDocumentRegistrationOptions
-	CompletionOptions
-}
-type CompletionTriggerKind uint32 // line 13581
-type ConfigurationItem struct {   // line 6401
-	// The scope to get the configuration section for.
-	ScopeURI string `json:"scopeUri,omitempty"`
-	// The configuration section asked for.
-	Section string `json:"section,omitempty"`
-}
-
-// The parameters of a configuration request.
-type ConfigurationParams struct { // line 2207
-	Items []ConfigurationItem `json:"items"`
-}
-
-// Create file operation.
-type CreateFile struct { // line 6717
-	// A create
-	Kind string `json:"kind"`
-	// The resource to create.
-	URI DocumentURI `json:"uri"`
-	// Additional options
-	Options *CreateFileOptions `json:"options,omitempty"`
-	ResourceOperation
-}
-
-// Options to create a file.
-type CreateFileOptions struct { // line 9437
-	// Overwrite existing file. Overwrite wins over `ignoreIfExists`
-	Overwrite bool `json:"overwrite,omitempty"`
-	// Ignore if exists.
-	IgnoreIfExists bool `json:"ignoreIfExists,omitempty"`
-}
-
-/*
- * The parameters sent in notifications/requests for user-initiated creation of
- * files.
- *
- * @since 3.16.0
- */
-type CreateFilesParams struct { // line 3197
-	// An array of all files/folders created in this operation.
-	Files []FileCreate `json:"files"`
-}
-
-// The declaration of a symbol representation as one or many [locations](#Location).
-type Declaration = []Location // (alias) line 13859
-// @since 3.14.0
-type DeclarationClientCapabilities struct { // line 11535
-	/*
-	 * Whether declaration supports dynamic registration. If this is set to `true`
-	 * the client supports the new `DeclarationRegistrationOptions` return value
-	 * for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	// The client supports additional metadata in the form of declaration links.
-	LinkSupport bool `json:"linkSupport,omitempty"`
-}
-
-/*
- * Information about where a symbol is declared.
- *
- * Provides additional metadata over normal [location](#Location) declarations, including the range of
- * the declaring symbol.
- *
- * Servers should prefer returning `DeclarationLink` over `Declaration` if supported
- * by the client.
- */
-type DeclarationLink = LocationLink // (alias) line 13879
-type DeclarationOptions struct {    // line 6496
-	WorkDoneProgressOptions
-}
-type DeclarationParams struct { // line 2516
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type DeclarationRegistrationOptions struct { // line 2536
-	DeclarationOptions
-	TextDocumentRegistrationOptions
-	StaticRegistrationOptions
-}
-
-/*
- * The definition of a symbol represented as one or many [locations](#Location).
- * For most programming languages there is only one location at which a symbol is
- * defined.
- *
- * Servers should prefer returning `DefinitionLink` over `Definition` if supported
- * by the client.
- */
-type Definition = Or_Definition // (alias) line 13777
-// Client Capabilities for a [DefinitionRequest](#DefinitionRequest).
-type DefinitionClientCapabilities struct { // line 11560
-	// Whether definition supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The client supports additional metadata in the form of definition links.
-	 *
-	 * @since 3.14.0
-	 */
-	LinkSupport bool `json:"linkSupport,omitempty"`
-}
-
-/*
- * Information about where a symbol is defined.
- *
- * Provides additional metadata over normal [location](#Location) definitions, including the range of
- * the defining symbol
- */
-type DefinitionLink = LocationLink // (alias) line 13797
-// Server Capabilities for a [DefinitionRequest](#DefinitionRequest).
-type DefinitionOptions struct { // line 8939
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [DefinitionRequest](#DefinitionRequest).
-type DefinitionParams struct { // line 5039
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [DefinitionRequest](#DefinitionRequest).
-type DefinitionRegistrationOptions struct { // line 5060
-	TextDocumentRegistrationOptions
-	DefinitionOptions
-}
-
-// Delete file operation
-type DeleteFile struct { // line 6799
-	// A delete
-	Kind string `json:"kind"`
-	// The file to delete.
-	URI DocumentURI `json:"uri"`
-	// Delete options.
-	Options *DeleteFileOptions `json:"options,omitempty"`
-	ResourceOperation
-}
-
-// Delete file options
-type DeleteFileOptions struct { // line 9485
-	// Delete the content recursively if a folder is denoted.
-	Recursive bool `json:"recursive,omitempty"`
-	// Ignore the operation if the file doesn't exist.
-	IgnoreIfNotExists bool `json:"ignoreIfNotExists,omitempty"`
-}
-
-/*
- * The parameters sent in notifications/requests for user-initiated deletes of
- * files.
- *
- * @since 3.16.0
- */
-type DeleteFilesParams struct { // line 3322
-	// An array of all files/folders deleted in this operation.
-	Files []FileDelete `json:"files"`
-}
-
-/*
- * Represents a diagnostic, such as a compiler error or warning. Diagnostic objects
- * are only valid in the scope of a resource.
- */
-type Diagnostic struct { // line 8545
-	// The range at which the message applies
-	Range Range `json:"range"`
-	/*
-	 * The diagnostic's severity. Can be omitted. If omitted it is up to the
-	 * client to interpret diagnostics as error, warning, info or hint.
-	 */
-	Severity DiagnosticSeverity `json:"severity,omitempty"`
-	// The diagnostic's code, which usually appear in the user interface.
-	Code interface{} `json:"code,omitempty"`
-	/*
-	 * An optional property to describe the error code.
-	 * Requires the code field (above) to be present/not null.
-	 *
-	 * @since 3.16.0
-	 */
-	CodeDescription *CodeDescription `json:"codeDescription,omitempty"`
-	/*
-	 * A human-readable string describing the source of this
-	 * diagnostic, e.g. 'typescript' or 'super lint'. It usually
-	 * appears in the user interface.
-	 */
-	Source string `json:"source,omitempty"`
-	// The diagnostic's message. It usually appears in the user interface
-	Message string `json:"message"`
-	/*
-	 * Additional metadata about the diagnostic.
-	 *
-	 * @since 3.15.0
-	 */
-	Tags []DiagnosticTag `json:"tags,omitempty"`
-	/*
-	 * An array of related diagnostic information, e.g. when symbol-names within
-	 * a scope collide all definitions can be marked via this property.
-	 */
-	RelatedInformation []DiagnosticRelatedInformation `json:"relatedInformation,omitempty"`
-	/*
-	 * A data entry field that is preserved between a `textDocument/publishDiagnostics`
-	 * notification and `textDocument/codeAction` request.
-	 *
-	 * @since 3.16.0
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-/*
- * Client capabilities specific to diagnostic pull requests.
- *
- * @since 3.17.0
- */
-type DiagnosticClientCapabilities struct { // line 12434
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `(TextDocumentRegistrationOptions & StaticRegistrationOptions)`
-	 * return value for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	// Whether the clients supports related documents for document diagnostic pulls.
-	RelatedDocumentSupport bool `json:"relatedDocumentSupport,omitempty"`
-}
-
-/*
- * Diagnostic options.
- *
- * @since 3.17.0
- */
-type DiagnosticOptions struct { // line 7298
-	/*
-	 * An optional identifier under which the diagnostics are
-	 * managed by the client.
-	 */
-	Identifier string `json:"identifier,omitempty"`
-	/*
-	 * Whether the language has inter file dependencies meaning that
-	 * editing code in one file can result in a different diagnostic
-	 * set in another file. Inter file dependencies are common for
-	 * most programming languages and typically uncommon for linters.
-	 */
-	InterFileDependencies bool `json:"interFileDependencies"`
-	// The server provides support for workspace diagnostics as well.
-	WorkspaceDiagnostics bool `json:"workspaceDiagnostics"`
-	WorkDoneProgressOptions
-}
-
-/*
- * Diagnostic registration options.
- *
- * @since 3.17.0
- */
-type DiagnosticRegistrationOptions struct { // line 3877
-	TextDocumentRegistrationOptions
-	DiagnosticOptions
-	StaticRegistrationOptions
-}
-
-/*
- * Represents a related message and source code location for a diagnostic. This should be
- * used to point to code locations that cause or related to a diagnostics, e.g when duplicating
- * a symbol in a scope.
- */
-type DiagnosticRelatedInformation struct { // line 10067
-	// The location of this related diagnostic information.
-	Location Location `json:"location"`
-	// The message of this related diagnostic information.
-	Message string `json:"message"`
-}
-
-/*
- * Cancellation data returned from a diagnostic request.
- *
- * @since 3.17.0
- */
-type DiagnosticServerCancellationData struct { // line 3863
-	RetriggerRequest bool `json:"retriggerRequest"`
-}
-type DiagnosticSeverity uint32 // line 13530
-type DiagnosticTag uint32      // line 13560
-/*
- * Workspace client capabilities specific to diagnostic pull requests.
- *
- * @since 3.17.0
- */
-type DiagnosticWorkspaceClientCapabilities struct { // line 11137
-	/*
-	 * Whether the client implementation supports a refresh request sent from
-	 * the server to the client.
-	 *
-	 * Note that this event is global and will force the client to refresh all
-	 * pulled diagnostics currently shown. It should be used with absolute care and
-	 * is useful for situation where a server for example detects a project wide
-	 * change that requires such a calculation.
-	 */
-	RefreshSupport bool `json:"refreshSupport,omitempty"`
-}
-type DidChangeConfigurationClientCapabilities struct { // line 10863
-	// Did change configuration notification supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// The parameters of a change configuration notification.
-type DidChangeConfigurationParams struct { // line 4166
-	// The actual changed settings
-	Settings interface{} `json:"settings"`
-}
-type DidChangeConfigurationRegistrationOptions struct { // line 4180
-	Section *OrPSection_workspace_didChangeConfiguration `json:"section,omitempty"`
-}
-
-/*
- * The params sent in a change notebook document notification.
- *
- * @since 3.17.0
- */
-type DidChangeNotebookDocumentParams struct { // line 3996
-	/*
-	 * The notebook document that did change. The version number points
-	 * to the version after all provided changes have been applied. If
-	 * only the text document content of a cell changes the notebook version
-	 * doesn't necessarily have to change.
-	 */
-	NotebookDocument VersionedNotebookDocumentIdentifier `json:"notebookDocument"`
-	/*
-	 * The actual changes to the notebook document.
-	 *
-	 * The changes describe single state changes to the notebook document.
-	 * So if there are two changes c1 (at array index 0) and c2 (at array
-	 * index 1) for a notebook in state S then c1 moves the notebook from
-	 * S to S' and c2 from S' to S''. So c1 is computed on the state S and
-	 * c2 is computed on the state S'.
-	 *
-	 * To mirror the content of a notebook using change events use the following approach:
-	 * - start with the same initial content
-	 * - apply the 'notebookDocument/didChange' notifications in the order you receive them.
-	 * - apply the `NotebookChangeEvent`s in a single notification in the order
-	 *   you receive them.
-	 */
-	Change NotebookDocumentChangeEvent `json:"change"`
-}
-
-// The change text document notification's parameters.
-type DidChangeTextDocumentParams struct { // line 4309
-	/*
-	 * The document that did change. The version number points
-	 * to the version after all provided content changes have
-	 * been applied.
-	 */
-	TextDocument VersionedTextDocumentIdentifier `json:"textDocument"`
-	/*
-	 * The actual content changes. The content changes describe single state changes
-	 * to the document. So if there are two content changes c1 (at array index 0) and
-	 * c2 (at array index 1) for a document in state S then c1 moves the document from
-	 * S to S' and c2 from S' to S''. So c1 is computed on the state S and c2 is computed
-	 * on the state S'.
-	 *
-	 * To mirror the content of a document using change events use the following approach:
-	 * - start with the same initial content
-	 * - apply the 'textDocument/didChange' notifications in the order you receive them.
-	 * - apply the `TextDocumentContentChangeEvent`s in a single notification in the order
-	 *   you receive them.
-	 */
-	ContentChanges []TextDocumentContentChangeEvent `json:"contentChanges"`
-}
-type DidChangeWatchedFilesClientCapabilities struct { // line 10877
-	/*
-	 * Did change watched files notification supports dynamic registration. Please note
-	 * that the current protocol doesn't support static configuration for file changes
-	 * from the server side.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Whether the client has support for {@link  RelativePattern relative pattern}
-	 * or not.
-	 *
-	 * @since 3.17.0
-	 */
-	RelativePatternSupport bool `json:"relativePatternSupport,omitempty"`
-}
-
-// The watched files change notification's parameters.
-type DidChangeWatchedFilesParams struct { // line 4450
-	// The actual file events.
-	Changes []FileEvent `json:"changes"`
-}
-
-// Describe options to be used when registered for text document change events.
-type DidChangeWatchedFilesRegistrationOptions struct { // line 4467
-	// The watchers to register.
-	Watchers []FileSystemWatcher `json:"watchers"`
-}
-
-// The parameters of a `workspace/didChangeWorkspaceFolders` notification.
-type DidChangeWorkspaceFoldersParams struct { // line 2193
-	// The actual workspace folder change event.
-	Event WorkspaceFoldersChangeEvent `json:"event"`
-}
-
-/*
- * The params sent in a close notebook document notification.
- *
- * @since 3.17.0
- */
-type DidCloseNotebookDocumentParams struct { // line 4034
-	// The notebook document that got closed.
-	NotebookDocument NotebookDocumentIdentifier `json:"notebookDocument"`
-	/*
-	 * The text documents that represent the content
-	 * of a notebook cell that got closed.
-	 */
-	CellTextDocuments []TextDocumentIdentifier `json:"cellTextDocuments"`
-}
-
-// The parameters sent in a close text document notification
-type DidCloseTextDocumentParams struct { // line 4354
-	// The document that was closed.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-}
-
-/*
- * The params sent in an open notebook document notification.
- *
- * @since 3.17.0
- */
-type DidOpenNotebookDocumentParams struct { // line 3970
-	// The notebook document that got opened.
-	NotebookDocument NotebookDocument `json:"notebookDocument"`
-	/*
-	 * The text documents that represent the content
-	 * of a notebook cell.
-	 */
-	CellTextDocuments []TextDocumentItem `json:"cellTextDocuments"`
-}
-
-// The parameters sent in an open text document notification
-type DidOpenTextDocumentParams struct { // line 4295
-	// The document that was opened.
-	TextDocument TextDocumentItem `json:"textDocument"`
-}
-
-/*
- * The params sent in a save notebook document notification.
- *
- * @since 3.17.0
- */
-type DidSaveNotebookDocumentParams struct { // line 4019
-	// The notebook document that got saved.
-	NotebookDocument NotebookDocumentIdentifier `json:"notebookDocument"`
-}
-
-// The parameters sent in a save text document notification
-type DidSaveTextDocumentParams struct { // line 4368
-	// The document that was saved.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	/*
-	 * Optional the content when saved. Depends on the includeText value
-	 * when the save notification was requested.
-	 */
-	Text *string `json:"text,omitempty"`
-}
-type DocumentColorClientCapabilities struct { // line 11901
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `DocumentColorRegistrationOptions` return value
-	 * for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-type DocumentColorOptions struct { // line 6476
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [DocumentColorRequest](#DocumentColorRequest).
-type DocumentColorParams struct { // line 2237
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type DocumentColorRegistrationOptions struct { // line 2283
-	TextDocumentRegistrationOptions
-	DocumentColorOptions
-	StaticRegistrationOptions
-}
-
-/*
- * Parameters of the document diagnostic request.
- *
- * @since 3.17.0
- */
-type DocumentDiagnosticParams struct { // line 3790
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The additional identifier  provided during registration.
-	Identifier string `json:"identifier,omitempty"`
-	// The result id of a previous response if provided.
-	PreviousResultID string `json:"previousResultId,omitempty"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-/*
- * The result of a document diagnostic pull request. A report can
- * either be a full report containing all diagnostics for the
- * requested document or an unchanged report indicating that nothing
- * has changed in terms of diagnostics in comparison to the last
- * pull request.
- *
- * @since 3.17.0
- */
-type DocumentDiagnosticReport = Or_DocumentDiagnosticReport // (alias) line 13909
-type DocumentDiagnosticReportKind string                    // line 12748
-/*
- * A partial result for a document diagnostic report.
- *
- * @since 3.17.0
- */
-type DocumentDiagnosticReportPartialResult struct { // line 3833
-	RelatedDocuments map[DocumentURI]interface{} `json:"relatedDocuments"`
-}
-
-/*
- * A document filter describes a top level text document or
- * a notebook cell document.
- *
- * @since 3.17.0 - proposed support for NotebookCellTextDocumentFilter.
- */
-type DocumentFilter = Or_DocumentFilter // (alias) line 14118
-// Client capabilities of a [DocumentFormattingRequest](#DocumentFormattingRequest).
-type DocumentFormattingClientCapabilities struct { // line 11915
-	// Whether formatting supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// Provider options for a [DocumentFormattingRequest](#DocumentFormattingRequest).
-type DocumentFormattingOptions struct { // line 9241
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [DocumentFormattingRequest](#DocumentFormattingRequest).
-type DocumentFormattingParams struct { // line 5746
-	// The document to format.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The format options.
-	Options FormattingOptions `json:"options"`
-	WorkDoneProgressParams
-}
-
-// Registration options for a [DocumentFormattingRequest](#DocumentFormattingRequest).
-type DocumentFormattingRegistrationOptions struct { // line 5774
-	TextDocumentRegistrationOptions
-	DocumentFormattingOptions
-}
-
-/*
- * A document highlight is a range inside a text document which deserves
- * special attention. Usually a document highlight is visualized by changing
- * the background color of its range.
- */
-type DocumentHighlight struct { // line 5140
-	// The range this highlight applies to.
-	Range Range `json:"range"`
-	// The highlight kind, default is [text](#DocumentHighlightKind.Text).
-	Kind DocumentHighlightKind `json:"kind,omitempty"`
-}
-
-// Client Capabilities for a [DocumentHighlightRequest](#DocumentHighlightRequest).
-type DocumentHighlightClientCapabilities struct { // line 11650
-	// Whether document highlight supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-type DocumentHighlightKind uint32 // line 13327
-// Provider options for a [DocumentHighlightRequest](#DocumentHighlightRequest).
-type DocumentHighlightOptions struct { // line 8975
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [DocumentHighlightRequest](#DocumentHighlightRequest).
-type DocumentHighlightParams struct { // line 5119
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [DocumentHighlightRequest](#DocumentHighlightRequest).
-type DocumentHighlightRegistrationOptions struct { // line 5163
-	TextDocumentRegistrationOptions
-	DocumentHighlightOptions
-}
-
-/*
- * A document link is a range in a text document that links to an internal or external resource, like another
- * text document or a web site.
- */
-type DocumentLink struct { // line 5689
-	// The range this link applies to.
-	Range Range `json:"range"`
-	// The uri this link points to. If missing a resolve request is sent later.
-	Target string `json:"target,omitempty"`
-	/*
-	 * The tooltip text when you hover over this link.
-	 *
-	 * If a tooltip is provided, is will be displayed in a string that includes instructions on how to
-	 * trigger the link, such as `{0} (ctrl + click)`. The specific instructions vary depending on OS,
-	 * user settings, and localization.
-	 *
-	 * @since 3.15.0
-	 */
-	Tooltip string `json:"tooltip,omitempty"`
-	/*
-	 * A data entry field that is preserved on a document link between a
-	 * DocumentLinkRequest and a DocumentLinkResolveRequest.
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-// The client capabilities of a [DocumentLinkRequest](#DocumentLinkRequest).
-type DocumentLinkClientCapabilities struct { // line 11876
-	// Whether document link supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Whether the client supports the `tooltip` property on `DocumentLink`.
-	 *
-	 * @since 3.15.0
-	 */
-	TooltipSupport bool `json:"tooltipSupport,omitempty"`
-}
-
-// Provider options for a [DocumentLinkRequest](#DocumentLinkRequest).
-type DocumentLinkOptions struct { // line 9168
-	// Document links have a resolve provider as well.
-	ResolveProvider bool `json:"resolveProvider,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [DocumentLinkRequest](#DocumentLinkRequest).
-type DocumentLinkParams struct { // line 5665
-	// The document to provide document links for.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [DocumentLinkRequest](#DocumentLinkRequest).
-type DocumentLinkRegistrationOptions struct { // line 5731
-	TextDocumentRegistrationOptions
-	DocumentLinkOptions
-}
-
-// Client capabilities of a [DocumentOnTypeFormattingRequest](#DocumentOnTypeFormattingRequest).
-type DocumentOnTypeFormattingClientCapabilities struct { // line 11945
-	// Whether on type formatting supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// Provider options for a [DocumentOnTypeFormattingRequest](#DocumentOnTypeFormattingRequest).
-type DocumentOnTypeFormattingOptions struct { // line 9263
-	// A character on which formatting should be triggered, like `{`.
-	FirstTriggerCharacter string `json:"firstTriggerCharacter"`
-	// More trigger characters.
-	MoreTriggerCharacter []string `json:"moreTriggerCharacter,omitempty"`
-}
-
-// The parameters of a [DocumentOnTypeFormattingRequest](#DocumentOnTypeFormattingRequest).
-type DocumentOnTypeFormattingParams struct { // line 5840
-	// The document to format.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	/*
-	 * The position around which the on type formatting should happen.
-	 * This is not necessarily the exact position where the character denoted
-	 * by the property `ch` got typed.
-	 */
-	Position Position `json:"position"`
-	/*
-	 * The character that has been typed that triggered the formatting
-	 * on type request. That is not necessarily the last character that
-	 * got inserted into the document since the client could auto insert
-	 * characters as well (e.g. like automatic brace completion).
-	 */
-	Ch string `json:"ch"`
-	// The formatting options.
-	Options FormattingOptions `json:"options"`
-}
-
-// Registration options for a [DocumentOnTypeFormattingRequest](#DocumentOnTypeFormattingRequest).
-type DocumentOnTypeFormattingRegistrationOptions struct { // line 5878
-	TextDocumentRegistrationOptions
-	DocumentOnTypeFormattingOptions
-}
-
-// Client capabilities of a [DocumentRangeFormattingRequest](#DocumentRangeFormattingRequest).
-type DocumentRangeFormattingClientCapabilities struct { // line 11930
-	// Whether range formatting supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// Provider options for a [DocumentRangeFormattingRequest](#DocumentRangeFormattingRequest).
-type DocumentRangeFormattingOptions struct { // line 9252
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [DocumentRangeFormattingRequest](#DocumentRangeFormattingRequest).
-type DocumentRangeFormattingParams struct { // line 5789
-	// The document to format.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The range to format
-	Range Range `json:"range"`
-	// The format options
-	Options FormattingOptions `json:"options"`
-	WorkDoneProgressParams
-}
-
-// Registration options for a [DocumentRangeFormattingRequest](#DocumentRangeFormattingRequest).
-type DocumentRangeFormattingRegistrationOptions struct { // line 5825
-	TextDocumentRegistrationOptions
-	DocumentRangeFormattingOptions
-}
-
-/*
- * A document selector is the combination of one or many document filters.
- *
- * @sample `let sel:DocumentSelector = [{ language: 'typescript' }, { language: 'json', pattern: '**∕tsconfig.json' }]`;
- *
- * The use of a string as a document filter is deprecated @since 3.16.0.
- */
-type DocumentSelector = []DocumentFilter // (alias) line 13990
-/*
- * Represents programming constructs like variables, classes, interfaces etc.
- * that appear in a document. Document symbols can be hierarchical and they
- * have two ranges: one that encloses its definition and one that points to
- * its most interesting range, e.g. the range of an identifier.
- */
-type DocumentSymbol struct { // line 5231
-	/*
-	 * The name of this symbol. Will be displayed in the user interface and therefore must not be
-	 * an empty string or a string only consisting of white spaces.
-	 */
-	Name string `json:"name"`
-	// More detail for this symbol, e.g the signature of a function.
-	Detail string `json:"detail,omitempty"`
-	// The kind of this symbol.
-	Kind SymbolKind `json:"kind"`
-	/*
-	 * Tags for this document symbol.
-	 *
-	 * @since 3.16.0
-	 */
-	Tags []SymbolTag `json:"tags,omitempty"`
-	/*
-	 * Indicates if this symbol is deprecated.
-	 *
-	 * @deprecated Use tags instead
-	 */
-	Deprecated bool `json:"deprecated,omitempty"`
-	/*
-	 * The range enclosing this symbol not including leading/trailing whitespace but everything else
-	 * like comments. This information is typically used to determine if the clients cursor is
-	 * inside the symbol to reveal in the symbol in the UI.
-	 */
-	Range Range `json:"range"`
-	/*
-	 * The range that should be selected and revealed when this symbol is being picked, e.g the name of a function.
-	 * Must be contained by the `range`.
-	 */
-	SelectionRange Range `json:"selectionRange"`
-	// Children of this symbol, e.g. properties of a class.
-	Children []DocumentSymbol `json:"children,omitempty"`
-}
-
-// Client Capabilities for a [DocumentSymbolRequest](#DocumentSymbolRequest).
-type DocumentSymbolClientCapabilities struct { // line 11665
-	// Whether document symbol supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Specific capabilities for the `SymbolKind` in the
-	 * `textDocument/documentSymbol` request.
-	 */
-	SymbolKind *PSymbolKindPDocumentSymbol `json:"symbolKind,omitempty"`
-	// The client supports hierarchical document symbols.
-	HierarchicalDocumentSymbolSupport bool `json:"hierarchicalDocumentSymbolSupport,omitempty"`
-	/*
-	 * The client supports tags on `SymbolInformation`. Tags are supported on
-	 * `DocumentSymbol` if `hierarchicalDocumentSymbolSupport` is set to true.
-	 * Clients supporting tags have to handle unknown tags gracefully.
-	 *
-	 * @since 3.16.0
-	 */
-	TagSupport *PTagSupportPDocumentSymbol `json:"tagSupport,omitempty"`
-	/*
-	 * The client supports an additional label presented in the UI when
-	 * registering a document symbol provider.
-	 *
-	 * @since 3.16.0
-	 */
-	LabelSupport bool `json:"labelSupport,omitempty"`
-}
-
-// Provider options for a [DocumentSymbolRequest](#DocumentSymbolRequest).
-type DocumentSymbolOptions struct { // line 9030
-	/*
-	 * A human-readable string that is shown when multiple outlines trees
-	 * are shown for the same document.
-	 *
-	 * @since 3.16.0
-	 */
-	Label string `json:"label,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [DocumentSymbolRequest](#DocumentSymbolRequest).
-type DocumentSymbolParams struct { // line 5178
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [DocumentSymbolRequest](#DocumentSymbolRequest).
-type DocumentSymbolRegistrationOptions struct { // line 5312
-	TextDocumentRegistrationOptions
-	DocumentSymbolOptions
-}
-type DocumentURI string // line 0
-type ErrorCodes int32   // line 12769
-// The client capabilities of a [ExecuteCommandRequest](#ExecuteCommandRequest).
-type ExecuteCommandClientCapabilities struct { // line 10988
-	// Execute command supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// The server capabilities of a [ExecuteCommandRequest](#ExecuteCommandRequest).
-type ExecuteCommandOptions struct { // line 9311
-	// The commands to be executed on the server
-	Commands []string `json:"commands"`
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [ExecuteCommandRequest](#ExecuteCommandRequest).
-type ExecuteCommandParams struct { // line 5960
-	// The identifier of the actual command handler.
-	Command string `json:"command"`
-	// Arguments that the command should be invoked with.
-	Arguments []json.RawMessage `json:"arguments,omitempty"`
-	WorkDoneProgressParams
-}
-
-// Registration options for a [ExecuteCommandRequest](#ExecuteCommandRequest).
-type ExecuteCommandRegistrationOptions struct { // line 5992
-	ExecuteCommandOptions
-}
-type ExecutionSummary struct { // line 10188
-	/*
-	 * A strict monotonically increasing value
-	 * indicating the execution order of a cell
-	 * inside a notebook.
-	 */
-	ExecutionOrder uint32 `json:"executionOrder"`
-	/*
-	 * Whether the execution was successful or
-	 * not if known by the client.
-	 */
-	Success bool `json:"success,omitempty"`
-}
-
-// created for Literal
-type FCellsPNotebookSelector struct { // line 9857
-	Language string `json:"language"`
-}
-
-// created for Literal
-type FCodeActionKindPCodeActionLiteralSupport struct { // line 11768
-	/*
-	 * The code action kind values the client supports. When this
-	 * property exists the client also guarantees that it will
-	 * handle values outside its set gracefully and falls back
-	 * to a default value when unknown.
-	 */
-	ValueSet []CodeActionKind `json:"valueSet"`
-}
-
-// created for Literal
-type FEditRangePItemDefaults struct { // line 4797
-	Insert  Range `json:"insert"`
-	Replace Range `json:"replace"`
-}
-
-// created for Literal
-type FFullPRequests struct { // line 12230
-	/*
-	 * The client will send the `textDocument/semanticTokens/full/delta` request if
-	 * the server provides a corresponding handler.
-	 */
-	Delta bool `json:"delta"`
-}
-
-// created for Literal
-type FInsertTextModeSupportPCompletionItem struct { // line 11321
-	ValueSet []InsertTextMode `json:"valueSet"`
-}
-
-// created for Literal
-type FParameterInformationPSignatureInformation struct { // line 11487
-	/*
-	 * The client supports processing label offsets instead of a
-	 * simple label string.
-	 *
-	 * @since 3.14.0
-	 */
-	LabelOffsetSupport bool `json:"labelOffsetSupport"`
-}
-
-// created for Literal
-type FRangePRequests struct { // line 12210
-}
-
-// created for Literal
-type FResolveSupportPCompletionItem struct { // line 11297
-	// The properties that a client can resolve lazily.
-	Properties []string `json:"properties"`
-}
-
-// created for Literal
-type FStructurePCells struct { // line 7492
-	// The change to the cell array.
-	Array NotebookCellArrayChange `json:"array"`
-	// Additional opened cell text documents.
-	DidOpen []TextDocumentItem `json:"didOpen"`
-	// Additional closed cell text documents.
-	DidClose []TextDocumentIdentifier `json:"didClose"`
-}
-
-// created for Literal
-type FTagSupportPCompletionItem struct { // line 11263
-	// The tags supported by the client.
-	ValueSet []CompletionItemTag `json:"valueSet"`
-}
-
-// created for Literal
-type FTextContentPCells struct { // line 7550
-	Document VersionedTextDocumentIdentifier  `json:"document"`
-	Changes  []TextDocumentContentChangeEvent `json:"changes"`
-}
-type FailureHandlingKind string // line 13719
-type FileChangeType uint32      // line 13480
-/*
- * Represents information on a file/folder create.
- *
- * @since 3.16.0
- */
-type FileCreate struct { // line 6667
-	// A file:// URI for the location of the file/folder being created.
-	URI string `json:"uri"`
-}
-
-/*
- * Represents information on a file/folder delete.
- *
- * @since 3.16.0
- */
-type FileDelete struct { // line 6916
-	// A file:// URI for the location of the file/folder being deleted.
-	URI string `json:"uri"`
-}
-
-// An event describing a file change.
-type FileEvent struct { // line 8500
-	// The file's uri.
-	URI DocumentURI `json:"uri"`
-	// The change type.
-	Type FileChangeType `json:"type"`
-}
-
-/*
- * Capabilities relating to events from file operations by the user in the client.
- *
- * These events do not come from the file system, they come from user operations
- * like renaming a file in the UI.
- *
- * @since 3.16.0
- */
-type FileOperationClientCapabilities struct { // line 11035
-	// Whether the client supports dynamic registration for file requests/notifications.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	// The client has support for sending didCreateFiles notifications.
-	DidCreate bool `json:"didCreate,omitempty"`
-	// The client has support for sending willCreateFiles requests.
-	WillCreate bool `json:"willCreate,omitempty"`
-	// The client has support for sending didRenameFiles notifications.
-	DidRename bool `json:"didRename,omitempty"`
-	// The client has support for sending willRenameFiles requests.
-	WillRename bool `json:"willRename,omitempty"`
-	// The client has support for sending didDeleteFiles notifications.
-	DidDelete bool `json:"didDelete,omitempty"`
-	// The client has support for sending willDeleteFiles requests.
-	WillDelete bool `json:"willDelete,omitempty"`
-}
-
-/*
- * A filter to describe in which file operation requests or notifications
- * the server is interested in receiving.
- *
- * @since 3.16.0
- */
-type FileOperationFilter struct { // line 6869
-	// A Uri scheme like `file` or `untitled`.
-	Scheme string `json:"scheme,omitempty"`
-	// The actual file operation pattern.
-	Pattern FileOperationPattern `json:"pattern"`
-}
-
-/*
- * Options for notifications/requests for user operations on files.
- *
- * @since 3.16.0
- */
-type FileOperationOptions struct { // line 9991
-	// The server is interested in receiving didCreateFiles notifications.
-	DidCreate *FileOperationRegistrationOptions `json:"didCreate,omitempty"`
-	// The server is interested in receiving willCreateFiles requests.
-	WillCreate *FileOperationRegistrationOptions `json:"willCreate,omitempty"`
-	// The server is interested in receiving didRenameFiles notifications.
-	DidRename *FileOperationRegistrationOptions `json:"didRename,omitempty"`
-	// The server is interested in receiving willRenameFiles requests.
-	WillRename *FileOperationRegistrationOptions `json:"willRename,omitempty"`
-	// The server is interested in receiving didDeleteFiles file notifications.
-	DidDelete *FileOperationRegistrationOptions `json:"didDelete,omitempty"`
-	// The server is interested in receiving willDeleteFiles file requests.
-	WillDelete *FileOperationRegistrationOptions `json:"willDelete,omitempty"`
-}
-
-/*
- * A pattern to describe in which file operation requests or notifications
- * the server is interested in receiving.
- *
- * @since 3.16.0
- */
-type FileOperationPattern struct { // line 9509
-	/*
-	 * The glob pattern to match. Glob patterns can have the following syntax:
-	 * - `*` to match one or more characters in a path segment
-	 * - `?` to match on one character in a path segment
-	 * - `**` to match any number of path segments, including none
-	 * - `{}` to group sub patterns into an OR expression. (e.g. `**​/*.{ts,js}` matches all TypeScript and JavaScript files)
-	 * - `[]` to declare a range of characters to match in a path segment (e.g., `example.[0-9]` to match on `example.0`, `example.1`, …)
-	 * - `[!...]` to negate a range of characters to match in a path segment (e.g., `example.[!0-9]` to match on `example.a`, `example.b`, but not `example.0`)
-	 */
-	Glob string `json:"glob"`
-	/*
-	 * Whether to match files or folders with this pattern.
-	 *
-	 * Matches both if undefined.
-	 */
-	Matches FileOperationPatternKind `json:"matches,omitempty"`
-	// Additional options used during matching.
-	Options *FileOperationPatternOptions `json:"options,omitempty"`
-}
-type FileOperationPatternKind string // line 13653
-/*
- * Matching options for the file operation pattern.
- *
- * @since 3.16.0
- */
-type FileOperationPatternOptions struct { // line 10172
-	// The pattern should be matched ignoring casing.
-	IgnoreCase bool `json:"ignoreCase,omitempty"`
-}
-
-/*
- * The options to register for file operations.
- *
- * @since 3.16.0
- */
-type FileOperationRegistrationOptions struct { // line 3286
-	// The actual filters.
-	Filters []FileOperationFilter `json:"filters"`
-}
-
-/*
- * Represents information on a file/folder rename.
- *
- * @since 3.16.0
- */
-type FileRename struct { // line 6893
-	// A file:// URI for the original location of the file/folder being renamed.
-	OldURI string `json:"oldUri"`
-	// A file:// URI for the new location of the file/folder being renamed.
-	NewURI string `json:"newUri"`
-}
-type FileSystemWatcher struct { // line 8522
-	/*
-	 * The glob pattern to watch. See {@link GlobPattern glob pattern} for more detail.
-	 *
-	 * @since 3.17.0 support for relative patterns.
-	 */
-	GlobPattern GlobPattern `json:"globPattern"`
-	/*
-	 * The kind of events of interest. If omitted it defaults
-	 * to WatchKind.Create | WatchKind.Change | WatchKind.Delete
-	 * which is 7.
-	 */
-	Kind WatchKind `json:"kind,omitempty"`
-}
-
-/*
- * Represents a folding range. To be valid, start and end line must be bigger than zero and smaller
- * than the number of lines in the document. Clients are free to ignore invalid ranges.
- */
-type FoldingRange struct { // line 2437
-	/*
-	 * The zero-based start line of the range to fold. The folded area starts after the line's last character.
-	 * To be valid, the end must be zero or larger and smaller than the number of lines in the document.
-	 */
-	StartLine uint32 `json:"startLine"`
-	// The zero-based character offset from where the folded range starts. If not defined, defaults to the length of the start line.
-	StartCharacter uint32 `json:"startCharacter,omitempty"`
-	/*
-	 * The zero-based end line of the range to fold. The folded area ends with the line's last character.
-	 * To be valid, the end must be zero or larger and smaller than the number of lines in the document.
-	 */
-	EndLine uint32 `json:"endLine"`
-	// The zero-based character offset before the folded range ends. If not defined, defaults to the length of the end line.
-	EndCharacter uint32 `json:"endCharacter,omitempty"`
-	/*
-	 * Describes the kind of the folding range such as `comment' or 'region'. The kind
-	 * is used to categorize folding ranges and used by commands like 'Fold all comments'.
-	 * See [FoldingRangeKind](#FoldingRangeKind) for an enumeration of standardized kinds.
-	 */
-	Kind string `json:"kind,omitempty"`
-	/*
-	 * The text that the client should show when the specified range is
-	 * collapsed. If not defined or not supported by the client, a default
-	 * will be chosen by the client.
-	 *
-	 * @since 3.17.0
-	 */
-	CollapsedText string `json:"collapsedText,omitempty"`
-}
-type FoldingRangeClientCapabilities struct { // line 12004
-	/*
-	 * Whether implementation supports dynamic registration for folding range
-	 * providers. If this is set to `true` the client supports the new
-	 * `FoldingRangeRegistrationOptions` return value for the corresponding
-	 * server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The maximum number of folding ranges that the client prefers to receive
-	 * per document. The value serves as a hint, servers are free to follow the
-	 * limit.
-	 */
-	RangeLimit uint32 `json:"rangeLimit,omitempty"`
-	/*
-	 * If set, the client signals that it only supports folding complete lines.
-	 * If set, client will ignore specified `startCharacter` and `endCharacter`
-	 * properties in a FoldingRange.
-	 */
-	LineFoldingOnly bool `json:"lineFoldingOnly,omitempty"`
-	/*
-	 * Specific options for the folding range kind.
-	 *
-	 * @since 3.17.0
-	 */
-	FoldingRangeKind *PFoldingRangeKindPFoldingRange `json:"foldingRangeKind,omitempty"`
-	/*
-	 * Specific options for the folding range.
-	 *
-	 * @since 3.17.0
-	 */
-	FoldingRange *PFoldingRangePFoldingRange `json:"foldingRange,omitempty"`
-}
-type FoldingRangeKind string      // line 12841
-type FoldingRangeOptions struct { // line 6486
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [FoldingRangeRequest](#FoldingRangeRequest).
-type FoldingRangeParams struct { // line 2413
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type FoldingRangeRegistrationOptions struct { // line 2496
-	TextDocumentRegistrationOptions
-	FoldingRangeOptions
-	StaticRegistrationOptions
-}
-
-// Value-object describing what options formatting should use.
-type FormattingOptions struct { // line 9189
-	// Size of a tab in spaces.
-	TabSize uint32 `json:"tabSize"`
-	// Prefer spaces over tabs.
-	InsertSpaces bool `json:"insertSpaces"`
-	/*
-	 * Trim trailing whitespace on a line.
-	 *
-	 * @since 3.15.0
-	 */
-	TrimTrailingWhitespace bool `json:"trimTrailingWhitespace,omitempty"`
-	/*
-	 * Insert a newline character at the end of the file if one does not exist.
-	 *
-	 * @since 3.15.0
-	 */
-	InsertFinalNewline bool `json:"insertFinalNewline,omitempty"`
-	/*
-	 * Trim all newlines after the final newline at the end of the file.
-	 *
-	 * @since 3.15.0
-	 */
-	TrimFinalNewlines bool `json:"trimFinalNewlines,omitempty"`
-}
-
-/*
- * A diagnostic report with a full set of problems.
- *
- * @since 3.17.0
- */
-type FullDocumentDiagnosticReport struct { // line 7240
-	// A full document diagnostic report.
-	Kind string `json:"kind"`
-	/*
-	 * An optional result id. If provided it will
-	 * be sent on the next diagnostic request for the
-	 * same document.
-	 */
-	ResultID string `json:"resultId,omitempty"`
-	// The actual items.
-	Items []Diagnostic `json:"items"`
-}
-
-/*
- * General client capabilities.
- *
- * @since 3.16.0
- */
-type GeneralClientCapabilities struct { // line 10690
-	/*
-	 * Client capability that signals how the client
-	 * handles stale requests (e.g. a request
-	 * for which the client will not process the response
-	 * anymore since the information is outdated).
-	 *
-	 * @since 3.17.0
-	 */
-	StaleRequestSupport *PStaleRequestSupportPGeneral `json:"staleRequestSupport,omitempty"`
-	/*
-	 * Client capabilities specific to regular expressions.
-	 *
-	 * @since 3.16.0
-	 */
-	RegularExpressions *RegularExpressionsClientCapabilities `json:"regularExpressions,omitempty"`
-	/*
-	 * Client capabilities specific to the client's markdown parser.
-	 *
-	 * @since 3.16.0
-	 */
-	Markdown *MarkdownClientCapabilities `json:"markdown,omitempty"`
-	/*
-	 * The position encodings supported by the client. Client and server
-	 * have to agree on the same position encoding to ensure that offsets
-	 * (e.g. character position in a line) are interpreted the same on both
-	 * sides.
-	 *
-	 * To keep the protocol backwards compatible the following applies: if
-	 * the value 'utf-16' is missing from the array of position encodings
-	 * servers can assume that the client supports UTF-16. UTF-16 is
-	 * therefore a mandatory encoding.
-	 *
-	 * If omitted it defaults to ['utf-16'].
-	 *
-	 * Implementation considerations: since the conversion from one encoding
-	 * into another requires the content of the file / line the conversion
-	 * is best done where the file is read which is usually on the server
-	 * side.
-	 *
-	 * @since 3.17.0
-	 */
-	PositionEncodings []PositionEncodingKind `json:"positionEncodings,omitempty"`
-}
-
-/*
- * The glob pattern. Either a string pattern or a relative pattern.
- *
- * @since 3.17.0
- */
-type GlobPattern = string // (alias) line 14136
-// The result of a hover request.
-type Hover struct { // line 4907
-	// The hover's content
-	Contents MarkupContent `json:"contents"`
-	/*
-	 * An optional range inside the text document that is used to
-	 * visualize the hover, e.g. by changing the background color.
-	 */
-	Range Range `json:"range,omitempty"`
-}
-type HoverClientCapabilities struct { // line 11428
-	// Whether hover supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Client supports the following content formats for the content
-	 * property. The order describes the preferred format of the client.
-	 */
-	ContentFormat []MarkupKind `json:"contentFormat,omitempty"`
-}
-
-// Hover options.
-type HoverOptions struct { // line 8796
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [HoverRequest](#HoverRequest).
-type HoverParams struct { // line 4890
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-}
-
-// Registration options for a [HoverRequest](#HoverRequest).
-type HoverRegistrationOptions struct { // line 4946
-	TextDocumentRegistrationOptions
-	HoverOptions
-}
-
-// @since 3.6.0
-type ImplementationClientCapabilities struct { // line 11609
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `ImplementationRegistrationOptions` return value
-	 * for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The client supports additional metadata in the form of definition links.
-	 *
-	 * @since 3.14.0
-	 */
-	LinkSupport bool `json:"linkSupport,omitempty"`
-}
-type ImplementationOptions struct { // line 6338
-	WorkDoneProgressOptions
-}
-type ImplementationParams struct { // line 2071
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type ImplementationRegistrationOptions struct { // line 2111
-	TextDocumentRegistrationOptions
-	ImplementationOptions
-	StaticRegistrationOptions
-}
-
-/*
- * The data type of the ResponseError if the
- * initialize request fails.
- */
-type InitializeError struct { // line 4148
-	/*
-	 * Indicates whether the client execute the following retry logic:
-	 * (1) show the message provided by the ResponseError to the user
-	 * (2) user selects retry or cancel
-	 * (3) if user selected retry the initialize method is sent again.
-	 */
-	Retry bool `json:"retry"`
-}
-type InitializeParams struct { // line 4090
-	XInitializeParams
-	WorkspaceFoldersInitializeParams
-}
-
-// The result returned from an initialize request.
-type InitializeResult struct { // line 4104
-	// The capabilities the language server provides.
-	Capabilities ServerCapabilities `json:"capabilities"`
-	/*
-	 * Information about the server.
-	 *
-	 * @since 3.15.0
-	 */
-	ServerInfo PServerInfoMsg_initialize `json:"serverInfo,omitempty"`
-}
-type InitializedParams struct { // line 4162
-}
-
-/*
- * Inlay hint information.
- *
- * @since 3.17.0
- */
-type InlayHint struct { // line 3667
-	// The position of this hint.
-	Position *Position `json:"position"`
-	/*
-	 * The label of this hint. A human readable string or an array of
-	 * InlayHintLabelPart label parts.
-	 *
-	 * *Note* that neither the string nor the label part can be empty.
-	 */
-	Label []InlayHintLabelPart `json:"label"`
-	/*
-	 * The kind of this hint. Can be omitted in which case the client
-	 * should fall back to a reasonable default.
-	 */
-	Kind InlayHintKind `json:"kind,omitempty"`
-	/*
-	 * Optional text edits that are performed when accepting this inlay hint.
-	 *
-	 * *Note* that edits are expected to change the document so that the inlay
-	 * hint (or its nearest variant) is now part of the document and the inlay
-	 * hint itself is now obsolete.
-	 */
-	TextEdits []TextEdit `json:"textEdits,omitempty"`
-	// The tooltip text when you hover over this item.
-	Tooltip *OrPTooltip_textDocument_inlayHint `json:"tooltip,omitempty"`
-	/*
-	 * Render padding before the hint.
-	 *
-	 * Note: Padding should use the editor's background color, not the
-	 * background color of the hint itself. That means padding can be used
-	 * to visually align/separate an inlay hint.
-	 */
-	PaddingLeft bool `json:"paddingLeft,omitempty"`
-	/*
-	 * Render padding after the hint.
-	 *
-	 * Note: Padding should use the editor's background color, not the
-	 * background color of the hint itself. That means padding can be used
-	 * to visually align/separate an inlay hint.
-	 */
-	PaddingRight bool `json:"paddingRight,omitempty"`
-	/*
-	 * A data entry field that is preserved on an inlay hint between
-	 * a `textDocument/inlayHint` and a `inlayHint/resolve` request.
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-/*
- * Inlay hint client capabilities.
- *
- * @since 3.17.0
- */
-type InlayHintClientCapabilities struct { // line 12395
-	// Whether inlay hints support dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Indicates which properties a client can resolve lazily on an inlay
-	 * hint.
-	 */
-	ResolveSupport *PResolveSupportPInlayHint `json:"resolveSupport,omitempty"`
-}
-type InlayHintKind uint32 // line 13059
-/*
- * An inlay hint label part allows for interactive and composite labels
- * of inlay hints.
- *
- * @since 3.17.0
- */
-type InlayHintLabelPart struct { // line 7067
-	// The value of this label part.
-	Value string `json:"value"`
-	/*
-	 * The tooltip text when you hover over this label part. Depending on
-	 * the client capability `inlayHint.resolveSupport` clients might resolve
-	 * this property late using the resolve request.
-	 */
-	Tooltip *OrPTooltipPLabel `json:"tooltip,omitempty"`
-	/*
-	 * An optional source code location that represents this
-	 * label part.
-	 *
-	 * The editor will use this location for the hover and for code navigation
-	 * features: This part will become a clickable link that resolves to the
-	 * definition of the symbol at the given location (not necessarily the
-	 * location itself), it shows the hover that shows at the given location,
-	 * and it shows a context menu with further code navigation commands.
-	 *
-	 * Depending on the client capability `inlayHint.resolveSupport` clients
-	 * might resolve this property late using the resolve request.
-	 */
-	Location *Location `json:"location,omitempty"`
-	/*
-	 * An optional command for this label part.
-	 *
-	 * Depending on the client capability `inlayHint.resolveSupport` clients
-	 * might resolve this property late using the resolve request.
-	 */
-	Command *Command `json:"command,omitempty"`
-}
-
-/*
- * Inlay hint options used during static registration.
- *
- * @since 3.17.0
- */
-type InlayHintOptions struct { // line 7140
-	/*
-	 * The server provides support to resolve additional
-	 * information for an inlay hint item.
-	 */
-	ResolveProvider bool `json:"resolveProvider,omitempty"`
-	WorkDoneProgressOptions
-}
-
-/*
- * A parameter literal used in inlay hint requests.
- *
- * @since 3.17.0
- */
-type InlayHintParams struct { // line 3638
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The document range for which inlay hints should be computed.
-	Range Range `json:"range"`
-	WorkDoneProgressParams
-}
-
-/*
- * Inlay hint options used during static or dynamic registration.
- *
- * @since 3.17.0
- */
-type InlayHintRegistrationOptions struct { // line 3768
-	InlayHintOptions
-	TextDocumentRegistrationOptions
-	StaticRegistrationOptions
-}
-
-/*
- * Client workspace capabilities specific to inlay hints.
- *
- * @since 3.17.0
- */
-type InlayHintWorkspaceClientCapabilities struct { // line 11121
-	/*
-	 * Whether the client implementation supports a refresh request sent from
-	 * the server to the client.
-	 *
-	 * Note that this event is global and will force the client to refresh all
-	 * inlay hints currently shown. It should be used with absolute care and
-	 * is useful for situation where a server for example detects a project wide
-	 * change that requires such a calculation.
-	 */
-	RefreshSupport bool `json:"refreshSupport,omitempty"`
-}
-
-/*
- * Inline value information can be provided by different means:
- * - directly as a text value (class InlineValueText).
- * - as a name to use for a variable lookup (class InlineValueVariableLookup)
- * - as an evaluatable expression (class InlineValueEvaluatableExpression)
- * The InlineValue types combines all inline value types into one type.
- *
- * @since 3.17.0
- */
-type InlineValue = Or_InlineValue // (alias) line 13887
-/*
- * Client capabilities specific to inline values.
- *
- * @since 3.17.0
- */
-type InlineValueClientCapabilities struct { // line 12379
-	// Whether implementation supports dynamic registration for inline value providers.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// @since 3.17.0
-type InlineValueContext struct { // line 6953
-	// The stack frame (as a DAP Id) where the execution has stopped.
-	FrameID int32 `json:"frameId"`
-	/*
-	 * The document range where execution has stopped.
-	 * Typically the end position of the range denotes the line where the inline values are shown.
-	 */
-	StoppedLocation Range `json:"stoppedLocation"`
-}
-
-/*
- * Provide an inline value through an expression evaluation.
- * If only a range is specified, the expression will be extracted from the underlying document.
- * An optional expression can be used to override the extracted expression.
- *
- * @since 3.17.0
- */
-type InlineValueEvaluatableExpression struct { // line 7031
-	/*
-	 * The document range for which the inline value applies.
-	 * The range is used to extract the evaluatable expression from the underlying document.
-	 */
-	Range Range `json:"range"`
-	// If specified the expression overrides the extracted expression.
-	Expression string `json:"expression,omitempty"`
-}
-
-/*
- * Inline value options used during static registration.
- *
- * @since 3.17.0
- */
-type InlineValueOptions struct { // line 7055
-	WorkDoneProgressOptions
-}
-
-/*
- * A parameter literal used in inline value requests.
- *
- * @since 3.17.0
- */
-type InlineValueParams struct { // line 3579
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The document range for which inline values should be computed.
-	Range Range `json:"range"`
-	/*
-	 * Additional information about the context in which inline values were
-	 * requested.
-	 */
-	Context InlineValueContext `json:"context"`
-	WorkDoneProgressParams
-}
-
-/*
- * Inline value options used during static or dynamic registration.
- *
- * @since 3.17.0
- */
-type InlineValueRegistrationOptions struct { // line 3616
-	InlineValueOptions
-	TextDocumentRegistrationOptions
-	StaticRegistrationOptions
-}
-
-/*
- * Provide inline value as text.
- *
- * @since 3.17.0
- */
-type InlineValueText struct { // line 6976
-	// The document range for which the inline value applies.
-	Range Range `json:"range"`
-	// The text of the inline value.
-	Text string `json:"text"`
-}
-
-/*
- * Provide inline value through a variable lookup.
- * If only a range is specified, the variable name will be extracted from the underlying document.
- * An optional variable name can be used to override the extracted name.
- *
- * @since 3.17.0
- */
-type InlineValueVariableLookup struct { // line 6999
-	/*
-	 * The document range for which the inline value applies.
-	 * The range is used to extract the variable name from the underlying document.
-	 */
-	Range Range `json:"range"`
-	// If specified the name of the variable to look up.
-	VariableName string `json:"variableName,omitempty"`
-	// How to perform the lookup.
-	CaseSensitiveLookup bool `json:"caseSensitiveLookup"`
-}
-
-/*
- * Client workspace capabilities specific to inline values.
- *
- * @since 3.17.0
- */
-type InlineValueWorkspaceClientCapabilities struct { // line 11105
-	/*
-	 * Whether the client implementation supports a refresh request sent from the
-	 * server to the client.
-	 *
-	 * Note that this event is global and will force the client to refresh all
-	 * inline values currently shown. It should be used with absolute care and is
-	 * useful for situation where a server for example detects a project wide
-	 * change that requires such a calculation.
-	 */
-	RefreshSupport bool `json:"refreshSupport,omitempty"`
-}
-
-/*
- * A special text edit to provide an insert and a replace operation.
- *
- * @since 3.16.0
- */
-type InsertReplaceEdit struct { // line 8696
-	// The string to be inserted.
-	NewText string `json:"newText"`
-	// The range if the insert is requested
-	Insert Range `json:"insert"`
-	// The range if the replace is requested.
-	Replace Range `json:"replace"`
-}
-type InsertTextFormat uint32 // line 13286
-type InsertTextMode uint32   // line 13306
-/*
- * The LSP any type.
- * Please note that strictly speaking a property with the value `undefined`
- * can't be converted into JSON preserving the property name. However for
- * convenience it is allowed and assumed that all these properties are
- * optional as well.
- * @since 3.17.0
- */
-type LSPAny = interface{} // (alias) line 13817
-/*
- * LSP arrays.
- * @since 3.17.0
- */
-type LSPArray = []interface{} // (alias) line 13805
-type LSPErrorCodes int32      // line 12809
-/*
- * LSP object definition.
- * @since 3.17.0
- */
-type LSPObject struct { // line 9618
-}
-
-/*
- * Client capabilities for the linked editing range request.
- *
- * @since 3.16.0
- */
-type LinkedEditingRangeClientCapabilities struct { // line 12331
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `(TextDocumentRegistrationOptions & StaticRegistrationOptions)`
-	 * return value for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-type LinkedEditingRangeOptions struct { // line 6657
-	WorkDoneProgressOptions
-}
-type LinkedEditingRangeParams struct { // line 3134
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-}
-type LinkedEditingRangeRegistrationOptions struct { // line 3177
-	TextDocumentRegistrationOptions
-	LinkedEditingRangeOptions
-	StaticRegistrationOptions
-}
-
-/*
- * The result of a linked editing range request.
- *
- * @since 3.16.0
- */
-type LinkedEditingRanges struct { // line 3150
-	/*
-	 * A list of ranges that can be edited together. The ranges must have
-	 * identical length and contain identical text content. The ranges cannot overlap.
-	 */
-	Ranges []Range `json:"ranges"`
-	/*
-	 * An optional word pattern (regular expression) that describes valid contents for
-	 * the given ranges. If no pattern is provided, the client configuration's word
-	 * pattern will be used.
-	 */
-	WordPattern string `json:"wordPattern,omitempty"`
-}
-
-/*
- * Represents a location inside a resource, such as a line
- * inside a text file.
- */
-type Location struct { // line 2091
-	URI   DocumentURI `json:"uri"`
-	Range Range       `json:"range"`
-}
-
-/*
- * Represents the connection of two locations. Provides additional metadata over normal [locations](#Location),
- * including an origin range.
- */
-type LocationLink struct { // line 6277
-	/*
-	 * Span of the origin of this link.
-	 *
-	 * Used as the underlined span for mouse interaction. Defaults to the word range at
-	 * the definition position.
-	 */
-	OriginSelectionRange *Range `json:"originSelectionRange,omitempty"`
-	// The target resource identifier of this link.
-	TargetURI DocumentURI `json:"targetUri"`
-	/*
-	 * The full target range of this link. If the target for example is a symbol then target range is the
-	 * range enclosing this symbol not including leading/trailing whitespace but everything else
-	 * like comments. This information is typically used to highlight the range in the editor.
-	 */
-	TargetRange Range `json:"targetRange"`
-	/*
-	 * The range that should be selected and revealed when this link is being followed, e.g the name of a function.
-	 * Must be contained by the `targetRange`. See also `DocumentSymbol#range`
-	 */
-	TargetSelectionRange Range `json:"targetSelectionRange"`
-}
-
-// The log message parameters.
-type LogMessageParams struct { // line 4273
-	// The message type. See {@link MessageType}
-	Type MessageType `json:"type"`
-	// The actual message.
-	Message string `json:"message"`
-}
-type LogTraceParams struct { // line 6178
-	Message string `json:"message"`
-	Verbose string `json:"verbose,omitempty"`
-}
-
-/*
- * Client capabilities specific to the used markdown parser.
- *
- * @since 3.16.0
- */
-type MarkdownClientCapabilities struct { // line 12550
-	// The name of the parser.
-	Parser string `json:"parser"`
-	// The version of the parser.
-	Version string `json:"version,omitempty"`
-	/*
-	 * A list of HTML tags that the client allows / supports in
-	 * Markdown.
-	 *
-	 * @since 3.17.0
-	 */
-	AllowedTags []string `json:"allowedTags,omitempty"`
-}
-
-/*
- * MarkedString can be used to render human readable text. It is either a markdown string
- * or a code-block that provides a language and a code snippet. The language identifier
- * is semantically equal to the optional language identifier in fenced code blocks in GitHub
- * issues. See https://help.github.com/articles/creating-and-highlighting-code-blocks/#syntax-highlighting
- *
- * The pair of a language and a value is an equivalent to markdown:
- * ```${language}
- * ${value}
- * ```
- *
- * Note that markdown strings will be sanitized - that means html will be escaped.
- * @deprecated use MarkupContent instead.
- */
-type MarkedString = Or_MarkedString // (alias) line 14084
-/*
- * A `MarkupContent` literal represents a string value which content is interpreted base on its
- * kind flag. Currently the protocol supports `plaintext` and `markdown` as markup kinds.
- *
- * If the kind is `markdown` then the value can contain fenced code blocks like in GitHub issues.
- * See https://help.github.com/articles/creating-and-highlighting-code-blocks/#syntax-highlighting
- *
- * Here is an example how such a string can be constructed using JavaScript / TypeScript:
- * ```ts
- * let markdown: MarkdownContent = {
- *  kind: MarkupKind.Markdown,
- *  value: [
- *    '# Header',
- *    'Some text',
- *    '```typescript',
- *    'someCode();',
- *    '```'
- *  ].join('\
- * ')
- * };
- * ```
- *
- * *Please Note* that clients might sanitize the return markdown. A client could decide to
- * remove HTML from the markdown to avoid script execution.
- */
-type MarkupContent struct { // line 7118
-	// The type of the Markup
-	Kind MarkupKind `json:"kind"`
-	// The content itself
-	Value string `json:"value"`
-}
-type MarkupKind string          // line 13433
-type MessageActionItem struct { // line 4260
-	// A short title like 'Retry', 'Open Log' etc.
-	Title string `json:"title"`
-}
-type MessageType uint32 // line 13080
-/*
- * Moniker definition to match LSIF 0.5 moniker definition.
- *
- * @since 3.16.0
- */
-type Moniker struct { // line 3360
-	// The scheme of the moniker. For example tsc or .Net
-	Scheme string `json:"scheme"`
-	/*
-	 * The identifier of the moniker. The value is opaque in LSIF however
-	 * schema owners are allowed to define the structure if they want.
-	 */
-	Identifier string `json:"identifier"`
-	// The scope in which the moniker is unique
-	Unique UniquenessLevel `json:"unique"`
-	// The moniker kind if known.
-	Kind MonikerKind `json:"kind,omitempty"`
-}
-
-/*
- * Client capabilities specific to the moniker request.
- *
- * @since 3.16.0
- */
-type MonikerClientCapabilities struct { // line 12347
-	/*
-	 * Whether moniker supports dynamic registration. If this is set to `true`
-	 * the client supports the new `MonikerRegistrationOptions` return value
-	 * for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-type MonikerKind string      // line 13033
-type MonikerOptions struct { // line 6931
-	WorkDoneProgressOptions
-}
-type MonikerParams struct { // line 3340
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type MonikerRegistrationOptions struct { // line 3400
-	TextDocumentRegistrationOptions
-	MonikerOptions
-}
-
-// created for Literal
-type Msg_MarkedString struct { // line 14093
-	Language string `json:"language"`
-	Value    string `json:"value"`
-}
-
-// created for Literal
-type Msg_NotebookDocumentFilter struct { // line 14268
-	// The type of the enclosing notebook.
-	NotebookType string `json:"notebookType"`
-	// A Uri [scheme](#Uri.scheme), like `file` or `untitled`.
-	Scheme string `json:"scheme"`
-	// A glob pattern.
-	Pattern string `json:"pattern"`
-}
-
-// created for Literal
-type Msg_PrepareRename2Gn struct { // line 13936
-	Range       Range  `json:"range"`
-	Placeholder string `json:"placeholder"`
-}
-
-// created for Literal
-type Msg_TextDocumentContentChangeEvent struct { // line 14033
-	// The range of the document that changed.
-	Range *Range `json:"range"`
-	/*
-	 * The optional length of the range that got replaced.
-	 *
-	 * @deprecated use range instead.
-	 */
-	RangeLength uint32 `json:"rangeLength"`
-	// The new text for the provided range.
-	Text string `json:"text"`
-}
-
-// created for Literal
-type Msg_TextDocumentFilter struct { // line 14159
-	// A language id, like `typescript`.
-	Language string `json:"language"`
-	// A Uri [scheme](#Uri.scheme), like `file` or `untitled`.
-	Scheme string `json:"scheme"`
-	// A glob pattern, like `*.{ts,js}`.
-	Pattern string `json:"pattern"`
-}
-
-// created for Literal
-type Msg_XInitializeParams_clientInfo struct { // line 7678
-	// The name of the client as defined by the client.
-	Name string `json:"name"`
-	// The client's version as defined by the client.
-	Version string `json:"version"`
-}
-
-/*
- * A notebook cell.
- *
- * A cell's document URI must be unique across ALL notebook
- * cells and can therefore be used to uniquely identify a
- * notebook cell or the cell's text document.
- *
- * @since 3.17.0
- */
-type NotebookCell struct { // line 9624
-	// The cell's kind
-	Kind NotebookCellKind `json:"kind"`
-	/*
-	 * The URI of the cell's text document
-	 * content.
-	 */
-	Document DocumentURI `json:"document"`
-	/*
-	 * Additional metadata stored with the cell.
-	 *
-	 * Note: should always be an object literal (e.g. LSPObject)
-	 */
-	Metadata *LSPObject `json:"metadata,omitempty"`
-	/*
-	 * Additional execution summary information
-	 * if supported by the client.
-	 */
-	ExecutionSummary *ExecutionSummary `json:"executionSummary,omitempty"`
-}
-
-/*
- * A change describing how to move a `NotebookCell`
- * array from state S to S'.
- *
- * @since 3.17.0
- */
-type NotebookCellArrayChange struct { // line 9665
-	// The start oftest of the cell that changed.
-	Start uint32 `json:"start"`
-	// The deleted cells
-	DeleteCount uint32 `json:"deleteCount"`
-	// The new cells, if any
-	Cells []NotebookCell `json:"cells,omitempty"`
-}
-type NotebookCellKind uint32 // line 13674
-/*
- * A notebook cell text document filter denotes a cell text
- * document by different properties.
- *
- * @since 3.17.0
- */
-type NotebookCellTextDocumentFilter struct { // line 10139
-	/*
-	 * A filter that matches against the notebook
-	 * containing the notebook cell. If a string
-	 * value is provided it matches against the
-	 * notebook type. '*' matches every notebook.
-	 */
-	Notebook NotebookDocumentFilter `json:"notebook"`
-	/*
-	 * A language id like `python`.
-	 *
-	 * Will be matched against the language id of the
-	 * notebook cell document. '*' matches every language.
-	 */
-	Language string `json:"language,omitempty"`
-}
-
-/*
- * A notebook document.
- *
- * @since 3.17.0
- */
-type NotebookDocument struct { // line 7359
-	// The notebook document's uri.
-	URI URI `json:"uri"`
-	// The type of the notebook.
-	NotebookType string `json:"notebookType"`
-	/*
-	 * The version number of this document (it will increase after each
-	 * change, including undo/redo).
-	 */
-	Version int32 `json:"version"`
-	/*
-	 * Additional metadata stored with the notebook
-	 * document.
-	 *
-	 * Note: should always be an object literal (e.g. LSPObject)
-	 */
-	Metadata *LSPObject `json:"metadata,omitempty"`
-	// The cells of a notebook.
-	Cells []NotebookCell `json:"cells"`
-}
-
-/*
- * A change event for a notebook document.
- *
- * @since 3.17.0
- */
-type NotebookDocumentChangeEvent struct { // line 7471
-	/*
-	 * The changed meta data if any.
-	 *
-	 * Note: should always be an object literal (e.g. LSPObject)
-	 */
-	Metadata *LSPObject `json:"metadata,omitempty"`
-	// Changes to cells
-	Cells *PCellsPChange `json:"cells,omitempty"`
-}
-
-/*
- * Capabilities specific to the notebook document support.
- *
- * @since 3.17.0
- */
-type NotebookDocumentClientCapabilities struct { // line 10639
-	/*
-	 * Capabilities specific to notebook document synchronization
-	 *
-	 * @since 3.17.0
-	 */
-	Synchronization NotebookDocumentSyncClientCapabilities `json:"synchronization"`
-}
-
-/*
- * A notebook document filter denotes a notebook document by
- * different properties. The properties will be match
- * against the notebook's URI (same as with documents)
- *
- * @since 3.17.0
- */
-type NotebookDocumentFilter = Msg_NotebookDocumentFilter // (alias) line 14263
-/*
- * A literal to identify a notebook document in the client.
- *
- * @since 3.17.0
- */
-type NotebookDocumentIdentifier struct { // line 7587
-	// The notebook document's uri.
-	URI URI `json:"uri"`
-}
-
-/*
- * Notebook specific client capabilities.
- *
- * @since 3.17.0
- */
-type NotebookDocumentSyncClientCapabilities struct { // line 12459
-	/*
-	 * Whether implementation supports dynamic registration. If this is
-	 * set to `true` the client supports the new
-	 * `(TextDocumentRegistrationOptions & StaticRegistrationOptions)`
-	 * return value for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	// The client supports sending execution summary data per cell.
-	ExecutionSummarySupport bool `json:"executionSummarySupport,omitempty"`
-}
-
-/*
- * Options specific to a notebook plus its cells
- * to be synced to the server.
- *
- * If a selector provides a notebook document
- * filter but no cell selector all cells of a
- * matching notebook document will be synced.
- *
- * If a selector provides no notebook document
- * filter but only a cell selector all notebook
- * document that contain at least one matching
- * cell will be synced.
- *
- * @since 3.17.0
- */
-type NotebookDocumentSyncOptions struct { // line 9821
-	// The notebooks to be synced
-	NotebookSelector []PNotebookSelectorPNotebookDocumentSync `json:"notebookSelector"`
-	/*
-	 * Whether save notification should be forwarded to
-	 * the server. Will only be honored if mode === `notebook`.
-	 */
-	Save bool `json:"save,omitempty"`
-}
-
-/*
- * Registration options specific to a notebook.
- *
- * @since 3.17.0
- */
-type NotebookDocumentSyncRegistrationOptions struct { // line 9941
-	NotebookDocumentSyncOptions
-	StaticRegistrationOptions
-}
-
-// A text document identifier to optionally denote a specific version of a text document.
-type OptionalVersionedTextDocumentIdentifier struct { // line 9363
-	/*
-	 * The version number of this document. If a versioned text document identifier
-	 * is sent from the server to the client and the file is not open in the editor
-	 * (the server has not received an open notification before) the server can send
-	 * `null` to indicate that the version is unknown and the content on disk is the
-	 * truth (as specified with document content ownership).
-	 */
-	Version int32 `json:"version"`
-	TextDocumentIdentifier
-}
-
-// created for Or [Range FEditRangePItemDefaults]
-type OrFEditRangePItemDefaults struct { // line 4791
-	Value interface{} `json:"value"`
-}
-
-// created for Or [string NotebookDocumentFilter]
-type OrFNotebookPNotebookSelector struct { // line 9838
-	Value interface{} `json:"value"`
-}
-
-// created for Or [Location PLocationMsg_workspace_symbol]
-type OrPLocation_workspace_symbol struct { // line 5540
-	Value interface{} `json:"value"`
-}
-
-// created for Or [string []string]
-type OrPSection_workspace_didChangeConfiguration struct { // line 4186
-	Value interface{} `json:"value"`
-}
-
-// created for Or [string MarkupContent]
-type OrPTooltipPLabel struct { // line 7081
-	Value interface{} `json:"value"`
-}
-
-// created for Or [string MarkupContent]
-type OrPTooltip_textDocument_inlayHint struct { // line 3722
-	Value interface{} `json:"value"`
-}
-
-// created for Or [Location []Location]
-type Or_Definition struct { // line 13780
-	Value interface{} `json:"value"`
-}
-
-// created for Or [RelatedFullDocumentDiagnosticReport RelatedUnchangedDocumentDiagnosticReport]
-type Or_DocumentDiagnosticReport struct { // line 13912
-	Value interface{} `json:"value"`
-}
-
-// created for Or [TextDocumentFilter NotebookCellTextDocumentFilter]
-type Or_DocumentFilter struct { // line 14121
-	Value interface{} `json:"value"`
-}
-
-// created for Or [InlineValueText InlineValueVariableLookup InlineValueEvaluatableExpression]
-type Or_InlineValue struct { // line 13890
-	Value interface{} `json:"value"`
-}
-
-// created for Or [string Msg_MarkedString]
-type Or_MarkedString struct { // line 14087
-	Value interface{} `json:"value"`
-}
-
-// created for Or [WorkspaceFolder URI]
-type Or_RelativePattern_baseUri struct { // line 10768
-	Value interface{} `json:"value"`
-}
-
-// created for Or [WorkspaceFullDocumentDiagnosticReport WorkspaceUnchangedDocumentDiagnosticReport]
-type Or_WorkspaceDocumentDiagnosticReport struct { // line 14013
-	Value interface{} `json:"value"`
-}
-
-// created for Or [Declaration []DeclarationLink ]
-type Or_textDocument_declaration struct { // line 257
-	Value interface{} `json:"value"`
-}
-
-// created for Literal
-type PCellsPChange struct { // line 7486
-	/*
-	 * Changes to the cell structure to add or
-	 * remove cells.
-	 */
-	Structure FStructurePCells `json:"structure"`
-	/*
-	 * Changes to notebook cells properties like its
-	 * kind, execution summary or metadata.
-	 */
-	Data []NotebookCell `json:"data"`
-	// Changes to the text content of notebook cells.
-	TextContent []FTextContentPCells `json:"textContent"`
-}
-
-// created for Literal
-type PChangeAnnotationSupportPWorkspaceEdit struct { // line 10842
-	/*
-	 * Whether the client groups edits with equal labels into tree nodes,
-	 * for instance all edits labelled with \"Changes in Strings\" would
-	 * be a tree node.
-	 */
-	GroupsOnLabel bool `json:"groupsOnLabel"`
-}
-
-// created for Literal
-type PCodeActionLiteralSupportPCodeAction struct { // line 11762
-	/*
-	 * The code action kind is support with the following value
-	 * set.
-	 */
-	CodeActionKind FCodeActionKindPCodeActionLiteralSupport `json:"codeActionKind"`
-}
-
-// created for Literal
-type PCompletionItemKindPCompletion struct { // line 11360
-	/*
-	 * The completion item kind values the client supports. When this
-	 * property exists the client also guarantees that it will
-	 * handle values outside its set gracefully and falls back
-	 * to a default value when unknown.
-	 *
-	 * If this property is not present the client only supports
-	 * the completion items kinds from `Text` to `Reference` as defined in
-	 * the initial version of the protocol.
-	 */
-	ValueSet []CompletionItemKind `json:"valueSet"`
-}
-
-// created for Literal
-type PCompletionItemPCompletion struct { // line 11209
-	/*
-	 * Client supports snippets as insert text.
-	 *
-	 * A snippet can define tab stops and placeholders with `$1`, `$2`
-	 * and `${3:foo}`. `$0` defines the final tab stop, it defaults to
-	 * the end of the snippet. Placeholders with equal identifiers are linked,
-	 * that is typing in one will update others too.
-	 */
-	SnippetSupport bool `json:"snippetSupport"`
-	// Client supports commit characters on a completion item.
-	CommitCharactersSupport bool `json:"commitCharactersSupport"`
-	/*
-	 * Client supports the following content formats for the documentation
-	 * property. The order describes the preferred format of the client.
-	 */
-	DocumentationFormat []MarkupKind `json:"documentationFormat"`
-	// Client supports the deprecated property on a completion item.
-	DeprecatedSupport bool `json:"deprecatedSupport"`
-	// Client supports the preselect property on a completion item.
-	PreselectSupport bool `json:"preselectSupport"`
-	/*
-	 * Client supports the tag property on a completion item. Clients supporting
-	 * tags have to handle unknown tags gracefully. Clients especially need to
-	 * preserve unknown tags when sending a completion item back to the server in
-	 * a resolve call.
-	 *
-	 * @since 3.15.0
-	 */
-	TagSupport FTagSupportPCompletionItem `json:"tagSupport"`
-	/*
-	 * Client support insert replace edit to control different behavior if a
-	 * completion item is inserted in the text or should replace text.
-	 *
-	 * @since 3.16.0
-	 */
-	InsertReplaceSupport bool `json:"insertReplaceSupport"`
-	/*
-	 * Indicates which properties a client can resolve lazily on a completion
-	 * item. Before version 3.16.0 only the predefined properties `documentation`
-	 * and `details` could be resolved lazily.
-	 *
-	 * @since 3.16.0
-	 */
-	ResolveSupport FResolveSupportPCompletionItem `json:"resolveSupport"`
-	/*
-	 * The client supports the `insertTextMode` property on
-	 * a completion item to override the whitespace handling mode
-	 * as defined by the client (see `insertTextMode`).
-	 *
-	 * @since 3.16.0
-	 */
-	InsertTextModeSupport FInsertTextModeSupportPCompletionItem `json:"insertTextModeSupport"`
-	/*
-	 * The client has support for completion item label
-	 * details (see also `CompletionItemLabelDetails`).
-	 *
-	 * @since 3.17.0
-	 */
-	LabelDetailsSupport bool `json:"labelDetailsSupport"`
-}
-
-// created for Literal
-type PCompletionItemPCompletionProvider struct { // line 8767
-	/*
-	 * The server has support for completion item label
-	 * details (see also `CompletionItemLabelDetails`) when
-	 * receiving a completion item in a resolve call.
-	 *
-	 * @since 3.17.0
-	 */
-	LabelDetailsSupport bool `json:"labelDetailsSupport"`
-}
-
-// created for Literal
-type PCompletionListPCompletion struct { // line 11402
-	/*
-	 * The client supports the following itemDefaults on
-	 * a completion list.
-	 *
-	 * The value lists the supported property names of the
-	 * `CompletionList.itemDefaults` object. If omitted
-	 * no properties are supported.
-	 *
-	 * @since 3.17.0
-	 */
-	ItemDefaults []string `json:"itemDefaults"`
-}
-
-// created for Literal
-type PDisabledMsg_textDocument_codeAction struct { // line 5446
-	/*
-	 * Human readable description of why the code action is currently disabled.
-	 *
-	 * This is displayed in the code actions UI.
-	 */
-	Reason string `json:"reason"`
-}
-
-// created for Literal
-type PFoldingRangeKindPFoldingRange struct { // line 12037
-	/*
-	 * The folding range kind values the client supports. When this
-	 * property exists the client also guarantees that it will
-	 * handle values outside its set gracefully and falls back
-	 * to a default value when unknown.
-	 */
-	ValueSet []FoldingRangeKind `json:"valueSet"`
-}
-
-// created for Literal
-type PFoldingRangePFoldingRange struct { // line 12062
-	/*
-	 * If set, the client signals that it supports setting collapsedText on
-	 * folding ranges to display custom labels instead of the default text.
-	 *
-	 * @since 3.17.0
-	 */
-	CollapsedText bool `json:"collapsedText"`
-}
-
-// created for Literal
-type PFullESemanticTokensOptions struct { // line 6591
-	// The server supports deltas for full documents.
-	Delta bool `json:"delta"`
-}
-
-// created for Literal
-type PItemDefaultsMsg_textDocument_completion struct { // line 4772
-	/*
-	 * A default commit character set.
-	 *
-	 * @since 3.17.0
-	 */
-	CommitCharacters []string `json:"commitCharacters"`
-	/*
-	 * A default edit range.
-	 *
-	 * @since 3.17.0
-	 */
-	EditRange OrFEditRangePItemDefaults `json:"editRange"`
-	/*
-	 * A default insert text format.
-	 *
-	 * @since 3.17.0
-	 */
-	InsertTextFormat InsertTextFormat `json:"insertTextFormat"`
-	/*
-	 * A default insert text mode.
-	 *
-	 * @since 3.17.0
-	 */
-	InsertTextMode InsertTextMode `json:"insertTextMode"`
-	/*
-	 * A default data value.
-	 *
-	 * @since 3.17.0
-	 */
-	Data interface{} `json:"data"`
-}
-
-// created for Literal
-type PLocationMsg_workspace_symbol struct { // line 5546
-	URI DocumentURI `json:"uri"`
-}
-
-// created for Literal
-type PMessageActionItemPShowMessage struct { // line 12490
-	/*
-	 * Whether the client supports additional attributes which
-	 * are preserved and send back to the server in the
-	 * request's response.
-	 */
-	AdditionalPropertiesSupport bool `json:"additionalPropertiesSupport"`
-}
-
-// created for Literal
-type PNotebookSelectorPNotebookDocumentSync struct { // line 9831
-	/*
-	 * The notebook to be synced If a string
-	 * value is provided it matches against the
-	 * notebook type. '*' matches every notebook.
-	 */
-	Notebook OrFNotebookPNotebookSelector `json:"notebook"`
-	// The cells of the matching notebook to be synced.
-	Cells []FCellsPNotebookSelector `json:"cells"`
-}
-
-// created for Literal
-type PRangeESemanticTokensOptions struct { // line 6571
-}
-
-// created for Literal
-type PRequestsPSemanticTokens struct { // line 12198
-	/*
-	 * The client will send the `textDocument/semanticTokens/range` request if
-	 * the server provides a corresponding handler.
-	 */
-	Range bool `json:"range"`
-	/*
-	 * The client will send the `textDocument/semanticTokens/full` request if
-	 * the server provides a corresponding handler.
-	 */
-	Full interface{} `json:"full"`
-}
-
-// created for Literal
-type PResolveSupportPCodeAction struct { // line 11827
-	// The properties that a client can resolve lazily.
-	Properties []string `json:"properties"`
-}
-
-// created for Literal
-type PResolveSupportPInlayHint struct { // line 12410
-	// The properties that a client can resolve lazily.
-	Properties []string `json:"properties"`
-}
-
-// created for Literal
-type PResolveSupportPSymbol struct { // line 10964
-	/*
-	 * The properties that a client can resolve lazily. Usually
-	 * `location.range`
-	 */
-	Properties []string `json:"properties"`
-}
-
-// created for Literal
-type PServerInfoMsg_initialize struct { // line 4118
-	// The name of the server as defined by the server.
-	Name string `json:"name"`
-	// The server's version as defined by the server.
-	Version string `json:"version"`
-}
-
-// created for Literal
-type PSignatureInformationPSignatureHelp struct { // line 11469
-	/*
-	 * Client supports the following content formats for the documentation
-	 * property. The order describes the preferred format of the client.
-	 */
-	DocumentationFormat []MarkupKind `json:"documentationFormat"`
-	// Client capabilities specific to parameter information.
-	ParameterInformation FParameterInformationPSignatureInformation `json:"parameterInformation"`
-	/*
-	 * The client supports the `activeParameter` property on `SignatureInformation`
-	 * literal.
-	 *
-	 * @since 3.16.0
-	 */
-	ActiveParameterSupport bool `json:"activeParameterSupport"`
-}
-
-// created for Literal
-type PStaleRequestSupportPGeneral struct { // line 10696
-	// The client will actively cancel the request.
-	Cancel bool `json:"cancel"`
-	/*
-	 * The list of requests for which the client
-	 * will retry the request if it receives a
-	 * response with error code `ContentModified`
-	 */
-	RetryOnContentModified []string `json:"retryOnContentModified"`
-}
-
-// created for Literal
-type PSymbolKindPDocumentSymbol struct { // line 11680
-	/*
-	 * The symbol kind values the client supports. When this
-	 * property exists the client also guarantees that it will
-	 * handle values outside its set gracefully and falls back
-	 * to a default value when unknown.
-	 *
-	 * If this property is not present the client only supports
-	 * the symbol kinds from `File` to `Array` as defined in
-	 * the initial version of the protocol.
-	 */
-	ValueSet []SymbolKind `json:"valueSet"`
-}
-
-// created for Literal
-type PSymbolKindPSymbol struct { // line 10916
-	/*
-	 * The symbol kind values the client supports. When this
-	 * property exists the client also guarantees that it will
-	 * handle values outside its set gracefully and falls back
-	 * to a default value when unknown.
-	 *
-	 * If this property is not present the client only supports
-	 * the symbol kinds from `File` to `Array` as defined in
-	 * the initial version of the protocol.
-	 */
-	ValueSet []SymbolKind `json:"valueSet"`
-}
-
-// created for Literal
-type PTagSupportPDocumentSymbol struct { // line 11713
-	// The tags supported by the client.
-	ValueSet []SymbolTag `json:"valueSet"`
-}
-
-// created for Literal
-type PTagSupportPPublishDiagnostics struct { // line 12113
-	// The tags supported by the client.
-	ValueSet []DiagnosticTag `json:"valueSet"`
-}
-
-// created for Literal
-type PTagSupportPSymbol struct { // line 10940
-	// The tags supported by the client.
-	ValueSet []SymbolTag `json:"valueSet"`
-}
-
-// The parameters of a configuration request.
-type ParamConfiguration struct { // line 2207
-	Items []ConfigurationItem `json:"items"`
-}
-type ParamInitialize struct { // line 4090
-	XInitializeParams
-	WorkspaceFoldersInitializeParams
-}
-
-/*
- * Represents a parameter of a callable-signature. A parameter can
- * have a label and a doc-comment.
- */
-type ParameterInformation struct { // line 10089
-	/*
-	 * The label of this parameter information.
-	 *
-	 * Either a string or an inclusive start and exclusive end offsets within its containing
-	 * signature label. (see SignatureInformation.label). The offsets are based on a UTF-16
-	 * string representation as `Position` and `Range` does.
-	 *
-	 * *Note*: a label of type string should be a substring of its containing signature label.
-	 * Its intended use case is to highlight the parameter label part in the `SignatureInformation.label`.
-	 */
-	Label string `json:"label"`
-	/*
-	 * The human-readable doc-comment of this parameter. Will be shown
-	 * in the UI but can be omitted.
-	 */
-	Documentation string `json:"documentation,omitempty"`
-}
-type PartialResultParams struct { // line 2223
-	/*
-	 * An optional token that a server can use to report partial results (e.g. streaming) to
-	 * the client.
-	 */
-	PartialResultToken ProgressToken `json:"partialResultToken,omitempty"`
-}
-
-/*
- * The glob pattern to watch relative to the base path. Glob patterns can have the following syntax:
- * - `*` to match one or more characters in a path segment
- * - `?` to match on one character in a path segment
- * - `**` to match any number of path segments, including none
- * - `{}` to group conditions (e.g. `**​/*.{ts,js}` matches all TypeScript and JavaScript files)
- * - `[]` to declare a range of characters to match in a path segment (e.g., `example.[0-9]` to match on `example.0`, `example.1`, …)
- * - `[!...]` to negate a range of characters to match in a path segment (e.g., `example.[!0-9]` to match on `example.a`, `example.b`, but not `example.0`)
- *
- * @since 3.17.0
- */
-type Pattern = string // (alias) line 14372
-/*
- * Position in a text document expressed as zero-based line and character
- * offset. Prior to 3.17 the offsets were always based on a UTF-16 string
- * representation. So a string of the form `a𐐀b` the character offset of the
- * character `a` is 0, the character offset of `𐐀` is 1 and the character
- * offset of b is 3 since `𐐀` is represented using two code units in UTF-16.
- * Since 3.17 clients and servers can agree on a different string encoding
- * representation (e.g. UTF-8). The client announces it's supported encoding
- * via the client capability [`general.positionEncodings`](#clientCapabilities).
- * The value is an array of position encodings the client supports, with
- * decreasing preference (e.g. the encoding at index `0` is the most preferred
- * one). To stay backwards compatible the only mandatory encoding is UTF-16
- * represented via the string `utf-16`. The server can pick one of the
- * encodings offered by the client and signals that encoding back to the
- * client via the initialize result's property
- * [`capabilities.positionEncoding`](#serverCapabilities). If the string value
- * `utf-16` is missing from the client's capability `general.positionEncodings`
- * servers can safely assume that the client supports UTF-16. If the server
- * omits the position encoding in its initialize result the encoding defaults
- * to the string value `utf-16`. Implementation considerations: since the
- * conversion from one encoding into another requires the content of the
- * file / line the conversion is best done where the file is read which is
- * usually on the server side.
- *
- * Positions are line end character agnostic. So you can not specify a position
- * that denotes `\\r|\
- * ` or `\
- * |` where `|` represents the character offset.
- *
- * @since 3.17.0 - support for negotiated position encoding.
- */
-type Position struct { // line 6506
-	/*
-	 * Line position in a document (zero-based).
-	 *
-	 * If a line number is greater than the number of lines in a document, it defaults back to the number of lines in the document.
-	 * If a line number is negative, it defaults to 0.
-	 */
-	Line uint32 `json:"line"`
-	/*
-	 * Character offset on a line in a document (zero-based).
-	 *
-	 * The meaning of this offset is determined by the negotiated
-	 * `PositionEncodingKind`.
-	 *
-	 * If the character value is greater than the line length it defaults back to the
-	 * line length.
-	 */
-	Character uint32 `json:"character"`
-}
-type PositionEncodingKind string             // line 13453
-type PrepareRename2Gn = Msg_PrepareRename2Gn // (alias) line 13927
-type PrepareRenameParams struct {            // line 5944
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-}
-type PrepareRenameResult = Msg_PrepareRename2Gn // (alias) line 13927
-type PrepareSupportDefaultBehavior interface{}  // line 13748
-/*
- * A previous result id in a workspace pull request.
- *
- * @since 3.17.0
- */
-type PreviousResultID struct { // line 7336
-	/*
-	 * The URI for which the client knowns a
-	 * result id.
-	 */
-	URI DocumentURI `json:"uri"`
-	// The value of the previous result id.
-	Value string `json:"value"`
-}
-
-/*
- * A previous result id in a workspace pull request.
- *
- * @since 3.17.0
- */
-type PreviousResultId struct { // line 7336
-	/*
-	 * The URI for which the client knowns a
-	 * result id.
-	 */
-	URI DocumentURI `json:"uri"`
-	// The value of the previous result id.
-	Value string `json:"value"`
-}
-type ProgressParams struct { // line 6220
-	// The progress token provided by the client or server.
-	Token ProgressToken `json:"token"`
-	// The progress data.
-	Value interface{} `json:"value"`
-}
-type ProgressToken = interface{} // (alias) line 13974
-// The publish diagnostic client capabilities.
-type PublishDiagnosticsClientCapabilities struct { // line 12098
-	// Whether the clients accepts diagnostics with related information.
-	RelatedInformation bool `json:"relatedInformation,omitempty"`
-	/*
-	 * Client supports the tag property to provide meta data about a diagnostic.
-	 * Clients supporting tags have to handle unknown tags gracefully.
-	 *
-	 * @since 3.15.0
-	 */
-	TagSupport *PTagSupportPPublishDiagnostics `json:"tagSupport,omitempty"`
-	/*
-	 * Whether the client interprets the version property of the
-	 * `textDocument/publishDiagnostics` notification's parameter.
-	 *
-	 * @since 3.15.0
-	 */
-	VersionSupport bool `json:"versionSupport,omitempty"`
-	/*
-	 * Client supports a codeDescription property
-	 *
-	 * @since 3.16.0
-	 */
-	CodeDescriptionSupport bool `json:"codeDescriptionSupport,omitempty"`
-	/*
-	 * Whether code action supports the `data` property which is
-	 * preserved between a `textDocument/publishDiagnostics` and
-	 * `textDocument/codeAction` request.
-	 *
-	 * @since 3.16.0
-	 */
-	DataSupport bool `json:"dataSupport,omitempty"`
-}
-
-// The publish diagnostic notification's parameters.
-type PublishDiagnosticsParams struct { // line 4484
-	// The URI for which diagnostic information is reported.
-	URI DocumentURI `json:"uri"`
-	/*
-	 * Optional the version number of the document the diagnostics are published for.
-	 *
-	 * @since 3.15.0
-	 */
-	Version int32 `json:"version,omitempty"`
-	// An array of diagnostic information items.
-	Diagnostics []Diagnostic `json:"diagnostics"`
-}
-
-/*
- * A range in a text document expressed as (zero-based) start and end positions.
- *
- * If you want to specify a range that contains a line including the line ending
- * character(s) then use an end position denoting the start of the next line.
- * For example:
- * ```ts
- * {
- *     start: { line: 5, character: 23 }
- *     end : { line 6, character : 0 }
- * }
- * ```
- */
-type Range struct { // line 6316
-	// The range's start position.
-	Start Position `json:"start"`
-	// The range's end position.
-	End Position `json:"end"`
-}
-
-// Client Capabilities for a [ReferencesRequest](#ReferencesRequest).
-type ReferenceClientCapabilities struct { // line 11635
-	// Whether references supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-/*
- * Value-object that contains additional information when
- * requesting references.
- */
-type ReferenceContext struct { // line 8950
-	// Include the declaration of the current symbol.
-	IncludeDeclaration bool `json:"includeDeclaration"`
-}
-
-// Reference options.
-type ReferenceOptions struct { // line 8964
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [ReferencesRequest](#ReferencesRequest).
-type ReferenceParams struct { // line 5075
-	Context ReferenceContext `json:"context"`
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [ReferencesRequest](#ReferencesRequest).
-type ReferenceRegistrationOptions struct { // line 5104
-	TextDocumentRegistrationOptions
-	ReferenceOptions
-}
-
-// General parameters to to register for an notification or to register a provider.
-type Registration struct { // line 7602
-	/*
-	 * The id used to register the request. The id can be used to deregister
-	 * the request again.
-	 */
-	ID string `json:"id"`
-	// The method / capability to register for.
-	Method string `json:"method"`
-	// Options necessary for the registration.
-	RegisterOptions interface{} `json:"registerOptions,omitempty"`
-}
-type RegistrationParams struct { // line 4060
-	Registrations []Registration `json:"registrations"`
-}
-
-/*
- * Client capabilities specific to regular expressions.
- *
- * @since 3.16.0
- */
-type RegularExpressionsClientCapabilities struct { // line 12526
-	// The engine's name.
-	Engine string `json:"engine"`
-	// The engine's version.
-	Version string `json:"version,omitempty"`
-}
-
-/*
- * A full diagnostic report with a set of related documents.
- *
- * @since 3.17.0
- */
-type RelatedFullDocumentDiagnosticReport struct { // line 7162
-	/*
-	 * Diagnostics of related documents. This information is useful
-	 * in programming languages where code in a file A can generate
-	 * diagnostics in a file B which A depends on. An example of
-	 * such a language is C/C++ where marco definitions in a file
-	 * a.cpp and result in errors in a header file b.hpp.
-	 *
-	 * @since 3.17.0
-	 */
-	RelatedDocuments map[DocumentURI]interface{} `json:"relatedDocuments,omitempty"`
-	FullDocumentDiagnosticReport
-}
-
-/*
- * An unchanged diagnostic report with a set of related documents.
- *
- * @since 3.17.0
- */
-type RelatedUnchangedDocumentDiagnosticReport struct { // line 7201
-	/*
-	 * Diagnostics of related documents. This information is useful
-	 * in programming languages where code in a file A can generate
-	 * diagnostics in a file B which A depends on. An example of
-	 * such a language is C/C++ where marco definitions in a file
-	 * a.cpp and result in errors in a header file b.hpp.
-	 *
-	 * @since 3.17.0
-	 */
-	RelatedDocuments map[DocumentURI]interface{} `json:"relatedDocuments,omitempty"`
-	UnchangedDocumentDiagnosticReport
-}
-
-/*
- * A relative pattern is a helper to construct glob patterns that are matched
- * relatively to a base URI. The common value for a `baseUri` is a workspace
- * folder root, but it can be another absolute URI as well.
- *
- * @since 3.17.0
- */
-type RelativePattern struct { // line 10762
-	/*
-	 * A workspace folder or a base URI to which this pattern will be matched
-	 * against relatively.
-	 */
-	BaseURI Or_RelativePattern_baseUri `json:"baseUri"`
-	// The actual glob pattern;
-	Pattern Pattern `json:"pattern"`
-}
-type RenameClientCapabilities struct { // line 11960
-	// Whether rename supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Client supports testing for validity of rename operations
-	 * before execution.
-	 *
-	 * @since 3.12.0
-	 */
-	PrepareSupport bool `json:"prepareSupport,omitempty"`
-	/*
-	 * Client supports the default behavior result.
-	 *
-	 * The value indicates the default behavior used by the
-	 * client.
-	 *
-	 * @since 3.16.0
-	 */
-	PrepareSupportDefaultBehavior interface{} `json:"prepareSupportDefaultBehavior,omitempty"`
-	/*
-	 * Whether the client honors the change annotations in
-	 * text edits and resource operations returned via the
-	 * rename request's workspace edit by for example presenting
-	 * the workspace edit in the user interface and asking
-	 * for confirmation.
-	 *
-	 * @since 3.16.0
-	 */
-	HonorsChangeAnnotations bool `json:"honorsChangeAnnotations,omitempty"`
-}
-
-// Rename file operation
-type RenameFile struct { // line 6754
-	// A rename
-	Kind string `json:"kind"`
-	// The old (existing) location.
-	OldURI DocumentURI `json:"oldUri"`
-	// The new location.
-	NewURI DocumentURI `json:"newUri"`
-	// Rename options.
-	Options *RenameFileOptions `json:"options,omitempty"`
-	ResourceOperation
-}
-
-// Rename file options
-type RenameFileOptions struct { // line 9461
-	// Overwrite target if existing. Overwrite wins over `ignoreIfExists`
-	Overwrite bool `json:"overwrite,omitempty"`
-	// Ignores if target exists.
-	IgnoreIfExists bool `json:"ignoreIfExists,omitempty"`
-}
-
-/*
- * The parameters sent in notifications/requests for user-initiated renames of
- * files.
- *
- * @since 3.16.0
- */
-type RenameFilesParams struct { // line 3304
-	/*
-	 * An array of all files/folders renamed in this operation. When a folder is renamed, only
-	 * the folder will be included, and not its children.
-	 */
-	Files []FileRename `json:"files"`
-}
-
-// Provider options for a [RenameRequest](#RenameRequest).
-type RenameOptions struct { // line 9289
-	/*
-	 * Renames should be checked and tested before being executed.
-	 *
-	 * @since version 3.12.0
-	 */
-	PrepareProvider bool `json:"prepareProvider,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [RenameRequest](#RenameRequest).
-type RenameParams struct { // line 5893
-	// The document to rename.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The position at which this request was sent.
-	Position Position `json:"position"`
-	/*
-	 * The new name of the symbol. If the given name is not valid the
-	 * request must return a [ResponseError](#ResponseError) with an
-	 * appropriate message set.
-	 */
-	NewName string `json:"newName"`
-	WorkDoneProgressParams
-}
-
-// Registration options for a [RenameRequest](#RenameRequest).
-type RenameRegistrationOptions struct { // line 5929
-	TextDocumentRegistrationOptions
-	RenameOptions
-}
-
-// A generic resource operation.
-type ResourceOperation struct { // line 9413
-	// The resource operation kind.
-	Kind string `json:"kind"`
-	/*
-	 * An optional annotation identifier describing the operation.
-	 *
-	 * @since 3.16.0
-	 */
-	AnnotationID ChangeAnnotationIdentifier `json:"annotationId,omitempty"`
-}
-type ResourceOperationKind string // line 13695
-// Save options.
-type SaveOptions struct { // line 8485
-	// The client is supposed to include the content on save.
-	IncludeText bool `json:"includeText,omitempty"`
-}
-
-/*
- * A selection range represents a part of a selection hierarchy. A selection range
- * may have a parent selection range that contains it.
- */
-type SelectionRange struct { // line 2591
-	// The [range](#Range) of this selection range.
-	Range Range `json:"range"`
-	// The parent selection range containing this range. Therefore `parent.range` must contain `this.range`.
-	Parent *SelectionRange `json:"parent,omitempty"`
-}
-type SelectionRangeClientCapabilities struct { // line 12084
-	/*
-	 * Whether implementation supports dynamic registration for selection range providers. If this is set to `true`
-	 * the client supports the new `SelectionRangeRegistrationOptions` return value for the corresponding server
-	 * capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-type SelectionRangeOptions struct { // line 6529
-	WorkDoneProgressOptions
-}
-
-// A parameter literal used in selection range requests.
-type SelectionRangeParams struct { // line 2556
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The positions inside the text document.
-	Positions []Position `json:"positions"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type SelectionRangeRegistrationOptions struct { // line 2614
-	SelectionRangeOptions
-	TextDocumentRegistrationOptions
-	StaticRegistrationOptions
-}
-type SemanticTokenModifiers string // line 12696
-type SemanticTokenTypes string     // line 12589
-// @since 3.16.0
-type SemanticTokens struct { // line 2902
-	/*
-	 * An optional result id. If provided and clients support delta updating
-	 * the client will include the result id in the next semantic token request.
-	 * A server can then instead of computing all semantic tokens again simply
-	 * send a delta.
-	 */
-	ResultID string `json:"resultId,omitempty"`
-	// The actual tokens.
-	Data []uint32 `json:"data"`
-}
-
-// @since 3.16.0
-type SemanticTokensClientCapabilities struct { // line 12183
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `(TextDocumentRegistrationOptions & StaticRegistrationOptions)`
-	 * return value for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * Which requests the client supports and might send to the server
-	 * depending on the server's capability. Please note that clients might not
-	 * show semantic tokens or degrade some of the user experience if a range
-	 * or full request is advertised by the client but not provided by the
-	 * server. If for example the client capability `requests.full` and
-	 * `request.range` are both set to true but the server only provides a
-	 * range provider the client might not render a minimap correctly or might
-	 * even decide to not show any semantic tokens at all.
-	 */
-	Requests PRequestsPSemanticTokens `json:"requests"`
-	// The token types that the client supports.
-	TokenTypes []string `json:"tokenTypes"`
-	// The token modifiers that the client supports.
-	TokenModifiers []string `json:"tokenModifiers"`
-	// The token formats the clients supports.
-	Formats []string `json:"formats"`
-	// Whether the client supports tokens that can overlap each other.
-	OverlappingTokenSupport bool `json:"overlappingTokenSupport,omitempty"`
-	// Whether the client supports tokens that can span multiple lines.
-	MultilineTokenSupport bool `json:"multilineTokenSupport,omitempty"`
-	/*
-	 * Whether the client allows the server to actively cancel a
-	 * semantic token request, e.g. supports returning
-	 * LSPErrorCodes.ServerCancelled. If a server does the client
-	 * needs to retrigger the request.
-	 *
-	 * @since 3.17.0
-	 */
-	ServerCancelSupport bool `json:"serverCancelSupport,omitempty"`
-	/*
-	 * Whether the client uses semantic tokens to augment existing
-	 * syntax tokens. If set to `true` client side created syntax
-	 * tokens and semantic tokens are both used for colorization. If
-	 * set to `false` the client only uses the returned semantic tokens
-	 * for colorization.
-	 *
-	 * If the value is `undefined` then the client behavior is not
-	 * specified.
-	 *
-	 * @since 3.17.0
-	 */
-	AugmentsSyntaxTokens bool `json:"augmentsSyntaxTokens,omitempty"`
-}
-
-// @since 3.16.0
-type SemanticTokensDelta struct { // line 3001
-	ResultID string `json:"resultId,omitempty"`
-	// The semantic token edits to transform a previous result into a new result.
-	Edits []SemanticTokensEdit `json:"edits"`
-}
-
-// @since 3.16.0
-type SemanticTokensDeltaParams struct { // line 2968
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	/*
-	 * The result id of a previous response. The result Id can either point to a full response
-	 * or a delta response depending on what was received last.
-	 */
-	PreviousResultID string `json:"previousResultId"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// @since 3.16.0
-type SemanticTokensDeltaPartialResult struct { // line 3027
-	Edits []SemanticTokensEdit `json:"edits"`
-}
-
-// @since 3.16.0
-type SemanticTokensEdit struct { // line 6622
-	// The start offset of the edit.
-	Start uint32 `json:"start"`
-	// The count of elements to remove.
-	DeleteCount uint32 `json:"deleteCount"`
-	// The elements to insert.
-	Data []uint32 `json:"data,omitempty"`
-}
-
-// @since 3.16.0
-type SemanticTokensLegend struct { // line 9334
-	// The token types a server uses.
-	TokenTypes []string `json:"tokenTypes"`
-	// The token modifiers a server uses.
-	TokenModifiers []string `json:"tokenModifiers"`
-}
-
-// @since 3.16.0
-type SemanticTokensOptions struct { // line 6551
-	// The legend used by the server
-	Legend SemanticTokensLegend `json:"legend"`
-	/*
-	 * Server supports providing semantic tokens for a specific range
-	 * of a document.
-	 */
-	Range interface{} `json:"range,omitempty"`
-	// Server supports providing semantic tokens for a full document.
-	Full bool `json:"full,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// @since 3.16.0
-type SemanticTokensParams struct { // line 2877
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// @since 3.16.0
-type SemanticTokensPartialResult struct { // line 2929
-	Data []uint32 `json:"data"`
-}
-
-// @since 3.16.0
-type SemanticTokensRangeParams struct { // line 3044
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The range the semantic tokens are requested for.
-	Range Range `json:"range"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// @since 3.16.0
-type SemanticTokensRegistrationOptions struct { // line 2946
-	TextDocumentRegistrationOptions
-	SemanticTokensOptions
-	StaticRegistrationOptions
-}
-
-// @since 3.16.0
-type SemanticTokensWorkspaceClientCapabilities struct { // line 11003
-	/*
-	 * Whether the client implementation supports a refresh request sent from
-	 * the server to the client.
-	 *
-	 * Note that this event is global and will force the client to refresh all
-	 * semantic tokens currently shown. It should be used with absolute care
-	 * and is useful for situation where a server for example detects a project
-	 * wide change that requires such a calculation.
-	 */
-	RefreshSupport bool `json:"refreshSupport,omitempty"`
-}
-
-/*
- * Defines the capabilities provided by a language
- * server.
- */
-type ServerCapabilities struct { // line 7829
-	/*
-	 * The position encoding the server picked from the encodings offered
-	 * by the client via the client capability `general.positionEncodings`.
-	 *
-	 * If the client didn't provide any position encodings the only valid
-	 * value that a server can return is 'utf-16'.
-	 *
-	 * If omitted it defaults to 'utf-16'.
-	 *
-	 * @since 3.17.0
-	 */
-	PositionEncoding PositionEncodingKind `json:"positionEncoding,omitempty"`
-	/*
-	 * Defines how text documents are synced. Is either a detailed structure
-	 * defining each notification or for backwards compatibility the
-	 * TextDocumentSyncKind number.
-	 */
-	TextDocumentSync interface{} `json:"textDocumentSync,omitempty"`
-	/*
-	 * Defines how notebook documents are synced.
-	 *
-	 * @since 3.17.0
-	 */
-	NotebookDocumentSync interface{} `json:"notebookDocumentSync,omitempty"`
-	// The server provides completion support.
-	CompletionProvider CompletionOptions `json:"completionProvider,omitempty"`
-	// The server provides hover support.
-	HoverProvider bool `json:"hoverProvider,omitempty"`
-	// The server provides signature help support.
-	SignatureHelpProvider SignatureHelpOptions `json:"signatureHelpProvider,omitempty"`
-	// The server provides Goto Declaration support.
-	DeclarationProvider bool `json:"declarationProvider,omitempty"`
-	// The server provides goto definition support.
-	DefinitionProvider bool `json:"definitionProvider,omitempty"`
-	// The server provides Goto Type Definition support.
-	TypeDefinitionProvider interface{} `json:"typeDefinitionProvider,omitempty"`
-	// The server provides Goto Implementation support.
-	ImplementationProvider interface{} `json:"implementationProvider,omitempty"`
-	// The server provides find references support.
-	ReferencesProvider bool `json:"referencesProvider,omitempty"`
-	// The server provides document highlight support.
-	DocumentHighlightProvider bool `json:"documentHighlightProvider,omitempty"`
-	// The server provides document symbol support.
-	DocumentSymbolProvider bool `json:"documentSymbolProvider,omitempty"`
-	/*
-	 * The server provides code actions. CodeActionOptions may only be
-	 * specified if the client states that it supports
-	 * `codeActionLiteralSupport` in its initial `initialize` request.
-	 */
-	CodeActionProvider interface{} `json:"codeActionProvider,omitempty"`
-	// The server provides code lens.
-	CodeLensProvider *CodeLensOptions `json:"codeLensProvider,omitempty"`
-	// The server provides document link support.
-	DocumentLinkProvider DocumentLinkOptions `json:"documentLinkProvider,omitempty"`
-	// The server provides color provider support.
-	ColorProvider interface{} `json:"colorProvider,omitempty"`
-	// The server provides workspace symbol support.
-	WorkspaceSymbolProvider bool `json:"workspaceSymbolProvider,omitempty"`
-	// The server provides document formatting.
-	DocumentFormattingProvider bool `json:"documentFormattingProvider,omitempty"`
-	// The server provides document range formatting.
-	DocumentRangeFormattingProvider bool `json:"documentRangeFormattingProvider,omitempty"`
-	// The server provides document formatting on typing.
-	DocumentOnTypeFormattingProvider *DocumentOnTypeFormattingOptions `json:"documentOnTypeFormattingProvider,omitempty"`
-	/*
-	 * The server provides rename support. RenameOptions may only be
-	 * specified if the client states that it supports
-	 * `prepareSupport` in its initial `initialize` request.
-	 */
-	RenameProvider interface{} `json:"renameProvider,omitempty"`
-	// The server provides folding provider support.
-	FoldingRangeProvider interface{} `json:"foldingRangeProvider,omitempty"`
-	// The server provides selection range support.
-	SelectionRangeProvider interface{} `json:"selectionRangeProvider,omitempty"`
-	// The server provides execute command support.
-	ExecuteCommandProvider ExecuteCommandOptions `json:"executeCommandProvider,omitempty"`
-	/*
-	 * The server provides call hierarchy support.
-	 *
-	 * @since 3.16.0
-	 */
-	CallHierarchyProvider interface{} `json:"callHierarchyProvider,omitempty"`
-	/*
-	 * The server provides linked editing range support.
-	 *
-	 * @since 3.16.0
-	 */
-	LinkedEditingRangeProvider interface{} `json:"linkedEditingRangeProvider,omitempty"`
-	/*
-	 * The server provides semantic tokens support.
-	 *
-	 * @since 3.16.0
-	 */
-	SemanticTokensProvider interface{} `json:"semanticTokensProvider,omitempty"`
-	/*
-	 * The server provides moniker support.
-	 *
-	 * @since 3.16.0
-	 */
-	MonikerProvider interface{} `json:"monikerProvider,omitempty"`
-	/*
-	 * The server provides type hierarchy support.
-	 *
-	 * @since 3.17.0
-	 */
-	TypeHierarchyProvider interface{} `json:"typeHierarchyProvider,omitempty"`
-	/*
-	 * The server provides inline values.
-	 *
-	 * @since 3.17.0
-	 */
-	InlineValueProvider interface{} `json:"inlineValueProvider,omitempty"`
-	/*
-	 * The server provides inlay hints.
-	 *
-	 * @since 3.17.0
-	 */
-	InlayHintProvider interface{} `json:"inlayHintProvider,omitempty"`
-	/*
-	 * The server has support for pull model diagnostics.
-	 *
-	 * @since 3.17.0
-	 */
-	DiagnosticProvider interface{} `json:"diagnosticProvider,omitempty"`
-	// Workspace specific server capabilities.
-	Workspace Workspace6Gn `json:"workspace,omitempty"`
-	// Experimental server capabilities.
-	Experimental interface{} `json:"experimental,omitempty"`
-}
-type SetTraceParams struct { // line 6166
-	Value TraceValues `json:"value"`
-}
-
-/*
- * Client capabilities for the showDocument request.
- *
- * @since 3.16.0
- */
-type ShowDocumentClientCapabilities struct { // line 12511
-	/*
-	 * The client has support for the showDocument
-	 * request.
-	 */
-	Support bool `json:"support"`
-}
-
-/*
- * Params to show a document.
- *
- * @since 3.16.0
- */
-type ShowDocumentParams struct { // line 3077
-	// The document uri to show.
-	URI URI `json:"uri"`
-	/*
-	 * Indicates to show the resource in an external program.
-	 * To show for example `https://code.visualstudio.com/`
-	 * in the default WEB browser set `external` to `true`.
-	 */
-	External bool `json:"external,omitempty"`
-	/*
-	 * An optional property to indicate whether the editor
-	 * showing the document should take focus or not.
-	 * Clients might ignore this property if an external
-	 * program is started.
-	 */
-	TakeFocus bool `json:"takeFocus,omitempty"`
-	/*
-	 * An optional selection range if the document is a text
-	 * document. Clients might ignore the property if an
-	 * external program is started or the file is not a text
-	 * file.
-	 */
-	Selection *Range `json:"selection,omitempty"`
-}
-
-/*
- * The result of a showDocument request.
- *
- * @since 3.16.0
- */
-type ShowDocumentResult struct { // line 3119
-	// A boolean indicating if the show was successful.
-	Success bool `json:"success"`
-}
-
-// The parameters of a notification message.
-type ShowMessageParams struct { // line 4205
-	// The message type. See {@link MessageType}
-	Type MessageType `json:"type"`
-	// The actual message.
-	Message string `json:"message"`
-}
-
-// Show message request client capabilities
-type ShowMessageRequestClientCapabilities struct { // line 12484
-	// Capabilities specific to the `MessageActionItem` type.
-	MessageActionItem *PMessageActionItemPShowMessage `json:"messageActionItem,omitempty"`
-}
-type ShowMessageRequestParams struct { // line 4227
-	// The message type. See {@link MessageType}
-	Type MessageType `json:"type"`
-	// The actual message.
-	Message string `json:"message"`
-	// The message action items to present.
-	Actions []MessageActionItem `json:"actions,omitempty"`
-}
-
-/*
- * Signature help represents the signature of something
- * callable. There can be multiple signature but only one
- * active and only one active parameter.
- */
-type SignatureHelp struct { // line 4989
-	// One or more signatures.
-	Signatures []SignatureInformation `json:"signatures"`
-	/*
-	 * The active signature. If omitted or the value lies outside the
-	 * range of `signatures` the value defaults to zero or is ignored if
-	 * the `SignatureHelp` has no signatures.
-	 *
-	 * Whenever possible implementors should make an active decision about
-	 * the active signature and shouldn't rely on a default value.
-	 *
-	 * In future version of the protocol this property might become
-	 * mandatory to better express this.
-	 */
-	ActiveSignature uint32 `json:"activeSignature,omitempty"`
-	/*
-	 * The active parameter of the active signature. If omitted or the value
-	 * lies outside the range of `signatures[activeSignature].parameters`
-	 * defaults to 0 if the active signature has parameters. If
-	 * the active signature has no parameters it is ignored.
-	 * In future version of the protocol this property might become
-	 * mandatory to better express the active parameter if the
-	 * active signature does have any.
-	 */
-	ActiveParameter uint32 `json:"activeParameter,omitempty"`
-}
-
-// Client Capabilities for a [SignatureHelpRequest](#SignatureHelpRequest).
-type SignatureHelpClientCapabilities struct { // line 11454
-	// Whether signature help supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The client supports the following `SignatureInformation`
-	 * specific properties.
-	 */
-	SignatureInformation *PSignatureInformationPSignatureHelp `json:"signatureInformation,omitempty"`
-	/*
-	 * The client supports to send additional context information for a
-	 * `textDocument/signatureHelp` request. A client that opts into
-	 * contextSupport will also support the `retriggerCharacters` on
-	 * `SignatureHelpOptions`.
-	 *
-	 * @since 3.15.0
-	 */
-	ContextSupport bool `json:"contextSupport,omitempty"`
-}
-
-/*
- * Additional information about the context in which a signature help request was triggered.
- *
- * @since 3.15.0
- */
-type SignatureHelpContext struct { // line 8807
-	// Action that caused signature help to be triggered.
-	TriggerKind SignatureHelpTriggerKind `json:"triggerKind"`
-	/*
-	 * Character that caused signature help to be triggered.
-	 *
-	 * This is undefined when `triggerKind !== SignatureHelpTriggerKind.TriggerCharacter`
-	 */
-	TriggerCharacter string `json:"triggerCharacter,omitempty"`
-	/*
-	 * `true` if signature help was already showing when it was triggered.
-	 *
-	 * Retriggers occurs when the signature help is already active and can be caused by actions such as
-	 * typing a trigger character, a cursor move, or document content changes.
-	 */
-	IsRetrigger bool `json:"isRetrigger"`
-	/*
-	 * The currently active `SignatureHelp`.
-	 *
-	 * The `activeSignatureHelp` has its `SignatureHelp.activeSignature` field updated based on
-	 * the user navigating through available signatures.
-	 */
-	ActiveSignatureHelp *SignatureHelp `json:"activeSignatureHelp,omitempty"`
-}
-
-// Server Capabilities for a [SignatureHelpRequest](#SignatureHelpRequest).
-type SignatureHelpOptions struct { // line 8902
-	// List of characters that trigger signature help automatically.
-	TriggerCharacters []string `json:"triggerCharacters,omitempty"`
-	/*
-	 * List of characters that re-trigger signature help.
-	 *
-	 * These trigger characters are only active when signature help is already showing. All trigger characters
-	 * are also counted as re-trigger characters.
-	 *
-	 * @since 3.15.0
-	 */
-	RetriggerCharacters []string `json:"retriggerCharacters,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// Parameters for a [SignatureHelpRequest](#SignatureHelpRequest).
-type SignatureHelpParams struct { // line 4961
-	/*
-	 * The signature help context. This is only available if the client specifies
-	 * to send this using the client capability `textDocument.signatureHelp.contextSupport === true`
-	 *
-	 * @since 3.15.0
-	 */
-	Context *SignatureHelpContext `json:"context,omitempty"`
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-}
-
-// Registration options for a [SignatureHelpRequest](#SignatureHelpRequest).
-type SignatureHelpRegistrationOptions struct { // line 5024
-	TextDocumentRegistrationOptions
-	SignatureHelpOptions
-}
-type SignatureHelpTriggerKind uint32 // line 13606
-/*
- * Represents the signature of something callable. A signature
- * can have a label, like a function-name, a doc-comment, and
- * a set of parameters.
- */
-type SignatureInformation struct { // line 8848
-	/*
-	 * The label of this signature. Will be shown in
-	 * the UI.
-	 */
-	Label string `json:"label"`
-	/*
-	 * The human-readable doc-comment of this signature. Will be shown
-	 * in the UI but can be omitted.
-	 */
-	Documentation string `json:"documentation,omitempty"`
-	// The parameters of this signature.
-	Parameters []ParameterInformation `json:"parameters,omitempty"`
-	/*
-	 * The index of the active parameter.
-	 *
-	 * If provided, this is used in place of `SignatureHelp.activeParameter`.
-	 *
-	 * @since 3.16.0
-	 */
-	ActiveParameter uint32 `json:"activeParameter,omitempty"`
-}
-
-/*
- * Static registration options to be returned in the initialize
- * request.
- */
-type StaticRegistrationOptions struct { // line 6348
-	/*
-	 * The id used to register the request. The id can be used to deregister
-	 * the request again. See also Registration#id.
-	 */
-	ID string `json:"id,omitempty"`
-}
-
-/*
- * Represents information about programming constructs like variables, classes,
- * interfaces etc.
- */
-type SymbolInformation struct { // line 5202
-	/*
-	 * Indicates if this symbol is deprecated.
-	 *
-	 * @deprecated Use tags instead
-	 */
-	Deprecated bool `json:"deprecated,omitempty"`
-	/*
-	 * The location of this symbol. The location's range is used by a tool
-	 * to reveal the location in the editor. If the symbol is selected in the
-	 * tool the range's start information is used to position the cursor. So
-	 * the range usually spans more than the actual symbol's name and does
-	 * normally include things like visibility modifiers.
-	 *
-	 * The range doesn't have to denote a node range in the sense of an abstract
-	 * syntax tree. It can therefore not be used to re-construct a hierarchy of
-	 * the symbols.
-	 */
-	Location Location `json:"location"`
-	// The name of this symbol.
-	Name string `json:"name"`
-	// The kind of this symbol.
-	Kind SymbolKind `json:"kind"`
-	/*
-	 * Tags for this symbol.
-	 *
-	 * @since 3.16.0
-	 */
-	Tags []SymbolTag `json:"tags,omitempty"`
-	/*
-	 * The name of the symbol containing this symbol. This information is for
-	 * user interface purposes (e.g. to render a qualifier in the user interface
-	 * if necessary). It can't be used to re-infer a hierarchy for the document
-	 * symbols.
-	 */
-	ContainerName string `json:"containerName,omitempty"`
-}
-type SymbolKind uint32 // line 12867
-type SymbolTag uint32  // line 12981
-// Describe options to be used when registered for text document change events.
-type TextDocumentChangeRegistrationOptions struct { // line 4334
-	// How documents are synced to the server.
-	SyncKind TextDocumentSyncKind `json:"syncKind"`
-	TextDocumentRegistrationOptions
-}
-
-// Text document specific client capabilities.
-type TextDocumentClientCapabilities struct { // line 10349
-	// Defines which synchronization capabilities the client supports.
-	Synchronization *TextDocumentSyncClientCapabilities `json:"synchronization,omitempty"`
-	// Capabilities specific to the `textDocument/completion` request.
-	Completion CompletionClientCapabilities `json:"completion,omitempty"`
-	// Capabilities specific to the `textDocument/hover` request.
-	Hover HoverClientCapabilities `json:"hover,omitempty"`
-	// Capabilities specific to the `textDocument/signatureHelp` request.
-	SignatureHelp *SignatureHelpClientCapabilities `json:"signatureHelp,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/declaration` request.
-	 *
-	 * @since 3.14.0
-	 */
-	Declaration *DeclarationClientCapabilities `json:"declaration,omitempty"`
-	// Capabilities specific to the `textDocument/definition` request.
-	Definition *DefinitionClientCapabilities `json:"definition,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/typeDefinition` request.
-	 *
-	 * @since 3.6.0
-	 */
-	TypeDefinition *TypeDefinitionClientCapabilities `json:"typeDefinition,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/implementation` request.
-	 *
-	 * @since 3.6.0
-	 */
-	Implementation *ImplementationClientCapabilities `json:"implementation,omitempty"`
-	// Capabilities specific to the `textDocument/references` request.
-	References *ReferenceClientCapabilities `json:"references,omitempty"`
-	// Capabilities specific to the `textDocument/documentHighlight` request.
-	DocumentHighlight *DocumentHighlightClientCapabilities `json:"documentHighlight,omitempty"`
-	// Capabilities specific to the `textDocument/documentSymbol` request.
-	DocumentSymbol DocumentSymbolClientCapabilities `json:"documentSymbol,omitempty"`
-	// Capabilities specific to the `textDocument/codeAction` request.
-	CodeAction CodeActionClientCapabilities `json:"codeAction,omitempty"`
-	// Capabilities specific to the `textDocument/codeLens` request.
-	CodeLens *CodeLensClientCapabilities `json:"codeLens,omitempty"`
-	// Capabilities specific to the `textDocument/documentLink` request.
-	DocumentLink *DocumentLinkClientCapabilities `json:"documentLink,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/documentColor` and the
-	 * `textDocument/colorPresentation` request.
-	 *
-	 * @since 3.6.0
-	 */
-	ColorProvider *DocumentColorClientCapabilities `json:"colorProvider,omitempty"`
-	// Capabilities specific to the `textDocument/formatting` request.
-	Formatting *DocumentFormattingClientCapabilities `json:"formatting,omitempty"`
-	// Capabilities specific to the `textDocument/rangeFormatting` request.
-	RangeFormatting *DocumentRangeFormattingClientCapabilities `json:"rangeFormatting,omitempty"`
-	// Capabilities specific to the `textDocument/onTypeFormatting` request.
-	OnTypeFormatting *DocumentOnTypeFormattingClientCapabilities `json:"onTypeFormatting,omitempty"`
-	// Capabilities specific to the `textDocument/rename` request.
-	Rename RenameClientCapabilities `json:"rename,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/foldingRange` request.
-	 *
-	 * @since 3.10.0
-	 */
-	FoldingRange FoldingRangeClientCapabilities `json:"foldingRange,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/selectionRange` request.
-	 *
-	 * @since 3.15.0
-	 */
-	SelectionRange *SelectionRangeClientCapabilities `json:"selectionRange,omitempty"`
-	// Capabilities specific to the `textDocument/publishDiagnostics` notification.
-	PublishDiagnostics PublishDiagnosticsClientCapabilities `json:"publishDiagnostics,omitempty"`
-	/*
-	 * Capabilities specific to the various call hierarchy requests.
-	 *
-	 * @since 3.16.0
-	 */
-	CallHierarchy *CallHierarchyClientCapabilities `json:"callHierarchy,omitempty"`
-	/*
-	 * Capabilities specific to the various semantic token request.
-	 *
-	 * @since 3.16.0
-	 */
-	SemanticTokens SemanticTokensClientCapabilities `json:"semanticTokens,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/linkedEditingRange` request.
-	 *
-	 * @since 3.16.0
-	 */
-	LinkedEditingRange *LinkedEditingRangeClientCapabilities `json:"linkedEditingRange,omitempty"`
-	/*
-	 * Client capabilities specific to the `textDocument/moniker` request.
-	 *
-	 * @since 3.16.0
-	 */
-	Moniker *MonikerClientCapabilities `json:"moniker,omitempty"`
-	/*
-	 * Capabilities specific to the various type hierarchy requests.
-	 *
-	 * @since 3.17.0
-	 */
-	TypeHierarchy *TypeHierarchyClientCapabilities `json:"typeHierarchy,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/inlineValue` request.
-	 *
-	 * @since 3.17.0
-	 */
-	InlineValue *InlineValueClientCapabilities `json:"inlineValue,omitempty"`
-	/*
-	 * Capabilities specific to the `textDocument/inlayHint` request.
-	 *
-	 * @since 3.17.0
-	 */
-	InlayHint *InlayHintClientCapabilities `json:"inlayHint,omitempty"`
-	/*
-	 * Capabilities specific to the diagnostic pull model.
-	 *
-	 * @since 3.17.0
-	 */
-	Diagnostic *DiagnosticClientCapabilities `json:"diagnostic,omitempty"`
-}
-
-/*
- * An event describing a change to a text document. If only a text is provided
- * it is considered to be the full content of the document.
- */
-type TextDocumentContentChangeEvent = Msg_TextDocumentContentChangeEvent // (alias) line 14028
-/*
- * Describes textual changes on a text document. A TextDocumentEdit describes all changes
- * on a document version Si and after they are applied move the document to version Si+1.
- * So the creator of a TextDocumentEdit doesn't need to sort the array of edits or do any
- * kind of ordering. However the edits must be non overlapping.
- */
-type TextDocumentEdit struct { // line 6682
-	// The text document to change.
-	TextDocument OptionalVersionedTextDocumentIdentifier `json:"textDocument"`
-	/*
-	 * The edits to be applied.
-	 *
-	 * @since 3.16.0 - support for AnnotatedTextEdit. This is guarded using a
-	 * client capability.
-	 */
-	Edits []TextEdit `json:"edits"`
-}
-
-/*
- * A document filter denotes a document by different properties like
- * the [language](#TextDocument.languageId), the [scheme](#Uri.scheme) of
- * its resource, or a glob-pattern that is applied to the [path](#TextDocument.fileName).
- *
- * Glob patterns can have the following syntax:
- * - `*` to match one or more characters in a path segment
- * - `?` to match on one character in a path segment
- * - `**` to match any number of path segments, including none
- * - `{}` to group sub patterns into an OR expression. (e.g. `**​/*.{ts,js}` matches all TypeScript and JavaScript files)
- * - `[]` to declare a range of characters to match in a path segment (e.g., `example.[0-9]` to match on `example.0`, `example.1`, …)
- * - `[!...]` to negate a range of characters to match in a path segment (e.g., `example.[!0-9]` to match on `example.a`, `example.b`, but not `example.0`)
- *
- * @sample A language filter that applies to typescript files on disk: `{ language: 'typescript', scheme: 'file' }`
- * @sample A language filter that applies to all package.json paths: `{ language: 'json', pattern: '**package.json' }`
- *
- * @since 3.17.0
- */
-type TextDocumentFilter = Msg_TextDocumentFilter // (alias) line 14154
-// A literal to identify a text document in the client.
-type TextDocumentIdentifier struct { // line 6424
-	// The text document's uri.
-	URI DocumentURI `json:"uri"`
-}
-
-/*
- * An item to transfer a text document from the client to the
- * server.
- */
-type TextDocumentItem struct { // line 7410
-	// The text document's uri.
-	URI DocumentURI `json:"uri"`
-	// The text document's language identifier.
-	LanguageID string `json:"languageId"`
-	/*
-	 * The version number of this document (it will increase after each
-	 * change, including undo/redo).
-	 */
-	Version int32 `json:"version"`
-	// The content of the opened text document.
-	Text string `json:"text"`
-}
-
-/*
- * A parameter literal used in requests to pass a text document and a position inside that
- * document.
- */
-type TextDocumentPositionParams struct { // line 6241
-	// The text document.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The position inside the text document.
-	Position Position `json:"position"`
-}
-
-// General text document registration options.
-type TextDocumentRegistrationOptions struct { // line 2390
-	/*
-	 * A document selector to identify the scope of the registration. If set to null
-	 * the document selector provided on the client side will be used.
-	 */
-	DocumentSelector DocumentSelector `json:"documentSelector"`
-}
-type TextDocumentSaveReason uint32 // line 13135
-// Save registration options.
-type TextDocumentSaveRegistrationOptions struct { // line 4391
-	TextDocumentRegistrationOptions
-	SaveOptions
-}
-type TextDocumentSyncClientCapabilities struct { // line 11153
-	// Whether text document synchronization supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	// The client supports sending will save notifications.
-	WillSave bool `json:"willSave,omitempty"`
-	/*
-	 * The client supports sending a will save request and
-	 * waits for a response providing text edits which will
-	 * be applied to the document before it is saved.
-	 */
-	WillSaveWaitUntil bool `json:"willSaveWaitUntil,omitempty"`
-	// The client supports did save notifications.
-	DidSave bool `json:"didSave,omitempty"`
-}
-type TextDocumentSyncKind uint32      // line 13110
-type TextDocumentSyncOptions struct { // line 9762
-	/*
-	 * Open and close notifications are sent to the server. If omitted open close notification should not
-	 * be sent.
-	 */
-	OpenClose bool `json:"openClose,omitempty"`
-	/*
-	 * Change notifications are sent to the server. See TextDocumentSyncKind.None, TextDocumentSyncKind.Full
-	 * and TextDocumentSyncKind.Incremental. If omitted it defaults to TextDocumentSyncKind.None.
-	 */
-	Change TextDocumentSyncKind `json:"change,omitempty"`
-	/*
-	 * If present will save notifications are sent to the server. If omitted the notification should not be
-	 * sent.
-	 */
-	WillSave bool `json:"willSave,omitempty"`
-	/*
-	 * If present will save wait until requests are sent to the server. If omitted the request should not be
-	 * sent.
-	 */
-	WillSaveWaitUntil bool `json:"willSaveWaitUntil,omitempty"`
-	/*
-	 * If present save notifications are sent to the server. If omitted the notification should not be
-	 * sent.
-	 */
-	Save SaveOptions `json:"save,omitempty"`
-}
-
-// A text edit applicable to a text document.
-type TextEdit struct { // line 4428
-	/*
-	 * The range of the text document to be manipulated. To insert
-	 * text into a document create a range where start === end.
-	 */
-	Range Range `json:"range"`
-	/*
-	 * The string to be inserted. For delete operations use an
-	 * empty string.
-	 */
-	NewText string `json:"newText"`
-}
-type TokenFormat string // line 13762
-type TraceValues string // line 13409
-// Since 3.6.0
-type TypeDefinitionClientCapabilities struct { // line 11585
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `TypeDefinitionRegistrationOptions` return value
-	 * for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	/*
-	 * The client supports additional metadata in the form of definition links.
-	 *
-	 * Since 3.14.0
-	 */
-	LinkSupport bool `json:"linkSupport,omitempty"`
-}
-type TypeDefinitionOptions struct { // line 6363
-	WorkDoneProgressOptions
-}
-type TypeDefinitionParams struct { // line 2131
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-	PartialResultParams
-}
-type TypeDefinitionRegistrationOptions struct { // line 2151
-	TextDocumentRegistrationOptions
-	TypeDefinitionOptions
-	StaticRegistrationOptions
-}
-
-// @since 3.17.0
-type TypeHierarchyClientCapabilities struct { // line 12363
-	/*
-	 * Whether implementation supports dynamic registration. If this is set to `true`
-	 * the client supports the new `(TextDocumentRegistrationOptions & StaticRegistrationOptions)`
-	 * return value for the corresponding server capability as well.
-	 */
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-}
-
-// @since 3.17.0
-type TypeHierarchyItem struct { // line 3432
-	// The name of this item.
-	Name string `json:"name"`
-	// The kind of this item.
-	Kind SymbolKind `json:"kind"`
-	// Tags for this item.
-	Tags []SymbolTag `json:"tags,omitempty"`
-	// More detail for this item, e.g. the signature of a function.
-	Detail string `json:"detail,omitempty"`
-	// The resource identifier of this item.
-	URI DocumentURI `json:"uri"`
-	/*
-	 * The range enclosing this symbol not including leading/trailing whitespace
-	 * but everything else, e.g. comments and code.
-	 */
-	Range Range `json:"range"`
-	/*
-	 * The range that should be selected and revealed when this symbol is being
-	 * picked, e.g. the name of a function. Must be contained by the
-	 * [`range`](#TypeHierarchyItem.range).
-	 */
-	SelectionRange Range `json:"selectionRange"`
-	/*
-	 * A data entry field that is preserved between a type hierarchy prepare and
-	 * supertypes or subtypes requests. It could also be used to identify the
-	 * type hierarchy in the server, helping improve the performance on
-	 * resolving supertypes and subtypes.
-	 */
-	Data interface{} `json:"data,omitempty"`
-}
-
-/*
- * Type hierarchy options used during static registration.
- *
- * @since 3.17.0
- */
-type TypeHierarchyOptions struct { // line 6941
-	WorkDoneProgressOptions
-}
-
-/*
- * The parameter of a `textDocument/prepareTypeHierarchy` request.
- *
- * @since 3.17.0
- */
-type TypeHierarchyPrepareParams struct { // line 3414
-	TextDocumentPositionParams
-	WorkDoneProgressParams
-}
-
-/*
- * Type hierarchy options used during static or dynamic registration.
- *
- * @since 3.17.0
- */
-type TypeHierarchyRegistrationOptions struct { // line 3509
-	TextDocumentRegistrationOptions
-	TypeHierarchyOptions
-	StaticRegistrationOptions
-}
-
-/*
- * The parameter of a `typeHierarchy/subtypes` request.
- *
- * @since 3.17.0
- */
-type TypeHierarchySubtypesParams struct { // line 3555
-	Item TypeHierarchyItem `json:"item"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-/*
- * The parameter of a `typeHierarchy/supertypes` request.
- *
- * @since 3.17.0
- */
-type TypeHierarchySupertypesParams struct { // line 3531
-	Item TypeHierarchyItem `json:"item"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// created for Tuple
-type UIntCommaUInt struct { // line 10101
-	Fld0 uint32 `json:"fld0"`
-	Fld1 uint32 `json:"fld1"`
-}
-type URI = string // (alias) line 0
-/*
- * A diagnostic report indicating that the last returned
- * report is still accurate.
- *
- * @since 3.17.0
- */
-type UnchangedDocumentDiagnosticReport struct { // line 7275
-	/*
-	 * A document diagnostic report indicating
-	 * no changes to the last result. A server can
-	 * only return `unchanged` if result ids are
-	 * provided.
-	 */
-	Kind string `json:"kind"`
-	/*
-	 * A result id which will be sent on the next
-	 * diagnostic request for the same document.
-	 */
-	ResultID string `json:"resultId"`
-}
-type UniquenessLevel string // line 12997
-// General parameters to unregister a request or notification.
-type Unregistration struct { // line 7633
-	/*
-	 * The id used to unregister the request or notification. Usually an id
-	 * provided during the register request.
-	 */
-	ID string `json:"id"`
-	// The method to unregister for.
-	Method string `json:"method"`
-}
-type UnregistrationParams struct { // line 4075
-	Unregisterations []Unregistration `json:"unregisterations"`
-}
-
-/*
- * A versioned notebook document identifier.
- *
- * @since 3.17.0
- */
-type VersionedNotebookDocumentIdentifier struct { // line 7448
-	// The version number of this notebook document.
-	Version int32 `json:"version"`
-	// The notebook document's uri.
-	URI URI `json:"uri"`
-}
-
-// A text document identifier to denote a specific version of a text document.
-type VersionedTextDocumentIdentifier struct { // line 8465
-	// The version number of this document.
-	Version int32 `json:"version"`
-	TextDocumentIdentifier
-}
-type WatchKind = uint32 // line 13505
-// The parameters sent in a will save text document notification.
-type WillSaveTextDocumentParams struct { // line 4406
-	// The document that will be saved.
-	TextDocument TextDocumentIdentifier `json:"textDocument"`
-	// The 'TextDocumentSaveReason'.
-	Reason TextDocumentSaveReason `json:"reason"`
-}
-type WindowClientCapabilities struct { // line 10655
-	/*
-	 * It indicates whether the client supports server initiated
-	 * progress using the `window/workDoneProgress/create` request.
-	 *
-	 * The capability also controls Whether client supports handling
-	 * of progress notifications. If set servers are allowed to report a
-	 * `workDoneProgress` property in the request specific server
-	 * capabilities.
-	 *
-	 * @since 3.15.0
-	 */
-	WorkDoneProgress bool `json:"workDoneProgress,omitempty"`
-	/*
-	 * Capabilities specific to the showMessage request.
-	 *
-	 * @since 3.16.0
-	 */
-	ShowMessage *ShowMessageRequestClientCapabilities `json:"showMessage,omitempty"`
-	/*
-	 * Capabilities specific to the showDocument request.
-	 *
-	 * @since 3.16.0
-	 */
-	ShowDocument *ShowDocumentClientCapabilities `json:"showDocument,omitempty"`
-}
-type WorkDoneProgressBegin struct { // line 6059
-	Kind string `json:"kind"`
-	/*
-	 * Mandatory title of the progress operation. Used to briefly inform about
-	 * the kind of operation being performed.
-	 *
-	 * Examples: \"Indexing\" or \"Linking dependencies\".
-	 */
-	Title string `json:"title"`
-	/*
-	 * Controls if a cancel button should show to allow the user to cancel the
-	 * long running operation. Clients that don't support cancellation are allowed
-	 * to ignore the setting.
-	 */
-	Cancellable bool `json:"cancellable,omitempty"`
-	/*
-	 * Optional, more detailed associated progress message. Contains
-	 * complementary information to the `title`.
-	 *
-	 * Examples: \"3/25 files\", \"project/src/module2\", \"node_modules/some_dep\".
-	 * If unset, the previous progress message (if any) is still valid.
-	 */
-	Message string `json:"message,omitempty"`
-	/*
-	 * Optional progress percentage to display (value 100 is considered 100%).
-	 * If not provided infinite progress is assumed and clients are allowed
-	 * to ignore the `percentage` value in subsequent in report notifications.
-	 *
-	 * The value should be steadily rising. Clients are free to ignore values
-	 * that are not following this rule. The value range is [0, 100].
-	 */
-	Percentage uint32 `json:"percentage,omitempty"`
-}
-type WorkDoneProgressCancelParams struct { // line 2647
-	// The token to be used to report progress.
-	Token ProgressToken `json:"token"`
-}
-type WorkDoneProgressCreateParams struct { // line 2634
-	// The token to be used to report progress.
-	Token ProgressToken `json:"token"`
-}
-type WorkDoneProgressEnd struct { // line 6145
-	Kind string `json:"kind"`
-	/*
-	 * Optional, a final message indicating to for example indicate the outcome
-	 * of the operation.
-	 */
-	Message string `json:"message,omitempty"`
-}
-type WorkDoneProgressOptions struct { // line 2377
-	WorkDoneProgress bool `json:"workDoneProgress,omitempty"`
-}
-
-// created for And
-type WorkDoneProgressOptionsAndTextDocumentRegistrationOptions struct { // line 204
-	WorkDoneProgressOptions
-	TextDocumentRegistrationOptions
-}
-type WorkDoneProgressParams struct { // line 6263
-	// An optional token that a server can use to report work done progress.
-	WorkDoneToken ProgressToken `json:"workDoneToken,omitempty"`
-}
-type WorkDoneProgressReport struct { // line 6106
-	Kind string `json:"kind"`
-	/*
-	 * Controls enablement state of a cancel button.
-	 *
-	 * Clients that don't support cancellation or don't support controlling the button's
-	 * enablement state are allowed to ignore the property.
-	 */
-	Cancellable bool `json:"cancellable,omitempty"`
-	/*
-	 * Optional, more detailed associated progress message. Contains
-	 * complementary information to the `title`.
-	 *
-	 * Examples: \"3/25 files\", \"project/src/module2\", \"node_modules/some_dep\".
-	 * If unset, the previous progress message (if any) is still valid.
-	 */
-	Message string `json:"message,omitempty"`
-	/*
-	 * Optional progress percentage to display (value 100 is considered 100%).
-	 * If not provided infinite progress is assumed and clients are allowed
-	 * to ignore the `percentage` value in subsequent in report notifications.
-	 *
-	 * The value should be steadily rising. Clients are free to ignore values
-	 * that are not following this rule. The value range is [0, 100]
-	 */
-	Percentage uint32 `json:"percentage,omitempty"`
-}
-
-// created for Literal
-type Workspace6Gn struct { // line 8424
-	/*
-	 * The server supports workspace folder.
-	 *
-	 * @since 3.6.0
-	 */
-	WorkspaceFolders WorkspaceFolders5Gn `json:"workspaceFolders"`
-	/*
-	 * The server is interested in notifications/requests for operations on files.
-	 *
-	 * @since 3.16.0
-	 */
-	FileOperations FileOperationOptions `json:"fileOperations"`
-}
-
-// Workspace specific client capabilities.
-type WorkspaceClientCapabilities struct { // line 10210
-	/*
-	 * The client supports applying batch edits
-	 * to the workspace by supporting the request
-	 * 'workspace/applyEdit'
-	 */
-	ApplyEdit bool `json:"applyEdit,omitempty"`
-	// Capabilities specific to `WorkspaceEdit`s.
-	WorkspaceEdit *WorkspaceEditClientCapabilities `json:"workspaceEdit,omitempty"`
-	// Capabilities specific to the `workspace/didChangeConfiguration` notification.
-	DidChangeConfiguration DidChangeConfigurationClientCapabilities `json:"didChangeConfiguration,omitempty"`
-	// Capabilities specific to the `workspace/didChangeWatchedFiles` notification.
-	DidChangeWatchedFiles DidChangeWatchedFilesClientCapabilities `json:"didChangeWatchedFiles,omitempty"`
-	// Capabilities specific to the `workspace/symbol` request.
-	Symbol *WorkspaceSymbolClientCapabilities `json:"symbol,omitempty"`
-	// Capabilities specific to the `workspace/executeCommand` request.
-	ExecuteCommand *ExecuteCommandClientCapabilities `json:"executeCommand,omitempty"`
-	/*
-	 * The client has support for workspace folders.
-	 *
-	 * @since 3.6.0
-	 */
-	WorkspaceFolders bool `json:"workspaceFolders,omitempty"`
-	/*
-	 * The client supports `workspace/configuration` requests.
-	 *
-	 * @since 3.6.0
-	 */
-	Configuration bool `json:"configuration,omitempty"`
-	/*
-	 * Capabilities specific to the semantic token requests scoped to the
-	 * workspace.
-	 *
-	 * @since 3.16.0.
-	 */
-	SemanticTokens *SemanticTokensWorkspaceClientCapabilities `json:"semanticTokens,omitempty"`
-	/*
-	 * Capabilities specific to the code lens requests scoped to the
-	 * workspace.
-	 *
-	 * @since 3.16.0.
-	 */
-	CodeLens *CodeLensWorkspaceClientCapabilities `json:"codeLens,omitempty"`
-	/*
-	 * The client has support for file notifications/requests for user operations on files.
-	 *
-	 * Since 3.16.0
-	 */
-	FileOperations *FileOperationClientCapabilities `json:"fileOperations,omitempty"`
-	/*
-	 * Capabilities specific to the inline values requests scoped to the
-	 * workspace.
-	 *
-	 * @since 3.17.0.
-	 */
-	InlineValue *InlineValueWorkspaceClientCapabilities `json:"inlineValue,omitempty"`
-	/*
-	 * Capabilities specific to the inlay hint requests scoped to the
-	 * workspace.
-	 *
-	 * @since 3.17.0.
-	 */
-	InlayHint *InlayHintWorkspaceClientCapabilities `json:"inlayHint,omitempty"`
-	/*
-	 * Capabilities specific to the diagnostic requests scoped to the
-	 * workspace.
-	 *
-	 * @since 3.17.0.
-	 */
-	Diagnostics *DiagnosticWorkspaceClientCapabilities `json:"diagnostics,omitempty"`
-}
-
-/*
- * Parameters of the workspace diagnostic request.
- *
- * @since 3.17.0
- */
-type WorkspaceDiagnosticParams struct { // line 3899
-	// The additional identifier provided during registration.
-	Identifier string `json:"identifier,omitempty"`
-	/*
-	 * The currently known diagnostic reports with their
-	 * previous result ids.
-	 */
-	PreviousResultIds []PreviousResultID `json:"previousResultIds"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-/*
- * A workspace diagnostic report.
- *
- * @since 3.17.0
- */
-type WorkspaceDiagnosticReport struct { // line 3936
-	Items []WorkspaceDocumentDiagnosticReport `json:"items"`
-}
-
-/*
- * A partial result for a workspace diagnostic report.
- *
- * @since 3.17.0
- */
-type WorkspaceDiagnosticReportPartialResult struct { // line 3953
-	Items []WorkspaceDocumentDiagnosticReport `json:"items"`
-}
-
-/*
- * A workspace diagnostic document report.
- *
- * @since 3.17.0
- */
-type WorkspaceDocumentDiagnosticReport = Or_WorkspaceDocumentDiagnosticReport // (alias) line 14010
-/*
- * A workspace edit represents changes to many resources managed in the workspace. The edit
- * should either provide `changes` or `documentChanges`. If documentChanges are present
- * they are preferred over `changes` if the client can handle versioned document edits.
- *
- * Since version 3.13.0 a workspace edit can contain resource operations as well. If resource
- * operations are present clients need to execute the operations in the order in which they
- * are provided. So a workspace edit for example can consist of the following two changes:
- * (1) a create file a.txt and (2) a text document edit which insert text into file a.txt.
- *
- * An invalid sequence (e.g. (1) delete file a.txt and (2) insert text into file a.txt) will
- * cause failure of the operation. How the client recovers from the failure is described by
- * the client capability: `workspace.workspaceEdit.failureHandling`
- */
-type WorkspaceEdit struct { // line 3215
-	// Holds changes to existing resources.
-	Changes map[DocumentURI][]TextEdit `json:"changes,omitempty"`
-	/*
-	 * Depending on the client capability `workspace.workspaceEdit.resourceOperations` document changes
-	 * are either an array of `TextDocumentEdit`s to express changes to n different text documents
-	 * where each text document edit addresses a specific version of a text document. Or it can contain
-	 * above `TextDocumentEdit`s mixed with create, rename and delete file / folder operations.
-	 *
-	 * Whether a client supports versioned document edits is expressed via
-	 * `workspace.workspaceEdit.documentChanges` client capability.
-	 *
-	 * If a client neither supports `documentChanges` nor `workspace.workspaceEdit.resourceOperations` then
-	 * only plain `TextEdit`s using the `changes` property are supported.
-	 */
-	DocumentChanges []DocumentChanges `json:"documentChanges,omitempty"`
-	/*
-	 * A map of change annotations that can be referenced in `AnnotatedTextEdit`s or create, rename and
-	 * delete file / folder operations.
-	 *
-	 * Whether clients honor this property depends on the client capability `workspace.changeAnnotationSupport`.
-	 *
-	 * @since 3.16.0
-	 */
-	ChangeAnnotations map[ChangeAnnotationIdentifier]ChangeAnnotation `json:"changeAnnotations,omitempty"`
-}
-type WorkspaceEditClientCapabilities struct { // line 10794
-	// The client supports versioned document changes in `WorkspaceEdit`s
-	DocumentChanges bool `json:"documentChanges,omitempty"`
-	/*
-	 * The resource operations the client supports. Clients should at least
-	 * support 'create', 'rename' and 'delete' files and folders.
-	 *
-	 * @since 3.13.0
-	 */
-	ResourceOperations []ResourceOperationKind `json:"resourceOperations,omitempty"`
-	/*
-	 * The failure handling strategy of a client if applying the workspace edit
-	 * fails.
-	 *
-	 * @since 3.13.0
-	 */
-	FailureHandling FailureHandlingKind `json:"failureHandling,omitempty"`
-	/*
-	 * Whether the client normalizes line endings to the client specific
-	 * setting.
-	 * If set to `true` the client will normalize line ending characters
-	 * in a workspace edit to the client-specified new line
-	 * character.
-	 *
-	 * @since 3.16.0
-	 */
-	NormalizesLineEndings bool `json:"normalizesLineEndings,omitempty"`
-	/*
-	 * Whether the client in general supports change annotations on text edits,
-	 * create file, rename file and delete file changes.
-	 *
-	 * @since 3.16.0
-	 */
-	ChangeAnnotationSupport *PChangeAnnotationSupportPWorkspaceEdit `json:"changeAnnotationSupport,omitempty"`
-}
-
-// A workspace folder inside a client.
-type WorkspaceFolder struct { // line 2171
-	// The associated URI for this workspace folder.
-	URI URI `json:"uri"`
-	/*
-	 * The name of the workspace folder. Used to refer to this
-	 * workspace folder in the user interface.
-	 */
-	Name string `json:"name"`
-}
-type WorkspaceFolders5Gn struct { // line 9959
-	// The server has support for workspace folders
-	Supported bool `json:"supported,omitempty"`
-	/*
-	 * Whether the server wants to receive workspace folder
-	 * change notifications.
-	 *
-	 * If a string is provided the string is treated as an ID
-	 * under which the notification is registered on the client
-	 * side. The ID can be used to unregister for these events
-	 * using the `client/unregisterCapability` request.
-	 */
-	ChangeNotifications string `json:"changeNotifications,omitempty"`
-}
-
-// The workspace folder change event.
-type WorkspaceFoldersChangeEvent struct { // line 6373
-	// The array of added workspace folders
-	Added []WorkspaceFolder `json:"added"`
-	// The array of the removed workspace folders
-	Removed []WorkspaceFolder `json:"removed"`
-}
-type WorkspaceFoldersInitializeParams struct { // line 7802
-	/*
-	 * The workspace folders configured in the client when the server starts.
-	 *
-	 * This property is only available if the client supports workspace folders.
-	 * It can be `null` if the client supports workspace folders but none are
-	 * configured.
-	 *
-	 * @since 3.6.0
-	 */
-	WorkspaceFolders []WorkspaceFolder `json:"workspaceFolders,omitempty"`
-}
-type WorkspaceFoldersServerCapabilities struct { // line 9959
-	// The server has support for workspace folders
-	Supported bool `json:"supported,omitempty"`
-	/*
-	 * Whether the server wants to receive workspace folder
-	 * change notifications.
-	 *
-	 * If a string is provided the string is treated as an ID
-	 * under which the notification is registered on the client
-	 * side. The ID can be used to unregister for these events
-	 * using the `client/unregisterCapability` request.
-	 */
-	ChangeNotifications string `json:"changeNotifications,omitempty"`
-}
-
-/*
- * A full document diagnostic report for a workspace diagnostic result.
- *
- * @since 3.17.0
- */
-type WorkspaceFullDocumentDiagnosticReport struct { // line 9542
-	// The URI for which diagnostic information is reported.
-	URI DocumentURI `json:"uri"`
-	/*
-	 * The version number for which the diagnostics are reported.
-	 * If the document is not marked as open `null` can be provided.
-	 */
-	Version int32 `json:"version"`
-	FullDocumentDiagnosticReport
-}
-
-/*
- * A special workspace symbol that supports locations without a range.
- *
- * See also SymbolInformation.
- *
- * @since 3.17.0
- */
-type WorkspaceSymbol struct { // line 5534
-	/*
-	 * The location of the symbol. Whether a server is allowed to
-	 * return a location without a range depends on the client
-	 * capability `workspace.symbol.resolveSupport`.
-	 *
-	 * See SymbolInformation#location for more details.
-	 */
-	Location OrPLocation_workspace_symbol `json:"location"`
-	/*
-	 * A data entry field that is preserved on a workspace symbol between a
-	 * workspace symbol request and a workspace symbol resolve request.
-	 */
-	Data interface{} `json:"data,omitempty"`
-	BaseSymbolInformation
-}
-
-// Client capabilities for a [WorkspaceSymbolRequest](#WorkspaceSymbolRequest).
-type WorkspaceSymbolClientCapabilities struct { // line 10901
-	// Symbol request supports dynamic registration.
-	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
-	// Specific capabilities for the `SymbolKind` in the `workspace/symbol` request.
-	SymbolKind *PSymbolKindPSymbol `json:"symbolKind,omitempty"`
-	/*
-	 * The client supports tags on `SymbolInformation`.
-	 * Clients supporting tags have to handle unknown tags gracefully.
-	 *
-	 * @since 3.16.0
-	 */
-	TagSupport *PTagSupportPSymbol `json:"tagSupport,omitempty"`
-	/*
-	 * The client support partial workspace symbols. The client will send the
-	 * request `workspaceSymbol/resolve` to the server to resolve additional
-	 * properties.
-	 *
-	 * @since 3.17.0
-	 */
-	ResolveSupport *PResolveSupportPSymbol `json:"resolveSupport,omitempty"`
-}
-
-// Server capabilities for a [WorkspaceSymbolRequest](#WorkspaceSymbolRequest).
-type WorkspaceSymbolOptions struct { // line 9125
-	/*
-	 * The server provides support to resolve additional
-	 * information for a workspace symbol.
-	 *
-	 * @since 3.17.0
-	 */
-	ResolveProvider bool `json:"resolveProvider,omitempty"`
-	WorkDoneProgressOptions
-}
-
-// The parameters of a [WorkspaceSymbolRequest](#WorkspaceSymbolRequest).
-type WorkspaceSymbolParams struct { // line 5510
-	/*
-	 * A query string to filter symbols by. Clients may send an empty
-	 * string here to request all symbols.
-	 */
-	Query string `json:"query"`
-	WorkDoneProgressParams
-	PartialResultParams
-}
-
-// Registration options for a [WorkspaceSymbolRequest](#WorkspaceSymbolRequest).
-type WorkspaceSymbolRegistrationOptions struct { // line 5583
-	WorkspaceSymbolOptions
-}
-
-/*
- * An unchanged document diagnostic report for a workspace diagnostic result.
- *
- * @since 3.17.0
- */
-type WorkspaceUnchangedDocumentDiagnosticReport struct { // line 9580
-	// The URI for which diagnostic information is reported.
-	URI DocumentURI `json:"uri"`
-	/*
-	 * The version number for which the diagnostics are reported.
-	 * If the document is not marked as open `null` can be provided.
-	 */
-	Version int32 `json:"version"`
-	UnchangedDocumentDiagnosticReport
-}
-
-// The initialize parameters
-type XInitializeParams struct { // line 7655
-	/*
-	 * The process Id of the parent process that started
-	 * the server.
-	 *
-	 * Is `null` if the process has not been started by another process.
-	 * If the parent process is not alive then the server should exit.
-	 */
-	ProcessID int32 `json:"processId"`
-	/*
-	 * Information about the client
-	 *
-	 * @since 3.15.0
-	 */
-	ClientInfo Msg_XInitializeParams_clientInfo `json:"clientInfo,omitempty"`
-	/*
-	 * The locale the client is currently showing the user interface
-	 * in. This must not necessarily be the locale of the operating
-	 * system.
-	 *
-	 * Uses IETF language tags as the value's syntax
-	 * (See https://en.wikipedia.org/wiki/IETF_language_tag)
-	 *
-	 * @since 3.16.0
-	 */
-	Locale string `json:"locale,omitempty"`
-	/*
-	 * The rootPath of the workspace. Is null
-	 * if no folder is open.
-	 *
-	 * @deprecated in favour of rootUri.
-	 */
-	RootPath string `json:"rootPath,omitempty"`
-	/*
-	 * The rootUri of the workspace. Is null if no
-	 * folder is open. If both `rootPath` and `rootUri` are set
-	 * `rootUri` wins.
-	 *
-	 * @deprecated in favour of workspaceFolders.
-	 */
-	RootURI DocumentURI `json:"rootUri"`
-	// The capabilities provided by the client (editor or tool)
-	Capabilities ClientCapabilities `json:"capabilities"`
-	// User provided initialization options.
-	InitializationOptions interface{} `json:"initializationOptions,omitempty"`
-	// The initial trace setting. If omitted trace is disabled ('off').
-	Trace string `json:"trace,omitempty"`
-}
-
-// The initialize parameters
-type _InitializeParams struct { // line 7655
-	/*
-	 * The process Id of the parent process that started
-	 * the server.
-	 *
-	 * Is `null` if the process has not been started by another process.
-	 * If the parent process is not alive then the server should exit.
-	 */
-	ProcessID int32 `json:"processId"`
-	/*
-	 * Information about the client
-	 *
-	 * @since 3.15.0
-	 */
-	ClientInfo *Msg_XInitializeParams_clientInfo `json:"clientInfo,omitempty"`
-	/*
-	 * The locale the client is currently showing the user interface
-	 * in. This must not necessarily be the locale of the operating
-	 * system.
-	 *
-	 * Uses IETF language tags as the value's syntax
-	 * (See https://en.wikipedia.org/wiki/IETF_language_tag)
-	 *
-	 * @since 3.16.0
-	 */
-	Locale string `json:"locale,omitempty"`
-	/*
-	 * The rootPath of the workspace. Is null
-	 * if no folder is open.
-	 *
-	 * @deprecated in favour of rootUri.
-	 */
-	RootPath string `json:"rootPath,omitempty"`
-	/*
-	 * The rootUri of the workspace. Is null if no
-	 * folder is open. If both `rootPath` and `rootUri` are set
-	 * `rootUri` wins.
-	 *
-	 * @deprecated in favour of workspaceFolders.
-	 */
-	RootURI DocumentURI `json:"rootUri"`
-	// The capabilities provided by the client (editor or tool)
-	Capabilities ClientCapabilities `json:"capabilities"`
-	// User provided initialization options.
-	InitializationOptions interface{} `json:"initializationOptions,omitempty"`
-	// The initial trace setting. If omitted trace is disabled ('off').
-	Trace string `json:"trace,omitempty"`
-}
-
-const (
-	// A set of predefined code action kinds
-	// Empty kind.
-	Empty CodeActionKind = "" // line 13359
-	// Base kind for quickfix actions: 'quickfix'
-	QuickFix CodeActionKind = "quickfix" // line 13364
-	// Base kind for refactoring actions: 'refactor'
-	Refactor CodeActionKind = "refactor" // line 13369
-	/*
-	 * Base kind for refactoring extraction actions: 'refactor.extract'
-	 *
-	 * Example extract actions:
-	 *
-	 * - Extract method
-	 * - Extract function
-	 * - Extract variable
-	 * - Extract interface from class
-	 * - ...
-	 */
-	RefactorExtract CodeActionKind = "refactor.extract" // line 13374
-	/*
-	 * Base kind for refactoring inline actions: 'refactor.inline'
-	 *
-	 * Example inline actions:
-	 *
-	 * - Inline function
-	 * - Inline variable
-	 * - Inline constant
-	 * - ...
-	 */
-	RefactorInline CodeActionKind = "refactor.inline" // line 13379
-	/*
-	 * Base kind for refactoring rewrite actions: 'refactor.rewrite'
-	 *
-	 * Example rewrite actions:
-	 *
-	 * - Convert JavaScript function to class
-	 * - Add or remove parameter
-	 * - Encapsulate field
-	 * - Make method static
-	 * - Move method to base class
-	 * - ...
-	 */
-	RefactorRewrite CodeActionKind = "refactor.rewrite" // line 13384
-	/*
-	 * Base kind for source actions: `source`
-	 *
-	 * Source code actions apply to the entire file.
-	 */
-	Source CodeActionKind = "source" // line 13389
-	// Base kind for an organize imports source action: `source.organizeImports`
-	SourceOrganizeImports CodeActionKind = "source.organizeImports" // line 13394
-	/*
-	 * Base kind for auto-fix source actions: `source.fixAll`.
-	 *
-	 * Fix all actions automatically fix errors that have a clear fix that do not require user input.
-	 * They should not suppress errors or perform unsafe fixes such as generating new types or classes.
-	 *
-	 * @since 3.15.0
-	 */
-	SourceFixAll CodeActionKind = "source.fixAll" // line 13399
-	/*
-	 * The reason why code actions were requested.
-	 *
-	 * @since 3.17.0
-	 */
-	// Code actions were explicitly requested by the user or by an extension.
-	CodeActionInvoked CodeActionTriggerKind = 1 // line 13639
-	/*
-	 * Code actions were requested automatically.
-	 *
-	 * This typically happens when current selection in a file changes, but can
-	 * also be triggered when file content changes.
-	 */
-	CodeActionAutomatic CodeActionTriggerKind = 2 // line 13644
-	// The kind of a completion entry.
-	TextCompletion          CompletionItemKind = 1  // line 13167
-	MethodCompletion        CompletionItemKind = 2  // line 13171
-	FunctionCompletion      CompletionItemKind = 3  // line 13175
-	ConstructorCompletion   CompletionItemKind = 4  // line 13179
-	FieldCompletion         CompletionItemKind = 5  // line 13183
-	VariableCompletion      CompletionItemKind = 6  // line 13187
-	ClassCompletion         CompletionItemKind = 7  // line 13191
-	InterfaceCompletion     CompletionItemKind = 8  // line 13195
-	ModuleCompletion        CompletionItemKind = 9  // line 13199
-	PropertyCompletion      CompletionItemKind = 10 // line 13203
-	UnitCompletion          CompletionItemKind = 11 // line 13207
-	ValueCompletion         CompletionItemKind = 12 // line 13211
-	EnumCompletion          CompletionItemKind = 13 // line 13215
-	KeywordCompletion       CompletionItemKind = 14 // line 13219
-	SnippetCompletion       CompletionItemKind = 15 // line 13223
-	ColorCompletion         CompletionItemKind = 16 // line 13227
-	FileCompletion          CompletionItemKind = 17 // line 13231
-	ReferenceCompletion     CompletionItemKind = 18 // line 13235
-	FolderCompletion        CompletionItemKind = 19 // line 13239
-	EnumMemberCompletion    CompletionItemKind = 20 // line 13243
-	ConstantCompletion      CompletionItemKind = 21 // line 13247
-	StructCompletion        CompletionItemKind = 22 // line 13251
-	EventCompletion         CompletionItemKind = 23 // line 13255
-	OperatorCompletion      CompletionItemKind = 24 // line 13259
-	TypeParameterCompletion CompletionItemKind = 25 // line 13263
-	/*
-	 * Completion item tags are extra annotations that tweak the rendering of a completion
-	 * item.
-	 *
-	 * @since 3.15.0
-	 */
-	// Render a completion as obsolete, usually using a strike-out.
-	ComplDeprecated CompletionItemTag = 1 // line 13277
-	// How a completion was triggered
-	/*
-	 * Completion was triggered by typing an identifier (24x7 code
-	 * complete), manual invocation (e.g Ctrl+Space) or via API.
-	 */
-	Invoked CompletionTriggerKind = 1 // line 13588
-	/*
-	 * Completion was triggered by a trigger character specified by
-	 * the `triggerCharacters` properties of the `CompletionRegistrationOptions`.
-	 */
-	TriggerCharacter CompletionTriggerKind = 2 // line 13593
-	// Completion was re-triggered as current completion list is incomplete
-	TriggerForIncompleteCompletions CompletionTriggerKind = 3 // line 13598
-	// The diagnostic's severity.
-	// Reports an error.
-	SeverityError DiagnosticSeverity = 1 // line 13537
-	// Reports a warning.
-	SeverityWarning DiagnosticSeverity = 2 // line 13542
-	// Reports an information.
-	SeverityInformation DiagnosticSeverity = 3 // line 13547
-	// Reports a hint.
-	SeverityHint DiagnosticSeverity = 4 // line 13552
-	/*
-	 * The diagnostic tags.
-	 *
-	 * @since 3.15.0
-	 */
-	/*
-	 * Unused or unnecessary code.
-	 *
-	 * Clients are allowed to render diagnostics with this tag faded out instead of having
-	 * an error squiggle.
-	 */
-	Unnecessary DiagnosticTag = 1 // line 13567
-	/*
-	 * Deprecated or obsolete code.
-	 *
-	 * Clients are allowed to rendered diagnostics with this tag strike through.
-	 */
-	Deprecated DiagnosticTag = 2 // line 13572
-	/*
-	 * The document diagnostic report kinds.
-	 *
-	 * @since 3.17.0
-	 */
-	/*
-	 * A diagnostic report with a full
-	 * set of problems.
-	 */
-	DiagnosticFull DocumentDiagnosticReportKind = "full" // line 12755
-	/*
-	 * A report indicating that the last
-	 * returned report is still accurate.
-	 */
-	DiagnosticUnchanged DocumentDiagnosticReportKind = "unchanged" // line 12760
-	// A document highlight kind.
-	// A textual occurrence.
-	Text DocumentHighlightKind = 1 // line 13334
-	// Read-access of a symbol, like reading a variable.
-	Read DocumentHighlightKind = 2 // line 13339
-	// Write-access of a symbol, like writing to a variable.
-	Write DocumentHighlightKind = 3 // line 13344
-	// Predefined error codes.
-	ParseError     ErrorCodes = -32700 // line 12776
-	InvalidRequest ErrorCodes = -32600 // line 12780
-	MethodNotFound ErrorCodes = -32601 // line 12784
-	InvalidParams  ErrorCodes = -32602 // line 12788
-	InternalError  ErrorCodes = -32603 // line 12792
-	/*
-	 * Error code indicating that a server received a notification or
-	 * request before the server has received the `initialize` request.
-	 */
-	ServerNotInitialized ErrorCodes = -32002 // line 12796
-	UnknownErrorCode     ErrorCodes = -32001 // line 12801
-	/*
-	 * Applying the workspace change is simply aborted if one of the changes provided
-	 * fails. All operations executed before the failing operation stay executed.
-	 */
-	Abort FailureHandlingKind = "abort" // line 13726
-	/*
-	 * All operations are executed transactional. That means they either all
-	 * succeed or no changes at all are applied to the workspace.
-	 */
-	Transactional FailureHandlingKind = "transactional" // line 13731
-	/*
-	 * If the workspace edit contains only textual file changes they are executed transactional.
-	 * If resource changes (create, rename or delete file) are part of the change the failure
-	 * handling strategy is abort.
-	 */
-	TextOnlyTransactional FailureHandlingKind = "textOnlyTransactional" // line 13736
-	/*
-	 * The client tries to undo the operations already executed. But there is no
-	 * guarantee that this is succeeding.
-	 */
-	Undo FailureHandlingKind = "undo" // line 13741
-	// The file event type
-	// The file got created.
-	Created FileChangeType = 1 // line 13487
-	// The file got changed.
-	Changed FileChangeType = 2 // line 13492
-	// The file got deleted.
-	Deleted FileChangeType = 3 // line 13497
-	/*
-	 * A pattern kind describing if a glob pattern matches a file a folder or
-	 * both.
-	 *
-	 * @since 3.16.0
-	 */
-	// The pattern matches a file only.
-	FilePattern FileOperationPatternKind = "file" // line 13660
-	// The pattern matches a folder only.
-	FolderPattern FileOperationPatternKind = "folder" // line 13665
-	// A set of predefined range kinds.
-	// Folding range for a comment
-	Comment FoldingRangeKind = "comment" // line 12848
-	// Folding range for an import or include
-	Imports FoldingRangeKind = "imports" // line 12853
-	// Folding range for a region (e.g. `#region`)
-	Region FoldingRangeKind = "region" // line 12858
-	/*
-	 * Inlay hint kinds.
-	 *
-	 * @since 3.17.0
-	 */
-	// An inlay hint that for a type annotation.
-	Type InlayHintKind = 1 // line 13066
-	// An inlay hint that is for a parameter.
-	Parameter InlayHintKind = 2 // line 13071
-	/*
-	 * Defines whether the insert text in a completion item should be interpreted as
-	 * plain text or a snippet.
-	 */
-	// The primary text to be inserted is treated as a plain string.
-	PlainTextTextFormat InsertTextFormat = 1 // line 13293
-	/*
-	 * The primary text to be inserted is treated as a snippet.
-	 *
-	 * A snippet can define tab stops and placeholders with `$1`, `$2`
-	 * and `${3:foo}`. `$0` defines the final tab stop, it defaults to
-	 * the end of the snippet. Placeholders with equal identifiers are linked,
-	 * that is typing in one will update others too.
-	 *
-	 * See also: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#snippet_syntax
-	 */
-	SnippetTextFormat InsertTextFormat = 2 // line 13298
-	/*
-	 * How whitespace and indentation is handled during completion
-	 * item insertion.
-	 *
-	 * @since 3.16.0
-	 */
-	/*
-	 * The insertion or replace strings is taken as it is. If the
-	 * value is multi line the lines below the cursor will be
-	 * inserted using the indentation defined in the string value.
-	 * The client will not apply any kind of adjustments to the
-	 * string.
-	 */
-	AsIs InsertTextMode = 1 // line 13313
-	/*
-	 * The editor adjusts leading whitespace of new lines so that
-	 * they match the indentation up to the cursor of the line for
-	 * which the item is accepted.
-	 *
-	 * Consider a line like this: <2tabs><cursor><3tabs>foo. Accepting a
-	 * multi line completion item is indented using 2 tabs and all
-	 * following lines inserted will be indented using 2 tabs as well.
-	 */
-	AdjustIndentation InsertTextMode = 2 // line 13318
-	/*
-	 * A request failed but it was syntactically correct, e.g the
-	 * method name was known and the parameters were valid. The error
-	 * message should contain human readable information about why
-	 * the request failed.
-	 *
-	 * @since 3.17.0
-	 */
-	RequestFailed LSPErrorCodes = -32803 // line 12816
-	/*
-	 * The server cancelled the request. This error code should
-	 * only be used for requests that explicitly support being
-	 * server cancellable.
-	 *
-	 * @since 3.17.0
-	 */
-	ServerCancelled LSPErrorCodes = -32802 // line 12822
-	/*
-	 * The server detected that the content of a document got
-	 * modified outside normal conditions. A server should
-	 * NOT send this error code if it detects a content change
-	 * in it unprocessed messages. The result even computed
-	 * on an older state might still be useful for the client.
-	 *
-	 * If a client decides that a result is not of any use anymore
-	 * the client should cancel the request.
-	 */
-	ContentModified LSPErrorCodes = -32801 // line 12828
-	/*
-	 * The client has canceled a request and a server as detected
-	 * the cancel.
-	 */
-	RequestCancelled LSPErrorCodes = -32800 // line 12833
-	/*
-	 * Describes the content type that a client supports in various
-	 * result literals like `Hover`, `ParameterInfo` or `CompletionItem`.
-	 *
-	 * Please note that `MarkupKinds` must not start with a `$`. This kinds
-	 * are reserved for internal usage.
-	 */
-	// Plain text is supported as a content format
-	PlainText MarkupKind = "plaintext" // line 13440
-	// Markdown is supported as a content format
-	Markdown MarkupKind = "markdown" // line 13445
-	// The message type
-	// An error message.
-	Error MessageType = 1 // line 13087
-	// A warning message.
-	Warning MessageType = 2 // line 13092
-	// An information message.
-	Info MessageType = 3 // line 13097
-	// A log message.
-	Log MessageType = 4 // line 13102
-	/*
-	 * The moniker kind.
-	 *
-	 * @since 3.16.0
-	 */
-	// The moniker represent a symbol that is imported into a project
-	Import MonikerKind = "import" // line 13040
-	// The moniker represents a symbol that is exported from a project
-	Export MonikerKind = "export" // line 13045
-	/*
-	 * The moniker represents a symbol that is local to a project (e.g. a local
-	 * variable of a function, a class not visible outside the project, ...)
-	 */
-	Local MonikerKind = "local" // line 13050
-	/*
-	 * A notebook cell kind.
-	 *
-	 * @since 3.17.0
-	 */
-	// A markup-cell is formatted source that is used for display.
-	Markup NotebookCellKind = 1 // line 13681
-	// A code-cell is source code.
-	Code NotebookCellKind = 2 // line 13686
-	/*
-	 * A set of predefined position encoding kinds.
-	 *
-	 * @since 3.17.0
-	 */
-	// Character offsets count UTF-8 code units.
-	UTF8 PositionEncodingKind = "utf-8" // line 13460
-	/*
-	 * Character offsets count UTF-16 code units.
-	 *
-	 * This is the default and must always be supported
-	 * by servers
-	 */
-	UTF16 PositionEncodingKind = "utf-16" // line 13465
-	/*
-	 * Character offsets count UTF-32 code units.
-	 *
-	 * Implementation note: these are the same as Unicode code points,
-	 * so this `PositionEncodingKind` may also be used for an
-	 * encoding-agnostic representation of character offsets.
-	 */
-	UTF32 PositionEncodingKind = "utf-32" // line 13470
-	// Supports creating new files and folders.
-	Create ResourceOperationKind = "create" // line 13702
-	// Supports renaming existing files and folders.
-	Rename ResourceOperationKind = "rename" // line 13707
-	// Supports deleting existing files and folders.
-	Delete ResourceOperationKind = "delete" // line 13712
-	/*
-	 * A set of predefined token modifiers. This set is not fixed
-	 * an clients can specify additional token types via the
-	 * corresponding client capabilities.
-	 *
-	 * @since 3.16.0
-	 */
-	ModDeclaration    SemanticTokenModifiers = "declaration"    // line 12703
-	ModDefinition     SemanticTokenModifiers = "definition"     // line 12707
-	ModReadonly       SemanticTokenModifiers = "readonly"       // line 12711
-	ModStatic         SemanticTokenModifiers = "static"         // line 12715
-	ModDeprecated     SemanticTokenModifiers = "deprecated"     // line 12719
-	ModAbstract       SemanticTokenModifiers = "abstract"       // line 12723
-	ModAsync          SemanticTokenModifiers = "async"          // line 12727
-	ModModification   SemanticTokenModifiers = "modification"   // line 12731
-	ModDocumentation  SemanticTokenModifiers = "documentation"  // line 12735
-	ModDefaultLibrary SemanticTokenModifiers = "defaultLibrary" // line 12739
-	/*
-	 * A set of predefined token types. This set is not fixed
-	 * an clients can specify additional token types via the
-	 * corresponding client capabilities.
-	 *
-	 * @since 3.16.0
-	 */
-	NamespaceType SemanticTokenTypes = "namespace" // line 12596
-	/*
-	 * Represents a generic type. Acts as a fallback for types which can't be mapped to
-	 * a specific type like class or enum.
-	 */
-	TypeType          SemanticTokenTypes = "type"          // line 12600
-	ClassType         SemanticTokenTypes = "class"         // line 12605
-	EnumType          SemanticTokenTypes = "enum"          // line 12609
-	InterfaceType     SemanticTokenTypes = "interface"     // line 12613
-	StructType        SemanticTokenTypes = "struct"        // line 12617
-	TypeParameterType SemanticTokenTypes = "typeParameter" // line 12621
-	ParameterType     SemanticTokenTypes = "parameter"     // line 12625
-	VariableType      SemanticTokenTypes = "variable"      // line 12629
-	PropertyType      SemanticTokenTypes = "property"      // line 12633
-	EnumMemberType    SemanticTokenTypes = "enumMember"    // line 12637
-	EventType         SemanticTokenTypes = "event"         // line 12641
-	FunctionType      SemanticTokenTypes = "function"      // line 12645
-	MethodType        SemanticTokenTypes = "method"        // line 12649
-	MacroType         SemanticTokenTypes = "macro"         // line 12653
-	KeywordType       SemanticTokenTypes = "keyword"       // line 12657
-	ModifierType      SemanticTokenTypes = "modifier"      // line 12661
-	CommentType       SemanticTokenTypes = "comment"       // line 12665
-	StringType        SemanticTokenTypes = "string"        // line 12669
-	NumberType        SemanticTokenTypes = "number"        // line 12673
-	RegexpType        SemanticTokenTypes = "regexp"        // line 12677
-	OperatorType      SemanticTokenTypes = "operator"      // line 12681
-	// @since 3.17.0
-	DecoratorType SemanticTokenTypes = "decorator" // line 12685
-	/*
-	 * How a signature help was triggered.
-	 *
-	 * @since 3.15.0
-	 */
-	// Signature help was invoked manually by the user or by a command.
-	SigInvoked SignatureHelpTriggerKind = 1 // line 13613
-	// Signature help was triggered by a trigger character.
-	SigTriggerCharacter SignatureHelpTriggerKind = 2 // line 13618
-	// Signature help was triggered by the cursor moving or by the document content changing.
-	SigContentChange SignatureHelpTriggerKind = 3 // line 13623
-	// A symbol kind.
-	File          SymbolKind = 1  // line 12874
-	Module        SymbolKind = 2  // line 12878
-	Namespace     SymbolKind = 3  // line 12882
-	Package       SymbolKind = 4  // line 12886
-	Class         SymbolKind = 5  // line 12890
-	Method        SymbolKind = 6  // line 12894
-	Property      SymbolKind = 7  // line 12898
-	Field         SymbolKind = 8  // line 12902
-	Constructor   SymbolKind = 9  // line 12906
-	Enum          SymbolKind = 10 // line 12910
-	Interface     SymbolKind = 11 // line 12914
-	Function      SymbolKind = 12 // line 12918
-	Variable      SymbolKind = 13 // line 12922
-	Constant      SymbolKind = 14 // line 12926
-	String        SymbolKind = 15 // line 12930
-	Number        SymbolKind = 16 // line 12934
-	Boolean       SymbolKind = 17 // line 12938
-	Array         SymbolKind = 18 // line 12942
-	Object        SymbolKind = 19 // line 12946
-	Key           SymbolKind = 20 // line 12950
-	Null          SymbolKind = 21 // line 12954
-	EnumMember    SymbolKind = 22 // line 12958
-	Struct        SymbolKind = 23 // line 12962
-	Event         SymbolKind = 24 // line 12966
-	Operator      SymbolKind = 25 // line 12970
-	TypeParameter SymbolKind = 26 // line 12974
-	/*
-	 * Symbol tags are extra annotations that tweak the rendering of a symbol.
-	 *
-	 * @since 3.16
-	 */
-	// Render a symbol as obsolete, usually using a strike-out.
-	DeprecatedSymbol SymbolTag = 1 // line 12988
-	// Represents reasons why a text document is saved.
-	/*
-	 * Manually triggered, e.g. by the user pressing save, by starting debugging,
-	 * or by an API call.
-	 */
-	Manual TextDocumentSaveReason = 1 // line 13142
-	// Automatic after a delay.
-	AfterDelay TextDocumentSaveReason = 2 // line 13147
-	// When the editor lost focus.
-	FocusOut TextDocumentSaveReason = 3 // line 13152
-	/*
-	 * Defines how the host (editor) should sync
-	 * document changes to the language server.
-	 */
-	// Documents should not be synced at all.
-	None TextDocumentSyncKind = 0 // line 13117
-	/*
-	 * Documents are synced by always sending the full content
-	 * of the document.
-	 */
-	Full TextDocumentSyncKind = 1 // line 13122
-	/*
-	 * Documents are synced by sending the full content on open.
-	 * After that only incremental updates to the document are
-	 * send.
-	 */
-	Incremental TextDocumentSyncKind = 2          // line 13127
-	Relative    TokenFormat          = "relative" // line 13769
-	// Turn tracing off.
-	Off TraceValues = "off" // line 13416
-	// Trace messages only.
-	Messages TraceValues = "messages" // line 13421
-	// Verbose message tracing.
-	Verbose TraceValues = "verbose" // line 13426
-	/*
-	 * Moniker uniqueness level to define scope of the moniker.
-	 *
-	 * @since 3.16.0
-	 */
-	// The moniker is only unique inside a document
-	Document UniquenessLevel = "document" // line 13004
-	// The moniker is unique inside a project for which a dump got created
-	Project UniquenessLevel = "project" // line 13009
-	// The moniker is unique inside the group to which a project belongs
-	Group UniquenessLevel = "group" // line 13014
-	// The moniker is unique inside the moniker scheme.
-	Scheme UniquenessLevel = "scheme" // line 13019
-	// The moniker is globally unique
-	Global UniquenessLevel = "global" // line 13024
-	// Interested in create events.
-	WatchCreate WatchKind = 1 // line 13512
-	// Interested in change events
-	WatchChange WatchKind = 2 // line 13517
-	// Interested in delete events
-	WatchDelete WatchKind = 4 // line 13522
-)
diff -urN a/gopls/internal/lsp/protocol/tsserver.go b/gopls/internal/lsp/protocol/tsserver.go
--- a/gopls/internal/lsp/protocol/tsserver.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/tsserver.go	1969-12-31 16:00:00
@@ -1,1186 +0,0 @@
-// Copyright 2019-2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package protocol
-
-// Code generated from version 3.17.0 of protocol/metaModel.json.
-// git hash 8de18faed635819dd2bc631d2c26ce4a18f7cf4a (as of Fri Sep 16 13:04:31 2022)
-// Code generated; DO NOT EDIT.
-
-import (
-	"context"
-	"encoding/json"
-
-	"golang.org/x/tools/internal/jsonrpc2"
-)
-
-type Server interface {
-	Progress(context.Context, *ProgressParams) error                                                       // $/progress
-	SetTrace(context.Context, *SetTraceParams) error                                                       // $/setTrace
-	IncomingCalls(context.Context, *CallHierarchyIncomingCallsParams) ([]CallHierarchyIncomingCall, error) // callHierarchy/incomingCalls
-	OutgoingCalls(context.Context, *CallHierarchyOutgoingCallsParams) ([]CallHierarchyOutgoingCall, error) // callHierarchy/outgoingCalls
-	ResolveCodeAction(context.Context, *CodeAction) (*CodeAction, error)                                   // codeAction/resolve
-	ResolveCodeLens(context.Context, *CodeLens) (*CodeLens, error)                                         // codeLens/resolve
-	ResolveCompletionItem(context.Context, *CompletionItem) (*CompletionItem, error)                       // completionItem/resolve
-	ResolveDocumentLink(context.Context, *DocumentLink) (*DocumentLink, error)                             // documentLink/resolve
-	Exit(context.Context) error                                                                            // exit
-	Initialize(context.Context, *ParamInitialize) (*InitializeResult, error)                               // initialize
-	Initialized(context.Context, *InitializedParams) error                                                 // initialized
-	Resolve(context.Context, *InlayHint) (*InlayHint, error)                                               // inlayHint/resolve
-	DidChangeNotebookDocument(context.Context, *DidChangeNotebookDocumentParams) error                     // notebookDocument/didChange
-	DidCloseNotebookDocument(context.Context, *DidCloseNotebookDocumentParams) error                       // notebookDocument/didClose
-	DidOpenNotebookDocument(context.Context, *DidOpenNotebookDocumentParams) error                         // notebookDocument/didOpen
-	DidSaveNotebookDocument(context.Context, *DidSaveNotebookDocumentParams) error                         // notebookDocument/didSave
-	Shutdown(context.Context) error                                                                        // shutdown
-	CodeAction(context.Context, *CodeActionParams) ([]CodeAction, error)                                   // textDocument/codeAction
-	CodeLens(context.Context, *CodeLensParams) ([]CodeLens, error)                                         // textDocument/codeLens
-	ColorPresentation(context.Context, *ColorPresentationParams) ([]ColorPresentation, error)              // textDocument/colorPresentation
-	Completion(context.Context, *CompletionParams) (*CompletionList, error)                                // textDocument/completion
-	Declaration(context.Context, *DeclarationParams) (*Or_textDocument_declaration, error)                 // textDocument/declaration
-	Definition(context.Context, *DefinitionParams) ([]Location, error)                                     // textDocument/definition
-	Diagnostic(context.Context, *string) (*string, error)                                                  // textDocument/diagnostic
-	DidChange(context.Context, *DidChangeTextDocumentParams) error                                         // textDocument/didChange
-	DidClose(context.Context, *DidCloseTextDocumentParams) error                                           // textDocument/didClose
-	DidOpen(context.Context, *DidOpenTextDocumentParams) error                                             // textDocument/didOpen
-	DidSave(context.Context, *DidSaveTextDocumentParams) error                                             // textDocument/didSave
-	DocumentColor(context.Context, *DocumentColorParams) ([]ColorInformation, error)                       // textDocument/documentColor
-	DocumentHighlight(context.Context, *DocumentHighlightParams) ([]DocumentHighlight, error)              // textDocument/documentHighlight
-	DocumentLink(context.Context, *DocumentLinkParams) ([]DocumentLink, error)                             // textDocument/documentLink
-	DocumentSymbol(context.Context, *DocumentSymbolParams) ([]interface{}, error)                          // textDocument/documentSymbol
-	FoldingRange(context.Context, *FoldingRangeParams) ([]FoldingRange, error)                             // textDocument/foldingRange
-	Formatting(context.Context, *DocumentFormattingParams) ([]TextEdit, error)                             // textDocument/formatting
-	Hover(context.Context, *HoverParams) (*Hover, error)                                                   // textDocument/hover
-	Implementation(context.Context, *ImplementationParams) ([]Location, error)                             // textDocument/implementation
-	InlayHint(context.Context, *InlayHintParams) ([]InlayHint, error)                                      // textDocument/inlayHint
-	InlineValue(context.Context, *InlineValueParams) ([]InlineValue, error)                                // textDocument/inlineValue
-	LinkedEditingRange(context.Context, *LinkedEditingRangeParams) (*LinkedEditingRanges, error)           // textDocument/linkedEditingRange
-	Moniker(context.Context, *MonikerParams) ([]Moniker, error)                                            // textDocument/moniker
-	OnTypeFormatting(context.Context, *DocumentOnTypeFormattingParams) ([]TextEdit, error)                 // textDocument/onTypeFormatting
-	PrepareCallHierarchy(context.Context, *CallHierarchyPrepareParams) ([]CallHierarchyItem, error)        // textDocument/prepareCallHierarchy
-	PrepareRename(context.Context, *PrepareRenameParams) (*PrepareRename2Gn, error)                        // textDocument/prepareRename
-	PrepareTypeHierarchy(context.Context, *TypeHierarchyPrepareParams) ([]TypeHierarchyItem, error)        // textDocument/prepareTypeHierarchy
-	RangeFormatting(context.Context, *DocumentRangeFormattingParams) ([]TextEdit, error)                   // textDocument/rangeFormatting
-	References(context.Context, *ReferenceParams) ([]Location, error)                                      // textDocument/references
-	Rename(context.Context, *RenameParams) (*WorkspaceEdit, error)                                         // textDocument/rename
-	SelectionRange(context.Context, *SelectionRangeParams) ([]SelectionRange, error)                       // textDocument/selectionRange
-	SemanticTokensFull(context.Context, *SemanticTokensParams) (*SemanticTokens, error)                    // textDocument/semanticTokens/full
-	SemanticTokensFullDelta(context.Context, *SemanticTokensDeltaParams) (interface{}, error)              // textDocument/semanticTokens/full/delta
-	SemanticTokensRange(context.Context, *SemanticTokensRangeParams) (*SemanticTokens, error)              // textDocument/semanticTokens/range
-	SignatureHelp(context.Context, *SignatureHelpParams) (*SignatureHelp, error)                           // textDocument/signatureHelp
-	TypeDefinition(context.Context, *TypeDefinitionParams) ([]Location, error)                             // textDocument/typeDefinition
-	WillSave(context.Context, *WillSaveTextDocumentParams) error                                           // textDocument/willSave
-	WillSaveWaitUntil(context.Context, *WillSaveTextDocumentParams) ([]TextEdit, error)                    // textDocument/willSaveWaitUntil
-	Subtypes(context.Context, *TypeHierarchySubtypesParams) ([]TypeHierarchyItem, error)                   // typeHierarchy/subtypes
-	Supertypes(context.Context, *TypeHierarchySupertypesParams) ([]TypeHierarchyItem, error)               // typeHierarchy/supertypes
-	WorkDoneProgressCancel(context.Context, *WorkDoneProgressCancelParams) error                           // window/workDoneProgress/cancel
-	DiagnosticWorkspace(context.Context, *WorkspaceDiagnosticParams) (*WorkspaceDiagnosticReport, error)   // workspace/diagnostic
-	DiagnosticRefresh(context.Context) error                                                               // workspace/diagnostic/refresh
-	DidChangeConfiguration(context.Context, *DidChangeConfigurationParams) error                           // workspace/didChangeConfiguration
-	DidChangeWatchedFiles(context.Context, *DidChangeWatchedFilesParams) error                             // workspace/didChangeWatchedFiles
-	DidChangeWorkspaceFolders(context.Context, *DidChangeWorkspaceFoldersParams) error                     // workspace/didChangeWorkspaceFolders
-	DidCreateFiles(context.Context, *CreateFilesParams) error                                              // workspace/didCreateFiles
-	DidDeleteFiles(context.Context, *DeleteFilesParams) error                                              // workspace/didDeleteFiles
-	DidRenameFiles(context.Context, *RenameFilesParams) error                                              // workspace/didRenameFiles
-	ExecuteCommand(context.Context, *ExecuteCommandParams) (interface{}, error)                            // workspace/executeCommand
-	InlayHintRefresh(context.Context) error                                                                // workspace/inlayHint/refresh
-	InlineValueRefresh(context.Context) error                                                              // workspace/inlineValue/refresh
-	SemanticTokensRefresh(context.Context) error                                                           // workspace/semanticTokens/refresh
-	Symbol(context.Context, *WorkspaceSymbolParams) ([]SymbolInformation, error)                           // workspace/symbol
-	WillCreateFiles(context.Context, *CreateFilesParams) (*WorkspaceEdit, error)                           // workspace/willCreateFiles
-	WillDeleteFiles(context.Context, *DeleteFilesParams) (*WorkspaceEdit, error)                           // workspace/willDeleteFiles
-	WillRenameFiles(context.Context, *RenameFilesParams) (*WorkspaceEdit, error)                           // workspace/willRenameFiles
-	ResolveWorkspaceSymbol(context.Context, *WorkspaceSymbol) (*WorkspaceSymbol, error)                    // workspaceSymbol/resolve
-	NonstandardRequest(ctx context.Context, method string, params interface{}) (interface{}, error)
-}
-
-func serverDispatch(ctx context.Context, server Server, reply jsonrpc2.Replier, r jsonrpc2.Request) (bool, error) {
-	switch r.Method() {
-	case "$/progress":
-		var params ProgressParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.Progress(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "$/setTrace":
-		var params SetTraceParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.SetTrace(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "callHierarchy/incomingCalls":
-		var params CallHierarchyIncomingCallsParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.IncomingCalls(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "callHierarchy/outgoingCalls":
-		var params CallHierarchyOutgoingCallsParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.OutgoingCalls(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "codeAction/resolve":
-		var params CodeAction
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ResolveCodeAction(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "codeLens/resolve":
-		var params CodeLens
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ResolveCodeLens(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "completionItem/resolve":
-		var params CompletionItem
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ResolveCompletionItem(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "documentLink/resolve":
-		var params DocumentLink
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ResolveDocumentLink(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "exit":
-		err := server.Exit(ctx)
-		return true, reply(ctx, nil, err) // 236
-	case "initialize":
-		var params ParamInitialize
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Initialize(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "initialized":
-		var params InitializedParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.Initialized(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "inlayHint/resolve":
-		var params InlayHint
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Resolve(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "notebookDocument/didChange":
-		var params DidChangeNotebookDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidChangeNotebookDocument(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "notebookDocument/didClose":
-		var params DidCloseNotebookDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidCloseNotebookDocument(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "notebookDocument/didOpen":
-		var params DidOpenNotebookDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidOpenNotebookDocument(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "notebookDocument/didSave":
-		var params DidSaveNotebookDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidSaveNotebookDocument(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "shutdown":
-		err := server.Shutdown(ctx)
-		return true, reply(ctx, nil, err) // 176
-	case "textDocument/codeAction":
-		var params CodeActionParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.CodeAction(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/codeLens":
-		var params CodeLensParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.CodeLens(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/colorPresentation":
-		var params ColorPresentationParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ColorPresentation(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/completion":
-		var params CompletionParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Completion(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/declaration":
-		var params DeclarationParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Declaration(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/definition":
-		var params DefinitionParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Definition(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/diagnostic":
-		var params string
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Diagnostic(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/didChange":
-		var params DidChangeTextDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidChange(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "textDocument/didClose":
-		var params DidCloseTextDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidClose(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "textDocument/didOpen":
-		var params DidOpenTextDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidOpen(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "textDocument/didSave":
-		var params DidSaveTextDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidSave(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "textDocument/documentColor":
-		var params DocumentColorParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.DocumentColor(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/documentHighlight":
-		var params DocumentHighlightParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.DocumentHighlight(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/documentLink":
-		var params DocumentLinkParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.DocumentLink(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/documentSymbol":
-		var params DocumentSymbolParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.DocumentSymbol(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/foldingRange":
-		var params FoldingRangeParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.FoldingRange(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/formatting":
-		var params DocumentFormattingParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Formatting(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/hover":
-		var params HoverParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Hover(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/implementation":
-		var params ImplementationParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Implementation(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/inlayHint":
-		var params InlayHintParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.InlayHint(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/inlineValue":
-		var params InlineValueParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.InlineValue(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/linkedEditingRange":
-		var params LinkedEditingRangeParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.LinkedEditingRange(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/moniker":
-		var params MonikerParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Moniker(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/onTypeFormatting":
-		var params DocumentOnTypeFormattingParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.OnTypeFormatting(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/prepareCallHierarchy":
-		var params CallHierarchyPrepareParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.PrepareCallHierarchy(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/prepareRename":
-		var params PrepareRenameParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.PrepareRename(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/prepareTypeHierarchy":
-		var params TypeHierarchyPrepareParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.PrepareTypeHierarchy(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/rangeFormatting":
-		var params DocumentRangeFormattingParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.RangeFormatting(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/references":
-		var params ReferenceParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.References(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/rename":
-		var params RenameParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Rename(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/selectionRange":
-		var params SelectionRangeParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.SelectionRange(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/semanticTokens/full":
-		var params SemanticTokensParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.SemanticTokensFull(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/semanticTokens/full/delta":
-		var params SemanticTokensDeltaParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.SemanticTokensFullDelta(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/semanticTokens/range":
-		var params SemanticTokensRangeParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.SemanticTokensRange(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/signatureHelp":
-		var params SignatureHelpParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.SignatureHelp(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/typeDefinition":
-		var params TypeDefinitionParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.TypeDefinition(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "textDocument/willSave":
-		var params WillSaveTextDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.WillSave(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "textDocument/willSaveWaitUntil":
-		var params WillSaveTextDocumentParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.WillSaveWaitUntil(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "typeHierarchy/subtypes":
-		var params TypeHierarchySubtypesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Subtypes(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "typeHierarchy/supertypes":
-		var params TypeHierarchySupertypesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Supertypes(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "window/workDoneProgress/cancel":
-		var params WorkDoneProgressCancelParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.WorkDoneProgressCancel(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/diagnostic":
-		var params WorkspaceDiagnosticParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.DiagnosticWorkspace(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/diagnostic/refresh":
-		err := server.DiagnosticRefresh(ctx)
-		return true, reply(ctx, nil, err) // 170
-	case "workspace/didChangeConfiguration":
-		var params DidChangeConfigurationParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidChangeConfiguration(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/didChangeWatchedFiles":
-		var params DidChangeWatchedFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidChangeWatchedFiles(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/didChangeWorkspaceFolders":
-		var params DidChangeWorkspaceFoldersParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidChangeWorkspaceFolders(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/didCreateFiles":
-		var params CreateFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidCreateFiles(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/didDeleteFiles":
-		var params DeleteFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidDeleteFiles(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/didRenameFiles":
-		var params RenameFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		err := server.DidRenameFiles(ctx, &params)
-		return true, reply(ctx, nil, err) // 231
-	case "workspace/executeCommand":
-		var params ExecuteCommandParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ExecuteCommand(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/inlayHint/refresh":
-		err := server.InlayHintRefresh(ctx)
-		return true, reply(ctx, nil, err) // 170
-	case "workspace/inlineValue/refresh":
-		err := server.InlineValueRefresh(ctx)
-		return true, reply(ctx, nil, err) // 170
-	case "workspace/semanticTokens/refresh":
-		err := server.SemanticTokensRefresh(ctx)
-		return true, reply(ctx, nil, err) // 170
-	case "workspace/symbol":
-		var params WorkspaceSymbolParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.Symbol(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/willCreateFiles":
-		var params CreateFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.WillCreateFiles(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/willDeleteFiles":
-		var params DeleteFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.WillDeleteFiles(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspace/willRenameFiles":
-		var params RenameFilesParams
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.WillRenameFiles(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	case "workspaceSymbol/resolve":
-		var params WorkspaceSymbol
-		if err := json.Unmarshal(r.Params(), &params); err != nil {
-			return true, sendParseError(ctx, reply, err)
-		}
-		resp, err := server.ResolveWorkspaceSymbol(ctx, &params)
-		if err != nil {
-			return true, reply(ctx, nil, err)
-		}
-		return true, reply(ctx, resp, nil) // 146
-	default:
-		return false, nil
-	}
-}
-
-func (s *serverDispatcher) Progress(ctx context.Context, params *ProgressParams) error {
-	return s.sender.Notify(ctx, "$/progress", params)
-} // 244
-func (s *serverDispatcher) SetTrace(ctx context.Context, params *SetTraceParams) error {
-	return s.sender.Notify(ctx, "$/setTrace", params)
-} // 244
-func (s *serverDispatcher) IncomingCalls(ctx context.Context, params *CallHierarchyIncomingCallsParams) ([]CallHierarchyIncomingCall, error) {
-	var result []CallHierarchyIncomingCall
-	if err := s.sender.Call(ctx, "callHierarchy/incomingCalls", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) OutgoingCalls(ctx context.Context, params *CallHierarchyOutgoingCallsParams) ([]CallHierarchyOutgoingCall, error) {
-	var result []CallHierarchyOutgoingCall
-	if err := s.sender.Call(ctx, "callHierarchy/outgoingCalls", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) ResolveCodeAction(ctx context.Context, params *CodeAction) (*CodeAction, error) {
-	var result *CodeAction
-	if err := s.sender.Call(ctx, "codeAction/resolve", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) ResolveCodeLens(ctx context.Context, params *CodeLens) (*CodeLens, error) {
-	var result *CodeLens
-	if err := s.sender.Call(ctx, "codeLens/resolve", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) ResolveCompletionItem(ctx context.Context, params *CompletionItem) (*CompletionItem, error) {
-	var result *CompletionItem
-	if err := s.sender.Call(ctx, "completionItem/resolve", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) ResolveDocumentLink(ctx context.Context, params *DocumentLink) (*DocumentLink, error) {
-	var result *DocumentLink
-	if err := s.sender.Call(ctx, "documentLink/resolve", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Exit(ctx context.Context) error {
-	return s.sender.Notify(ctx, "exit", nil)
-} // 249
-func (s *serverDispatcher) Initialize(ctx context.Context, params *ParamInitialize) (*InitializeResult, error) {
-	var result *InitializeResult
-	if err := s.sender.Call(ctx, "initialize", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Initialized(ctx context.Context, params *InitializedParams) error {
-	return s.sender.Notify(ctx, "initialized", params)
-} // 244
-func (s *serverDispatcher) Resolve(ctx context.Context, params *InlayHint) (*InlayHint, error) {
-	var result *InlayHint
-	if err := s.sender.Call(ctx, "inlayHint/resolve", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) DidChangeNotebookDocument(ctx context.Context, params *DidChangeNotebookDocumentParams) error {
-	return s.sender.Notify(ctx, "notebookDocument/didChange", params)
-} // 244
-func (s *serverDispatcher) DidCloseNotebookDocument(ctx context.Context, params *DidCloseNotebookDocumentParams) error {
-	return s.sender.Notify(ctx, "notebookDocument/didClose", params)
-} // 244
-func (s *serverDispatcher) DidOpenNotebookDocument(ctx context.Context, params *DidOpenNotebookDocumentParams) error {
-	return s.sender.Notify(ctx, "notebookDocument/didOpen", params)
-} // 244
-func (s *serverDispatcher) DidSaveNotebookDocument(ctx context.Context, params *DidSaveNotebookDocumentParams) error {
-	return s.sender.Notify(ctx, "notebookDocument/didSave", params)
-} // 244
-func (s *serverDispatcher) Shutdown(ctx context.Context) error {
-	return s.sender.Call(ctx, "shutdown", nil, nil)
-} // 209
-func (s *serverDispatcher) CodeAction(ctx context.Context, params *CodeActionParams) ([]CodeAction, error) {
-	var result []CodeAction
-	if err := s.sender.Call(ctx, "textDocument/codeAction", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) CodeLens(ctx context.Context, params *CodeLensParams) ([]CodeLens, error) {
-	var result []CodeLens
-	if err := s.sender.Call(ctx, "textDocument/codeLens", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) ColorPresentation(ctx context.Context, params *ColorPresentationParams) ([]ColorPresentation, error) {
-	var result []ColorPresentation
-	if err := s.sender.Call(ctx, "textDocument/colorPresentation", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Completion(ctx context.Context, params *CompletionParams) (*CompletionList, error) {
-	var result *CompletionList
-	if err := s.sender.Call(ctx, "textDocument/completion", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Declaration(ctx context.Context, params *DeclarationParams) (*Or_textDocument_declaration, error) {
-	var result *Or_textDocument_declaration
-	if err := s.sender.Call(ctx, "textDocument/declaration", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Definition(ctx context.Context, params *DefinitionParams) ([]Location, error) {
-	var result []Location
-	if err := s.sender.Call(ctx, "textDocument/definition", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Diagnostic(ctx context.Context, params *string) (*string, error) {
-	var result *string
-	if err := s.sender.Call(ctx, "textDocument/diagnostic", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) DidChange(ctx context.Context, params *DidChangeTextDocumentParams) error {
-	return s.sender.Notify(ctx, "textDocument/didChange", params)
-} // 244
-func (s *serverDispatcher) DidClose(ctx context.Context, params *DidCloseTextDocumentParams) error {
-	return s.sender.Notify(ctx, "textDocument/didClose", params)
-} // 244
-func (s *serverDispatcher) DidOpen(ctx context.Context, params *DidOpenTextDocumentParams) error {
-	return s.sender.Notify(ctx, "textDocument/didOpen", params)
-} // 244
-func (s *serverDispatcher) DidSave(ctx context.Context, params *DidSaveTextDocumentParams) error {
-	return s.sender.Notify(ctx, "textDocument/didSave", params)
-} // 244
-func (s *serverDispatcher) DocumentColor(ctx context.Context, params *DocumentColorParams) ([]ColorInformation, error) {
-	var result []ColorInformation
-	if err := s.sender.Call(ctx, "textDocument/documentColor", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) DocumentHighlight(ctx context.Context, params *DocumentHighlightParams) ([]DocumentHighlight, error) {
-	var result []DocumentHighlight
-	if err := s.sender.Call(ctx, "textDocument/documentHighlight", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) DocumentLink(ctx context.Context, params *DocumentLinkParams) ([]DocumentLink, error) {
-	var result []DocumentLink
-	if err := s.sender.Call(ctx, "textDocument/documentLink", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) DocumentSymbol(ctx context.Context, params *DocumentSymbolParams) ([]interface{}, error) {
-	var result []interface{}
-	if err := s.sender.Call(ctx, "textDocument/documentSymbol", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) FoldingRange(ctx context.Context, params *FoldingRangeParams) ([]FoldingRange, error) {
-	var result []FoldingRange
-	if err := s.sender.Call(ctx, "textDocument/foldingRange", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Formatting(ctx context.Context, params *DocumentFormattingParams) ([]TextEdit, error) {
-	var result []TextEdit
-	if err := s.sender.Call(ctx, "textDocument/formatting", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Hover(ctx context.Context, params *HoverParams) (*Hover, error) {
-	var result *Hover
-	if err := s.sender.Call(ctx, "textDocument/hover", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Implementation(ctx context.Context, params *ImplementationParams) ([]Location, error) {
-	var result []Location
-	if err := s.sender.Call(ctx, "textDocument/implementation", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) InlayHint(ctx context.Context, params *InlayHintParams) ([]InlayHint, error) {
-	var result []InlayHint
-	if err := s.sender.Call(ctx, "textDocument/inlayHint", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) InlineValue(ctx context.Context, params *InlineValueParams) ([]InlineValue, error) {
-	var result []InlineValue
-	if err := s.sender.Call(ctx, "textDocument/inlineValue", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) LinkedEditingRange(ctx context.Context, params *LinkedEditingRangeParams) (*LinkedEditingRanges, error) {
-	var result *LinkedEditingRanges
-	if err := s.sender.Call(ctx, "textDocument/linkedEditingRange", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Moniker(ctx context.Context, params *MonikerParams) ([]Moniker, error) {
-	var result []Moniker
-	if err := s.sender.Call(ctx, "textDocument/moniker", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) OnTypeFormatting(ctx context.Context, params *DocumentOnTypeFormattingParams) ([]TextEdit, error) {
-	var result []TextEdit
-	if err := s.sender.Call(ctx, "textDocument/onTypeFormatting", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) PrepareCallHierarchy(ctx context.Context, params *CallHierarchyPrepareParams) ([]CallHierarchyItem, error) {
-	var result []CallHierarchyItem
-	if err := s.sender.Call(ctx, "textDocument/prepareCallHierarchy", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) PrepareRename(ctx context.Context, params *PrepareRenameParams) (*PrepareRename2Gn, error) {
-	var result *PrepareRename2Gn
-	if err := s.sender.Call(ctx, "textDocument/prepareRename", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) PrepareTypeHierarchy(ctx context.Context, params *TypeHierarchyPrepareParams) ([]TypeHierarchyItem, error) {
-	var result []TypeHierarchyItem
-	if err := s.sender.Call(ctx, "textDocument/prepareTypeHierarchy", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) RangeFormatting(ctx context.Context, params *DocumentRangeFormattingParams) ([]TextEdit, error) {
-	var result []TextEdit
-	if err := s.sender.Call(ctx, "textDocument/rangeFormatting", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) References(ctx context.Context, params *ReferenceParams) ([]Location, error) {
-	var result []Location
-	if err := s.sender.Call(ctx, "textDocument/references", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Rename(ctx context.Context, params *RenameParams) (*WorkspaceEdit, error) {
-	var result *WorkspaceEdit
-	if err := s.sender.Call(ctx, "textDocument/rename", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) SelectionRange(ctx context.Context, params *SelectionRangeParams) ([]SelectionRange, error) {
-	var result []SelectionRange
-	if err := s.sender.Call(ctx, "textDocument/selectionRange", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) SemanticTokensFull(ctx context.Context, params *SemanticTokensParams) (*SemanticTokens, error) {
-	var result *SemanticTokens
-	if err := s.sender.Call(ctx, "textDocument/semanticTokens/full", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) SemanticTokensFullDelta(ctx context.Context, params *SemanticTokensDeltaParams) (interface{}, error) {
-	var result interface{}
-	if err := s.sender.Call(ctx, "textDocument/semanticTokens/full/delta", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) SemanticTokensRange(ctx context.Context, params *SemanticTokensRangeParams) (*SemanticTokens, error) {
-	var result *SemanticTokens
-	if err := s.sender.Call(ctx, "textDocument/semanticTokens/range", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) SignatureHelp(ctx context.Context, params *SignatureHelpParams) (*SignatureHelp, error) {
-	var result *SignatureHelp
-	if err := s.sender.Call(ctx, "textDocument/signatureHelp", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) TypeDefinition(ctx context.Context, params *TypeDefinitionParams) ([]Location, error) {
-	var result []Location
-	if err := s.sender.Call(ctx, "textDocument/typeDefinition", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) WillSave(ctx context.Context, params *WillSaveTextDocumentParams) error {
-	return s.sender.Notify(ctx, "textDocument/willSave", params)
-} // 244
-func (s *serverDispatcher) WillSaveWaitUntil(ctx context.Context, params *WillSaveTextDocumentParams) ([]TextEdit, error) {
-	var result []TextEdit
-	if err := s.sender.Call(ctx, "textDocument/willSaveWaitUntil", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Subtypes(ctx context.Context, params *TypeHierarchySubtypesParams) ([]TypeHierarchyItem, error) {
-	var result []TypeHierarchyItem
-	if err := s.sender.Call(ctx, "typeHierarchy/subtypes", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) Supertypes(ctx context.Context, params *TypeHierarchySupertypesParams) ([]TypeHierarchyItem, error) {
-	var result []TypeHierarchyItem
-	if err := s.sender.Call(ctx, "typeHierarchy/supertypes", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) WorkDoneProgressCancel(ctx context.Context, params *WorkDoneProgressCancelParams) error {
-	return s.sender.Notify(ctx, "window/workDoneProgress/cancel", params)
-} // 244
-func (s *serverDispatcher) DiagnosticWorkspace(ctx context.Context, params *WorkspaceDiagnosticParams) (*WorkspaceDiagnosticReport, error) {
-	var result *WorkspaceDiagnosticReport
-	if err := s.sender.Call(ctx, "workspace/diagnostic", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) DiagnosticRefresh(ctx context.Context) error {
-	return s.sender.Call(ctx, "workspace/diagnostic/refresh", nil, nil)
-} // 209
-func (s *serverDispatcher) DidChangeConfiguration(ctx context.Context, params *DidChangeConfigurationParams) error {
-	return s.sender.Notify(ctx, "workspace/didChangeConfiguration", params)
-} // 244
-func (s *serverDispatcher) DidChangeWatchedFiles(ctx context.Context, params *DidChangeWatchedFilesParams) error {
-	return s.sender.Notify(ctx, "workspace/didChangeWatchedFiles", params)
-} // 244
-func (s *serverDispatcher) DidChangeWorkspaceFolders(ctx context.Context, params *DidChangeWorkspaceFoldersParams) error {
-	return s.sender.Notify(ctx, "workspace/didChangeWorkspaceFolders", params)
-} // 244
-func (s *serverDispatcher) DidCreateFiles(ctx context.Context, params *CreateFilesParams) error {
-	return s.sender.Notify(ctx, "workspace/didCreateFiles", params)
-} // 244
-func (s *serverDispatcher) DidDeleteFiles(ctx context.Context, params *DeleteFilesParams) error {
-	return s.sender.Notify(ctx, "workspace/didDeleteFiles", params)
-} // 244
-func (s *serverDispatcher) DidRenameFiles(ctx context.Context, params *RenameFilesParams) error {
-	return s.sender.Notify(ctx, "workspace/didRenameFiles", params)
-} // 244
-func (s *serverDispatcher) ExecuteCommand(ctx context.Context, params *ExecuteCommandParams) (interface{}, error) {
-	var result interface{}
-	if err := s.sender.Call(ctx, "workspace/executeCommand", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) InlayHintRefresh(ctx context.Context) error {
-	return s.sender.Call(ctx, "workspace/inlayHint/refresh", nil, nil)
-} // 209
-func (s *serverDispatcher) InlineValueRefresh(ctx context.Context) error {
-	return s.sender.Call(ctx, "workspace/inlineValue/refresh", nil, nil)
-} // 209
-func (s *serverDispatcher) SemanticTokensRefresh(ctx context.Context) error {
-	return s.sender.Call(ctx, "workspace/semanticTokens/refresh", nil, nil)
-} // 209
-func (s *serverDispatcher) Symbol(ctx context.Context, params *WorkspaceSymbolParams) ([]SymbolInformation, error) {
-	var result []SymbolInformation
-	if err := s.sender.Call(ctx, "workspace/symbol", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) WillCreateFiles(ctx context.Context, params *CreateFilesParams) (*WorkspaceEdit, error) {
-	var result *WorkspaceEdit
-	if err := s.sender.Call(ctx, "workspace/willCreateFiles", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) WillDeleteFiles(ctx context.Context, params *DeleteFilesParams) (*WorkspaceEdit, error) {
-	var result *WorkspaceEdit
-	if err := s.sender.Call(ctx, "workspace/willDeleteFiles", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) WillRenameFiles(ctx context.Context, params *RenameFilesParams) (*WorkspaceEdit, error) {
-	var result *WorkspaceEdit
-	if err := s.sender.Call(ctx, "workspace/willRenameFiles", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) ResolveWorkspaceSymbol(ctx context.Context, params *WorkspaceSymbol) (*WorkspaceSymbol, error) {
-	var result *WorkspaceSymbol
-	if err := s.sender.Call(ctx, "workspaceSymbol/resolve", params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-} // 169
-func (s *serverDispatcher) NonstandardRequest(ctx context.Context, method string, params interface{}) (interface{}, error) {
-	var result interface{}
-	if err := s.sender.Call(ctx, method, params, &result); err != nil {
-		return nil, err
-	}
-	return result, nil
-}
diff -urN a/gopls/internal/lsp/protocol/typescript/README.md b/gopls/internal/lsp/protocol/typescript/README.md
--- a/gopls/internal/lsp/protocol/typescript/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/typescript/README.md	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-# Generate Go types and signatures for the LSP protocol
-
-## Setup
-
-Make sure `node` and `tsc` are installed and in your PATH. There are detailed instructions below.
-(`tsc -v` should be at least `4.2.4`.)
-Get the typescript code for the jsonrpc protocol with
-
-`git clone git@github.com:microsoft vscode-languageserver-node.git` or
-`git clone https://github.com/microsoft/vscode-languageserver-node.git`
-
-`util.ts` expects it to be in your HOME directory
-
-If you want to reproduce the existing files you need to be on a branch with the same git hash that `util.ts` expects, for instance, `git checkout 7b90c29`
-
-## Usage
-
-Code is generated and normalized by
-
-`tsc && node code.js && gofmt -w ts*.go`
-
-(`code.ts` imports `util.ts`.) This generates 3 files in the current directory, `tsprotocol.go`
-containing type definitions, and `tsserver.go`, `tsclient.go` containing API stubs.
-
-## Notes
-
-1. `code.ts` and `util.ts` use the Typescript compiler's API, which is [introduced](https://github.com/Microsoft/TypeScript/wiki/Architectural-Overview) in their wiki.
-2. Because the Typescript and Go type systems are incompatible, `code.ts` and `util.ts` are filled with heuristics and special cases. Therefore they are tied to a specific commit of `vscode-languageserver-node`. The hash code of the commit is included in the header of
-the generated files and stored in the variable `gitHash` in `go.ts`. It is checked (see `git()` in `util.ts`) on every execution.
-3. Generating the `ts*.go` files is only semi-automated. Please file an issue if the released version is too far behind.
-4. For the impatient, first change `gitHash` by hand (`git()` shows how to find the hash).
-    1. Then try to run `code.ts`. This will likely fail because the heuristics don't cover some new case. For instance, some simple type like `string` might have changed to a union type `string | [number,number]`. Another example is that some generated formal parameter may have anonymous structure type, which is essentially unusable.
-    2. Next step is to move the generated code to `internal/lsp/protocol` and try to build `gopls` and its tests. This will likely fail because types have changed. Generally the fixes are fairly easy. Then run all the tests.
-    3. Since there are not adequate integration tests, the next step is to run `gopls`.
-
-## Detailed instructions for installing node and typescript
-
-(The instructions are somewhat different for  Linux and MacOS. They install some things locally, so `$PATH` needs to be changed.)
-
-1. For Linux, it is possible to build node from scratch, but if there's a package manager, that's simpler.
-    1. To use the Ubuntu package manager
-        1. `sudo apt update` (if you can't `sudo` then these instructions are not helpful)
-        2. `sudo apt install nodejs` (this may install `/usr/bin/nodejs` rather than `/usr/bin/node`. For me, `/usr/bin/nodejs` pointed to an actual executable `/etc/alternatives/nodejs`, which should be copied to `/usr/bin/node`)
-        3. `sudo apt intall npm`
-    1. To build from scratch
-        1. Go to the [node site](https://nodejs.org), and download the one recommended for most users, and then you're on your own. (It's got binaries in it. Untar the file somewhere and put its `bin` directory in your path, perhaps?)
-2. The Mac is easier. Download the macOS installer from [nodejs](https://nodejs.org), click on it, and let it install.
-3. (There's a good chance that soon you will be asked to upgrade your new npm. `sudo npm install -g npm` is the command.)
-4. For either system, node and nvm should now be available. Running `node -v` and `npm -v` should produce version numbers.
-5. `npm install typescript`
-    1. This may give warning messages that indicate you've failed to set up a project. Ignore them.
-    2. Your home directory will now have new directories `.npm` and `node_modules` (and a `package_lock.json` file)
-    3. The typescript executable `tsc` will be in `node_modules/.bin`, so put that directory in your path.
-    4. `tsc -v` should print "Version 4.2.4" (or later). If not you may (as I did) have an obsolete tsc earlier in your path.
-6. `npm install @types/node` (Without this there will be many incomprehensible typescript error messages.)
diff -urN a/gopls/internal/lsp/protocol/typescript/code.ts b/gopls/internal/lsp/protocol/typescript/code.ts
--- a/gopls/internal/lsp/protocol/typescript/code.ts	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/typescript/code.ts	1969-12-31 16:00:00
@@ -1,1450 +0,0 @@
-/* eslint-disable no-useless-return */
-// read files from vscode-languageserver-node, and generate Go rpc stubs
-// and data definitions. (and maybe someday unmarshaling code)
-
-// The output is 3 files, tsprotocol.go contains the type definitions
-// while tsclient.go and tsserver.go contain the LSP API and stub. An LSP server
-// uses both APIs. To read the code, start in this file's main() function.
-
-// The code is rich in heuristics and special cases, some of which are to avoid
-// extensive changes to gopls, and some of which are due to the mismatch between
-// typescript and Go types. In particular, there is no Go equivalent to union
-// types, so each case ought to be considered separately. The Go equivalent of A
-// & B could frequently be struct{A;B;}, or it could be the equivalent type
-// listing all the members of A and B. Typically the code uses the former, but
-// especially if A and B have elements with the same name, it does a version of
-// the latter. ClientCapabilities has to be expanded, and ServerCapabilities is
-// expanded to make the generated code easier to read.
-
-// for us typescript ignorati, having an import makes this file a module
-import * as fs from 'fs';
-import * as ts from 'typescript';
-import * as u from './util';
-import { constName, getComments, goName, loc, strKind } from './util';
-
-var program: ts.Program;
-
-function parse() {
-  // this won't complain if some fnames don't exist
-  program = ts.createProgram(
-    u.fnames,
-    { target: ts.ScriptTarget.ES2018, module: ts.ModuleKind.CommonJS });
-  program.getTypeChecker();  // finish type checking and assignment
-}
-
-// ----- collecting information for RPCs
-let req = new Map<string, ts.NewExpression>();               // requests
-let not = new Map<string, ts.NewExpression>();               // notifications
-let ptypes = new Map<string, [ts.TypeNode, ts.TypeNode]>();  // req, resp types
-let receives = new Map<string, 'server' | 'client'>();         // who receives it
-let rpcTypes = new Set<string>();  // types seen in the rpcs
-
-function findRPCs(node: ts.Node) {
-  if (!ts.isModuleDeclaration(node)) {
-    return;
-  }
-  if (!ts.isIdentifier(node.name)) {
-    throw new Error(
-      `expected Identifier, got ${strKind(node.name)} at ${loc(node)}`);
-  }
-  let reqnot = req;
-  let v = node.name.getText();
-  if (v.endsWith('Notification')) reqnot = not;
-  else if (!v.endsWith('Request')) return;
-
-  if (!ts.isModuleBlock(node.body)) {
-    throw new Error(
-      `expected ModuleBlock got ${strKind(node.body)} at ${loc(node)}`);
-  }
-  let x: ts.ModuleBlock = node.body;
-  // The story is to expect const method = 'textDocument/implementation'
-  // const type = new ProtocolRequestType<...>(method)
-  // but the method may be an explicit string
-  let rpc: string = '';
-  let newNode: ts.NewExpression;
-  for (let i = 0; i < x.statements.length; i++) {
-    const uu = x.statements[i];
-    if (!ts.isVariableStatement(uu)) continue;
-    const dl: ts.VariableDeclarationList = uu.declarationList;
-    if (dl.declarations.length != 1)
-      throw new Error(`expected a single decl at ${loc(dl)}`);
-    const decl: ts.VariableDeclaration = dl.declarations[0];
-    const name = decl.name.getText();
-    // we want the initializers
-    if (name == 'method') {  // mostly StringLiteral but NoSubstitutionTemplateLiteral in protocol.semanticTokens.ts
-      if (!ts.isStringLiteral(decl.initializer)) {
-        if (!ts.isNoSubstitutionTemplateLiteral(decl.initializer)) {
-          console.log(`81: ${decl.initializer.getText()}`);
-          throw new Error(`expect StringLiteral at ${loc(decl)} got ${strKind(decl.initializer)}`);
-        }
-      }
-      rpc = decl.initializer.getText();
-    }
-    else if (name == 'type') {  // NewExpression
-      if (!ts.isNewExpression(decl.initializer))
-        throw new Error(`89 expected new at ${loc(decl)}`);
-      const nn: ts.NewExpression = decl.initializer;
-      newNode = nn;
-      const mtd = nn.arguments[0];
-      if (ts.isStringLiteral(mtd)) rpc = mtd.getText();
-      switch (nn.typeArguments.length) {
-        case 1:  // exit
-          ptypes.set(rpc, [nn.typeArguments[0], null]);
-          break;
-        case 2:  // notifications
-          ptypes.set(rpc, [nn.typeArguments[0], null]);
-          break;
-        case 4:  // request with no parameters
-          ptypes.set(rpc, [null, nn.typeArguments[0]]);
-          break;
-        case 5:  // request req, resp, partial(?)
-          ptypes.set(rpc, [nn.typeArguments[0], nn.typeArguments[1]]);
-          break;
-        default:
-          throw new Error(`${nn.typeArguments?.length} at ${loc(nn)}`);
-      }
-    }
-  }
-  if (rpc == '') throw new Error(`112 no name found at ${loc(x)}`);
-  // remember the implied types
-  const [a, b] = ptypes.get(rpc);
-  const add = function (n: ts.Node) {
-    rpcTypes.add(goName(n.getText()));
-  };
-  underlying(a, add);
-  underlying(b, add);
-  rpc = rpc.substring(1, rpc.length - 1);  // 'exit'
-  reqnot.set(rpc, newNode);
-}
-
-function setReceives() {
-  // mark them all as server, then adjust the client ones.
-  // it would be nice to have some independent check on this
-  // (this logic fails if the server ever sends $/canceRequest
-  //  or $/progress)
-  req.forEach((_, k) => { receives.set(k, 'server'); });
-  not.forEach((_, k) => { receives.set(k, 'server'); });
-  receives.set('window/showMessage', 'client');
-  receives.set('window/showMessageRequest', 'client');
-  receives.set('window/logMessage', 'client');
-  receives.set('telemetry/event', 'client');
-  receives.set('client/registerCapability', 'client');
-  receives.set('client/unregisterCapability', 'client');
-  receives.set('workspace/workspaceFolders', 'client');
-  receives.set('workspace/configuration', 'client');
-  receives.set('workspace/applyEdit', 'client');
-  receives.set('textDocument/publishDiagnostics', 'client');
-  receives.set('window/workDoneProgress/create', 'client');
-  receives.set('window/showDocument', 'client');
-  receives.set('$/progress', 'client');
-  // a small check
-  receives.forEach((_, k) => {
-    if (!req.get(k) && !not.get(k)) throw new Error(`145 missing ${k}}`);
-    if (req.get(k) && not.get(k)) throw new Error(`146 dup ${k}`);
-  });
-}
-
-type DataKind = 'module' | 'interface' | 'alias' | 'enum' | 'class';
-
-interface Data {
-  kind: DataKind;
-  me: ts.Node;   // root node for this type
-  name: string;  // Go name
-  origname: string; // their name
-  generics: ts.NodeArray<ts.TypeParameterDeclaration>;
-  as: ts.NodeArray<ts.HeritageClause>;  // inheritance
-  // Interface
-  properties: ts.NodeArray<ts.PropertySignature>
-  alias: ts.TypeNode;                        // type alias
-  // module
-  statements: ts.NodeArray<ts.Statement>;
-  enums: ts.NodeArray<ts.EnumMember>;
-  // class
-  members: ts.NodeArray<ts.PropertyDeclaration>;
-}
-function newData(n: ts.Node, nm: string, k: DataKind, origname: string): Data {
-  return {
-    kind: k,
-    me: n, name: goName(nm), origname: origname,
-    generics: ts.factory.createNodeArray<ts.TypeParameterDeclaration>(),
-    as: ts.factory.createNodeArray<ts.HeritageClause>(),
-    properties: ts.factory.createNodeArray<ts.PropertySignature>(), alias: undefined,
-    statements: ts.factory.createNodeArray<ts.Statement>(),
-    enums: ts.factory.createNodeArray<ts.EnumMember>(),
-    members: ts.factory.createNodeArray<ts.PropertyDeclaration>(),
-  };
-}
-
-// for debugging, produce a skeleton description
-function strData(d: Data): string {
-  if (!d) { return 'nil'; }
-  const f = function (na: ts.NodeArray<any>): number {
-    return na.length;
-  };
-  const nm = d.name == d.origname ? `${d.name}` : `${d.name}/${d.origname}`;
-  return `g:${f(d.generics)} a:${f(d.as)} p:${f(d.properties)} s:${f(d.statements)} e:${f(d.enums)} m:${f(d.members)} a:${d.alias !== undefined} D(${nm}) k:${d.kind}`;
-}
-
-let data = new Map<string, Data>();            // parsed data types
-let seenTypes = new Map<string, Data>();       // type names we've seen
-let extraTypes = new Map<string, string[]>();  // to avoid struct params
-
-function setData(nm: string, d: Data) {
-  const v = data.get(nm);
-  if (!v) {
-    data.set(nm, d);
-    return;
-  }
-  // if there are multiple definitions of the same name, decide what to do.
-  // For now the choices are only aliases and modules
-  // alias is preferred unless the constant values are needed
-  if (nm === 'PrepareSupportDefaultBehavior') {
-    // want the alias, as we're going to change the type and can't afford a constant
-    if (d.kind === 'alias') data.set(nm, d);
-    else if (v.kind == 'alias') data.set(nm, v);
-    else throw new Error(`208 ${d.kind} ${v.kind}`);
-    return;
-  }
-  if (nm === 'CodeActionKind') {
-    // want the module, need the constants
-    if (d.kind === 'module') data.set(nm, d);
-    else if (v.kind === 'module') data.set(nm, v);
-    else throw new Error(`215 ${d.kind} ${v.kind}`);
-  }
-  if (v.kind === 'alias' && d.kind !== 'alias') return;
-  if (d.kind === 'alias' && v.kind !== 'alias') {
-    data.set(nm, d);
-    return;
-  }
-  if (v.kind === 'alias' && d.kind === 'alias') return;
-  // protocol/src/common/protocol.foldingRange.ts 44: 1 (39: 2) and
-  // types/src/main.ts 397: 1 (392: 2)
-  // for FoldingRangeKind
-  if (d.me.getText() === v.me.getText()) return;
-  // error messages for an unexpected case
-  console.log(`228 ${strData(v)} ${loc(v.me)} for`);
-  console.log(`229 ${v.me.getText().replace(/\n/g, '\\n')}`);
-  console.log(`230 ${strData(d)} ${loc(d.me)}`);
-  console.log(`231 ${d.me.getText().replace(/\n/g, '\\n')}`);
-  throw new Error(`232 setData found ${v.kind} for ${d.kind}`);
-}
-
-// look at top level data definitions
-function genTypes(node: ts.Node) {
-  // Ignore top-level items that can't produce output
-  if (ts.isExpressionStatement(node) || ts.isFunctionDeclaration(node) ||
-    ts.isImportDeclaration(node) || ts.isVariableStatement(node) ||
-    ts.isExportDeclaration(node) || ts.isEmptyStatement(node) ||
-    ts.isExportAssignment(node) || ts.isImportEqualsDeclaration(node) ||
-    ts.isBlock(node) || node.kind == ts.SyntaxKind.EndOfFileToken) {
-    return;
-  }
-  if (ts.isInterfaceDeclaration(node)) {
-    const v: ts.InterfaceDeclaration = node;
-    // need to check the members, many of which are disruptive
-    let mems: ts.PropertySignature[] = [];
-    const f = function (t: ts.TypeElement) {
-      if (ts.isPropertySignature(t)) {
-        mems.push(t);
-      } else if (ts.isMethodSignature(t) || ts.isCallSignatureDeclaration(t)) {
-        return;
-      } else if (ts.isIndexSignatureDeclaration(t)) {
-        // probably safe to ignore these
-        // [key: string]: boolean | number | string | undefined;
-        // and InitializeResult: [custom: string]: any;]
-      } else
-        throw new Error(`259 unexpected ${strKind(t)}`);
-    };
-    v.members.forEach(f);
-    if (mems.length == 0 && !v.heritageClauses &&
-      v.name.getText() != 'InitializedParams') {
-      return;  // Don't seem to need any of these [Logger, PipTransport, ...]
-    }
-    // Found one we want
-    let x = newData(v, goName(v.name.getText()), 'interface', v.name.getText());
-    x.properties = ts.factory.createNodeArray<ts.PropertySignature>(mems);
-    if (v.typeParameters) x.generics = v.typeParameters;
-    if (v.heritageClauses) x.as = v.heritageClauses;
-    if (x.generics.length > 1) {  // Unneeded
-      // Item interface Item<K, V>...
-      return;
-    }
-    if (data.has(x.name)) {  // modifying one we've seen
-      x = dataChoose(x, data.get(x.name));
-    }
-    setData(x.name, x);
-  } else if (ts.isTypeAliasDeclaration(node)) {
-    const v: ts.TypeAliasDeclaration = node;
-    let x = newData(v, v.name.getText(), 'alias', v.name.getText());
-    x.alias = v.type;
-    // if type is a union of constants, we (mostly) don't want it
-    // (at the top level)
-    // Unfortunately this is false for TraceValues
-    if (ts.isUnionTypeNode(v.type) &&
-      v.type.types.every((n: ts.TypeNode) => ts.isLiteralTypeNode(n))) {
-      if (x.name != 'TraceValues') return;
-    }
-    if (v.typeParameters) {
-      x.generics = v.typeParameters;
-    }
-    if (data.has(x.name)) x = dataChoose(x, data.get(x.name));
-    if (x.generics.length > 1) {
-      return;
-    }
-    setData(x.name, x);
-  } else if (ts.isModuleDeclaration(node)) {
-    const v: ts.ModuleDeclaration = node;
-    if (!ts.isModuleBlock(v.body)) {
-      throw new Error(`${loc(v)} not ModuleBlock, but ${strKind(v.body)}`);
-    }
-    const b: ts.ModuleBlock = v.body;
-    var s: ts.Statement[] = [];
-    // we don't want most of these
-    const fx = function (x: ts.Statement) {
-      if (ts.isFunctionDeclaration(x)) {
-        return;
-      }
-      if (ts.isTypeAliasDeclaration(x) || ts.isModuleDeclaration(x)) {
-        return;
-      }
-      if (!ts.isVariableStatement(x))
-        throw new Error(
-          `315 expected VariableStatment ${loc(x)} ${strKind(x)} ${x.getText()}`);
-      if (hasNewExpression(x)) {
-        return;
-      }
-      s.push(x);
-    };
-    b.statements.forEach(fx);
-    if (s.length == 0) {
-      return;
-    }
-    let m = newData(node, v.name.getText(), 'module', v.name.getText());
-    m.statements = ts.factory.createNodeArray<ts.Statement>(s);
-    if (data.has(m.name)) m = dataChoose(m, data.get(m.name));
-    setData(m.name, m);
-  } else if (ts.isEnumDeclaration(node)) {
-    const nm = node.name.getText();
-    let v = newData(node, nm, 'enum', node.name.getText());
-    v.enums = node.members;
-    if (data.has(nm)) {
-      v = dataChoose(v, data.get(nm));
-    }
-    setData(nm, v);
-  } else if (ts.isClassDeclaration(node)) {
-    const v: ts.ClassDeclaration = node;
-    var d: ts.PropertyDeclaration[] = [];
-    const wanted = function (c: ts.ClassElement): string {
-      if (ts.isConstructorDeclaration(c)) {
-        return '';
-      }
-      if (ts.isMethodDeclaration(c)) {
-        return '';
-      }
-      if (ts.isGetAccessor(c)) {
-        return '';
-      }
-      if (ts.isSetAccessor(c)) {
-        return '';
-      }
-      if (ts.isPropertyDeclaration(c)) {
-        d.push(c);
-        return strKind(c);
-      }
-      throw new Error(`Class decl ${strKind(c)} `);
-    };
-    v.members.forEach((c) => wanted(c));
-    if (d.length == 0) {
-      return;
-    }  // don't need it
-    let c = newData(v, v.name.getText(), 'class', v.name.getText());
-    c.members = ts.factory.createNodeArray<ts.PropertyDeclaration>(d);
-    if (v.typeParameters) {
-      c.generics = v.typeParameters;
-    }
-    if (c.generics.length > 1) {
-      return;
-    }
-    if (v.heritageClauses) {
-      c.as = v.heritageClauses;
-    }
-    if (data.has(c.name))
-      throw new Error(`Class dup ${loc(c.me)} and ${loc(data.get(c.name).me)}`);
-    setData(c.name, c);
-  } else {
-    throw new Error(`378 unexpected ${strKind(node)} ${loc(node)} `);
-  }
-}
-
-// Typescript can accumulate, but this chooses one or the other
-function dataChoose(a: Data, b: Data): Data {
-  // maybe they are textually identical? (e.g., FoldingRangeKind)
-  const [at, bt] = [a.me.getText(), b.me.getText()];
-  if (at == bt) {
-    return a;
-  }
-  switch (a.name) {
-    case 'InitializeError':
-    case 'CompletionItemTag':
-    case 'SymbolTag':
-    case 'CodeActionKind':
-    case 'Integer':
-    case 'Uinteger':
-    case 'Decimal':
-      // want the Module, if anything
-      return a.statements.length > 0 ? a : b;
-    case 'CancellationToken':
-    case 'CancellationStrategy':
-      // want the Interface
-      return a.properties.length > 0 ? a : b;
-    case 'TextDocumentContentChangeEvent':  // almost the same
-    case 'TokenFormat':
-    case 'PrepareSupportDefaultBehavior':
-      return a;
-  }
-  console.log(
-    `409 ${strKind(a.me)} ${strKind(b.me)} ${a.name} ${loc(a.me)} ${loc(b.me)}`);
-  throw new Error(`410 Fix dataChoose for ${a.name}`);
-}
-
-// is a node an ancestor of a NewExpression
-function hasNewExpression(n: ts.Node): boolean {
-  let ans = false;
-  n.forEachChild((n: ts.Node) => {
-    if (ts.isNewExpression(n)) ans = true;
-  });
-  return ans;
-}
-
-function checkOnce() {
-  // Data for all the rpc types?
-  rpcTypes.forEach(s => {
-    if (!data.has(s)) throw new Error(`checkOnce, ${s}?`);
-  });
-}
-
-// helper function to find underlying types
-// eslint-disable-next-line no-unused-vars
-function underlying(n: ts.Node | undefined, f: (n: ts.Node) => void) {
-  if (!n) return;
-  const ff = function (n: ts.Node) {
-    underlying(n, f);
-  };
-  if (ts.isIdentifier(n)) {
-    f(n);
-  } else if (
-    n.kind == ts.SyntaxKind.StringKeyword ||
-    n.kind == ts.SyntaxKind.NumberKeyword ||
-    n.kind == ts.SyntaxKind.AnyKeyword ||
-    n.kind == ts.SyntaxKind.UnknownKeyword ||
-    n.kind == ts.SyntaxKind.NullKeyword ||
-    n.kind == ts.SyntaxKind.BooleanKeyword ||
-    n.kind == ts.SyntaxKind.ObjectKeyword ||
-    n.kind == ts.SyntaxKind.VoidKeyword) {
-    // nothing to do
-  } else if (ts.isTypeReferenceNode(n)) {
-    f(n.typeName);
-  } else if (ts.isArrayTypeNode(n)) {
-    underlying(n.elementType, f);
-  } else if (ts.isHeritageClause(n)) {
-    n.types.forEach(ff);
-  } else if (ts.isExpressionWithTypeArguments(n)) {
-    underlying(n.expression, f);
-  } else if (ts.isPropertySignature(n)) {
-    underlying(n.type, f);
-  } else if (ts.isTypeLiteralNode(n)) {
-    n.members.forEach(ff);
-  } else if (ts.isUnionTypeNode(n) || ts.isIntersectionTypeNode(n)) {
-    n.types.forEach(ff);
-  } else if (ts.isIndexSignatureDeclaration(n)) {
-    underlying(n.type, f);
-  } else if (ts.isParenthesizedTypeNode(n)) {
-    underlying(n.type, f);
-  } else if (
-    ts.isLiteralTypeNode(n) || ts.isVariableStatement(n) ||
-    ts.isTupleTypeNode(n)) {
-    // we only see these in moreTypes, but they are handled elsewhere
-  } else if (ts.isEnumMember(n)) {
-    if (ts.isStringLiteral(n.initializer)) return;
-    throw new Error(`472 EnumMember ${strKind(n.initializer)} ${n.name.getText()}`);
-  } else {
-    throw new Error(`474 saw ${strKind(n)} in underlying. ${n.getText()} at ${loc(n)}`);
-  }
-}
-
-// find all the types implied by seenTypes.
-// Simplest way to the transitive closure is to stabilize the size of seenTypes
-// but it is slow
-function moreTypes() {
-  const extra = function (s: string) {
-    if (!data.has(s)) throw new Error(`moreTypes needs ${s}`);
-    seenTypes.set(s, data.get(s));
-  };
-  rpcTypes.forEach(extra);  // all the types needed by the rpcs
-  // needed in enums.go (or elsewhere)
-  extra('InitializeError');
-  extra('WatchKind');
-  extra('FoldingRangeKind');
-  // not sure why these weren't picked up
-  extra('DidChangeWatchedFilesRegistrationOptions');
-  extra('WorkDoneProgressBegin');
-  extra('WorkDoneProgressReport');
-  extra('WorkDoneProgressEnd');
-  let old = 0;
-  do {
-    old = seenTypes.size;
-
-    const m = new Map<string, Data>();
-    const add = function (n: ts.Node) {
-      const nm = goName(n.getText());
-      if (seenTypes.has(nm) || m.has(nm)) return;
-      if (data.get(nm)) {
-        m.set(nm, data.get(nm));
-      }
-    };
-    // expect all the heritage clauses have single Identifiers
-    const h = function (n: ts.Node) {
-      underlying(n, add);
-    };
-    const f = function (x: ts.NodeArray<ts.Node>) {
-      x.forEach(h);
-    };
-    seenTypes.forEach((d: Data) => d && f(d.as));
-    // find the types in the properties
-    seenTypes.forEach((d: Data) => d && f(d.properties));
-    // and in the alias and in the statements and in the enums
-    seenTypes.forEach((d: Data) => d && underlying(d.alias, add));
-    seenTypes.forEach((d: Data) => d && f(d.statements));
-    seenTypes.forEach((d: Data) => d && f(d.enums));
-    m.forEach((d, k) => seenTypes.set(k, d));
-  }
-  while (seenTypes.size != old)
-    ;
-}
-
-function cleanData() { // middle pass
-  // seenTypes contains all the top-level types.
-  seenTypes.forEach((d) => {
-    if (d.kind == 'alias') mergeAlias(d);
-  });
-}
-
-function sameType(a: ts.TypeNode, b: ts.TypeNode): boolean {
-  if (a.kind !== b.kind) return false;
-  if (a.kind === ts.SyntaxKind.BooleanKeyword) return true;
-  if (a.kind === ts.SyntaxKind.StringKeyword) return true;
-  if (ts.isTypeReferenceNode(a) && ts.isTypeReferenceNode(b) &&
-    a.typeName.getText() === b.typeName.getText()) return true;
-  if (ts.isArrayTypeNode(a) && ts.isArrayTypeNode(b)) return sameType(a.elementType, b.elementType);
-  if (ts.isTypeLiteralNode(a) && ts.isTypeLiteralNode(b)) {
-    if (a.members.length !== b.members.length) return false;
-    if (a.members.length === 1) return a.members[0].name.getText() === b.members[0].name.getText();
-    if (loc(a) === loc(b)) return true;
-  }
-  throw new Error(`544 sameType? ${strKind(a)} ${strKind(b)} ${a.getText()}`);
-}
-type CreateMutable<Type> = {
-  -readonly [Property in keyof Type]: Type[Property];
-};
-type propMap = Map<string, ts.PropertySignature>;
-function propMapSet(pm: propMap, name: string, v: ts.PropertySignature) {
-  if (!pm.get(name)) {
-    try { getComments(v); } catch (e) { console.log(`552 ${name} ${e}`); }
-    pm.set(name, v);
-    return;
-  }
-  const a = pm.get(name).type;
-  const b = v.type;
-  if (sameType(a, b)) {
-    return;
-  }
-  if (ts.isTypeReferenceNode(a) && ts.isTypeLiteralNode(b)) {
-    const x = mergeTypeRefLit(a, b);
-    const fake: CreateMutable<ts.PropertySignature> = v;
-    fake['type'] = x;
-    check(fake as ts.PropertySignature, '565');
-    pm.set(name, fake as ts.PropertySignature);
-    return;
-  }
-  if (ts.isTypeLiteralNode(a) && ts.isTypeLiteralNode(b)) {
-    const x = mergeTypeLitLit(a, b);
-    const fake: CreateMutable<ts.PropertySignature> = v;
-    fake['type'] = x;
-    check(fake as ts.PropertySignature, '578');
-    pm.set(name, fake as ts.PropertySignature);
-    return;
-  }
-  console.log(`577 ${pm.get(name).getText()}\n${v.getText()}`);
-  throw new Error(`578 should merge ${strKind(a)} and ${strKind(b)} for ${name}`);
-}
-function addToProperties(pm: propMap, tn: ts.TypeNode | undefined, prefix = '') {
-  if (!tn) return;
-  if (ts.isTypeReferenceNode(tn)) {
-    const d = seenTypes.get(goName(tn.typeName.getText()));
-    if (tn.typeName.getText() === 'T') return;
-    if (!d) throw new Error(`584 ${tn.typeName.getText()} not found`);
-    if (d.properties.length === 0 && d.alias === undefined) return;
-    if (d.alias !== undefined) {
-      if (ts.isIntersectionTypeNode(d.alias)) {
-        d.alias.types.forEach((tn) => addToProperties(pm, tn, prefix)); // prefix?
-        return;
-      }
-    }
-    d.properties.forEach((ps) => {
-      const name = `${prefix}.${ps.name.getText()}`;
-      propMapSet(pm, name, ps);
-      addToProperties(pm, ps.type, name);
-    });
-  } else if (strKind(tn) === 'TypeLiteral') {
-    if (!ts.isTypeLiteralNode(tn)) new Error(`599 ${strKind(tn)}`);
-    tn.forEachChild((child: ts.Node) => {
-      if (ts.isPropertySignature(child)) {
-        const name = `${prefix}.${child.name.getText()}`;
-        propMapSet(pm, name, child);
-        addToProperties(pm, child.type, name);
-      } else if (!ts.isIndexSignatureDeclaration(child)) {
-        // ignoring IndexSignatures, seen as relatedDocument in
-        // RelatedFullDocumentDiagnosticReport
-        throw new Error(`608 ${strKind(child)} ${loc(child)}`);
-      }
-    });
-  }
-}
-function deepProperties(d: Data): propMap | undefined {
-  let properties: propMap = new Map<string, ts.PropertySignature>();
-  if (!d.alias || !ts.isIntersectionTypeNode(d.alias)) return undefined;
-  d.alias.types.forEach((ts) => addToProperties(properties, ts));
-  return properties;
-}
-
-function mergeAlias(d: Data) {
-  const props = deepProperties(d);
-  if (!props) return; // nothing merged
-  // now each element of props should have length 1
-  // change d to merged, toss its alias field, fill in its properties
-  const v: ts.PropertySignature[] = [];
-  props.forEach((ps, nm) => {
-    const xlen = nm.split('.').length;
-    if (xlen !== 2) return; // not top-level
-    v.push(ps);
-  });
-  d.kind = 'interface';
-  d.alias = undefined;
-  d.properties = ts.factory.createNodeArray(v);
-}
-
-function mergeTypeLitLit(a: ts.TypeLiteralNode, b: ts.TypeLiteralNode): ts.TypeLiteralNode {
-  const v = new Map<string, ts.TypeElement>(); // avoid duplicates
-  a.members.forEach((te) => v.set(te.name.getText(), te));
-  b.members.forEach((te) => v.set(te.name.getText(), te));
-  const x: ts.TypeElement[] = [];
-  v.forEach((te) => x.push(te));
-  const fake: CreateMutable<ts.TypeLiteralNode> = a;
-  fake['members'] = ts.factory.createNodeArray(x);
-  check(fake as ts.TypeLiteralNode, '643');
-  return fake as ts.TypeLiteralNode;
-}
-
-function mergeTypeRefLit(a: ts.TypeReferenceNode, b: ts.TypeLiteralNode): ts.TypeLiteralNode {
-  const d = seenTypes.get(goName(a.typeName.getText()));
-  if (!d) throw new Error(`644 name ${a.typeName.getText()} not found`);
-  const typ = d.me;
-  if (!ts.isInterfaceDeclaration(typ)) throw new Error(`646 got ${strKind(typ)} not InterfaceDecl`);
-  const v = new Map<string, ts.TypeElement>(); // avoid duplicates
-  typ.members.forEach((te) => v.set(te.name.getText(), te));
-  b.members.forEach((te) => v.set(te.name.getText(), te));
-  const x: ts.TypeElement[] = [];
-  v.forEach((te) => x.push(te));
-
-  const w = ts.factory.createNodeArray(x);
-  const fk: CreateMutable<ts.TypeLiteralNode> = b;
-  fk['members'] = w;
-  (fk['members'] as { pos: number })['pos'] = b.members.pos;
-  (fk['members'] as { end: number })['end'] = b.members.end;
-  check(fk as ts.TypeLiteralNode, '662');
-  return fk as ts.TypeLiteralNode;
-}
-
-// check that constructed nodes still have associated text
-function check(n: ts.Node, loc: string) {
-  try { getComments(n); } catch (e) { console.log(`check at ${loc} ${e}`); }
-  try { n.getText(); } catch (e) { console.log(`text check at ${loc}`); }
-}
-
-let typesOut = new Array<string>();
-let constsOut = new Array<string>();
-
-// generate Go types
-function toGo(d: Data, nm: string) {
-  if (!d) return;  // this is probably a generic T
-  if (d.name.startsWith('Inner') || d.name === 'WindowClientCapabilities') return; // removed by alias processing
-  if (d.name === 'Integer' || d.name === 'Uinteger') return; // unneeded
-  switch (d.kind) {
-    case 'alias':
-      goTypeAlias(d, nm); break;
-    case 'module': goModule(d, nm); break;
-    case 'enum': goEnum(d, nm); break;
-    case 'interface': goInterface(d, nm); break;
-    default:
-      throw new Error(
-        `672: more cases in toGo ${nm} ${d.kind}`);
-  }
-}
-
-// these fields need a * and are not covered by the code
-// that calls isStructType.
-var starred: [string, string][] = [
-  ['TextDocumentContentChangeEvent', 'range'], ['CodeAction', 'command'],
-  ['CodeAction', 'disabled'],
-  ['DidSaveTextDocumentParams', 'text'], ['CompletionItem', 'command'],
-  ['Diagnostic', 'codeDescription']
-];
-
-// generate Go code for an interface
-function goInterface(d: Data, nm: string) {
-  let ans = `type ${goName(nm)} struct {\n`;
-
-  // generate the code for each member
-  const g = function (n: ts.PropertySignature) {
-    if (!ts.isPropertySignature(n))
-      throw new Error(`expected PropertySignature got ${strKind(n)} `);
-    ans = ans.concat(getComments(n));
-    const json = u.JSON(n);
-    let gt = goType(n.type, n.name.getText());
-    if (gt == d.name) gt = '*' + gt; // avoid recursive types (SelectionRange)
-    // there are several cases where a * is needed
-    // (putting * in front of too many things breaks uses of CodeActionKind)
-    starred.forEach(([a, b]) => {
-      if (d.name == a && n.name.getText() == b) {
-        gt = '*' + gt;
-      }
-    });
-    ans = ans.concat(`${goName(n.name.getText())} ${gt}`, json, '\n');
-  };
-  d.properties.forEach(g);
-  // heritage clauses become embedded types
-  // check they are all Identifiers
-  const f = function (n: ts.ExpressionWithTypeArguments) {
-    if (!ts.isIdentifier(n.expression))
-      throw new Error(`Interface ${nm} heritage ${strKind(n.expression)} `);
-    if (n.expression.getText() === 'Omit') return;  // Type modification type
-    ans = ans.concat(goName(n.expression.getText()), '\n');
-  };
-  d.as.forEach((n: ts.HeritageClause) => n.types.forEach(f));
-  ans = ans.concat('}\n');
-  typesOut.push(getComments(d.me));
-  typesOut.push(ans);
-}
-
-// generate Go code for a module (const declarations)
-// Generates type definitions, and named constants
-function goModule(d: Data, nm: string) {
-  if (d.generics.length > 0 || d.as.length > 0) {
-    throw new Error(`743 goModule: unexpected for ${nm}
-  `);
-  }
-  // all the statements should be export const <id>: value
-  //   or value = value
-  // They are VariableStatements with x.declarationList having a single
-  //   VariableDeclaration
-  let isNumeric = false;
-  const f = function (n: ts.Statement, i: number) {
-    if (!ts.isVariableStatement(n)) {
-      throw new Error(`753 ${nm} ${i} expected VariableStatement,
-      got ${strKind(n)}`);
-    }
-    const c = getComments(n);
-    const v = n.declarationList.declarations[0];  // only one
-
-    if (!v.initializer)
-      throw new Error(`760 no initializer ${nm} ${i} ${v.name.getText()}`);
-    isNumeric = strKind(v.initializer) == 'NumericLiteral';
-    if (c != '') constsOut.push(c);  // no point if there are no comments
-    // There are duplicates.
-    const cname = constName(goName(v.name.getText()), nm);
-    let val = v.initializer.getText();
-    val = val.split('\'').join('"');  // useless work for numbers
-    constsOut.push(`${cname} ${nm} = ${val}`);
-  };
-  d.statements.forEach(f);
-  typesOut.push(getComments(d.me));
-  // Or should they be type aliases?
-  typesOut.push(`type ${nm} ${isNumeric ? 'float64' : 'string'}`);
-}
-
-// generate Go code for an enum. Both types and named constants
-function goEnum(d: Data, nm: string) {
-  let isNumeric = false;
-  const f = function (v: ts.EnumMember, j: number) {  // same as goModule
-    if (!v.initializer)
-      throw new Error(`goEnum no initializer ${nm} ${j} ${v.name.getText()}`);
-    isNumeric = strKind(v.initializer) == 'NumericLiteral';
-    const c = getComments(v);
-    const cname = constName(goName(v.name.getText()), nm);
-    let val = v.initializer.getText();
-    val = val.split('\'').join('"');  // replace quotes. useless work for numbers
-    constsOut.push(`${c}${cname} ${nm} = ${val}`);
-  };
-  d.enums.forEach(f);
-  typesOut.push(getComments(d.me));
-  // Or should they be type aliases?
-  typesOut.push(`type ${nm} ${isNumeric ? 'float64' : 'string'}`);
-}
-
-// generate code for a type alias
-function goTypeAlias(d: Data, nm: string) {
-  if (d.as.length != 0 || d.generics.length != 0) {
-    if (nm != 'ServerCapabilities')
-      throw new Error(`${nm} has extra fields(${d.as.length},${d.generics.length}) ${d.me.getText()}`);
-  }
-  typesOut.push(getComments(d.me));
-  // d.alias doesn't seem to have comments
-  let aliasStr = goName(nm) == 'DocumentURI' ? ' ' : ' = ';
-  if (nm == 'PrepareSupportDefaultBehavior') {
-    // code-insiders is sending a bool, not a number. PJW: check this after Feb/2021
-    // (and gopls never looks at it anyway)
-    typesOut.push(`type ${goName(nm)}${aliasStr}interface{}\n`);
-    return;
-  }
-  typesOut.push(`type ${goName(nm)}${aliasStr}${goType(d.alias, nm)}\n`);
-}
-
-// return a go type and maybe an assocated javascript tag
-function goType(n: ts.TypeNode | undefined, nm: string): string {
-  if (!n) throw new Error(`goType undefined for ${nm}`);
-  if (n.getText() == 'T') return 'interface{}';  // should check it's generic
-  if (ts.isTypeReferenceNode(n)) {
-    // DocumentDiagnosticReportKind.unChanged (or .new) value is "new" or "unChanged"
-    if (n.getText().startsWith('DocumentDiagnostic')) return 'string';
-    switch (n.getText()) {
-      case 'integer': return 'int32';
-      case 'uinteger': return 'uint32';
-      default: return goName(n.typeName.getText());  // avoid <T>
-    }
-  } else if (ts.isUnionTypeNode(n)) {
-    return goUnionType(n, nm);
-  } else if (ts.isIntersectionTypeNode(n)) {
-    return goIntersectionType(n, nm);
-  } else if (strKind(n) == 'StringKeyword') {
-    return 'string';
-  } else if (strKind(n) == 'NumberKeyword') {
-    return 'float64';
-  } else if (strKind(n) == 'BooleanKeyword') {
-    return 'bool';
-  } else if (strKind(n) == 'AnyKeyword' || strKind(n) == 'UnknownKeyword') {
-    return 'interface{}';
-  } else if (strKind(n) == 'NullKeyword') {
-    return 'nil';
-  } else if (strKind(n) == 'VoidKeyword' || strKind(n) == 'NeverKeyword') {
-    return 'void';
-  } else if (strKind(n) == 'ObjectKeyword') {
-    return 'interface{}';
-  } else if (ts.isArrayTypeNode(n)) {
-    if (nm === 'arguments') {
-      // Command and ExecuteCommandParams
-      return '[]json.RawMessage';
-    }
-    return `[]${goType(n.elementType, nm)}`;
-  } else if (ts.isParenthesizedTypeNode(n)) {
-    return goType(n.type, nm);
-  } else if (ts.isLiteralTypeNode(n)) {
-    return strKind(n.literal) == 'StringLiteral' ? 'string' : 'float64';
-  } else if (ts.isTypeLiteralNode(n)) {
-    // these are anonymous structs
-    const v = goTypeLiteral(n, nm);
-    return v;
-  } else if (ts.isTupleTypeNode(n)) {
-    if (n.getText() == '[number, number]') return '[]float64';
-    throw new Error(`goType unexpected Tuple ${n.getText()}`);
-  }
-  throw new Error(`${strKind(n)} goType unexpected ${n.getText()} for ${nm}`);
-}
-
-// The choice is uniform interface{}, or some heuristically assigned choice,
-// or some better sytematic idea I haven't thought of. Using interface{}
-// is, in practice, impossibly complex in the existing code.
-function goUnionType(n: ts.UnionTypeNode, nm: string): string {
-  let help = `/*${n.getText()}*/`;  // show the original as a comment
-  // There are some bad cases with newlines:
-  // range?: boolean | {\n	};
-  // full?: boolean | {\n		/**\n		 * The server supports deltas for full documents.\n		 */\n		delta?: boolean;\n	}
-  // These are handled specially:
-  if (nm == 'range') help = help.replace(/\n/, '');
-  if (nm == 'full' && help.indexOf('\n') != -1) {
-    help = '/*boolean | <elided struct>*/';
-  }
-  // handle all the special cases
-  switch (n.types.length) {
-    case 2: {
-      const a = strKind(n.types[0]);
-      const b = strKind(n.types[1]);
-      if (a == 'NumberKeyword' && b == 'StringKeyword') {  // ID
-        return `interface{} ${help}`;
-      }
-      // for null, b is not useful (LiternalType)
-      if (n.types[1].getText() === 'null') {
-        if (nm == 'textDocument/codeAction') {
-          // (Command | CodeAction)[] | null
-          return `[]CodeAction ${help}`;
-        }
-        let v = goType(n.types[0], 'a');
-        return `${v} ${help}`;
-      }
-      if (a == 'BooleanKeyword') {  // usually want bool
-        if (nm == 'codeActionProvider') return `interface{} ${help}`;
-        if (nm == 'renameProvider') return `interface{} ${help}`;
-        if (nm == 'full') return `interface{} ${help}`; // there's a struct
-        if (nm == 'save') return `${goType(n.types[1], '680')} ${help}`;
-        return `${goType(n.types[0], 'b')} ${help}`;
-      }
-      if (b == 'ArrayType') return `${goType(n.types[1], 'c')} ${help}`;
-      if (help.includes('InsertReplaceEdit') && n.types[0].getText() == 'TextEdit') {
-        return `*TextEdit ${help}`;
-      }
-      if (a == 'TypeReference') {
-        if (nm == 'edits') return `${goType(n.types[0], '901')} ${help}`;
-        if (a == b) return `interface{} ${help}`;
-        if (nm == 'code') return `interface{} ${help}`;
-        if (nm == 'editRange') return `${goType(n.types[0], '904')} ${help}`;
-        if (nm === 'location') return `${goType(n.types[0], '905')} ${help}`;
-      }
-      if (a == 'StringKeyword') return `string ${help}`;
-      if (a == 'TypeLiteral' && nm == 'TextDocumentContentChangeEvent') {
-        return `${goType(n.types[0], nm)}`;
-      }
-      if (a == 'TypeLiteral' && b === 'TypeLiteral') {
-        // DocumentDiagnosticReport
-        // the first one includes the second one
-        return `${goType(n.types[0], '9d')}`;
-      }
-      throw new Error(`911 ${nm}: a:${a}/${goType(n.types[0], '9a')} b:${b}/${goType(n.types[1], '9b')} ${loc(n)}`);
-    }
-    case 3: {
-      const aa = strKind(n.types[0]);
-      const bb = strKind(n.types[1]);
-      const cc = strKind(n.types[2]);
-      if (nm === 'workspace/symbol') return `${goType(n.types[0], '930')} ${help}`;
-      if (nm == 'DocumentFilter' || nm == 'NotebookDocumentFilter' || nm == 'TextDocumentFilter') {
-        // not really a union. the first is enough, up to a missing
-        // omitempty but avoid repetitious comments
-        return `${goType(n.types[0], 'g')}`;
-      }
-      if (nm == 'textDocument/documentSymbol') {
-        return `[]interface{} ${help}`;
-      }
-      if (aa == 'TypeReference' && bb == 'ArrayType' && (cc == 'NullKeyword' || cc === 'LiteralType')) {
-        return `${goType(n.types[0], 'd')} ${help}`;
-      }
-      if (aa == 'TypeReference' && bb == aa && cc == 'ArrayType') {
-        // should check that this is Hover.Contents
-        return `${goType(n.types[0], 'e')} ${help}`;
-      }
-      if (aa == 'ArrayType' && bb == 'TypeReference' && (cc == 'NullKeyword' || cc === 'LiteralType')) {
-        // check this is nm == 'textDocument/completion'
-        return `${goType(n.types[1], 'f')} ${help}`;
-      }
-      if (aa == 'LiteralType' && bb == aa && cc == aa) return `string ${help}`;
-      // keep this for diagnosing unexpected interface{} results
-      // console.log(`931, interface{} for ${aa}/${goType(n.types[0], 'g')},${bb}/${goType(n.types[1], 'h')},${cc}/${goType(n.types[2], 'i')} ${nm}`);
-      break;
-    }
-    case 4:
-      if (nm == 'documentChanges') return `TextDocumentEdit ${help} `;
-      if (nm == 'textDocument/prepareRename') {
-        // these names have to be made unique
-        const genName = `${goName("prepareRename")}${extraTypes.size}Gn`;
-        extraTypes.set(genName, [`Range       Range  \`json:"range"\`
-          Placeholder string \`json:"placeholder"\``]);
-        return `${genName} ${help} `;
-      }
-      break;
-    case 8: // LSPany
-      break;
-    default:
-      throw new Error(`957 goUnionType len=${n.types.length} nm=${nm} ${n.getText()}`);
-  }
-
-  // Result will be interface{} with a comment
-  let isLiteral = true;
-  let literal = 'string';
-  let res = 'interface{} /* ';
-  n.types.forEach((v: ts.TypeNode, i: number) => {
-    // might get an interface inside:
-    //  (Command | CodeAction)[] | null
-    let m = goType(v, nm);
-    if (m.indexOf('interface') != -1) {
-      // avoid nested comments
-      m = m.split(' ')[0];
-    }
-    m = m.split('\n').join('; ');  // sloppy: struct{;
-    res = res.concat(`${i == 0 ? '' : ' | '}`, m);
-    if (!ts.isLiteralTypeNode(v)) isLiteral = false;
-    else literal = strKind(v.literal) == 'StringLiteral' ? 'string' : 'number';
-  });
-  if (!isLiteral) {
-    return res + '*/';
-  }
-  // I don't think we get here
-  // trace?: 'off' | 'messages' | 'verbose' should get string
-  return `${literal} /* ${n.getText()} */`;
-}
-
-// some of the intersection types A&B are ok as struct{A;B;} and some
-// could be expanded, and ClientCapabilites has to be expanded,
-// at least for workspace. It's possible to check algorithmically,
-// but much simpler just to check explicitly.
-function goIntersectionType(n: ts.IntersectionTypeNode, nm: string): string {
-  if (nm == 'ClientCapabilities') return expandIntersection(n);
-  //if (nm == 'ServerCapabilities') return expandIntersection(n); // save for later consideration
-  let inner = '';
-  n.types.forEach(
-    (t: ts.TypeNode) => { inner = inner.concat(goType(t, nm), '\n'); });
-  return `struct{ \n${inner}} `;
-}
-
-// for each of the intersected types, extract its components (each will
-// have a Data with properties) extract the properties, and keep track
-// of them by name. The names that occur once can be output. The names
-// that occur more than once need to be combined.
-function expandIntersection(n: ts.IntersectionTypeNode): string {
-  const bad = function (n: ts.Node, s: string) {
-    return new Error(`expandIntersection ${strKind(n)} ${s}`);
-  };
-  let props = new Map<string, ts.PropertySignature[]>();
-  for (const tp of n.types) {
-    if (!ts.isTypeReferenceNode(tp)) throw bad(tp, 'A');
-    const d = data.get(goName(tp.typeName.getText()));
-    for (const p of d.properties) {
-      if (!ts.isPropertySignature(p)) throw bad(p, 'B');
-      let v = props.get(p.name.getText()) || [];
-      v.push(p);
-      props.set(p.name.getText(), v);
-    }
-  }
-  let ans = 'struct {\n';
-  for (const [k, v] of Array.from(props)) {
-    if (v.length == 1) {
-      const a = v[0];
-      ans = ans.concat(getComments(a));
-      ans = ans.concat(`${goName(k)} ${goType(a.type, k)} ${u.JSON(a)}\n`);
-      continue;
-    }
-    ans = ans.concat(`${goName(k)} struct {\n`);
-    for (let i = 0; i < v.length; i++) {
-      const a = v[i];
-      if (ts.isTypeReferenceNode(a.type)) {
-        ans = ans.concat(getComments(a));
-        ans = ans.concat(goName(a.type.typeName.getText()), '\n');
-      } else if (ts.isTypeLiteralNode(a.type)) {
-        if (a.type.members.length != 1) throw bad(a.type, 'C');
-        const b = a.type.members[0];
-        if (!ts.isPropertySignature(b)) throw bad(b, 'D');
-        ans = ans.concat(getComments(b));
-        ans = ans.concat(
-          goName(b.name.getText()), ' ', goType(b.type, 'a'), u.JSON(b), '\n');
-      } else {
-        throw bad(a.type, `E ${a.getText()} in ${goName(k)} at ${loc(a)}`);
-      }
-    }
-    ans = ans.concat('}\n');
-  }
-  ans = ans.concat('}\n');
-  return ans;
-}
-
-// Does it make sense to use a pointer?
-function isStructType(te: ts.TypeNode): boolean {
-  switch (strKind(te)) {
-    case 'UnionType': // really need to know which type will be chosen
-    case 'BooleanKeyword':
-    case 'StringKeyword':
-    case 'ArrayType':
-      return false;
-    case 'TypeLiteral': return false; // true makes for difficult compound constants
-    // but think more carefully to understands why starred is needed.
-    case 'TypeReference': {
-      if (!ts.isTypeReferenceNode(te)) throw new Error(`1047 impossible ${strKind(te)}`);
-      const d = seenTypes.get(goName(te.typeName.getText()));
-      if (d === undefined || d.properties.length == 0) return false;
-      if (d.properties.length > 1) return true;
-      // alias or interface with a single property (The alias is Uinteger, which we ignore later)
-      if (d.alias) return false;
-      const x = d.properties[0].type;
-      return isStructType(x);
-    }
-    default: throw new Error(`1055 indirectable> ${strKind(te)}`);
-  }
-}
-
-function goTypeLiteral(n: ts.TypeLiteralNode, nm: string): string {
-  let ans: string[] = [];  // in case we generate a new extra type
-  let res = 'struct{\n';   // the actual answer usually
-  const g = function (nx: ts.TypeElement) {
-    // add the json, as in goInterface(). Strange inside union types.
-    if (ts.isPropertySignature(nx)) {
-      let json = u.JSON(nx);
-      let typ = goType(nx.type, nx.name.getText());
-      // }/*\n*/`json:v` is not legal, the comment is a newline
-      if (typ.includes('\n') && typ.indexOf('*/') === typ.length - 2) {
-        typ = typ.replace(/\n\t*/g, ' ');
-      }
-      const v = getComments(nx) || '';
-      starred.forEach(([a, b]) => {
-        if (a != nm || b != typ.toLowerCase()) return;
-        typ = '*' + typ;
-        json = json.substring(0, json.length - 2) + ',omitempty"`';
-      });
-      if (typ[0] !== '*' && isStructType(nx.type)) typ = '*' + typ;
-      res = res.concat(`${v} ${goName(nx.name.getText())} ${typ}`, json, '\n');
-      ans.push(`${v}${goName(nx.name.getText())} ${typ} ${json}\n`);
-    } else if (ts.isIndexSignatureDeclaration(nx)) {
-      const comment = nx.getText().replace(/[/]/g, '');
-      if (nx.getText() == '[uri: string]: TextEdit[];') {
-        res = 'map[string][]TextEdit';
-      } else if (nx.getText().startsWith('[id: ChangeAnnotationIdentifier]')) {
-        res = 'map[string]ChangeAnnotationIdentifier';
-      } else if (nx.getText().startsWith('[uri: string')) {
-        res = 'map[string]interface{}';
-      } else if (nx.getText().startsWith('[uri: DocumentUri')) {
-        res = 'map[DocumentURI][]TextEdit';
-      } else if (nx.getText().startsWith('[key: string')) {
-        res = 'map[string]interface{}';
-      } else {
-        throw new Error(`1100 handle ${nx.getText()} ${loc(nx)}`);
-      }
-      res += ` /*${comment}*/`;
-      ans.push(res);
-      return;
-    } else
-      throw new Error(`TypeLiteral had ${strKind(nx)}`);
-  };
-  n.members.forEach(g);
-  // for some the generated type is wanted, for others it's not needed
-  if (!nm.startsWith('workspace')) {
-    if (res.startsWith('struct')) return res + '}';  // map[] is special
-    return res;
-  }
-  // these names have to be made unique
-  const genName = `${goName(nm)}${extraTypes.size}Gn`;
-  extraTypes.set(genName, ans);
-  return genName;
-}
-
-// print all the types and constants and extra types
-function outputTypes() {
-  // generate go types alphabeticaly
-  let v = Array.from(seenTypes.keys());
-  v.sort();
-  v.forEach((x) => toGo(seenTypes.get(x), x));
-  u.prgo(u.computeHeader(true));
-  u.prgo('import "encoding/json"\n\n');
-  typesOut.forEach((s) => {
-    u.prgo(s);
-    // it's more convenient not to have to think about trailing newlines
-    // when generating types, but doc comments can't have an extra \n
-    if (s.indexOf('/**') < 0) u.prgo('\n');
-  });
-  u.prgo('\nconst (\n');
-  constsOut.forEach((s) => {
-    u.prgo(s);
-    u.prgo('\n');
-  });
-  u.prgo(')\n');
-  u.prgo('// Types created to name formal parameters and embedded structs\n');
-  extraTypes.forEach((v, k) => {
-    u.prgo(` type ${k} struct {\n`);
-    v.forEach((s) => {
-      u.prgo(s);
-      u.prgo('\n');
-    });
-    u.prgo('}\n');
-  });
-}
-
-// client and server ------------------
-
-interface side {
-  methods: string[];
-  cases: string[];
-  calls: string[];
-  name: string;    // client or server
-  goName: string;  // Client or Server
-  outputFile?: string;
-  fd?: number
-}
-let client: side = {
-  methods: [],
-  cases: [],
-  calls: [],
-  name: 'client',
-  goName: 'Client',
-};
-let server: side = {
-  methods: [],
-  cases: [],
-  calls: [],
-  name: 'server',
-  goName: 'Server',
-};
-
-// commonly used output
-const notNil = `if len(r.Params()) > 0 {
-  return true, reply(ctx, nil, fmt.Errorf("%w: expected no params", jsonrpc2.ErrInvalidParams))
-}`;
-
-// Go code for notifications. Side is client or server, m is the request
-// method
-function goNot(side: side, m: string) {
-  if (m == '$/cancelRequest') return;  // handled specially in protocol.go
-  const n = not.get(m);
-  const a = goType(n.typeArguments[0], m);
-  const nm = methodName(m);
-  side.methods.push(sig(nm, a, ''));
-  const caseHdr = ` case "${m}":  // notif`;
-  let case1 = notNil;
-  if (a != '' && a != 'void') {
-    case1 = `var params ${a}
-    if err := json.Unmarshal(r.Params(), &params); err != nil {
-      return true, sendParseError(ctx, reply, err)
-    }
-    err:= ${side.name}.${nm}(ctx, &params)
-    return true, reply(ctx, nil, err)`;
-  } else {
-    case1 = `err := ${side.name}.${nm}(ctx)
-    return true, reply(ctx, nil, err)`;
-  }
-  side.cases.push(`${caseHdr}\n${case1}`);
-
-  const arg3 = a == '' || a == 'void' ? 'nil' : 'params';
-  side.calls.push(`
-  func (s *${side.name}Dispatcher) ${sig(nm, a, '', true)} {
-    return s.sender.Notify(ctx, "${m}", ${arg3})
-  }`);
-}
-
-// Go code for requests.
-function goReq(side: side, m: string) {
-  const n = req.get(m);
-  const nm = methodName(m);
-  let a = goType(n.typeArguments[0], m);
-  let b = goType(n.typeArguments[1], m);
-  if (n.getText().includes('Type0')) {
-    b = a;
-    a = '';  // workspace/workspaceFolders and shutdown
-  }
-  u.prb(`${side.name} req ${a != ''}, ${b != ''} ${nm} ${m} ${loc(n)} `);
-  side.methods.push(sig(nm, a, b));
-
-  const caseHdr = `case "${m}": // req`;
-  let case1 = notNil;
-  if (a != '') {
-    if (extraTypes.has('Param' + nm)) a = 'Param' + nm;
-    case1 = `var params ${a}
-    if err := json.Unmarshal(r.Params(), &params); err != nil {
-      return true, sendParseError(ctx, reply, err)
-    }`;
-    if (a === 'ParamInitialize') {
-      case1 = `var params ${a}
-    if err := json.Unmarshal(r.Params(), &params); err != nil {
-      if _, ok := err.(*json.UnmarshalTypeError); !ok {
-        return true, sendParseError(ctx, reply, err)
-      }
-    }`;
-    }
-  }
-  const arg2 = a == '' ? '' : ', &params';
-  // if case2 is not explicitly typed string, typescript makes it a union of strings
-  let case2: string = `if err := ${side.name}.${nm}(ctx${arg2}); err != nil {
-    event.Error(ctx, "", err)
-  }`;
-  if (b != '' && b != 'void') {
-    case2 = `resp, err := ${side.name}.${nm}(ctx${arg2})
-    if err != nil {
-      return true, reply(ctx, nil, err)
-    }
-    return true, reply(ctx, resp, nil)`;
-  } else {  // response is nil
-    case2 = `err := ${side.name}.${nm}(ctx${arg2})
-    return true, reply(ctx, nil, err)`;
-  }
-
-  side.cases.push(`${caseHdr}\n${case1}\n${case2}`);
-
-  const callHdr = `func (s *${side.name}Dispatcher) ${sig(nm, a, b, true)} {`;
-  let callBody = `return s.sender.Call(ctx, "${m}", nil, nil)\n}`;
-  if (b != '' && b != 'void') {
-    const p2 = a == '' ? 'nil' : 'params';
-    const returnType = indirect(b) ? `*${b}` : b;
-    callBody = `var result ${returnType}
-			if err := s.sender.Call(ctx, "${m}", ${p2}, &result); err != nil {
-				return nil, err
-      }
-      return result, nil
-    }`;
-  } else if (a != '') {
-    callBody = `return s.sender.Call(ctx, "${m}", params, nil) // Call, not Notify
-  }`;
-  }
-  side.calls.push(`${callHdr}\n${callBody}\n`);
-}
-
-// make sure method names are unique
-let seenNames = new Set<string>();
-function methodName(m: string): string {
-  let i = m.indexOf('/');
-  let s = m.substring(i + 1);
-  let x = s[0].toUpperCase() + s.substring(1);
-  for (let j = x.indexOf('/'); j >= 0; j = x.indexOf('/')) {
-    let suffix = x.substring(j + 1);
-    suffix = suffix[0].toUpperCase() + suffix.substring(1);
-    let prefix = x.substring(0, j);
-    x = prefix + suffix;
-  }
-  if (seenNames.has(x)) {
-    // various Resolve and Diagnostic
-    x += m[0].toUpperCase() + m.substring(1, i);
-  }
-  seenNames.add(x);
-  return x;
-}
-
-// used in sig and in goReq
-function indirect(s: string): boolean {
-  if (s == '' || s == 'void') return false;
-  const skip = (x: string) => s.startsWith(x);
-  if (skip('[]') || skip('interface') || skip('Declaration') ||
-    skip('Definition') || skip('DocumentSelector'))
-    return false;
-  return true;
-}
-
-// Go signatures for methods.
-function sig(nm: string, a: string, b: string, names?: boolean): string {
-  if (a.indexOf('struct') != -1) {
-    const v = a.split('\n');
-    extraTypes.set(`Param${nm}`, v.slice(1, v.length - 1));
-    a = 'Param' + nm;
-  }
-  if (a == 'void')
-    a = '';
-  else if (a != '') {
-    if (names)
-      a = ', params *' + a;
-    else
-      a = ', *' + a;
-  }
-  let ret = 'error';
-  if (b != '' && b != 'void') {
-    // avoid * when it is senseless
-    if (indirect(b)) b = '*' + b;
-    ret = `(${b}, error)`;
-  }
-  let start = `${nm}(`;
-  if (names) {
-    start = start + 'ctx ';
-  }
-  return `${start}context.Context${a}) ${ret}`;
-}
-
-// write the request/notification code
-function output(side: side) {
-  // make sure the output file exists
-  if (!side.outputFile) {
-    side.outputFile = `ts${side.name}.go`;
-    side.fd = fs.openSync(side.outputFile, 'w');
-  }
-  const f = function (s: string) {
-    fs.writeSync(side.fd!, s);
-    fs.writeSync(side.fd!, '\n');
-  };
-  f(u.computeHeader(false));
-  f(`
-        import (
-          "context"
-          "encoding/json"
-
-          "golang.org/x/tools/internal/jsonrpc2"
-        )
-        `);
-  const a = side.name[0].toUpperCase() + side.name.substring(1);
-  f(`type ${a} interface {`);
-  side.methods.forEach((v) => { f(v); });
-  f('}\n');
-  f(`func ${side.name}Dispatch(ctx context.Context, ${side.name} ${a}, reply jsonrpc2.Replier, r jsonrpc2.Request) (bool, error) {
-          switch r.Method() {`);
-  side.cases.forEach((v) => { f(v); });
-  f(`
-        default:
-          return false, nil
-        }
-      }`);
-  side.calls.forEach((v) => { f(v); });
-}
-
-// Handling of non-standard requests, so we can add gopls-specific calls.
-function nonstandardRequests() {
-  server.methods.push(
-    'NonstandardRequest(ctx context.Context, method string, params interface{}) (interface{}, error)');
-  server.calls.push(
-    `func (s *serverDispatcher) NonstandardRequest(ctx context.Context, method string, params interface{}) (interface{}, error) {
-      var result interface{}
-      if err := s.sender.Call(ctx, method, params, &result); err != nil {
-        return nil, err
-      }
-      return result, nil
-    }
-  `);
-}
-
-// ----- remember it's a scripting language
-function main() {
-  if (u.gitHash != u.git()) {
-    throw new Error(
-      `git hash mismatch, wanted\n${u.gitHash} but source is at\n${u.git()}`);
-  }
-  u.createOutputFiles();
-  parse();
-  u.printAST(program);
-  // find the Requests and Nofificatations
-  for (const sourceFile of program.getSourceFiles()) {
-    if (!sourceFile.isDeclarationFile) {
-      ts.forEachChild(sourceFile, findRPCs);
-    }
-  }
-  // separate RPCs into client and server
-  setReceives();
-  // visit every sourceFile collecting top-level type definitions
-  for (const sourceFile of program.getSourceFiles()) {
-    if (!sourceFile.isDeclarationFile) {
-      ts.forEachChild(sourceFile, genTypes);
-    }
-  }
-  // check that each thing occurs exactly once, and put pointers into
-  // seenTypes
-  checkOnce();
-  // for each of Client and Server there are 3 parts to the output:
-  // 1. type X interface {methods}
-  // 2. func (h *serverHandler) Deliver(...) { switch r.method }
-  // 3. func (x *xDispatcher) Method(ctx, parm)
-  not.forEach(  // notifications
-    (v, k) => {
-      receives.get(k) == 'client' ? goNot(client, k) : goNot(server, k);
-    });
-  req.forEach(  // requests
-    (v, k) => {
-      receives.get(k) == 'client' ? goReq(client, k) : goReq(server, k);
-    });
-  nonstandardRequests();
-  // find all the types implied by seenTypes and rpcs to try to avoid
-  // generating types that aren't used
-  moreTypes();
-  // do merging
-  cleanData();
-  // and print the Go code
-  outputTypes();
-  console.log(`seen ${seenTypes.size + extraTypes.size}`);
-  output(client);
-  output(server);
-}
-
-main();
diff -urN a/gopls/internal/lsp/protocol/typescript/tsconfig.json b/gopls/internal/lsp/protocol/typescript/tsconfig.json
--- a/gopls/internal/lsp/protocol/typescript/tsconfig.json	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/typescript/tsconfig.json	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-{
-    "compilerOptions": {
-        "isolatedModules": true,
-        "moduleResolution": "node",
-        "lib":["ES2020"],
-        "sourceMap": true, // sourceMap or inlineSourceMap? and see inlineSources
-        "target": "ES5",
-
-        "noFallthroughCasesInSwitch": false, // there is one legitimate on
-        "noImplicitReturns": true,
-        "noPropertyAccessFromIndexSignature": true,
-        "noUncheckedIndexedAccess": true,
-        "noUnusedLocals": true,
-        "noUnusedParameters": false,
-        "noEmitOnError": true,
-
-        // "extendedDiagnostics": true, // for occasional amusement
-
-        // "strict": true, // too many undefineds in types, etc
-        "alwaysStrict": true,
-        "noImplicitAny": true,
-        "noImplicitThis": true,
-        "strictBindCallApply": true,
-        "strictFunctionTypes": true,
-        "strictNullChecks": false, // doesn't like arrray access, among other things.
-        //"strictPropertyInitialization": true, // needs strictNullChecks
-    },
-    "files": ["./code.ts", "./util.ts"]
-}
diff -urN a/gopls/internal/lsp/protocol/typescript/util.ts b/gopls/internal/lsp/protocol/typescript/util.ts
--- a/gopls/internal/lsp/protocol/typescript/util.ts	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/protocol/typescript/util.ts	1969-12-31 16:00:00
@@ -1,254 +0,0 @@
-
-// for us typescript ignorati, having an import makes this file a module
-import * as fs from 'fs';
-import * as process from 'process';
-import * as ts from 'typescript';
-
-// This file contains various utilities having to do with producing strings
-// and managing output
-
-// ------ create files
-let dir = process.env['HOME'];
-const srcDir = '/vscode-languageserver-node';
-export const fnames = [
-  `${dir}${srcDir}/protocol/src/common/protocol.ts`,
-  `${dir}/${srcDir}/protocol/src/browser/main.ts`, `${dir}${srcDir}/types/src/main.ts`,
-  `${dir}${srcDir}/jsonrpc/src/node/main.ts`
-];
-export const gitHash = '696f9285bf849b73745682fdb1c1feac73eb8772';
-let outFname = 'tsprotocol.go';
-let fda: number, fdb: number, fde: number;  // file descriptors
-
-export function createOutputFiles() {
-  fda = fs.openSync('/tmp/ts-a', 'w');  // dump of AST
-  fdb = fs.openSync('/tmp/ts-b', 'w');  // unused, for debugging
-  fde = fs.openSync(outFname, 'w');     // generated Go
-}
-export function pra(s: string) {
-  return (fs.writeSync(fda, s));
-}
-export function prb(s: string) {
-  return (fs.writeSync(fdb, s));
-}
-export function prgo(s: string) {
-  return (fs.writeSync(fde, s));
-}
-
-// Get the hash value of the git commit
-export function git(): string {
-  let a = fs.readFileSync(`${dir}${srcDir}/.git/HEAD`).toString();
-  // ref: refs/heads/foo, or a hash like
-  // cc12d1a1c7df935012cdef5d085cdba04a7c8ebe
-  if (a.charAt(a.length - 1) == '\n') {
-    a = a.substring(0, a.length - 1);
-  }
-  if (a.length == 40) {
-    return a;  // a hash
-  }
-  if (a.substring(0, 5) == 'ref: ') {
-    const fname = `${dir}${srcDir}/.git/` + a.substring(5);
-    let b = fs.readFileSync(fname).toString();
-    if (b.length == 41) {
-      return b.substring(0, 40);
-    }
-  }
-  throw new Error('failed to find the git commit hash');
-}
-
-// Produce a header for Go output files
-export function computeHeader(pkgDoc: boolean): string {
-  let lastMod = 0;
-  let lastDate = new Date();
-  for (const f of fnames) {
-    const st = fs.statSync(f);
-    if (st.mtimeMs > lastMod) {
-      lastMod = st.mtimeMs;
-      lastDate = st.mtime;
-    }
-  }
-  const cp = `// Copyright 2019 The Go Authors. All rights reserved.
-  // Use of this source code is governed by a BSD-style
-  // license that can be found in the LICENSE file.
-
-  `;
-  const a =
-    '// Package protocol contains data types and code for LSP json rpcs\n' +
-    '// generated automatically from vscode-languageserver-node\n' +
-    `// commit: ${gitHash}\n` +
-    `// last fetched ${lastDate}\n`;
-  const b = 'package protocol\n';
-  const c = '\n// Code generated (see typescript/README.md) DO NOT EDIT.\n\n';
-  if (pkgDoc) {
-    return cp + c + a + b;
-  }
-  else {
-    return cp + c+ b + a;
-  }
-}
-
-// Turn a typescript name into an exportable Go name, and appease lint
-export function goName(s: string): string {
-  let ans = s;
-  if (s.charAt(0) == '_') {
-    // in the end, none of these are emitted.
-    ans = 'Inner' + s.substring(1);
-  }
-  else { ans = s.substring(0, 1).toUpperCase() + s.substring(1); }
-  ans = ans.replace(/Uri$/, 'URI');
-  ans = ans.replace(/Id$/, 'ID');
-  return ans;
-}
-
-// Generate JSON tag for a struct field
-export function JSON(n: ts.PropertySignature): string {
-  const json = `\`json:"${n.name.getText()}${n.questionToken !== undefined ? ',omitempty' : ''}"\``;
-  return json;
-}
-
-// Generate modifying prefixes and suffixes to ensure
-// consts are unique. (Go consts are package-level, but Typescript's are
-// not.) Use suffixes to minimize changes to gopls.
-export function constName(nm: string, type: string): string {
-  let pref = new Map<string, string>([
-    ['DiagnosticSeverity', 'Severity'], ['WatchKind', 'Watch'],
-    ['SignatureHelpTriggerKind', 'Sig'], ['CompletionItemTag', 'Compl'],
-    ['Integer', 'INT_'], ['Uinteger', 'UINT_'], ['CodeActionTriggerKind', 'CodeAction']
-  ]);  // typeName->prefix
-  let suff = new Map<string, string>([
-    ['CompletionItemKind', 'Completion'], ['InsertTextFormat', 'TextFormat'],
-    ['SymbolTag', 'Symbol'], ['FileOperationPatternKind', 'Op'],
-  ]);
-  let ans = nm;
-  if (pref.get(type)) ans = pref.get(type) + ans;
-  if (suff.has(type)) ans = ans + suff.get(type);
-  return ans;
-}
-
-// Find the comments associated with an AST node
-export function getComments(node: ts.Node): string {
-  const sf = node.getSourceFile();
-  const start = node.getStart(sf, false);
-  const starta = node.getStart(sf, true);
-  const x = sf.text.substring(starta, start);
-  return x;
-}
-
-
-// --------- printing the AST, for debugging
-
-export function printAST(program: ts.Program) {
-  // dump the ast, for debugging
-  const f = function (n: ts.Node) {
-    describe(n, pra);
-  };
-  for (const sourceFile of program.getSourceFiles()) {
-    if (!sourceFile.isDeclarationFile) {
-      // walk the tree to do stuff
-      ts.forEachChild(sourceFile, f);
-    }
-  }
-  pra('\n');
-  for (const key of Object.keys(seenThings).sort()) {
-    pra(`${key}: ${seenThings.get(key)} \n`);
-  }
-}
-
-// Used in printing the AST
-let seenThings = new Map<string, number>();
-function seenAdd(x: string) {
-  const u = seenThings.get(x);
-  seenThings.set(x, u === undefined ? 1 : u + 1);
-}
-
-// eslint-disable-next-line no-unused-vars
-function describe(node: ts.Node, pr: (_: string) => any) {
-  if (node === undefined) {
-    return;
-  }
-  let indent = '';
-
-  function f(n: ts.Node) {
-    seenAdd(kinds(n));
-    if (ts.isIdentifier(n)) {
-      pr(`${indent} ${loc(n)} ${strKind(n)} ${n.text} \n`);
-    }
-    else if (ts.isPropertySignature(n) || ts.isEnumMember(n)) {
-      pra(`${indent} ${loc(n)} ${strKind(n)} \n`);
-    }
-    else if (ts.isTypeLiteralNode(n)) {
-      let m = n.members;
-      pr(`${indent} ${loc(n)} ${strKind(n)} ${m.length} \n`);
-    }
-    else if (ts.isStringLiteral(n)) {
-      pr(`${indent} ${loc(n)} ${strKind(n)} ${n.text} \n`);
-    }
-    else { pr(`${indent} ${loc(n)} ${strKind(n)} \n`); }
-    indent += ' .';
-    ts.forEachChild(n, f);
-    indent = indent.slice(0, indent.length - 2);
-  }
-  f(node);
-}
-
-
-// For debugging, say where an AST node is in a file
-export function loc(node: ts.Node | undefined): string {
-  if (!node) throw new Error('loc called with undefined (cannot happen!)');
-  const sf = node.getSourceFile();
-  const start = node.getStart();
-  const x = sf.getLineAndCharacterOfPosition(start);
-  const full = node.getFullStart();
-  const y = sf.getLineAndCharacterOfPosition(full);
-  let fn = sf.fileName;
-  const n = fn.search(/-node./);
-  fn = fn.substring(n + 6);
-  return `${fn} ${x.line + 1}: ${x.character + 1} (${y.line + 1}: ${y.character + 1})`;
-}
-
-// --- various string stuff
-
-// return a string of the kinds of the immediate descendants
-// as part of printing the AST tree
-function kinds(n: ts.Node): string {
-  let res = 'Seen ' + strKind(n);
-  function f(n: ts.Node): void { res += ' ' + strKind(n); }
-  ts.forEachChild(n, f);
-  return res;
-}
-
-// What kind of AST node is it? This would just be typescript's
-// SyntaxKind[n.kind] except that the default names for some nodes
-// are misleading
-export function strKind(n: ts.Node | undefined): string {
-  if (n == null || n == undefined) {
-    return 'null';
-  }
-  return kindToStr(n.kind);
-}
-
-function kindToStr(k: ts.SyntaxKind): string {
-  const x = ts.SyntaxKind[k];
-  // some of these have two names
-  switch (x) {
-    default:
-      return x;
-    case 'FirstAssignment':
-      return 'EqualsToken';
-    case 'FirstBinaryOperator':
-      return 'LessThanToken';
-    case 'FirstCompoundAssignment':
-      return 'PlusEqualsToken';
-    case 'FirstContextualKeyword':
-      return 'AbstractKeyword';
-    case 'FirstLiteralToken':
-      return 'NumericLiteral';
-    case 'FirstNode':
-      return 'QualifiedName';
-    case 'FirstTemplateToken':
-      return 'NoSubstitutionTemplateLiteral';
-    case 'LastTemplateToken':
-      return 'TemplateTail';
-    case 'FirstTypeNode':
-      return 'TypePredicate';
-  }
-}
diff -urN a/gopls/internal/lsp/references.go b/gopls/internal/lsp/references.go
--- a/gopls/internal/lsp/references.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/references.go	1969-12-31 16:00:00
@@ -1,40 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-)
-
-func (s *Server) references(ctx context.Context, params *protocol.ReferenceParams) ([]protocol.Location, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	if snapshot.View().FileKind(fh) == source.Tmpl {
-		return template.References(ctx, snapshot, fh, params)
-	}
-	references, err := source.References(ctx, snapshot, fh, params.Position, params.Context.IncludeDeclaration)
-	if err != nil {
-		return nil, err
-	}
-	var locations []protocol.Location
-	for _, ref := range references {
-		refRange, err := ref.Range()
-		if err != nil {
-			return nil, err
-		}
-		locations = append(locations, protocol.Location{
-			URI:   protocol.URIFromSpanURI(ref.URI()),
-			Range: refRange,
-		})
-	}
-	return locations, nil
-}
diff -urN a/gopls/internal/lsp/regtest/doc.go b/gopls/internal/lsp/regtest/doc.go
--- a/gopls/internal/lsp/regtest/doc.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/doc.go	1969-12-31 16:00:00
@@ -1,157 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package regtest provides a framework for writing gopls regression tests.
-//
-// User reported regressions are often expressed in terms of editor
-// interactions. For example: "When I open my editor in this directory,
-// navigate to this file, and change this line, I get a diagnostic that doesn't
-// make sense". In these cases reproducing, diagnosing, and writing a test to
-// protect against this regression can be difficult.
-//
-// The regtest package provides an API for developers to express these types of
-// user interactions in ordinary Go tests, validate them, and run them in a
-// variety of execution modes.
-//
-// # Test package setup
-//
-// The regression test package uses a couple of uncommon patterns to reduce
-// boilerplate in test bodies. First, it is intended to be imported as "." so
-// that helpers do not need to be qualified. Second, it requires some setup
-// that is currently implemented in the regtest.Main function, which must be
-// invoked by TestMain. Therefore, a minimal regtest testing package looks
-// like this:
-//
-//	package lsptests
-//
-//	import (
-//		"fmt"
-//		"testing"
-//
-//		"golang.org/x/tools/gopls/internal/hooks"
-//		. "golang.org/x/tools/gopls/internal/lsp/regtest"
-//	)
-//
-//	func TestMain(m *testing.M) {
-//		Main(m, hooks.Options)
-//	}
-//
-// # Writing a simple regression test
-//
-// To run a regression test use the regtest.Run function, which accepts a
-// txtar-encoded archive defining the initial workspace state. This function
-// sets up the workspace in a temporary directory, creates a fake text editor,
-// starts gopls, and initializes an LSP session. It then invokes the provided
-// test function with an *Env handle encapsulating the newly created
-// environment. Because gopls may be run in various modes (as a sidecar or
-// daemon process, with different settings), the test runner may perform this
-// process multiple times, re-running the test function each time with a new
-// environment.
-//
-//	func TestOpenFile(t *testing.T) {
-//		const files = `
-//	-- go.mod --
-//	module mod.com
-//
-//	go 1.12
-//	-- foo.go --
-//	package foo
-//	`
-//		Run(t, files, func(t *testing.T, env *Env) {
-//			env.OpenFile("foo.go")
-//		})
-//	}
-//
-// # Configuring Regtest Execution
-//
-// The regtest package exposes several options that affect the setup process
-// described above. To use these options, use the WithOptions function:
-//
-//	WithOptions(opts...).Run(...)
-//
-// See options.go for a full list of available options.
-//
-// # Operating on editor state
-//
-// To operate on editor state within the test body, the Env type provides
-// access to the workspace directory (Env.SandBox), text editor (Env.Editor),
-// LSP server (Env.Server), and 'awaiter' (Env.Awaiter).
-//
-// In most cases, operations on these primitive building blocks of the
-// regression test environment expect a Context (which should be a child of
-// env.Ctx), and return an error. To avoid boilerplate, the Env exposes a set
-// of wrappers in wrappers.go for use in scripting:
-//
-//	env.CreateBuffer("c/c.go", "")
-//	env.EditBuffer("c/c.go", fake.Edit{
-//		Text: `package c`,
-//	})
-//
-// These wrappers thread through Env.Ctx, and call t.Fatal on any errors.
-//
-// # Expressing expectations
-//
-// The general pattern for a regression test is to script interactions with the
-// fake editor and sandbox, and assert that gopls behaves correctly after each
-// state change. Unfortunately, this is complicated by the fact that state
-// changes are communicated to gopls via unidirectional client->server
-// notifications (didOpen, didChange, etc.), and resulting gopls behavior such
-// as diagnostics, logs, or messages is communicated back via server->client
-// notifications. Therefore, within regression tests we must be able to say "do
-// this, and then eventually gopls should do that". To achieve this, the
-// regtest package provides a framework for expressing conditions that must
-// eventually be met, in terms of the Expectation type.
-//
-// To express the assertion that "eventually gopls must meet these
-// expectations", use env.Await(...):
-//
-//	env.RegexpReplace("x/x.go", `package x`, `package main`)
-//	env.Await(env.DiagnosticAtRegexp("x/main.go", `fmt`))
-//
-// Await evaluates the provided expectations atomically, whenever the client
-// receives a state-changing notification from gopls. See expectation.go for a
-// full list of available expectations.
-//
-// A fundamental problem with this model is that if gopls never meets the
-// provided expectations, the test runner will hang until the test timeout
-// (which defaults to 10m). There are two ways to work around this poor
-// behavior:
-//
-//  1. Use a precondition to define precisely when we expect conditions to be
-//     met. Gopls provides the OnceMet(precondition, expectations...) pattern
-//     to express ("once this precondition is met, the following expectations
-//     must all hold"). To instrument preconditions, gopls uses verbose
-//     progress notifications to inform the client about ongoing work (see
-//     CompletedWork). The most common precondition is to wait for gopls to be
-//     done processing all change notifications, for which the regtest package
-//     provides the AfterChange helper. For example:
-//
-//     // We expect diagnostics to be cleared after gopls is done processing the
-//     // didSave notification.
-//     env.SaveBuffer("a/go.mod")
-//     env.AfterChange(EmptyDiagnostics("a/go.mod"))
-//
-//  2. Set a shorter timeout during development, if you expect to be breaking
-//     tests. By setting the environment variable GOPLS_REGTEST_TIMEOUT=5s,
-//     regression tests will time out after 5 seconds.
-//
-// # Tips & Tricks
-//
-// Here are some tips and tricks for working with regression tests:
-//
-//  1. Set the environment variable GOPLS_REGTEST_TIMEOUT=5s during development.
-//  2. Run tests with  -short. This will only run regression tests in the
-//     default gopls execution mode.
-//  3. Use capture groups to narrow regexp positions. All regular-expression
-//     based positions (such as DiagnosticAtRegexp) will match the position of
-//     the first capture group, if any are provided. This can be used to
-//     identify a specific position in the code for a pattern that may occur in
-//     multiple places. For example `var (mu) sync.Mutex` matches the position
-//     of "mu" within the variable declaration.
-//  4. Read diagnostics into a variable to implement more complicated
-//     assertions about diagnostic state in the editor. To do this, use the
-//     pattern OnceMet(precondition, ReadDiagnostics("file.go", &d)) to capture
-//     the current diagnostics as soon as the precondition is met. This is
-//     preferable to accessing the diagnostics directly, as it avoids races.
-package regtest
diff -urN a/gopls/internal/lsp/regtest/env.go b/gopls/internal/lsp/regtest/env.go
--- a/gopls/internal/lsp/regtest/env.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/env.go	1969-12-31 16:00:00
@@ -1,367 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"context"
-	"fmt"
-	"strings"
-	"sync"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-)
-
-// Env holds the building blocks of an editor testing environment, providing
-// wrapper methods that hide the boilerplate of plumbing contexts and checking
-// errors.
-type Env struct {
-	T   testing.TB // TODO(rfindley): rename to TB
-	Ctx context.Context
-
-	// Most tests should not need to access the scratch area, editor, server, or
-	// connection, but they are available if needed.
-	Sandbox *fake.Sandbox
-	Server  servertest.Connector
-
-	// Editor is owned by the Env, and shut down
-	Editor *fake.Editor
-
-	Awaiter *Awaiter
-}
-
-// An Awaiter keeps track of relevant LSP state, so that it may be asserted
-// upon with Expectations.
-//
-// Wire it into a fake.Editor using Awaiter.Hooks().
-//
-// TODO(rfindley): consider simply merging Awaiter with the fake.Editor. It
-// probably is not worth its own abstraction.
-type Awaiter struct {
-	workdir *fake.Workdir
-
-	mu sync.Mutex
-	// For simplicity, each waiter gets a unique ID.
-	nextWaiterID int
-	state        State
-	waiters      map[int]*condition
-}
-
-func NewAwaiter(workdir *fake.Workdir) *Awaiter {
-	return &Awaiter{
-		workdir: workdir,
-		state: State{
-			diagnostics: make(map[string]*protocol.PublishDiagnosticsParams),
-			work:        make(map[protocol.ProgressToken]*workProgress),
-		},
-		waiters: make(map[int]*condition),
-	}
-}
-
-func (a *Awaiter) Hooks() fake.ClientHooks {
-	return fake.ClientHooks{
-		OnDiagnostics:            a.onDiagnostics,
-		OnLogMessage:             a.onLogMessage,
-		OnWorkDoneProgressCreate: a.onWorkDoneProgressCreate,
-		OnProgress:               a.onProgress,
-		OnShowMessage:            a.onShowMessage,
-		OnShowMessageRequest:     a.onShowMessageRequest,
-		OnRegistration:           a.onRegistration,
-		OnUnregistration:         a.onUnregistration,
-	}
-}
-
-// State encapsulates the server state TODO: explain more
-type State struct {
-	// diagnostics are a map of relative path->diagnostics params
-	diagnostics        map[string]*protocol.PublishDiagnosticsParams
-	logs               []*protocol.LogMessageParams
-	showMessage        []*protocol.ShowMessageParams
-	showMessageRequest []*protocol.ShowMessageRequestParams
-
-	registrations          []*protocol.RegistrationParams
-	registeredCapabilities map[string]protocol.Registration
-	unregistrations        []*protocol.UnregistrationParams
-
-	// outstandingWork is a map of token->work summary. All tokens are assumed to
-	// be string, though the spec allows for numeric tokens as well.  When work
-	// completes, it is deleted from this map.
-	work map[protocol.ProgressToken]*workProgress
-}
-
-// outstandingWork counts started but not complete work items by title.
-func (s State) outstandingWork() map[string]uint64 {
-	outstanding := make(map[string]uint64)
-	for _, work := range s.work {
-		if !work.complete {
-			outstanding[work.title]++
-		}
-	}
-	return outstanding
-}
-
-// completedWork counts complete work items by title.
-func (s State) completedWork() map[string]uint64 {
-	completed := make(map[string]uint64)
-	for _, work := range s.work {
-		if work.complete {
-			completed[work.title]++
-		}
-	}
-	return completed
-}
-
-// startedWork counts started (and possibly complete) work items.
-func (s State) startedWork() map[string]uint64 {
-	started := make(map[string]uint64)
-	for _, work := range s.work {
-		started[work.title]++
-	}
-	return started
-}
-
-type workProgress struct {
-	title, msg, endMsg string
-	percent            float64
-	complete           bool // seen 'end'.
-}
-
-// This method, provided for debugging, accesses mutable fields without a lock,
-// so it must not be called concurrent with any State mutation.
-func (s State) String() string {
-	var b strings.Builder
-	b.WriteString("#### log messages (see RPC logs for full text):\n")
-	for _, msg := range s.logs {
-		summary := fmt.Sprintf("%v: %q", msg.Type, msg.Message)
-		if len(summary) > 60 {
-			summary = summary[:57] + "..."
-		}
-		// Some logs are quite long, and since they should be reproduced in the RPC
-		// logs on any failure we include here just a short summary.
-		fmt.Fprint(&b, "\t"+summary+"\n")
-	}
-	b.WriteString("\n")
-	b.WriteString("#### diagnostics:\n")
-	for name, params := range s.diagnostics {
-		fmt.Fprintf(&b, "\t%s (version %d):\n", name, int(params.Version))
-		for _, d := range params.Diagnostics {
-			fmt.Fprintf(&b, "\t\t(%d, %d) [%s]: %s\n", int(d.Range.Start.Line), int(d.Range.Start.Character), d.Source, d.Message)
-		}
-	}
-	b.WriteString("\n")
-	b.WriteString("#### outstanding work:\n")
-	for token, state := range s.work {
-		if state.complete {
-			continue
-		}
-		name := state.title
-		if name == "" {
-			name = fmt.Sprintf("!NO NAME(token: %s)", token)
-		}
-		fmt.Fprintf(&b, "\t%s: %.2f\n", name, state.percent)
-	}
-	b.WriteString("#### completed work:\n")
-	for name, count := range s.completedWork() {
-		fmt.Fprintf(&b, "\t%s: %d\n", name, count)
-	}
-	return b.String()
-}
-
-// A condition is satisfied when all expectations are simultaneously
-// met. At that point, the 'met' channel is closed. On any failure, err is set
-// and the failed channel is closed.
-type condition struct {
-	expectations []Expectation
-	verdict      chan Verdict
-}
-
-func (a *Awaiter) onDiagnostics(_ context.Context, d *protocol.PublishDiagnosticsParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	pth := a.workdir.URIToPath(d.URI)
-	a.state.diagnostics[pth] = d
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) onShowMessage(_ context.Context, m *protocol.ShowMessageParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	a.state.showMessage = append(a.state.showMessage, m)
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) onShowMessageRequest(_ context.Context, m *protocol.ShowMessageRequestParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	a.state.showMessageRequest = append(a.state.showMessageRequest, m)
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) onLogMessage(_ context.Context, m *protocol.LogMessageParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	a.state.logs = append(a.state.logs, m)
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) onWorkDoneProgressCreate(_ context.Context, m *protocol.WorkDoneProgressCreateParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	a.state.work[m.Token] = &workProgress{}
-	return nil
-}
-
-func (a *Awaiter) onProgress(_ context.Context, m *protocol.ProgressParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-	work, ok := a.state.work[m.Token]
-	if !ok {
-		panic(fmt.Sprintf("got progress report for unknown report %v: %v", m.Token, m))
-	}
-	v := m.Value.(map[string]interface{})
-	switch kind := v["kind"]; kind {
-	case "begin":
-		work.title = v["title"].(string)
-		if msg, ok := v["message"]; ok {
-			work.msg = msg.(string)
-		}
-	case "report":
-		if pct, ok := v["percentage"]; ok {
-			work.percent = pct.(float64)
-		}
-		if msg, ok := v["message"]; ok {
-			work.msg = msg.(string)
-		}
-	case "end":
-		work.complete = true
-		if msg, ok := v["message"]; ok {
-			work.endMsg = msg.(string)
-		}
-	}
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) onRegistration(_ context.Context, m *protocol.RegistrationParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	a.state.registrations = append(a.state.registrations, m)
-	if a.state.registeredCapabilities == nil {
-		a.state.registeredCapabilities = make(map[string]protocol.Registration)
-	}
-	for _, reg := range m.Registrations {
-		a.state.registeredCapabilities[reg.Method] = reg
-	}
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) onUnregistration(_ context.Context, m *protocol.UnregistrationParams) error {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-
-	a.state.unregistrations = append(a.state.unregistrations, m)
-	a.checkConditionsLocked()
-	return nil
-}
-
-func (a *Awaiter) checkConditionsLocked() {
-	for id, condition := range a.waiters {
-		if v, _ := checkExpectations(a.state, condition.expectations); v != Unmet {
-			delete(a.waiters, id)
-			condition.verdict <- v
-		}
-	}
-}
-
-// checkExpectations reports whether s meets all expectations.
-func checkExpectations(s State, expectations []Expectation) (Verdict, string) {
-	finalVerdict := Met
-	var summary strings.Builder
-	for _, e := range expectations {
-		v := e.Check(s)
-		if v > finalVerdict {
-			finalVerdict = v
-		}
-		summary.WriteString(fmt.Sprintf("%v: %s\n", v, e.Description()))
-	}
-	return finalVerdict, summary.String()
-}
-
-// DiagnosticsFor returns the current diagnostics for the file. It is useful
-// after waiting on AnyDiagnosticAtCurrentVersion, when the desired diagnostic
-// is not simply described by DiagnosticAt.
-//
-// TODO(rfindley): this method is inherently racy. Replace usages of this
-// method with the atomic OnceMet(..., ReadDiagnostics) pattern.
-func (a *Awaiter) DiagnosticsFor(name string) *protocol.PublishDiagnosticsParams {
-	a.mu.Lock()
-	defer a.mu.Unlock()
-	return a.state.diagnostics[name]
-}
-
-func (e *Env) Await(expectations ...Expectation) {
-	e.T.Helper()
-	if err := e.Awaiter.Await(e.Ctx, expectations...); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// Await waits for all expectations to simultaneously be met. It should only be
-// called from the main test goroutine.
-func (a *Awaiter) Await(ctx context.Context, expectations ...Expectation) error {
-	a.mu.Lock()
-	// Before adding the waiter, we check if the condition is currently met or
-	// failed to avoid a race where the condition was realized before Await was
-	// called.
-	switch verdict, summary := checkExpectations(a.state, expectations); verdict {
-	case Met:
-		a.mu.Unlock()
-		return nil
-	case Unmeetable:
-		err := fmt.Errorf("unmeetable expectations:\n%s\nstate:\n%v", summary, a.state)
-		a.mu.Unlock()
-		return err
-	}
-	cond := &condition{
-		expectations: expectations,
-		verdict:      make(chan Verdict),
-	}
-	a.waiters[a.nextWaiterID] = cond
-	a.nextWaiterID++
-	a.mu.Unlock()
-
-	var err error
-	select {
-	case <-ctx.Done():
-		err = ctx.Err()
-	case v := <-cond.verdict:
-		if v != Met {
-			err = fmt.Errorf("condition has final verdict %v", v)
-		}
-	}
-	a.mu.Lock()
-	defer a.mu.Unlock()
-	_, summary := checkExpectations(a.state, expectations)
-
-	// Debugging an unmet expectation can be tricky, so we put some effort into
-	// nicely formatting the failure.
-	if err != nil {
-		return fmt.Errorf("waiting on:\n%s\nerr:%v\n\nstate:\n%v", summary, err, a.state)
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/regtest/env_test.go b/gopls/internal/lsp/regtest/env_test.go
--- a/gopls/internal/lsp/regtest/env_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/env_test.go	1969-12-31 16:00:00
@@ -1,66 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"context"
-	"encoding/json"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func TestProgressUpdating(t *testing.T) {
-	a := &Awaiter{
-		state: State{
-			work: make(map[protocol.ProgressToken]*workProgress),
-		},
-	}
-	ctx := context.Background()
-	if err := a.onWorkDoneProgressCreate(ctx, &protocol.WorkDoneProgressCreateParams{
-		Token: "foo",
-	}); err != nil {
-		t.Fatal(err)
-	}
-	if err := a.onWorkDoneProgressCreate(ctx, &protocol.WorkDoneProgressCreateParams{
-		Token: "bar",
-	}); err != nil {
-		t.Fatal(err)
-	}
-	updates := []struct {
-		token string
-		value interface{}
-	}{
-		{"foo", protocol.WorkDoneProgressBegin{Kind: "begin", Title: "foo work"}},
-		{"bar", protocol.WorkDoneProgressBegin{Kind: "begin", Title: "bar work"}},
-		{"foo", protocol.WorkDoneProgressEnd{Kind: "end"}},
-		{"bar", protocol.WorkDoneProgressReport{Kind: "report", Percentage: 42}},
-	}
-	for _, update := range updates {
-		params := &protocol.ProgressParams{
-			Token: update.token,
-			Value: update.value,
-		}
-		data, err := json.Marshal(params)
-		if err != nil {
-			t.Fatal(err)
-		}
-		var unmarshaled protocol.ProgressParams
-		if err := json.Unmarshal(data, &unmarshaled); err != nil {
-			t.Fatal(err)
-		}
-		if err := a.onProgress(ctx, &unmarshaled); err != nil {
-			t.Fatal(err)
-		}
-	}
-	if !a.state.work["foo"].complete {
-		t.Error("work entry \"foo\" is incomplete, want complete")
-	}
-	got := *a.state.work["bar"]
-	want := workProgress{title: "bar work", percent: 42}
-	if got != want {
-		t.Errorf("work progress for \"bar\": %v, want %v", got, want)
-	}
-}
diff -urN a/gopls/internal/lsp/regtest/expectation.go b/gopls/internal/lsp/regtest/expectation.go
--- a/gopls/internal/lsp/regtest/expectation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/expectation.go	1969-12-31 16:00:00
@@ -1,825 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"fmt"
-	"regexp"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/testenv"
-)
-
-// An Expectation asserts that the state of the editor at a point in time
-// matches an expected condition. This is used for signaling in tests when
-// certain conditions in the editor are met.
-type Expectation interface {
-	// Check determines whether the state of the editor satisfies the
-	// expectation, returning the results that met the condition.
-	Check(State) Verdict
-	// Description is a human-readable description of the expectation.
-	Description() string
-}
-
-var (
-	// InitialWorkspaceLoad is an expectation that the workspace initial load has
-	// completed. It is verified via workdone reporting.
-	InitialWorkspaceLoad = CompletedWork(lsp.DiagnosticWorkTitle(lsp.FromInitialWorkspaceLoad), 1, false)
-)
-
-// A Verdict is the result of checking an expectation against the current
-// editor state.
-type Verdict int
-
-// Order matters for the following constants: verdicts are sorted in order of
-// decisiveness.
-const (
-	// Met indicates that an expectation is satisfied by the current state.
-	Met Verdict = iota
-	// Unmet indicates that an expectation is not currently met, but could be met
-	// in the future.
-	Unmet
-	// Unmeetable indicates that an expectation cannot be satisfied in the
-	// future.
-	Unmeetable
-)
-
-func (v Verdict) String() string {
-	switch v {
-	case Met:
-		return "Met"
-	case Unmet:
-		return "Unmet"
-	case Unmeetable:
-		return "Unmeetable"
-	}
-	return fmt.Sprintf("unrecognized verdict %d", v)
-}
-
-// SimpleExpectation holds an arbitrary check func, and implements the Expectation interface.
-type SimpleExpectation struct {
-	check       func(State) Verdict
-	description string
-}
-
-// Check invokes e.check.
-func (e SimpleExpectation) Check(s State) Verdict {
-	return e.check(s)
-}
-
-// Description returns e.description.
-func (e SimpleExpectation) Description() string {
-	return e.description
-}
-
-// OnceMet returns an Expectation that, once the precondition is met, asserts
-// that mustMeet is met.
-func OnceMet(precondition Expectation, mustMeets ...Expectation) *SimpleExpectation {
-	check := func(s State) Verdict {
-		switch pre := precondition.Check(s); pre {
-		case Unmeetable:
-			return Unmeetable
-		case Met:
-			for _, mustMeet := range mustMeets {
-				verdict := mustMeet.Check(s)
-				if verdict != Met {
-					return Unmeetable
-				}
-			}
-			return Met
-		default:
-			return Unmet
-		}
-	}
-	description := describeExpectations(mustMeets...)
-	return &SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("once %q is met, must have:\n%s", precondition.Description(), description),
-	}
-}
-
-func describeExpectations(expectations ...Expectation) string {
-	var descriptions []string
-	for _, e := range expectations {
-		descriptions = append(descriptions, e.Description())
-	}
-	return strings.Join(descriptions, "\n")
-}
-
-// AnyOf returns an expectation that is satisfied when any of the given
-// expectations is met.
-func AnyOf(anyOf ...Expectation) *SimpleExpectation {
-	check := func(s State) Verdict {
-		for _, e := range anyOf {
-			verdict := e.Check(s)
-			if verdict == Met {
-				return Met
-			}
-		}
-		return Unmet
-	}
-	description := describeExpectations(anyOf...)
-	return &SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("Any of:\n%s", description),
-	}
-}
-
-// AllOf expects that all given expectations are met.
-//
-// TODO(rfindley): the problem with these types of combinators (OnceMet, AnyOf
-// and AllOf) is that we lose the information of *why* they failed: the Awaiter
-// is not smart enough to look inside.
-//
-// Refactor the API such that the Check function is responsible for explaining
-// why an expectation failed. This should allow us to significantly improve
-// test output: we won't need to summarize state at all, as the verdict
-// explanation itself should describe clearly why the expectation not met.
-func AllOf(allOf ...Expectation) *SimpleExpectation {
-	check := func(s State) Verdict {
-		verdict := Met
-		for _, e := range allOf {
-			if v := e.Check(s); v > verdict {
-				verdict = v
-			}
-		}
-		return verdict
-	}
-	description := describeExpectations(allOf...)
-	return &SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("All of:\n%s", description),
-	}
-}
-
-// ReadDiagnostics is an 'expectation' that is used to read diagnostics
-// atomically. It is intended to be used with 'OnceMet'.
-func ReadDiagnostics(fileName string, into *protocol.PublishDiagnosticsParams) *SimpleExpectation {
-	check := func(s State) Verdict {
-		diags, ok := s.diagnostics[fileName]
-		if !ok {
-			return Unmeetable
-		}
-		*into = *diags
-		return Met
-	}
-	return &SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("read diagnostics for %q", fileName),
-	}
-}
-
-// NoOutstandingWork asserts that there is no work initiated using the LSP
-// $/progress API that has not completed.
-func NoOutstandingWork() SimpleExpectation {
-	check := func(s State) Verdict {
-		if len(s.outstandingWork()) == 0 {
-			return Met
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: "no outstanding work",
-	}
-}
-
-// NoShownMessage asserts that the editor has not received a ShowMessage.
-func NoShownMessage(subString string) SimpleExpectation {
-	check := func(s State) Verdict {
-		for _, m := range s.showMessage {
-			if strings.Contains(m.Message, subString) {
-				return Unmeetable
-			}
-		}
-		return Met
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("no ShowMessage received containing %q", subString),
-	}
-}
-
-// ShownMessage asserts that the editor has received a ShowMessageRequest
-// containing the given substring.
-func ShownMessage(containing string) SimpleExpectation {
-	check := func(s State) Verdict {
-		for _, m := range s.showMessage {
-			if strings.Contains(m.Message, containing) {
-				return Met
-			}
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: "received ShowMessage",
-	}
-}
-
-// ShowMessageRequest asserts that the editor has received a ShowMessageRequest
-// with an action item that has the given title.
-func ShowMessageRequest(title string) SimpleExpectation {
-	check := func(s State) Verdict {
-		if len(s.showMessageRequest) == 0 {
-			return Unmet
-		}
-		// Only check the most recent one.
-		m := s.showMessageRequest[len(s.showMessageRequest)-1]
-		if len(m.Actions) == 0 || len(m.Actions) > 1 {
-			return Unmet
-		}
-		if m.Actions[0].Title == title {
-			return Met
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: "received ShowMessageRequest",
-	}
-}
-
-// DoneDiagnosingChanges expects that diagnostics are complete from common
-// change notifications: didOpen, didChange, didSave, didChangeWatchedFiles,
-// and didClose.
-//
-// This can be used when multiple notifications may have been sent, such as
-// when a didChange is immediately followed by a didSave. It is insufficient to
-// simply await NoOutstandingWork, because the LSP client has no control over
-// when the server starts processing a notification. Therefore, we must keep
-// track of
-func (e *Env) DoneDiagnosingChanges() Expectation {
-	stats := e.Editor.Stats()
-	statsBySource := map[lsp.ModificationSource]uint64{
-		lsp.FromDidOpen:               stats.DidOpen,
-		lsp.FromDidChange:             stats.DidChange,
-		lsp.FromDidSave:               stats.DidSave,
-		lsp.FromDidChangeWatchedFiles: stats.DidChangeWatchedFiles,
-		lsp.FromDidClose:              stats.DidClose,
-	}
-
-	var expected []lsp.ModificationSource
-	for k, v := range statsBySource {
-		if v > 0 {
-			expected = append(expected, k)
-		}
-	}
-
-	// Sort for stability.
-	sort.Slice(expected, func(i, j int) bool {
-		return expected[i] < expected[j]
-	})
-
-	var all []Expectation
-	for _, source := range expected {
-		all = append(all, CompletedWork(lsp.DiagnosticWorkTitle(source), statsBySource[source], true))
-	}
-
-	return AllOf(all...)
-}
-
-// AfterChange expects that the given expectations will be met after all
-// state-changing notifications have been processed by the server.
-//
-// It awaits the completion of all anticipated work before checking the given
-// expectations.
-func (e *Env) AfterChange(expectations ...Expectation) {
-	e.T.Helper()
-	e.Await(
-		OnceMet(
-			e.DoneDiagnosingChanges(),
-			expectations...,
-		),
-	)
-}
-
-// DoneWithOpen expects all didOpen notifications currently sent by the editor
-// to be completely processed.
-func (e *Env) DoneWithOpen() Expectation {
-	opens := e.Editor.Stats().DidOpen
-	return CompletedWork(lsp.DiagnosticWorkTitle(lsp.FromDidOpen), opens, true)
-}
-
-// StartedChange expects that the server has at least started processing all
-// didChange notifications sent from the client.
-func (e *Env) StartedChange() Expectation {
-	changes := e.Editor.Stats().DidChange
-	return StartedWork(lsp.DiagnosticWorkTitle(lsp.FromDidChange), changes)
-}
-
-// DoneWithChange expects all didChange notifications currently sent by the
-// editor to be completely processed.
-func (e *Env) DoneWithChange() Expectation {
-	changes := e.Editor.Stats().DidChange
-	return CompletedWork(lsp.DiagnosticWorkTitle(lsp.FromDidChange), changes, true)
-}
-
-// DoneWithSave expects all didSave notifications currently sent by the editor
-// to be completely processed.
-func (e *Env) DoneWithSave() Expectation {
-	saves := e.Editor.Stats().DidSave
-	return CompletedWork(lsp.DiagnosticWorkTitle(lsp.FromDidSave), saves, true)
-}
-
-// DoneWithChangeWatchedFiles expects all didChangeWatchedFiles notifications
-// currently sent by the editor to be completely processed.
-func (e *Env) DoneWithChangeWatchedFiles() Expectation {
-	changes := e.Editor.Stats().DidChangeWatchedFiles
-	return CompletedWork(lsp.DiagnosticWorkTitle(lsp.FromDidChangeWatchedFiles), changes, true)
-}
-
-// DoneWithClose expects all didClose notifications currently sent by the
-// editor to be completely processed.
-func (e *Env) DoneWithClose() Expectation {
-	changes := e.Editor.Stats().DidClose
-	return CompletedWork(lsp.DiagnosticWorkTitle(lsp.FromDidClose), changes, true)
-}
-
-// StartedWork expect a work item to have been started >= atLeast times.
-//
-// See CompletedWork.
-func StartedWork(title string, atLeast uint64) SimpleExpectation {
-	check := func(s State) Verdict {
-		if s.startedWork()[title] >= atLeast {
-			return Met
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("started work %q at least %d time(s)", title, atLeast),
-	}
-}
-
-// CompletedWork expects a work item to have been completed >= atLeast times.
-//
-// Since the Progress API doesn't include any hidden metadata, we must use the
-// progress notification title to identify the work we expect to be completed.
-func CompletedWork(title string, count uint64, atLeast bool) SimpleExpectation {
-	check := func(s State) Verdict {
-		completed := s.completedWork()
-		if completed[title] == count || atLeast && completed[title] > count {
-			return Met
-		}
-		return Unmet
-	}
-	desc := fmt.Sprintf("completed work %q %v times", title, count)
-	if atLeast {
-		desc = fmt.Sprintf("completed work %q at least %d time(s)", title, count)
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: desc,
-	}
-}
-
-type WorkStatus struct {
-	// Last seen message from either `begin` or `report` progress.
-	Msg string
-	// Message sent with `end` progress message.
-	EndMsg string
-}
-
-// CompletedProgress expects that workDone progress is complete for the given
-// progress token. When non-nil WorkStatus is provided, it will be filled
-// when the expectation is met.
-//
-// If the token is not a progress token that the client has seen, this
-// expectation is Unmeetable.
-func CompletedProgress(token protocol.ProgressToken, into *WorkStatus) SimpleExpectation {
-	check := func(s State) Verdict {
-		work, ok := s.work[token]
-		if !ok {
-			return Unmeetable // TODO(rfindley): refactor to allow the verdict to explain this result
-		}
-		if work.complete {
-			if into != nil {
-				into.Msg = work.msg
-				into.EndMsg = work.endMsg
-			}
-			return Met
-		}
-		return Unmet
-	}
-	desc := fmt.Sprintf("completed work for token %v", token)
-	return SimpleExpectation{
-		check:       check,
-		description: desc,
-	}
-}
-
-// OutstandingWork expects a work item to be outstanding. The given title must
-// be an exact match, whereas the given msg must only be contained in the work
-// item's message.
-func OutstandingWork(title, msg string) SimpleExpectation {
-	check := func(s State) Verdict {
-		for _, work := range s.work {
-			if work.complete {
-				continue
-			}
-			if work.title == title && strings.Contains(work.msg, msg) {
-				return Met
-			}
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("outstanding work: %q containing %q", title, msg),
-	}
-}
-
-// LogExpectation is an expectation on the log messages received by the editor
-// from gopls.
-type LogExpectation struct {
-	check       func([]*protocol.LogMessageParams) Verdict
-	description string
-}
-
-// Check implements the Expectation interface.
-func (e LogExpectation) Check(s State) Verdict {
-	return e.check(s.logs)
-}
-
-// Description implements the Expectation interface.
-func (e LogExpectation) Description() string {
-	return e.description
-}
-
-// NoErrorLogs asserts that the client has not received any log messages of
-// error severity.
-func NoErrorLogs() LogExpectation {
-	return NoLogMatching(protocol.Error, "")
-}
-
-// LogMatching asserts that the client has received a log message
-// of type typ matching the regexp re a certain number of times.
-//
-// The count argument specifies the expected number of matching logs. If
-// atLeast is set, this is a lower bound, otherwise there must be exactly cound
-// matching logs.
-func LogMatching(typ protocol.MessageType, re string, count int, atLeast bool) LogExpectation {
-	rec, err := regexp.Compile(re)
-	if err != nil {
-		panic(err)
-	}
-	check := func(msgs []*protocol.LogMessageParams) Verdict {
-		var found int
-		for _, msg := range msgs {
-			if msg.Type == typ && rec.Match([]byte(msg.Message)) {
-				found++
-			}
-		}
-		// Check for an exact or "at least" match.
-		if found == count || (found >= count && atLeast) {
-			return Met
-		}
-		return Unmet
-	}
-	desc := fmt.Sprintf("log message matching %q expected %v times", re, count)
-	if atLeast {
-		desc = fmt.Sprintf("log message matching %q expected at least %v times", re, count)
-	}
-	return LogExpectation{
-		check:       check,
-		description: desc,
-	}
-}
-
-// NoLogMatching asserts that the client has not received a log message
-// of type typ matching the regexp re. If re is an empty string, any log
-// message is considered a match.
-func NoLogMatching(typ protocol.MessageType, re string) LogExpectation {
-	var r *regexp.Regexp
-	if re != "" {
-		var err error
-		r, err = regexp.Compile(re)
-		if err != nil {
-			panic(err)
-		}
-	}
-	check := func(msgs []*protocol.LogMessageParams) Verdict {
-		for _, msg := range msgs {
-			if msg.Type != typ {
-				continue
-			}
-			if r == nil || r.Match([]byte(msg.Message)) {
-				return Unmeetable
-			}
-		}
-		return Met
-	}
-	return LogExpectation{
-		check:       check,
-		description: fmt.Sprintf("no log message matching %q", re),
-	}
-}
-
-// FileWatchMatching expects that a file registration matches re.
-func FileWatchMatching(re string) SimpleExpectation {
-	return SimpleExpectation{
-		check:       checkFileWatch(re, Met, Unmet),
-		description: fmt.Sprintf("file watch matching %q", re),
-	}
-}
-
-// NoFileWatchMatching expects that no file registration matches re.
-func NoFileWatchMatching(re string) SimpleExpectation {
-	return SimpleExpectation{
-		check:       checkFileWatch(re, Unmet, Met),
-		description: fmt.Sprintf("no file watch matching %q", re),
-	}
-}
-
-func checkFileWatch(re string, onMatch, onNoMatch Verdict) func(State) Verdict {
-	rec := regexp.MustCompile(re)
-	return func(s State) Verdict {
-		r := s.registeredCapabilities["workspace/didChangeWatchedFiles"]
-		watchers := jsonProperty(r.RegisterOptions, "watchers").([]interface{})
-		for _, watcher := range watchers {
-			pattern := jsonProperty(watcher, "globPattern").(string)
-			if rec.MatchString(pattern) {
-				return onMatch
-			}
-		}
-		return onNoMatch
-	}
-}
-
-// jsonProperty extracts a value from a path of JSON property names, assuming
-// the default encoding/json unmarshaling to the empty interface (i.e.: that
-// JSON objects are unmarshalled as map[string]interface{})
-//
-// For example, if obj is unmarshalled from the following json:
-//
-//	{
-//		"foo": { "bar": 3 }
-//	}
-//
-// Then jsonProperty(obj, "foo", "bar") will be 3.
-func jsonProperty(obj interface{}, path ...string) interface{} {
-	if len(path) == 0 || obj == nil {
-		return obj
-	}
-	m := obj.(map[string]interface{})
-	return jsonProperty(m[path[0]], path[1:]...)
-}
-
-// RegistrationMatching asserts that the client has received a capability
-// registration matching the given regexp.
-//
-// TODO(rfindley): remove this once TestWatchReplaceTargets has been revisited.
-//
-// Deprecated: use (No)FileWatchMatching
-func RegistrationMatching(re string) SimpleExpectation {
-	rec := regexp.MustCompile(re)
-	check := func(s State) Verdict {
-		for _, p := range s.registrations {
-			for _, r := range p.Registrations {
-				if rec.Match([]byte(r.Method)) {
-					return Met
-				}
-			}
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("registration matching %q", re),
-	}
-}
-
-// UnregistrationMatching asserts that the client has received an
-// unregistration whose ID matches the given regexp.
-func UnregistrationMatching(re string) SimpleExpectation {
-	rec := regexp.MustCompile(re)
-	check := func(s State) Verdict {
-		for _, p := range s.unregistrations {
-			for _, r := range p.Unregisterations {
-				if rec.Match([]byte(r.Method)) {
-					return Met
-				}
-			}
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("unregistration matching %q", re),
-	}
-}
-
-// A DiagnosticExpectation is a condition that must be met by the current set
-// of diagnostics for a file.
-type DiagnosticExpectation struct {
-	// optionally, the position of the diagnostic and the regex used to calculate it.
-	pos *fake.Pos
-	re  string
-
-	// optionally, the message that the diagnostic should contain.
-	message string
-
-	// whether the expectation is that the diagnostic is present, or absent.
-	present bool
-
-	// path is the scratch workdir-relative path to the file being asserted on.
-	path string
-
-	// optionally, the diagnostic source
-	source string
-}
-
-// Check implements the Expectation interface.
-func (e DiagnosticExpectation) Check(s State) Verdict {
-	diags, ok := s.diagnostics[e.path]
-	if !ok {
-		if !e.present {
-			return Met
-		}
-		return Unmet
-	}
-
-	found := false
-	for _, d := range diags.Diagnostics {
-		if e.pos != nil {
-			if d.Range.Start.Line != uint32(e.pos.Line) || d.Range.Start.Character != uint32(e.pos.Column) {
-				continue
-			}
-		}
-		if e.message != "" {
-			if !strings.Contains(d.Message, e.message) {
-				continue
-			}
-		}
-		if e.source != "" && e.source != d.Source {
-			continue
-		}
-		found = true
-		break
-	}
-
-	if found == e.present {
-		return Met
-	}
-	return Unmet
-}
-
-// Description implements the Expectation interface.
-func (e DiagnosticExpectation) Description() string {
-	desc := e.path + ":"
-	if !e.present {
-		desc += " no"
-	}
-	desc += " diagnostic"
-	if e.pos != nil {
-		desc += fmt.Sprintf(" at {line:%d, column:%d}", e.pos.Line, e.pos.Column)
-		if e.re != "" {
-			desc += fmt.Sprintf(" (location of %q)", e.re)
-		}
-	}
-	if e.message != "" {
-		desc += fmt.Sprintf(" with message %q", e.message)
-	}
-	if e.source != "" {
-		desc += fmt.Sprintf(" from source %q", e.source)
-	}
-	return desc
-}
-
-// NoOutstandingDiagnostics asserts that the workspace has no outstanding
-// diagnostic messages.
-func NoOutstandingDiagnostics() Expectation {
-	check := func(s State) Verdict {
-		for _, diags := range s.diagnostics {
-			if len(diags.Diagnostics) > 0 {
-				return Unmet
-			}
-		}
-		return Met
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: "no outstanding diagnostics",
-	}
-}
-
-// EmptyDiagnostics asserts that empty diagnostics are sent for the
-// workspace-relative path name.
-func EmptyDiagnostics(name string) Expectation {
-	check := func(s State) Verdict {
-		if diags := s.diagnostics[name]; diags != nil && len(diags.Diagnostics) == 0 {
-			return Met
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("empty diagnostics for %q", name),
-	}
-}
-
-// EmptyOrNoDiagnostics asserts that either no diagnostics are sent for the
-// workspace-relative path name, or empty diagnostics are sent.
-// TODO(rFindley): this subtlety shouldn't be necessary. Gopls should always
-// send at least one diagnostic set for open files.
-func EmptyOrNoDiagnostics(name string) Expectation {
-	check := func(s State) Verdict {
-		if diags := s.diagnostics[name]; diags == nil || len(diags.Diagnostics) == 0 {
-			return Met
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("empty or no diagnostics for %q", name),
-	}
-}
-
-// NoDiagnostics asserts that no diagnostics are sent for the
-// workspace-relative path name. It should be used primarily in conjunction
-// with a OnceMet, as it has to check that all outstanding diagnostics have
-// already been delivered.
-func NoDiagnostics(name string) Expectation {
-	check := func(s State) Verdict {
-		if _, ok := s.diagnostics[name]; !ok {
-			return Met
-		}
-		return Unmet
-	}
-	return SimpleExpectation{
-		check:       check,
-		description: fmt.Sprintf("no diagnostics for %q", name),
-	}
-}
-
-// DiagnosticAtRegexp expects that there is a diagnostic entry at the start
-// position matching the regexp search string re in the buffer specified by
-// name. Note that this currently ignores the end position.
-func (e *Env) DiagnosticAtRegexp(name, re string) DiagnosticExpectation {
-	e.T.Helper()
-	pos := e.RegexpSearch(name, re)
-	return DiagnosticExpectation{path: name, pos: &pos, re: re, present: true}
-}
-
-// DiagnosticAtRegexpWithMessage is like DiagnosticAtRegexp, but it also
-// checks for the content of the diagnostic message,
-func (e *Env) DiagnosticAtRegexpWithMessage(name, re, msg string) DiagnosticExpectation {
-	e.T.Helper()
-	pos := e.RegexpSearch(name, re)
-	return DiagnosticExpectation{path: name, pos: &pos, re: re, present: true, message: msg}
-}
-
-// DiagnosticAtRegexpFromSource expects a diagnostic at the first position
-// matching re, from the given source.
-func (e *Env) DiagnosticAtRegexpFromSource(name, re, source string) DiagnosticExpectation {
-	e.T.Helper()
-	pos := e.RegexpSearch(name, re)
-	return DiagnosticExpectation{path: name, pos: &pos, re: re, present: true, source: source}
-}
-
-// DiagnosticAt asserts that there is a diagnostic entry at the position
-// specified by line and col, for the workdir-relative path name.
-func DiagnosticAt(name string, line, col int) DiagnosticExpectation {
-	return DiagnosticExpectation{path: name, pos: &fake.Pos{Line: line, Column: col}, present: true}
-}
-
-// NoDiagnosticAtRegexp expects that there is no diagnostic entry at the start
-// position matching the regexp search string re in the buffer specified by
-// name. Note that this currently ignores the end position.
-// This should only be used in combination with OnceMet for a given condition,
-// otherwise it may always succeed.
-func (e *Env) NoDiagnosticAtRegexp(name, re string) DiagnosticExpectation {
-	e.T.Helper()
-	pos := e.RegexpSearch(name, re)
-	return DiagnosticExpectation{path: name, pos: &pos, re: re, present: false}
-}
-
-// NoDiagnosticWithMessage asserts that there is no diagnostic entry with the
-// given message.
-//
-// This should only be used in combination with OnceMet for a given condition,
-// otherwise it may always succeed.
-func NoDiagnosticWithMessage(name, msg string) DiagnosticExpectation {
-	return DiagnosticExpectation{path: name, message: msg, present: false}
-}
-
-// GoSumDiagnostic asserts that a "go.sum is out of sync" diagnostic for the
-// given module (as formatted in a go.mod file, e.g. "example.com v1.0.0") is
-// present.
-func (e *Env) GoSumDiagnostic(name, module string) Expectation {
-	e.T.Helper()
-	// In 1.16, go.sum diagnostics should appear on the relevant module. Earlier
-	// errors have no information and appear on the module declaration.
-	if testenv.Go1Point() >= 16 {
-		return e.DiagnosticAtRegexpWithMessage(name, module, "go.sum is out of sync")
-	} else {
-		return e.DiagnosticAtRegexpWithMessage(name, `module`, "go.sum is out of sync")
-	}
-}
diff -urN a/gopls/internal/lsp/regtest/options.go b/gopls/internal/lsp/regtest/options.go
--- a/gopls/internal/lsp/regtest/options.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/options.go	1969-12-31 16:00:00
@@ -1,105 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import "golang.org/x/tools/gopls/internal/lsp/fake"
-
-type runConfig struct {
-	editor    fake.EditorConfig
-	sandbox   fake.SandboxConfig
-	modes     Mode
-	skipHooks bool
-}
-
-// A RunOption augments the behavior of the test runner.
-type RunOption interface {
-	set(*runConfig)
-}
-
-type optionSetter func(*runConfig)
-
-func (f optionSetter) set(opts *runConfig) {
-	f(opts)
-}
-
-// ProxyFiles configures a file proxy using the given txtar-encoded string.
-func ProxyFiles(txt string) RunOption {
-	return optionSetter(func(opts *runConfig) {
-		opts.sandbox.ProxyFiles = fake.UnpackTxt(txt)
-	})
-}
-
-// Modes configures the execution modes that the test should run in.
-//
-// By default, modes are configured by the test runner. If this option is set,
-// it overrides the set of default modes and the test runs in exactly these
-// modes.
-func Modes(modes Mode) RunOption {
-	return optionSetter(func(opts *runConfig) {
-		if opts.modes != 0 {
-			panic("modes set more than once")
-		}
-		opts.modes = modes
-	})
-}
-
-// WindowsLineEndings configures the editor to use windows line endings.
-func WindowsLineEndings() RunOption {
-	return optionSetter(func(opts *runConfig) {
-		opts.editor.WindowsLineEndings = true
-	})
-}
-
-// Settings is a RunOption that sets user-provided configuration for the LSP
-// server.
-//
-// As a special case, the env setting must not be provided via Settings: use
-// EnvVars instead.
-type Settings map[string]interface{}
-
-func (s Settings) set(opts *runConfig) {
-	if opts.editor.Settings == nil {
-		opts.editor.Settings = make(map[string]interface{})
-	}
-	for k, v := range s {
-		opts.editor.Settings[k] = v
-	}
-}
-
-// WorkspaceFolders configures the workdir-relative workspace folders to send
-// to the LSP server. By default the editor sends a single workspace folder
-// corresponding to the workdir root. To explicitly configure no workspace
-// folders, use WorkspaceFolders with no arguments.
-func WorkspaceFolders(relFolders ...string) RunOption {
-	if len(relFolders) == 0 {
-		// Use an empty non-nil slice to signal explicitly no folders.
-		relFolders = []string{}
-	}
-	return optionSetter(func(opts *runConfig) {
-		opts.editor.WorkspaceFolders = relFolders
-	})
-}
-
-// EnvVars sets environment variables for the LSP session. When applying these
-// variables to the session, the special string $SANDBOX_WORKDIR is replaced by
-// the absolute path to the sandbox working directory.
-type EnvVars map[string]string
-
-func (e EnvVars) set(opts *runConfig) {
-	if opts.editor.Env == nil {
-		opts.editor.Env = make(map[string]string)
-	}
-	for k, v := range e {
-		opts.editor.Env[k] = v
-	}
-}
-
-// InGOPATH configures the workspace working directory to be GOPATH, rather
-// than a separate working directory for use with modules.
-func InGOPATH() RunOption {
-	return optionSetter(func(opts *runConfig) {
-		opts.sandbox.InGoPath = true
-	})
-}
diff -urN a/gopls/internal/lsp/regtest/regtest.go b/gopls/internal/lsp/regtest/regtest.go
--- a/gopls/internal/lsp/regtest/regtest.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/regtest.go	1969-12-31 16:00:00
@@ -1,155 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"go/token"
-	"io/ioutil"
-	"os"
-	"runtime"
-	"testing"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/cmd"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/memoize"
-	"golang.org/x/tools/internal/testenv"
-	"golang.org/x/tools/internal/tool"
-)
-
-var (
-	runSubprocessTests       = flag.Bool("enable_gopls_subprocess_tests", false, "run regtests against a gopls subprocess")
-	goplsBinaryPath          = flag.String("gopls_test_binary", "", "path to the gopls binary for use as a remote, for use with the -enable_gopls_subprocess_tests flag")
-	regtestTimeout           = flag.Duration("regtest_timeout", defaultRegtestTimeout(), "if nonzero, default timeout for each regtest; defaults to GOPLS_REGTEST_TIMEOUT")
-	skipCleanup              = flag.Bool("regtest_skip_cleanup", false, "whether to skip cleaning up temp directories")
-	printGoroutinesOnFailure = flag.Bool("regtest_print_goroutines", false, "whether to print goroutines info on failure")
-	printLogs                = flag.Bool("regtest_print_logs", false, "whether to print LSP logs")
-)
-
-func defaultRegtestTimeout() time.Duration {
-	s := os.Getenv("GOPLS_REGTEST_TIMEOUT")
-	if s == "" {
-		return 0
-	}
-	d, err := time.ParseDuration(s)
-	if err != nil {
-		fmt.Fprintf(os.Stderr, "invalid GOPLS_REGTEST_TIMEOUT %q: %v\n", s, err)
-		os.Exit(2)
-	}
-	return d
-}
-
-var runner *Runner
-
-type regtestRunner interface {
-	Run(t *testing.T, files string, f TestFunc)
-}
-
-func Run(t *testing.T, files string, f TestFunc) {
-	runner.Run(t, files, f)
-}
-
-func WithOptions(opts ...RunOption) configuredRunner {
-	return configuredRunner{opts: opts}
-}
-
-type configuredRunner struct {
-	opts []RunOption
-}
-
-func (r configuredRunner) Run(t *testing.T, files string, f TestFunc) {
-	runner.Run(t, files, f, r.opts...)
-}
-
-type RunMultiple []struct {
-	Name   string
-	Runner regtestRunner
-}
-
-func (r RunMultiple) Run(t *testing.T, files string, f TestFunc) {
-	for _, runner := range r {
-		t.Run(runner.Name, func(t *testing.T) {
-			runner.Runner.Run(t, files, f)
-		})
-	}
-}
-
-// DefaultModes returns the default modes to run for each regression test (they
-// may be reconfigured by the tests themselves).
-func DefaultModes() Mode {
-	modes := Default
-	if !testing.Short() {
-		modes |= Experimental | Forwarded
-	}
-	if *runSubprocessTests {
-		modes |= SeparateProcess
-	}
-	return modes
-}
-
-// Main sets up and tears down the shared regtest state.
-func Main(m *testing.M, hook func(*source.Options)) {
-	// golang/go#54461: enable additional debugging around hanging Go commands.
-	gocommand.DebugHangingGoCommands = true
-
-	// If this magic environment variable is set, run gopls instead of the test
-	// suite. See the documentation for runTestAsGoplsEnvvar for more details.
-	if os.Getenv(runTestAsGoplsEnvvar) == "true" {
-		tool.Main(context.Background(), cmd.New("gopls", "", nil, hook), os.Args[1:])
-		os.Exit(0)
-	}
-
-	testenv.ExitIfSmallMachine()
-
-	// Disable GOPACKAGESDRIVER, as it can cause spurious test failures.
-	os.Setenv("GOPACKAGESDRIVER", "off")
-
-	flag.Parse()
-
-	runner = &Runner{
-		DefaultModes:             DefaultModes(),
-		Timeout:                  *regtestTimeout,
-		PrintGoroutinesOnFailure: *printGoroutinesOnFailure,
-		SkipCleanup:              *skipCleanup,
-		OptionsHook:              hook,
-		fset:                     token.NewFileSet(),
-		store:                    memoize.NewStore(memoize.NeverEvict),
-	}
-
-	runner.goplsPath = *goplsBinaryPath
-	if runner.goplsPath == "" {
-		var err error
-		runner.goplsPath, err = os.Executable()
-		if err != nil {
-			panic(fmt.Sprintf("finding test binary path: %v", err))
-		}
-	}
-
-	dir, err := ioutil.TempDir("", "gopls-regtest-")
-	if err != nil {
-		panic(fmt.Errorf("creating regtest temp directory: %v", err))
-	}
-	runner.tempDir = dir
-
-	var code int
-	defer func() {
-		if err := runner.Close(); err != nil {
-			fmt.Fprintf(os.Stderr, "closing test runner: %v\n", err)
-			// Regtest cleanup is broken in go1.12 and earlier, and sometimes flakes on
-			// Windows due to file locking, but this is OK for our CI.
-			//
-			// Fail on go1.13+, except for windows and android which have shutdown problems.
-			if testenv.Go1Point() >= 13 && runtime.GOOS != "windows" && runtime.GOOS != "android" {
-				os.Exit(1)
-			}
-		}
-		os.Exit(code)
-	}()
-	code = m.Run()
-}
diff -urN a/gopls/internal/lsp/regtest/runner.go b/gopls/internal/lsp/regtest/runner.go
--- a/gopls/internal/lsp/regtest/runner.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/runner.go	1969-12-31 16:00:00
@@ -1,441 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/token"
-	"io"
-	"io/ioutil"
-	"net"
-	"os"
-	"path/filepath"
-	"runtime"
-	"runtime/pprof"
-	"strings"
-	"sync"
-	"testing"
-	"time"
-
-	exec "golang.org/x/sys/execabs"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-	"golang.org/x/tools/internal/memoize"
-	"golang.org/x/tools/internal/testenv"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// Mode is a bitmask that defines for which execution modes a test should run.
-//
-// Each mode controls several aspects of gopls' configuration:
-//   - Which server options to use for gopls sessions
-//   - Whether to use a shared cache
-//   - Whether to use a shared server
-//   - Whether to run the server in-process or in a separate process
-//
-// The behavior of each mode with respect to these aspects is summarized below.
-// TODO(rfindley, cleanup): rather than using arbitrary names for these modes,
-// we can compose them explicitly out of the features described here, allowing
-// individual tests more freedom in constructing problematic execution modes.
-// For example, a test could assert on a certain behavior when running with
-// experimental options on a separate process. Moreover, we could unify 'Modes'
-// with 'Options', and use RunMultiple rather than a hard-coded loop through
-// modes.
-//
-// Mode            | Options      | Shared Cache? | Shared Server? | In-process?
-// ---------------------------------------------------------------------------
-// Default         | Default      | Y             | N              | Y
-// Forwarded       | Default      | Y             | Y              | Y
-// SeparateProcess | Default      | Y             | Y              | N
-// Experimental    | Experimental | N             | N              | Y
-type Mode int
-
-const (
-	// Default mode runs gopls with the default options, communicating over pipes
-	// to emulate the lsp sidecar execution mode, which communicates over
-	// stdin/stdout.
-	//
-	// It uses separate servers for each test, but a shared cache, to avoid
-	// duplicating work when processing GOROOT.
-	Default Mode = 1 << iota
-
-	// Forwarded uses the default options, but forwards connections to a shared
-	// in-process gopls server.
-	Forwarded
-
-	// SeparateProcess uses the default options, but forwards connection to an
-	// external gopls daemon.
-	//
-	// Only supported on GOOS=linux.
-	SeparateProcess
-
-	// Experimental enables all of the experimental configurations that are
-	// being developed, and runs gopls in sidecar mode.
-	//
-	// It uses a separate cache for each test, to exercise races that may only
-	// appear with cache misses.
-	Experimental
-)
-
-func (m Mode) String() string {
-	switch m {
-	case Default:
-		return "default"
-	case Forwarded:
-		return "forwarded"
-	case SeparateProcess:
-		return "separate process"
-	case Experimental:
-		return "experimental"
-	default:
-		return "unknown mode"
-	}
-}
-
-// A Runner runs tests in gopls execution environments, as specified by its
-// modes. For modes that share state (for example, a shared cache or common
-// remote), any tests that execute on the same Runner will share the same
-// state.
-type Runner struct {
-	// Configuration
-	DefaultModes             Mode                  // modes to run for each test
-	Timeout                  time.Duration         // per-test timeout, if set
-	PrintGoroutinesOnFailure bool                  // whether to dump goroutines on test failure
-	SkipCleanup              bool                  // if set, don't delete test data directories when the test exits
-	OptionsHook              func(*source.Options) // if set, use these options when creating gopls sessions
-
-	// Immutable state shared across test invocations
-	goplsPath string         // path to the gopls executable (for SeparateProcess mode)
-	tempDir   string         // shared parent temp directory
-	fset      *token.FileSet // shared FileSet
-	store     *memoize.Store // shared store
-
-	// Lazily allocated resources
-	tsOnce sync.Once
-	ts     *servertest.TCPServer // shared in-process test server ("forwarded" mode)
-
-	startRemoteOnce sync.Once
-	remoteSocket    string // unix domain socket for shared daemon ("separate process" mode)
-	remoteErr       error
-	cancelRemote    func()
-}
-
-type TestFunc func(t *testing.T, env *Env)
-
-// Run executes the test function in the default configured gopls execution
-// modes. For each a test run, a new workspace is created containing the
-// un-txtared files specified by filedata.
-func (r *Runner) Run(t *testing.T, files string, test TestFunc, opts ...RunOption) {
-	// TODO(rfindley): this function has gotten overly complicated, and warrants
-	// refactoring.
-	t.Helper()
-	checkBuilder(t)
-	testenv.NeedsGoPackages(t)
-
-	tests := []struct {
-		name      string
-		mode      Mode
-		getServer func(func(*source.Options)) jsonrpc2.StreamServer
-	}{
-		{"default", Default, r.defaultServer},
-		{"forwarded", Forwarded, r.forwardedServer},
-		{"separate_process", SeparateProcess, r.separateProcessServer},
-		{"experimental", Experimental, r.experimentalServer},
-	}
-
-	for _, tc := range tests {
-		tc := tc
-		var config runConfig
-		for _, opt := range opts {
-			opt.set(&config)
-		}
-		modes := r.DefaultModes
-		if config.modes != 0 {
-			modes = config.modes
-		}
-		if modes&tc.mode == 0 {
-			continue
-		}
-
-		t.Run(tc.name, func(t *testing.T) {
-			// TODO(rfindley): once jsonrpc2 shutdown is fixed, we should not leak
-			// goroutines in this test function.
-			// stacktest.NoLeak(t)
-
-			ctx := context.Background()
-			if r.Timeout != 0 {
-				var cancel context.CancelFunc
-				ctx, cancel = context.WithTimeout(ctx, r.Timeout)
-				defer cancel()
-			} else if d, ok := testenv.Deadline(t); ok {
-				timeout := time.Until(d) * 19 / 20 // Leave an arbitrary 5% for cleanup.
-				var cancel context.CancelFunc
-				ctx, cancel = context.WithTimeout(ctx, timeout)
-				defer cancel()
-			}
-
-			// TODO(rfindley): do we need an instance at all? Can it be removed?
-			ctx = debug.WithInstance(ctx, "", "off")
-
-			rootDir := filepath.Join(r.tempDir, filepath.FromSlash(t.Name()))
-			if err := os.MkdirAll(rootDir, 0755); err != nil {
-				t.Fatal(err)
-			}
-
-			files := fake.UnpackTxt(files)
-			if config.editor.WindowsLineEndings {
-				for name, data := range files {
-					files[name] = bytes.ReplaceAll(data, []byte("\n"), []byte("\r\n"))
-				}
-			}
-			config.sandbox.Files = files
-			config.sandbox.RootDir = rootDir
-			sandbox, err := fake.NewSandbox(&config.sandbox)
-			if err != nil {
-				t.Fatal(err)
-			}
-			defer func() {
-				if !r.SkipCleanup {
-					if err := sandbox.Close(); err != nil {
-						pprof.Lookup("goroutine").WriteTo(os.Stderr, 1)
-						t.Errorf("closing the sandbox: %v", err)
-					}
-				}
-			}()
-
-			ss := tc.getServer(r.OptionsHook)
-
-			framer := jsonrpc2.NewRawStream
-			ls := &loggingFramer{}
-			framer = ls.framer(jsonrpc2.NewRawStream)
-			ts := servertest.NewPipeServer(ss, framer)
-
-			awaiter := NewAwaiter(sandbox.Workdir)
-			editor, err := fake.NewEditor(sandbox, config.editor).Connect(ctx, ts, awaiter.Hooks())
-			if err != nil {
-				t.Fatal(err)
-			}
-			env := &Env{
-				T:       t,
-				Ctx:     ctx,
-				Sandbox: sandbox,
-				Editor:  editor,
-				Server:  ts,
-				Awaiter: awaiter,
-			}
-			defer func() {
-				if t.Failed() && r.PrintGoroutinesOnFailure {
-					pprof.Lookup("goroutine").WriteTo(os.Stderr, 1)
-				}
-				if t.Failed() || *printLogs {
-					ls.printBuffers(t.Name(), os.Stderr)
-				}
-				// For tests that failed due to a timeout, don't fail to shutdown
-				// because ctx is done.
-				//
-				// There is little point to setting an arbitrary timeout for closing
-				// the editor: in general we want to clean up before proceeding to the
-				// next test, and if there is a deadlock preventing closing it will
-				// eventually be handled by the `go test` timeout.
-				if err := editor.Close(xcontext.Detach(ctx)); err != nil {
-					t.Errorf("closing editor: %v", err)
-				}
-			}()
-			// Always await the initial workspace load.
-			env.Await(InitialWorkspaceLoad)
-			test(t, env)
-		})
-	}
-}
-
-// longBuilders maps builders that are skipped when -short is set to a
-// (possibly empty) justification.
-var longBuilders = map[string]string{
-	"openbsd-amd64-64":        "golang.org/issues/42789",
-	"openbsd-386-64":          "golang.org/issues/42789",
-	"openbsd-386-68":          "golang.org/issues/42789",
-	"openbsd-amd64-68":        "golang.org/issues/42789",
-	"darwin-amd64-10_12":      "",
-	"freebsd-amd64-race":      "",
-	"illumos-amd64":           "",
-	"netbsd-arm-bsiegert":     "",
-	"solaris-amd64-oraclerel": "",
-	"windows-arm-zx2c4":       "",
-}
-
-func checkBuilder(t *testing.T) {
-	t.Helper()
-	builder := os.Getenv("GO_BUILDER_NAME")
-	if reason, ok := longBuilders[builder]; ok && testing.Short() {
-		if reason != "" {
-			t.Skipf("Skipping %s with -short due to %s", builder, reason)
-		} else {
-			t.Skipf("Skipping %s with -short", builder)
-		}
-	}
-}
-
-type loggingFramer struct {
-	mu  sync.Mutex
-	buf *safeBuffer
-}
-
-// safeBuffer is a threadsafe buffer for logs.
-type safeBuffer struct {
-	mu  sync.Mutex
-	buf bytes.Buffer
-}
-
-func (b *safeBuffer) Write(p []byte) (int, error) {
-	b.mu.Lock()
-	defer b.mu.Unlock()
-	return b.buf.Write(p)
-}
-
-func (s *loggingFramer) framer(f jsonrpc2.Framer) jsonrpc2.Framer {
-	return func(nc net.Conn) jsonrpc2.Stream {
-		s.mu.Lock()
-		framed := false
-		if s.buf == nil {
-			s.buf = &safeBuffer{buf: bytes.Buffer{}}
-			framed = true
-		}
-		s.mu.Unlock()
-		stream := f(nc)
-		if framed {
-			return protocol.LoggingStream(stream, s.buf)
-		}
-		return stream
-	}
-}
-
-func (s *loggingFramer) printBuffers(testname string, w io.Writer) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-
-	if s.buf == nil {
-		return
-	}
-	fmt.Fprintf(os.Stderr, "#### Start Gopls Test Logs for %q\n", testname)
-	s.buf.mu.Lock()
-	io.Copy(w, &s.buf.buf)
-	s.buf.mu.Unlock()
-	fmt.Fprintf(os.Stderr, "#### End Gopls Test Logs for %q\n", testname)
-}
-
-// defaultServer handles the Default execution mode.
-func (r *Runner) defaultServer(optsHook func(*source.Options)) jsonrpc2.StreamServer {
-	return lsprpc.NewStreamServer(cache.New(r.fset, r.store), false, optsHook)
-}
-
-// experimentalServer handles the Experimental execution mode.
-func (r *Runner) experimentalServer(optsHook func(*source.Options)) jsonrpc2.StreamServer {
-	options := func(o *source.Options) {
-		optsHook(o)
-		o.EnableAllExperiments()
-		// ExperimentalWorkspaceModule is not (as of writing) enabled by
-		// source.Options.EnableAllExperiments, but we want to test it.
-		o.ExperimentalWorkspaceModule = true
-	}
-	return lsprpc.NewStreamServer(cache.New(nil, nil), false, options)
-}
-
-// forwardedServer handles the Forwarded execution mode.
-func (r *Runner) forwardedServer(optsHook func(*source.Options)) jsonrpc2.StreamServer {
-	r.tsOnce.Do(func() {
-		ctx := context.Background()
-		ctx = debug.WithInstance(ctx, "", "off")
-		ss := lsprpc.NewStreamServer(cache.New(nil, nil), false, optsHook)
-		r.ts = servertest.NewTCPServer(ctx, ss, nil)
-	})
-	return newForwarder("tcp", r.ts.Addr)
-}
-
-// runTestAsGoplsEnvvar triggers TestMain to run gopls instead of running
-// tests. It's a trick to allow tests to find a binary to use to start a gopls
-// subprocess.
-const runTestAsGoplsEnvvar = "_GOPLS_TEST_BINARY_RUN_AS_GOPLS"
-
-// separateProcessServer handles the SeparateProcess execution mode.
-func (r *Runner) separateProcessServer(optsHook func(*source.Options)) jsonrpc2.StreamServer {
-	if runtime.GOOS != "linux" {
-		panic("separate process execution mode is only supported on linux")
-	}
-
-	r.startRemoteOnce.Do(func() {
-		socketDir, err := ioutil.TempDir(r.tempDir, "gopls-regtest-socket")
-		if err != nil {
-			r.remoteErr = err
-			return
-		}
-		r.remoteSocket = filepath.Join(socketDir, "gopls-test-daemon")
-
-		// The server should be killed by when the test runner exits, but to be
-		// conservative also set a listen timeout.
-		args := []string{"serve", "-listen", "unix;" + r.remoteSocket, "-listen.timeout", "1m"}
-
-		ctx, cancel := context.WithCancel(context.Background())
-		cmd := exec.CommandContext(ctx, r.goplsPath, args...)
-		cmd.Env = append(os.Environ(), runTestAsGoplsEnvvar+"=true")
-
-		// Start the external gopls process. This is still somewhat racy, as we
-		// don't know when gopls binds to the socket, but the gopls forwarder
-		// client has built-in retry behavior that should mostly mitigate this
-		// problem (and if it doesn't, we probably want to improve the retry
-		// behavior).
-		if err := cmd.Start(); err != nil {
-			cancel()
-			r.remoteSocket = ""
-			r.remoteErr = err
-		} else {
-			r.cancelRemote = cancel
-			// Spin off a goroutine to wait, so that we free up resources when the
-			// server exits.
-			go cmd.Wait()
-		}
-	})
-
-	return newForwarder("unix", r.remoteSocket)
-}
-
-func newForwarder(network, address string) *lsprpc.Forwarder {
-	server, err := lsprpc.NewForwarder(network+";"+address, nil)
-	if err != nil {
-		// This should never happen, as we are passing an explicit address.
-		panic(fmt.Sprintf("internal error: unable to create forwarder: %v", err))
-	}
-	return server
-}
-
-// Close cleans up resource that have been allocated to this workspace.
-func (r *Runner) Close() error {
-	var errmsgs []string
-	if r.ts != nil {
-		if err := r.ts.Close(); err != nil {
-			errmsgs = append(errmsgs, err.Error())
-		}
-	}
-	if r.cancelRemote != nil {
-		r.cancelRemote()
-	}
-	if !r.SkipCleanup {
-		if err := os.RemoveAll(r.tempDir); err != nil {
-			errmsgs = append(errmsgs, err.Error())
-		}
-	}
-	if len(errmsgs) > 0 {
-		return fmt.Errorf("errors closing the test runner:\n\t%s", strings.Join(errmsgs, "\n\t"))
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/regtest/wrappers.go b/gopls/internal/lsp/regtest/wrappers.go
--- a/gopls/internal/lsp/regtest/wrappers.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/regtest/wrappers.go	1969-12-31 16:00:00
@@ -1,488 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"encoding/json"
-	"path"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// RemoveWorkspaceFile deletes a file on disk but does nothing in the
-// editor. It calls t.Fatal on any error.
-func (e *Env) RemoveWorkspaceFile(name string) {
-	e.T.Helper()
-	if err := e.Sandbox.Workdir.RemoveFile(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// ReadWorkspaceFile reads a file from the workspace, calling t.Fatal on any
-// error.
-func (e *Env) ReadWorkspaceFile(name string) string {
-	e.T.Helper()
-	content, err := e.Sandbox.Workdir.ReadFile(name)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return content
-}
-
-// WriteWorkspaceFile writes a file to disk but does nothing in the editor.
-// It calls t.Fatal on any error.
-func (e *Env) WriteWorkspaceFile(name, content string) {
-	e.T.Helper()
-	if err := e.Sandbox.Workdir.WriteFile(e.Ctx, name, content); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// WriteWorkspaceFiles deletes a file on disk but does nothing in the
-// editor. It calls t.Fatal on any error.
-func (e *Env) WriteWorkspaceFiles(files map[string]string) {
-	e.T.Helper()
-	if err := e.Sandbox.Workdir.WriteFiles(e.Ctx, files); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// ListFiles lists relative paths to files in the given directory.
-// It calls t.Fatal on any error.
-func (e *Env) ListFiles(dir string) []string {
-	e.T.Helper()
-	paths, err := e.Sandbox.Workdir.ListFiles(dir)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return paths
-}
-
-// OpenFile opens a file in the editor, calling t.Fatal on any error.
-func (e *Env) OpenFile(name string) {
-	e.T.Helper()
-	if err := e.Editor.OpenFile(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// CreateBuffer creates a buffer in the editor, calling t.Fatal on any error.
-func (e *Env) CreateBuffer(name string, content string) {
-	e.T.Helper()
-	if err := e.Editor.CreateBuffer(e.Ctx, name, content); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// BufferText returns the current buffer contents for the file with the given
-// relative path, calling t.Fatal if the file is not open in a buffer.
-func (e *Env) BufferText(name string) string {
-	e.T.Helper()
-	text, ok := e.Editor.BufferText(name)
-	if !ok {
-		e.T.Fatalf("buffer %q is not open", name)
-	}
-	return text
-}
-
-// CloseBuffer closes an editor buffer without saving, calling t.Fatal on any
-// error.
-func (e *Env) CloseBuffer(name string) {
-	e.T.Helper()
-	if err := e.Editor.CloseBuffer(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// EditBuffer applies edits to an editor buffer, calling t.Fatal on any error.
-func (e *Env) EditBuffer(name string, edits ...fake.Edit) {
-	e.T.Helper()
-	if err := e.Editor.EditBuffer(e.Ctx, name, edits); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-func (e *Env) SetBufferContent(name string, content string) {
-	e.T.Helper()
-	if err := e.Editor.SetBufferContent(e.Ctx, name, content); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// RegexpRange returns the range of the first match for re in the buffer
-// specified by name, calling t.Fatal on any error. It first searches for the
-// position in open buffers, then in workspace files.
-func (e *Env) RegexpRange(name, re string) (fake.Pos, fake.Pos) {
-	e.T.Helper()
-	start, end, err := e.Editor.RegexpRange(name, re)
-	if err == fake.ErrUnknownBuffer {
-		start, end, err = e.Sandbox.Workdir.RegexpRange(name, re)
-	}
-	if err != nil {
-		e.T.Fatalf("RegexpRange: %v, %v", name, err)
-	}
-	return start, end
-}
-
-// RegexpSearch returns the starting position of the first match for re in the
-// buffer specified by name, calling t.Fatal on any error. It first searches
-// for the position in open buffers, then in workspace files.
-func (e *Env) RegexpSearch(name, re string) fake.Pos {
-	e.T.Helper()
-	pos, err := e.Editor.RegexpSearch(name, re)
-	if err == fake.ErrUnknownBuffer {
-		pos, err = e.Sandbox.Workdir.RegexpSearch(name, re)
-	}
-	if err != nil {
-		e.T.Fatalf("RegexpSearch: %v, %v", name, err)
-	}
-	return pos
-}
-
-// RegexpReplace replaces the first group in the first match of regexpStr with
-// the replace text, calling t.Fatal on any error.
-func (e *Env) RegexpReplace(name, regexpStr, replace string) {
-	e.T.Helper()
-	if err := e.Editor.RegexpReplace(e.Ctx, name, regexpStr, replace); err != nil {
-		e.T.Fatalf("RegexpReplace: %v", err)
-	}
-}
-
-// SaveBuffer saves an editor buffer, calling t.Fatal on any error.
-func (e *Env) SaveBuffer(name string) {
-	e.T.Helper()
-	if err := e.Editor.SaveBuffer(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-func (e *Env) SaveBufferWithoutActions(name string) {
-	e.T.Helper()
-	if err := e.Editor.SaveBufferWithoutActions(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// GoToDefinition goes to definition in the editor, calling t.Fatal on any
-// error. It returns the path and position of the resulting jump.
-func (e *Env) GoToDefinition(name string, pos fake.Pos) (string, fake.Pos) {
-	e.T.Helper()
-	n, p, err := e.Editor.GoToDefinition(e.Ctx, name, pos)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return n, p
-}
-
-// Symbol returns symbols matching query
-func (e *Env) Symbol(query string) []fake.SymbolInformation {
-	e.T.Helper()
-	r, err := e.Editor.Symbol(e.Ctx, query)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return r
-}
-
-// FormatBuffer formats the editor buffer, calling t.Fatal on any error.
-func (e *Env) FormatBuffer(name string) {
-	e.T.Helper()
-	if err := e.Editor.FormatBuffer(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// OrganizeImports processes the source.organizeImports codeAction, calling
-// t.Fatal on any error.
-func (e *Env) OrganizeImports(name string) {
-	e.T.Helper()
-	if err := e.Editor.OrganizeImports(e.Ctx, name); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// ApplyQuickFixes processes the quickfix codeAction, calling t.Fatal on any error.
-func (e *Env) ApplyQuickFixes(path string, diagnostics []protocol.Diagnostic) {
-	e.T.Helper()
-	if err := e.Editor.ApplyQuickFixes(e.Ctx, path, nil, diagnostics); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// ApplyCodeAction applies the given code action.
-func (e *Env) ApplyCodeAction(action protocol.CodeAction) {
-	e.T.Helper()
-	if err := e.Editor.ApplyCodeAction(e.Ctx, action); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// GetQuickFixes returns the available quick fix code actions.
-func (e *Env) GetQuickFixes(path string, diagnostics []protocol.Diagnostic) []protocol.CodeAction {
-	e.T.Helper()
-	actions, err := e.Editor.GetQuickFixes(e.Ctx, path, nil, diagnostics)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return actions
-}
-
-// Hover in the editor, calling t.Fatal on any error.
-func (e *Env) Hover(name string, pos fake.Pos) (*protocol.MarkupContent, fake.Pos) {
-	e.T.Helper()
-	c, p, err := e.Editor.Hover(e.Ctx, name, pos)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return c, p
-}
-
-func (e *Env) DocumentLink(name string) []protocol.DocumentLink {
-	e.T.Helper()
-	links, err := e.Editor.DocumentLink(e.Ctx, name)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return links
-}
-
-func (e *Env) DocumentHighlight(name string, pos fake.Pos) []protocol.DocumentHighlight {
-	e.T.Helper()
-	highlights, err := e.Editor.DocumentHighlight(e.Ctx, name, pos)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return highlights
-}
-
-// RunGenerate runs go:generate on the given dir, calling t.Fatal on any error.
-// It waits for the generate command to complete and checks for file changes
-// before returning.
-func (e *Env) RunGenerate(dir string) {
-	e.T.Helper()
-	if err := e.Editor.RunGenerate(e.Ctx, dir); err != nil {
-		e.T.Fatal(err)
-	}
-	e.Await(NoOutstandingWork())
-	// Ideally the fake.Workspace would handle all synthetic file watching, but
-	// we help it out here as we need to wait for the generate command to
-	// complete before checking the filesystem.
-	e.CheckForFileChanges()
-}
-
-// RunGoCommand runs the given command in the sandbox's default working
-// directory.
-func (e *Env) RunGoCommand(verb string, args ...string) {
-	e.T.Helper()
-	if err := e.Sandbox.RunGoCommand(e.Ctx, "", verb, args, true); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// RunGoCommandInDir is like RunGoCommand, but executes in the given
-// relative directory of the sandbox.
-func (e *Env) RunGoCommandInDir(dir, verb string, args ...string) {
-	e.T.Helper()
-	if err := e.Sandbox.RunGoCommand(e.Ctx, dir, verb, args, true); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// GoVersion checks the version of the go command.
-// It returns the X in Go 1.X.
-func (e *Env) GoVersion() int {
-	e.T.Helper()
-	v, err := e.Sandbox.GoVersion(e.Ctx)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return v
-}
-
-// DumpGoSum prints the correct go.sum contents for dir in txtar format,
-// for use in creating regtests.
-func (e *Env) DumpGoSum(dir string) {
-	e.T.Helper()
-
-	if err := e.Sandbox.RunGoCommand(e.Ctx, dir, "list", []string{"-mod=mod", "..."}, true); err != nil {
-		e.T.Fatal(err)
-	}
-	sumFile := path.Join(dir, "/go.sum")
-	e.T.Log("\n\n-- " + sumFile + " --\n" + e.ReadWorkspaceFile(sumFile))
-	e.T.Fatal("see contents above")
-}
-
-// CheckForFileChanges triggers a manual poll of the workspace for any file
-// changes since creation, or since last polling. It is a workaround for the
-// lack of true file watching support in the fake workspace.
-func (e *Env) CheckForFileChanges() {
-	e.T.Helper()
-	if err := e.Sandbox.Workdir.CheckForFileChanges(e.Ctx); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// CodeLens calls textDocument/codeLens for the given path, calling t.Fatal on
-// any error.
-func (e *Env) CodeLens(path string) []protocol.CodeLens {
-	e.T.Helper()
-	lens, err := e.Editor.CodeLens(e.Ctx, path)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return lens
-}
-
-// ExecuteCodeLensCommand executes the command for the code lens matching the
-// given command name.
-func (e *Env) ExecuteCodeLensCommand(path string, cmd command.Command, result interface{}) {
-	e.T.Helper()
-	lenses := e.CodeLens(path)
-	var lens protocol.CodeLens
-	var found bool
-	for _, l := range lenses {
-		if l.Command.Command == cmd.ID() {
-			lens = l
-			found = true
-		}
-	}
-	if !found {
-		e.T.Fatalf("found no command with the ID %s", cmd.ID())
-	}
-	e.ExecuteCommand(&protocol.ExecuteCommandParams{
-		Command:   lens.Command.Command,
-		Arguments: lens.Command.Arguments,
-	}, result)
-}
-
-func (e *Env) ExecuteCommand(params *protocol.ExecuteCommandParams, result interface{}) {
-	e.T.Helper()
-	response, err := e.Editor.ExecuteCommand(e.Ctx, params)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	if result == nil {
-		return
-	}
-	// Hack: The result of an executeCommand request will be unmarshaled into
-	// maps. Re-marshal and unmarshal into the type we expect.
-	//
-	// This could be improved by generating a jsonrpc2 command client from the
-	// command.Interface, but that should only be done if we're consolidating
-	// this part of the tsprotocol generation.
-	data, err := json.Marshal(response)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	if err := json.Unmarshal(data, result); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// InlayHints calls textDocument/inlayHints for the given path, calling t.Fatal on
-// any error.
-func (e *Env) InlayHints(path string) []protocol.InlayHint {
-	e.T.Helper()
-	hints, err := e.Editor.InlayHint(e.Ctx, path)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return hints
-}
-
-// WorkspaceSymbol calls workspace/symbol
-func (e *Env) WorkspaceSymbol(sym string) []protocol.SymbolInformation {
-	e.T.Helper()
-	ans, err := e.Editor.Symbols(e.Ctx, sym)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return ans
-}
-
-// References wraps Editor.References, calling t.Fatal on any error.
-func (e *Env) References(path string, pos fake.Pos) []protocol.Location {
-	e.T.Helper()
-	locations, err := e.Editor.References(e.Ctx, path, pos)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return locations
-}
-
-// Rename wraps Editor.Rename, calling t.Fatal on any error.
-func (e *Env) Rename(path string, pos fake.Pos, newName string) {
-	e.T.Helper()
-	if err := e.Editor.Rename(e.Ctx, path, pos, newName); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// Implementations wraps Editor.Implementations, calling t.Fatal on any error.
-func (e *Env) Implementations(path string, pos fake.Pos) []protocol.Location {
-	e.T.Helper()
-	locations, err := e.Editor.Implementations(e.Ctx, path, pos)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return locations
-}
-
-// RenameFile wraps Editor.RenameFile, calling t.Fatal on any error.
-func (e *Env) RenameFile(oldPath, newPath string) {
-	e.T.Helper()
-	if err := e.Editor.RenameFile(e.Ctx, oldPath, newPath); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// Completion executes a completion request on the server.
-func (e *Env) Completion(path string, pos fake.Pos) *protocol.CompletionList {
-	e.T.Helper()
-	completions, err := e.Editor.Completion(e.Ctx, path, pos)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return completions
-}
-
-// AcceptCompletion accepts a completion for the given item at the given
-// position.
-func (e *Env) AcceptCompletion(path string, pos fake.Pos, item protocol.CompletionItem) {
-	e.T.Helper()
-	if err := e.Editor.AcceptCompletion(e.Ctx, path, pos, item); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// CodeAction calls testDocument/codeAction for the given path, and calls
-// t.Fatal if there are errors.
-func (e *Env) CodeAction(path string, diagnostics []protocol.Diagnostic) []protocol.CodeAction {
-	e.T.Helper()
-	actions, err := e.Editor.CodeAction(e.Ctx, path, nil, diagnostics)
-	if err != nil {
-		e.T.Fatal(err)
-	}
-	return actions
-}
-
-// ChangeConfiguration updates the editor config, calling t.Fatal on any error.
-func (e *Env) ChangeConfiguration(newConfig fake.EditorConfig) {
-	e.T.Helper()
-	if err := e.Editor.ChangeConfiguration(e.Ctx, newConfig); err != nil {
-		e.T.Fatal(err)
-	}
-}
-
-// ChangeWorkspaceFolders updates the editor workspace folders, calling t.Fatal
-// on any error.
-func (e *Env) ChangeWorkspaceFolders(newFolders ...string) {
-	e.T.Helper()
-	if err := e.Editor.ChangeWorkspaceFolders(e.Ctx, newFolders); err != nil {
-		e.T.Fatal(err)
-	}
-}
diff -urN a/gopls/internal/lsp/rename.go b/gopls/internal/lsp/rename.go
--- a/gopls/internal/lsp/rename.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/rename.go	1969-12-31 16:00:00
@@ -1,79 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"path/filepath"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (s *Server) rename(ctx context.Context, params *protocol.RenameParams) (*protocol.WorkspaceEdit, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	// Because we don't handle directory renaming within source.Rename, source.Rename returns
-	// boolean value isPkgRenaming to determine whether an DocumentChanges of type RenameFile should
-	// be added to the return protocol.WorkspaceEdit value.
-	edits, isPkgRenaming, err := source.Rename(ctx, snapshot, fh, params.Position, params.NewName)
-	if err != nil {
-		return nil, err
-	}
-
-	var docChanges []protocol.DocumentChanges
-	for uri, e := range edits {
-		fh, err := snapshot.GetVersionedFile(ctx, uri)
-		if err != nil {
-			return nil, err
-		}
-		docChanges = append(docChanges, documentChanges(fh, e)...)
-	}
-	if isPkgRenaming {
-		uri := params.TextDocument.URI.SpanURI()
-		oldBase := filepath.Dir(span.URI.Filename(uri))
-		newURI := filepath.Join(filepath.Dir(oldBase), params.NewName)
-		docChanges = append(docChanges, protocol.DocumentChanges{
-			RenameFile: &protocol.RenameFile{
-				Kind:   "rename",
-				OldURI: protocol.URIFromPath(oldBase),
-				NewURI: protocol.URIFromPath(newURI),
-			},
-		})
-	}
-	return &protocol.WorkspaceEdit{
-		DocumentChanges: docChanges,
-	}, nil
-}
-
-// prepareRename implements the textDocument/prepareRename handler. It may
-// return (nil, nil) if there is no rename at the cursor position, but it is
-// not desirable to display an error to the user.
-//
-// TODO(rfindley): why wouldn't we want to show an error to the user, if the
-// user initiated a rename request at the cursor?
-func (s *Server) prepareRename(ctx context.Context, params *protocol.PrepareRenameParams) (*protocol.PrepareRename2Gn, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	// Do not return errors here, as it adds clutter.
-	// Returning a nil result means there is not a valid rename.
-	item, usererr, err := source.PrepareRename(ctx, snapshot, fh, params.Position)
-	if err != nil {
-		// Return usererr here rather than err, to avoid cluttering the UI with
-		// internal error details.
-		return nil, usererr
-	}
-	return &protocol.PrepareRename2Gn{
-		Range:       item.Range,
-		Placeholder: item.Text,
-	}, nil
-}
diff -urN a/gopls/internal/lsp/reset_golden.sh b/gopls/internal/lsp/reset_golden.sh
--- a/gopls/internal/lsp/reset_golden.sh	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/reset_golden.sh	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-#!/bin/bash
-#
-# Copyright 2022 The Go Authors. All rights reserved.
-# Use of this source code is governed by a BSD-style
-# license that can be found in the LICENSE file.
-#
-# Updates the *.golden files ... to match the tests' current behavior.
-
-set -eu
-
-GO117BIN="go1.17.9"
-
-command -v $GO117BIN >/dev/null 2>&1 || {
-  go install golang.org/dl/$GO117BIN@latest
-  $GO117BIN download
-}
-
-find ./internal/lsp/testdata -name *.golden ! -name summary*.txt.golden -delete
-# Here we intentionally do not run the ./internal/lsp/source tests with
-# -golden. Eventually these tests will be deleted, and in the meantime they are
-# redundant with the ./internal/lsp tests.
-#
-# Note: go1.17.9 tests must be run *before* go tests, as by convention the
-# golden output should match the output of gopls built with the most recent
-# version of Go. If output differs at 1.17, tests must be tolerant of the 1.17
-# output.
-$GO117BIN test ./internal/lsp -golden
-go test ./internal/lsp -golden
-$GO117BIN test ./test  -golden
-go test ./test  -golden
diff -urN a/gopls/internal/lsp/safetoken/safetoken.go b/gopls/internal/lsp/safetoken/safetoken.go
--- a/gopls/internal/lsp/safetoken/safetoken.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/safetoken/safetoken.go	1969-12-31 16:00:00
@@ -1,109 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package safetoken provides wrappers around methods in go/token,
-// that return errors rather than panicking.
-//
-// It also provides a central place for workarounds in the underlying
-// packages. The use of this package's functions instead of methods of
-// token.File (such as Offset, Position, and PositionFor) is mandatory
-// throughout the gopls codebase and enforced by a static check.
-package safetoken
-
-import (
-	"fmt"
-	"go/token"
-)
-
-// Offset returns f.Offset(pos), but first checks that the file
-// contains the pos.
-//
-// The definition of "contains" here differs from that of token.File
-// in order to work around a bug in the parser (issue #57490): during
-// error recovery, the parser may create syntax nodes whose computed
-// End position is 1 byte beyond EOF, which would cause
-// token.File.Offset to panic. The workaround is that this function
-// accepts a Pos that is exactly 1 byte beyond EOF and maps it to the
-// EOF offset.
-func Offset(f *token.File, pos token.Pos) (int, error) {
-	if !inRange(f, pos) {
-		// Accept a Pos that is 1 byte beyond EOF,
-		// and map it to the EOF offset.
-		// (Workaround for #57490.)
-		if int(pos) == f.Base()+f.Size()+1 {
-			return f.Size(), nil
-		}
-
-		return -1, fmt.Errorf("pos %d is not in range [%d:%d] of file %s",
-			pos, f.Base(), f.Base()+f.Size(), f.Name())
-	}
-	return int(pos) - f.Base(), nil
-}
-
-// Pos returns f.Pos(offset), but first checks that the offset is
-// non-negative and not larger than the size of the file.
-func Pos(f *token.File, offset int) (token.Pos, error) {
-	if !(0 <= offset && offset <= f.Size()) {
-		return token.NoPos, fmt.Errorf("offset %d is not in range for file %s of size %d", offset, f.Name(), f.Size())
-	}
-	return token.Pos(f.Base() + offset), nil
-}
-
-// inRange reports whether file f contains position pos,
-// according to the invariants of token.File.
-//
-// This function is not public because of the ambiguity it would
-// create w.r.t. the definition of "contains". Use Offset instead.
-func inRange(f *token.File, pos token.Pos) bool {
-	return token.Pos(f.Base()) <= pos && pos <= token.Pos(f.Base()+f.Size())
-}
-
-// Position returns the Position for the pos value in the given file.
-//
-// p must be NoPos, a valid Pos in the range of f, or exactly 1 byte
-// beyond the end of f. (See [Offset] for explanation.)
-// Any other value causes a panic.
-//
-// Line directives (//line comments) are ignored.
-func Position(f *token.File, pos token.Pos) token.Position {
-	// Work around issue #57490.
-	if int(pos) == f.Base()+f.Size()+1 {
-		pos--
-	}
-
-	// TODO(adonovan): centralize the workaround for
-	// golang/go#41029 (newline at EOF) here too.
-
-	return f.PositionFor(pos, false)
-}
-
-// StartPosition converts a start Pos in the FileSet into a Position.
-//
-// Call this function only if start represents the start of a token or
-// parse tree, such as the result of Node.Pos().  If start is the end of
-// an interval, such as Node.End(), call EndPosition instead, as it
-// may need the correction described at [Position].
-func StartPosition(fset *token.FileSet, start token.Pos) (_ token.Position) {
-	if f := fset.File(start); f != nil {
-		return Position(f, start)
-	}
-	return
-}
-
-// EndPosition converts an end Pos in the FileSet into a Position.
-//
-// Call this function only if pos represents the end of
-// a non-empty interval, such as the result of Node.End().
-func EndPosition(fset *token.FileSet, end token.Pos) (_ token.Position) {
-	if f := fset.File(end); f != nil && int(end) > f.Base() {
-		return Position(f, end)
-	}
-
-	// Work around issue #57490.
-	if f := fset.File(end - 1); f != nil {
-		return Position(f, end)
-	}
-
-	return
-}
diff -urN a/gopls/internal/lsp/safetoken/safetoken_test.go b/gopls/internal/lsp/safetoken/safetoken_test.go
--- a/gopls/internal/lsp/safetoken/safetoken_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/safetoken/safetoken_test.go	1969-12-31 16:00:00
@@ -1,121 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package safetoken_test
-
-import (
-	"fmt"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"os"
-	"testing"
-
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestWorkaroundIssue57490(t *testing.T) {
-	// During error recovery the parser synthesizes various close
-	// tokens at EOF, causing the End position of incomplete
-	// syntax nodes, computed as Rbrace+len("}"), to be beyond EOF.
-	src := `package p; func f() { var x struct`
-	fset := token.NewFileSet()
-	file, _ := parser.ParseFile(fset, "a.go", src, 0)
-	tf := fset.File(file.Pos())
-
-	// Add another file to the FileSet.
-	file2, _ := parser.ParseFile(fset, "b.go", "package q", 0)
-
-	// This is the ambiguity of #57490...
-	if file.End() != file2.Pos() {
-		t.Errorf("file.End() %d != %d file2.Pos()", file.End(), file2.Pos())
-	}
-	// ...which causes these statements to panic.
-	if false {
-		tf.Offset(file.End())   // panic: invalid Pos value 36 (should be in [1, 35])
-		tf.Position(file.End()) // panic: invalid Pos value 36 (should be in [1, 35])
-	}
-
-	// The offset of the EOF position is the file size.
-	offset, err := safetoken.Offset(tf, file.End()-1)
-	if err != nil || offset != tf.Size() {
-		t.Errorf("Offset(EOF) = (%d, %v), want token.File.Size %d", offset, err, tf.Size())
-	}
-
-	// The offset of the file.End() position, 1 byte beyond EOF,
-	// is also the size of the file.
-	offset, err = safetoken.Offset(tf, file.End())
-	if err != nil || offset != tf.Size() {
-		t.Errorf("Offset(ast.File.End()) = (%d, %v), want token.File.Size %d", offset, err, tf.Size())
-	}
-
-	if got, want := safetoken.Position(tf, file.End()).String(), "a.go:1:35"; got != want {
-		t.Errorf("Position(ast.File.End()) = %s, want %s", got, want)
-	}
-
-	if got, want := safetoken.EndPosition(fset, file.End()).String(), "a.go:1:35"; got != want {
-		t.Errorf("EndPosition(ast.File.End()) = %s, want %s", got, want)
-	}
-
-	// Note that calling StartPosition on an end may yield the wrong file:
-	if got, want := safetoken.StartPosition(fset, file.End()).String(), "b.go:1:1"; got != want {
-		t.Errorf("StartPosition(ast.File.End()) = %s, want %s", got, want)
-	}
-}
-
-// To reduce the risk of panic, or bugs for which this package
-// provides a workaround, this test statically reports references to
-// forbidden methods of token.File or FileSet throughout gopls and
-// suggests alternatives.
-func TestGoplsSourceDoesNotCallTokenFileMethods(t *testing.T) {
-	testenv.NeedsGoPackages(t)
-
-	pkgs, err := packages.Load(&packages.Config{
-		Mode: packages.NeedName | packages.NeedModule | packages.NeedCompiledGoFiles | packages.NeedTypes | packages.NeedTypesInfo | packages.NeedSyntax | packages.NeedImports | packages.NeedDeps,
-	}, "go/token", "golang.org/x/tools/gopls/...")
-	if err != nil {
-		t.Fatal(err)
-	}
-	var tokenPkg *packages.Package
-	for _, pkg := range pkgs {
-		if pkg.PkgPath == "go/token" {
-			tokenPkg = pkg
-			break
-		}
-	}
-	if tokenPkg == nil {
-		t.Fatal("missing package go/token")
-	}
-
-	File := tokenPkg.Types.Scope().Lookup("File")
-	FileSet := tokenPkg.Types.Scope().Lookup("FileSet")
-
-	alternative := make(map[types.Object]string)
-	setAlternative := func(recv types.Object, old, new string) {
-		oldMethod, _, _ := types.LookupFieldOrMethod(recv.Type(), true, recv.Pkg(), old)
-		alternative[oldMethod] = new
-	}
-	setAlternative(File, "Offset", "safetoken.Offset")
-	setAlternative(File, "Position", "safetoken.Position")
-	setAlternative(File, "PositionFor", "safetoken.Position")
-	setAlternative(FileSet, "Position", "safetoken.StartPosition or EndPosition")
-	setAlternative(FileSet, "PositionFor", "safetoken.StartPosition or EndPosition")
-
-	for _, pkg := range pkgs {
-		switch pkg.PkgPath {
-		case "go/token", "golang.org/x/tools/gopls/internal/lsp/safetoken":
-			continue // allow calls within these packages
-		}
-
-		for ident, obj := range pkg.TypesInfo.Uses {
-			if alt, ok := alternative[obj]; ok {
-				posn := safetoken.StartPosition(pkg.Fset, ident.Pos())
-				fmt.Fprintf(os.Stderr, "%s: forbidden use of %v; use %s instead.\n", posn, obj, alt)
-				t.Fail()
-			}
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/selection_range.go b/gopls/internal/lsp/selection_range.go
--- a/gopls/internal/lsp/selection_range.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/selection_range.go	1969-12-31 16:00:00
@@ -1,69 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-// selectionRange defines the textDocument/selectionRange feature,
-// which, given a list of positions within a file,
-// reports a linked list of enclosing syntactic blocks, innermost first.
-//
-// See https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textDocument_selectionRange.
-//
-// This feature can be used by a client to implement "expand selection" in a
-// language-aware fashion. Multiple input positions are supported to allow
-// for multiple cursors, and the entire path up to the whole document is
-// returned for each cursor to avoid multiple round-trips when the user is
-// likely to issue this command multiple times in quick succession.
-func (s *Server) selectionRange(ctx context.Context, params *protocol.SelectionRangeParams) ([]protocol.SelectionRange, error) {
-	ctx, done := event.Start(ctx, "lsp.Server.documentSymbol")
-	defer done()
-
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-
-	pgf, err := snapshot.ParseGo(ctx, fh, source.ParseFull)
-	if err != nil {
-		return nil, err
-	}
-
-	result := make([]protocol.SelectionRange, len(params.Positions))
-	for i, protocolPos := range params.Positions {
-		pos, err := pgf.Mapper.Pos(protocolPos)
-		if err != nil {
-			return nil, err
-		}
-
-		path, _ := astutil.PathEnclosingInterval(pgf.File, pos, pos)
-
-		tail := &result[i] // tail of the Parent linked list, built head first
-
-		for j, node := range path {
-			rng, err := pgf.Mapper.PosRange(node.Pos(), node.End())
-			if err != nil {
-				return nil, err
-			}
-
-			// Add node to tail.
-			if j > 0 {
-				tail.Parent = &protocol.SelectionRange{}
-				tail = tail.Parent
-			}
-			tail.Range = rng
-		}
-	}
-
-	return result, nil
-}
diff -urN a/gopls/internal/lsp/semantic.go b/gopls/internal/lsp/semantic.go
--- a/gopls/internal/lsp/semantic.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/semantic.go	1969-12-31 16:00:00
@@ -1,992 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"log"
-	"path/filepath"
-	"sort"
-	"strings"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// The LSP says that errors for the semantic token requests should only be returned
-// for exceptions (a word not otherwise defined). This code treats a too-large file
-// as an exception. On parse errors, the code does what it can.
-
-// reject full semantic token requests for large files
-const maxFullFileSize int = 100000
-
-// to control comprehensive logging of decisions (gopls semtok foo.go > /dev/null shows log output)
-// semDebug should NEVER be true in checked-in code
-const semDebug = false
-
-func (s *Server) semanticTokensFull(ctx context.Context, p *protocol.SemanticTokensParams) (*protocol.SemanticTokens, error) {
-	ret, err := s.computeSemanticTokens(ctx, p.TextDocument, nil)
-	return ret, err
-}
-
-func (s *Server) semanticTokensFullDelta(ctx context.Context, p *protocol.SemanticTokensDeltaParams) (interface{}, error) {
-	return nil, fmt.Errorf("implement SemanticTokensFullDelta")
-}
-
-func (s *Server) semanticTokensRange(ctx context.Context, p *protocol.SemanticTokensRangeParams) (*protocol.SemanticTokens, error) {
-	ret, err := s.computeSemanticTokens(ctx, p.TextDocument, &p.Range)
-	return ret, err
-}
-
-func (s *Server) semanticTokensRefresh(ctx context.Context) error {
-	// in the code, but not in the protocol spec
-	return fmt.Errorf("implement SemanticTokensRefresh")
-}
-
-func (s *Server) computeSemanticTokens(ctx context.Context, td protocol.TextDocumentIdentifier, rng *protocol.Range) (*protocol.SemanticTokens, error) {
-	ans := protocol.SemanticTokens{
-		Data: []uint32{},
-	}
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, td.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	vv := snapshot.View()
-	if !vv.Options().SemanticTokens {
-		// return an error, so if the option changes
-		// the client won't remember the wrong answer
-		return nil, fmt.Errorf("semantictokens are disabled")
-	}
-	kind := snapshot.View().FileKind(fh)
-	if kind == source.Tmpl {
-		// this is a little cumbersome to avoid both exporting 'encoded' and its methods
-		// and to avoid import cycles
-		e := &encoded{
-			ctx:      ctx,
-			rng:      rng,
-			tokTypes: s.session.Options().SemanticTypes,
-			tokMods:  s.session.Options().SemanticMods,
-		}
-		add := func(line, start uint32, len uint32) {
-			e.add(line, start, len, tokMacro, nil)
-		}
-		data := func() []uint32 {
-			return e.Data()
-		}
-		return template.SemanticTokens(ctx, snapshot, fh.URI(), add, data)
-	}
-	if kind != source.Go {
-		return nil, nil
-	}
-	pkg, pgf, err := source.PackageForFile(ctx, snapshot, fh.URI(), source.TypecheckFull, source.WidestPackage)
-	if err != nil {
-		return nil, err
-	}
-
-	if rng == nil && len(pgf.Src) > maxFullFileSize {
-		err := fmt.Errorf("semantic tokens: file %s too large for full (%d>%d)",
-			fh.URI().Filename(), len(pgf.Src), maxFullFileSize)
-		return nil, err
-	}
-	e := &encoded{
-		ctx:       ctx,
-		pgf:       pgf,
-		rng:       rng,
-		ti:        pkg.GetTypesInfo(),
-		pkg:       pkg,
-		fset:      pkg.FileSet(),
-		tokTypes:  s.session.Options().SemanticTypes,
-		tokMods:   s.session.Options().SemanticMods,
-		noStrings: vv.Options().NoSemanticString,
-		noNumbers: vv.Options().NoSemanticNumber,
-	}
-	if err := e.init(); err != nil {
-		// e.init should never return an error, unless there's some
-		// seemingly impossible race condition
-		return nil, err
-	}
-	e.semantics()
-	ans.Data = e.Data()
-	// For delta requests, but we've never seen any.
-	ans.ResultID = fmt.Sprintf("%v", time.Now())
-	return &ans, nil
-}
-
-func (e *encoded) semantics() {
-	f := e.pgf.File
-	// may not be in range, but harmless
-	e.token(f.Package, len("package"), tokKeyword, nil)
-	e.token(f.Name.NamePos, len(f.Name.Name), tokNamespace, nil)
-	inspect := func(n ast.Node) bool {
-		return e.inspector(n)
-	}
-	for _, d := range f.Decls {
-		// only look at the decls that overlap the range
-		start, end := d.Pos(), d.End()
-		if end <= e.start || start >= e.end {
-			continue
-		}
-		ast.Inspect(d, inspect)
-	}
-	for _, cg := range f.Comments {
-		for _, c := range cg.List {
-			if !strings.Contains(c.Text, "\n") {
-				e.token(c.Pos(), len(c.Text), tokComment, nil)
-				continue
-			}
-			e.multiline(c.Pos(), c.End(), c.Text, tokComment)
-		}
-	}
-}
-
-type tokenType string
-
-const (
-	tokNamespace tokenType = "namespace"
-	tokType      tokenType = "type"
-	tokInterface tokenType = "interface"
-	tokTypeParam tokenType = "typeParameter"
-	tokParameter tokenType = "parameter"
-	tokVariable  tokenType = "variable"
-	tokMethod    tokenType = "method"
-	tokFunction  tokenType = "function"
-	tokKeyword   tokenType = "keyword"
-	tokComment   tokenType = "comment"
-	tokString    tokenType = "string"
-	tokNumber    tokenType = "number"
-	tokOperator  tokenType = "operator"
-
-	tokMacro tokenType = "macro" // for templates
-)
-
-func (e *encoded) token(start token.Pos, leng int, typ tokenType, mods []string) {
-	if !start.IsValid() {
-		// This is not worth reporting. TODO(pjw): does it still happen?
-		return
-	}
-	if start >= e.end || start+token.Pos(leng) <= e.start {
-		return
-	}
-	// want a line and column from start (in LSP coordinates). Ignore line directives.
-	rng := source.NewMappedRange(e.pgf.Mapper, start, start+token.Pos(leng))
-	lspRange, err := rng.Range()
-	if err != nil {
-		event.Error(e.ctx, "failed to convert to range", err)
-		return
-	}
-	if lspRange.End.Line != lspRange.Start.Line {
-		// this happens if users are typing at the end of the file, but report nothing
-		return
-	}
-	// token is all on one line
-	length := lspRange.End.Character - lspRange.Start.Character
-	e.add(lspRange.Start.Line, lspRange.Start.Character, length, typ, mods)
-}
-
-func (e *encoded) add(line, start uint32, len uint32, tok tokenType, mod []string) {
-	x := semItem{line, start, len, tok, mod}
-	e.items = append(e.items, x)
-}
-
-// semItem represents a token found walking the parse tree
-type semItem struct {
-	line, start uint32
-	len         uint32
-	typeStr     tokenType
-	mods        []string
-}
-
-type encoded struct {
-	// the generated data
-	items []semItem
-
-	noStrings bool
-	noNumbers bool
-
-	ctx               context.Context
-	tokTypes, tokMods []string
-	pgf               *source.ParsedGoFile
-	rng               *protocol.Range
-	ti                *types.Info
-	pkg               source.Package
-	fset              *token.FileSet
-	// allowed starting and ending token.Pos, set by init
-	// used to avoid looking at declarations not in range
-	start, end token.Pos
-	// path from the root of the parse tree, used for debugging
-	stack []ast.Node
-}
-
-// convert the stack to a string, for debugging
-func (e *encoded) strStack() string {
-	msg := []string{"["}
-	for i := len(e.stack) - 1; i >= 0; i-- {
-		s := e.stack[i]
-		msg = append(msg, fmt.Sprintf("%T", s)[5:])
-	}
-	if len(e.stack) > 0 {
-		loc := e.stack[len(e.stack)-1].Pos()
-		if _, err := safetoken.Offset(e.pgf.Tok, loc); err != nil {
-			msg = append(msg, fmt.Sprintf("invalid position %v for %s", loc, e.pgf.URI))
-		} else {
-			add := safetoken.Position(e.pgf.Tok, loc)
-			nm := filepath.Base(add.Filename)
-			msg = append(msg, fmt.Sprintf("(%s:%d,col:%d)", nm, add.Line, add.Column))
-		}
-	}
-	msg = append(msg, "]")
-	return strings.Join(msg, " ")
-}
-
-// find the line in the source
-func (e *encoded) srcLine(x ast.Node) string {
-	file := e.pgf.Tok
-	line := file.Line(x.Pos())
-	start, err := safetoken.Offset(file, file.LineStart(line))
-	if err != nil {
-		return ""
-	}
-	end := start
-	for ; end < len(e.pgf.Src) && e.pgf.Src[end] != '\n'; end++ {
-
-	}
-	ans := e.pgf.Src[start:end]
-	return string(ans)
-}
-
-func (e *encoded) inspector(n ast.Node) bool {
-	pop := func() {
-		e.stack = e.stack[:len(e.stack)-1]
-	}
-	if n == nil {
-		pop()
-		return true
-	}
-	e.stack = append(e.stack, n)
-	switch x := n.(type) {
-	case *ast.ArrayType:
-	case *ast.AssignStmt:
-		e.token(x.TokPos, len(x.Tok.String()), tokOperator, nil)
-	case *ast.BasicLit:
-		if strings.Contains(x.Value, "\n") {
-			// has to be a string.
-			e.multiline(x.Pos(), x.End(), x.Value, tokString)
-			break
-		}
-		ln := len(x.Value)
-		what := tokNumber
-		if x.Kind == token.STRING {
-			what = tokString
-		}
-		e.token(x.Pos(), ln, what, nil)
-	case *ast.BinaryExpr:
-		e.token(x.OpPos, len(x.Op.String()), tokOperator, nil)
-	case *ast.BlockStmt:
-	case *ast.BranchStmt:
-		e.token(x.TokPos, len(x.Tok.String()), tokKeyword, nil)
-		// There's no semantic encoding for labels
-	case *ast.CallExpr:
-		if x.Ellipsis != token.NoPos {
-			e.token(x.Ellipsis, len("..."), tokOperator, nil)
-		}
-	case *ast.CaseClause:
-		iam := "case"
-		if x.List == nil {
-			iam = "default"
-		}
-		e.token(x.Case, len(iam), tokKeyword, nil)
-	case *ast.ChanType:
-		// chan | chan <- | <- chan
-		switch {
-		case x.Arrow == token.NoPos:
-			e.token(x.Begin, len("chan"), tokKeyword, nil)
-		case x.Arrow == x.Begin:
-			e.token(x.Arrow, 2, tokOperator, nil)
-			pos := e.findKeyword("chan", x.Begin+2, x.Value.Pos())
-			e.token(pos, len("chan"), tokKeyword, nil)
-		case x.Arrow != x.Begin:
-			e.token(x.Begin, len("chan"), tokKeyword, nil)
-			e.token(x.Arrow, 2, tokOperator, nil)
-		}
-	case *ast.CommClause:
-		iam := len("case")
-		if x.Comm == nil {
-			iam = len("default")
-		}
-		e.token(x.Case, iam, tokKeyword, nil)
-	case *ast.CompositeLit:
-	case *ast.DeclStmt:
-	case *ast.DeferStmt:
-		e.token(x.Defer, len("defer"), tokKeyword, nil)
-	case *ast.Ellipsis:
-		e.token(x.Ellipsis, len("..."), tokOperator, nil)
-	case *ast.EmptyStmt:
-	case *ast.ExprStmt:
-	case *ast.Field:
-	case *ast.FieldList:
-	case *ast.ForStmt:
-		e.token(x.For, len("for"), tokKeyword, nil)
-	case *ast.FuncDecl:
-	case *ast.FuncLit:
-	case *ast.FuncType:
-		if x.Func != token.NoPos {
-			e.token(x.Func, len("func"), tokKeyword, nil)
-		}
-	case *ast.GenDecl:
-		e.token(x.TokPos, len(x.Tok.String()), tokKeyword, nil)
-	case *ast.GoStmt:
-		e.token(x.Go, len("go"), tokKeyword, nil)
-	case *ast.Ident:
-		e.ident(x)
-	case *ast.IfStmt:
-		e.token(x.If, len("if"), tokKeyword, nil)
-		if x.Else != nil {
-			// x.Body.End() or x.Body.End()+1, not that it matters
-			pos := e.findKeyword("else", x.Body.End(), x.Else.Pos())
-			e.token(pos, len("else"), tokKeyword, nil)
-		}
-	case *ast.ImportSpec:
-		e.importSpec(x)
-		pop()
-		return false
-	case *ast.IncDecStmt:
-		e.token(x.TokPos, len(x.Tok.String()), tokOperator, nil)
-	case *ast.IndexExpr:
-	case *typeparams.IndexListExpr:
-	case *ast.InterfaceType:
-		e.token(x.Interface, len("interface"), tokKeyword, nil)
-	case *ast.KeyValueExpr:
-	case *ast.LabeledStmt:
-	case *ast.MapType:
-		e.token(x.Map, len("map"), tokKeyword, nil)
-	case *ast.ParenExpr:
-	case *ast.RangeStmt:
-		e.token(x.For, len("for"), tokKeyword, nil)
-		// x.TokPos == token.NoPos is legal (for range foo {})
-		offset := x.TokPos
-		if offset == token.NoPos {
-			offset = x.For
-		}
-		pos := e.findKeyword("range", offset, x.X.Pos())
-		e.token(pos, len("range"), tokKeyword, nil)
-	case *ast.ReturnStmt:
-		e.token(x.Return, len("return"), tokKeyword, nil)
-	case *ast.SelectStmt:
-		e.token(x.Select, len("select"), tokKeyword, nil)
-	case *ast.SelectorExpr:
-	case *ast.SendStmt:
-		e.token(x.Arrow, len("<-"), tokOperator, nil)
-	case *ast.SliceExpr:
-	case *ast.StarExpr:
-		e.token(x.Star, len("*"), tokOperator, nil)
-	case *ast.StructType:
-		e.token(x.Struct, len("struct"), tokKeyword, nil)
-	case *ast.SwitchStmt:
-		e.token(x.Switch, len("switch"), tokKeyword, nil)
-	case *ast.TypeAssertExpr:
-		if x.Type == nil {
-			pos := e.findKeyword("type", x.Lparen, x.Rparen)
-			e.token(pos, len("type"), tokKeyword, nil)
-		}
-	case *ast.TypeSpec:
-	case *ast.TypeSwitchStmt:
-		e.token(x.Switch, len("switch"), tokKeyword, nil)
-	case *ast.UnaryExpr:
-		e.token(x.OpPos, len(x.Op.String()), tokOperator, nil)
-	case *ast.ValueSpec:
-	// things only seen with parsing or type errors, so ignore them
-	case *ast.BadDecl, *ast.BadExpr, *ast.BadStmt:
-		return true
-	// not going to see these
-	case *ast.File, *ast.Package:
-		e.unexpected(fmt.Sprintf("implement %T %s", x, safetoken.Position(e.pgf.Tok, x.Pos())))
-	// other things we knowingly ignore
-	case *ast.Comment, *ast.CommentGroup:
-		pop()
-		return false
-	default:
-		e.unexpected(fmt.Sprintf("failed to implement %T", x))
-	}
-	return true
-}
-
-func (e *encoded) ident(x *ast.Ident) {
-	if e.ti == nil {
-		what, mods := e.unkIdent(x)
-		if what != "" {
-			e.token(x.Pos(), len(x.String()), what, mods)
-		}
-		if semDebug {
-			log.Printf(" nil %s/nil/nil %q %v %s", x.String(), what, mods, e.strStack())
-		}
-		return
-	}
-	def := e.ti.Defs[x]
-	if def != nil {
-		what, mods := e.definitionFor(x, def)
-		if what != "" {
-			e.token(x.Pos(), len(x.String()), what, mods)
-		}
-		if semDebug {
-			log.Printf(" for %s/%T/%T got %s %v (%s)", x.String(), def, def.Type(), what, mods, e.strStack())
-		}
-		return
-	}
-	use := e.ti.Uses[x]
-	tok := func(pos token.Pos, lng int, tok tokenType, mods []string) {
-		e.token(pos, lng, tok, mods)
-		q := "nil"
-		if use != nil {
-			q = fmt.Sprintf("%T", use.Type())
-		}
-		if semDebug {
-			log.Printf(" use %s/%T/%s got %s %v (%s)", x.String(), use, q, tok, mods, e.strStack())
-		}
-	}
-
-	switch y := use.(type) {
-	case nil:
-		what, mods := e.unkIdent(x)
-		if what != "" {
-			tok(x.Pos(), len(x.String()), what, mods)
-		} else if semDebug {
-			// tok() wasn't called, so didn't log
-			log.Printf(" nil %s/%T/nil %q %v (%s)", x.String(), use, what, mods, e.strStack())
-		}
-		return
-	case *types.Builtin:
-		tok(x.NamePos, len(x.Name), tokFunction, []string{"defaultLibrary"})
-	case *types.Const:
-		mods := []string{"readonly"}
-		tt := y.Type()
-		if _, ok := tt.(*types.Basic); ok {
-			tok(x.Pos(), len(x.String()), tokVariable, mods)
-			break
-		}
-		if ttx, ok := tt.(*types.Named); ok {
-			if x.String() == "iota" {
-				e.unexpected(fmt.Sprintf("iota:%T", ttx))
-			}
-			if _, ok := ttx.Underlying().(*types.Basic); ok {
-				tok(x.Pos(), len(x.String()), tokVariable, mods)
-				break
-			}
-			e.unexpected(fmt.Sprintf("%q/%T", x.String(), tt))
-		}
-		// can this happen? Don't think so
-		e.unexpected(fmt.Sprintf("%s %T %#v", x.String(), tt, tt))
-	case *types.Func:
-		tok(x.Pos(), len(x.Name), tokFunction, nil)
-	case *types.Label:
-		// nothing to map it to
-	case *types.Nil:
-		// nil is a predeclared identifier
-		tok(x.Pos(), len("nil"), tokVariable, []string{"readonly", "defaultLibrary"})
-	case *types.PkgName:
-		tok(x.Pos(), len(x.Name), tokNamespace, nil)
-	case *types.TypeName: // could be a tokTpeParam
-		var mods []string
-		if _, ok := y.Type().(*types.Basic); ok {
-			mods = []string{"defaultLibrary"}
-		} else if _, ok := y.Type().(*typeparams.TypeParam); ok {
-			tok(x.Pos(), len(x.String()), tokTypeParam, mods)
-			break
-		}
-		tok(x.Pos(), len(x.String()), tokType, mods)
-	case *types.Var:
-		if isSignature(y) {
-			tok(x.Pos(), len(x.Name), tokFunction, nil)
-		} else if e.isParam(use.Pos()) {
-			// variable, unless use.pos is the pos of a Field in an ancestor FuncDecl
-			// or FuncLit and then it's a parameter
-			tok(x.Pos(), len(x.Name), tokParameter, nil)
-		} else {
-			tok(x.Pos(), len(x.Name), tokVariable, nil)
-		}
-
-	default:
-		// can't happen
-		if use == nil {
-			msg := fmt.Sprintf("%#v/%#v %#v %#v", x, x.Obj, e.ti.Defs[x], e.ti.Uses[x])
-			e.unexpected(msg)
-		}
-		if use.Type() != nil {
-			e.unexpected(fmt.Sprintf("%s %T/%T,%#v", x.String(), use, use.Type(), use))
-		} else {
-			e.unexpected(fmt.Sprintf("%s %T", x.String(), use))
-		}
-	}
-}
-
-func (e *encoded) isParam(pos token.Pos) bool {
-	for i := len(e.stack) - 1; i >= 0; i-- {
-		switch n := e.stack[i].(type) {
-		case *ast.FuncDecl:
-			for _, f := range n.Type.Params.List {
-				for _, id := range f.Names {
-					if id.Pos() == pos {
-						return true
-					}
-				}
-			}
-		case *ast.FuncLit:
-			for _, f := range n.Type.Params.List {
-				for _, id := range f.Names {
-					if id.Pos() == pos {
-						return true
-					}
-				}
-			}
-		}
-	}
-	return false
-}
-
-func isSignature(use types.Object) bool {
-	if _, ok := use.(*types.Var); !ok {
-		return false
-	}
-	v := use.Type()
-	if v == nil {
-		return false
-	}
-	if _, ok := v.(*types.Signature); ok {
-		return true
-	}
-	return false
-}
-
-// both e.ti.Defs and e.ti.Uses are nil. use the parse stack.
-// a lot of these only happen when the package doesn't compile
-// but in that case it is all best-effort from the parse tree
-func (e *encoded) unkIdent(x *ast.Ident) (tokenType, []string) {
-	def := []string{"definition"}
-	n := len(e.stack) - 2 // parent of Ident
-	if n < 0 {
-		e.unexpected("no stack?")
-		return "", nil
-	}
-	switch nd := e.stack[n].(type) {
-	case *ast.BinaryExpr, *ast.UnaryExpr, *ast.ParenExpr, *ast.StarExpr,
-		*ast.IncDecStmt, *ast.SliceExpr, *ast.ExprStmt, *ast.IndexExpr,
-		*ast.ReturnStmt, *ast.ChanType, *ast.SendStmt,
-		*ast.ForStmt,      // possibly incomplete
-		*ast.IfStmt,       /* condition */
-		*ast.KeyValueExpr: // either key or value
-		return tokVariable, nil
-	case *typeparams.IndexListExpr:
-		return tokVariable, nil
-	case *ast.Ellipsis:
-		return tokType, nil
-	case *ast.CaseClause:
-		if n-2 >= 0 {
-			if _, ok := e.stack[n-2].(*ast.TypeSwitchStmt); ok {
-				return tokType, nil
-			}
-		}
-		return tokVariable, nil
-	case *ast.ArrayType:
-		if x == nd.Len {
-			// or maybe a Type Param, but we can't just from the parse tree
-			return tokVariable, nil
-		} else {
-			return tokType, nil
-		}
-	case *ast.MapType:
-		return tokType, nil
-	case *ast.CallExpr:
-		if x == nd.Fun {
-			return tokFunction, nil
-		}
-		return tokVariable, nil
-	case *ast.SwitchStmt:
-		return tokVariable, nil
-	case *ast.TypeAssertExpr:
-		if x == nd.X {
-			return tokVariable, nil
-		} else if x == nd.Type {
-			return tokType, nil
-		}
-	case *ast.ValueSpec:
-		for _, p := range nd.Names {
-			if p == x {
-				return tokVariable, def
-			}
-		}
-		for _, p := range nd.Values {
-			if p == x {
-				return tokVariable, nil
-			}
-		}
-		return tokType, nil
-	case *ast.SelectorExpr: // e.ti.Selections[nd] is nil, so no help
-		if n-1 >= 0 {
-			if ce, ok := e.stack[n-1].(*ast.CallExpr); ok {
-				// ... CallExpr SelectorExpr Ident (_.x())
-				if ce.Fun == nd && nd.Sel == x {
-					return tokFunction, nil
-				}
-			}
-		}
-		return tokVariable, nil
-	case *ast.AssignStmt:
-		for _, p := range nd.Lhs {
-			// x := ..., or x = ...
-			if p == x {
-				if nd.Tok != token.DEFINE {
-					def = nil
-				}
-				return tokVariable, def // '_' in _ = ...
-			}
-		}
-		// RHS, = x
-		return tokVariable, nil
-	case *ast.TypeSpec: // it's a type if it is either the Name or the Type
-		if x == nd.Type {
-			def = nil
-		}
-		return tokType, def
-	case *ast.Field:
-		// ident could be type in a field, or a method in an interface type, or a variable
-		if x == nd.Type {
-			return tokType, nil
-		}
-		if n-2 >= 0 {
-			_, okit := e.stack[n-2].(*ast.InterfaceType)
-			_, okfl := e.stack[n-1].(*ast.FieldList)
-			if okit && okfl {
-				return tokMethod, def
-			}
-		}
-		return tokVariable, nil
-	case *ast.LabeledStmt, *ast.BranchStmt:
-		// nothing to report
-	case *ast.CompositeLit:
-		if nd.Type == x {
-			return tokType, nil
-		}
-		return tokVariable, nil
-	case *ast.RangeStmt:
-		if nd.Tok != token.DEFINE {
-			def = nil
-		}
-		return tokVariable, def
-	case *ast.FuncDecl:
-		return tokFunction, def
-	default:
-		msg := fmt.Sprintf("%T undexpected: %s %s%q", nd, x.Name, e.strStack(), e.srcLine(x))
-		e.unexpected(msg)
-	}
-	return "", nil
-}
-
-func isDeprecated(n *ast.CommentGroup) bool {
-	if n == nil {
-		return false
-	}
-	for _, c := range n.List {
-		if strings.HasPrefix(c.Text, "// Deprecated") {
-			return true
-		}
-	}
-	return false
-}
-
-func (e *encoded) definitionFor(x *ast.Ident, def types.Object) (tokenType, []string) {
-	// PJW: def == types.Label? probably a nothing
-	// PJW: look into replacing these syntactic tests with types more generally
-	mods := []string{"definition"}
-	for i := len(e.stack) - 1; i >= 0; i-- {
-		s := e.stack[i]
-		switch y := s.(type) {
-		case *ast.AssignStmt, *ast.RangeStmt:
-			if x.Name == "_" {
-				return "", nil // not really a variable
-			}
-			return tokVariable, mods
-		case *ast.GenDecl:
-			if isDeprecated(y.Doc) {
-				mods = append(mods, "deprecated")
-			}
-			if y.Tok == token.CONST {
-				mods = append(mods, "readonly")
-			}
-			return tokVariable, mods
-		case *ast.FuncDecl:
-			// If x is immediately under a FuncDecl, it is a function or method
-			if i == len(e.stack)-2 {
-				if isDeprecated(y.Doc) {
-					mods = append(mods, "deprecated")
-				}
-				if y.Recv != nil {
-					return tokMethod, mods
-				}
-				return tokFunction, mods
-			}
-			// if x < ... < FieldList < FuncDecl, this is the receiver, a variable
-			if _, ok := e.stack[i+1].(*ast.FieldList); ok {
-				return tokVariable, nil
-			}
-			// if x < ... < FieldList < FuncType < FuncDecl, this is a param
-			return tokParameter, mods
-		case *ast.FuncType: // is it in the TypeParams?
-			if isTypeParam(x, y) {
-				return tokTypeParam, mods
-			}
-			return tokParameter, mods
-		case *ast.InterfaceType:
-			return tokMethod, mods
-		case *ast.TypeSpec:
-			// GenDecl/Typespec/FuncType/FieldList/Field/Ident
-			// (type A func(b uint64)) (err error)
-			// b and err should not be tokType, but tokVaraible
-			// and in GenDecl/TpeSpec/StructType/FieldList/Field/Ident
-			// (type A struct{b uint64}
-			// but on type B struct{C}), C is a type, but is not being defined.
-			// GenDecl/TypeSpec/FieldList/Field/Ident is a typeParam
-			if _, ok := e.stack[i+1].(*ast.FieldList); ok {
-				return tokTypeParam, mods
-			}
-			fldm := e.stack[len(e.stack)-2]
-			if fld, ok := fldm.(*ast.Field); ok {
-				// if len(fld.names) == 0 this is a tokType, being used
-				if len(fld.Names) == 0 {
-					return tokType, nil
-				}
-				return tokVariable, mods
-			}
-			return tokType, mods
-		}
-	}
-	// can't happen
-	msg := fmt.Sprintf("failed to find the decl for %s", safetoken.Position(e.pgf.Tok, x.Pos()))
-	e.unexpected(msg)
-	return "", []string{""}
-}
-
-func isTypeParam(x *ast.Ident, y *ast.FuncType) bool {
-	tp := typeparams.ForFuncType(y)
-	if tp == nil {
-		return false
-	}
-	for _, p := range tp.List {
-		for _, n := range p.Names {
-			if x == n {
-				return true
-			}
-		}
-	}
-	return false
-}
-
-func (e *encoded) multiline(start, end token.Pos, val string, tok tokenType) {
-	f := e.fset.File(start)
-	// the hard part is finding the lengths of lines. include the \n
-	leng := func(line int) int {
-		n := f.LineStart(line)
-		if line >= f.LineCount() {
-			return f.Size() - int(n)
-		}
-		return int(f.LineStart(line+1) - n)
-	}
-	spos := safetoken.StartPosition(e.fset, start)
-	epos := safetoken.EndPosition(e.fset, end)
-	sline := spos.Line
-	eline := epos.Line
-	// first line is from spos.Column to end
-	e.token(start, leng(sline)-spos.Column, tok, nil) // leng(sline)-1 - (spos.Column-1)
-	for i := sline + 1; i < eline; i++ {
-		// intermediate lines are from 1 to end
-		e.token(f.LineStart(i), leng(i)-1, tok, nil) // avoid the newline
-	}
-	// last line is from 1 to epos.Column
-	e.token(f.LineStart(eline), epos.Column-1, tok, nil) // columns are 1-based
-}
-
-// findKeyword finds a keyword rather than guessing its location
-func (e *encoded) findKeyword(keyword string, start, end token.Pos) token.Pos {
-	offset := int(start) - e.pgf.Tok.Base()
-	last := int(end) - e.pgf.Tok.Base()
-	buf := e.pgf.Src
-	idx := bytes.Index(buf[offset:last], []byte(keyword))
-	if idx != -1 {
-		return start + token.Pos(idx)
-	}
-	//(in unparsable programs: type _ <-<-chan int)
-	e.unexpected(fmt.Sprintf("not found:%s %v", keyword, safetoken.StartPosition(e.fset, start)))
-	return token.NoPos
-}
-
-func (e *encoded) init() error {
-	e.start = token.Pos(e.pgf.Tok.Base())
-	e.end = e.start + token.Pos(e.pgf.Tok.Size())
-	if e.rng == nil {
-		return nil
-	}
-	span, err := e.pgf.Mapper.RangeSpan(*e.rng)
-	if err != nil {
-		return fmt.Errorf("range span (%w) error for %s", err, e.pgf.File.Name)
-	}
-	e.end = e.start + token.Pos(span.End().Offset())
-	e.start += token.Pos(span.Start().Offset())
-	return nil
-}
-
-func (e *encoded) Data() []uint32 {
-	// binary operators, at least, will be out of order
-	sort.Slice(e.items, func(i, j int) bool {
-		if e.items[i].line != e.items[j].line {
-			return e.items[i].line < e.items[j].line
-		}
-		return e.items[i].start < e.items[j].start
-	})
-	typeMap, modMap := e.maps()
-	// each semantic token needs five values
-	// (see Integer Encoding for Tokens in the LSP spec)
-	x := make([]uint32, 5*len(e.items))
-	var j int
-	var last semItem
-	for i := 0; i < len(e.items); i++ {
-		item := e.items[i]
-		typ, ok := typeMap[item.typeStr]
-		if !ok {
-			continue // client doesn't want typeStr
-		}
-		if item.typeStr == tokString && e.noStrings {
-			continue
-		}
-		if item.typeStr == tokNumber && e.noNumbers {
-			continue
-		}
-		if j == 0 {
-			x[0] = e.items[0].line
-		} else {
-			x[j] = item.line - last.line
-		}
-		x[j+1] = item.start
-		if j > 0 && x[j] == 0 {
-			x[j+1] = item.start - last.start
-		}
-		x[j+2] = item.len
-		x[j+3] = uint32(typ)
-		mask := 0
-		for _, s := range item.mods {
-			// modMap[s] is 0 if the client doesn't want this modifier
-			mask |= modMap[s]
-		}
-		x[j+4] = uint32(mask)
-		j += 5
-		last = item
-	}
-	return x[:j]
-}
-
-func (e *encoded) importSpec(d *ast.ImportSpec) {
-	// a local package name or the last component of the Path
-	if d.Name != nil {
-		nm := d.Name.String()
-		if nm != "_" && nm != "." {
-			e.token(d.Name.Pos(), len(nm), tokNamespace, nil)
-		}
-		return // don't mark anything for . or _
-	}
-	importPath := source.UnquoteImportPath(d)
-	if importPath == "" {
-		return
-	}
-	// Import strings are implementation defined. Try to match with parse information.
-	imported, err := e.pkg.ResolveImportPath(importPath)
-	if err != nil {
-		// unexpected, but impact is that maybe some import is not colored
-		return
-	}
-	// Check whether the original literal contains the package's declared name.
-	j := strings.LastIndex(d.Path.Value, string(imported.Name()))
-	if j == -1 {
-		// name doesn't show up, for whatever reason, so nothing to report
-		return
-	}
-	// Report virtual declaration at the position of the substring.
-	start := d.Path.Pos() + token.Pos(j)
-	e.token(start, len(imported.Name()), tokNamespace, nil)
-}
-
-// log unexpected state
-func (e *encoded) unexpected(msg string) {
-	if semDebug {
-		panic(msg)
-	}
-	event.Error(e.ctx, e.strStack(), errors.New(msg))
-}
-
-// SemType returns a string equivalent of the type, for gopls semtok
-func SemType(n int) string {
-	tokTypes := SemanticTypes()
-	tokMods := SemanticModifiers()
-	if n >= 0 && n < len(tokTypes) {
-		return tokTypes[n]
-	}
-	// not found for some reason
-	return fmt.Sprintf("?%d[%d,%d]?", n, len(tokTypes), len(tokMods))
-}
-
-// SemMods returns the []string equivalent of the mods, for gopls semtok.
-func SemMods(n int) []string {
-	tokMods := SemanticModifiers()
-	mods := []string{}
-	for i := 0; i < len(tokMods); i++ {
-		if (n & (1 << uint(i))) != 0 {
-			mods = append(mods, tokMods[i])
-		}
-	}
-	return mods
-}
-
-func (e *encoded) maps() (map[tokenType]int, map[string]int) {
-	tmap := make(map[tokenType]int)
-	mmap := make(map[string]int)
-	for i, t := range e.tokTypes {
-		tmap[tokenType(t)] = i
-	}
-	for i, m := range e.tokMods {
-		mmap[m] = 1 << uint(i) // go 1.12 compatibility
-	}
-	return tmap, mmap
-}
-
-// SemanticTypes to use in case there is no client, as in the command line, or tests
-func SemanticTypes() []string {
-	return semanticTypes[:]
-}
-
-// SemanticModifiers to use in case there is no client.
-func SemanticModifiers() []string {
-	return semanticModifiers[:]
-}
-
-var (
-	semanticTypes = [...]string{
-		"namespace", "type", "class", "enum", "interface",
-		"struct", "typeParameter", "parameter", "variable", "property", "enumMember",
-		"event", "function", "method", "macro", "keyword", "modifier", "comment",
-		"string", "number", "regexp", "operator",
-	}
-	semanticModifiers = [...]string{
-		"declaration", "definition", "readonly", "static",
-		"deprecated", "abstract", "async", "modification", "documentation", "defaultLibrary",
-	}
-)
diff -urN a/gopls/internal/lsp/server.go b/gopls/internal/lsp/server.go
--- a/gopls/internal/lsp/server.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/server.go	1969-12-31 16:00:00
@@ -1,169 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package lsp implements LSP for gopls.
-package lsp
-
-import (
-	"context"
-	"fmt"
-	"sync"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/progress"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/jsonrpc2"
-)
-
-const concurrentAnalyses = 1
-
-// NewServer creates an LSP server and binds it to handle incoming client
-// messages on on the supplied stream.
-func NewServer(session *cache.Session, client protocol.ClientCloser) *Server {
-	return &Server{
-		diagnostics:           map[span.URI]*fileReports{},
-		gcOptimizationDetails: make(map[source.PackageID]struct{}),
-		watchedGlobPatterns:   make(map[string]struct{}),
-		changedFiles:          make(map[span.URI]struct{}),
-		session:               session,
-		client:                client,
-		diagnosticsSema:       make(chan struct{}, concurrentAnalyses),
-		progress:              progress.NewTracker(client),
-		diagDebouncer:         newDebouncer(),
-		watchedFileDebouncer:  newDebouncer(),
-	}
-}
-
-type serverState int
-
-const (
-	serverCreated      = serverState(iota)
-	serverInitializing // set once the server has received "initialize" request
-	serverInitialized  // set once the server has received "initialized" request
-	serverShutDown
-)
-
-func (s serverState) String() string {
-	switch s {
-	case serverCreated:
-		return "created"
-	case serverInitializing:
-		return "initializing"
-	case serverInitialized:
-		return "initialized"
-	case serverShutDown:
-		return "shutDown"
-	}
-	return fmt.Sprintf("(unknown state: %d)", int(s))
-}
-
-// Server implements the protocol.Server interface.
-type Server struct {
-	client protocol.ClientCloser
-
-	stateMu sync.Mutex
-	state   serverState
-	// notifications generated before serverInitialized
-	notifications []*protocol.ShowMessageParams
-
-	session *cache.Session
-
-	tempDir string
-
-	// changedFiles tracks files for which there has been a textDocument/didChange.
-	changedFilesMu sync.Mutex
-	changedFiles   map[span.URI]struct{}
-
-	// folders is only valid between initialize and initialized, and holds the
-	// set of folders to build views for when we are ready
-	pendingFolders []protocol.WorkspaceFolder
-
-	// watchedGlobPatterns is the set of glob patterns that we have requested
-	// the client watch on disk. It will be updated as the set of directories
-	// that the server should watch changes.
-	watchedGlobPatternsMu  sync.Mutex
-	watchedGlobPatterns    map[string]struct{}
-	watchRegistrationCount int
-
-	diagnosticsMu sync.Mutex
-	diagnostics   map[span.URI]*fileReports
-
-	// gcOptimizationDetails describes the packages for which we want
-	// optimization details to be included in the diagnostics. The key is the
-	// ID of the package.
-	gcOptimizationDetailsMu sync.Mutex
-	gcOptimizationDetails   map[source.PackageID]struct{}
-
-	// diagnosticsSema limits the concurrency of diagnostics runs, which can be
-	// expensive.
-	diagnosticsSema chan struct{}
-
-	progress *progress.Tracker
-
-	// diagDebouncer is used for debouncing diagnostics.
-	diagDebouncer *debouncer
-
-	// watchedFileDebouncer is used for batching didChangeWatchedFiles notifications.
-	watchedFileDebouncer *debouncer
-	fileChangeMu         sync.Mutex
-	pendingOnDiskChanges []*pendingModificationSet
-
-	// When the workspace fails to load, we show its status through a progress
-	// report with an error message.
-	criticalErrorStatusMu sync.Mutex
-	criticalErrorStatus   *progress.WorkDone
-}
-
-type pendingModificationSet struct {
-	diagnoseDone chan struct{}
-	changes      []source.FileModification
-}
-
-func (s *Server) workDoneProgressCancel(ctx context.Context, params *protocol.WorkDoneProgressCancelParams) error {
-	return s.progress.Cancel(params.Token)
-}
-
-func (s *Server) nonstandardRequest(ctx context.Context, method string, params interface{}) (interface{}, error) {
-	switch method {
-	case "gopls/diagnoseFiles":
-		paramMap := params.(map[string]interface{})
-		// TODO(adonovan): opt: parallelize FileDiagnostics(URI...), either
-		// by calling it in multiple goroutines or, better, by making
-		// the relevant APIs accept a set of URIs/packages.
-		for _, file := range paramMap["files"].([]interface{}) {
-			snapshot, fh, ok, release, err := s.beginFileRequest(ctx, protocol.DocumentURI(file.(string)), source.UnknownKind)
-			defer release()
-			if !ok {
-				return nil, err
-			}
-
-			fileID, diagnostics, err := source.FileDiagnostics(ctx, snapshot, fh.URI())
-			if err != nil {
-				return nil, err
-			}
-			if err := s.client.PublishDiagnostics(ctx, &protocol.PublishDiagnosticsParams{
-				URI:         protocol.URIFromSpanURI(fh.URI()),
-				Diagnostics: toProtocolDiagnostics(diagnostics),
-				Version:     fileID.Version,
-			}); err != nil {
-				return nil, err
-			}
-		}
-		if err := s.client.PublishDiagnostics(ctx, &protocol.PublishDiagnosticsParams{
-			URI: "gopls://diagnostics-done",
-		}); err != nil {
-			return nil, err
-		}
-		return struct{}{}, nil
-	}
-	return nil, notImplemented(method)
-}
-
-func notImplemented(method string) error {
-	return fmt.Errorf("%w: %q not yet implemented", jsonrpc2.ErrMethodNotFound, method)
-}
-
-//go:generate helper/helper -d protocol/tsserver.go -o server_gen.go -u .
diff -urN a/gopls/internal/lsp/server_gen.go b/gopls/internal/lsp/server_gen.go
--- a/gopls/internal/lsp/server_gen.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/server_gen.go	1969-12-31 16:00:00
@@ -1,317 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-// code generated by helper. DO NOT EDIT.
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func (s *Server) CodeAction(ctx context.Context, params *protocol.CodeActionParams) ([]protocol.CodeAction, error) {
-	return s.codeAction(ctx, params)
-}
-
-func (s *Server) CodeLens(ctx context.Context, params *protocol.CodeLensParams) ([]protocol.CodeLens, error) {
-	return s.codeLens(ctx, params)
-}
-
-func (s *Server) ColorPresentation(context.Context, *protocol.ColorPresentationParams) ([]protocol.ColorPresentation, error) {
-	return nil, notImplemented("ColorPresentation")
-}
-
-func (s *Server) Completion(ctx context.Context, params *protocol.CompletionParams) (*protocol.CompletionList, error) {
-	return s.completion(ctx, params)
-}
-
-func (s *Server) Declaration(context.Context, *protocol.DeclarationParams) (*protocol.Or_textDocument_declaration, error) {
-	return nil, notImplemented("Declaration")
-}
-
-func (s *Server) Definition(ctx context.Context, params *protocol.DefinitionParams) ([]protocol.Location, error) {
-	return s.definition(ctx, params)
-}
-
-func (s *Server) Diagnostic(context.Context, *string) (*string, error) {
-	return nil, notImplemented("Diagnostic")
-}
-
-func (s *Server) DiagnosticRefresh(context.Context) error {
-	return notImplemented("DiagnosticRefresh")
-}
-
-func (s *Server) DiagnosticWorkspace(context.Context, *protocol.WorkspaceDiagnosticParams) (*protocol.WorkspaceDiagnosticReport, error) {
-	return nil, notImplemented("DiagnosticWorkspace")
-}
-
-func (s *Server) DidChange(ctx context.Context, params *protocol.DidChangeTextDocumentParams) error {
-	return s.didChange(ctx, params)
-}
-
-func (s *Server) DidChangeConfiguration(ctx context.Context, _gen *protocol.DidChangeConfigurationParams) error {
-	return s.didChangeConfiguration(ctx, _gen)
-}
-
-func (s *Server) DidChangeNotebookDocument(context.Context, *protocol.DidChangeNotebookDocumentParams) error {
-	return notImplemented("DidChangeNotebookDocument")
-}
-
-func (s *Server) DidChangeWatchedFiles(ctx context.Context, params *protocol.DidChangeWatchedFilesParams) error {
-	return s.didChangeWatchedFiles(ctx, params)
-}
-
-func (s *Server) DidChangeWorkspaceFolders(ctx context.Context, params *protocol.DidChangeWorkspaceFoldersParams) error {
-	return s.didChangeWorkspaceFolders(ctx, params)
-}
-
-func (s *Server) DidClose(ctx context.Context, params *protocol.DidCloseTextDocumentParams) error {
-	return s.didClose(ctx, params)
-}
-
-func (s *Server) DidCloseNotebookDocument(context.Context, *protocol.DidCloseNotebookDocumentParams) error {
-	return notImplemented("DidCloseNotebookDocument")
-}
-
-func (s *Server) DidCreateFiles(context.Context, *protocol.CreateFilesParams) error {
-	return notImplemented("DidCreateFiles")
-}
-
-func (s *Server) DidDeleteFiles(context.Context, *protocol.DeleteFilesParams) error {
-	return notImplemented("DidDeleteFiles")
-}
-
-func (s *Server) DidOpen(ctx context.Context, params *protocol.DidOpenTextDocumentParams) error {
-	return s.didOpen(ctx, params)
-}
-
-func (s *Server) DidOpenNotebookDocument(context.Context, *protocol.DidOpenNotebookDocumentParams) error {
-	return notImplemented("DidOpenNotebookDocument")
-}
-
-func (s *Server) DidRenameFiles(context.Context, *protocol.RenameFilesParams) error {
-	return notImplemented("DidRenameFiles")
-}
-
-func (s *Server) DidSave(ctx context.Context, params *protocol.DidSaveTextDocumentParams) error {
-	return s.didSave(ctx, params)
-}
-
-func (s *Server) DidSaveNotebookDocument(context.Context, *protocol.DidSaveNotebookDocumentParams) error {
-	return notImplemented("DidSaveNotebookDocument")
-}
-
-func (s *Server) DocumentColor(context.Context, *protocol.DocumentColorParams) ([]protocol.ColorInformation, error) {
-	return nil, notImplemented("DocumentColor")
-}
-
-func (s *Server) DocumentHighlight(ctx context.Context, params *protocol.DocumentHighlightParams) ([]protocol.DocumentHighlight, error) {
-	return s.documentHighlight(ctx, params)
-}
-
-func (s *Server) DocumentLink(ctx context.Context, params *protocol.DocumentLinkParams) ([]protocol.DocumentLink, error) {
-	return s.documentLink(ctx, params)
-}
-
-func (s *Server) DocumentSymbol(ctx context.Context, params *protocol.DocumentSymbolParams) ([]interface{}, error) {
-	return s.documentSymbol(ctx, params)
-}
-
-func (s *Server) ExecuteCommand(ctx context.Context, params *protocol.ExecuteCommandParams) (interface{}, error) {
-	return s.executeCommand(ctx, params)
-}
-
-func (s *Server) Exit(ctx context.Context) error {
-	return s.exit(ctx)
-}
-
-func (s *Server) FoldingRange(ctx context.Context, params *protocol.FoldingRangeParams) ([]protocol.FoldingRange, error) {
-	return s.foldingRange(ctx, params)
-}
-
-func (s *Server) Formatting(ctx context.Context, params *protocol.DocumentFormattingParams) ([]protocol.TextEdit, error) {
-	return s.formatting(ctx, params)
-}
-
-func (s *Server) Hover(ctx context.Context, params *protocol.HoverParams) (*protocol.Hover, error) {
-	return s.hover(ctx, params)
-}
-
-func (s *Server) Implementation(ctx context.Context, params *protocol.ImplementationParams) ([]protocol.Location, error) {
-	return s.implementation(ctx, params)
-}
-
-func (s *Server) IncomingCalls(ctx context.Context, params *protocol.CallHierarchyIncomingCallsParams) ([]protocol.CallHierarchyIncomingCall, error) {
-	return s.incomingCalls(ctx, params)
-}
-
-func (s *Server) Initialize(ctx context.Context, params *protocol.ParamInitialize) (*protocol.InitializeResult, error) {
-	return s.initialize(ctx, params)
-}
-
-func (s *Server) Initialized(ctx context.Context, params *protocol.InitializedParams) error {
-	return s.initialized(ctx, params)
-}
-
-func (s *Server) InlayHint(ctx context.Context, params *protocol.InlayHintParams) ([]protocol.InlayHint, error) {
-	return s.inlayHint(ctx, params)
-}
-
-func (s *Server) InlayHintRefresh(context.Context) error {
-	return notImplemented("InlayHintRefresh")
-}
-
-func (s *Server) InlineValue(context.Context, *protocol.InlineValueParams) ([]protocol.InlineValue, error) {
-	return nil, notImplemented("InlineValue")
-}
-
-func (s *Server) InlineValueRefresh(context.Context) error {
-	return notImplemented("InlineValueRefresh")
-}
-
-func (s *Server) LinkedEditingRange(context.Context, *protocol.LinkedEditingRangeParams) (*protocol.LinkedEditingRanges, error) {
-	return nil, notImplemented("LinkedEditingRange")
-}
-
-func (s *Server) Moniker(context.Context, *protocol.MonikerParams) ([]protocol.Moniker, error) {
-	return nil, notImplemented("Moniker")
-}
-
-func (s *Server) NonstandardRequest(ctx context.Context, method string, params interface{}) (interface{}, error) {
-	return s.nonstandardRequest(ctx, method, params)
-}
-
-func (s *Server) OnTypeFormatting(context.Context, *protocol.DocumentOnTypeFormattingParams) ([]protocol.TextEdit, error) {
-	return nil, notImplemented("OnTypeFormatting")
-}
-
-func (s *Server) OutgoingCalls(ctx context.Context, params *protocol.CallHierarchyOutgoingCallsParams) ([]protocol.CallHierarchyOutgoingCall, error) {
-	return s.outgoingCalls(ctx, params)
-}
-
-func (s *Server) PrepareCallHierarchy(ctx context.Context, params *protocol.CallHierarchyPrepareParams) ([]protocol.CallHierarchyItem, error) {
-	return s.prepareCallHierarchy(ctx, params)
-}
-
-func (s *Server) PrepareRename(ctx context.Context, params *protocol.PrepareRenameParams) (*protocol.PrepareRename2Gn, error) {
-	return s.prepareRename(ctx, params)
-}
-
-func (s *Server) PrepareTypeHierarchy(context.Context, *protocol.TypeHierarchyPrepareParams) ([]protocol.TypeHierarchyItem, error) {
-	return nil, notImplemented("PrepareTypeHierarchy")
-}
-
-func (s *Server) Progress(context.Context, *protocol.ProgressParams) error {
-	return notImplemented("Progress")
-}
-
-func (s *Server) RangeFormatting(context.Context, *protocol.DocumentRangeFormattingParams) ([]protocol.TextEdit, error) {
-	return nil, notImplemented("RangeFormatting")
-}
-
-func (s *Server) References(ctx context.Context, params *protocol.ReferenceParams) ([]protocol.Location, error) {
-	return s.references(ctx, params)
-}
-
-func (s *Server) Rename(ctx context.Context, params *protocol.RenameParams) (*protocol.WorkspaceEdit, error) {
-	return s.rename(ctx, params)
-}
-
-func (s *Server) Resolve(context.Context, *protocol.InlayHint) (*protocol.InlayHint, error) {
-	return nil, notImplemented("Resolve")
-}
-
-func (s *Server) ResolveCodeAction(context.Context, *protocol.CodeAction) (*protocol.CodeAction, error) {
-	return nil, notImplemented("ResolveCodeAction")
-}
-
-func (s *Server) ResolveCodeLens(context.Context, *protocol.CodeLens) (*protocol.CodeLens, error) {
-	return nil, notImplemented("ResolveCodeLens")
-}
-
-func (s *Server) ResolveCompletionItem(context.Context, *protocol.CompletionItem) (*protocol.CompletionItem, error) {
-	return nil, notImplemented("ResolveCompletionItem")
-}
-
-func (s *Server) ResolveDocumentLink(context.Context, *protocol.DocumentLink) (*protocol.DocumentLink, error) {
-	return nil, notImplemented("ResolveDocumentLink")
-}
-
-func (s *Server) ResolveWorkspaceSymbol(context.Context, *protocol.WorkspaceSymbol) (*protocol.WorkspaceSymbol, error) {
-	return nil, notImplemented("ResolveWorkspaceSymbol")
-}
-
-func (s *Server) SelectionRange(ctx context.Context, params *protocol.SelectionRangeParams) ([]protocol.SelectionRange, error) {
-	return s.selectionRange(ctx, params)
-}
-
-func (s *Server) SemanticTokensFull(ctx context.Context, p *protocol.SemanticTokensParams) (*protocol.SemanticTokens, error) {
-	return s.semanticTokensFull(ctx, p)
-}
-
-func (s *Server) SemanticTokensFullDelta(ctx context.Context, p *protocol.SemanticTokensDeltaParams) (interface{}, error) {
-	return s.semanticTokensFullDelta(ctx, p)
-}
-
-func (s *Server) SemanticTokensRange(ctx context.Context, p *protocol.SemanticTokensRangeParams) (*protocol.SemanticTokens, error) {
-	return s.semanticTokensRange(ctx, p)
-}
-
-func (s *Server) SemanticTokensRefresh(ctx context.Context) error {
-	return s.semanticTokensRefresh(ctx)
-}
-
-func (s *Server) SetTrace(context.Context, *protocol.SetTraceParams) error {
-	return notImplemented("SetTrace")
-}
-
-func (s *Server) Shutdown(ctx context.Context) error {
-	return s.shutdown(ctx)
-}
-
-func (s *Server) SignatureHelp(ctx context.Context, params *protocol.SignatureHelpParams) (*protocol.SignatureHelp, error) {
-	return s.signatureHelp(ctx, params)
-}
-
-func (s *Server) Subtypes(context.Context, *protocol.TypeHierarchySubtypesParams) ([]protocol.TypeHierarchyItem, error) {
-	return nil, notImplemented("Subtypes")
-}
-
-func (s *Server) Supertypes(context.Context, *protocol.TypeHierarchySupertypesParams) ([]protocol.TypeHierarchyItem, error) {
-	return nil, notImplemented("Supertypes")
-}
-
-func (s *Server) Symbol(ctx context.Context, params *protocol.WorkspaceSymbolParams) ([]protocol.SymbolInformation, error) {
-	return s.symbol(ctx, params)
-}
-
-func (s *Server) TypeDefinition(ctx context.Context, params *protocol.TypeDefinitionParams) ([]protocol.Location, error) {
-	return s.typeDefinition(ctx, params)
-}
-
-func (s *Server) WillCreateFiles(context.Context, *protocol.CreateFilesParams) (*protocol.WorkspaceEdit, error) {
-	return nil, notImplemented("WillCreateFiles")
-}
-
-func (s *Server) WillDeleteFiles(context.Context, *protocol.DeleteFilesParams) (*protocol.WorkspaceEdit, error) {
-	return nil, notImplemented("WillDeleteFiles")
-}
-
-func (s *Server) WillRenameFiles(context.Context, *protocol.RenameFilesParams) (*protocol.WorkspaceEdit, error) {
-	return nil, notImplemented("WillRenameFiles")
-}
-
-func (s *Server) WillSave(context.Context, *protocol.WillSaveTextDocumentParams) error {
-	return notImplemented("WillSave")
-}
-
-func (s *Server) WillSaveWaitUntil(context.Context, *protocol.WillSaveTextDocumentParams) ([]protocol.TextEdit, error) {
-	return nil, notImplemented("WillSaveWaitUntil")
-}
-
-func (s *Server) WorkDoneProgressCancel(ctx context.Context, params *protocol.WorkDoneProgressCancelParams) error {
-	return s.workDoneProgressCancel(ctx, params)
-}
diff -urN a/gopls/internal/lsp/signature_help.go b/gopls/internal/lsp/signature_help.go
--- a/gopls/internal/lsp/signature_help.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/signature_help.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func (s *Server) signatureHelp(ctx context.Context, params *protocol.SignatureHelpParams) (*protocol.SignatureHelp, error) {
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.Go)
-	defer release()
-	if !ok {
-		return nil, err
-	}
-	info, activeParameter, err := source.SignatureHelp(ctx, snapshot, fh, params.Position)
-	if err != nil {
-		event.Error(ctx, "no signature help", err, tag.Position.Of(params.Position))
-		return nil, nil
-	}
-	return &protocol.SignatureHelp{
-		Signatures:      []protocol.SignatureInformation{*info},
-		ActiveParameter: uint32(activeParameter),
-	}, nil
-}
diff -urN a/gopls/internal/lsp/snippet/snippet_builder.go b/gopls/internal/lsp/snippet/snippet_builder.go
--- a/gopls/internal/lsp/snippet/snippet_builder.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/snippet/snippet_builder.go	1969-12-31 16:00:00
@@ -1,111 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package snippet implements the specification for the LSP snippet format.
-//
-// Snippets are "tab stop" templates returned as an optional attribute of LSP
-// completion candidates. As the user presses tab, they cycle through a series of
-// tab stops defined in the snippet. Each tab stop can optionally have placeholder
-// text, which can be pre-selected by editors. For a full description of syntax
-// and features, see "Snippet Syntax" at
-// https://microsoft.github.io/language-server-protocol/specifications/specification-3-14/#textDocument_completion.
-//
-// A typical snippet looks like "foo(${1:i int}, ${2:s string})".
-package snippet
-
-import (
-	"fmt"
-	"strings"
-)
-
-// A Builder is used to build an LSP snippet piecemeal.
-// The zero value is ready to use. Do not copy a non-zero Builder.
-type Builder struct {
-	// currentTabStop is the index of the previous tab stop. The
-	// next tab stop will be currentTabStop+1.
-	currentTabStop int
-	sb             strings.Builder
-}
-
-// Escape characters defined in https://microsoft.github.io/language-server-protocol/specifications/specification-3-14/#textDocument_completion under "Grammar".
-var replacer = strings.NewReplacer(
-	`\`, `\\`,
-	`}`, `\}`,
-	`$`, `\$`,
-)
-
-func (b *Builder) WriteText(s string) {
-	replacer.WriteString(&b.sb, s)
-}
-
-func (b *Builder) PrependText(s string) {
-	rawSnip := b.String()
-	b.sb.Reset()
-	b.WriteText(s)
-	b.sb.WriteString(rawSnip)
-}
-
-func (b *Builder) Write(data []byte) (int, error) {
-	return b.sb.Write(data)
-}
-
-// WritePlaceholder writes a tab stop and placeholder value to the Builder.
-// The callback style allows for creating nested placeholders. To write an
-// empty tab stop, provide a nil callback.
-func (b *Builder) WritePlaceholder(fn func(*Builder)) {
-	fmt.Fprintf(&b.sb, "${%d:", b.nextTabStop())
-	if fn != nil {
-		fn(b)
-	}
-	b.sb.WriteByte('}')
-}
-
-// WriteFinalTabstop marks where cursor ends up after the user has
-// cycled through all the normal tab stops. It defaults to the
-// character after the snippet.
-func (b *Builder) WriteFinalTabstop() {
-	fmt.Fprint(&b.sb, "$0")
-}
-
-// In addition to '\', '}', and '$', snippet choices also use '|' and ',' as
-// meta characters, so they must be escaped within the choices.
-var choiceReplacer = strings.NewReplacer(
-	`\`, `\\`,
-	`}`, `\}`,
-	`$`, `\$`,
-	`|`, `\|`,
-	`,`, `\,`,
-)
-
-// WriteChoice writes a tab stop and list of text choices to the Builder.
-// The user's editor will prompt the user to choose one of the choices.
-func (b *Builder) WriteChoice(choices []string) {
-	fmt.Fprintf(&b.sb, "${%d|", b.nextTabStop())
-	for i, c := range choices {
-		if i != 0 {
-			b.sb.WriteByte(',')
-		}
-		choiceReplacer.WriteString(&b.sb, c)
-	}
-	b.sb.WriteString("|}")
-}
-
-// String returns the built snippet string.
-func (b *Builder) String() string {
-	return b.sb.String()
-}
-
-// Clone returns a copy of b.
-func (b *Builder) Clone() *Builder {
-	var clone Builder
-	clone.sb.WriteString(b.String())
-	return &clone
-}
-
-// nextTabStop returns the next tab stop index for a new placeholder.
-func (b *Builder) nextTabStop() int {
-	// Tab stops start from 1, so increment before returning.
-	b.currentTabStop++
-	return b.currentTabStop
-}
diff -urN a/gopls/internal/lsp/snippet/snippet_builder_test.go b/gopls/internal/lsp/snippet/snippet_builder_test.go
--- a/gopls/internal/lsp/snippet/snippet_builder_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/snippet/snippet_builder_test.go	1969-12-31 16:00:00
@@ -1,62 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package snippet
-
-import (
-	"testing"
-)
-
-func TestSnippetBuilder(t *testing.T) {
-	expect := func(expected string, fn func(*Builder)) {
-		t.Helper()
-
-		var b Builder
-		fn(&b)
-		if got := b.String(); got != expected {
-			t.Errorf("got %q, expected %q", got, expected)
-		}
-	}
-
-	expect("", func(b *Builder) {})
-
-	expect(`hi { \} \$ | " , / \\`, func(b *Builder) {
-		b.WriteText(`hi { } $ | " , / \`)
-	})
-
-	expect("${1:}", func(b *Builder) {
-		b.WritePlaceholder(nil)
-	})
-
-	expect("hi ${1:there}", func(b *Builder) {
-		b.WriteText("hi ")
-		b.WritePlaceholder(func(b *Builder) {
-			b.WriteText("there")
-		})
-	})
-
-	expect(`${1:id=${2:{your id\}}}`, func(b *Builder) {
-		b.WritePlaceholder(func(b *Builder) {
-			b.WriteText("id=")
-			b.WritePlaceholder(func(b *Builder) {
-				b.WriteText("{your id}")
-			})
-		})
-	})
-
-	expect(`${1|one,{ \} \$ \| " \, / \\,three|}`, func(b *Builder) {
-		b.WriteChoice([]string{"one", `{ } $ | " , / \`, "three"})
-	})
-
-	expect("$0 hello", func(b *Builder) {
-		b.WriteFinalTabstop()
-		b.WriteText(" hello")
-	})
-
-	expect(`prepended \$5 ${1:} hello`, func(b *Builder) {
-		b.WritePlaceholder(nil)
-		b.WriteText(" hello")
-		b.PrependText("prepended $5 ")
-	})
-}
diff -urN a/gopls/internal/lsp/source/add_import.go b/gopls/internal/lsp/source/add_import.go
--- a/gopls/internal/lsp/source/add_import.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/add_import.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/imports"
-)
-
-// AddImport adds a single import statement to the given file
-func AddImport(ctx context.Context, snapshot Snapshot, fh VersionedFileHandle, importPath string) ([]protocol.TextEdit, error) {
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, err
-	}
-	return ComputeOneImportFixEdits(snapshot, pgf, &imports.ImportFix{
-		StmtInfo: imports.ImportInfo{
-			ImportPath: importPath,
-		},
-		FixType: imports.AddImport,
-	})
-}
diff -urN a/gopls/internal/lsp/source/api_json.go b/gopls/internal/lsp/source/api_json.go
--- a/gopls/internal/lsp/source/api_json.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/api_json.go	1969-12-31 16:00:00
@@ -1,1132 +0,0 @@
-// Code generated by "golang.org/x/tools/gopls/doc/generate"; DO NOT EDIT.
-
-package source
-
-var GeneratedAPIJSON = &APIJSON{
-	Options: map[string][]*OptionJSON{
-		"User": {
-			{
-				Name:      "buildFlags",
-				Type:      "[]string",
-				Doc:       "buildFlags is the set of flags passed on to the build system when invoked.\nIt is applied to queries like `go list`, which is used when discovering files.\nThe most common use is to set `-tags`.\n",
-				Default:   "[]",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "env",
-				Type:      "map[string]string",
-				Doc:       "env adds environment variables to external commands run by `gopls`, most notably `go list`.\n",
-				Default:   "{}",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "directoryFilters",
-				Type:      "[]string",
-				Doc:       "directoryFilters can be used to exclude unwanted directories from the\nworkspace. By default, all directories are included. Filters are an\noperator, `+` to include and `-` to exclude, followed by a path prefix\nrelative to the workspace folder. They are evaluated in order, and\nthe last filter that applies to a path controls whether it is included.\nThe path prefix can be empty, so an initial `-` excludes everything.\n\nDirectoryFilters also supports the `**` operator to match 0 or more directories.\n\nExamples:\n\nExclude node_modules at current depth: `-node_modules`\n\nExclude node_modules at any depth: `-**/node_modules`\n\nInclude only project_a: `-` (exclude everything), `+project_a`\n\nInclude only project_a, but not node_modules inside it: `-`, `+project_a`, `-project_a/node_modules`\n",
-				Default:   "[\"-**/node_modules\"]",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "templateExtensions",
-				Type:      "[]string",
-				Doc:       "templateExtensions gives the extensions of file names that are treateed\nas template files. (The extension\nis the part of the file name after the final dot.)\n",
-				Default:   "[]",
-				Hierarchy: "build",
-			},
-			{
-				Name: "memoryMode",
-				Type: "enum",
-				Doc:  "memoryMode controls the tradeoff `gopls` makes between memory usage and\ncorrectness.\n\nValues other than `Normal` are untested and may break in surprising ways.\n",
-				EnumValues: []EnumValue{
-					{
-						Value: "\"DegradeClosed\"",
-						Doc:   "`\"DegradeClosed\"`: In DegradeClosed mode, `gopls` will collect less information about\npackages without open files. As a result, features like Find\nReferences and Rename will miss results in such packages.\n",
-					},
-					{Value: "\"Normal\""},
-				},
-				Default:   "\"Normal\"",
-				Status:    "experimental",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "expandWorkspaceToModule",
-				Type:      "bool",
-				Doc:       "expandWorkspaceToModule instructs `gopls` to adjust the scope of the\nworkspace to find the best available module root. `gopls` first looks for\na go.mod file in any parent directory of the workspace folder, expanding\nthe scope to that directory if it exists. If no viable parent directory is\nfound, gopls will check if there is exactly one child directory containing\na go.mod file, narrowing the scope to that directory if it exists.\n",
-				Default:   "true",
-				Status:    "experimental",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "experimentalWorkspaceModule",
-				Type:      "bool",
-				Doc:       "experimentalWorkspaceModule opts a user into the experimental support\nfor multi-module workspaces.\n\nDeprecated: this feature is deprecated and will be removed in a future\nversion of gopls (https://go.dev/issue/55331).\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "experimentalPackageCacheKey",
-				Type:      "bool",
-				Doc:       "experimentalPackageCacheKey controls whether to use a coarser cache key\nfor package type information to increase cache hits. This setting removes\nthe user's environment, build flags, and working directory from the cache\nkey, which should be a safe change as all relevant inputs into the type\nchecking pass are already hashed into the key. This is temporarily guarded\nby an experiment because caching behavior is subtle and difficult to\ncomprehensively test.\n",
-				Default:   "true",
-				Status:    "experimental",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "allowModfileModifications",
-				Type:      "bool",
-				Doc:       "allowModfileModifications disables -mod=readonly, allowing imports from\nout-of-scope modules. This option will eventually be removed.\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "allowImplicitNetworkAccess",
-				Type:      "bool",
-				Doc:       "allowImplicitNetworkAccess disables GOPROXY=off, allowing implicit module\ndownloads rather than requiring user action. This option will eventually\nbe removed.\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "build",
-			},
-			{
-				Name:      "standaloneTags",
-				Type:      "[]string",
-				Doc:       "standaloneTags specifies a set of build constraints that identify\nindividual Go source files that make up the entire main package of an\nexecutable.\n\nA common example of standalone main files is the convention of using the\ndirective `//go:build ignore` to denote files that are not intended to be\nincluded in any package, for example because they are invoked directly by\nthe developer using `go run`.\n\nGopls considers a file to be a standalone main file if and only if it has\npackage name \"main\" and has a build directive of the exact form\n\"//go:build tag\" or \"// +build tag\", where tag is among the list of tags\nconfigured by this setting. Notably, if the build constraint is more\ncomplicated than a simple tag (such as the composite constraint\n`//go:build tag && go1.18`), the file is not considered to be a standalone\nmain file.\n\nThis setting is only supported when gopls is built with Go 1.16 or later.\n",
-				Default:   "[\"ignore\"]",
-				Hierarchy: "build",
-			},
-			{
-				Name: "hoverKind",
-				Type: "enum",
-				Doc:  "hoverKind controls the information that appears in the hover text.\nSingleLine and Structured are intended for use only by authors of editor plugins.\n",
-				EnumValues: []EnumValue{
-					{Value: "\"FullDocumentation\""},
-					{Value: "\"NoDocumentation\""},
-					{Value: "\"SingleLine\""},
-					{
-						Value: "\"Structured\"",
-						Doc:   "`\"Structured\"` is an experimental setting that returns a structured hover format.\nThis format separates the signature from the documentation, so that the client\ncan do more manipulation of these fields.\n\nThis should only be used by clients that support this behavior.\n",
-					},
-					{Value: "\"SynopsisDocumentation\""},
-				},
-				Default:   "\"FullDocumentation\"",
-				Hierarchy: "ui.documentation",
-			},
-			{
-				Name:      "linkTarget",
-				Type:      "string",
-				Doc:       "linkTarget controls where documentation links go.\nIt might be one of:\n\n* `\"godoc.org\"`\n* `\"pkg.go.dev\"`\n\nIf company chooses to use its own `godoc.org`, its address can be used as well.\n\nModules matching the GOPRIVATE environment variable will not have\ndocumentation links in hover.\n",
-				Default:   "\"pkg.go.dev\"",
-				Hierarchy: "ui.documentation",
-			},
-			{
-				Name:      "linksInHover",
-				Type:      "bool",
-				Doc:       "linksInHover toggles the presence of links to documentation in hover.\n",
-				Default:   "true",
-				Hierarchy: "ui.documentation",
-			},
-			{
-				Name:      "usePlaceholders",
-				Type:      "bool",
-				Doc:       "placeholders enables placeholders for function parameters or struct\nfields in completion responses.\n",
-				Default:   "false",
-				Hierarchy: "ui.completion",
-			},
-			{
-				Name:      "completionBudget",
-				Type:      "time.Duration",
-				Doc:       "completionBudget is the soft latency goal for completion requests. Most\nrequests finish in a couple milliseconds, but in some cases deep\ncompletions can take much longer. As we use up our budget we\ndynamically reduce the search scope to ensure we return timely\nresults. Zero means unlimited.\n",
-				Default:   "\"100ms\"",
-				Status:    "debug",
-				Hierarchy: "ui.completion",
-			},
-			{
-				Name: "matcher",
-				Type: "enum",
-				Doc:  "matcher sets the algorithm that is used when calculating completion\ncandidates.\n",
-				EnumValues: []EnumValue{
-					{Value: "\"CaseInsensitive\""},
-					{Value: "\"CaseSensitive\""},
-					{Value: "\"Fuzzy\""},
-				},
-				Default:   "\"Fuzzy\"",
-				Status:    "advanced",
-				Hierarchy: "ui.completion",
-			},
-			{
-				Name:      "experimentalPostfixCompletions",
-				Type:      "bool",
-				Doc:       "experimentalPostfixCompletions enables artificial method snippets\nsuch as \"someSlice.sort!\".\n",
-				Default:   "true",
-				Status:    "experimental",
-				Hierarchy: "ui.completion",
-			},
-			{
-				Name: "importShortcut",
-				Type: "enum",
-				Doc:  "importShortcut specifies whether import statements should link to\ndocumentation or go to definitions.\n",
-				EnumValues: []EnumValue{
-					{Value: "\"Both\""},
-					{Value: "\"Definition\""},
-					{Value: "\"Link\""},
-				},
-				Default:   "\"Both\"",
-				Hierarchy: "ui.navigation",
-			},
-			{
-				Name: "symbolMatcher",
-				Type: "enum",
-				Doc:  "symbolMatcher sets the algorithm that is used when finding workspace symbols.\n",
-				EnumValues: []EnumValue{
-					{Value: "\"CaseInsensitive\""},
-					{Value: "\"CaseSensitive\""},
-					{Value: "\"FastFuzzy\""},
-					{Value: "\"Fuzzy\""},
-				},
-				Default:   "\"FastFuzzy\"",
-				Status:    "advanced",
-				Hierarchy: "ui.navigation",
-			},
-			{
-				Name: "symbolStyle",
-				Type: "enum",
-				Doc:  "symbolStyle controls how symbols are qualified in symbol responses.\n\nExample Usage:\n\n```json5\n\"gopls\": {\n...\n  \"symbolStyle\": \"Dynamic\",\n...\n}\n```\n",
-				EnumValues: []EnumValue{
-					{
-						Value: "\"Dynamic\"",
-						Doc:   "`\"Dynamic\"` uses whichever qualifier results in the highest scoring\nmatch for the given symbol query. Here a \"qualifier\" is any \"/\" or \".\"\ndelimited suffix of the fully qualified symbol. i.e. \"to/pkg.Foo.Field\" or\njust \"Foo.Field\".\n",
-					},
-					{
-						Value: "\"Full\"",
-						Doc:   "`\"Full\"` is fully qualified symbols, i.e.\n\"path/to/pkg.Foo.Field\".\n",
-					},
-					{
-						Value: "\"Package\"",
-						Doc:   "`\"Package\"` is package qualified symbols i.e.\n\"pkg.Foo.Field\".\n",
-					},
-				},
-				Default:   "\"Dynamic\"",
-				Status:    "advanced",
-				Hierarchy: "ui.navigation",
-			},
-			{
-				Name: "analyses",
-				Type: "map[string]bool",
-				Doc:  "analyses specify analyses that the user would like to enable or disable.\nA map of the names of analysis passes that should be enabled/disabled.\nA full list of analyzers that gopls uses can be found in\n[analyzers.md](https://github.com/golang/tools/blob/master/gopls/doc/analyzers.md).\n\nExample Usage:\n\n```json5\n...\n\"analyses\": {\n  \"unreachable\": false, // Disable the unreachable analyzer.\n  \"unusedparams\": true  // Enable the unusedparams analyzer.\n}\n...\n```\n",
-				EnumKeys: EnumKeys{
-					ValueType: "bool",
-					Keys: []EnumKey{
-						{
-							Name:    "\"asmdecl\"",
-							Doc:     "report mismatches between assembly files and Go declarations",
-							Default: "true",
-						},
-						{
-							Name:    "\"assign\"",
-							Doc:     "check for useless assignments\n\nThis checker reports assignments of the form x = x or a[i] = a[i].\nThese are almost always useless, and even when they aren't they are\nusually a mistake.",
-							Default: "true",
-						},
-						{
-							Name:    "\"atomic\"",
-							Doc:     "check for common mistakes using the sync/atomic package\n\nThe atomic checker looks for assignment statements of the form:\n\n\tx = atomic.AddUint64(&x, 1)\n\nwhich are not atomic.",
-							Default: "true",
-						},
-						{
-							Name:    "\"atomicalign\"",
-							Doc:     "check for non-64-bits-aligned arguments to sync/atomic functions",
-							Default: "true",
-						},
-						{
-							Name:    "\"bools\"",
-							Doc:     "check for common mistakes involving boolean operators",
-							Default: "true",
-						},
-						{
-							Name:    "\"buildtag\"",
-							Doc:     "check that +build tags are well-formed and correctly located",
-							Default: "true",
-						},
-						{
-							Name:    "\"cgocall\"",
-							Doc:     "detect some violations of the cgo pointer passing rules\n\nCheck for invalid cgo pointer passing.\nThis looks for code that uses cgo to call C code passing values\nwhose types are almost always invalid according to the cgo pointer\nsharing rules.\nSpecifically, it warns about attempts to pass a Go chan, map, func,\nor slice to C, either directly, or via a pointer, array, or struct.",
-							Default: "true",
-						},
-						{
-							Name:    "\"composites\"",
-							Doc:     "check for unkeyed composite literals\n\nThis analyzer reports a diagnostic for composite literals of struct\ntypes imported from another package that do not use the field-keyed\nsyntax. Such literals are fragile because the addition of a new field\n(even if unexported) to the struct will cause compilation to fail.\n\nAs an example,\n\n\terr = &net.DNSConfigError{err}\n\nshould be replaced by:\n\n\terr = &net.DNSConfigError{Err: err}\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"copylocks\"",
-							Doc:     "check for locks erroneously passed by value\n\nInadvertently copying a value containing a lock, such as sync.Mutex or\nsync.WaitGroup, may cause both copies to malfunction. Generally such\nvalues should be referred to through a pointer.",
-							Default: "true",
-						},
-						{
-							Name:    "\"deepequalerrors\"",
-							Doc:     "check for calls of reflect.DeepEqual on error values\n\nThe deepequalerrors checker looks for calls of the form:\n\n    reflect.DeepEqual(err1, err2)\n\nwhere err1 and err2 are errors. Using reflect.DeepEqual to compare\nerrors is discouraged.",
-							Default: "true",
-						},
-						{
-							Name:    "\"embed\"",
-							Doc:     "check for //go:embed directive import\n\nThis analyzer checks that the embed package is imported when source code contains //go:embed comment directives.\nThe embed package must be imported for //go:embed directives to function.import _ \"embed\".",
-							Default: "true",
-						},
-						{
-							Name:    "\"errorsas\"",
-							Doc:     "report passing non-pointer or non-error values to errors.As\n\nThe errorsas analysis reports calls to errors.As where the type\nof the second argument is not a pointer to a type implementing error.",
-							Default: "true",
-						},
-						{
-							Name:    "\"fieldalignment\"",
-							Doc:     "find structs that would use less memory if their fields were sorted\n\nThis analyzer find structs that can be rearranged to use less memory, and provides\na suggested edit with the most compact order.\n\nNote that there are two different diagnostics reported. One checks struct size,\nand the other reports \"pointer bytes\" used. Pointer bytes is how many bytes of the\nobject that the garbage collector has to potentially scan for pointers, for example:\n\n\tstruct { uint32; string }\n\nhave 16 pointer bytes because the garbage collector has to scan up through the string's\ninner pointer.\n\n\tstruct { string; *uint32 }\n\nhas 24 pointer bytes because it has to scan further through the *uint32.\n\n\tstruct { string; uint32 }\n\nhas 8 because it can stop immediately after the string pointer.\n\nBe aware that the most compact order is not always the most efficient.\nIn rare cases it may cause two variables each updated by its own goroutine\nto occupy the same CPU cache line, inducing a form of memory contention\nknown as \"false sharing\" that slows down both goroutines.\n",
-							Default: "false",
-						},
-						{
-							Name:    "\"httpresponse\"",
-							Doc:     "check for mistakes using HTTP responses\n\nA common mistake when using the net/http package is to defer a function\ncall to close the http.Response Body before checking the error that\ndetermines whether the response is valid:\n\n\tresp, err := http.Head(url)\n\tdefer resp.Body.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t// (defer statement belongs here)\n\nThis checker helps uncover latent nil dereference bugs by reporting a\ndiagnostic for such mistakes.",
-							Default: "true",
-						},
-						{
-							Name:    "\"ifaceassert\"",
-							Doc:     "detect impossible interface-to-interface type assertions\n\nThis checker flags type assertions v.(T) and corresponding type-switch cases\nin which the static type V of v is an interface that cannot possibly implement\nthe target interface T. This occurs when V and T contain methods with the same\nname but different signatures. Example:\n\n\tvar v interface {\n\t\tRead()\n\t}\n\t_ = v.(io.Reader)\n\nThe Read method in v has a different signature than the Read method in\nio.Reader, so this assertion cannot succeed.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"infertypeargs\"",
-							Doc:     "check for unnecessary type arguments in call expressions\n\nExplicit type arguments may be omitted from call expressions if they can be\ninferred from function arguments, or from other type arguments:\n\n\tfunc f[T any](T) {}\n\t\n\tfunc _() {\n\t\tf[string](\"foo\") // string could be inferred\n\t}\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"loopclosure\"",
-							Doc:     "check references to loop variables from within nested functions\n\nThis analyzer reports places where a function literal references the\niteration variable of an enclosing loop, and the loop calls the function\nin such a way (e.g. with go or defer) that it may outlive the loop\niteration and possibly observe the wrong value of the variable.\n\nIn this example, all the deferred functions run after the loop has\ncompleted, so all observe the final value of v.\n\n    for _, v := range list {\n        defer func() {\n            use(v) // incorrect\n        }()\n    }\n\nOne fix is to create a new variable for each iteration of the loop:\n\n    for _, v := range list {\n        v := v // new var per iteration\n        defer func() {\n            use(v) // ok\n        }()\n    }\n\nThe next example uses a go statement and has a similar problem.\nIn addition, it has a data race because the loop updates v\nconcurrent with the goroutines accessing it.\n\n    for _, v := range elem {\n        go func() {\n            use(v)  // incorrect, and a data race\n        }()\n    }\n\nA fix is the same as before. The checker also reports problems\nin goroutines started by golang.org/x/sync/errgroup.Group.\nA hard-to-spot variant of this form is common in parallel tests:\n\n    func Test(t *testing.T) {\n        for _, test := range tests {\n            t.Run(test.name, func(t *testing.T) {\n                t.Parallel()\n                use(test) // incorrect, and a data race\n            })\n        }\n    }\n\nThe t.Parallel() call causes the rest of the function to execute\nconcurrent with the loop.\n\nThe analyzer reports references only in the last statement,\nas it is not deep enough to understand the effects of subsequent\nstatements that might render the reference benign.\n(\"Last statement\" is defined recursively in compound\nstatements such as if, switch, and select.)\n\nSee: https://golang.org/doc/go_faq.html#closures_and_goroutines",
-							Default: "true",
-						},
-						{
-							Name:    "\"lostcancel\"",
-							Doc:     "check cancel func returned by context.WithCancel is called\n\nThe cancellation function returned by context.WithCancel, WithTimeout,\nand WithDeadline must be called or the new context will remain live\nuntil its parent context is cancelled.\n(The background context is never cancelled.)",
-							Default: "true",
-						},
-						{
-							Name:    "\"nilfunc\"",
-							Doc:     "check for useless comparisons between functions and nil\n\nA useless comparison is one like f == nil as opposed to f() == nil.",
-							Default: "true",
-						},
-						{
-							Name:    "\"nilness\"",
-							Doc:     "check for redundant or impossible nil comparisons\n\nThe nilness checker inspects the control-flow graph of each function in\na package and reports nil pointer dereferences, degenerate nil\npointers, and panics with nil values. A degenerate comparison is of the form\nx==nil or x!=nil where x is statically known to be nil or non-nil. These are\noften a mistake, especially in control flow related to errors. Panics with nil\nvalues are checked because they are not detectable by\n\n\tif r := recover(); r != nil {\n\nThis check reports conditions such as:\n\n\tif f == nil { // impossible condition (f is a function)\n\t}\n\nand:\n\n\tp := &v\n\t...\n\tif p != nil { // tautological condition\n\t}\n\nand:\n\n\tif p == nil {\n\t\tprint(*p) // nil dereference\n\t}\n\nand:\n\n\tif p == nil {\n\t\tpanic(p)\n\t}\n",
-							Default: "false",
-						},
-						{
-							Name:    "\"printf\"",
-							Doc:     "check consistency of Printf format strings and arguments\n\nThe check applies to known functions (for example, those in package fmt)\nas well as any detected wrappers of known functions.\n\nA function that wants to avail itself of printf checking but is not\nfound by this analyzer's heuristics (for example, due to use of\ndynamic calls) can insert a bogus call:\n\n\tif false {\n\t\t_ = fmt.Sprintf(format, args...) // enable printf checking\n\t}\n\nThe -funcs flag specifies a comma-separated list of names of additional\nknown formatting functions or methods. If the name contains a period,\nit must denote a specific function using one of the following forms:\n\n\tdir/pkg.Function\n\tdir/pkg.Type.Method\n\t(*dir/pkg.Type).Method\n\nOtherwise the name is interpreted as a case-insensitive unqualified\nidentifier such as \"errorf\". Either way, if a listed name ends in f, the\nfunction is assumed to be Printf-like, taking a format string before the\nargument list. Otherwise it is assumed to be Print-like, taking a list\nof arguments with no format string.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"shadow\"",
-							Doc:     "check for possible unintended shadowing of variables\n\nThis analyzer check for shadowed variables.\nA shadowed variable is a variable declared in an inner scope\nwith the same name and type as a variable in an outer scope,\nand where the outer variable is mentioned after the inner one\nis declared.\n\n(This definition can be refined; the module generates too many\nfalse positives and is not yet enabled by default.)\n\nFor example:\n\n\tfunc BadRead(f *os.File, buf []byte) error {\n\t\tvar err error\n\t\tfor {\n\t\t\tn, err := f.Read(buf) // shadows the function variable 'err'\n\t\t\tif err != nil {\n\t\t\t\tbreak // causes return of wrong value\n\t\t\t}\n\t\t\tfoo(buf)\n\t\t}\n\t\treturn err\n\t}\n",
-							Default: "false",
-						},
-						{
-							Name:    "\"shift\"",
-							Doc:     "check for shifts that equal or exceed the width of the integer",
-							Default: "true",
-						},
-						{
-							Name:    "\"simplifycompositelit\"",
-							Doc:     "check for composite literal simplifications\n\nAn array, slice, or map composite literal of the form:\n\t[]T{T{}, T{}}\nwill be simplified to:\n\t[]T{{}, {}}\n\nThis is one of the simplifications that \"gofmt -s\" applies.",
-							Default: "true",
-						},
-						{
-							Name:    "\"simplifyrange\"",
-							Doc:     "check for range statement simplifications\n\nA range of the form:\n\tfor x, _ = range v {...}\nwill be simplified to:\n\tfor x = range v {...}\n\nA range of the form:\n\tfor _ = range v {...}\nwill be simplified to:\n\tfor range v {...}\n\nThis is one of the simplifications that \"gofmt -s\" applies.",
-							Default: "true",
-						},
-						{
-							Name:    "\"simplifyslice\"",
-							Doc:     "check for slice simplifications\n\nA slice expression of the form:\n\ts[a:len(s)]\nwill be simplified to:\n\ts[a:]\n\nThis is one of the simplifications that \"gofmt -s\" applies.",
-							Default: "true",
-						},
-						{
-							Name:    "\"sortslice\"",
-							Doc:     "check the argument type of sort.Slice\n\nsort.Slice requires an argument of a slice type. Check that\nthe interface{} value passed to sort.Slice is actually a slice.",
-							Default: "true",
-						},
-						{
-							Name:    "\"stdmethods\"",
-							Doc:     "check signature of methods of well-known interfaces\n\nSometimes a type may be intended to satisfy an interface but may fail to\ndo so because of a mistake in its method signature.\nFor example, the result of this WriteTo method should be (int64, error),\nnot error, to satisfy io.WriterTo:\n\n\ttype myWriterTo struct{...}\n        func (myWriterTo) WriteTo(w io.Writer) error { ... }\n\nThis check ensures that each method whose name matches one of several\nwell-known interface methods from the standard library has the correct\nsignature for that interface.\n\nChecked method names include:\n\tFormat GobEncode GobDecode MarshalJSON MarshalXML\n\tPeek ReadByte ReadFrom ReadRune Scan Seek\n\tUnmarshalJSON UnreadByte UnreadRune WriteByte\n\tWriteTo\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"stringintconv\"",
-							Doc:     "check for string(int) conversions\n\nThis checker flags conversions of the form string(x) where x is an integer\n(but not byte or rune) type. Such conversions are discouraged because they\nreturn the UTF-8 representation of the Unicode code point x, and not a decimal\nstring representation of x as one might expect. Furthermore, if x denotes an\ninvalid code point, the conversion cannot be statically rejected.\n\nFor conversions that intend on using the code point, consider replacing them\nwith string(rune(x)). Otherwise, strconv.Itoa and its equivalents return the\nstring representation of the value in the desired base.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"structtag\"",
-							Doc:     "check that struct field tags conform to reflect.StructTag.Get\n\nAlso report certain struct tags (json, xml) used with unexported fields.",
-							Default: "true",
-						},
-						{
-							Name:    "\"testinggoroutine\"",
-							Doc:     "report calls to (*testing.T).Fatal from goroutines started by a test.\n\nFunctions that abruptly terminate a test, such as the Fatal, Fatalf, FailNow, and\nSkip{,f,Now} methods of *testing.T, must be called from the test goroutine itself.\nThis checker detects calls to these functions that occur within a goroutine\nstarted by the test. For example:\n\nfunc TestFoo(t *testing.T) {\n    go func() {\n        t.Fatal(\"oops\") // error: (*T).Fatal called from non-test goroutine\n    }()\n}\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"tests\"",
-							Doc:     "check for common mistaken usages of tests and examples\n\nThe tests checker walks Test, Benchmark and Example functions checking\nmalformed names, wrong signatures and examples documenting non-existent\nidentifiers.\n\nPlease see the documentation for package testing in golang.org/pkg/testing\nfor the conventions that are enforced for Tests, Benchmarks, and Examples.",
-							Default: "true",
-						},
-						{
-							Name:    "\"timeformat\"",
-							Doc:     "check for calls of (time.Time).Format or time.Parse with 2006-02-01\n\nThe timeformat checker looks for time formats with the 2006-02-01 (yyyy-dd-mm)\nformat. Internationally, \"yyyy-dd-mm\" does not occur in common calendar date\nstandards, and so it is more likely that 2006-01-02 (yyyy-mm-dd) was intended.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"unmarshal\"",
-							Doc:     "report passing non-pointer or non-interface values to unmarshal\n\nThe unmarshal analysis reports calls to functions such as json.Unmarshal\nin which the argument type is not a pointer or an interface.",
-							Default: "true",
-						},
-						{
-							Name:    "\"unreachable\"",
-							Doc:     "check for unreachable code\n\nThe unreachable analyzer finds statements that execution can never reach\nbecause they are preceded by an return statement, a call to panic, an\ninfinite loop, or similar constructs.",
-							Default: "true",
-						},
-						{
-							Name:    "\"unsafeptr\"",
-							Doc:     "check for invalid conversions of uintptr to unsafe.Pointer\n\nThe unsafeptr analyzer reports likely incorrect uses of unsafe.Pointer\nto convert integers to pointers. A conversion from uintptr to\nunsafe.Pointer is invalid if it implies that there is a uintptr-typed\nword in memory that holds a pointer value, because that word will be\ninvisible to stack copying and to the garbage collector.",
-							Default: "true",
-						},
-						{
-							Name:    "\"unusedparams\"",
-							Doc:     "check for unused parameters of functions\n\nThe unusedparams analyzer checks functions to see if there are\nany parameters that are not being used.\n\nTo reduce false positives it ignores:\n- methods\n- parameters that do not have a name or are underscored\n- functions in test files\n- functions with empty bodies or those with just a return stmt",
-							Default: "false",
-						},
-						{
-							Name:    "\"unusedresult\"",
-							Doc:     "check for unused results of calls to some functions\n\nSome functions like fmt.Errorf return a result and have no side effects,\nso it is always a mistake to discard the result. This analyzer reports\ncalls to certain functions in which the result of the call is ignored.\n\nThe set of functions may be controlled using flags.",
-							Default: "true",
-						},
-						{
-							Name:    "\"unusedwrite\"",
-							Doc:     "checks for unused writes\n\nThe analyzer reports instances of writes to struct fields and\narrays that are never read. Specifically, when a struct object\nor an array is copied, its elements are copied implicitly by\nthe compiler, and any element write to this copy does nothing\nwith the original object.\n\nFor example:\n\n\ttype T struct { x int }\n\tfunc f(input []T) {\n\t\tfor i, v := range input {  // v is a copy\n\t\t\tv.x = i  // unused write to field x\n\t\t}\n\t}\n\nAnother example is about non-pointer receiver:\n\n\ttype T struct { x int }\n\tfunc (t T) f() {  // t is a copy\n\t\tt.x = i  // unused write to field x\n\t}\n",
-							Default: "false",
-						},
-						{
-							Name:    "\"useany\"",
-							Doc:     "check for constraints that could be simplified to \"any\"",
-							Default: "false",
-						},
-						{
-							Name:    "\"fillreturns\"",
-							Doc:     "suggest fixes for errors due to an incorrect number of return values\n\nThis checker provides suggested fixes for type errors of the\ntype \"wrong number of return values (want %d, got %d)\". For example:\n\tfunc m() (int, string, *bool, error) {\n\t\treturn\n\t}\nwill turn into\n\tfunc m() (int, string, *bool, error) {\n\t\treturn 0, \"\", nil, nil\n\t}\n\nThis functionality is similar to https://github.com/sqs/goreturns.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"nonewvars\"",
-							Doc:     "suggested fixes for \"no new vars on left side of :=\"\n\nThis checker provides suggested fixes for type errors of the\ntype \"no new vars on left side of :=\". For example:\n\tz := 1\n\tz := 2\nwill turn into\n\tz := 1\n\tz = 2\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"noresultvalues\"",
-							Doc:     "suggested fixes for unexpected return values\n\nThis checker provides suggested fixes for type errors of the\ntype \"no result values expected\" or \"too many return values\".\nFor example:\n\tfunc z() { return nil }\nwill turn into\n\tfunc z() { return }\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"undeclaredname\"",
-							Doc:     "suggested fixes for \"undeclared name: <>\"\n\nThis checker provides suggested fixes for type errors of the\ntype \"undeclared name: <>\". It will either insert a new statement,\nsuch as:\n\n\"<> := \"\n\nor a new function declaration, such as:\n\nfunc <>(inferred parameters) {\n\tpanic(\"implement me!\")\n}\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"unusedvariable\"",
-							Doc:     "check for unused variables\n\nThe unusedvariable analyzer suggests fixes for unused variables errors.\n",
-							Default: "false",
-						},
-						{
-							Name:    "\"fillstruct\"",
-							Doc:     "note incomplete struct initializations\n\nThis analyzer provides diagnostics for any struct literals that do not have\nany fields initialized. Because the suggested fix for this analysis is\nexpensive to compute, callers should compute it separately, using the\nSuggestedFix function below.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"stubmethods\"",
-							Doc:     "stub methods analyzer\n\nThis analyzer generates method stubs for concrete types\nin order to implement a target interface",
-							Default: "true",
-						},
-					},
-				},
-				Default:   "{}",
-				Hierarchy: "ui.diagnostic",
-			},
-			{
-				Name:      "staticcheck",
-				Type:      "bool",
-				Doc:       "staticcheck enables additional analyses from staticcheck.io.\nThese analyses are documented on\n[Staticcheck's website](https://staticcheck.io/docs/checks/).\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "ui.diagnostic",
-			},
-			{
-				Name: "annotations",
-				Type: "map[string]bool",
-				Doc:  "annotations specifies the various kinds of optimization diagnostics\nthat should be reported by the gc_details command.\n",
-				EnumKeys: EnumKeys{
-					ValueType: "bool",
-					Keys: []EnumKey{
-						{
-							Name:    "\"bounds\"",
-							Doc:     "`\"bounds\"` controls bounds checking diagnostics.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"escape\"",
-							Doc:     "`\"escape\"` controls diagnostics about escape choices.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"inline\"",
-							Doc:     "`\"inline\"` controls diagnostics about inlining choices.\n",
-							Default: "true",
-						},
-						{
-							Name:    "\"nil\"",
-							Doc:     "`\"nil\"` controls nil checks.\n",
-							Default: "true",
-						},
-					},
-				},
-				Default:   "{\"bounds\":true,\"escape\":true,\"inline\":true,\"nil\":true}",
-				Status:    "experimental",
-				Hierarchy: "ui.diagnostic",
-			},
-			{
-				Name: "vulncheck",
-				Type: "enum",
-				Doc:  "vulncheck enables vulnerability scanning.\n",
-				EnumValues: []EnumValue{
-					{
-						Value: "\"Imports\"",
-						Doc:   "`\"Imports\"`: In Imports mode, `gopls` will report vulnerabilities that affect packages\ndirectly and indirectly used by the analyzed main module.\n",
-					},
-					{
-						Value: "\"Off\"",
-						Doc:   "`\"Off\"`: Disable vulnerability analysis.\n",
-					},
-				},
-				Default:   "\"Off\"",
-				Status:    "experimental",
-				Hierarchy: "ui.diagnostic",
-			},
-			{
-				Name:      "diagnosticsDelay",
-				Type:      "time.Duration",
-				Doc:       "diagnosticsDelay controls the amount of time that gopls waits\nafter the most recent file modification before computing deep diagnostics.\nSimple diagnostics (parsing and type-checking) are always run immediately\non recently modified packages.\n\nThis option must be set to a valid duration string, for example `\"250ms\"`.\n",
-				Default:   "\"250ms\"",
-				Status:    "advanced",
-				Hierarchy: "ui.diagnostic",
-			},
-			{
-				Name:      "experimentalWatchedFileDelay",
-				Type:      "time.Duration",
-				Doc:       "experimentalWatchedFileDelay controls the amount of time that gopls waits\nfor additional workspace/didChangeWatchedFiles notifications to arrive,\nbefore processing all such notifications in a single batch. This is\nintended for use by LSP clients that don't support their own batching of\nfile system notifications.\n\nThis option must be set to a valid duration string, for example `\"100ms\"`.\n\nDeprecated: this setting is deprecated and will be removed in a future\nversion of gopls (https://go.dev/issue/55332)\n",
-				Default:   "\"0s\"",
-				Status:    "experimental",
-				Hierarchy: "ui.diagnostic",
-			},
-			{
-				Name: "hints",
-				Type: "map[string]bool",
-				Doc:  "hints specify inlay hints that users want to see. A full list of hints\nthat gopls uses can be found in\n[inlayHints.md](https://github.com/golang/tools/blob/master/gopls/doc/inlayHints.md).\n",
-				EnumKeys: EnumKeys{Keys: []EnumKey{
-					{
-						Name:    "\"assignVariableTypes\"",
-						Doc:     "Enable/disable inlay hints for variable types in assign statements:\n```go\n\ti/* int*/, j/* int*/ := 0, len(r)-1\n```",
-						Default: "false",
-					},
-					{
-						Name:    "\"compositeLiteralFields\"",
-						Doc:     "Enable/disable inlay hints for composite literal field names:\n```go\n\t{/*in: */\"Hello, world\", /*want: */\"dlrow ,olleH\"}\n```",
-						Default: "false",
-					},
-					{
-						Name:    "\"compositeLiteralTypes\"",
-						Doc:     "Enable/disable inlay hints for composite literal types:\n```go\n\tfor _, c := range []struct {\n\t\tin, want string\n\t}{\n\t\t/*struct{ in string; want string }*/{\"Hello, world\", \"dlrow ,olleH\"},\n\t}\n```",
-						Default: "false",
-					},
-					{
-						Name:    "\"constantValues\"",
-						Doc:     "Enable/disable inlay hints for constant values:\n```go\n\tconst (\n\t\tKindNone   Kind = iota/* = 0*/\n\t\tKindPrint/*  = 1*/\n\t\tKindPrintf/* = 2*/\n\t\tKindErrorf/* = 3*/\n\t)\n```",
-						Default: "false",
-					},
-					{
-						Name:    "\"functionTypeParameters\"",
-						Doc:     "Enable/disable inlay hints for implicit type parameters on generic functions:\n```go\n\tmyFoo/*[int, string]*/(1, \"hello\")\n```",
-						Default: "false",
-					},
-					{
-						Name:    "\"parameterNames\"",
-						Doc:     "Enable/disable inlay hints for parameter names:\n```go\n\tparseInt(/* str: */ \"123\", /* radix: */ 8)\n```",
-						Default: "false",
-					},
-					{
-						Name:    "\"rangeVariableTypes\"",
-						Doc:     "Enable/disable inlay hints for variable types in range statements:\n```go\n\tfor k/* int*/, v/* string*/ := range []string{} {\n\t\tfmt.Println(k, v)\n\t}\n```",
-						Default: "false",
-					},
-				}},
-				Default:   "{}",
-				Status:    "experimental",
-				Hierarchy: "ui.inlayhint",
-			},
-			{
-				Name: "codelenses",
-				Type: "map[string]bool",
-				Doc:  "codelenses overrides the enabled/disabled state of code lenses. See the\n\"Code Lenses\" section of the\n[Settings page](https://github.com/golang/tools/blob/master/gopls/doc/settings.md#code-lenses)\nfor the list of supported lenses.\n\nExample Usage:\n\n```json5\n\"gopls\": {\n...\n  \"codelenses\": {\n    \"generate\": false,  // Don't show the `go generate` lens.\n    \"gc_details\": true  // Show a code lens toggling the display of gc's choices.\n  }\n...\n}\n```\n",
-				EnumKeys: EnumKeys{
-					ValueType: "bool",
-					Keys: []EnumKey{
-						{
-							Name:    "\"gc_details\"",
-							Doc:     "Toggle the calculation of gc annotations.",
-							Default: "false",
-						},
-						{
-							Name:    "\"generate\"",
-							Doc:     "Runs `go generate` for a given directory.",
-							Default: "true",
-						},
-						{
-							Name:    "\"regenerate_cgo\"",
-							Doc:     "Regenerates cgo definitions.",
-							Default: "true",
-						},
-						{
-							Name:    "\"run_govulncheck\"",
-							Doc:     "Run vulnerability check (`govulncheck`).",
-							Default: "false",
-						},
-						{
-							Name:    "\"test\"",
-							Doc:     "Runs `go test` for a specific set of test or benchmark functions.",
-							Default: "false",
-						},
-						{
-							Name:    "\"tidy\"",
-							Doc:     "Runs `go mod tidy` for a module.",
-							Default: "true",
-						},
-						{
-							Name:    "\"upgrade_dependency\"",
-							Doc:     "Upgrades a dependency in the go.mod file for a module.",
-							Default: "true",
-						},
-						{
-							Name:    "\"vendor\"",
-							Doc:     "Runs `go mod vendor` for a module.",
-							Default: "true",
-						},
-					},
-				},
-				Default:   "{\"gc_details\":false,\"generate\":true,\"regenerate_cgo\":true,\"tidy\":true,\"upgrade_dependency\":true,\"vendor\":true}",
-				Hierarchy: "ui",
-			},
-			{
-				Name:      "semanticTokens",
-				Type:      "bool",
-				Doc:       "semanticTokens controls whether the LSP server will send\nsemantic tokens to the client.\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "ui",
-			},
-			{
-				Name:      "noSemanticString",
-				Type:      "bool",
-				Doc:       "noSemanticString turns off the sending of the semantic token 'string'\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "ui",
-			},
-			{
-				Name:      "noSemanticNumber",
-				Type:      "bool",
-				Doc:       "noSemanticNumber  turns off the sending of the semantic token 'number'\n",
-				Default:   "false",
-				Status:    "experimental",
-				Hierarchy: "ui",
-			},
-			{
-				Name:      "local",
-				Type:      "string",
-				Doc:       "local is the equivalent of the `goimports -local` flag, which puts\nimports beginning with this string after third-party packages. It should\nbe the prefix of the import path whose imports should be grouped\nseparately.\n",
-				Default:   "\"\"",
-				Hierarchy: "formatting",
-			},
-			{
-				Name:      "gofumpt",
-				Type:      "bool",
-				Doc:       "gofumpt indicates if we should run gofumpt formatting.\n",
-				Default:   "false",
-				Hierarchy: "formatting",
-			},
-			{
-				Name:    "verboseOutput",
-				Type:    "bool",
-				Doc:     "verboseOutput enables additional debug logging.\n",
-				Default: "false",
-				Status:  "debug",
-			},
-		},
-	},
-	Commands: []*CommandJSON{
-		{
-			Command: "gopls.add_dependency",
-			Title:   "Add a dependency",
-			Doc:     "Adds a dependency to the go.mod file for a module.",
-			ArgDoc:  "{\n\t// The go.mod file URI.\n\t\"URI\": string,\n\t// Additional args to pass to the go command.\n\t\"GoCmdArgs\": []string,\n\t// Whether to add a require directive.\n\t\"AddRequire\": bool,\n}",
-		},
-		{
-			Command: "gopls.add_import",
-			Title:   "Add an import",
-			Doc:     "Ask the server to add an import path to a given Go file.  The method will\ncall applyEdit on the client so that clients don't have to apply the edit\nthemselves.",
-			ArgDoc:  "{\n\t// ImportPath is the target import path that should\n\t// be added to the URI file\n\t\"ImportPath\": string,\n\t// URI is the file that the ImportPath should be\n\t// added to\n\t\"URI\": string,\n}",
-		},
-		{
-			Command: "gopls.apply_fix",
-			Title:   "Apply a fix",
-			Doc:     "Applies a fix to a region of source code.",
-			ArgDoc:  "{\n\t// The fix to apply.\n\t\"Fix\": string,\n\t// The file URI for the document to fix.\n\t\"URI\": string,\n\t// The document range to scan for fixes.\n\t\"Range\": {\n\t\t\"start\": {\n\t\t\t\"line\": uint32,\n\t\t\t\"character\": uint32,\n\t\t},\n\t\t\"end\": {\n\t\t\t\"line\": uint32,\n\t\t\t\"character\": uint32,\n\t\t},\n\t},\n}",
-		},
-		{
-			Command: "gopls.check_upgrades",
-			Title:   "Check for upgrades",
-			Doc:     "Checks for module upgrades.",
-			ArgDoc:  "{\n\t// The go.mod file URI.\n\t\"URI\": string,\n\t// The modules to check.\n\t\"Modules\": []string,\n}",
-		},
-		{
-			Command: "gopls.edit_go_directive",
-			Title:   "Run go mod edit -go=version",
-			Doc:     "Runs `go mod edit -go=version` for a module.",
-			ArgDoc:  "{\n\t// Any document URI within the relevant module.\n\t\"URI\": string,\n\t// The version to pass to `go mod edit -go`.\n\t\"Version\": string,\n}",
-		},
-		{
-			Command:   "gopls.fetch_vulncheck_result",
-			Title:     "Get known vulncheck result",
-			Doc:       "Fetch the result of latest vulnerability check (`govulncheck`).",
-			ArgDoc:    "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-			ResultDoc: "map[golang.org/x/tools/gopls/internal/lsp/protocol.DocumentURI]*golang.org/x/tools/gopls/internal/govulncheck.Result",
-		},
-		{
-			Command: "gopls.gc_details",
-			Title:   "Toggle gc_details",
-			Doc:     "Toggle the calculation of gc annotations.",
-			ArgDoc:  "string",
-		},
-		{
-			Command: "gopls.generate",
-			Title:   "Run go generate",
-			Doc:     "Runs `go generate` for a given directory.",
-			ArgDoc:  "{\n\t// URI for the directory to generate.\n\t\"Dir\": string,\n\t// Whether to generate recursively (go generate ./...)\n\t\"Recursive\": bool,\n}",
-		},
-		{
-			Command: "gopls.generate_gopls_mod",
-			Title:   "Generate gopls.mod",
-			Doc:     "(Re)generate the gopls.mod file for a workspace.",
-			ArgDoc:  "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-		},
-		{
-			Command: "gopls.go_get_package",
-			Title:   "go get a package",
-			Doc:     "Runs `go get` to fetch a package.",
-			ArgDoc:  "{\n\t// Any document URI within the relevant module.\n\t\"URI\": string,\n\t// The package to go get.\n\t\"Pkg\": string,\n\t\"AddRequire\": bool,\n}",
-		},
-		{
-			Command:   "gopls.list_imports",
-			Title:     "List imports of a file and its package",
-			Doc:       "Retrieve a list of imports in the given Go file, and the package it\nbelongs to.",
-			ArgDoc:    "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-			ResultDoc: "{\n\t// Imports is a list of imports in the requested file.\n\t\"Imports\": []{\n\t\t\"Path\": string,\n\t\t\"Name\": string,\n\t},\n\t// PackageImports is a list of all imports in the requested file's package.\n\t\"PackageImports\": []{\n\t\t\"Path\": string,\n\t},\n}",
-		},
-		{
-			Command:   "gopls.list_known_packages",
-			Title:     "List known packages",
-			Doc:       "Retrieve a list of packages that are importable from the given URI.",
-			ArgDoc:    "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-			ResultDoc: "{\n\t// Packages is a list of packages relative\n\t// to the URIArg passed by the command request.\n\t// In other words, it omits paths that are already\n\t// imported or cannot be imported due to compiler\n\t// restrictions.\n\t\"Packages\": []string,\n}",
-		},
-		{
-			Command: "gopls.regenerate_cgo",
-			Title:   "Regenerate cgo",
-			Doc:     "Regenerates cgo definitions.",
-			ArgDoc:  "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-		},
-		{
-			Command: "gopls.remove_dependency",
-			Title:   "Remove a dependency",
-			Doc:     "Removes a dependency from the go.mod file of a module.",
-			ArgDoc:  "{\n\t// The go.mod file URI.\n\t\"URI\": string,\n\t// The module path to remove.\n\t\"ModulePath\": string,\n\t\"OnlyDiagnostic\": bool,\n}",
-		},
-		{
-			Command: "gopls.reset_go_mod_diagnostics",
-			Title:   "Reset go.mod diagnostics",
-			Doc:     "Reset diagnostics in the go.mod file of a module.",
-			ArgDoc:  "{\n\t\"URIArg\": {\n\t\t\"URI\": string,\n\t},\n\t// Optional: source of the diagnostics to reset.\n\t// If not set, all resettable go.mod diagnostics will be cleared.\n\t\"DiagnosticSource\": string,\n}",
-		},
-		{
-			Command:   "gopls.run_govulncheck",
-			Title:     "Run govulncheck.",
-			Doc:       "Run vulnerability check (`govulncheck`).",
-			ArgDoc:    "{\n\t// Any document in the directory from which govulncheck will run.\n\t\"URI\": string,\n\t// Package pattern. E.g. \"\", \".\", \"./...\".\n\t\"Pattern\": string,\n}",
-			ResultDoc: "{\n\t// Token holds the progress token for LSP workDone reporting of the vulncheck\n\t// invocation.\n\t\"Token\": interface{},\n}",
-		},
-		{
-			Command: "gopls.run_tests",
-			Title:   "Run test(s)",
-			Doc:     "Runs `go test` for a specific set of test or benchmark functions.",
-			ArgDoc:  "{\n\t// The test file containing the tests to run.\n\t\"URI\": string,\n\t// Specific test names to run, e.g. TestFoo.\n\t\"Tests\": []string,\n\t// Specific benchmarks to run, e.g. BenchmarkFoo.\n\t\"Benchmarks\": []string,\n}",
-		},
-		{
-			Command:   "gopls.start_debugging",
-			Title:     "Start the gopls debug server",
-			Doc:       "Start the gopls debug server if it isn't running, and return the debug\naddress.",
-			ArgDoc:    "{\n\t// Optional: the address (including port) for the debug server to listen on.\n\t// If not provided, the debug server will bind to \"localhost:0\", and the\n\t// full debug URL will be contained in the result.\n\t// \n\t// If there is more than one gopls instance along the serving path (i.e. you\n\t// are using a daemon), each gopls instance will attempt to start debugging.\n\t// If Addr specifies a port, only the daemon will be able to bind to that\n\t// port, and each intermediate gopls instance will fail to start debugging.\n\t// For this reason it is recommended not to specify a port (or equivalently,\n\t// to specify \":0\").\n\t// \n\t// If the server was already debugging this field has no effect, and the\n\t// result will contain the previously configured debug URL(s).\n\t\"Addr\": string,\n}",
-			ResultDoc: "{\n\t// The URLs to use to access the debug servers, for all gopls instances in\n\t// the serving path. For the common case of a single gopls instance (i.e. no\n\t// daemon), this will be exactly one address.\n\t// \n\t// In the case of one or more gopls instances forwarding the LSP to a daemon,\n\t// URLs will contain debug addresses for each server in the serving path, in\n\t// serving order. The daemon debug address will be the last entry in the\n\t// slice. If any intermediate gopls instance fails to start debugging, no\n\t// error will be returned but the debug URL for that server in the URLs slice\n\t// will be empty.\n\t\"URLs\": []string,\n}",
-		},
-		{
-			Command: "gopls.test",
-			Title:   "Run test(s) (legacy)",
-			Doc:     "Runs `go test` for a specific set of test or benchmark functions.",
-			ArgDoc:  "string,\n[]string,\n[]string",
-		},
-		{
-			Command: "gopls.tidy",
-			Title:   "Run go mod tidy",
-			Doc:     "Runs `go mod tidy` for a module.",
-			ArgDoc:  "{\n\t// The file URIs.\n\t\"URIs\": []string,\n}",
-		},
-		{
-			Command: "gopls.toggle_gc_details",
-			Title:   "Toggle gc_details",
-			Doc:     "Toggle the calculation of gc annotations.",
-			ArgDoc:  "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-		},
-		{
-			Command: "gopls.update_go_sum",
-			Title:   "Update go.sum",
-			Doc:     "Updates the go.sum file for a module.",
-			ArgDoc:  "{\n\t// The file URIs.\n\t\"URIs\": []string,\n}",
-		},
-		{
-			Command: "gopls.upgrade_dependency",
-			Title:   "Upgrade a dependency",
-			Doc:     "Upgrades a dependency in the go.mod file for a module.",
-			ArgDoc:  "{\n\t// The go.mod file URI.\n\t\"URI\": string,\n\t// Additional args to pass to the go command.\n\t\"GoCmdArgs\": []string,\n\t// Whether to add a require directive.\n\t\"AddRequire\": bool,\n}",
-		},
-		{
-			Command: "gopls.vendor",
-			Title:   "Run go mod vendor",
-			Doc:     "Runs `go mod vendor` for a module.",
-			ArgDoc:  "{\n\t// The file URI.\n\t\"URI\": string,\n}",
-		},
-	},
-	Lenses: []*LensJSON{
-		{
-			Lens:  "gc_details",
-			Title: "Toggle gc_details",
-			Doc:   "Toggle the calculation of gc annotations.",
-		},
-		{
-			Lens:  "generate",
-			Title: "Run go generate",
-			Doc:   "Runs `go generate` for a given directory.",
-		},
-		{
-			Lens:  "regenerate_cgo",
-			Title: "Regenerate cgo",
-			Doc:   "Regenerates cgo definitions.",
-		},
-		{
-			Lens:  "run_govulncheck",
-			Title: "Run govulncheck.",
-			Doc:   "Run vulnerability check (`govulncheck`).",
-		},
-		{
-			Lens:  "test",
-			Title: "Run test(s) (legacy)",
-			Doc:   "Runs `go test` for a specific set of test or benchmark functions.",
-		},
-		{
-			Lens:  "tidy",
-			Title: "Run go mod tidy",
-			Doc:   "Runs `go mod tidy` for a module.",
-		},
-		{
-			Lens:  "upgrade_dependency",
-			Title: "Upgrade a dependency",
-			Doc:   "Upgrades a dependency in the go.mod file for a module.",
-		},
-		{
-			Lens:  "vendor",
-			Title: "Run go mod vendor",
-			Doc:   "Runs `go mod vendor` for a module.",
-		},
-	},
-	Analyzers: []*AnalyzerJSON{
-		{
-			Name:    "asmdecl",
-			Doc:     "report mismatches between assembly files and Go declarations",
-			Default: true,
-		},
-		{
-			Name:    "assign",
-			Doc:     "check for useless assignments\n\nThis checker reports assignments of the form x = x or a[i] = a[i].\nThese are almost always useless, and even when they aren't they are\nusually a mistake.",
-			Default: true,
-		},
-		{
-			Name:    "atomic",
-			Doc:     "check for common mistakes using the sync/atomic package\n\nThe atomic checker looks for assignment statements of the form:\n\n\tx = atomic.AddUint64(&x, 1)\n\nwhich are not atomic.",
-			Default: true,
-		},
-		{
-			Name:    "atomicalign",
-			Doc:     "check for non-64-bits-aligned arguments to sync/atomic functions",
-			Default: true,
-		},
-		{
-			Name:    "bools",
-			Doc:     "check for common mistakes involving boolean operators",
-			Default: true,
-		},
-		{
-			Name:    "buildtag",
-			Doc:     "check that +build tags are well-formed and correctly located",
-			Default: true,
-		},
-		{
-			Name:    "cgocall",
-			Doc:     "detect some violations of the cgo pointer passing rules\n\nCheck for invalid cgo pointer passing.\nThis looks for code that uses cgo to call C code passing values\nwhose types are almost always invalid according to the cgo pointer\nsharing rules.\nSpecifically, it warns about attempts to pass a Go chan, map, func,\nor slice to C, either directly, or via a pointer, array, or struct.",
-			Default: true,
-		},
-		{
-			Name:    "composites",
-			Doc:     "check for unkeyed composite literals\n\nThis analyzer reports a diagnostic for composite literals of struct\ntypes imported from another package that do not use the field-keyed\nsyntax. Such literals are fragile because the addition of a new field\n(even if unexported) to the struct will cause compilation to fail.\n\nAs an example,\n\n\terr = &net.DNSConfigError{err}\n\nshould be replaced by:\n\n\terr = &net.DNSConfigError{Err: err}\n",
-			Default: true,
-		},
-		{
-			Name:    "copylocks",
-			Doc:     "check for locks erroneously passed by value\n\nInadvertently copying a value containing a lock, such as sync.Mutex or\nsync.WaitGroup, may cause both copies to malfunction. Generally such\nvalues should be referred to through a pointer.",
-			Default: true,
-		},
-		{
-			Name:    "deepequalerrors",
-			Doc:     "check for calls of reflect.DeepEqual on error values\n\nThe deepequalerrors checker looks for calls of the form:\n\n    reflect.DeepEqual(err1, err2)\n\nwhere err1 and err2 are errors. Using reflect.DeepEqual to compare\nerrors is discouraged.",
-			Default: true,
-		},
-		{
-			Name:    "embed",
-			Doc:     "check for //go:embed directive import\n\nThis analyzer checks that the embed package is imported when source code contains //go:embed comment directives.\nThe embed package must be imported for //go:embed directives to function.import _ \"embed\".",
-			Default: true,
-		},
-		{
-			Name:    "errorsas",
-			Doc:     "report passing non-pointer or non-error values to errors.As\n\nThe errorsas analysis reports calls to errors.As where the type\nof the second argument is not a pointer to a type implementing error.",
-			Default: true,
-		},
-		{
-			Name: "fieldalignment",
-			Doc:  "find structs that would use less memory if their fields were sorted\n\nThis analyzer find structs that can be rearranged to use less memory, and provides\na suggested edit with the most compact order.\n\nNote that there are two different diagnostics reported. One checks struct size,\nand the other reports \"pointer bytes\" used. Pointer bytes is how many bytes of the\nobject that the garbage collector has to potentially scan for pointers, for example:\n\n\tstruct { uint32; string }\n\nhave 16 pointer bytes because the garbage collector has to scan up through the string's\ninner pointer.\n\n\tstruct { string; *uint32 }\n\nhas 24 pointer bytes because it has to scan further through the *uint32.\n\n\tstruct { string; uint32 }\n\nhas 8 because it can stop immediately after the string pointer.\n\nBe aware that the most compact order is not always the most efficient.\nIn rare cases it may cause two variables each updated by its own goroutine\nto occupy the same CPU cache line, inducing a form of memory contention\nknown as \"false sharing\" that slows down both goroutines.\n",
-		},
-		{
-			Name:    "httpresponse",
-			Doc:     "check for mistakes using HTTP responses\n\nA common mistake when using the net/http package is to defer a function\ncall to close the http.Response Body before checking the error that\ndetermines whether the response is valid:\n\n\tresp, err := http.Head(url)\n\tdefer resp.Body.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t// (defer statement belongs here)\n\nThis checker helps uncover latent nil dereference bugs by reporting a\ndiagnostic for such mistakes.",
-			Default: true,
-		},
-		{
-			Name:    "ifaceassert",
-			Doc:     "detect impossible interface-to-interface type assertions\n\nThis checker flags type assertions v.(T) and corresponding type-switch cases\nin which the static type V of v is an interface that cannot possibly implement\nthe target interface T. This occurs when V and T contain methods with the same\nname but different signatures. Example:\n\n\tvar v interface {\n\t\tRead()\n\t}\n\t_ = v.(io.Reader)\n\nThe Read method in v has a different signature than the Read method in\nio.Reader, so this assertion cannot succeed.\n",
-			Default: true,
-		},
-		{
-			Name:    "infertypeargs",
-			Doc:     "check for unnecessary type arguments in call expressions\n\nExplicit type arguments may be omitted from call expressions if they can be\ninferred from function arguments, or from other type arguments:\n\n\tfunc f[T any](T) {}\n\t\n\tfunc _() {\n\t\tf[string](\"foo\") // string could be inferred\n\t}\n",
-			Default: true,
-		},
-		{
-			Name:    "loopclosure",
-			Doc:     "check references to loop variables from within nested functions\n\nThis analyzer reports places where a function literal references the\niteration variable of an enclosing loop, and the loop calls the function\nin such a way (e.g. with go or defer) that it may outlive the loop\niteration and possibly observe the wrong value of the variable.\n\nIn this example, all the deferred functions run after the loop has\ncompleted, so all observe the final value of v.\n\n    for _, v := range list {\n        defer func() {\n            use(v) // incorrect\n        }()\n    }\n\nOne fix is to create a new variable for each iteration of the loop:\n\n    for _, v := range list {\n        v := v // new var per iteration\n        defer func() {\n            use(v) // ok\n        }()\n    }\n\nThe next example uses a go statement and has a similar problem.\nIn addition, it has a data race because the loop updates v\nconcurrent with the goroutines accessing it.\n\n    for _, v := range elem {\n        go func() {\n            use(v)  // incorrect, and a data race\n        }()\n    }\n\nA fix is the same as before. The checker also reports problems\nin goroutines started by golang.org/x/sync/errgroup.Group.\nA hard-to-spot variant of this form is common in parallel tests:\n\n    func Test(t *testing.T) {\n        for _, test := range tests {\n            t.Run(test.name, func(t *testing.T) {\n                t.Parallel()\n                use(test) // incorrect, and a data race\n            })\n        }\n    }\n\nThe t.Parallel() call causes the rest of the function to execute\nconcurrent with the loop.\n\nThe analyzer reports references only in the last statement,\nas it is not deep enough to understand the effects of subsequent\nstatements that might render the reference benign.\n(\"Last statement\" is defined recursively in compound\nstatements such as if, switch, and select.)\n\nSee: https://golang.org/doc/go_faq.html#closures_and_goroutines",
-			Default: true,
-		},
-		{
-			Name:    "lostcancel",
-			Doc:     "check cancel func returned by context.WithCancel is called\n\nThe cancellation function returned by context.WithCancel, WithTimeout,\nand WithDeadline must be called or the new context will remain live\nuntil its parent context is cancelled.\n(The background context is never cancelled.)",
-			Default: true,
-		},
-		{
-			Name:    "nilfunc",
-			Doc:     "check for useless comparisons between functions and nil\n\nA useless comparison is one like f == nil as opposed to f() == nil.",
-			Default: true,
-		},
-		{
-			Name: "nilness",
-			Doc:  "check for redundant or impossible nil comparisons\n\nThe nilness checker inspects the control-flow graph of each function in\na package and reports nil pointer dereferences, degenerate nil\npointers, and panics with nil values. A degenerate comparison is of the form\nx==nil or x!=nil where x is statically known to be nil or non-nil. These are\noften a mistake, especially in control flow related to errors. Panics with nil\nvalues are checked because they are not detectable by\n\n\tif r := recover(); r != nil {\n\nThis check reports conditions such as:\n\n\tif f == nil { // impossible condition (f is a function)\n\t}\n\nand:\n\n\tp := &v\n\t...\n\tif p != nil { // tautological condition\n\t}\n\nand:\n\n\tif p == nil {\n\t\tprint(*p) // nil dereference\n\t}\n\nand:\n\n\tif p == nil {\n\t\tpanic(p)\n\t}\n",
-		},
-		{
-			Name:    "printf",
-			Doc:     "check consistency of Printf format strings and arguments\n\nThe check applies to known functions (for example, those in package fmt)\nas well as any detected wrappers of known functions.\n\nA function that wants to avail itself of printf checking but is not\nfound by this analyzer's heuristics (for example, due to use of\ndynamic calls) can insert a bogus call:\n\n\tif false {\n\t\t_ = fmt.Sprintf(format, args...) // enable printf checking\n\t}\n\nThe -funcs flag specifies a comma-separated list of names of additional\nknown formatting functions or methods. If the name contains a period,\nit must denote a specific function using one of the following forms:\n\n\tdir/pkg.Function\n\tdir/pkg.Type.Method\n\t(*dir/pkg.Type).Method\n\nOtherwise the name is interpreted as a case-insensitive unqualified\nidentifier such as \"errorf\". Either way, if a listed name ends in f, the\nfunction is assumed to be Printf-like, taking a format string before the\nargument list. Otherwise it is assumed to be Print-like, taking a list\nof arguments with no format string.\n",
-			Default: true,
-		},
-		{
-			Name: "shadow",
-			Doc:  "check for possible unintended shadowing of variables\n\nThis analyzer check for shadowed variables.\nA shadowed variable is a variable declared in an inner scope\nwith the same name and type as a variable in an outer scope,\nand where the outer variable is mentioned after the inner one\nis declared.\n\n(This definition can be refined; the module generates too many\nfalse positives and is not yet enabled by default.)\n\nFor example:\n\n\tfunc BadRead(f *os.File, buf []byte) error {\n\t\tvar err error\n\t\tfor {\n\t\t\tn, err := f.Read(buf) // shadows the function variable 'err'\n\t\t\tif err != nil {\n\t\t\t\tbreak // causes return of wrong value\n\t\t\t}\n\t\t\tfoo(buf)\n\t\t}\n\t\treturn err\n\t}\n",
-		},
-		{
-			Name:    "shift",
-			Doc:     "check for shifts that equal or exceed the width of the integer",
-			Default: true,
-		},
-		{
-			Name:    "simplifycompositelit",
-			Doc:     "check for composite literal simplifications\n\nAn array, slice, or map composite literal of the form:\n\t[]T{T{}, T{}}\nwill be simplified to:\n\t[]T{{}, {}}\n\nThis is one of the simplifications that \"gofmt -s\" applies.",
-			Default: true,
-		},
-		{
-			Name:    "simplifyrange",
-			Doc:     "check for range statement simplifications\n\nA range of the form:\n\tfor x, _ = range v {...}\nwill be simplified to:\n\tfor x = range v {...}\n\nA range of the form:\n\tfor _ = range v {...}\nwill be simplified to:\n\tfor range v {...}\n\nThis is one of the simplifications that \"gofmt -s\" applies.",
-			Default: true,
-		},
-		{
-			Name:    "simplifyslice",
-			Doc:     "check for slice simplifications\n\nA slice expression of the form:\n\ts[a:len(s)]\nwill be simplified to:\n\ts[a:]\n\nThis is one of the simplifications that \"gofmt -s\" applies.",
-			Default: true,
-		},
-		{
-			Name:    "sortslice",
-			Doc:     "check the argument type of sort.Slice\n\nsort.Slice requires an argument of a slice type. Check that\nthe interface{} value passed to sort.Slice is actually a slice.",
-			Default: true,
-		},
-		{
-			Name:    "stdmethods",
-			Doc:     "check signature of methods of well-known interfaces\n\nSometimes a type may be intended to satisfy an interface but may fail to\ndo so because of a mistake in its method signature.\nFor example, the result of this WriteTo method should be (int64, error),\nnot error, to satisfy io.WriterTo:\n\n\ttype myWriterTo struct{...}\n        func (myWriterTo) WriteTo(w io.Writer) error { ... }\n\nThis check ensures that each method whose name matches one of several\nwell-known interface methods from the standard library has the correct\nsignature for that interface.\n\nChecked method names include:\n\tFormat GobEncode GobDecode MarshalJSON MarshalXML\n\tPeek ReadByte ReadFrom ReadRune Scan Seek\n\tUnmarshalJSON UnreadByte UnreadRune WriteByte\n\tWriteTo\n",
-			Default: true,
-		},
-		{
-			Name:    "stringintconv",
-			Doc:     "check for string(int) conversions\n\nThis checker flags conversions of the form string(x) where x is an integer\n(but not byte or rune) type. Such conversions are discouraged because they\nreturn the UTF-8 representation of the Unicode code point x, and not a decimal\nstring representation of x as one might expect. Furthermore, if x denotes an\ninvalid code point, the conversion cannot be statically rejected.\n\nFor conversions that intend on using the code point, consider replacing them\nwith string(rune(x)). Otherwise, strconv.Itoa and its equivalents return the\nstring representation of the value in the desired base.\n",
-			Default: true,
-		},
-		{
-			Name:    "structtag",
-			Doc:     "check that struct field tags conform to reflect.StructTag.Get\n\nAlso report certain struct tags (json, xml) used with unexported fields.",
-			Default: true,
-		},
-		{
-			Name:    "testinggoroutine",
-			Doc:     "report calls to (*testing.T).Fatal from goroutines started by a test.\n\nFunctions that abruptly terminate a test, such as the Fatal, Fatalf, FailNow, and\nSkip{,f,Now} methods of *testing.T, must be called from the test goroutine itself.\nThis checker detects calls to these functions that occur within a goroutine\nstarted by the test. For example:\n\nfunc TestFoo(t *testing.T) {\n    go func() {\n        t.Fatal(\"oops\") // error: (*T).Fatal called from non-test goroutine\n    }()\n}\n",
-			Default: true,
-		},
-		{
-			Name:    "tests",
-			Doc:     "check for common mistaken usages of tests and examples\n\nThe tests checker walks Test, Benchmark and Example functions checking\nmalformed names, wrong signatures and examples documenting non-existent\nidentifiers.\n\nPlease see the documentation for package testing in golang.org/pkg/testing\nfor the conventions that are enforced for Tests, Benchmarks, and Examples.",
-			Default: true,
-		},
-		{
-			Name:    "timeformat",
-			Doc:     "check for calls of (time.Time).Format or time.Parse with 2006-02-01\n\nThe timeformat checker looks for time formats with the 2006-02-01 (yyyy-dd-mm)\nformat. Internationally, \"yyyy-dd-mm\" does not occur in common calendar date\nstandards, and so it is more likely that 2006-01-02 (yyyy-mm-dd) was intended.\n",
-			Default: true,
-		},
-		{
-			Name:    "unmarshal",
-			Doc:     "report passing non-pointer or non-interface values to unmarshal\n\nThe unmarshal analysis reports calls to functions such as json.Unmarshal\nin which the argument type is not a pointer or an interface.",
-			Default: true,
-		},
-		{
-			Name:    "unreachable",
-			Doc:     "check for unreachable code\n\nThe unreachable analyzer finds statements that execution can never reach\nbecause they are preceded by an return statement, a call to panic, an\ninfinite loop, or similar constructs.",
-			Default: true,
-		},
-		{
-			Name:    "unsafeptr",
-			Doc:     "check for invalid conversions of uintptr to unsafe.Pointer\n\nThe unsafeptr analyzer reports likely incorrect uses of unsafe.Pointer\nto convert integers to pointers. A conversion from uintptr to\nunsafe.Pointer is invalid if it implies that there is a uintptr-typed\nword in memory that holds a pointer value, because that word will be\ninvisible to stack copying and to the garbage collector.",
-			Default: true,
-		},
-		{
-			Name: "unusedparams",
-			Doc:  "check for unused parameters of functions\n\nThe unusedparams analyzer checks functions to see if there are\nany parameters that are not being used.\n\nTo reduce false positives it ignores:\n- methods\n- parameters that do not have a name or are underscored\n- functions in test files\n- functions with empty bodies or those with just a return stmt",
-		},
-		{
-			Name:    "unusedresult",
-			Doc:     "check for unused results of calls to some functions\n\nSome functions like fmt.Errorf return a result and have no side effects,\nso it is always a mistake to discard the result. This analyzer reports\ncalls to certain functions in which the result of the call is ignored.\n\nThe set of functions may be controlled using flags.",
-			Default: true,
-		},
-		{
-			Name: "unusedwrite",
-			Doc:  "checks for unused writes\n\nThe analyzer reports instances of writes to struct fields and\narrays that are never read. Specifically, when a struct object\nor an array is copied, its elements are copied implicitly by\nthe compiler, and any element write to this copy does nothing\nwith the original object.\n\nFor example:\n\n\ttype T struct { x int }\n\tfunc f(input []T) {\n\t\tfor i, v := range input {  // v is a copy\n\t\t\tv.x = i  // unused write to field x\n\t\t}\n\t}\n\nAnother example is about non-pointer receiver:\n\n\ttype T struct { x int }\n\tfunc (t T) f() {  // t is a copy\n\t\tt.x = i  // unused write to field x\n\t}\n",
-		},
-		{
-			Name: "useany",
-			Doc:  "check for constraints that could be simplified to \"any\"",
-		},
-		{
-			Name:    "fillreturns",
-			Doc:     "suggest fixes for errors due to an incorrect number of return values\n\nThis checker provides suggested fixes for type errors of the\ntype \"wrong number of return values (want %d, got %d)\". For example:\n\tfunc m() (int, string, *bool, error) {\n\t\treturn\n\t}\nwill turn into\n\tfunc m() (int, string, *bool, error) {\n\t\treturn 0, \"\", nil, nil\n\t}\n\nThis functionality is similar to https://github.com/sqs/goreturns.\n",
-			Default: true,
-		},
-		{
-			Name:    "nonewvars",
-			Doc:     "suggested fixes for \"no new vars on left side of :=\"\n\nThis checker provides suggested fixes for type errors of the\ntype \"no new vars on left side of :=\". For example:\n\tz := 1\n\tz := 2\nwill turn into\n\tz := 1\n\tz = 2\n",
-			Default: true,
-		},
-		{
-			Name:    "noresultvalues",
-			Doc:     "suggested fixes for unexpected return values\n\nThis checker provides suggested fixes for type errors of the\ntype \"no result values expected\" or \"too many return values\".\nFor example:\n\tfunc z() { return nil }\nwill turn into\n\tfunc z() { return }\n",
-			Default: true,
-		},
-		{
-			Name:    "undeclaredname",
-			Doc:     "suggested fixes for \"undeclared name: <>\"\n\nThis checker provides suggested fixes for type errors of the\ntype \"undeclared name: <>\". It will either insert a new statement,\nsuch as:\n\n\"<> := \"\n\nor a new function declaration, such as:\n\nfunc <>(inferred parameters) {\n\tpanic(\"implement me!\")\n}\n",
-			Default: true,
-		},
-		{
-			Name: "unusedvariable",
-			Doc:  "check for unused variables\n\nThe unusedvariable analyzer suggests fixes for unused variables errors.\n",
-		},
-		{
-			Name:    "fillstruct",
-			Doc:     "note incomplete struct initializations\n\nThis analyzer provides diagnostics for any struct literals that do not have\nany fields initialized. Because the suggested fix for this analysis is\nexpensive to compute, callers should compute it separately, using the\nSuggestedFix function below.\n",
-			Default: true,
-		},
-		{
-			Name:    "stubmethods",
-			Doc:     "stub methods analyzer\n\nThis analyzer generates method stubs for concrete types\nin order to implement a target interface",
-			Default: true,
-		},
-	},
-	Hints: []*HintJSON{
-		{
-			Name: "assignVariableTypes",
-			Doc:  "Enable/disable inlay hints for variable types in assign statements:\n```go\n\ti/* int*/, j/* int*/ := 0, len(r)-1\n```",
-		},
-		{
-			Name: "compositeLiteralFields",
-			Doc:  "Enable/disable inlay hints for composite literal field names:\n```go\n\t{/*in: */\"Hello, world\", /*want: */\"dlrow ,olleH\"}\n```",
-		},
-		{
-			Name: "compositeLiteralTypes",
-			Doc:  "Enable/disable inlay hints for composite literal types:\n```go\n\tfor _, c := range []struct {\n\t\tin, want string\n\t}{\n\t\t/*struct{ in string; want string }*/{\"Hello, world\", \"dlrow ,olleH\"},\n\t}\n```",
-		},
-		{
-			Name: "constantValues",
-			Doc:  "Enable/disable inlay hints for constant values:\n```go\n\tconst (\n\t\tKindNone   Kind = iota/* = 0*/\n\t\tKindPrint/*  = 1*/\n\t\tKindPrintf/* = 2*/\n\t\tKindErrorf/* = 3*/\n\t)\n```",
-		},
-		{
-			Name: "functionTypeParameters",
-			Doc:  "Enable/disable inlay hints for implicit type parameters on generic functions:\n```go\n\tmyFoo/*[int, string]*/(1, \"hello\")\n```",
-		},
-		{
-			Name: "parameterNames",
-			Doc:  "Enable/disable inlay hints for parameter names:\n```go\n\tparseInt(/* str: */ \"123\", /* radix: */ 8)\n```",
-		},
-		{
-			Name: "rangeVariableTypes",
-			Doc:  "Enable/disable inlay hints for variable types in range statements:\n```go\n\tfor k/* int*/, v/* string*/ := range []string{} {\n\t\tfmt.Println(k, v)\n\t}\n```",
-		},
-	},
-}
diff -urN a/gopls/internal/lsp/source/call_hierarchy.go b/gopls/internal/lsp/source/call_hierarchy.go
--- a/gopls/internal/lsp/source/call_hierarchy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/call_hierarchy.go	1969-12-31 16:00:00
@@ -1,308 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"path/filepath"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-// PrepareCallHierarchy returns an array of CallHierarchyItem for a file and the position within the file.
-func PrepareCallHierarchy(ctx context.Context, snapshot Snapshot, fh FileHandle, pos protocol.Position) ([]protocol.CallHierarchyItem, error) {
-	ctx, done := event.Start(ctx, "source.PrepareCallHierarchy")
-	defer done()
-
-	identifier, err := Identifier(ctx, snapshot, fh, pos)
-	if err != nil {
-		if errors.Is(err, ErrNoIdentFound) || errors.Is(err, errNoObjectFound) {
-			return nil, nil
-		}
-		return nil, err
-	}
-
-	// The identifier can be nil if it is an import spec.
-	if identifier == nil || identifier.Declaration.obj == nil {
-		return nil, nil
-	}
-
-	if _, ok := identifier.Declaration.obj.Type().Underlying().(*types.Signature); !ok {
-		return nil, nil
-	}
-
-	if len(identifier.Declaration.MappedRange) == 0 {
-		return nil, nil
-	}
-	declMappedRange := identifier.Declaration.MappedRange[0]
-	rng, err := declMappedRange.Range()
-	if err != nil {
-		return nil, err
-	}
-
-	callHierarchyItem := protocol.CallHierarchyItem{
-		Name:           identifier.Name,
-		Kind:           protocol.Function,
-		Tags:           []protocol.SymbolTag{},
-		Detail:         fmt.Sprintf("%s • %s", identifier.Declaration.obj.Pkg().Path(), filepath.Base(declMappedRange.URI().Filename())),
-		URI:            protocol.DocumentURI(declMappedRange.URI()),
-		Range:          rng,
-		SelectionRange: rng,
-	}
-	return []protocol.CallHierarchyItem{callHierarchyItem}, nil
-}
-
-// IncomingCalls returns an array of CallHierarchyIncomingCall for a file and the position within the file.
-func IncomingCalls(ctx context.Context, snapshot Snapshot, fh FileHandle, pos protocol.Position) ([]protocol.CallHierarchyIncomingCall, error) {
-	ctx, done := event.Start(ctx, "source.IncomingCalls")
-	defer done()
-
-	refs, err := References(ctx, snapshot, fh, pos, false)
-	if err != nil {
-		if errors.Is(err, ErrNoIdentFound) || errors.Is(err, errNoObjectFound) {
-			return nil, nil
-		}
-		return nil, err
-	}
-
-	return toProtocolIncomingCalls(ctx, snapshot, refs)
-}
-
-// toProtocolIncomingCalls returns an array of protocol.CallHierarchyIncomingCall for ReferenceInfo's.
-// References inside same enclosure are assigned to the same enclosing function.
-func toProtocolIncomingCalls(ctx context.Context, snapshot Snapshot, refs []*ReferenceInfo) ([]protocol.CallHierarchyIncomingCall, error) {
-	// an enclosing node could have multiple calls to a reference, we only show the enclosure
-	// once in the result but highlight all calls using FromRanges (ranges at which the calls occur)
-	var incomingCalls = map[protocol.Location]*protocol.CallHierarchyIncomingCall{}
-	for _, ref := range refs {
-		refRange, err := ref.Range()
-		if err != nil {
-			return nil, err
-		}
-
-		callItem, err := enclosingNodeCallItem(snapshot, ref.pkg, ref.URI(), ref.ident.NamePos)
-		if err != nil {
-			event.Error(ctx, "error getting enclosing node", err, tag.Method.Of(ref.Name))
-			continue
-		}
-
-		loc := protocol.Location{
-			URI:   callItem.URI,
-			Range: callItem.Range,
-		}
-		call, ok := incomingCalls[loc]
-		if !ok {
-			call = &protocol.CallHierarchyIncomingCall{From: callItem}
-			incomingCalls[loc] = call
-		}
-		call.FromRanges = append(call.FromRanges, refRange)
-	}
-
-	incomingCallItems := make([]protocol.CallHierarchyIncomingCall, 0, len(incomingCalls))
-	for _, callItem := range incomingCalls {
-		incomingCallItems = append(incomingCallItems, *callItem)
-	}
-	return incomingCallItems, nil
-}
-
-// enclosingNodeCallItem creates a CallHierarchyItem representing the function call at pos
-func enclosingNodeCallItem(snapshot Snapshot, pkg Package, uri span.URI, pos token.Pos) (protocol.CallHierarchyItem, error) {
-	pgf, err := pkg.File(uri)
-	if err != nil {
-		return protocol.CallHierarchyItem{}, err
-	}
-
-	var funcDecl *ast.FuncDecl
-	var funcLit *ast.FuncLit // innermost function literal
-	var litCount int
-	// Find the enclosing function, if any, and the number of func literals in between.
-	path, _ := astutil.PathEnclosingInterval(pgf.File, pos, pos)
-outer:
-	for _, node := range path {
-		switch n := node.(type) {
-		case *ast.FuncDecl:
-			funcDecl = n
-			break outer
-		case *ast.FuncLit:
-			litCount++
-			if litCount > 1 {
-				continue
-			}
-			funcLit = n
-		}
-	}
-
-	nameIdent := path[len(path)-1].(*ast.File).Name
-	kind := protocol.Package
-	if funcDecl != nil {
-		nameIdent = funcDecl.Name
-		kind = protocol.Function
-	}
-
-	nameStart, nameEnd := nameIdent.Pos(), nameIdent.End()
-	if funcLit != nil {
-		nameStart, nameEnd = funcLit.Type.Func, funcLit.Type.Params.Pos()
-		kind = protocol.Function
-	}
-	rng, err := NewMappedRange(pgf.Mapper, nameStart, nameEnd).Range()
-	if err != nil {
-		return protocol.CallHierarchyItem{}, err
-	}
-
-	name := nameIdent.Name
-	for i := 0; i < litCount; i++ {
-		name += ".func()"
-	}
-
-	return protocol.CallHierarchyItem{
-		Name:           name,
-		Kind:           kind,
-		Tags:           []protocol.SymbolTag{},
-		Detail:         fmt.Sprintf("%s • %s", pkg.PkgPath(), filepath.Base(uri.Filename())),
-		URI:            protocol.DocumentURI(uri),
-		Range:          rng,
-		SelectionRange: rng,
-	}, nil
-}
-
-// OutgoingCalls returns an array of CallHierarchyOutgoingCall for a file and the position within the file.
-func OutgoingCalls(ctx context.Context, snapshot Snapshot, fh FileHandle, pos protocol.Position) ([]protocol.CallHierarchyOutgoingCall, error) {
-	ctx, done := event.Start(ctx, "source.OutgoingCalls")
-	defer done()
-
-	identifier, err := Identifier(ctx, snapshot, fh, pos)
-	if err != nil {
-		if errors.Is(err, ErrNoIdentFound) || errors.Is(err, errNoObjectFound) {
-			return nil, nil
-		}
-		return nil, err
-	}
-
-	if _, ok := identifier.Declaration.obj.Type().Underlying().(*types.Signature); !ok {
-		return nil, nil
-	}
-	node := identifier.Declaration.node
-	if node == nil {
-		return nil, nil
-	}
-	if len(identifier.Declaration.MappedRange) == 0 {
-		return nil, nil
-	}
-	callExprs, err := collectCallExpressions(identifier.Declaration.MappedRange[0].m, node)
-	if err != nil {
-		return nil, err
-	}
-
-	return toProtocolOutgoingCalls(ctx, snapshot, fh, callExprs)
-}
-
-// collectCallExpressions collects call expression ranges inside a function.
-func collectCallExpressions(mapper *protocol.ColumnMapper, node ast.Node) ([]protocol.Range, error) {
-	type callPos struct {
-		start, end token.Pos
-	}
-	callPositions := []callPos{}
-
-	ast.Inspect(node, func(n ast.Node) bool {
-		if call, ok := n.(*ast.CallExpr); ok {
-			var start, end token.Pos
-			switch n := call.Fun.(type) {
-			case *ast.SelectorExpr:
-				start, end = n.Sel.NamePos, call.Lparen
-			case *ast.Ident:
-				start, end = n.NamePos, call.Lparen
-			case *ast.FuncLit:
-				// while we don't add the function literal as an 'outgoing' call
-				// we still want to traverse into it
-				return true
-			default:
-				// ignore any other kind of call expressions
-				// for ex: direct function literal calls since that's not an 'outgoing' call
-				return false
-			}
-			callPositions = append(callPositions, callPos{start: start, end: end})
-		}
-		return true
-	})
-
-	callRanges := []protocol.Range{}
-	for _, call := range callPositions {
-		callRange, err := NewMappedRange(mapper, call.start, call.end).Range()
-		if err != nil {
-			return nil, err
-		}
-		callRanges = append(callRanges, callRange)
-	}
-	return callRanges, nil
-}
-
-// toProtocolOutgoingCalls returns an array of protocol.CallHierarchyOutgoingCall for ast call expressions.
-// Calls to the same function are assigned to the same declaration.
-func toProtocolOutgoingCalls(ctx context.Context, snapshot Snapshot, fh FileHandle, callRanges []protocol.Range) ([]protocol.CallHierarchyOutgoingCall, error) {
-	// Multiple calls could be made to the same function, defined by "same declaration
-	// AST node & same identifier name" to provide a unique identifier key even when
-	// the func is declared in a struct or interface.
-	type key struct {
-		decl ast.Node
-		name string
-	}
-	outgoingCalls := map[key]*protocol.CallHierarchyOutgoingCall{}
-	for _, callRange := range callRanges {
-		identifier, err := Identifier(ctx, snapshot, fh, callRange.Start)
-		if err != nil {
-			if errors.Is(err, ErrNoIdentFound) || errors.Is(err, errNoObjectFound) {
-				continue
-			}
-			return nil, err
-		}
-
-		// ignore calls to builtin functions
-		if identifier.Declaration.obj.Pkg() == nil {
-			continue
-		}
-
-		if outgoingCall, ok := outgoingCalls[key{identifier.Declaration.node, identifier.Name}]; ok {
-			outgoingCall.FromRanges = append(outgoingCall.FromRanges, callRange)
-			continue
-		}
-
-		if len(identifier.Declaration.MappedRange) == 0 {
-			continue
-		}
-		declMappedRange := identifier.Declaration.MappedRange[0]
-		rng, err := declMappedRange.Range()
-		if err != nil {
-			return nil, err
-		}
-
-		outgoingCalls[key{identifier.Declaration.node, identifier.Name}] = &protocol.CallHierarchyOutgoingCall{
-			To: protocol.CallHierarchyItem{
-				Name:           identifier.Name,
-				Kind:           protocol.Function,
-				Tags:           []protocol.SymbolTag{},
-				Detail:         fmt.Sprintf("%s • %s", identifier.Declaration.obj.Pkg().Path(), filepath.Base(declMappedRange.URI().Filename())),
-				URI:            protocol.DocumentURI(declMappedRange.URI()),
-				Range:          rng,
-				SelectionRange: rng,
-			},
-			FromRanges: []protocol.Range{callRange},
-		}
-	}
-
-	outgoingCallItems := make([]protocol.CallHierarchyOutgoingCall, 0, len(outgoingCalls))
-	for _, callItem := range outgoingCalls {
-		outgoingCallItems = append(outgoingCallItems, *callItem)
-	}
-	return outgoingCallItems, nil
-}
diff -urN a/gopls/internal/lsp/source/code_lens.go b/gopls/internal/lsp/source/code_lens.go
--- a/gopls/internal/lsp/source/code_lens.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/code_lens.go	1969-12-31 16:00:00
@@ -1,248 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"path/filepath"
-	"regexp"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-type LensFunc func(context.Context, Snapshot, FileHandle) ([]protocol.CodeLens, error)
-
-// LensFuncs returns the supported lensFuncs for Go files.
-func LensFuncs() map[command.Command]LensFunc {
-	return map[command.Command]LensFunc{
-		command.Generate:      goGenerateCodeLens,
-		command.Test:          runTestCodeLens,
-		command.RegenerateCgo: regenerateCgoLens,
-		command.GCDetails:     toggleDetailsCodeLens,
-	}
-}
-
-var (
-	testRe      = regexp.MustCompile("^Test[^a-z]")
-	benchmarkRe = regexp.MustCompile("^Benchmark[^a-z]")
-)
-
-func runTestCodeLens(ctx context.Context, snapshot Snapshot, fh FileHandle) ([]protocol.CodeLens, error) {
-	codeLens := make([]protocol.CodeLens, 0)
-
-	fns, err := TestsAndBenchmarks(ctx, snapshot, fh)
-	if err != nil {
-		return nil, err
-	}
-	puri := protocol.URIFromSpanURI(fh.URI())
-	for _, fn := range fns.Tests {
-		cmd, err := command.NewTestCommand("run test", puri, []string{fn.Name}, nil)
-		if err != nil {
-			return nil, err
-		}
-		rng := protocol.Range{Start: fn.Rng.Start, End: fn.Rng.Start}
-		codeLens = append(codeLens, protocol.CodeLens{Range: rng, Command: cmd})
-	}
-
-	for _, fn := range fns.Benchmarks {
-		cmd, err := command.NewTestCommand("run benchmark", puri, nil, []string{fn.Name})
-		if err != nil {
-			return nil, err
-		}
-		rng := protocol.Range{Start: fn.Rng.Start, End: fn.Rng.Start}
-		codeLens = append(codeLens, protocol.CodeLens{Range: rng, Command: cmd})
-	}
-
-	if len(fns.Benchmarks) > 0 {
-		pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-		if err != nil {
-			return nil, err
-		}
-		// add a code lens to the top of the file which runs all benchmarks in the file
-		rng, err := NewMappedRange(pgf.Mapper, pgf.File.Package, pgf.File.Package).Range()
-		if err != nil {
-			return nil, err
-		}
-		var benches []string
-		for _, fn := range fns.Benchmarks {
-			benches = append(benches, fn.Name)
-		}
-		cmd, err := command.NewTestCommand("run file benchmarks", puri, nil, benches)
-		if err != nil {
-			return nil, err
-		}
-		codeLens = append(codeLens, protocol.CodeLens{Range: rng, Command: cmd})
-	}
-	return codeLens, nil
-}
-
-type testFn struct {
-	Name string
-	Rng  protocol.Range
-}
-
-type testFns struct {
-	Tests      []testFn
-	Benchmarks []testFn
-}
-
-func TestsAndBenchmarks(ctx context.Context, snapshot Snapshot, fh FileHandle) (testFns, error) {
-	var out testFns
-
-	if !strings.HasSuffix(fh.URI().Filename(), "_test.go") {
-		return out, nil
-	}
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckWorkspace, WidestPackage)
-	if err != nil {
-		return out, err
-	}
-
-	for _, d := range pgf.File.Decls {
-		fn, ok := d.(*ast.FuncDecl)
-		if !ok {
-			continue
-		}
-
-		rng, err := NewMappedRange(pgf.Mapper, fn.Pos(), fn.End()).Range()
-		if err != nil {
-			return out, err
-		}
-
-		if matchTestFunc(fn, pkg, testRe, "T") {
-			out.Tests = append(out.Tests, testFn{fn.Name.Name, rng})
-		}
-
-		if matchTestFunc(fn, pkg, benchmarkRe, "B") {
-			out.Benchmarks = append(out.Benchmarks, testFn{fn.Name.Name, rng})
-		}
-	}
-
-	return out, nil
-}
-
-func matchTestFunc(fn *ast.FuncDecl, pkg Package, nameRe *regexp.Regexp, paramID string) bool {
-	// Make sure that the function name matches a test function.
-	if !nameRe.MatchString(fn.Name.Name) {
-		return false
-	}
-	info := pkg.GetTypesInfo()
-	if info == nil {
-		return false
-	}
-	obj := info.ObjectOf(fn.Name)
-	if obj == nil {
-		return false
-	}
-	sig, ok := obj.Type().(*types.Signature)
-	if !ok {
-		return false
-	}
-	// Test functions should have only one parameter.
-	if sig.Params().Len() != 1 {
-		return false
-	}
-
-	// Check the type of the only parameter
-	paramTyp, ok := sig.Params().At(0).Type().(*types.Pointer)
-	if !ok {
-		return false
-	}
-	named, ok := paramTyp.Elem().(*types.Named)
-	if !ok {
-		return false
-	}
-	namedObj := named.Obj()
-	if namedObj.Pkg().Path() != "testing" {
-		return false
-	}
-	return namedObj.Id() == paramID
-}
-
-func goGenerateCodeLens(ctx context.Context, snapshot Snapshot, fh FileHandle) ([]protocol.CodeLens, error) {
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, err
-	}
-	const ggDirective = "//go:generate"
-	for _, c := range pgf.File.Comments {
-		for _, l := range c.List {
-			if !strings.HasPrefix(l.Text, ggDirective) {
-				continue
-			}
-			rng, err := NewMappedRange(pgf.Mapper, l.Pos(), l.Pos()+token.Pos(len(ggDirective))).Range()
-			if err != nil {
-				return nil, err
-			}
-			dir := protocol.URIFromSpanURI(span.URIFromPath(filepath.Dir(fh.URI().Filename())))
-			nonRecursiveCmd, err := command.NewGenerateCommand("run go generate", command.GenerateArgs{Dir: dir, Recursive: false})
-			if err != nil {
-				return nil, err
-			}
-			recursiveCmd, err := command.NewGenerateCommand("run go generate ./...", command.GenerateArgs{Dir: dir, Recursive: true})
-			if err != nil {
-				return nil, err
-			}
-			return []protocol.CodeLens{
-				{Range: rng, Command: recursiveCmd},
-				{Range: rng, Command: nonRecursiveCmd},
-			}, nil
-
-		}
-	}
-	return nil, nil
-}
-
-func regenerateCgoLens(ctx context.Context, snapshot Snapshot, fh FileHandle) ([]protocol.CodeLens, error) {
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, err
-	}
-	var c *ast.ImportSpec
-	for _, imp := range pgf.File.Imports {
-		if imp.Path.Value == `"C"` {
-			c = imp
-		}
-	}
-	if c == nil {
-		return nil, nil
-	}
-	rng, err := NewMappedRange(pgf.Mapper, c.Pos(), c.End()).Range()
-	if err != nil {
-		return nil, err
-	}
-	puri := protocol.URIFromSpanURI(fh.URI())
-	cmd, err := command.NewRegenerateCgoCommand("regenerate cgo definitions", command.URIArg{URI: puri})
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.CodeLens{{Range: rng, Command: cmd}}, nil
-}
-
-func toggleDetailsCodeLens(ctx context.Context, snapshot Snapshot, fh FileHandle) ([]protocol.CodeLens, error) {
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, err
-	}
-	if !pgf.File.Package.IsValid() {
-		// Without a package name we have nowhere to put the codelens, so give up.
-		return nil, nil
-	}
-	rng, err := NewMappedRange(pgf.Mapper, pgf.File.Package, pgf.File.Package).Range()
-	if err != nil {
-		return nil, err
-	}
-	puri := protocol.URIFromSpanURI(fh.URI())
-	cmd, err := command.NewGCDetailsCommand("Toggle gc annotation details", puri)
-	if err != nil {
-		return nil, err
-	}
-	return []protocol.CodeLens{{Range: rng, Command: cmd}}, nil
-}
diff -urN a/gopls/internal/lsp/source/comment.go b/gopls/internal/lsp/source/comment.go
--- a/gopls/internal/lsp/source/comment.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/comment.go	1969-12-31 16:00:00
@@ -1,384 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.19
-// +build !go1.19
-
-package source
-
-import (
-	"bytes"
-	"io"
-	"regexp"
-	"strings"
-	"unicode"
-	"unicode/utf8"
-)
-
-// CommentToMarkdown converts comment text to formatted markdown.
-// The comment was prepared by DocReader,
-// so it is known not to have leading, trailing blank lines
-// nor to have trailing spaces at the end of lines.
-// The comment markers have already been removed.
-//
-// Each line is converted into a markdown line and empty lines are just converted to
-// newlines. Heading are prefixed with `### ` to make it a markdown heading.
-//
-// A span of indented lines retains a 4 space prefix block, with the common indent
-// prefix removed unless empty, in which case it will be converted to a newline.
-//
-// URLs in the comment text are converted into links.
-func CommentToMarkdown(text string) string {
-	buf := &bytes.Buffer{}
-	commentToMarkdown(buf, text)
-	return buf.String()
-}
-
-var (
-	mdNewline   = []byte("\n")
-	mdHeader    = []byte("### ")
-	mdIndent    = []byte("    ")
-	mdLinkStart = []byte("[")
-	mdLinkDiv   = []byte("](")
-	mdLinkEnd   = []byte(")")
-)
-
-func commentToMarkdown(w io.Writer, text string) {
-	blocks := blocks(text)
-	for i, b := range blocks {
-		switch b.op {
-		case opPara:
-			for _, line := range b.lines {
-				emphasize(w, line, true)
-			}
-		case opHead:
-			// The header block can consist of only one line.
-			// However, check the number of lines, just in case.
-			if len(b.lines) == 0 {
-				// Skip this block.
-				continue
-			}
-			header := b.lines[0]
-
-			w.Write(mdHeader)
-			commentEscape(w, header, true)
-			// Header doesn't end with \n unlike the lines of other blocks.
-			w.Write(mdNewline)
-		case opPre:
-			for _, line := range b.lines {
-				if isBlank(line) {
-					w.Write(mdNewline)
-					continue
-				}
-				w.Write(mdIndent)
-				w.Write([]byte(line))
-			}
-		}
-
-		if i < len(blocks)-1 {
-			w.Write(mdNewline)
-		}
-	}
-}
-
-const (
-	ulquo = "“"
-	urquo = "”"
-)
-
-var (
-	markdownEscape = regexp.MustCompile(`([\\\x60*{}[\]()#+\-.!_>~|"$%&'\/:;<=?@^])`)
-
-	unicodeQuoteReplacer = strings.NewReplacer("``", ulquo, "''", urquo)
-)
-
-// commentEscape escapes comment text for markdown. If nice is set,
-// also turn double ` and ' into “ and ”.
-func commentEscape(w io.Writer, text string, nice bool) {
-	if nice {
-		text = convertQuotes(text)
-	}
-	text = escapeRegex(text)
-	w.Write([]byte(text))
-}
-
-func convertQuotes(text string) string {
-	return unicodeQuoteReplacer.Replace(text)
-}
-
-func escapeRegex(text string) string {
-	return markdownEscape.ReplaceAllString(text, `\$1`)
-}
-
-func emphasize(w io.Writer, line string, nice bool) {
-	for {
-		m := matchRx.FindStringSubmatchIndex(line)
-		if m == nil {
-			break
-		}
-		// m >= 6 (two parenthesized sub-regexps in matchRx, 1st one is urlRx)
-
-		// write text before match
-		commentEscape(w, line[0:m[0]], nice)
-
-		// adjust match for URLs
-		match := line[m[0]:m[1]]
-		if strings.Contains(match, "://") {
-			m0, m1 := m[0], m[1]
-			for _, s := range []string{"()", "{}", "[]"} {
-				open, close := s[:1], s[1:] // E.g., "(" and ")"
-				// require opening parentheses before closing parentheses (#22285)
-				if i := strings.Index(match, close); i >= 0 && i < strings.Index(match, open) {
-					m1 = m0 + i
-					match = line[m0:m1]
-				}
-				// require balanced pairs of parentheses (#5043)
-				for i := 0; strings.Count(match, open) != strings.Count(match, close) && i < 10; i++ {
-					m1 = strings.LastIndexAny(line[:m1], s)
-					match = line[m0:m1]
-				}
-			}
-			if m1 != m[1] {
-				// redo matching with shortened line for correct indices
-				m = matchRx.FindStringSubmatchIndex(line[:m[0]+len(match)])
-			}
-		}
-
-		// Following code has been modified from go/doc since words is always
-		// nil. All html formatting has also been transformed into markdown formatting
-
-		// analyze match
-		url := ""
-		if m[2] >= 0 {
-			url = match
-		}
-
-		// write match
-		if len(url) > 0 {
-			w.Write(mdLinkStart)
-		}
-
-		commentEscape(w, match, nice)
-
-		if len(url) > 0 {
-			w.Write(mdLinkDiv)
-			w.Write([]byte(urlReplacer.Replace(url)))
-			w.Write(mdLinkEnd)
-		}
-
-		// advance
-		line = line[m[1]:]
-	}
-	commentEscape(w, line, nice)
-}
-
-// Everything from here on is a copy of go/doc/comment.go
-
-const (
-	// Regexp for Go identifiers
-	identRx = `[\pL_][\pL_0-9]*`
-
-	// Regexp for URLs
-	// Match parens, and check later for balance - see #5043, #22285
-	// Match .,:;?! within path, but not at end - see #18139, #16565
-	// This excludes some rare yet valid urls ending in common punctuation
-	// in order to allow sentences ending in URLs.
-
-	// protocol (required) e.g. http
-	protoPart = `(https?|ftp|file|gopher|mailto|nntp)`
-	// host (required) e.g. www.example.com or [::1]:8080
-	hostPart = `([a-zA-Z0-9_@\-.\[\]:]+)`
-	// path+query+fragment (optional) e.g. /path/index.html?q=foo#bar
-	pathPart = `([.,:;?!]*[a-zA-Z0-9$'()*+&#=@~_/\-\[\]%])*`
-
-	urlRx = protoPart + `://` + hostPart + pathPart
-)
-
-var (
-	matchRx     = regexp.MustCompile(`(` + urlRx + `)|(` + identRx + `)`)
-	urlReplacer = strings.NewReplacer(`(`, `\(`, `)`, `\)`)
-)
-
-func indentLen(s string) int {
-	i := 0
-	for i < len(s) && (s[i] == ' ' || s[i] == '\t') {
-		i++
-	}
-	return i
-}
-
-func isBlank(s string) bool {
-	return len(s) == 0 || (len(s) == 1 && s[0] == '\n')
-}
-
-func commonPrefix(a, b string) string {
-	i := 0
-	for i < len(a) && i < len(b) && a[i] == b[i] {
-		i++
-	}
-	return a[0:i]
-}
-
-func unindent(block []string) {
-	if len(block) == 0 {
-		return
-	}
-
-	// compute maximum common white prefix
-	prefix := block[0][0:indentLen(block[0])]
-	for _, line := range block {
-		if !isBlank(line) {
-			prefix = commonPrefix(prefix, line)
-		}
-	}
-	n := len(prefix)
-
-	// remove
-	for i, line := range block {
-		if !isBlank(line) {
-			block[i] = line[n:]
-		}
-	}
-}
-
-// heading returns the trimmed line if it passes as a section heading;
-// otherwise it returns the empty string.
-func heading(line string) string {
-	line = strings.TrimSpace(line)
-	if len(line) == 0 {
-		return ""
-	}
-
-	// a heading must start with an uppercase letter
-	r, _ := utf8.DecodeRuneInString(line)
-	if !unicode.IsLetter(r) || !unicode.IsUpper(r) {
-		return ""
-	}
-
-	// it must end in a letter or digit:
-	r, _ = utf8.DecodeLastRuneInString(line)
-	if !unicode.IsLetter(r) && !unicode.IsDigit(r) {
-		return ""
-	}
-
-	// exclude lines with illegal characters. we allow "(),"
-	if strings.ContainsAny(line, ";:!?+*/=[]{}_^°&§~%#@<\">\\") {
-		return ""
-	}
-
-	// allow "'" for possessive "'s" only
-	for b := line; ; {
-		i := strings.IndexRune(b, '\'')
-		if i < 0 {
-			break
-		}
-		if i+1 >= len(b) || b[i+1] != 's' || (i+2 < len(b) && b[i+2] != ' ') {
-			return "" // not followed by "s "
-		}
-		b = b[i+2:]
-	}
-
-	// allow "." when followed by non-space
-	for b := line; ; {
-		i := strings.IndexRune(b, '.')
-		if i < 0 {
-			break
-		}
-		if i+1 >= len(b) || b[i+1] == ' ' {
-			return "" // not followed by non-space
-		}
-		b = b[i+1:]
-	}
-
-	return line
-}
-
-type op int
-
-const (
-	opPara op = iota
-	opHead
-	opPre
-)
-
-type block struct {
-	op    op
-	lines []string
-}
-
-func blocks(text string) []block {
-	var (
-		out  []block
-		para []string
-
-		lastWasBlank   = false
-		lastWasHeading = false
-	)
-
-	close := func() {
-		if para != nil {
-			out = append(out, block{opPara, para})
-			para = nil
-		}
-	}
-
-	lines := strings.SplitAfter(text, "\n")
-	unindent(lines)
-	for i := 0; i < len(lines); {
-		line := lines[i]
-		if isBlank(line) {
-			// close paragraph
-			close()
-			i++
-			lastWasBlank = true
-			continue
-		}
-		if indentLen(line) > 0 {
-			// close paragraph
-			close()
-
-			// count indented or blank lines
-			j := i + 1
-			for j < len(lines) && (isBlank(lines[j]) || indentLen(lines[j]) > 0) {
-				j++
-			}
-			// but not trailing blank lines
-			for j > i && isBlank(lines[j-1]) {
-				j--
-			}
-			pre := lines[i:j]
-			i = j
-
-			unindent(pre)
-
-			// put those lines in a pre block
-			out = append(out, block{opPre, pre})
-			lastWasHeading = false
-			continue
-		}
-
-		if lastWasBlank && !lastWasHeading && i+2 < len(lines) &&
-			isBlank(lines[i+1]) && !isBlank(lines[i+2]) && indentLen(lines[i+2]) == 0 {
-			// current line is non-blank, surrounded by blank lines
-			// and the next non-blank line is not indented: this
-			// might be a heading.
-			if head := heading(line); head != "" {
-				close()
-				out = append(out, block{opHead, []string{head}})
-				i += 2
-				lastWasHeading = true
-				continue
-			}
-		}
-
-		// open paragraph
-		lastWasBlank = false
-		lastWasHeading = false
-		para = append(para, lines[i])
-		i++
-	}
-	close()
-
-	return out
-}
diff -urN a/gopls/internal/lsp/source/comment_go118.go b/gopls/internal/lsp/source/comment_go118.go
--- a/gopls/internal/lsp/source/comment_go118.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/comment_go118.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package source
-
-// Starting with go1.19, the formatting of comments has changed, and there
-// is a new package (go/doc/comment) for processing them.
-// As long as gopls has to compile under earlier versions, tests
-// have to pass with both the old and new code, which produce
-// slightly different results. (cmd/test/definition.go, source/comment_test.go,
-// and source/source_test.go) Each of the test files checks the results
-// with a function, tests.CheckSameMarkdown, that accepts both the old and the new
-// results. (The old code escapes many characters the new code does not,
-// and the new code sometimes adds a blank line.)
-
-// When gopls no longer needs to compile with go1.18, the old comment.go should
-// be replaced by this file, the golden test files should be updated.
-// (and checkSameMarkdown() could be replaced by a simple comparison.)
-
-import "go/doc/comment"
-
-// CommentToMarkdown converts comment text to formatted markdown.
-// The comment was prepared by DocReader,
-// so it is known not to have leading, trailing blank lines
-// nor to have trailing spaces at the end of lines.
-// The comment markers have already been removed.
-func CommentToMarkdown(text string) string {
-	var p comment.Parser
-	doc := p.Parse(text)
-	var pr comment.Printer
-	// The default produces {#Hdr-...} tags for headings.
-	// vscode displays thems, which is undesirable.
-	// The godoc for comment.Printer says the tags
-	// avoid a security problem.
-	pr.HeadingID = func(*comment.Heading) string { return "" }
-	easy := pr.Markdown(doc)
-	return string(easy)
-}
diff -urN a/gopls/internal/lsp/source/comment_go118_test.go b/gopls/internal/lsp/source/comment_go118_test.go
--- a/gopls/internal/lsp/source/comment_go118_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/comment_go118_test.go	1969-12-31 16:00:00
@@ -1,371 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.19
-// +build !go1.19
-
-package source
-
-import (
-	"bytes"
-	"reflect"
-	"strings"
-	"testing"
-)
-
-// This file is a copy of go/doc/comment_test.go with the exception for
-// the test cases for TestEmphasize and TestCommentEscape
-
-var headingTests = []struct {
-	line string
-	ok   bool
-}{
-	{"Section", true},
-	{"A typical usage", true},
-	{"ΔΛΞ is Greek", true},
-	{"Foo 42", true},
-	{"", false},
-	{"section", false},
-	{"A typical usage:", false},
-	{"This code:", false},
-	{"δ is Greek", false},
-	{"Foo §", false},
-	{"Fermat's Last Sentence", true},
-	{"Fermat's", true},
-	{"'sX", false},
-	{"Ted 'Too' Bar", false},
-	{"Use n+m", false},
-	{"Scanning:", false},
-	{"N:M", false},
-}
-
-func TestIsHeading(t *testing.T) {
-	for _, tt := range headingTests {
-		if h := heading(tt.line); (len(h) > 0) != tt.ok {
-			t.Errorf("isHeading(%q) = %v, want %v", tt.line, h, tt.ok)
-		}
-	}
-}
-
-var blocksTests = []struct {
-	in   string
-	out  []block
-	text string
-}{
-	{
-		in: `Para 1.
-Para 1 line 2.
-
-Para 2.
-
-Section
-
-Para 3.
-
-	pre
-	pre1
-
-Para 4.
-
-	pre
-	pre1
-
-	pre2
-
-Para 5.
-
-
-	pre
-
-
-	pre1
-	pre2
-
-Para 6.
-	pre
-	pre2
-`,
-		out: []block{
-			{opPara, []string{"Para 1.\n", "Para 1 line 2.\n"}},
-			{opPara, []string{"Para 2.\n"}},
-			{opHead, []string{"Section"}},
-			{opPara, []string{"Para 3.\n"}},
-			{opPre, []string{"pre\n", "pre1\n"}},
-			{opPara, []string{"Para 4.\n"}},
-			{opPre, []string{"pre\n", "pre1\n", "\n", "pre2\n"}},
-			{opPara, []string{"Para 5.\n"}},
-			{opPre, []string{"pre\n", "\n", "\n", "pre1\n", "pre2\n"}},
-			{opPara, []string{"Para 6.\n"}},
-			{opPre, []string{"pre\n", "pre2\n"}},
-		},
-		text: `.   Para 1. Para 1 line 2.
-
-.   Para 2.
-
-
-.   Section
-
-.   Para 3.
-
-$	pre
-$	pre1
-
-.   Para 4.
-
-$	pre
-$	pre1
-
-$	pre2
-
-.   Para 5.
-
-$	pre
-
-
-$	pre1
-$	pre2
-
-.   Para 6.
-
-$	pre
-$	pre2
-`,
-	},
-	{
-		in: "Para.\n\tshould not be ``escaped''",
-		out: []block{
-			{opPara, []string{"Para.\n"}},
-			{opPre, []string{"should not be ``escaped''"}},
-		},
-		text: ".   Para.\n\n$	should not be ``escaped''",
-	},
-	{
-		in: "// A very long line of 46 char for line wrapping.",
-		out: []block{
-			{opPara, []string{"// A very long line of 46 char for line wrapping."}},
-		},
-		text: `.   // A very long line of 46 char for line
-.   // wrapping.
-`,
-	},
-	{
-		in: `/* A very long line of 46 char for line wrapping.
-A very long line of 46 char for line wrapping. */`,
-		out: []block{
-			{opPara, []string{"/* A very long line of 46 char for line wrapping.\n", "A very long line of 46 char for line wrapping. */"}},
-		},
-		text: `.   /* A very long line of 46 char for line
-.   wrapping. A very long line of 46 char
-.   for line wrapping. */
-`,
-	},
-}
-
-func TestBlocks(t *testing.T) {
-	for i, tt := range blocksTests {
-		b := blocks(tt.in)
-		if !reflect.DeepEqual(b, tt.out) {
-			t.Errorf("#%d: mismatch\nhave: %v\nwant: %v", i, b, tt.out)
-		}
-	}
-}
-
-// This has been modified from go/doc to use markdown links instead of html ones
-// and use markdown escaping instead oh html
-var emphasizeTests = []struct {
-	in, out string
-}{
-	{"", ""},
-	{"http://[::1]:8080/foo.txt", `[http\:\/\/\[\:\:1\]\:8080\/foo\.txt](http://[::1]:8080/foo.txt)`},
-	{"before (https://www.google.com) after", `before \([https\:\/\/www\.google\.com](https://www.google.com)\) after`},
-	{"before https://www.google.com:30/x/y/z:b::c. After", `before [https\:\/\/www\.google\.com\:30\/x\/y\/z\:b\:\:c](https://www.google.com:30/x/y/z:b::c)\. After`},
-	{"http://www.google.com/path/:;!-/?query=%34b#093124", `[http\:\/\/www\.google\.com\/path\/\:\;\!\-\/\?query\=\%34b\#093124](http://www.google.com/path/:;!-/?query=%34b#093124)`},
-	{"http://www.google.com/path/:;!-/?query=%34bar#093124", `[http\:\/\/www\.google\.com\/path\/\:\;\!\-\/\?query\=\%34bar\#093124](http://www.google.com/path/:;!-/?query=%34bar#093124)`},
-	{"http://www.google.com/index.html! After", `[http\:\/\/www\.google\.com\/index\.html](http://www.google.com/index.html)\! After`},
-	{"http://www.google.com/", `[http\:\/\/www\.google\.com\/](http://www.google.com/)`},
-	{"https://www.google.com/", `[https\:\/\/www\.google\.com\/](https://www.google.com/)`},
-	{"http://www.google.com/path.", `[http\:\/\/www\.google\.com\/path](http://www.google.com/path)\.`},
-	{"http://en.wikipedia.org/wiki/Camellia_(cipher)", `[http\:\/\/en\.wikipedia\.org\/wiki\/Camellia\_\(cipher\)](http://en.wikipedia.org/wiki/Camellia_\(cipher\))`},
-	{"(http://www.google.com/)", `\([http\:\/\/www\.google\.com\/](http://www.google.com/)\)`},
-	{"http://gmail.com)", `[http\:\/\/gmail\.com](http://gmail.com)\)`},
-	{"((http://gmail.com))", `\(\([http\:\/\/gmail\.com](http://gmail.com)\)\)`},
-	{"http://gmail.com ((http://gmail.com)) ()", `[http\:\/\/gmail\.com](http://gmail.com) \(\([http\:\/\/gmail\.com](http://gmail.com)\)\) \(\)`},
-	{"Foo bar http://example.com/ quux!", `Foo bar [http\:\/\/example\.com\/](http://example.com/) quux\!`},
-	{"Hello http://example.com/%2f/ /world.", `Hello [http\:\/\/example\.com\/\%2f\/](http://example.com/%2f/) \/world\.`},
-	{"Lorem http: ipsum //host/path", `Lorem http\: ipsum \/\/host\/path`},
-	{"javascript://is/not/linked", `javascript\:\/\/is\/not\/linked`},
-	{"http://foo", `[http\:\/\/foo](http://foo)`},
-	{"art by [[https://www.example.com/person/][Person Name]]", `art by \[\[[https\:\/\/www\.example\.com\/person\/](https://www.example.com/person/)\]\[Person Name\]\]`},
-	{"please visit (http://golang.org/)", `please visit \([http\:\/\/golang\.org\/](http://golang.org/)\)`},
-	{"please visit http://golang.org/hello())", `please visit [http\:\/\/golang\.org\/hello\(\)](http://golang.org/hello\(\))\)`},
-	{"http://git.qemu.org/?p=qemu.git;a=blob;f=qapi-schema.json;hb=HEAD", `[http\:\/\/git\.qemu\.org\/\?p\=qemu\.git\;a\=blob\;f\=qapi\-schema\.json\;hb\=HEAD](http://git.qemu.org/?p=qemu.git;a=blob;f=qapi-schema.json;hb=HEAD)`},
-	{"https://foo.bar/bal/x(])", `[https\:\/\/foo\.bar\/bal\/x\(](https://foo.bar/bal/x\()\]\)`},
-	{"foo [ http://bar(])", `foo \[ [http\:\/\/bar\(](http://bar\()\]\)`},
-}
-
-func TestEmphasize(t *testing.T) {
-	for i, tt := range emphasizeTests {
-		var buf bytes.Buffer
-		emphasize(&buf, tt.in, true)
-		out := buf.String()
-		if out != tt.out {
-			t.Errorf("#%d: mismatch\nhave: %v\nwant: %v", i, out, tt.out)
-		}
-	}
-}
-
-func TestCommentEscape(t *testing.T) {
-	//ldquo -> ulquo and rdquo -> urquo
-	commentTests := []struct {
-		in, out string
-	}{
-		{"typically invoked as ``go tool asm'',", "typically invoked as " + ulquo + "go tool asm" + urquo + ","},
-		{"For more detail, run ``go help test'' and ``go help testflag''", "For more detail, run " + ulquo + "go help test" + urquo + " and " + ulquo + "go help testflag" + urquo}}
-	for i, tt := range commentTests {
-		var buf strings.Builder
-		commentEscape(&buf, tt.in, true)
-		out := buf.String()
-		if out != tt.out {
-			t.Errorf("#%d: mismatch\nhave: %q\nwant: %q", i, out, tt.out)
-		}
-	}
-}
-
-func TestCommentToMarkdown(t *testing.T) {
-	tests := []struct {
-		in, out string
-	}{
-		{
-			in:  "F declaration.\n",
-			out: "F declaration\\.\n",
-		},
-		{
-			in: `
-F declaration. Lorem ipsum dolor sit amet.
-Etiam mattis eros at orci mollis molestie.
-`,
-			out: `
-F declaration\. Lorem ipsum dolor sit amet\.
-Etiam mattis eros at orci mollis molestie\.
-`,
-		},
-		{
-			in: `
-F declaration.
-
-Lorem ipsum dolor sit amet.
-Sed id dui turpis.
-
-
-
-
-Aenean tempus velit non auctor eleifend.
-Aenean efficitur a sem id ultricies.
-
-
-Phasellus efficitur mauris et viverra bibendum.
-`,
-			out: `
-F declaration\.
-
-Lorem ipsum dolor sit amet\.
-Sed id dui turpis\.
-
-Aenean tempus velit non auctor eleifend\.
-Aenean efficitur a sem id ultricies\.
-
-Phasellus efficitur mauris et viverra bibendum\.
-`,
-		},
-		{
-			in: `
-F declaration.
-
-Aenean tempus velit non auctor eleifend.
-
-Section
-
-Lorem ipsum dolor sit amet, consectetur adipiscing elit.
-
-  func foo() {}
-
-
-  func bar() {}
-
-Fusce lorem lacus.
-
-    func foo() {}
-
-    func bar() {}
-
-Maecenas in lobortis lectus.
-
-	func foo() {}
-
-	func bar() {}
-
-Phasellus efficitur mauris et viverra bibendum.
-`,
-			out: `
-F declaration\.
-
-Aenean tempus velit non auctor eleifend\.
-
-### Section
-
-Lorem ipsum dolor sit amet, consectetur adipiscing elit\.
-
-    func foo() {}
-
-
-    func bar() {}
-
-Fusce lorem lacus\.
-
-    func foo() {}
-
-    func bar() {}
-
-Maecenas in lobortis lectus\.
-
-    func foo() {}
-
-    func bar() {}
-
-Phasellus efficitur mauris et viverra bibendum\.
-`,
-		},
-		{
-			in: `
-F declaration.
-
-	func foo() {
-		fmt.Println("foo")
-	}
-	func bar() {
-		fmt.Println("bar")
-	}
-`,
-			out: `
-F declaration\.
-
-    func foo() {
-    	fmt.Println("foo")
-    }
-    func bar() {
-    	fmt.Println("bar")
-    }
-`,
-		},
-	}
-	for i, tt := range tests {
-		// Comments start with new lines for better readability. So, we should trim them.
-		tt.in = strings.TrimPrefix(tt.in, "\n")
-		tt.out = strings.TrimPrefix(tt.out, "\n")
-
-		if out := CommentToMarkdown(tt.in); out != tt.out {
-			t.Errorf("#%d: mismatch\nhave: %q\nwant: %q", i, out, tt.out)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/builtin.go b/gopls/internal/lsp/source/completion/builtin.go
--- a/gopls/internal/lsp/source/completion/builtin.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/builtin.go	1969-12-31 16:00:00
@@ -1,147 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"context"
-	"go/ast"
-	"go/types"
-)
-
-// builtinArgKind determines the expected object kind for a builtin
-// argument. It attempts to use the AST hints from builtin.go where
-// possible.
-func (c *completer) builtinArgKind(ctx context.Context, obj types.Object, call *ast.CallExpr) objKind {
-	builtin, err := c.snapshot.BuiltinFile(ctx)
-	if err != nil {
-		return 0
-	}
-	exprIdx := exprAtPos(c.pos, call.Args)
-
-	builtinObj := builtin.File.Scope.Lookup(obj.Name())
-	if builtinObj == nil {
-		return 0
-	}
-	decl, ok := builtinObj.Decl.(*ast.FuncDecl)
-	if !ok || exprIdx >= len(decl.Type.Params.List) {
-		return 0
-	}
-
-	switch ptyp := decl.Type.Params.List[exprIdx].Type.(type) {
-	case *ast.ChanType:
-		return kindChan
-	case *ast.ArrayType:
-		return kindSlice
-	case *ast.MapType:
-		return kindMap
-	case *ast.Ident:
-		switch ptyp.Name {
-		case "Type":
-			switch obj.Name() {
-			case "make":
-				return kindChan | kindSlice | kindMap
-			case "len":
-				return kindSlice | kindMap | kindArray | kindString | kindChan
-			case "cap":
-				return kindSlice | kindArray | kindChan
-			}
-		}
-	}
-
-	return 0
-}
-
-// builtinArgType infers the type of an argument to a builtin
-// function. parentInf is the inferred type info for the builtin
-// call's parent node.
-func (c *completer) builtinArgType(obj types.Object, call *ast.CallExpr, parentInf candidateInference) candidateInference {
-	var (
-		exprIdx = exprAtPos(c.pos, call.Args)
-
-		// Propagate certain properties from our parent's inference.
-		inf = candidateInference{
-			typeName:  parentInf.typeName,
-			modifiers: parentInf.modifiers,
-		}
-	)
-
-	switch obj.Name() {
-	case "append":
-		if exprIdx <= 0 {
-			// Infer first append() arg type as apparent return type of
-			// append().
-			inf.objType = parentInf.objType
-			if parentInf.variadic {
-				inf.objType = types.NewSlice(inf.objType)
-			}
-			break
-		}
-
-		// For non-initial append() args, infer slice type from the first
-		// append() arg, or from parent context.
-		if len(call.Args) > 0 {
-			inf.objType = c.pkg.GetTypesInfo().TypeOf(call.Args[0])
-		}
-		if inf.objType == nil {
-			inf.objType = parentInf.objType
-		}
-		if inf.objType == nil {
-			break
-		}
-
-		inf.objType = deslice(inf.objType)
-
-		// Check if we are completing the variadic append() param.
-		inf.variadic = exprIdx == 1 && len(call.Args) <= 2
-
-		// Penalize the first append() argument as a candidate. You
-		// don't normally append a slice to itself.
-		if sliceChain := objChain(c.pkg.GetTypesInfo(), call.Args[0]); len(sliceChain) > 0 {
-			inf.penalized = append(inf.penalized, penalizedObj{objChain: sliceChain, penalty: 0.9})
-		}
-	case "delete":
-		if exprIdx > 0 && len(call.Args) > 0 {
-			// Try to fill in expected type of map key.
-			firstArgType := c.pkg.GetTypesInfo().TypeOf(call.Args[0])
-			if firstArgType != nil {
-				if mt, ok := firstArgType.Underlying().(*types.Map); ok {
-					inf.objType = mt.Key()
-				}
-			}
-		}
-	case "copy":
-		var t1, t2 types.Type
-		if len(call.Args) > 0 {
-			t1 = c.pkg.GetTypesInfo().TypeOf(call.Args[0])
-			if len(call.Args) > 1 {
-				t2 = c.pkg.GetTypesInfo().TypeOf(call.Args[1])
-			}
-		}
-
-		// Fill in expected type of either arg if the other is already present.
-		if exprIdx == 1 && t1 != nil {
-			inf.objType = t1
-		} else if exprIdx == 0 && t2 != nil {
-			inf.objType = t2
-		}
-	case "new":
-		inf.typeName.wantTypeName = true
-		if parentInf.objType != nil {
-			// Expected type for "new" is the de-pointered parent type.
-			if ptr, ok := parentInf.objType.Underlying().(*types.Pointer); ok {
-				inf.objType = ptr.Elem()
-			}
-		}
-	case "make":
-		if exprIdx == 0 {
-			inf.typeName.wantTypeName = true
-			inf.objType = parentInf.objType
-		} else {
-			inf.objType = types.Typ[types.UntypedInt]
-		}
-	}
-
-	return inf
-}
diff -urN a/gopls/internal/lsp/source/completion/completion.go b/gopls/internal/lsp/source/completion/completion.go
--- a/gopls/internal/lsp/source/completion/completion.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/completion.go	1969-12-31 16:00:00
@@ -1,3016 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package completion provides core functionality for code completion in Go
-// editors and tools.
-package completion
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/constant"
-	"go/scanner"
-	"go/token"
-	"go/types"
-	"math"
-	"sort"
-	"strconv"
-	"strings"
-	"sync"
-	"time"
-	"unicode"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/fuzzy"
-	"golang.org/x/tools/internal/imports"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-type CompletionItem struct {
-	// Label is the primary text the user sees for this completion item.
-	Label string
-
-	// Detail is supplemental information to present to the user.
-	// This often contains the type or return type of the completion item.
-	Detail string
-
-	// InsertText is the text to insert if this item is selected.
-	// Any of the prefix that has already been typed is not trimmed.
-	// The insert text does not contain snippets.
-	InsertText string
-
-	Kind       protocol.CompletionItemKind
-	Tags       []protocol.CompletionItemTag
-	Deprecated bool // Deprecated, prefer Tags if available
-
-	// An optional array of additional TextEdits that are applied when
-	// selecting this completion.
-	//
-	// Additional text edits should be used to change text unrelated to the current cursor position
-	// (for example adding an import statement at the top of the file if the completion item will
-	// insert an unqualified type).
-	AdditionalTextEdits []protocol.TextEdit
-
-	// Depth is how many levels were searched to find this completion.
-	// For example when completing "foo<>", "fooBar" is depth 0, and
-	// "fooBar.Baz" is depth 1.
-	Depth int
-
-	// Score is the internal relevance score.
-	// A higher score indicates that this completion item is more relevant.
-	Score float64
-
-	// snippet is the LSP snippet for the completion item. The LSP
-	// specification contains details about LSP snippets. For example, a
-	// snippet for a function with the following signature:
-	//
-	//     func foo(a, b, c int)
-	//
-	// would be:
-	//
-	//     foo(${1:a int}, ${2: b int}, ${3: c int})
-	//
-	// If Placeholders is false in the CompletionOptions, the above
-	// snippet would instead be:
-	//
-	//     foo(${1:})
-	snippet *snippet.Builder
-
-	// Documentation is the documentation for the completion item.
-	Documentation string
-
-	// obj is the object from which this candidate was derived, if any.
-	// obj is for internal use only.
-	obj types.Object
-}
-
-// completionOptions holds completion specific configuration.
-type completionOptions struct {
-	unimported        bool
-	documentation     bool
-	fullDocumentation bool
-	placeholders      bool
-	literal           bool
-	snippets          bool
-	postfix           bool
-	matcher           source.Matcher
-	budget            time.Duration
-}
-
-// Snippet is a convenience returns the snippet if available, otherwise
-// the InsertText.
-// used for an item, depending on if the callee wants placeholders or not.
-func (i *CompletionItem) Snippet() string {
-	if i.snippet != nil {
-		return i.snippet.String()
-	}
-	return i.InsertText
-}
-
-// Scoring constants are used for weighting the relevance of different candidates.
-const (
-	// stdScore is the base score for all completion items.
-	stdScore float64 = 1.0
-
-	// highScore indicates a very relevant completion item.
-	highScore float64 = 10.0
-
-	// lowScore indicates an irrelevant or not useful completion item.
-	lowScore float64 = 0.01
-)
-
-// matcher matches a candidate's label against the user input. The
-// returned score reflects the quality of the match. A score of zero
-// indicates no match, and a score of one means a perfect match.
-type matcher interface {
-	Score(candidateLabel string) (score float32)
-}
-
-// prefixMatcher implements case sensitive prefix matching.
-type prefixMatcher string
-
-func (pm prefixMatcher) Score(candidateLabel string) float32 {
-	if strings.HasPrefix(candidateLabel, string(pm)) {
-		return 1
-	}
-	return -1
-}
-
-// insensitivePrefixMatcher implements case insensitive prefix matching.
-type insensitivePrefixMatcher string
-
-func (ipm insensitivePrefixMatcher) Score(candidateLabel string) float32 {
-	if strings.HasPrefix(strings.ToLower(candidateLabel), string(ipm)) {
-		return 1
-	}
-	return -1
-}
-
-// completer contains the necessary information for a single completion request.
-type completer struct {
-	snapshot source.Snapshot
-	pkg      source.Package
-	qf       types.Qualifier
-	opts     *completionOptions
-
-	// completionContext contains information about the trigger for this
-	// completion request.
-	completionContext completionContext
-
-	// fh is a handle to the file associated with this completion request.
-	fh source.FileHandle
-
-	// filename is the name of the file associated with this completion request.
-	filename string
-
-	// file is the AST of the file associated with this completion request.
-	file *ast.File
-
-	// (tokFile, pos) is the position at which the request was triggered.
-	tokFile *token.File
-	pos     token.Pos
-
-	// path is the path of AST nodes enclosing the position.
-	path []ast.Node
-
-	// seen is the map that ensures we do not return duplicate results.
-	seen map[types.Object]bool
-
-	// items is the list of completion items returned.
-	items []CompletionItem
-
-	// completionCallbacks is a list of callbacks to collect completions that
-	// require expensive operations. This includes operations where we search
-	// through the entire module cache.
-	completionCallbacks []func(opts *imports.Options) error
-
-	// surrounding describes the identifier surrounding the position.
-	surrounding *Selection
-
-	// inference contains information we've inferred about ideal
-	// candidates such as the candidate's type.
-	inference candidateInference
-
-	// enclosingFunc contains information about the function enclosing
-	// the position.
-	enclosingFunc *funcInfo
-
-	// enclosingCompositeLiteral contains information about the composite literal
-	// enclosing the position.
-	enclosingCompositeLiteral *compLitInfo
-
-	// deepState contains the current state of our deep completion search.
-	deepState deepCompletionState
-
-	// matcher matches the candidates against the surrounding prefix.
-	matcher matcher
-
-	// methodSetCache caches the types.NewMethodSet call, which is relatively
-	// expensive and can be called many times for the same type while searching
-	// for deep completions.
-	methodSetCache map[methodSetKey]*types.MethodSet
-
-	// mapper converts the positions in the file from which the completion originated.
-	mapper *protocol.ColumnMapper
-
-	// startTime is when we started processing this completion request. It does
-	// not include any time the request spent in the queue.
-	startTime time.Time
-
-	// scopes contains all scopes defined by nodes in our path,
-	// including nil values for nodes that don't defined a scope. It
-	// also includes our package scope and the universal scope at the
-	// end.
-	scopes []*types.Scope
-}
-
-// funcInfo holds info about a function object.
-type funcInfo struct {
-	// sig is the function declaration enclosing the position.
-	sig *types.Signature
-
-	// body is the function's body.
-	body *ast.BlockStmt
-}
-
-type compLitInfo struct {
-	// cl is the *ast.CompositeLit enclosing the position.
-	cl *ast.CompositeLit
-
-	// clType is the type of cl.
-	clType types.Type
-
-	// kv is the *ast.KeyValueExpr enclosing the position, if any.
-	kv *ast.KeyValueExpr
-
-	// inKey is true if we are certain the position is in the key side
-	// of a key-value pair.
-	inKey bool
-
-	// maybeInFieldName is true if inKey is false and it is possible
-	// we are completing a struct field name. For example,
-	// "SomeStruct{<>}" will be inKey=false, but maybeInFieldName=true
-	// because we _could_ be completing a field name.
-	maybeInFieldName bool
-}
-
-type importInfo struct {
-	importPath string
-	name       string
-}
-
-type methodSetKey struct {
-	typ         types.Type
-	addressable bool
-}
-
-type completionContext struct {
-	// triggerCharacter is the character used to trigger completion at current
-	// position, if any.
-	triggerCharacter string
-
-	// triggerKind is information about how a completion was triggered.
-	triggerKind protocol.CompletionTriggerKind
-
-	// commentCompletion is true if we are completing a comment.
-	commentCompletion bool
-
-	// packageCompletion is true if we are completing a package name.
-	packageCompletion bool
-}
-
-// A Selection represents the cursor position and surrounding identifier.
-type Selection struct {
-	content string
-	cursor  token.Pos // relative to rng.TokFile
-	rng     span.Range
-}
-
-func (p Selection) Content() string {
-	return p.content
-}
-
-func (p Selection) Range() span.Range {
-	return p.rng
-}
-
-func (p Selection) Prefix() string {
-	return p.content[:p.cursor-p.rng.Start]
-}
-
-func (p Selection) Suffix() string {
-	return p.content[p.cursor-p.rng.Start:]
-}
-
-func (c *completer) setSurrounding(ident *ast.Ident) {
-	if c.surrounding != nil {
-		return
-	}
-	if !(ident.Pos() <= c.pos && c.pos <= ident.End()) {
-		return
-	}
-
-	c.surrounding = &Selection{
-		content: ident.Name,
-		cursor:  c.pos,
-		// Overwrite the prefix only.
-		rng: span.NewRange(c.tokFile, ident.Pos(), ident.End()),
-	}
-
-	c.setMatcherFromPrefix(c.surrounding.Prefix())
-}
-
-func (c *completer) setMatcherFromPrefix(prefix string) {
-	switch c.opts.matcher {
-	case source.Fuzzy:
-		c.matcher = fuzzy.NewMatcher(prefix)
-	case source.CaseSensitive:
-		c.matcher = prefixMatcher(prefix)
-	default:
-		c.matcher = insensitivePrefixMatcher(strings.ToLower(prefix))
-	}
-}
-
-func (c *completer) getSurrounding() *Selection {
-	if c.surrounding == nil {
-		c.surrounding = &Selection{
-			content: "",
-			cursor:  c.pos,
-			rng:     span.NewRange(c.tokFile, c.pos, c.pos),
-		}
-	}
-	return c.surrounding
-}
-
-// candidate represents a completion candidate.
-type candidate struct {
-	// obj is the types.Object to complete to.
-	obj types.Object
-
-	// score is used to rank candidates.
-	score float64
-
-	// name is the deep object name path, e.g. "foo.bar"
-	name string
-
-	// detail is additional information about this item. If not specified,
-	// defaults to type string for the object.
-	detail string
-
-	// path holds the path from the search root (excluding the candidate
-	// itself) for a deep candidate.
-	path []types.Object
-
-	// pathInvokeMask is a bit mask tracking whether each entry in path
-	// should be formatted with "()" (i.e. whether it is a function
-	// invocation).
-	pathInvokeMask uint16
-
-	// mods contains modifications that should be applied to the
-	// candidate when inserted. For example, "foo" may be inserted as
-	// "*foo" or "foo()".
-	mods []typeModKind
-
-	// addressable is true if a pointer can be taken to the candidate.
-	addressable bool
-
-	// convertTo is a type that this candidate should be cast to. For
-	// example, if convertTo is float64, "foo" should be formatted as
-	// "float64(foo)".
-	convertTo types.Type
-
-	// imp is the import that needs to be added to this package in order
-	// for this candidate to be valid. nil if no import needed.
-	imp *importInfo
-}
-
-func (c candidate) hasMod(mod typeModKind) bool {
-	for _, m := range c.mods {
-		if m == mod {
-			return true
-		}
-	}
-	return false
-}
-
-// ErrIsDefinition is an error that informs the user they got no
-// completions because they tried to complete the name of a new object
-// being defined.
-type ErrIsDefinition struct {
-	objStr string
-}
-
-func (e ErrIsDefinition) Error() string {
-	msg := "this is a definition"
-	if e.objStr != "" {
-		msg += " of " + e.objStr
-	}
-	return msg
-}
-
-// Completion returns a list of possible candidates for completion, given a
-// a file and a position.
-//
-// The selection is computed based on the preceding identifier and can be used by
-// the client to score the quality of the completion. For instance, some clients
-// may tolerate imperfect matches as valid completion results, since users may make typos.
-func Completion(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, protoPos protocol.Position, protoContext protocol.CompletionContext) ([]CompletionItem, *Selection, error) {
-	ctx, done := event.Start(ctx, "completion.Completion")
-	defer done()
-
-	startTime := time.Now()
-
-	pkg, pgf, err := source.PackageForFile(ctx, snapshot, fh.URI(), source.TypecheckWorkspace, source.NarrowestPackage)
-	if err != nil || pgf.File.Package == token.NoPos {
-		// If we can't parse this file or find position for the package
-		// keyword, it may be missing a package declaration. Try offering
-		// suggestions for the package declaration.
-		// Note that this would be the case even if the keyword 'package' is
-		// present but no package name exists.
-		items, surrounding, innerErr := packageClauseCompletions(ctx, snapshot, fh, protoPos)
-		if innerErr != nil {
-			// return the error for GetParsedFile since it's more relevant in this situation.
-			return nil, nil, fmt.Errorf("getting file %s for Completion: %w (package completions: %v)", fh.URI(), err, innerErr)
-		}
-		return items, surrounding, nil
-	}
-	pos, err := pgf.Mapper.Pos(protoPos)
-	if err != nil {
-		return nil, nil, err
-	}
-	// Completion is based on what precedes the cursor.
-	// Find the path to the position before pos.
-	path, _ := astutil.PathEnclosingInterval(pgf.File, pos-1, pos-1)
-	if path == nil {
-		return nil, nil, fmt.Errorf("cannot find node enclosing position")
-	}
-
-	// Check if completion at this position is valid. If not, return early.
-	switch n := path[0].(type) {
-	case *ast.BasicLit:
-		// Skip completion inside literals except for ImportSpec
-		if len(path) > 1 {
-			if _, ok := path[1].(*ast.ImportSpec); ok {
-				break
-			}
-		}
-		return nil, nil, nil
-	case *ast.CallExpr:
-		if n.Ellipsis.IsValid() && pos > n.Ellipsis && pos <= n.Ellipsis+token.Pos(len("...")) {
-			// Don't offer completions inside or directly after "...". For
-			// example, don't offer completions at "<>" in "foo(bar...<>").
-			return nil, nil, nil
-		}
-	case *ast.Ident:
-		// reject defining identifiers
-		if obj, ok := pkg.GetTypesInfo().Defs[n]; ok {
-			if v, ok := obj.(*types.Var); ok && v.IsField() && v.Embedded() {
-				// An anonymous field is also a reference to a type.
-			} else if pgf.File.Name == n {
-				// Don't skip completions if Ident is for package name.
-				break
-			} else {
-				objStr := ""
-				if obj != nil {
-					qual := types.RelativeTo(pkg.GetTypes())
-					objStr = types.ObjectString(obj, qual)
-				}
-				ans, sel := definition(path, obj, pgf.Tok, fh)
-				if ans != nil {
-					sort.Slice(ans, func(i, j int) bool {
-						return ans[i].Score > ans[j].Score
-					})
-					return ans, sel, nil
-				}
-				return nil, nil, ErrIsDefinition{objStr: objStr}
-			}
-		}
-	}
-
-	// Collect all surrounding scopes, innermost first.
-	scopes := source.CollectScopes(pkg.GetTypesInfo(), path, pos)
-	scopes = append(scopes, pkg.GetTypes().Scope(), types.Universe)
-
-	opts := snapshot.View().Options()
-	c := &completer{
-		pkg:      pkg,
-		snapshot: snapshot,
-		qf:       source.Qualifier(pgf.File, pkg.GetTypes(), pkg.GetTypesInfo()),
-		completionContext: completionContext{
-			triggerCharacter: protoContext.TriggerCharacter,
-			triggerKind:      protoContext.TriggerKind,
-		},
-		fh:                        fh,
-		filename:                  fh.URI().Filename(),
-		tokFile:                   pgf.Tok,
-		file:                      pgf.File,
-		path:                      path,
-		pos:                       pos,
-		seen:                      make(map[types.Object]bool),
-		enclosingFunc:             enclosingFunction(path, pkg.GetTypesInfo()),
-		enclosingCompositeLiteral: enclosingCompositeLiteral(path, pos, pkg.GetTypesInfo()),
-		deepState: deepCompletionState{
-			enabled: opts.DeepCompletion,
-		},
-		opts: &completionOptions{
-			matcher:           opts.Matcher,
-			unimported:        opts.CompleteUnimported,
-			documentation:     opts.CompletionDocumentation && opts.HoverKind != source.NoDocumentation,
-			fullDocumentation: opts.HoverKind == source.FullDocumentation,
-			placeholders:      opts.UsePlaceholders,
-			literal:           opts.LiteralCompletions && opts.InsertTextFormat == protocol.SnippetTextFormat,
-			budget:            opts.CompletionBudget,
-			snippets:          opts.InsertTextFormat == protocol.SnippetTextFormat,
-			postfix:           opts.ExperimentalPostfixCompletions,
-		},
-		// default to a matcher that always matches
-		matcher:        prefixMatcher(""),
-		methodSetCache: make(map[methodSetKey]*types.MethodSet),
-		mapper:         pgf.Mapper,
-		startTime:      startTime,
-		scopes:         scopes,
-	}
-
-	var cancel context.CancelFunc
-	if c.opts.budget == 0 {
-		ctx, cancel = context.WithCancel(ctx)
-	} else {
-		// timeoutDuration is the completion budget remaining. If less than
-		// 10ms, set to 10ms
-		timeoutDuration := time.Until(c.startTime.Add(c.opts.budget))
-		if timeoutDuration < 10*time.Millisecond {
-			timeoutDuration = 10 * time.Millisecond
-		}
-		ctx, cancel = context.WithTimeout(ctx, timeoutDuration)
-	}
-	defer cancel()
-
-	if surrounding := c.containingIdent(pgf.Src); surrounding != nil {
-		c.setSurrounding(surrounding)
-	}
-
-	c.inference = expectedCandidate(ctx, c)
-
-	err = c.collectCompletions(ctx)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	// Deep search collected candidates and their members for more candidates.
-	c.deepSearch(ctx)
-
-	for _, callback := range c.completionCallbacks {
-		if err := c.snapshot.RunProcessEnvFunc(ctx, callback); err != nil {
-			return nil, nil, err
-		}
-	}
-
-	// Search candidates populated by expensive operations like
-	// unimportedMembers etc. for more completion items.
-	c.deepSearch(ctx)
-
-	// Statement candidates offer an entire statement in certain contexts, as
-	// opposed to a single object. Add statement candidates last because they
-	// depend on other candidates having already been collected.
-	c.addStatementCandidates()
-
-	c.sortItems()
-	return c.items, c.getSurrounding(), nil
-}
-
-// collectCompletions adds possible completion candidates to either the deep
-// search queue or completion items directly for different completion contexts.
-func (c *completer) collectCompletions(ctx context.Context) error {
-	// Inside import blocks, return completions for unimported packages.
-	for _, importSpec := range c.file.Imports {
-		if !(importSpec.Path.Pos() <= c.pos && c.pos <= importSpec.Path.End()) {
-			continue
-		}
-		return c.populateImportCompletions(ctx, importSpec)
-	}
-
-	// Inside comments, offer completions for the name of the relevant symbol.
-	for _, comment := range c.file.Comments {
-		if comment.Pos() < c.pos && c.pos <= comment.End() {
-			c.populateCommentCompletions(ctx, comment)
-			return nil
-		}
-	}
-
-	// Struct literals are handled entirely separately.
-	if c.wantStructFieldCompletions() {
-		// If we are definitely completing a struct field name, deep completions
-		// don't make sense.
-		if c.enclosingCompositeLiteral.inKey {
-			c.deepState.enabled = false
-		}
-		return c.structLiteralFieldName(ctx)
-	}
-
-	if lt := c.wantLabelCompletion(); lt != labelNone {
-		c.labels(lt)
-		return nil
-	}
-
-	if c.emptySwitchStmt() {
-		// Empty switch statements only admit "default" and "case" keywords.
-		c.addKeywordItems(map[string]bool{}, highScore, CASE, DEFAULT)
-		return nil
-	}
-
-	switch n := c.path[0].(type) {
-	case *ast.Ident:
-		if c.file.Name == n {
-			return c.packageNameCompletions(ctx, c.fh.URI(), n)
-		} else if sel, ok := c.path[1].(*ast.SelectorExpr); ok && sel.Sel == n {
-			// Is this the Sel part of a selector?
-			return c.selector(ctx, sel)
-		}
-		return c.lexical(ctx)
-	// The function name hasn't been typed yet, but the parens are there:
-	//   recv.‸(arg)
-	case *ast.TypeAssertExpr:
-		// Create a fake selector expression.
-		return c.selector(ctx, &ast.SelectorExpr{X: n.X})
-	case *ast.SelectorExpr:
-		return c.selector(ctx, n)
-	// At the file scope, only keywords are allowed.
-	case *ast.BadDecl, *ast.File:
-		c.addKeywordCompletions()
-	default:
-		// fallback to lexical completions
-		return c.lexical(ctx)
-	}
-
-	return nil
-}
-
-// containingIdent returns the *ast.Ident containing pos, if any. It
-// synthesizes an *ast.Ident to allow completion in the face of
-// certain syntax errors.
-func (c *completer) containingIdent(src []byte) *ast.Ident {
-	// In the normal case, our leaf AST node is the identifier being completed.
-	if ident, ok := c.path[0].(*ast.Ident); ok {
-		return ident
-	}
-
-	pos, tkn, lit := c.scanToken(src)
-	if !pos.IsValid() {
-		return nil
-	}
-
-	fakeIdent := &ast.Ident{Name: lit, NamePos: pos}
-
-	if _, isBadDecl := c.path[0].(*ast.BadDecl); isBadDecl {
-		// You don't get *ast.Idents at the file level, so look for bad
-		// decls and use the manually extracted token.
-		return fakeIdent
-	} else if c.emptySwitchStmt() {
-		// Only keywords are allowed in empty switch statements.
-		// *ast.Idents are not parsed, so we must use the manually
-		// extracted token.
-		return fakeIdent
-	} else if tkn.IsKeyword() {
-		// Otherwise, manually extract the prefix if our containing token
-		// is a keyword. This improves completion after an "accidental
-		// keyword", e.g. completing to "variance" in "someFunc(var<>)".
-		return fakeIdent
-	}
-
-	return nil
-}
-
-// scanToken scans pgh's contents for the token containing pos.
-func (c *completer) scanToken(contents []byte) (token.Pos, token.Token, string) {
-	tok := c.pkg.FileSet().File(c.pos)
-
-	var s scanner.Scanner
-	s.Init(tok, contents, nil, 0)
-	for {
-		tknPos, tkn, lit := s.Scan()
-		if tkn == token.EOF || tknPos >= c.pos {
-			return token.NoPos, token.ILLEGAL, ""
-		}
-
-		if len(lit) > 0 && tknPos <= c.pos && c.pos <= tknPos+token.Pos(len(lit)) {
-			return tknPos, tkn, lit
-		}
-	}
-}
-
-func (c *completer) sortItems() {
-	sort.SliceStable(c.items, func(i, j int) bool {
-		// Sort by score first.
-		if c.items[i].Score != c.items[j].Score {
-			return c.items[i].Score > c.items[j].Score
-		}
-
-		// Then sort by label so order stays consistent. This also has the
-		// effect of preferring shorter candidates.
-		return c.items[i].Label < c.items[j].Label
-	})
-}
-
-// emptySwitchStmt reports whether pos is in an empty switch or select
-// statement.
-func (c *completer) emptySwitchStmt() bool {
-	block, ok := c.path[0].(*ast.BlockStmt)
-	if !ok || len(block.List) > 0 || len(c.path) == 1 {
-		return false
-	}
-
-	switch c.path[1].(type) {
-	case *ast.SwitchStmt, *ast.TypeSwitchStmt, *ast.SelectStmt:
-		return true
-	default:
-		return false
-	}
-}
-
-// populateImportCompletions yields completions for an import path around the cursor.
-//
-// Completions are suggested at the directory depth of the given import path so
-// that we don't overwhelm the user with a large list of possibilities. As an
-// example, a completion for the prefix "golang" results in "golang.org/".
-// Completions for "golang.org/" yield its subdirectories
-// (i.e. "golang.org/x/"). The user is meant to accept completion suggestions
-// until they reach a complete import path.
-func (c *completer) populateImportCompletions(ctx context.Context, searchImport *ast.ImportSpec) error {
-	if !strings.HasPrefix(searchImport.Path.Value, `"`) {
-		return nil
-	}
-
-	// deepSearch is not valuable for import completions.
-	c.deepState.enabled = false
-
-	importPath := searchImport.Path.Value
-
-	// Extract the text between the quotes (if any) in an import spec.
-	// prefix is the part of import path before the cursor.
-	prefixEnd := c.pos - searchImport.Path.Pos()
-	prefix := strings.Trim(importPath[:prefixEnd], `"`)
-
-	// The number of directories in the import path gives us the depth at
-	// which to search.
-	depth := len(strings.Split(prefix, "/")) - 1
-
-	content := importPath
-	start, end := searchImport.Path.Pos(), searchImport.Path.End()
-	namePrefix, nameSuffix := `"`, `"`
-	// If a starting quote is present, adjust surrounding to either after the
-	// cursor or after the first slash (/), except if cursor is at the starting
-	// quote. Otherwise we provide a completion including the starting quote.
-	if strings.HasPrefix(importPath, `"`) && c.pos > searchImport.Path.Pos() {
-		content = content[1:]
-		start++
-		if depth > 0 {
-			// Adjust textEdit start to replacement range. For ex: if current
-			// path was "golang.or/x/to<>ols/internal/", where <> is the cursor
-			// position, start of the replacement range would be after
-			// "golang.org/x/".
-			path := strings.SplitAfter(prefix, "/")
-			numChars := len(strings.Join(path[:len(path)-1], ""))
-			content = content[numChars:]
-			start += token.Pos(numChars)
-		}
-		namePrefix = ""
-	}
-
-	// We won't provide an ending quote if one is already present, except if
-	// cursor is after the ending quote but still in import spec. This is
-	// because cursor has to be in our textEdit range.
-	if strings.HasSuffix(importPath, `"`) && c.pos < searchImport.Path.End() {
-		end--
-		content = content[:len(content)-1]
-		nameSuffix = ""
-	}
-
-	c.surrounding = &Selection{
-		content: content,
-		cursor:  c.pos,
-		rng:     span.NewRange(c.tokFile, start, end),
-	}
-
-	seenImports := make(map[string]struct{})
-	for _, importSpec := range c.file.Imports {
-		if importSpec.Path.Value == importPath {
-			continue
-		}
-		seenImportPath, err := strconv.Unquote(importSpec.Path.Value)
-		if err != nil {
-			return err
-		}
-		seenImports[seenImportPath] = struct{}{}
-	}
-
-	var mu sync.Mutex // guard c.items locally, since searchImports is called in parallel
-	seen := make(map[string]struct{})
-	searchImports := func(pkg imports.ImportFix) {
-		path := pkg.StmtInfo.ImportPath
-		if _, ok := seenImports[path]; ok {
-			return
-		}
-
-		// Any package path containing fewer directories than the search
-		// prefix is not a match.
-		pkgDirList := strings.Split(path, "/")
-		if len(pkgDirList) < depth+1 {
-			return
-		}
-		pkgToConsider := strings.Join(pkgDirList[:depth+1], "/")
-
-		name := pkgDirList[depth]
-		// if we're adding an opening quote to completion too, set name to full
-		// package path since we'll need to overwrite that range.
-		if namePrefix == `"` {
-			name = pkgToConsider
-		}
-
-		score := pkg.Relevance
-		if len(pkgDirList)-1 == depth {
-			score *= highScore
-		} else {
-			// For incomplete package paths, add a terminal slash to indicate that the
-			// user should keep triggering completions.
-			name += "/"
-			pkgToConsider += "/"
-		}
-
-		if _, ok := seen[pkgToConsider]; ok {
-			return
-		}
-		seen[pkgToConsider] = struct{}{}
-
-		mu.Lock()
-		defer mu.Unlock()
-
-		name = namePrefix + name + nameSuffix
-		obj := types.NewPkgName(0, nil, name, types.NewPackage(pkgToConsider, name))
-		c.deepState.enqueue(candidate{
-			obj:    obj,
-			detail: fmt.Sprintf("%q", pkgToConsider),
-			score:  score,
-		})
-	}
-
-	c.completionCallbacks = append(c.completionCallbacks, func(opts *imports.Options) error {
-		return imports.GetImportPaths(ctx, searchImports, prefix, c.filename, c.pkg.GetTypes().Name(), opts.Env)
-	})
-	return nil
-}
-
-// populateCommentCompletions yields completions for comments preceding or in declarations.
-func (c *completer) populateCommentCompletions(ctx context.Context, comment *ast.CommentGroup) {
-	// If the completion was triggered by a period, ignore it. These types of
-	// completions will not be useful in comments.
-	if c.completionContext.triggerCharacter == "." {
-		return
-	}
-
-	// Using the comment position find the line after
-	file := c.pkg.FileSet().File(comment.End())
-	if file == nil {
-		return
-	}
-
-	// Deep completion doesn't work properly in comments since we don't
-	// have a type object to complete further.
-	c.deepState.enabled = false
-	c.completionContext.commentCompletion = true
-
-	// Documentation isn't useful in comments, since it might end up being the
-	// comment itself.
-	c.opts.documentation = false
-
-	commentLine := file.Line(comment.End())
-
-	// comment is valid, set surrounding as word boundaries around cursor
-	c.setSurroundingForComment(comment)
-
-	// Using the next line pos, grab and parse the exported symbol on that line
-	for _, n := range c.file.Decls {
-		declLine := file.Line(n.Pos())
-		// if the comment is not in, directly above or on the same line as a declaration
-		if declLine != commentLine && declLine != commentLine+1 &&
-			!(n.Pos() <= comment.Pos() && comment.End() <= n.End()) {
-			continue
-		}
-		switch node := n.(type) {
-		// handle const, vars, and types
-		case *ast.GenDecl:
-			for _, spec := range node.Specs {
-				switch spec := spec.(type) {
-				case *ast.ValueSpec:
-					for _, name := range spec.Names {
-						if name.String() == "_" {
-							continue
-						}
-						obj := c.pkg.GetTypesInfo().ObjectOf(name)
-						c.deepState.enqueue(candidate{obj: obj, score: stdScore})
-					}
-				case *ast.TypeSpec:
-					// add TypeSpec fields to completion
-					switch typeNode := spec.Type.(type) {
-					case *ast.StructType:
-						c.addFieldItems(ctx, typeNode.Fields)
-					case *ast.FuncType:
-						c.addFieldItems(ctx, typeNode.Params)
-						c.addFieldItems(ctx, typeNode.Results)
-					case *ast.InterfaceType:
-						c.addFieldItems(ctx, typeNode.Methods)
-					}
-
-					if spec.Name.String() == "_" {
-						continue
-					}
-
-					obj := c.pkg.GetTypesInfo().ObjectOf(spec.Name)
-					// Type name should get a higher score than fields but not highScore by default
-					// since field near a comment cursor gets a highScore
-					score := stdScore * 1.1
-					// If type declaration is on the line after comment, give it a highScore.
-					if declLine == commentLine+1 {
-						score = highScore
-					}
-
-					c.deepState.enqueue(candidate{obj: obj, score: score})
-				}
-			}
-		// handle functions
-		case *ast.FuncDecl:
-			c.addFieldItems(ctx, node.Recv)
-			c.addFieldItems(ctx, node.Type.Params)
-			c.addFieldItems(ctx, node.Type.Results)
-
-			// collect receiver struct fields
-			if node.Recv != nil {
-				for _, fields := range node.Recv.List {
-					for _, name := range fields.Names {
-						obj := c.pkg.GetTypesInfo().ObjectOf(name)
-						if obj == nil {
-							continue
-						}
-
-						recvType := obj.Type().Underlying()
-						if ptr, ok := recvType.(*types.Pointer); ok {
-							recvType = ptr.Elem()
-						}
-						recvStruct, ok := recvType.Underlying().(*types.Struct)
-						if !ok {
-							continue
-						}
-						for i := 0; i < recvStruct.NumFields(); i++ {
-							field := recvStruct.Field(i)
-							c.deepState.enqueue(candidate{obj: field, score: lowScore})
-						}
-					}
-				}
-			}
-
-			if node.Name.String() == "_" {
-				continue
-			}
-
-			obj := c.pkg.GetTypesInfo().ObjectOf(node.Name)
-			if obj == nil || obj.Pkg() != nil && obj.Pkg() != c.pkg.GetTypes() {
-				continue
-			}
-
-			c.deepState.enqueue(candidate{obj: obj, score: highScore})
-		}
-	}
-}
-
-// sets word boundaries surrounding a cursor for a comment
-func (c *completer) setSurroundingForComment(comments *ast.CommentGroup) {
-	var cursorComment *ast.Comment
-	for _, comment := range comments.List {
-		if c.pos >= comment.Pos() && c.pos <= comment.End() {
-			cursorComment = comment
-			break
-		}
-	}
-	// if cursor isn't in the comment
-	if cursorComment == nil {
-		return
-	}
-
-	// index of cursor in comment text
-	cursorOffset := int(c.pos - cursorComment.Pos())
-	start, end := cursorOffset, cursorOffset
-	for start > 0 && isValidIdentifierChar(cursorComment.Text[start-1]) {
-		start--
-	}
-	for end < len(cursorComment.Text) && isValidIdentifierChar(cursorComment.Text[end]) {
-		end++
-	}
-
-	c.surrounding = &Selection{
-		content: cursorComment.Text[start:end],
-		cursor:  c.pos,
-		rng:     span.NewRange(c.tokFile, token.Pos(int(cursorComment.Slash)+start), token.Pos(int(cursorComment.Slash)+end)),
-	}
-	c.setMatcherFromPrefix(c.surrounding.Prefix())
-}
-
-// isValidIdentifierChar returns true if a byte is a valid go identifier
-// character, i.e. unicode letter or digit or underscore.
-func isValidIdentifierChar(char byte) bool {
-	charRune := rune(char)
-	return unicode.In(charRune, unicode.Letter, unicode.Digit) || char == '_'
-}
-
-// adds struct fields, interface methods, function declaration fields to completion
-func (c *completer) addFieldItems(ctx context.Context, fields *ast.FieldList) {
-	if fields == nil {
-		return
-	}
-
-	cursor := c.surrounding.cursor
-	for _, field := range fields.List {
-		for _, name := range field.Names {
-			if name.String() == "_" {
-				continue
-			}
-			obj := c.pkg.GetTypesInfo().ObjectOf(name)
-			if obj == nil {
-				continue
-			}
-
-			// if we're in a field comment/doc, score that field as more relevant
-			score := stdScore
-			if field.Comment != nil && field.Comment.Pos() <= cursor && cursor <= field.Comment.End() {
-				score = highScore
-			} else if field.Doc != nil && field.Doc.Pos() <= cursor && cursor <= field.Doc.End() {
-				score = highScore
-			}
-
-			c.deepState.enqueue(candidate{obj: obj, score: score})
-		}
-	}
-}
-
-func (c *completer) wantStructFieldCompletions() bool {
-	clInfo := c.enclosingCompositeLiteral
-	if clInfo == nil {
-		return false
-	}
-
-	return clInfo.isStruct() && (clInfo.inKey || clInfo.maybeInFieldName)
-}
-
-func (c *completer) wantTypeName() bool {
-	return !c.completionContext.commentCompletion && c.inference.typeName.wantTypeName
-}
-
-// See https://golang.org/issue/36001. Unimported completions are expensive.
-const (
-	maxUnimportedPackageNames = 5
-	unimportedMemberTarget    = 100
-)
-
-// selector finds completions for the specified selector expression.
-func (c *completer) selector(ctx context.Context, sel *ast.SelectorExpr) error {
-	c.inference.objChain = objChain(c.pkg.GetTypesInfo(), sel.X)
-
-	// Is sel a qualified identifier?
-	if id, ok := sel.X.(*ast.Ident); ok {
-		if pkgName, ok := c.pkg.GetTypesInfo().Uses[id].(*types.PkgName); ok {
-			pkg, _ := c.pkg.DirectDep(source.PackagePath(pkgName.Imported().Path()))
-			// If the package is not imported, try searching for unimported
-			// completions.
-			if pkg == nil && c.opts.unimported {
-				if err := c.unimportedMembers(ctx, id); err != nil {
-					return err
-				}
-			}
-			c.packageMembers(pkgName.Imported(), stdScore, nil, func(cand candidate) {
-				c.deepState.enqueue(cand)
-			})
-			return nil
-		}
-	}
-
-	// Invariant: sel is a true selector.
-	tv, ok := c.pkg.GetTypesInfo().Types[sel.X]
-	if ok {
-		c.methodsAndFields(tv.Type, tv.Addressable(), nil, func(cand candidate) {
-			c.deepState.enqueue(cand)
-		})
-
-		c.addPostfixSnippetCandidates(ctx, sel)
-
-		return nil
-	}
-
-	// Try unimported packages.
-	if id, ok := sel.X.(*ast.Ident); ok && c.opts.unimported {
-		if err := c.unimportedMembers(ctx, id); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-func (c *completer) unimportedMembers(ctx context.Context, id *ast.Ident) error {
-	// Try loaded packages first. They're relevant, fast, and fully typed.
-	known, err := c.snapshot.CachedImportPaths(ctx)
-	if err != nil {
-		return err
-	}
-
-	var paths []string
-	for path, pkg := range known {
-		if pkg.GetTypes().Name() != id.Name {
-			continue
-		}
-		paths = append(paths, string(path))
-	}
-
-	var relevances map[string]float64
-	if len(paths) != 0 {
-		if err := c.snapshot.RunProcessEnvFunc(ctx, func(opts *imports.Options) error {
-			var err error
-			relevances, err = imports.ScoreImportPaths(ctx, opts.Env, paths)
-			return err
-		}); err != nil {
-			return err
-		}
-	}
-	sort.Slice(paths, func(i, j int) bool {
-		return relevances[paths[i]] > relevances[paths[j]]
-	})
-
-	for _, path := range paths {
-		pkg := known[source.PackagePath(path)]
-		if pkg.GetTypes().Name() != id.Name {
-			continue
-		}
-		imp := &importInfo{
-			importPath: path,
-		}
-		if imports.ImportPathToAssumedName(path) != pkg.GetTypes().Name() {
-			imp.name = pkg.GetTypes().Name()
-		}
-		c.packageMembers(pkg.GetTypes(), unimportedScore(relevances[path]), imp, func(cand candidate) {
-			c.deepState.enqueue(cand)
-		})
-		if len(c.items) >= unimportedMemberTarget {
-			return nil
-		}
-	}
-
-	ctx, cancel := context.WithCancel(ctx)
-
-	var mu sync.Mutex
-	add := func(pkgExport imports.PackageExport) {
-		mu.Lock()
-		defer mu.Unlock()
-		// TODO(adonovan): what if the actual package has a vendor/ prefix?
-		if _, ok := known[source.PackagePath(pkgExport.Fix.StmtInfo.ImportPath)]; ok {
-			return // We got this one above.
-		}
-
-		// Continue with untyped proposals.
-		pkg := types.NewPackage(pkgExport.Fix.StmtInfo.ImportPath, pkgExport.Fix.IdentName)
-		for _, export := range pkgExport.Exports {
-			score := unimportedScore(pkgExport.Fix.Relevance)
-			c.deepState.enqueue(candidate{
-				obj:   types.NewVar(0, pkg, export, nil),
-				score: score,
-				imp: &importInfo{
-					importPath: pkgExport.Fix.StmtInfo.ImportPath,
-					name:       pkgExport.Fix.StmtInfo.Name,
-				},
-			})
-		}
-		if len(c.items) >= unimportedMemberTarget {
-			cancel()
-		}
-	}
-
-	c.completionCallbacks = append(c.completionCallbacks, func(opts *imports.Options) error {
-		defer cancel()
-		return imports.GetPackageExports(ctx, add, id.Name, c.filename, c.pkg.GetTypes().Name(), opts.Env)
-	})
-	return nil
-}
-
-// unimportedScore returns a score for an unimported package that is generally
-// lower than other candidates.
-func unimportedScore(relevance float64) float64 {
-	return (stdScore + .1*relevance) / 2
-}
-
-func (c *completer) packageMembers(pkg *types.Package, score float64, imp *importInfo, cb func(candidate)) {
-	scope := pkg.Scope()
-	for _, name := range scope.Names() {
-		obj := scope.Lookup(name)
-		cb(candidate{
-			obj:         obj,
-			score:       score,
-			imp:         imp,
-			addressable: isVar(obj),
-		})
-	}
-}
-
-func (c *completer) methodsAndFields(typ types.Type, addressable bool, imp *importInfo, cb func(candidate)) {
-	mset := c.methodSetCache[methodSetKey{typ, addressable}]
-	if mset == nil {
-		if addressable && !types.IsInterface(typ) && !isPointer(typ) {
-			// Add methods of *T, which includes methods with receiver T.
-			mset = types.NewMethodSet(types.NewPointer(typ))
-		} else {
-			// Add methods of T.
-			mset = types.NewMethodSet(typ)
-		}
-		c.methodSetCache[methodSetKey{typ, addressable}] = mset
-	}
-
-	if isStarTestingDotF(typ) && addressable {
-		// is that a sufficient test? (or is more care needed?)
-		if c.fuzz(typ, mset, imp, cb, c.pkg.FileSet()) {
-			return
-		}
-	}
-
-	for i := 0; i < mset.Len(); i++ {
-		cb(candidate{
-			obj:         mset.At(i).Obj(),
-			score:       stdScore,
-			imp:         imp,
-			addressable: addressable || isPointer(typ),
-		})
-	}
-
-	// Add fields of T.
-	eachField(typ, func(v *types.Var) {
-		cb(candidate{
-			obj:         v,
-			score:       stdScore - 0.01,
-			imp:         imp,
-			addressable: addressable || isPointer(typ),
-		})
-	})
-}
-
-// isStarTestingDotF reports whether typ is *testing.F.
-func isStarTestingDotF(typ types.Type) bool {
-	ptr, _ := typ.(*types.Pointer)
-	if ptr == nil {
-		return false
-	}
-	named, _ := ptr.Elem().(*types.Named)
-	if named == nil {
-		return false
-	}
-	obj := named.Obj()
-	// obj.Pkg is nil for the error type.
-	return obj != nil && obj.Pkg() != nil && obj.Pkg().Path() == "testing" && obj.Name() == "F"
-}
-
-// lexical finds completions in the lexical environment.
-func (c *completer) lexical(ctx context.Context) error {
-	var (
-		builtinIota = types.Universe.Lookup("iota")
-		builtinNil  = types.Universe.Lookup("nil")
-		// comparable is an interface that exists on the dev.typeparams Go branch.
-		// Filter it out from completion results to stabilize tests.
-		// TODO(rFindley) update (or remove) our handling for comparable once the
-		//                type parameter API has stabilized.
-		builtinAny        = types.Universe.Lookup("any")
-		builtinComparable = types.Universe.Lookup("comparable")
-	)
-
-	// Track seen variables to avoid showing completions for shadowed variables.
-	// This works since we look at scopes from innermost to outermost.
-	seen := make(map[string]struct{})
-
-	// Process scopes innermost first.
-	for i, scope := range c.scopes {
-		if scope == nil {
-			continue
-		}
-
-	Names:
-		for _, name := range scope.Names() {
-			declScope, obj := scope.LookupParent(name, c.pos)
-			if declScope != scope {
-				continue // Name was declared in some enclosing scope, or not at all.
-			}
-			if obj == builtinComparable || obj == builtinAny {
-				continue
-			}
-
-			// If obj's type is invalid, find the AST node that defines the lexical block
-			// containing the declaration of obj. Don't resolve types for packages.
-			if !isPkgName(obj) && !typeIsValid(obj.Type()) {
-				// Match the scope to its ast.Node. If the scope is the package scope,
-				// use the *ast.File as the starting node.
-				var node ast.Node
-				if i < len(c.path) {
-					node = c.path[i]
-				} else if i == len(c.path) { // use the *ast.File for package scope
-					node = c.path[i-1]
-				}
-				if node != nil {
-					if resolved := resolveInvalid(c.pkg.FileSet(), obj, node, c.pkg.GetTypesInfo()); resolved != nil {
-						obj = resolved
-					}
-				}
-			}
-
-			// Don't use LHS of decl in RHS.
-			for _, ident := range enclosingDeclLHS(c.path) {
-				if obj.Pos() == ident.Pos() {
-					continue Names
-				}
-			}
-
-			// Don't suggest "iota" outside of const decls.
-			if obj == builtinIota && !c.inConstDecl() {
-				continue
-			}
-
-			// Rank outer scopes lower than inner.
-			score := stdScore * math.Pow(.99, float64(i))
-
-			// Dowrank "nil" a bit so it is ranked below more interesting candidates.
-			if obj == builtinNil {
-				score /= 2
-			}
-
-			// If we haven't already added a candidate for an object with this name.
-			if _, ok := seen[obj.Name()]; !ok {
-				seen[obj.Name()] = struct{}{}
-				c.deepState.enqueue(candidate{
-					obj:         obj,
-					score:       score,
-					addressable: isVar(obj),
-				})
-			}
-		}
-	}
-
-	if c.inference.objType != nil {
-		if named, _ := source.Deref(c.inference.objType).(*types.Named); named != nil {
-			// If we expected a named type, check the type's package for
-			// completion items. This is useful when the current file hasn't
-			// imported the type's package yet.
-
-			if named.Obj() != nil && named.Obj().Pkg() != nil {
-				pkg := named.Obj().Pkg()
-
-				// Make sure the package name isn't already in use by another
-				// object, and that this file doesn't import the package yet.
-				// TODO(adonovan): what if pkg.Path has vendor/ prefix?
-				if _, ok := seen[pkg.Name()]; !ok && pkg != c.pkg.GetTypes() && !alreadyImports(c.file, source.ImportPath(pkg.Path())) {
-					seen[pkg.Name()] = struct{}{}
-					obj := types.NewPkgName(0, nil, pkg.Name(), pkg)
-					imp := &importInfo{
-						importPath: pkg.Path(),
-					}
-					if imports.ImportPathToAssumedName(pkg.Path()) != pkg.Name() {
-						imp.name = pkg.Name()
-					}
-					c.deepState.enqueue(candidate{
-						obj:   obj,
-						score: stdScore,
-						imp:   imp,
-					})
-				}
-			}
-		}
-	}
-
-	if c.opts.unimported {
-		if err := c.unimportedPackages(ctx, seen); err != nil {
-			return err
-		}
-	}
-
-	if c.inference.typeName.isTypeParam {
-		// If we are completing a type param, offer each structural type.
-		// This ensures we suggest "[]int" and "[]float64" for a constraint
-		// with type union "[]int | []float64".
-		if t, _ := c.inference.objType.(*types.Interface); t != nil {
-			terms, _ := typeparams.InterfaceTermSet(t)
-			for _, term := range terms {
-				c.injectType(ctx, term.Type())
-			}
-		}
-	} else {
-		c.injectType(ctx, c.inference.objType)
-	}
-
-	// Add keyword completion items appropriate in the current context.
-	c.addKeywordCompletions()
-
-	return nil
-}
-
-// injectType manufacters candidates based on the given type. This is
-// intended for types not discoverable via lexical search, such as
-// composite and/or generic types. For example, if the type is "[]int",
-// this method makes sure you get candidates "[]int{}" and "[]int"
-// (the latter applies when completing a type name).
-func (c *completer) injectType(ctx context.Context, t types.Type) {
-	if t == nil {
-		return
-	}
-
-	t = source.Deref(t)
-
-	// If we have an expected type and it is _not_ a named type, handle
-	// it specially. Non-named types like "[]int" will never be
-	// considered via a lexical search, so we need to directly inject
-	// them. Also allow generic types since lexical search does not
-	// infer instantiated versions of them.
-	if named, _ := t.(*types.Named); named == nil || typeparams.ForNamed(named).Len() > 0 {
-		// If our expected type is "[]int", this will add a literal
-		// candidate of "[]int{}".
-		c.literal(ctx, t, nil)
-
-		if _, isBasic := t.(*types.Basic); !isBasic {
-			// If we expect a non-basic type name (e.g. "[]int"), hack up
-			// a named type whose name is literally "[]int". This allows
-			// us to reuse our object based completion machinery.
-			fakeNamedType := candidate{
-				obj:   types.NewTypeName(token.NoPos, nil, types.TypeString(t, c.qf), t),
-				score: stdScore,
-			}
-			// Make sure the type name matches before considering
-			// candidate. This cuts down on useless candidates.
-			if c.matchingTypeName(&fakeNamedType) {
-				c.deepState.enqueue(fakeNamedType)
-			}
-		}
-	}
-}
-
-func (c *completer) unimportedPackages(ctx context.Context, seen map[string]struct{}) error {
-	var prefix string
-	if c.surrounding != nil {
-		prefix = c.surrounding.Prefix()
-	}
-
-	// Don't suggest unimported packages if we have absolutely nothing
-	// to go on.
-	if prefix == "" {
-		return nil
-	}
-
-	count := 0
-
-	// TODO(adonovan): strength-reduce to a metadata query.
-	// All that's needed below is Package.{Name,Path}.
-	// Presumably that can be answered more thoroughly more quickly.
-	known, err := c.snapshot.CachedImportPaths(ctx)
-	if err != nil {
-		return err
-	}
-	var paths []string // actually PackagePaths
-	for path, pkg := range known {
-		if !strings.HasPrefix(pkg.GetTypes().Name(), prefix) {
-			continue
-		}
-		paths = append(paths, string(path))
-	}
-
-	var relevances map[string]float64
-	if len(paths) != 0 {
-		if err := c.snapshot.RunProcessEnvFunc(ctx, func(opts *imports.Options) error {
-			var err error
-			relevances, err = imports.ScoreImportPaths(ctx, opts.Env, paths)
-			return err
-		}); err != nil {
-			return err
-		}
-	}
-
-	sort.Slice(paths, func(i, j int) bool {
-		if relevances[paths[i]] != relevances[paths[j]] {
-			return relevances[paths[i]] > relevances[paths[j]]
-		}
-
-		// Fall back to lexical sort to keep truncated set of candidates
-		// in a consistent order.
-		return paths[i] < paths[j]
-	})
-
-	for _, path := range paths {
-		pkg := known[source.PackagePath(path)]
-		if _, ok := seen[pkg.GetTypes().Name()]; ok {
-			continue
-		}
-		imp := &importInfo{
-			importPath: path,
-		}
-		if imports.ImportPathToAssumedName(path) != pkg.GetTypes().Name() {
-			imp.name = pkg.GetTypes().Name()
-		}
-		if count >= maxUnimportedPackageNames {
-			return nil
-		}
-		c.deepState.enqueue(candidate{
-			// Pass an empty *types.Package to disable deep completions.
-			obj:   types.NewPkgName(0, nil, pkg.GetTypes().Name(), types.NewPackage(path, string(pkg.Name()))),
-			score: unimportedScore(relevances[path]),
-			imp:   imp,
-		})
-		count++
-	}
-
-	ctx, cancel := context.WithCancel(ctx)
-
-	var mu sync.Mutex
-	add := func(pkg imports.ImportFix) {
-		mu.Lock()
-		defer mu.Unlock()
-		if _, ok := seen[pkg.IdentName]; ok {
-			return
-		}
-		if _, ok := relevances[pkg.StmtInfo.ImportPath]; ok {
-			return
-		}
-
-		if count >= maxUnimportedPackageNames {
-			cancel()
-			return
-		}
-
-		// Do not add the unimported packages to seen, since we can have
-		// multiple packages of the same name as completion suggestions, since
-		// only one will be chosen.
-		obj := types.NewPkgName(0, nil, pkg.IdentName, types.NewPackage(pkg.StmtInfo.ImportPath, pkg.IdentName))
-		c.deepState.enqueue(candidate{
-			obj:   obj,
-			score: unimportedScore(pkg.Relevance),
-			imp: &importInfo{
-				importPath: pkg.StmtInfo.ImportPath,
-				name:       pkg.StmtInfo.Name,
-			},
-		})
-		count++
-	}
-	c.completionCallbacks = append(c.completionCallbacks, func(opts *imports.Options) error {
-		defer cancel()
-		return imports.GetAllCandidates(ctx, add, prefix, c.filename, c.pkg.GetTypes().Name(), opts.Env)
-	})
-	return nil
-}
-
-// alreadyImports reports whether f has an import with the specified path.
-func alreadyImports(f *ast.File, path source.ImportPath) bool {
-	for _, s := range f.Imports {
-		if source.UnquoteImportPath(s) == path {
-			return true
-		}
-	}
-	return false
-}
-
-func (c *completer) inConstDecl() bool {
-	for _, n := range c.path {
-		if decl, ok := n.(*ast.GenDecl); ok && decl.Tok == token.CONST {
-			return true
-		}
-	}
-	return false
-}
-
-// structLiteralFieldName finds completions for struct field names inside a struct literal.
-func (c *completer) structLiteralFieldName(ctx context.Context) error {
-	clInfo := c.enclosingCompositeLiteral
-
-	// Mark fields of the composite literal that have already been set,
-	// except for the current field.
-	addedFields := make(map[*types.Var]bool)
-	for _, el := range clInfo.cl.Elts {
-		if kvExpr, ok := el.(*ast.KeyValueExpr); ok {
-			if clInfo.kv == kvExpr {
-				continue
-			}
-
-			if key, ok := kvExpr.Key.(*ast.Ident); ok {
-				if used, ok := c.pkg.GetTypesInfo().Uses[key]; ok {
-					if usedVar, ok := used.(*types.Var); ok {
-						addedFields[usedVar] = true
-					}
-				}
-			}
-		}
-	}
-
-	deltaScore := 0.0001
-	switch t := clInfo.clType.(type) {
-	case *types.Struct:
-		for i := 0; i < t.NumFields(); i++ {
-			field := t.Field(i)
-			if !addedFields[field] {
-				c.deepState.enqueue(candidate{
-					obj:   field,
-					score: highScore - float64(i)*deltaScore,
-				})
-			}
-		}
-
-		// Add lexical completions if we aren't certain we are in the key part of a
-		// key-value pair.
-		if clInfo.maybeInFieldName {
-			return c.lexical(ctx)
-		}
-	default:
-		return c.lexical(ctx)
-	}
-
-	return nil
-}
-
-func (cl *compLitInfo) isStruct() bool {
-	_, ok := cl.clType.(*types.Struct)
-	return ok
-}
-
-// enclosingCompositeLiteral returns information about the composite literal enclosing the
-// position.
-func enclosingCompositeLiteral(path []ast.Node, pos token.Pos, info *types.Info) *compLitInfo {
-	for _, n := range path {
-		switch n := n.(type) {
-		case *ast.CompositeLit:
-			// The enclosing node will be a composite literal if the user has just
-			// opened the curly brace (e.g. &x{<>) or the completion request is triggered
-			// from an already completed composite literal expression (e.g. &x{foo: 1, <>})
-			//
-			// The position is not part of the composite literal unless it falls within the
-			// curly braces (e.g. "foo.Foo<>Struct{}").
-			if !(n.Lbrace < pos && pos <= n.Rbrace) {
-				// Keep searching since we may yet be inside a composite literal.
-				// For example "Foo{B: Ba<>{}}".
-				break
-			}
-
-			tv, ok := info.Types[n]
-			if !ok {
-				return nil
-			}
-
-			clInfo := compLitInfo{
-				cl:     n,
-				clType: source.Deref(tv.Type).Underlying(),
-			}
-
-			var (
-				expr    ast.Expr
-				hasKeys bool
-			)
-			for _, el := range n.Elts {
-				// Remember the expression that the position falls in, if any.
-				if el.Pos() <= pos && pos <= el.End() {
-					expr = el
-				}
-
-				if kv, ok := el.(*ast.KeyValueExpr); ok {
-					hasKeys = true
-					// If expr == el then we know the position falls in this expression,
-					// so also record kv as the enclosing *ast.KeyValueExpr.
-					if expr == el {
-						clInfo.kv = kv
-						break
-					}
-				}
-			}
-
-			if clInfo.kv != nil {
-				// If in a *ast.KeyValueExpr, we know we are in the key if the position
-				// is to the left of the colon (e.g. "Foo{F<>: V}".
-				clInfo.inKey = pos <= clInfo.kv.Colon
-			} else if hasKeys {
-				// If we aren't in a *ast.KeyValueExpr but the composite literal has
-				// other *ast.KeyValueExprs, we must be on the key side of a new
-				// *ast.KeyValueExpr (e.g. "Foo{F: V, <>}").
-				clInfo.inKey = true
-			} else {
-				switch clInfo.clType.(type) {
-				case *types.Struct:
-					if len(n.Elts) == 0 {
-						// If the struct literal is empty, next could be a struct field
-						// name or an expression (e.g. "Foo{<>}" could become "Foo{F:}"
-						// or "Foo{someVar}").
-						clInfo.maybeInFieldName = true
-					} else if len(n.Elts) == 1 {
-						// If there is one expression and the position is in that expression
-						// and the expression is an identifier, we may be writing a field
-						// name or an expression (e.g. "Foo{F<>}").
-						_, clInfo.maybeInFieldName = expr.(*ast.Ident)
-					}
-				case *types.Map:
-					// If we aren't in a *ast.KeyValueExpr we must be adding a new key
-					// to the map.
-					clInfo.inKey = true
-				}
-			}
-
-			return &clInfo
-		default:
-			if breaksExpectedTypeInference(n, pos) {
-				return nil
-			}
-		}
-	}
-
-	return nil
-}
-
-// enclosingFunction returns the signature and body of the function
-// enclosing the given position.
-func enclosingFunction(path []ast.Node, info *types.Info) *funcInfo {
-	for _, node := range path {
-		switch t := node.(type) {
-		case *ast.FuncDecl:
-			if obj, ok := info.Defs[t.Name]; ok {
-				return &funcInfo{
-					sig:  obj.Type().(*types.Signature),
-					body: t.Body,
-				}
-			}
-		case *ast.FuncLit:
-			if typ, ok := info.Types[t]; ok {
-				if sig, _ := typ.Type.(*types.Signature); sig == nil {
-					// golang/go#49397: it should not be possible, but we somehow arrived
-					// here with a non-signature type, most likely due to AST mangling
-					// such that node.Type is not a FuncType.
-					return nil
-				}
-				return &funcInfo{
-					sig:  typ.Type.(*types.Signature),
-					body: t.Body,
-				}
-			}
-		}
-	}
-	return nil
-}
-
-func (c *completer) expectedCompositeLiteralType() types.Type {
-	clInfo := c.enclosingCompositeLiteral
-	switch t := clInfo.clType.(type) {
-	case *types.Slice:
-		if clInfo.inKey {
-			return types.Typ[types.UntypedInt]
-		}
-		return t.Elem()
-	case *types.Array:
-		if clInfo.inKey {
-			return types.Typ[types.UntypedInt]
-		}
-		return t.Elem()
-	case *types.Map:
-		if clInfo.inKey {
-			return t.Key()
-		}
-		return t.Elem()
-	case *types.Struct:
-		// If we are completing a key (i.e. field name), there is no expected type.
-		if clInfo.inKey {
-			return nil
-		}
-
-		// If we are in a key-value pair, but not in the key, then we must be on the
-		// value side. The expected type of the value will be determined from the key.
-		if clInfo.kv != nil {
-			if key, ok := clInfo.kv.Key.(*ast.Ident); ok {
-				for i := 0; i < t.NumFields(); i++ {
-					if field := t.Field(i); field.Name() == key.Name {
-						return field.Type()
-					}
-				}
-			}
-		} else {
-			// If we aren't in a key-value pair and aren't in the key, we must be using
-			// implicit field names.
-
-			// The order of the literal fields must match the order in the struct definition.
-			// Find the element that the position belongs to and suggest that field's type.
-			if i := exprAtPos(c.pos, clInfo.cl.Elts); i < t.NumFields() {
-				return t.Field(i).Type()
-			}
-		}
-	}
-	return nil
-}
-
-// typeMod represents an operator that changes the expected type.
-type typeMod struct {
-	mod      typeModKind
-	arrayLen int64
-}
-
-type typeModKind int
-
-const (
-	dereference   typeModKind = iota // pointer indirection: "*"
-	reference                        // adds level of pointer: "&" for values, "*" for type names
-	chanRead                         // channel read operator: "<-"
-	sliceType                        // make a slice type: "[]" in "[]int"
-	arrayType                        // make an array type: "[2]" in "[2]int"
-	invoke                           // make a function call: "()" in "foo()"
-	takeSlice                        // take slice of array: "[:]" in "foo[:]"
-	takeDotDotDot                    // turn slice into variadic args: "..." in "foo..."
-	index                            // index into slice/array: "[0]" in "foo[0]"
-)
-
-type objKind int
-
-const (
-	kindAny   objKind = 0
-	kindArray objKind = 1 << iota
-	kindSlice
-	kindChan
-	kindMap
-	kindStruct
-	kindString
-	kindInt
-	kindBool
-	kindBytes
-	kindPtr
-	kindFloat
-	kindComplex
-	kindError
-	kindStringer
-	kindFunc
-)
-
-// penalizedObj represents an object that should be disfavored as a
-// completion candidate.
-type penalizedObj struct {
-	// objChain is the full "chain", e.g. "foo.bar().baz" becomes
-	// []types.Object{foo, bar, baz}.
-	objChain []types.Object
-	// penalty is score penalty in the range (0, 1).
-	penalty float64
-}
-
-// candidateInference holds information we have inferred about a type that can be
-// used at the current position.
-type candidateInference struct {
-	// objType is the desired type of an object used at the query position.
-	objType types.Type
-
-	// objKind is a mask of expected kinds of types such as "map", "slice", etc.
-	objKind objKind
-
-	// variadic is true if we are completing the initial variadic
-	// parameter. For example:
-	//   append([]T{}, <>)      // objType=T variadic=true
-	//   append([]T{}, T{}, <>) // objType=T variadic=false
-	variadic bool
-
-	// modifiers are prefixes such as "*", "&" or "<-" that influence how
-	// a candidate type relates to the expected type.
-	modifiers []typeMod
-
-	// convertibleTo is a type our candidate type must be convertible to.
-	convertibleTo types.Type
-
-	// typeName holds information about the expected type name at
-	// position, if any.
-	typeName typeNameInference
-
-	// assignees are the types that would receive a function call's
-	// results at the position. For example:
-	//
-	// foo := 123
-	// foo, bar := <>
-	//
-	// at "<>", the assignees are [int, <invalid>].
-	assignees []types.Type
-
-	// variadicAssignees is true if we could be completing an inner
-	// function call that fills out an outer function call's variadic
-	// params. For example:
-	//
-	// func foo(int, ...string) {}
-	//
-	// foo(<>)         // variadicAssignees=true
-	// foo(bar<>)      // variadicAssignees=true
-	// foo(bar, baz<>) // variadicAssignees=false
-	variadicAssignees bool
-
-	// penalized holds expressions that should be disfavored as
-	// candidates. For example, it tracks expressions already used in a
-	// switch statement's other cases. Each expression is tracked using
-	// its entire object "chain" allowing differentiation between
-	// "a.foo" and "b.foo" when "a" and "b" are the same type.
-	penalized []penalizedObj
-
-	// objChain contains the chain of objects representing the
-	// surrounding *ast.SelectorExpr. For example, if we are completing
-	// "foo.bar.ba<>", objChain will contain []types.Object{foo, bar}.
-	objChain []types.Object
-}
-
-// typeNameInference holds information about the expected type name at
-// position.
-type typeNameInference struct {
-	// wantTypeName is true if we expect the name of a type.
-	wantTypeName bool
-
-	// modifiers are prefixes such as "*", "&" or "<-" that influence how
-	// a candidate type relates to the expected type.
-	modifiers []typeMod
-
-	// assertableFrom is a type that must be assertable to our candidate type.
-	assertableFrom types.Type
-
-	// wantComparable is true if we want a comparable type.
-	wantComparable bool
-
-	// seenTypeSwitchCases tracks types that have already been used by
-	// the containing type switch.
-	seenTypeSwitchCases []types.Type
-
-	// compLitType is true if we are completing a composite literal type
-	// name, e.g "foo<>{}".
-	compLitType bool
-
-	// isTypeParam is true if we are completing a type instantiation parameter
-	isTypeParam bool
-}
-
-// expectedCandidate returns information about the expected candidate
-// for an expression at the query position.
-func expectedCandidate(ctx context.Context, c *completer) (inf candidateInference) {
-	inf.typeName = expectTypeName(c)
-
-	if c.enclosingCompositeLiteral != nil {
-		inf.objType = c.expectedCompositeLiteralType()
-	}
-
-Nodes:
-	for i, node := range c.path {
-		switch node := node.(type) {
-		case *ast.BinaryExpr:
-			// Determine if query position comes from left or right of op.
-			e := node.X
-			if c.pos < node.OpPos {
-				e = node.Y
-			}
-			if tv, ok := c.pkg.GetTypesInfo().Types[e]; ok {
-				switch node.Op {
-				case token.LAND, token.LOR:
-					// Don't infer "bool" type for "&&" or "||". Often you want
-					// to compose a boolean expression from non-boolean
-					// candidates.
-				default:
-					inf.objType = tv.Type
-				}
-				break Nodes
-			}
-		case *ast.AssignStmt:
-			// Only rank completions if you are on the right side of the token.
-			if c.pos > node.TokPos {
-				i := exprAtPos(c.pos, node.Rhs)
-				if i >= len(node.Lhs) {
-					i = len(node.Lhs) - 1
-				}
-				if tv, ok := c.pkg.GetTypesInfo().Types[node.Lhs[i]]; ok {
-					inf.objType = tv.Type
-				}
-
-				// If we have a single expression on the RHS, record the LHS
-				// assignees so we can favor multi-return function calls with
-				// matching result values.
-				if len(node.Rhs) <= 1 {
-					for _, lhs := range node.Lhs {
-						inf.assignees = append(inf.assignees, c.pkg.GetTypesInfo().TypeOf(lhs))
-					}
-				} else {
-					// Otherwise, record our single assignee, even if its type is
-					// not available. We use this info to downrank functions
-					// with the wrong number of result values.
-					inf.assignees = append(inf.assignees, c.pkg.GetTypesInfo().TypeOf(node.Lhs[i]))
-				}
-			}
-			return inf
-		case *ast.ValueSpec:
-			if node.Type != nil && c.pos > node.Type.End() {
-				inf.objType = c.pkg.GetTypesInfo().TypeOf(node.Type)
-			}
-			return inf
-		case *ast.CallExpr:
-			// Only consider CallExpr args if position falls between parens.
-			if node.Lparen < c.pos && c.pos <= node.Rparen {
-				// For type conversions like "int64(foo)" we can only infer our
-				// desired type is convertible to int64.
-				if typ := typeConversion(node, c.pkg.GetTypesInfo()); typ != nil {
-					inf.convertibleTo = typ
-					break Nodes
-				}
-
-				sig, _ := c.pkg.GetTypesInfo().Types[node.Fun].Type.(*types.Signature)
-
-				if sig != nil && typeparams.ForSignature(sig).Len() > 0 {
-					// If we are completing a generic func call, re-check the call expression.
-					// This allows type param inference to work in cases like:
-					//
-					// func foo[T any](T) {}
-					// foo[int](<>) // <- get "int" completions instead of "T"
-					//
-					// TODO: remove this after https://go.dev/issue/52503
-					info := &types.Info{Types: make(map[ast.Expr]types.TypeAndValue)}
-					types.CheckExpr(c.pkg.FileSet(), c.pkg.GetTypes(), node.Fun.Pos(), node.Fun, info)
-					sig, _ = info.Types[node.Fun].Type.(*types.Signature)
-				}
-
-				if sig != nil {
-					inf = c.expectedCallParamType(inf, node, sig)
-				}
-
-				if funIdent, ok := node.Fun.(*ast.Ident); ok {
-					obj := c.pkg.GetTypesInfo().ObjectOf(funIdent)
-
-					if obj != nil && obj.Parent() == types.Universe {
-						// Defer call to builtinArgType so we can provide it the
-						// inferred type from its parent node.
-						defer func() {
-							inf = c.builtinArgType(obj, node, inf)
-							inf.objKind = c.builtinArgKind(ctx, obj, node)
-						}()
-
-						// The expected type of builtin arguments like append() is
-						// the expected type of the builtin call itself. For
-						// example:
-						//
-						// var foo []int = append(<>)
-						//
-						// To find the expected type at <> we "skip" the append()
-						// node and get the expected type one level up, which is
-						// []int.
-						continue Nodes
-					}
-				}
-
-				return inf
-			}
-		case *ast.ReturnStmt:
-			if c.enclosingFunc != nil {
-				sig := c.enclosingFunc.sig
-				// Find signature result that corresponds to our return statement.
-				if resultIdx := exprAtPos(c.pos, node.Results); resultIdx < len(node.Results) {
-					if resultIdx < sig.Results().Len() {
-						inf.objType = sig.Results().At(resultIdx).Type()
-					}
-				}
-			}
-			return inf
-		case *ast.CaseClause:
-			if swtch, ok := findSwitchStmt(c.path[i+1:], c.pos, node).(*ast.SwitchStmt); ok {
-				if tv, ok := c.pkg.GetTypesInfo().Types[swtch.Tag]; ok {
-					inf.objType = tv.Type
-
-					// Record which objects have already been used in the case
-					// statements so we don't suggest them again.
-					for _, cc := range swtch.Body.List {
-						for _, caseExpr := range cc.(*ast.CaseClause).List {
-							// Don't record the expression we are currently completing.
-							if caseExpr.Pos() < c.pos && c.pos <= caseExpr.End() {
-								continue
-							}
-
-							if objs := objChain(c.pkg.GetTypesInfo(), caseExpr); len(objs) > 0 {
-								inf.penalized = append(inf.penalized, penalizedObj{objChain: objs, penalty: 0.1})
-							}
-						}
-					}
-				}
-			}
-			return inf
-		case *ast.SliceExpr:
-			// Make sure position falls within the brackets (e.g. "foo[a:<>]").
-			if node.Lbrack < c.pos && c.pos <= node.Rbrack {
-				inf.objType = types.Typ[types.UntypedInt]
-			}
-			return inf
-		case *ast.IndexExpr:
-			// Make sure position falls within the brackets (e.g. "foo[<>]").
-			if node.Lbrack < c.pos && c.pos <= node.Rbrack {
-				if tv, ok := c.pkg.GetTypesInfo().Types[node.X]; ok {
-					switch t := tv.Type.Underlying().(type) {
-					case *types.Map:
-						inf.objType = t.Key()
-					case *types.Slice, *types.Array:
-						inf.objType = types.Typ[types.UntypedInt]
-					}
-
-					if ct := expectedConstraint(tv.Type, 0); ct != nil {
-						inf.objType = ct
-						inf.typeName.wantTypeName = true
-						inf.typeName.isTypeParam = true
-					}
-				}
-			}
-			return inf
-		case *typeparams.IndexListExpr:
-			if node.Lbrack < c.pos && c.pos <= node.Rbrack {
-				if tv, ok := c.pkg.GetTypesInfo().Types[node.X]; ok {
-					if ct := expectedConstraint(tv.Type, exprAtPos(c.pos, node.Indices)); ct != nil {
-						inf.objType = ct
-						inf.typeName.wantTypeName = true
-						inf.typeName.isTypeParam = true
-					}
-				}
-			}
-			return inf
-		case *ast.SendStmt:
-			// Make sure we are on right side of arrow (e.g. "foo <- <>").
-			if c.pos > node.Arrow+1 {
-				if tv, ok := c.pkg.GetTypesInfo().Types[node.Chan]; ok {
-					if ch, ok := tv.Type.Underlying().(*types.Chan); ok {
-						inf.objType = ch.Elem()
-					}
-				}
-			}
-			return inf
-		case *ast.RangeStmt:
-			if source.NodeContains(node.X, c.pos) {
-				inf.objKind |= kindSlice | kindArray | kindMap | kindString
-				if node.Value == nil {
-					inf.objKind |= kindChan
-				}
-			}
-			return inf
-		case *ast.StarExpr:
-			inf.modifiers = append(inf.modifiers, typeMod{mod: dereference})
-		case *ast.UnaryExpr:
-			switch node.Op {
-			case token.AND:
-				inf.modifiers = append(inf.modifiers, typeMod{mod: reference})
-			case token.ARROW:
-				inf.modifiers = append(inf.modifiers, typeMod{mod: chanRead})
-			}
-		case *ast.DeferStmt, *ast.GoStmt:
-			inf.objKind |= kindFunc
-			return inf
-		default:
-			if breaksExpectedTypeInference(node, c.pos) {
-				return inf
-			}
-		}
-	}
-
-	return inf
-}
-
-func (c *completer) expectedCallParamType(inf candidateInference, node *ast.CallExpr, sig *types.Signature) candidateInference {
-	numParams := sig.Params().Len()
-	if numParams == 0 {
-		return inf
-	}
-
-	exprIdx := exprAtPos(c.pos, node.Args)
-
-	// If we have one or zero arg expressions, we may be
-	// completing to a function call that returns multiple
-	// values, in turn getting passed in to the surrounding
-	// call. Record the assignees so we can favor function
-	// calls that return matching values.
-	if len(node.Args) <= 1 && exprIdx == 0 {
-		for i := 0; i < sig.Params().Len(); i++ {
-			inf.assignees = append(inf.assignees, sig.Params().At(i).Type())
-		}
-
-		// Record that we may be completing into variadic parameters.
-		inf.variadicAssignees = sig.Variadic()
-	}
-
-	// Make sure not to run past the end of expected parameters.
-	if exprIdx >= numParams {
-		inf.objType = sig.Params().At(numParams - 1).Type()
-	} else {
-		inf.objType = sig.Params().At(exprIdx).Type()
-	}
-
-	if sig.Variadic() && exprIdx >= (numParams-1) {
-		// If we are completing a variadic param, deslice the variadic type.
-		inf.objType = deslice(inf.objType)
-		// Record whether we are completing the initial variadic param.
-		inf.variadic = exprIdx == numParams-1 && len(node.Args) <= numParams
-
-		// Check if we can infer object kind from printf verb.
-		inf.objKind |= printfArgKind(c.pkg.GetTypesInfo(), node, exprIdx)
-	}
-
-	// If our expected type is an uninstantiated generic type param,
-	// swap to the constraint which will do a decent job filtering
-	// candidates.
-	if tp, _ := inf.objType.(*typeparams.TypeParam); tp != nil {
-		inf.objType = tp.Constraint()
-	}
-
-	return inf
-}
-
-func expectedConstraint(t types.Type, idx int) types.Type {
-	var tp *typeparams.TypeParamList
-	if named, _ := t.(*types.Named); named != nil {
-		tp = typeparams.ForNamed(named)
-	} else if sig, _ := t.Underlying().(*types.Signature); sig != nil {
-		tp = typeparams.ForSignature(sig)
-	}
-	if tp == nil || idx >= tp.Len() {
-		return nil
-	}
-	return tp.At(idx).Constraint()
-}
-
-// objChain decomposes e into a chain of objects if possible. For
-// example, "foo.bar().baz" will yield []types.Object{foo, bar, baz}.
-// If any part can't be turned into an object, return nil.
-func objChain(info *types.Info, e ast.Expr) []types.Object {
-	var objs []types.Object
-
-	for e != nil {
-		switch n := e.(type) {
-		case *ast.Ident:
-			obj := info.ObjectOf(n)
-			if obj == nil {
-				return nil
-			}
-			objs = append(objs, obj)
-			e = nil
-		case *ast.SelectorExpr:
-			obj := info.ObjectOf(n.Sel)
-			if obj == nil {
-				return nil
-			}
-			objs = append(objs, obj)
-			e = n.X
-		case *ast.CallExpr:
-			if len(n.Args) > 0 {
-				return nil
-			}
-			e = n.Fun
-		default:
-			return nil
-		}
-	}
-
-	// Reverse order so the layout matches the syntactic order.
-	for i := 0; i < len(objs)/2; i++ {
-		objs[i], objs[len(objs)-1-i] = objs[len(objs)-1-i], objs[i]
-	}
-
-	return objs
-}
-
-// applyTypeModifiers applies the list of type modifiers to a type.
-// It returns nil if the modifiers could not be applied.
-func (ci candidateInference) applyTypeModifiers(typ types.Type, addressable bool) types.Type {
-	for _, mod := range ci.modifiers {
-		switch mod.mod {
-		case dereference:
-			// For every "*" indirection operator, remove a pointer layer
-			// from candidate type.
-			if ptr, ok := typ.Underlying().(*types.Pointer); ok {
-				typ = ptr.Elem()
-			} else {
-				return nil
-			}
-		case reference:
-			// For every "&" address operator, add another pointer layer to
-			// candidate type, if the candidate is addressable.
-			if addressable {
-				typ = types.NewPointer(typ)
-			} else {
-				return nil
-			}
-		case chanRead:
-			// For every "<-" operator, remove a layer of channelness.
-			if ch, ok := typ.(*types.Chan); ok {
-				typ = ch.Elem()
-			} else {
-				return nil
-			}
-		}
-	}
-
-	return typ
-}
-
-// applyTypeNameModifiers applies the list of type modifiers to a type name.
-func (ci candidateInference) applyTypeNameModifiers(typ types.Type) types.Type {
-	for _, mod := range ci.typeName.modifiers {
-		switch mod.mod {
-		case reference:
-			typ = types.NewPointer(typ)
-		case arrayType:
-			typ = types.NewArray(typ, mod.arrayLen)
-		case sliceType:
-			typ = types.NewSlice(typ)
-		}
-	}
-	return typ
-}
-
-// matchesVariadic returns true if we are completing a variadic
-// parameter and candType is a compatible slice type.
-func (ci candidateInference) matchesVariadic(candType types.Type) bool {
-	return ci.variadic && ci.objType != nil && assignableTo(candType, types.NewSlice(ci.objType))
-}
-
-// findSwitchStmt returns an *ast.CaseClause's corresponding *ast.SwitchStmt or
-// *ast.TypeSwitchStmt. path should start from the case clause's first ancestor.
-func findSwitchStmt(path []ast.Node, pos token.Pos, c *ast.CaseClause) ast.Stmt {
-	// Make sure position falls within a "case <>:" clause.
-	if exprAtPos(pos, c.List) >= len(c.List) {
-		return nil
-	}
-	// A case clause is always nested within a block statement in a switch statement.
-	if len(path) < 2 {
-		return nil
-	}
-	if _, ok := path[0].(*ast.BlockStmt); !ok {
-		return nil
-	}
-	switch s := path[1].(type) {
-	case *ast.SwitchStmt:
-		return s
-	case *ast.TypeSwitchStmt:
-		return s
-	default:
-		return nil
-	}
-}
-
-// breaksExpectedTypeInference reports if an expression node's type is unrelated
-// to its child expression node types. For example, "Foo{Bar: x.Baz(<>)}" should
-// expect a function argument, not a composite literal value.
-func breaksExpectedTypeInference(n ast.Node, pos token.Pos) bool {
-	switch n := n.(type) {
-	case *ast.CompositeLit:
-		// Doesn't break inference if pos is in type name.
-		// For example: "Foo<>{Bar: 123}"
-		return !source.NodeContains(n.Type, pos)
-	case *ast.CallExpr:
-		// Doesn't break inference if pos is in func name.
-		// For example: "Foo<>(123)"
-		return !source.NodeContains(n.Fun, pos)
-	case *ast.FuncLit, *ast.IndexExpr, *ast.SliceExpr:
-		return true
-	default:
-		return false
-	}
-}
-
-// expectTypeName returns information about the expected type name at position.
-func expectTypeName(c *completer) typeNameInference {
-	var inf typeNameInference
-
-Nodes:
-	for i, p := range c.path {
-		switch n := p.(type) {
-		case *ast.FieldList:
-			// Expect a type name if pos is in a FieldList. This applies to
-			// FuncType params/results, FuncDecl receiver, StructType, and
-			// InterfaceType. We don't need to worry about the field name
-			// because completion bails out early if pos is in an *ast.Ident
-			// that defines an object.
-			inf.wantTypeName = true
-			break Nodes
-		case *ast.CaseClause:
-			// Expect type names in type switch case clauses.
-			if swtch, ok := findSwitchStmt(c.path[i+1:], c.pos, n).(*ast.TypeSwitchStmt); ok {
-				// The case clause types must be assertable from the type switch parameter.
-				ast.Inspect(swtch.Assign, func(n ast.Node) bool {
-					if ta, ok := n.(*ast.TypeAssertExpr); ok {
-						inf.assertableFrom = c.pkg.GetTypesInfo().TypeOf(ta.X)
-						return false
-					}
-					return true
-				})
-				inf.wantTypeName = true
-
-				// Track the types that have already been used in this
-				// switch's case statements so we don't recommend them.
-				for _, e := range swtch.Body.List {
-					for _, typeExpr := range e.(*ast.CaseClause).List {
-						// Skip if type expression contains pos. We don't want to
-						// count it as already used if the user is completing it.
-						if typeExpr.Pos() < c.pos && c.pos <= typeExpr.End() {
-							continue
-						}
-
-						if t := c.pkg.GetTypesInfo().TypeOf(typeExpr); t != nil {
-							inf.seenTypeSwitchCases = append(inf.seenTypeSwitchCases, t)
-						}
-					}
-				}
-
-				break Nodes
-			}
-			return typeNameInference{}
-		case *ast.TypeAssertExpr:
-			// Expect type names in type assert expressions.
-			if n.Lparen < c.pos && c.pos <= n.Rparen {
-				// The type in parens must be assertable from the expression type.
-				inf.assertableFrom = c.pkg.GetTypesInfo().TypeOf(n.X)
-				inf.wantTypeName = true
-				break Nodes
-			}
-			return typeNameInference{}
-		case *ast.StarExpr:
-			inf.modifiers = append(inf.modifiers, typeMod{mod: reference})
-		case *ast.CompositeLit:
-			// We want a type name if position is in the "Type" part of a
-			// composite literal (e.g. "Foo<>{}").
-			if n.Type != nil && n.Type.Pos() <= c.pos && c.pos <= n.Type.End() {
-				inf.wantTypeName = true
-				inf.compLitType = true
-
-				if i < len(c.path)-1 {
-					// Track preceding "&" operator. Technically it applies to
-					// the composite literal and not the type name, but if
-					// affects our type completion nonetheless.
-					if u, ok := c.path[i+1].(*ast.UnaryExpr); ok && u.Op == token.AND {
-						inf.modifiers = append(inf.modifiers, typeMod{mod: reference})
-					}
-				}
-			}
-			break Nodes
-		case *ast.ArrayType:
-			// If we are inside the "Elt" part of an array type, we want a type name.
-			if n.Elt.Pos() <= c.pos && c.pos <= n.Elt.End() {
-				inf.wantTypeName = true
-				if n.Len == nil {
-					// No "Len" expression means a slice type.
-					inf.modifiers = append(inf.modifiers, typeMod{mod: sliceType})
-				} else {
-					// Try to get the array type using the constant value of "Len".
-					tv, ok := c.pkg.GetTypesInfo().Types[n.Len]
-					if ok && tv.Value != nil && tv.Value.Kind() == constant.Int {
-						if arrayLen, ok := constant.Int64Val(tv.Value); ok {
-							inf.modifiers = append(inf.modifiers, typeMod{mod: arrayType, arrayLen: arrayLen})
-						}
-					}
-				}
-
-				// ArrayTypes can be nested, so keep going if our parent is an
-				// ArrayType.
-				if i < len(c.path)-1 {
-					if _, ok := c.path[i+1].(*ast.ArrayType); ok {
-						continue Nodes
-					}
-				}
-
-				break Nodes
-			}
-		case *ast.MapType:
-			inf.wantTypeName = true
-			if n.Key != nil {
-				inf.wantComparable = source.NodeContains(n.Key, c.pos)
-			} else {
-				// If the key is empty, assume we are completing the key if
-				// pos is directly after the "map[".
-				inf.wantComparable = c.pos == n.Pos()+token.Pos(len("map["))
-			}
-			break Nodes
-		case *ast.ValueSpec:
-			inf.wantTypeName = source.NodeContains(n.Type, c.pos)
-			break Nodes
-		case *ast.TypeSpec:
-			inf.wantTypeName = source.NodeContains(n.Type, c.pos)
-		default:
-			if breaksExpectedTypeInference(p, c.pos) {
-				return typeNameInference{}
-			}
-		}
-	}
-
-	return inf
-}
-
-func (c *completer) fakeObj(T types.Type) *types.Var {
-	return types.NewVar(token.NoPos, c.pkg.GetTypes(), "", T)
-}
-
-// derivableTypes iterates types you can derive from t. For example,
-// from "foo" we might derive "&foo", and "foo()".
-func derivableTypes(t types.Type, addressable bool, f func(t types.Type, addressable bool, mod typeModKind) bool) bool {
-	switch t := t.Underlying().(type) {
-	case *types.Signature:
-		// If t is a func type with a single result, offer the result type.
-		if t.Results().Len() == 1 && f(t.Results().At(0).Type(), false, invoke) {
-			return true
-		}
-	case *types.Array:
-		if f(t.Elem(), true, index) {
-			return true
-		}
-		// Try converting array to slice.
-		if f(types.NewSlice(t.Elem()), false, takeSlice) {
-			return true
-		}
-	case *types.Pointer:
-		if f(t.Elem(), false, dereference) {
-			return true
-		}
-	case *types.Slice:
-		if f(t.Elem(), true, index) {
-			return true
-		}
-	case *types.Map:
-		if f(t.Elem(), false, index) {
-			return true
-		}
-	case *types.Chan:
-		if f(t.Elem(), false, chanRead) {
-			return true
-		}
-	}
-
-	// Check if c is addressable and a pointer to c matches our type inference.
-	if addressable && f(types.NewPointer(t), false, reference) {
-		return true
-	}
-
-	return false
-}
-
-// anyCandType reports whether f returns true for any candidate type
-// derivable from c. It searches up to three levels of type
-// modification. For example, given "foo" we could discover "***foo"
-// or "*foo()".
-func (c *candidate) anyCandType(f func(t types.Type, addressable bool) bool) bool {
-	if c.obj == nil || c.obj.Type() == nil {
-		return false
-	}
-
-	const maxDepth = 3
-
-	var searchTypes func(t types.Type, addressable bool, mods []typeModKind) bool
-	searchTypes = func(t types.Type, addressable bool, mods []typeModKind) bool {
-		if f(t, addressable) {
-			if len(mods) > 0 {
-				newMods := make([]typeModKind, len(mods)+len(c.mods))
-				copy(newMods, mods)
-				copy(newMods[len(mods):], c.mods)
-				c.mods = newMods
-			}
-			return true
-		}
-
-		if len(mods) == maxDepth {
-			return false
-		}
-
-		return derivableTypes(t, addressable, func(t types.Type, addressable bool, mod typeModKind) bool {
-			return searchTypes(t, addressable, append(mods, mod))
-		})
-	}
-
-	return searchTypes(c.obj.Type(), c.addressable, make([]typeModKind, 0, maxDepth))
-}
-
-// matchingCandidate reports whether cand matches our type inferences.
-// It mutates cand's score in certain cases.
-func (c *completer) matchingCandidate(cand *candidate) bool {
-	if c.completionContext.commentCompletion {
-		return false
-	}
-
-	// Bail out early if we are completing a field name in a composite literal.
-	if v, ok := cand.obj.(*types.Var); ok && v.IsField() && c.wantStructFieldCompletions() {
-		return true
-	}
-
-	if isTypeName(cand.obj) {
-		return c.matchingTypeName(cand)
-	} else if c.wantTypeName() {
-		// If we want a type, a non-type object never matches.
-		return false
-	}
-
-	if c.inference.candTypeMatches(cand) {
-		return true
-	}
-
-	candType := cand.obj.Type()
-	if candType == nil {
-		return false
-	}
-
-	if sig, ok := candType.Underlying().(*types.Signature); ok {
-		if c.inference.assigneesMatch(cand, sig) {
-			// Invoke the candidate if its results are multi-assignable.
-			cand.mods = append(cand.mods, invoke)
-			return true
-		}
-	}
-
-	// Default to invoking *types.Func candidates. This is so function
-	// completions in an empty statement (or other cases with no expected type)
-	// are invoked by default.
-	if isFunc(cand.obj) {
-		cand.mods = append(cand.mods, invoke)
-	}
-
-	return false
-}
-
-// candTypeMatches reports whether cand makes a good completion
-// candidate given the candidate inference. cand's score may be
-// mutated to downrank the candidate in certain situations.
-func (ci *candidateInference) candTypeMatches(cand *candidate) bool {
-	var (
-		expTypes     = make([]types.Type, 0, 2)
-		variadicType types.Type
-	)
-	if ci.objType != nil {
-		expTypes = append(expTypes, ci.objType)
-
-		if ci.variadic {
-			variadicType = types.NewSlice(ci.objType)
-			expTypes = append(expTypes, variadicType)
-		}
-	}
-
-	return cand.anyCandType(func(candType types.Type, addressable bool) bool {
-		// Take into account any type modifiers on the expected type.
-		candType = ci.applyTypeModifiers(candType, addressable)
-		if candType == nil {
-			return false
-		}
-
-		if ci.convertibleTo != nil && convertibleTo(candType, ci.convertibleTo) {
-			return true
-		}
-
-		for _, expType := range expTypes {
-			if isEmptyInterface(expType) {
-				continue
-			}
-
-			matches := ci.typeMatches(expType, candType)
-			if !matches {
-				// If candType doesn't otherwise match, consider if we can
-				// convert candType directly to expType.
-				if considerTypeConversion(candType, expType, cand.path) {
-					cand.convertTo = expType
-					// Give a major score penalty so we always prefer directly
-					// assignable candidates, all else equal.
-					cand.score *= 0.5
-					return true
-				}
-
-				continue
-			}
-
-			if expType == variadicType {
-				cand.mods = append(cand.mods, takeDotDotDot)
-			}
-
-			// Lower candidate score for untyped conversions. This avoids
-			// ranking untyped constants above candidates with an exact type
-			// match. Don't lower score of builtin constants, e.g. "true".
-			if isUntyped(candType) && !types.Identical(candType, expType) && cand.obj.Parent() != types.Universe {
-				// Bigger penalty for deep completions into other packages to
-				// avoid random constants from other packages popping up all
-				// the time.
-				if len(cand.path) > 0 && isPkgName(cand.path[0]) {
-					cand.score *= 0.5
-				} else {
-					cand.score *= 0.75
-				}
-			}
-
-			return true
-		}
-
-		// If we don't have a specific expected type, fall back to coarser
-		// object kind checks.
-		if ci.objType == nil || isEmptyInterface(ci.objType) {
-			// If we were able to apply type modifiers to our candidate type,
-			// count that as a match. For example:
-			//
-			//   var foo chan int
-			//   <-fo<>
-			//
-			// We were able to apply the "<-" type modifier to "foo", so "foo"
-			// matches.
-			if len(ci.modifiers) > 0 {
-				return true
-			}
-
-			// If we didn't have an exact type match, check if our object kind
-			// matches.
-			if ci.kindMatches(candType) {
-				if ci.objKind == kindFunc {
-					cand.mods = append(cand.mods, invoke)
-				}
-				return true
-			}
-		}
-
-		return false
-	})
-}
-
-// considerTypeConversion returns true if we should offer a completion
-// automatically converting "from" to "to".
-func considerTypeConversion(from, to types.Type, path []types.Object) bool {
-	// Don't offer to convert deep completions from other packages.
-	// Otherwise there are many random package level consts/vars that
-	// pop up as candidates all the time.
-	if len(path) > 0 && isPkgName(path[0]) {
-		return false
-	}
-
-	if _, ok := from.(*typeparams.TypeParam); ok {
-		return false
-	}
-
-	if !convertibleTo(from, to) {
-		return false
-	}
-
-	// Don't offer to convert ints to strings since that probably
-	// doesn't do what the user wants.
-	if isBasicKind(from, types.IsInteger) && isBasicKind(to, types.IsString) {
-		return false
-	}
-
-	return true
-}
-
-// typeMatches reports whether an object of candType makes a good
-// completion candidate given the expected type expType.
-func (ci *candidateInference) typeMatches(expType, candType types.Type) bool {
-	// Handle untyped values specially since AssignableTo gives false negatives
-	// for them (see https://golang.org/issue/32146).
-	if candBasic, ok := candType.Underlying().(*types.Basic); ok {
-		if expBasic, ok := expType.Underlying().(*types.Basic); ok {
-			// Note that the candidate and/or the expected can be untyped.
-			// In "fo<> == 100" the expected type is untyped, and the
-			// candidate could also be an untyped constant.
-
-			// Sort by is_untyped and then by is_int to simplify below logic.
-			a, b := candBasic.Info(), expBasic.Info()
-			if a&types.IsUntyped == 0 || (b&types.IsInteger > 0 && b&types.IsUntyped > 0) {
-				a, b = b, a
-			}
-
-			// If at least one is untyped...
-			if a&types.IsUntyped > 0 {
-				switch {
-				// Untyped integers are compatible with floats.
-				case a&types.IsInteger > 0 && b&types.IsFloat > 0:
-					return true
-
-				// Check if their constant kind (bool|int|float|complex|string) matches.
-				// This doesn't take into account the constant value, so there will be some
-				// false positives due to integer sign and overflow.
-				case a&types.IsConstType == b&types.IsConstType:
-					return true
-				}
-			}
-		}
-	}
-
-	// AssignableTo covers the case where the types are equal, but also handles
-	// cases like assigning a concrete type to an interface type.
-	return assignableTo(candType, expType)
-}
-
-// kindMatches reports whether candType's kind matches our expected
-// kind (e.g. slice, map, etc.).
-func (ci *candidateInference) kindMatches(candType types.Type) bool {
-	return ci.objKind > 0 && ci.objKind&candKind(candType) > 0
-}
-
-// assigneesMatch reports whether an invocation of sig matches the
-// number and type of any assignees.
-func (ci *candidateInference) assigneesMatch(cand *candidate, sig *types.Signature) bool {
-	if len(ci.assignees) == 0 {
-		return false
-	}
-
-	// Uniresult functions are always usable and are handled by the
-	// normal, non-assignees type matching logic.
-	if sig.Results().Len() == 1 {
-		return false
-	}
-
-	// Don't prefer completing into func(...interface{}) calls since all
-	// functions would match.
-	if ci.variadicAssignees && len(ci.assignees) == 1 && isEmptyInterface(deslice(ci.assignees[0])) {
-		return false
-	}
-
-	var numberOfResultsCouldMatch bool
-	if ci.variadicAssignees {
-		numberOfResultsCouldMatch = sig.Results().Len() >= len(ci.assignees)-1
-	} else {
-		numberOfResultsCouldMatch = sig.Results().Len() == len(ci.assignees)
-	}
-
-	// If our signature doesn't return the right number of values, it's
-	// not a match, so downrank it. For example:
-	//
-	//  var foo func() (int, int)
-	//  a, b, c := <> // downrank "foo()" since it only returns two values
-	if !numberOfResultsCouldMatch {
-		cand.score /= 2
-		return false
-	}
-
-	// If at least one assignee has a valid type, and all valid
-	// assignees match the corresponding sig result value, the signature
-	// is a match.
-	allMatch := false
-	for i := 0; i < sig.Results().Len(); i++ {
-		var assignee types.Type
-
-		// If we are completing into variadic parameters, deslice the
-		// expected variadic type.
-		if ci.variadicAssignees && i >= len(ci.assignees)-1 {
-			assignee = ci.assignees[len(ci.assignees)-1]
-			if elem := deslice(assignee); elem != nil {
-				assignee = elem
-			}
-		} else {
-			assignee = ci.assignees[i]
-		}
-
-		if assignee == nil || assignee == types.Typ[types.Invalid] {
-			continue
-		}
-
-		allMatch = ci.typeMatches(assignee, sig.Results().At(i).Type())
-		if !allMatch {
-			break
-		}
-	}
-	return allMatch
-}
-
-func (c *completer) matchingTypeName(cand *candidate) bool {
-	if !c.wantTypeName() {
-		return false
-	}
-
-	typeMatches := func(candType types.Type) bool {
-		// Take into account any type name modifier prefixes.
-		candType = c.inference.applyTypeNameModifiers(candType)
-
-		if from := c.inference.typeName.assertableFrom; from != nil {
-			// Don't suggest the starting type in type assertions. For example,
-			// if "foo" is an io.Writer, don't suggest "foo.(io.Writer)".
-			if types.Identical(from, candType) {
-				return false
-			}
-
-			if intf, ok := from.Underlying().(*types.Interface); ok {
-				if !types.AssertableTo(intf, candType) {
-					return false
-				}
-			}
-		}
-
-		if c.inference.typeName.wantComparable && !types.Comparable(candType) {
-			return false
-		}
-
-		// Skip this type if it has already been used in another type
-		// switch case.
-		for _, seen := range c.inference.typeName.seenTypeSwitchCases {
-			if types.Identical(candType, seen) {
-				return false
-			}
-		}
-
-		// We can expect a type name and have an expected type in cases like:
-		//
-		//   var foo []int
-		//   foo = []i<>
-		//
-		// Where our expected type is "[]int", and we expect a type name.
-		if c.inference.objType != nil {
-			return assignableTo(candType, c.inference.objType)
-		}
-
-		// Default to saying any type name is a match.
-		return true
-	}
-
-	t := cand.obj.Type()
-
-	if typeMatches(t) {
-		return true
-	}
-
-	if !source.IsInterface(t) && typeMatches(types.NewPointer(t)) {
-		if c.inference.typeName.compLitType {
-			// If we are completing a composite literal type as in
-			// "foo<>{}", to make a pointer we must prepend "&".
-			cand.mods = append(cand.mods, reference)
-		} else {
-			// If we are completing a normal type name such as "foo<>", to
-			// make a pointer we must prepend "*".
-			cand.mods = append(cand.mods, dereference)
-		}
-		return true
-	}
-
-	return false
-}
-
-var (
-	// "interface { Error() string }" (i.e. error)
-	errorIntf = types.Universe.Lookup("error").Type().Underlying().(*types.Interface)
-
-	// "interface { String() string }" (i.e. fmt.Stringer)
-	stringerIntf = types.NewInterfaceType([]*types.Func{
-		types.NewFunc(token.NoPos, nil, "String", types.NewSignature(
-			nil,
-			nil,
-			types.NewTuple(types.NewParam(token.NoPos, nil, "", types.Typ[types.String])),
-			false,
-		)),
-	}, nil).Complete()
-
-	byteType = types.Universe.Lookup("byte").Type()
-)
-
-// candKind returns the objKind of candType, if any.
-func candKind(candType types.Type) objKind {
-	var kind objKind
-
-	switch t := candType.Underlying().(type) {
-	case *types.Array:
-		kind |= kindArray
-		if t.Elem() == byteType {
-			kind |= kindBytes
-		}
-	case *types.Slice:
-		kind |= kindSlice
-		if t.Elem() == byteType {
-			kind |= kindBytes
-		}
-	case *types.Chan:
-		kind |= kindChan
-	case *types.Map:
-		kind |= kindMap
-	case *types.Pointer:
-		kind |= kindPtr
-
-		// Some builtins handle array pointers as arrays, so just report a pointer
-		// to an array as an array.
-		if _, isArray := t.Elem().Underlying().(*types.Array); isArray {
-			kind |= kindArray
-		}
-	case *types.Basic:
-		switch info := t.Info(); {
-		case info&types.IsString > 0:
-			kind |= kindString
-		case info&types.IsInteger > 0:
-			kind |= kindInt
-		case info&types.IsFloat > 0:
-			kind |= kindFloat
-		case info&types.IsComplex > 0:
-			kind |= kindComplex
-		case info&types.IsBoolean > 0:
-			kind |= kindBool
-		}
-	case *types.Signature:
-		return kindFunc
-	}
-
-	if types.Implements(candType, errorIntf) {
-		kind |= kindError
-	}
-
-	if types.Implements(candType, stringerIntf) {
-		kind |= kindStringer
-	}
-
-	return kind
-}
-
-// innermostScope returns the innermost scope for c.pos.
-func (c *completer) innermostScope() *types.Scope {
-	for _, s := range c.scopes {
-		if s != nil {
-			return s
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/source/completion/deep_completion.go b/gopls/internal/lsp/source/completion/deep_completion.go
--- a/gopls/internal/lsp/source/completion/deep_completion.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/deep_completion.go	1969-12-31 16:00:00
@@ -1,362 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"context"
-	"go/types"
-	"strings"
-	"time"
-)
-
-// MaxDeepCompletions limits deep completion results because in most cases
-// there are too many to be useful.
-const MaxDeepCompletions = 3
-
-// deepCompletionState stores our state as we search for deep completions.
-// "deep completion" refers to searching into objects' fields and methods to
-// find more completion candidates.
-type deepCompletionState struct {
-	// enabled indicates whether deep completion is permitted.
-	enabled bool
-
-	// queueClosed is used to disable adding new sub-fields to search queue
-	// once we're running out of our time budget.
-	queueClosed bool
-
-	// thisQueue holds the current breadth first search queue.
-	thisQueue []candidate
-
-	// nextQueue holds the next breadth first search iteration's queue.
-	nextQueue []candidate
-
-	// highScores tracks the highest deep candidate scores we have found
-	// so far. This is used to avoid work for low scoring deep candidates.
-	highScores [MaxDeepCompletions]float64
-
-	// candidateCount is the count of unique deep candidates encountered
-	// so far.
-	candidateCount int
-}
-
-// enqueue adds a candidate to the search queue.
-func (s *deepCompletionState) enqueue(cand candidate) {
-	s.nextQueue = append(s.nextQueue, cand)
-}
-
-// dequeue removes and returns the leftmost element from the search queue.
-func (s *deepCompletionState) dequeue() *candidate {
-	var cand *candidate
-	cand, s.thisQueue = &s.thisQueue[len(s.thisQueue)-1], s.thisQueue[:len(s.thisQueue)-1]
-	return cand
-}
-
-// scorePenalty computes a deep candidate score penalty. A candidate is
-// penalized based on depth to favor shallower candidates. We also give a
-// slight bonus to unexported objects and a slight additional penalty to
-// function objects.
-func (s *deepCompletionState) scorePenalty(cand *candidate) float64 {
-	var deepPenalty float64
-	for _, dc := range cand.path {
-		deepPenalty++
-
-		if !dc.Exported() {
-			deepPenalty -= 0.1
-		}
-
-		if _, isSig := dc.Type().Underlying().(*types.Signature); isSig {
-			deepPenalty += 0.1
-		}
-	}
-
-	// Normalize penalty to a max depth of 10.
-	return deepPenalty / 10
-}
-
-// isHighScore returns whether score is among the top MaxDeepCompletions deep
-// candidate scores encountered so far. If so, it adds score to highScores,
-// possibly displacing an existing high score.
-func (s *deepCompletionState) isHighScore(score float64) bool {
-	// Invariant: s.highScores is sorted with highest score first. Unclaimed
-	// positions are trailing zeros.
-
-	// If we beat an existing score then take its spot.
-	for i, deepScore := range s.highScores {
-		if score <= deepScore {
-			continue
-		}
-
-		if deepScore != 0 && i != len(s.highScores)-1 {
-			// If this wasn't an empty slot then we need to scooch everyone
-			// down one spot.
-			copy(s.highScores[i+1:], s.highScores[i:])
-		}
-		s.highScores[i] = score
-		return true
-	}
-
-	return false
-}
-
-// newPath returns path from search root for an object following a given
-// candidate.
-func (s *deepCompletionState) newPath(cand candidate, obj types.Object) []types.Object {
-	path := make([]types.Object, len(cand.path)+1)
-	copy(path, cand.path)
-	path[len(path)-1] = obj
-
-	return path
-}
-
-// deepSearch searches a candidate and its subordinate objects for completion
-// items if deep completion is enabled and adds the valid candidates to
-// completion items.
-func (c *completer) deepSearch(ctx context.Context) {
-	defer func() {
-		// We can return early before completing the search, so be sure to
-		// clear out our queues to not impact any further invocations.
-		c.deepState.thisQueue = c.deepState.thisQueue[:0]
-		c.deepState.nextQueue = c.deepState.nextQueue[:0]
-	}()
-
-	for len(c.deepState.nextQueue) > 0 {
-		c.deepState.thisQueue, c.deepState.nextQueue = c.deepState.nextQueue, c.deepState.thisQueue[:0]
-
-	outer:
-		for _, cand := range c.deepState.thisQueue {
-			obj := cand.obj
-
-			if obj == nil {
-				continue
-			}
-
-			// At the top level, dedupe by object.
-			if len(cand.path) == 0 {
-				if c.seen[obj] {
-					continue
-				}
-				c.seen[obj] = true
-			}
-
-			// If obj is not accessible because it lives in another package and is
-			// not exported, don't treat it as a completion candidate unless it's
-			// a package completion candidate.
-			if !c.completionContext.packageCompletion &&
-				obj.Pkg() != nil && obj.Pkg() != c.pkg.GetTypes() && !obj.Exported() {
-				continue
-			}
-
-			// If we want a type name, don't offer non-type name candidates.
-			// However, do offer package names since they can contain type names,
-			// and do offer any candidate without a type since we aren't sure if it
-			// is a type name or not (i.e. unimported candidate).
-			if c.wantTypeName() && obj.Type() != nil && !isTypeName(obj) && !isPkgName(obj) {
-				continue
-			}
-
-			// When searching deep, make sure we don't have a cycle in our chain.
-			// We don't dedupe by object because we want to allow both "foo.Baz"
-			// and "bar.Baz" even though "Baz" is represented the same types.Object
-			// in both.
-			for _, seenObj := range cand.path {
-				if seenObj == obj {
-					continue outer
-				}
-			}
-
-			c.addCandidate(ctx, &cand)
-
-			c.deepState.candidateCount++
-			if c.opts.budget > 0 && c.deepState.candidateCount%100 == 0 {
-				spent := float64(time.Since(c.startTime)) / float64(c.opts.budget)
-				select {
-				case <-ctx.Done():
-					return
-				default:
-					// If we are almost out of budgeted time, no further elements
-					// should be added to the queue. This ensures remaining time is
-					// used for processing current queue.
-					if !c.deepState.queueClosed && spent >= 0.85 {
-						c.deepState.queueClosed = true
-					}
-				}
-			}
-
-			// if deep search is disabled, don't add any more candidates.
-			if !c.deepState.enabled || c.deepState.queueClosed {
-				continue
-			}
-
-			// Searching members for a type name doesn't make sense.
-			if isTypeName(obj) {
-				continue
-			}
-			if obj.Type() == nil {
-				continue
-			}
-
-			// Don't search embedded fields because they were already included in their
-			// parent's fields.
-			if v, ok := obj.(*types.Var); ok && v.Embedded() {
-				continue
-			}
-
-			if sig, ok := obj.Type().Underlying().(*types.Signature); ok {
-				// If obj is a function that takes no arguments and returns one
-				// value, keep searching across the function call.
-				if sig.Params().Len() == 0 && sig.Results().Len() == 1 {
-					path := c.deepState.newPath(cand, obj)
-					// The result of a function call is not addressable.
-					c.methodsAndFields(sig.Results().At(0).Type(), false, cand.imp, func(newCand candidate) {
-						newCand.pathInvokeMask = cand.pathInvokeMask | (1 << uint64(len(cand.path)))
-						newCand.path = path
-						c.deepState.enqueue(newCand)
-					})
-				}
-			}
-
-			path := c.deepState.newPath(cand, obj)
-			switch obj := obj.(type) {
-			case *types.PkgName:
-				c.packageMembers(obj.Imported(), stdScore, cand.imp, func(newCand candidate) {
-					newCand.pathInvokeMask = cand.pathInvokeMask
-					newCand.path = path
-					c.deepState.enqueue(newCand)
-				})
-			default:
-				c.methodsAndFields(obj.Type(), cand.addressable, cand.imp, func(newCand candidate) {
-					newCand.pathInvokeMask = cand.pathInvokeMask
-					newCand.path = path
-					c.deepState.enqueue(newCand)
-				})
-			}
-		}
-	}
-}
-
-// addCandidate adds a completion candidate to suggestions, without searching
-// its members for more candidates.
-func (c *completer) addCandidate(ctx context.Context, cand *candidate) {
-	obj := cand.obj
-	if c.matchingCandidate(cand) {
-		cand.score *= highScore
-
-		if p := c.penalty(cand); p > 0 {
-			cand.score *= (1 - p)
-		}
-	} else if isTypeName(obj) {
-		// If obj is a *types.TypeName that didn't otherwise match, check
-		// if a literal object of this type makes a good candidate.
-
-		// We only care about named types (i.e. don't want builtin types).
-		if _, isNamed := obj.Type().(*types.Named); isNamed {
-			c.literal(ctx, obj.Type(), cand.imp)
-		}
-	}
-
-	// Lower score of method calls so we prefer fields and vars over calls.
-	if cand.hasMod(invoke) {
-		if sig, ok := obj.Type().Underlying().(*types.Signature); ok && sig.Recv() != nil {
-			cand.score *= 0.9
-		}
-	}
-
-	// Prefer private objects over public ones.
-	if !obj.Exported() && obj.Parent() != types.Universe {
-		cand.score *= 1.1
-	}
-
-	// Slight penalty for index modifier (e.g. changing "foo" to
-	// "foo[]") to curb false positives.
-	if cand.hasMod(index) {
-		cand.score *= 0.9
-	}
-
-	// Favor shallow matches by lowering score according to depth.
-	cand.score -= cand.score * c.deepState.scorePenalty(cand)
-
-	if cand.score < 0 {
-		cand.score = 0
-	}
-
-	cand.name = deepCandName(cand)
-	if item, err := c.item(ctx, *cand); err == nil {
-		c.items = append(c.items, item)
-	}
-}
-
-// deepCandName produces the full candidate name including any
-// ancestor objects. For example, "foo.bar().baz" for candidate "baz".
-func deepCandName(cand *candidate) string {
-	totalLen := len(cand.obj.Name())
-	for i, obj := range cand.path {
-		totalLen += len(obj.Name()) + 1
-		if cand.pathInvokeMask&(1<<uint16(i)) > 0 {
-			totalLen += 2
-		}
-	}
-
-	var buf strings.Builder
-	buf.Grow(totalLen)
-
-	for i, obj := range cand.path {
-		buf.WriteString(obj.Name())
-		if cand.pathInvokeMask&(1<<uint16(i)) > 0 {
-			buf.WriteByte('(')
-			buf.WriteByte(')')
-		}
-		buf.WriteByte('.')
-	}
-
-	buf.WriteString(cand.obj.Name())
-
-	return buf.String()
-}
-
-// penalty reports a score penalty for cand in the range (0, 1).
-// For example, a candidate is penalized if it has already been used
-// in another switch case statement.
-func (c *completer) penalty(cand *candidate) float64 {
-	for _, p := range c.inference.penalized {
-		if c.objChainMatches(cand, p.objChain) {
-			return p.penalty
-		}
-	}
-
-	return 0
-}
-
-// objChainMatches reports whether cand combined with the surrounding
-// object prefix matches chain.
-func (c *completer) objChainMatches(cand *candidate, chain []types.Object) bool {
-	// For example, when completing:
-	//
-	//   foo.ba<>
-	//
-	// If we are considering the deep candidate "bar.baz", cand is baz,
-	// objChain is [foo] and deepChain is [bar]. We would match the
-	// chain [foo, bar, baz].
-	if len(chain) != len(c.inference.objChain)+len(cand.path)+1 {
-		return false
-	}
-
-	if chain[len(chain)-1] != cand.obj {
-		return false
-	}
-
-	for i, o := range c.inference.objChain {
-		if chain[i] != o {
-			return false
-		}
-	}
-
-	for i, o := range cand.path {
-		if chain[i+len(c.inference.objChain)] != o {
-			return false
-		}
-	}
-
-	return true
-}
diff -urN a/gopls/internal/lsp/source/completion/deep_completion_test.go b/gopls/internal/lsp/source/completion/deep_completion_test.go
--- a/gopls/internal/lsp/source/completion/deep_completion_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/deep_completion_test.go	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"testing"
-)
-
-func TestDeepCompletionIsHighScore(t *testing.T) {
-	// Test that deepCompletionState.isHighScore properly tracks the top
-	// N=MaxDeepCompletions scores.
-
-	var s deepCompletionState
-
-	if !s.isHighScore(1) {
-		// No other scores yet, anything is a winner.
-		t.Error("1 should be high score")
-	}
-
-	// Fill up with higher scores.
-	for i := 0; i < MaxDeepCompletions; i++ {
-		if !s.isHighScore(10) {
-			t.Error("10 should be high score")
-		}
-	}
-
-	// High scores should be filled with 10s so 2 is not a high score.
-	if s.isHighScore(2) {
-		t.Error("2 shouldn't be high score")
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/definition.go b/gopls/internal/lsp/source/completion/definition.go
--- a/gopls/internal/lsp/source/completion/definition.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/definition.go	1969-12-31 16:00:00
@@ -1,129 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/ast"
-	"go/token"
-	"go/types"
-	"strings"
-	"unicode"
-	"unicode/utf8"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// some definitions can be completed
-// So far, TestFoo(t *testing.T), TestMain(m *testing.M)
-// BenchmarkFoo(b *testing.B), FuzzFoo(f *testing.F)
-
-// path[0] is known to be *ast.Ident
-func definition(path []ast.Node, obj types.Object, tokFile *token.File, fh source.FileHandle) ([]CompletionItem, *Selection) {
-	if _, ok := obj.(*types.Func); !ok {
-		return nil, nil // not a function at all
-	}
-	if !strings.HasSuffix(fh.URI().Filename(), "_test.go") {
-		return nil, nil
-	}
-
-	name := path[0].(*ast.Ident).Name
-	if len(name) == 0 {
-		// can't happen
-		return nil, nil
-	}
-	start := path[0].Pos()
-	end := path[0].End()
-	sel := &Selection{
-		content: "",
-		cursor:  start,
-		rng:     span.NewRange(tokFile, start, end),
-	}
-	var ans []CompletionItem
-
-	// Always suggest TestMain, if possible
-	if strings.HasPrefix("TestMain", name) {
-		ans = []CompletionItem{defItem("TestMain(m *testing.M)", obj)}
-	}
-
-	// If a snippet is possible, suggest it
-	if strings.HasPrefix("Test", name) {
-		ans = append(ans, defSnippet("Test", "Xxx", "(t *testing.T)", obj))
-		return ans, sel
-	} else if strings.HasPrefix("Benchmark", name) {
-		ans = append(ans, defSnippet("Benchmark", "Xxx", "(b *testing.B)", obj))
-		return ans, sel
-	} else if strings.HasPrefix("Fuzz", name) {
-		ans = append(ans, defSnippet("Fuzz", "Xxx", "(f *testing.F)", obj))
-		return ans, sel
-	}
-
-	// Fill in the argument for what the user has already typed
-	if got := defMatches(name, "Test", path, "(t *testing.T)"); got != "" {
-		ans = append(ans, defItem(got, obj))
-	} else if got := defMatches(name, "Benchmark", path, "(b *testing.B)"); got != "" {
-		ans = append(ans, defItem(got, obj))
-	} else if got := defMatches(name, "Fuzz", path, "(f *testing.F)"); got != "" {
-		ans = append(ans, defItem(got, obj))
-	}
-	return ans, sel
-}
-
-func defMatches(name, pat string, path []ast.Node, arg string) string {
-	idx := strings.Index(name, pat)
-	if idx < 0 {
-		return ""
-	}
-	c, _ := utf8.DecodeRuneInString(name[len(pat):])
-	if unicode.IsLower(c) {
-		return ""
-	}
-	fd, ok := path[1].(*ast.FuncDecl)
-	if !ok {
-		// we don't know what's going on
-		return ""
-	}
-	fp := fd.Type.Params
-	if fp != nil && len(fp.List) > 0 {
-		// signature already there, minimal suggestion
-		return name
-	}
-	// suggesting signature too
-	return name + arg
-}
-
-func defSnippet(prefix, placeholder, suffix string, obj types.Object) CompletionItem {
-	var sn snippet.Builder
-	sn.WriteText(prefix)
-	if placeholder != "" {
-		sn.WritePlaceholder(func(b *snippet.Builder) { b.WriteText(placeholder) })
-	}
-	sn.WriteText(suffix + " {\n")
-	sn.WriteFinalTabstop()
-	sn.WriteText("\n}")
-	return CompletionItem{
-		Label:         prefix + placeholder + suffix,
-		Detail:        "tab, type the rest of the name, then tab",
-		Kind:          protocol.FunctionCompletion,
-		Depth:         0,
-		Score:         10,
-		snippet:       &sn,
-		Documentation: prefix + " test function",
-		obj:           obj,
-	}
-}
-func defItem(val string, obj types.Object) CompletionItem {
-	return CompletionItem{
-		Label:         val,
-		InsertText:    val,
-		Kind:          protocol.FunctionCompletion,
-		Depth:         0,
-		Score:         9, // prefer the snippets when available
-		Documentation: "complete the parameter",
-		obj:           obj,
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/format.go b/gopls/internal/lsp/source/completion/format.go
--- a/gopls/internal/lsp/source/completion/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/format.go	1969-12-31 16:00:00
@@ -1,338 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/doc"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/imports"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-var (
-	errNoMatch  = errors.New("not a surrounding match")
-	errLowScore = errors.New("not a high scoring candidate")
-)
-
-// item formats a candidate to a CompletionItem.
-func (c *completer) item(ctx context.Context, cand candidate) (CompletionItem, error) {
-	obj := cand.obj
-
-	// if the object isn't a valid match against the surrounding, return early.
-	matchScore := c.matcher.Score(cand.name)
-	if matchScore <= 0 {
-		return CompletionItem{}, errNoMatch
-	}
-	cand.score *= float64(matchScore)
-
-	// Ignore deep candidates that wont be in the MaxDeepCompletions anyway.
-	if len(cand.path) != 0 && !c.deepState.isHighScore(cand.score) {
-		return CompletionItem{}, errLowScore
-	}
-
-	// Handle builtin types separately.
-	if obj.Parent() == types.Universe {
-		return c.formatBuiltin(ctx, cand)
-	}
-
-	var (
-		label         = cand.name
-		detail        = types.TypeString(obj.Type(), c.qf)
-		insert        = label
-		kind          = protocol.TextCompletion
-		snip          snippet.Builder
-		protocolEdits []protocol.TextEdit
-	)
-	if obj.Type() == nil {
-		detail = ""
-	}
-	if isTypeName(obj) && c.wantTypeParams() {
-		x := cand.obj.(*types.TypeName)
-		if named, ok := x.Type().(*types.Named); ok {
-			tp := typeparams.ForNamed(named)
-			label += source.FormatTypeParams(tp)
-			insert = label // maintain invariant above (label == insert)
-		}
-	}
-
-	snip.WriteText(insert)
-
-	switch obj := obj.(type) {
-	case *types.TypeName:
-		detail, kind = source.FormatType(obj.Type(), c.qf)
-	case *types.Const:
-		kind = protocol.ConstantCompletion
-	case *types.Var:
-		if _, ok := obj.Type().(*types.Struct); ok {
-			detail = "struct{...}" // for anonymous structs
-		} else if obj.IsField() {
-			detail = source.FormatVarType(c.pkg, obj, c.qf)
-		}
-		if obj.IsField() {
-			kind = protocol.FieldCompletion
-			c.structFieldSnippet(cand, detail, &snip)
-		} else {
-			kind = protocol.VariableCompletion
-		}
-		if obj.Type() == nil {
-			break
-		}
-	case *types.Func:
-		sig, ok := obj.Type().Underlying().(*types.Signature)
-		if !ok {
-			break
-		}
-		kind = protocol.FunctionCompletion
-		if sig != nil && sig.Recv() != nil {
-			kind = protocol.MethodCompletion
-		}
-	case *types.PkgName:
-		kind = protocol.ModuleCompletion
-		detail = fmt.Sprintf("%q", obj.Imported().Path())
-	case *types.Label:
-		kind = protocol.ConstantCompletion
-		detail = "label"
-	}
-
-	var prefix string
-	for _, mod := range cand.mods {
-		switch mod {
-		case reference:
-			prefix = "&" + prefix
-		case dereference:
-			prefix = "*" + prefix
-		case chanRead:
-			prefix = "<-" + prefix
-		}
-	}
-
-	var (
-		suffix   string
-		funcType = obj.Type()
-	)
-Suffixes:
-	for _, mod := range cand.mods {
-		switch mod {
-		case invoke:
-			if sig, ok := funcType.Underlying().(*types.Signature); ok {
-				s := source.NewSignature(ctx, c.snapshot, c.pkg, sig, nil, c.qf)
-				c.functionCallSnippet("", s.TypeParams(), s.Params(), &snip)
-				if sig.Results().Len() == 1 {
-					funcType = sig.Results().At(0).Type()
-				}
-				detail = "func" + s.Format()
-			}
-
-			if !c.opts.snippets {
-				// Without snippets the candidate will not include "()". Don't
-				// add further suffixes since they will be invalid. For
-				// example, with snippets "foo()..." would become "foo..."
-				// without snippets if we added the dotDotDot.
-				break Suffixes
-			}
-		case takeSlice:
-			suffix += "[:]"
-		case takeDotDotDot:
-			suffix += "..."
-		case index:
-			snip.WriteText("[")
-			snip.WritePlaceholder(nil)
-			snip.WriteText("]")
-		}
-	}
-
-	// If this candidate needs an additional import statement,
-	// add the additional text edits needed.
-	if cand.imp != nil {
-		addlEdits, err := c.importEdits(cand.imp)
-
-		if err != nil {
-			return CompletionItem{}, err
-		}
-
-		protocolEdits = append(protocolEdits, addlEdits...)
-		if kind != protocol.ModuleCompletion {
-			if detail != "" {
-				detail += " "
-			}
-			detail += fmt.Sprintf("(from %q)", cand.imp.importPath)
-		}
-	}
-
-	if cand.convertTo != nil {
-		typeName := types.TypeString(cand.convertTo, c.qf)
-
-		switch cand.convertTo.(type) {
-		// We need extra parens when casting to these types. For example,
-		// we need "(*int)(foo)", not "*int(foo)".
-		case *types.Pointer, *types.Signature:
-			typeName = "(" + typeName + ")"
-		}
-
-		prefix = typeName + "(" + prefix
-		suffix = ")"
-	}
-
-	if prefix != "" {
-		// If we are in a selector, add an edit to place prefix before selector.
-		if sel := enclosingSelector(c.path, c.pos); sel != nil {
-			edits, err := c.editText(sel.Pos(), sel.Pos(), prefix)
-			if err != nil {
-				return CompletionItem{}, err
-			}
-			protocolEdits = append(protocolEdits, edits...)
-		} else {
-			// If there is no selector, just stick the prefix at the start.
-			insert = prefix + insert
-			snip.PrependText(prefix)
-		}
-	}
-
-	if suffix != "" {
-		insert += suffix
-		snip.WriteText(suffix)
-	}
-
-	detail = strings.TrimPrefix(detail, "untyped ")
-	// override computed detail with provided detail, if something is provided.
-	if cand.detail != "" {
-		detail = cand.detail
-	}
-	item := CompletionItem{
-		Label:               label,
-		InsertText:          insert,
-		AdditionalTextEdits: protocolEdits,
-		Detail:              detail,
-		Kind:                kind,
-		Score:               cand.score,
-		Depth:               len(cand.path),
-		snippet:             &snip,
-		obj:                 obj,
-	}
-	// If the user doesn't want documentation for completion items.
-	if !c.opts.documentation {
-		return item, nil
-	}
-	pos := safetoken.StartPosition(c.pkg.FileSet(), obj.Pos())
-
-	// We ignore errors here, because some types, like "unsafe" or "error",
-	// may not have valid positions that we can use to get documentation.
-	if !pos.IsValid() {
-		return item, nil
-	}
-	uri := span.URIFromPath(pos.Filename)
-
-	// Find the source file of the candidate.
-	pkg, err := source.FindPackageFromPos(c.pkg, obj.Pos())
-	if err != nil {
-		return item, nil
-	}
-
-	decl, _ := source.FindDeclAndField(pkg.GetSyntax(), obj.Pos()) // may be nil
-	hover, err := source.FindHoverContext(ctx, c.snapshot, pkg, obj, decl, nil)
-	if err != nil {
-		event.Error(ctx, "failed to find Hover", err, tag.URI.Of(uri))
-		return item, nil
-	}
-	if c.opts.fullDocumentation {
-		item.Documentation = hover.Comment.Text()
-	} else {
-		item.Documentation = doc.Synopsis(hover.Comment.Text())
-	}
-	// The desired pattern is `^// Deprecated`, but the prefix has been removed
-	if strings.HasPrefix(hover.Comment.Text(), "Deprecated") {
-		if c.snapshot.View().Options().CompletionTags {
-			item.Tags = []protocol.CompletionItemTag{protocol.ComplDeprecated}
-		} else if c.snapshot.View().Options().CompletionDeprecated {
-			item.Deprecated = true
-		}
-	}
-
-	return item, nil
-}
-
-// importEdits produces the text edits necessary to add the given import to the current file.
-func (c *completer) importEdits(imp *importInfo) ([]protocol.TextEdit, error) {
-	if imp == nil {
-		return nil, nil
-	}
-
-	pgf, err := c.pkg.File(span.URIFromPath(c.filename))
-	if err != nil {
-		return nil, err
-	}
-
-	return source.ComputeOneImportFixEdits(c.snapshot, pgf, &imports.ImportFix{
-		StmtInfo: imports.ImportInfo{
-			ImportPath: imp.importPath,
-			Name:       imp.name,
-		},
-		// IdentName is unused on this path and is difficult to get.
-		FixType: imports.AddImport,
-	})
-}
-
-func (c *completer) formatBuiltin(ctx context.Context, cand candidate) (CompletionItem, error) {
-	obj := cand.obj
-	item := CompletionItem{
-		Label:      obj.Name(),
-		InsertText: obj.Name(),
-		Score:      cand.score,
-	}
-	switch obj.(type) {
-	case *types.Const:
-		item.Kind = protocol.ConstantCompletion
-	case *types.Builtin:
-		item.Kind = protocol.FunctionCompletion
-		sig, err := source.NewBuiltinSignature(ctx, c.snapshot, obj.Name())
-		if err != nil {
-			return CompletionItem{}, err
-		}
-		item.Detail = "func" + sig.Format()
-		item.snippet = &snippet.Builder{}
-		c.functionCallSnippet(obj.Name(), sig.TypeParams(), sig.Params(), item.snippet)
-	case *types.TypeName:
-		if types.IsInterface(obj.Type()) {
-			item.Kind = protocol.InterfaceCompletion
-		} else {
-			item.Kind = protocol.ClassCompletion
-		}
-	case *types.Nil:
-		item.Kind = protocol.VariableCompletion
-	}
-	return item, nil
-}
-
-// decide if the type params (if any) should be part of the completion
-// which only possible for types.Named and types.Signature
-// (so far, only in receivers, e.g.; func (s *GENERIC[K, V])..., which is a types.Named)
-func (c *completer) wantTypeParams() bool {
-	// Need to be lexically in a receiver, and a child of an IndexListExpr
-	// (but IndexListExpr only exists with go1.18)
-	start := c.path[0].Pos()
-	for i, nd := range c.path {
-		if fd, ok := nd.(*ast.FuncDecl); ok {
-			if i > 0 && fd.Recv != nil && start < fd.Recv.End() {
-				return true
-			} else {
-				return false
-			}
-		}
-	}
-	return false
-}
diff -urN a/gopls/internal/lsp/source/completion/fuzz.go b/gopls/internal/lsp/source/completion/fuzz.go
--- a/gopls/internal/lsp/source/completion/fuzz.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/fuzz.go	1969-12-31 16:00:00
@@ -1,142 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// golang/go#51089
-// *testing.F deserves special treatment as member use is constrained:
-// The arguments to f.Fuzz are determined by the arguments to a previous f.Add
-// Inside f.Fuzz only f.Failed and f.Name are allowed.
-// PJW: are there other packages where we can deduce usage constraints?
-
-// if we find fuzz completions, then return true, as those are the only completions to offer
-func (c *completer) fuzz(typ types.Type, mset *types.MethodSet, imp *importInfo, cb func(candidate), fset *token.FileSet) bool {
-	// 1. inside f.Fuzz? (only f.Failed and f.Name)
-	// 2. possible completing f.Fuzz?
-	//    [Ident,SelectorExpr,Callexpr,ExprStmt,BlockiStmt,FuncDecl(Fuzz...)]
-	// 3. before f.Fuzz, same (for 2., offer choice when looking at an F)
-
-	// does the path contain FuncLit as arg to f.Fuzz CallExpr?
-	inside := false
-Loop:
-	for i, n := range c.path {
-		switch v := n.(type) {
-		case *ast.CallExpr:
-			if len(v.Args) != 1 {
-				continue Loop
-			}
-			if _, ok := v.Args[0].(*ast.FuncLit); !ok {
-				continue
-			}
-			if s, ok := v.Fun.(*ast.SelectorExpr); !ok || s.Sel.Name != "Fuzz" {
-				continue
-			}
-			if i > 2 { // avoid t.Fuzz itself in tests
-				inside = true
-				break Loop
-			}
-		}
-	}
-	if inside {
-		for i := 0; i < mset.Len(); i++ {
-			o := mset.At(i).Obj()
-			if o.Name() == "Failed" || o.Name() == "Name" {
-				cb(candidate{
-					obj:         o,
-					score:       stdScore,
-					imp:         imp,
-					addressable: true,
-				})
-			}
-		}
-		return true
-	}
-	// if it could be t.Fuzz, look for the preceding t.Add
-	id, ok := c.path[0].(*ast.Ident)
-	if ok && strings.HasPrefix("Fuzz", id.Name) {
-		var add *ast.CallExpr
-		f := func(n ast.Node) bool {
-			if n == nil {
-				return true
-			}
-			call, ok := n.(*ast.CallExpr)
-			if !ok {
-				return true
-			}
-			s, ok := call.Fun.(*ast.SelectorExpr)
-			if !ok {
-				return true
-			}
-			if s.Sel.Name != "Add" {
-				return true
-			}
-			// Sel.X should be of type *testing.F
-			got := c.pkg.GetTypesInfo().Types[s.X]
-			if got.Type.String() == "*testing.F" {
-				add = call
-			}
-			return false // because we're done...
-		}
-		// look at the enclosing FuzzFoo functions
-		if len(c.path) < 2 {
-			return false
-		}
-		n := c.path[len(c.path)-2]
-		if _, ok := n.(*ast.FuncDecl); !ok {
-			// the path should start with ast.File, ast.FuncDecl, ...
-			// but it didn't, so give up
-			return false
-		}
-		ast.Inspect(n, f)
-		if add == nil {
-			// looks like f.Fuzz without a preceding f.Add.
-			// let the regular completion handle it.
-			return false
-		}
-
-		lbl := "Fuzz(func(t *testing.T"
-		for i, a := range add.Args {
-			info := c.pkg.GetTypesInfo().TypeOf(a)
-			if info == nil {
-				return false // How could this happen, but better safe than panic.
-			}
-			lbl += fmt.Sprintf(", %c %s", 'a'+i, info)
-		}
-		lbl += ")"
-		xx := CompletionItem{
-			Label:         lbl,
-			InsertText:    lbl,
-			Kind:          protocol.FunctionCompletion,
-			Depth:         0,
-			Score:         10, // pretty confident the user should see this
-			Documentation: "argument types from f.Add",
-			obj:           nil,
-		}
-		c.items = append(c.items, xx)
-		for i := 0; i < mset.Len(); i++ {
-			o := mset.At(i).Obj()
-			if o.Name() != "Fuzz" {
-				cb(candidate{
-					obj:         o,
-					score:       stdScore,
-					imp:         imp,
-					addressable: true,
-				})
-			}
-		}
-		return true // done
-	}
-	// let the standard processing take care of it instead
-	return false
-}
diff -urN a/gopls/internal/lsp/source/completion/keywords.go b/gopls/internal/lsp/source/completion/keywords.go
--- a/gopls/internal/lsp/source/completion/keywords.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/keywords.go	1969-12-31 16:00:00
@@ -1,154 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/ast"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-const (
-	BREAK       = "break"
-	CASE        = "case"
-	CHAN        = "chan"
-	CONST       = "const"
-	CONTINUE    = "continue"
-	DEFAULT     = "default"
-	DEFER       = "defer"
-	ELSE        = "else"
-	FALLTHROUGH = "fallthrough"
-	FOR         = "for"
-	FUNC        = "func"
-	GO          = "go"
-	GOTO        = "goto"
-	IF          = "if"
-	IMPORT      = "import"
-	INTERFACE   = "interface"
-	MAP         = "map"
-	PACKAGE     = "package"
-	RANGE       = "range"
-	RETURN      = "return"
-	SELECT      = "select"
-	STRUCT      = "struct"
-	SWITCH      = "switch"
-	TYPE        = "type"
-	VAR         = "var"
-)
-
-// addKeywordCompletions offers keyword candidates appropriate at the position.
-func (c *completer) addKeywordCompletions() {
-	seen := make(map[string]bool)
-
-	if c.wantTypeName() && c.inference.objType == nil {
-		// If we want a type name but don't have an expected obj type,
-		// include "interface", "struct", "func", "chan", and "map".
-
-		// "interface" and "struct" are more common declaring named types.
-		// Give them a higher score if we are in a type declaration.
-		structIntf, funcChanMap := stdScore, highScore
-		if len(c.path) > 1 {
-			if _, namedDecl := c.path[1].(*ast.TypeSpec); namedDecl {
-				structIntf, funcChanMap = highScore, stdScore
-			}
-		}
-
-		c.addKeywordItems(seen, structIntf, STRUCT, INTERFACE)
-		c.addKeywordItems(seen, funcChanMap, FUNC, CHAN, MAP)
-	}
-
-	// If we are at the file scope, only offer decl keywords. We don't
-	// get *ast.Idents at the file scope because non-keyword identifiers
-	// turn into *ast.BadDecl, not *ast.Ident.
-	if len(c.path) == 1 || isASTFile(c.path[1]) {
-		c.addKeywordItems(seen, stdScore, TYPE, CONST, VAR, FUNC, IMPORT)
-		return
-	} else if _, ok := c.path[0].(*ast.Ident); !ok {
-		// Otherwise only offer keywords if the client is completing an identifier.
-		return
-	}
-
-	if len(c.path) > 2 {
-		// Offer "range" if we are in ast.ForStmt.Init. This is what the
-		// AST looks like before "range" is typed, e.g. "for i := r<>".
-		if loop, ok := c.path[2].(*ast.ForStmt); ok && source.NodeContains(loop.Init, c.pos) {
-			c.addKeywordItems(seen, stdScore, RANGE)
-		}
-	}
-
-	// Only suggest keywords if we are beginning a statement.
-	switch n := c.path[1].(type) {
-	case *ast.BlockStmt, *ast.ExprStmt:
-		// OK - our ident must be at beginning of statement.
-	case *ast.CommClause:
-		// Make sure we aren't in the Comm statement.
-		if !n.Colon.IsValid() || c.pos <= n.Colon {
-			return
-		}
-	case *ast.CaseClause:
-		// Make sure we aren't in the case List.
-		if !n.Colon.IsValid() || c.pos <= n.Colon {
-			return
-		}
-	default:
-		return
-	}
-
-	// Filter out keywords depending on scope
-	// Skip the first one because we want to look at the enclosing scopes
-	path := c.path[1:]
-	for i, n := range path {
-		switch node := n.(type) {
-		case *ast.CaseClause:
-			// only recommend "fallthrough" and "break" within the bodies of a case clause
-			if c.pos > node.Colon {
-				c.addKeywordItems(seen, stdScore, BREAK)
-				// "fallthrough" is only valid in switch statements.
-				// A case clause is always nested within a block statement in a switch statement,
-				// that block statement is nested within either a TypeSwitchStmt or a SwitchStmt.
-				if i+2 >= len(path) {
-					continue
-				}
-				if _, ok := path[i+2].(*ast.SwitchStmt); ok {
-					c.addKeywordItems(seen, stdScore, FALLTHROUGH)
-				}
-			}
-		case *ast.CommClause:
-			if c.pos > node.Colon {
-				c.addKeywordItems(seen, stdScore, BREAK)
-			}
-		case *ast.TypeSwitchStmt, *ast.SelectStmt, *ast.SwitchStmt:
-			c.addKeywordItems(seen, stdScore, CASE, DEFAULT)
-		case *ast.ForStmt, *ast.RangeStmt:
-			c.addKeywordItems(seen, stdScore, BREAK, CONTINUE)
-		// This is a bit weak, functions allow for many keywords
-		case *ast.FuncDecl:
-			if node.Body != nil && c.pos > node.Body.Lbrace {
-				c.addKeywordItems(seen, stdScore, DEFER, RETURN, FOR, GO, SWITCH, SELECT, IF, ELSE, VAR, CONST, GOTO, TYPE)
-			}
-		}
-	}
-}
-
-// addKeywordItems dedupes and adds completion items for the specified
-// keywords with the specified score.
-func (c *completer) addKeywordItems(seen map[string]bool, score float64, kws ...string) {
-	for _, kw := range kws {
-		if seen[kw] {
-			continue
-		}
-		seen[kw] = true
-
-		if matchScore := c.matcher.Score(kw); matchScore > 0 {
-			c.items = append(c.items, CompletionItem{
-				Label:      kw,
-				Kind:       protocol.KeywordCompletion,
-				InsertText: kw,
-				Score:      score * float64(matchScore),
-			})
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/labels.go b/gopls/internal/lsp/source/completion/labels.go
--- a/gopls/internal/lsp/source/completion/labels.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/labels.go	1969-12-31 16:00:00
@@ -1,112 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/ast"
-	"go/token"
-	"math"
-)
-
-type labelType int
-
-const (
-	labelNone labelType = iota
-	labelBreak
-	labelContinue
-	labelGoto
-)
-
-// wantLabelCompletion returns true if we want (only) label
-// completions at the position.
-func (c *completer) wantLabelCompletion() labelType {
-	if _, ok := c.path[0].(*ast.Ident); ok && len(c.path) > 1 {
-		// We want a label if we are an *ast.Ident child of a statement
-		// that accepts a label, e.g. "break Lo<>".
-		return takesLabel(c.path[1])
-	}
-
-	return labelNone
-}
-
-// takesLabel returns the corresponding labelType if n is a statement
-// that accepts a label, otherwise labelNone.
-func takesLabel(n ast.Node) labelType {
-	if bs, ok := n.(*ast.BranchStmt); ok {
-		switch bs.Tok {
-		case token.BREAK:
-			return labelBreak
-		case token.CONTINUE:
-			return labelContinue
-		case token.GOTO:
-			return labelGoto
-		}
-	}
-	return labelNone
-}
-
-// labels adds completion items for labels defined in the enclosing
-// function.
-func (c *completer) labels(lt labelType) {
-	if c.enclosingFunc == nil {
-		return
-	}
-
-	addLabel := func(score float64, l *ast.LabeledStmt) {
-		labelObj := c.pkg.GetTypesInfo().ObjectOf(l.Label)
-		if labelObj != nil {
-			c.deepState.enqueue(candidate{obj: labelObj, score: score})
-		}
-	}
-
-	switch lt {
-	case labelBreak, labelContinue:
-		// "break" and "continue" only accept labels from enclosing statements.
-
-		for i, p := range c.path {
-			switch p := p.(type) {
-			case *ast.FuncLit:
-				// Labels are function scoped, so don't continue out of functions.
-				return
-			case *ast.LabeledStmt:
-				switch p.Stmt.(type) {
-				case *ast.ForStmt, *ast.RangeStmt:
-					// Loop labels can be used for "break" or "continue".
-					addLabel(highScore*math.Pow(.99, float64(i)), p)
-				case *ast.SwitchStmt, *ast.SelectStmt, *ast.TypeSwitchStmt:
-					// Switch and select labels can be used only for "break".
-					if lt == labelBreak {
-						addLabel(highScore*math.Pow(.99, float64(i)), p)
-					}
-				}
-			}
-		}
-	case labelGoto:
-		// Goto accepts any label in the same function not in a nested
-		// block. It also doesn't take labels that would jump across
-		// variable definitions, but ignore that case for now.
-		ast.Inspect(c.enclosingFunc.body, func(n ast.Node) bool {
-			if n == nil {
-				return false
-			}
-
-			switch n := n.(type) {
-			// Only search into block-like nodes enclosing our "goto".
-			// This prevents us from finding labels in nested blocks.
-			case *ast.BlockStmt, *ast.CommClause, *ast.CaseClause:
-				for _, p := range c.path {
-					if n == p {
-						return true
-					}
-				}
-				return false
-			case *ast.LabeledStmt:
-				addLabel(highScore, n)
-			}
-
-			return true
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/literal.go b/gopls/internal/lsp/source/completion/literal.go
--- a/gopls/internal/lsp/source/completion/literal.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/literal.go	1969-12-31 16:00:00
@@ -1,568 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"context"
-	"fmt"
-	"go/types"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// literal generates composite literal, function literal, and make()
-// completion items.
-func (c *completer) literal(ctx context.Context, literalType types.Type, imp *importInfo) {
-	if !c.opts.literal {
-		return
-	}
-
-	expType := c.inference.objType
-
-	if c.inference.matchesVariadic(literalType) {
-		// Don't offer literal slice candidates for variadic arguments.
-		// For example, don't offer "[]interface{}{}" in "fmt.Print(<>)".
-		return
-	}
-
-	// Avoid literal candidates if the expected type is an empty
-	// interface. It isn't very useful to suggest a literal candidate of
-	// every possible type.
-	if expType != nil && isEmptyInterface(expType) {
-		return
-	}
-
-	// We handle unnamed literal completions explicitly before searching
-	// for candidates. Avoid named-type literal completions for
-	// unnamed-type expected type since that results in duplicate
-	// candidates. For example, in
-	//
-	// type mySlice []int
-	// var []int = <>
-	//
-	// don't offer "mySlice{}" since we have already added a candidate
-	// of "[]int{}".
-	if _, named := literalType.(*types.Named); named && expType != nil {
-		if _, named := source.Deref(expType).(*types.Named); !named {
-			return
-		}
-	}
-
-	// Check if an object of type literalType would match our expected type.
-	cand := candidate{
-		obj: c.fakeObj(literalType),
-	}
-
-	switch literalType.Underlying().(type) {
-	// These literal types are addressable (e.g. "&[]int{}"), others are
-	// not (e.g. can't do "&(func(){})").
-	case *types.Struct, *types.Array, *types.Slice, *types.Map:
-		cand.addressable = true
-	}
-
-	if !c.matchingCandidate(&cand) || cand.convertTo != nil {
-		return
-	}
-
-	var (
-		qf  = c.qf
-		sel = enclosingSelector(c.path, c.pos)
-	)
-
-	// Don't qualify the type name if we are in a selector expression
-	// since the package name is already present.
-	if sel != nil {
-		qf = func(_ *types.Package) string { return "" }
-	}
-
-	snip, typeName := c.typeNameSnippet(literalType, qf)
-
-	// A type name of "[]int" doesn't work very will with the matcher
-	// since "[" isn't a valid identifier prefix. Here we strip off the
-	// slice (and array) prefix yielding just "int".
-	matchName := typeName
-	switch t := literalType.(type) {
-	case *types.Slice:
-		matchName = types.TypeString(t.Elem(), qf)
-	case *types.Array:
-		matchName = types.TypeString(t.Elem(), qf)
-	}
-
-	addlEdits, err := c.importEdits(imp)
-	if err != nil {
-		event.Error(ctx, "error adding import for literal candidate", err)
-		return
-	}
-
-	// If prefix matches the type name, client may want a composite literal.
-	if score := c.matcher.Score(matchName); score > 0 {
-		if cand.hasMod(reference) {
-			if sel != nil {
-				// If we are in a selector we must place the "&" before the selector.
-				// For example, "foo.B<>" must complete to "&foo.Bar{}", not
-				// "foo.&Bar{}".
-				edits, err := c.editText(sel.Pos(), sel.Pos(), "&")
-				if err != nil {
-					event.Error(ctx, "error making edit for literal pointer completion", err)
-					return
-				}
-				addlEdits = append(addlEdits, edits...)
-			} else {
-				// Otherwise we can stick the "&" directly before the type name.
-				typeName = "&" + typeName
-				snip.PrependText("&")
-			}
-		}
-
-		switch t := literalType.Underlying().(type) {
-		case *types.Struct, *types.Array, *types.Slice, *types.Map:
-			c.compositeLiteral(t, snip.Clone(), typeName, float64(score), addlEdits)
-		case *types.Signature:
-			// Add a literal completion for a signature type that implements
-			// an interface. For example, offer "http.HandlerFunc()" when
-			// expected type is "http.Handler".
-			if source.IsInterface(expType) {
-				c.basicLiteral(t, snip.Clone(), typeName, float64(score), addlEdits)
-			}
-		case *types.Basic:
-			// Add a literal completion for basic types that implement our
-			// expected interface (e.g. named string type http.Dir
-			// implements http.FileSystem), or are identical to our expected
-			// type (i.e. yielding a type conversion such as "float64()").
-			if source.IsInterface(expType) || types.Identical(expType, literalType) {
-				c.basicLiteral(t, snip.Clone(), typeName, float64(score), addlEdits)
-			}
-		}
-	}
-
-	// If prefix matches "make", client may want a "make()"
-	// invocation. We also include the type name to allow for more
-	// flexible fuzzy matching.
-	if score := c.matcher.Score("make." + matchName); !cand.hasMod(reference) && score > 0 {
-		switch literalType.Underlying().(type) {
-		case *types.Slice:
-			// The second argument to "make()" for slices is required, so default to "0".
-			c.makeCall(snip.Clone(), typeName, "0", float64(score), addlEdits)
-		case *types.Map, *types.Chan:
-			// Maps and channels don't require the second argument, so omit
-			// to keep things simple for now.
-			c.makeCall(snip.Clone(), typeName, "", float64(score), addlEdits)
-		}
-	}
-
-	// If prefix matches "func", client may want a function literal.
-	if score := c.matcher.Score("func"); !cand.hasMod(reference) && score > 0 && !source.IsInterface(expType) {
-		switch t := literalType.Underlying().(type) {
-		case *types.Signature:
-			c.functionLiteral(t, float64(score))
-		}
-	}
-}
-
-// literalCandidateScore is the base score for literal candidates.
-// Literal candidates match the expected type so they should be high
-// scoring, but we want them ranked below lexical objects of the
-// correct type, so scale down highScore.
-const literalCandidateScore = highScore / 2
-
-// functionLiteral adds a function literal completion item for the
-// given signature.
-func (c *completer) functionLiteral(sig *types.Signature, matchScore float64) {
-	snip := &snippet.Builder{}
-	snip.WriteText("func(")
-
-	// First we generate names for each param and keep a seen count so
-	// we know if we need to uniquify param names. For example,
-	// "func(int)" will become "func(i int)", but "func(int, int64)"
-	// will become "func(i1 int, i2 int64)".
-	var (
-		paramNames     = make([]string, sig.Params().Len())
-		paramNameCount = make(map[string]int)
-		hasTypeParams  bool
-	)
-	for i := 0; i < sig.Params().Len(); i++ {
-		var (
-			p    = sig.Params().At(i)
-			name = p.Name()
-		)
-
-		if tp, _ := p.Type().(*typeparams.TypeParam); tp != nil && !c.typeParamInScope(tp) {
-			hasTypeParams = true
-		}
-
-		if name == "" {
-			// If the param has no name in the signature, guess a name based
-			// on the type. Use an empty qualifier to ignore the package.
-			// For example, we want to name "http.Request" "r", not "hr".
-			name = source.FormatVarType(c.pkg, p, func(p *types.Package) string {
-				return ""
-			})
-			name = abbreviateTypeName(name)
-		}
-		paramNames[i] = name
-		if name != "_" {
-			paramNameCount[name]++
-		}
-	}
-
-	for n, c := range paramNameCount {
-		// Any names we saw more than once will need a unique suffix added
-		// on. Reset the count to 1 to act as the suffix for the first
-		// name.
-		if c >= 2 {
-			paramNameCount[n] = 1
-		} else {
-			delete(paramNameCount, n)
-		}
-	}
-
-	for i := 0; i < sig.Params().Len(); i++ {
-		if hasTypeParams && !c.opts.placeholders {
-			// If there are type params in the args then the user must
-			// choose the concrete types. If placeholders are disabled just
-			// drop them between the parens and let them fill things in.
-			snip.WritePlaceholder(nil)
-			break
-		}
-
-		if i > 0 {
-			snip.WriteText(", ")
-		}
-
-		var (
-			p    = sig.Params().At(i)
-			name = paramNames[i]
-		)
-
-		// Uniquify names by adding on an incrementing numeric suffix.
-		if idx, found := paramNameCount[name]; found {
-			paramNameCount[name]++
-			name = fmt.Sprintf("%s%d", name, idx)
-		}
-
-		if name != p.Name() && c.opts.placeholders {
-			// If we didn't use the signature's param name verbatim then we
-			// may have chosen a poor name. Give the user a placeholder so
-			// they can easily fix the name.
-			snip.WritePlaceholder(func(b *snippet.Builder) {
-				b.WriteText(name)
-			})
-		} else {
-			snip.WriteText(name)
-		}
-
-		// If the following param's type is identical to this one, omit
-		// this param's type string. For example, emit "i, j int" instead
-		// of "i int, j int".
-		if i == sig.Params().Len()-1 || !types.Identical(p.Type(), sig.Params().At(i+1).Type()) {
-			snip.WriteText(" ")
-			typeStr := source.FormatVarType(c.pkg, p, c.qf)
-			if sig.Variadic() && i == sig.Params().Len()-1 {
-				typeStr = strings.Replace(typeStr, "[]", "...", 1)
-			}
-
-			if tp, _ := p.Type().(*typeparams.TypeParam); tp != nil && !c.typeParamInScope(tp) {
-				snip.WritePlaceholder(func(snip *snippet.Builder) {
-					snip.WriteText(typeStr)
-				})
-			} else {
-				snip.WriteText(typeStr)
-			}
-		}
-	}
-	snip.WriteText(")")
-
-	results := sig.Results()
-	if results.Len() > 0 {
-		snip.WriteText(" ")
-	}
-
-	resultsNeedParens := results.Len() > 1 ||
-		results.Len() == 1 && results.At(0).Name() != ""
-
-	var resultHasTypeParams bool
-	for i := 0; i < results.Len(); i++ {
-		if tp, _ := results.At(i).Type().(*typeparams.TypeParam); tp != nil && !c.typeParamInScope(tp) {
-			resultHasTypeParams = true
-		}
-	}
-
-	if resultsNeedParens {
-		snip.WriteText("(")
-	}
-	for i := 0; i < results.Len(); i++ {
-		if resultHasTypeParams && !c.opts.placeholders {
-			// Leave an empty tabstop if placeholders are disabled and there
-			// are type args that need specificying.
-			snip.WritePlaceholder(nil)
-			break
-		}
-
-		if i > 0 {
-			snip.WriteText(", ")
-		}
-		r := results.At(i)
-		if name := r.Name(); name != "" {
-			snip.WriteText(name + " ")
-		}
-
-		text := source.FormatVarType(c.pkg, r, c.qf)
-		if tp, _ := r.Type().(*typeparams.TypeParam); tp != nil && !c.typeParamInScope(tp) {
-			snip.WritePlaceholder(func(snip *snippet.Builder) {
-				snip.WriteText(text)
-			})
-		} else {
-			snip.WriteText(text)
-		}
-	}
-	if resultsNeedParens {
-		snip.WriteText(")")
-	}
-
-	snip.WriteText(" {")
-	snip.WriteFinalTabstop()
-	snip.WriteText("}")
-
-	c.items = append(c.items, CompletionItem{
-		Label:   "func(...) {}",
-		Score:   matchScore * literalCandidateScore,
-		Kind:    protocol.VariableCompletion,
-		snippet: snip,
-	})
-}
-
-// conventionalAcronyms contains conventional acronyms for type names
-// in lower case. For example, "ctx" for "context" and "err" for "error".
-var conventionalAcronyms = map[string]string{
-	"context":        "ctx",
-	"error":          "err",
-	"tx":             "tx",
-	"responsewriter": "w",
-}
-
-// abbreviateTypeName abbreviates type names into acronyms. For
-// example, "fooBar" is abbreviated "fb". Care is taken to ignore
-// non-identifier runes. For example, "[]int" becomes "i", and
-// "struct { i int }" becomes "s".
-func abbreviateTypeName(s string) string {
-	var (
-		b            strings.Builder
-		useNextUpper bool
-	)
-
-	// Trim off leading non-letters. We trim everything between "[" and
-	// "]" to handle array types like "[someConst]int".
-	var inBracket bool
-	s = strings.TrimFunc(s, func(r rune) bool {
-		if inBracket {
-			inBracket = r != ']'
-			return true
-		}
-
-		if r == '[' {
-			inBracket = true
-		}
-
-		return !unicode.IsLetter(r)
-	})
-
-	if acr, ok := conventionalAcronyms[strings.ToLower(s)]; ok {
-		return acr
-	}
-
-	for i, r := range s {
-		// Stop if we encounter a non-identifier rune.
-		if !unicode.IsLetter(r) && !unicode.IsNumber(r) {
-			break
-		}
-
-		if i == 0 {
-			b.WriteRune(unicode.ToLower(r))
-		}
-
-		if unicode.IsUpper(r) {
-			if useNextUpper {
-				b.WriteRune(unicode.ToLower(r))
-				useNextUpper = false
-			}
-		} else {
-			useNextUpper = true
-		}
-	}
-
-	return b.String()
-}
-
-// compositeLiteral adds a composite literal completion item for the given typeName.
-func (c *completer) compositeLiteral(T types.Type, snip *snippet.Builder, typeName string, matchScore float64, edits []protocol.TextEdit) {
-	snip.WriteText("{")
-	// Don't put the tab stop inside the composite literal curlies "{}"
-	// for structs that have no accessible fields.
-	if strct, ok := T.(*types.Struct); !ok || fieldsAccessible(strct, c.pkg.GetTypes()) {
-		snip.WriteFinalTabstop()
-	}
-	snip.WriteText("}")
-
-	nonSnippet := typeName + "{}"
-
-	c.items = append(c.items, CompletionItem{
-		Label:               nonSnippet,
-		InsertText:          nonSnippet,
-		Score:               matchScore * literalCandidateScore,
-		Kind:                protocol.VariableCompletion,
-		AdditionalTextEdits: edits,
-		snippet:             snip,
-	})
-}
-
-// basicLiteral adds a literal completion item for the given basic
-// type name typeName.
-func (c *completer) basicLiteral(T types.Type, snip *snippet.Builder, typeName string, matchScore float64, edits []protocol.TextEdit) {
-	// Never give type conversions like "untyped int()".
-	if isUntyped(T) {
-		return
-	}
-
-	snip.WriteText("(")
-	snip.WriteFinalTabstop()
-	snip.WriteText(")")
-
-	nonSnippet := typeName + "()"
-
-	c.items = append(c.items, CompletionItem{
-		Label:               nonSnippet,
-		InsertText:          nonSnippet,
-		Detail:              T.String(),
-		Score:               matchScore * literalCandidateScore,
-		Kind:                protocol.VariableCompletion,
-		AdditionalTextEdits: edits,
-		snippet:             snip,
-	})
-}
-
-// makeCall adds a completion item for a "make()" call given a specific type.
-func (c *completer) makeCall(snip *snippet.Builder, typeName string, secondArg string, matchScore float64, edits []protocol.TextEdit) {
-	// Keep it simple and don't add any placeholders for optional "make()" arguments.
-
-	snip.PrependText("make(")
-	if secondArg != "" {
-		snip.WriteText(", ")
-		snip.WritePlaceholder(func(b *snippet.Builder) {
-			if c.opts.placeholders {
-				b.WriteText(secondArg)
-			}
-		})
-	}
-	snip.WriteText(")")
-
-	var nonSnippet strings.Builder
-	nonSnippet.WriteString("make(" + typeName)
-	if secondArg != "" {
-		nonSnippet.WriteString(", ")
-		nonSnippet.WriteString(secondArg)
-	}
-	nonSnippet.WriteByte(')')
-
-	c.items = append(c.items, CompletionItem{
-		Label:               nonSnippet.String(),
-		InsertText:          nonSnippet.String(),
-		Score:               matchScore * literalCandidateScore,
-		Kind:                protocol.FunctionCompletion,
-		AdditionalTextEdits: edits,
-		snippet:             snip,
-	})
-}
-
-// Create a snippet for a type name where type params become placeholders.
-func (c *completer) typeNameSnippet(literalType types.Type, qf types.Qualifier) (*snippet.Builder, string) {
-	var (
-		snip     snippet.Builder
-		typeName string
-		named, _ = literalType.(*types.Named)
-	)
-
-	if named != nil && named.Obj() != nil && typeparams.ForNamed(named).Len() > 0 && !c.fullyInstantiated(named) {
-		// We are not "fully instantiated" meaning we have type params that must be specified.
-		if pkg := qf(named.Obj().Pkg()); pkg != "" {
-			typeName = pkg + "."
-		}
-
-		// We do this to get "someType" instead of "someType[T]".
-		typeName += named.Obj().Name()
-		snip.WriteText(typeName + "[")
-
-		if c.opts.placeholders {
-			for i := 0; i < typeparams.ForNamed(named).Len(); i++ {
-				if i > 0 {
-					snip.WriteText(", ")
-				}
-				snip.WritePlaceholder(func(snip *snippet.Builder) {
-					snip.WriteText(types.TypeString(typeparams.ForNamed(named).At(i), qf))
-				})
-			}
-		} else {
-			snip.WritePlaceholder(nil)
-		}
-		snip.WriteText("]")
-		typeName += "[...]"
-	} else {
-		// We don't have unspecified type params so use default type formatting.
-		typeName = types.TypeString(literalType, qf)
-		snip.WriteText(typeName)
-	}
-
-	return &snip, typeName
-}
-
-// fullyInstantiated reports whether all of t's type params have
-// specified type args.
-func (c *completer) fullyInstantiated(t *types.Named) bool {
-	tps := typeparams.ForNamed(t)
-	tas := typeparams.NamedTypeArgs(t)
-
-	if tps.Len() != tas.Len() {
-		return false
-	}
-
-	for i := 0; i < tas.Len(); i++ {
-		switch ta := tas.At(i).(type) {
-		case *typeparams.TypeParam:
-			// A *TypeParam only counts as specified if it is currently in
-			// scope (i.e. we are in a generic definition).
-			if !c.typeParamInScope(ta) {
-				return false
-			}
-		case *types.Named:
-			if !c.fullyInstantiated(ta) {
-				return false
-			}
-		}
-	}
-	return true
-}
-
-// typeParamInScope returns whether tp's object is in scope at c.pos.
-// This tells you whether you are in a generic definition and can
-// assume tp has been specified.
-func (c *completer) typeParamInScope(tp *typeparams.TypeParam) bool {
-	obj := tp.Obj()
-	if obj == nil {
-		return false
-	}
-
-	scope := c.innermostScope()
-	if scope == nil {
-		return false
-	}
-
-	_, foundObj := scope.LookupParent(obj.Name(), c.pos)
-	return obj == foundObj
-}
diff -urN a/gopls/internal/lsp/source/completion/package.go b/gopls/internal/lsp/source/completion/package.go
--- a/gopls/internal/lsp/source/completion/package.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/package.go	1969-12-31 16:00:00
@@ -1,363 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/parser"
-	"go/scanner"
-	"go/token"
-	"go/types"
-	"path/filepath"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/fuzzy"
-)
-
-// packageClauseCompletions offers completions for a package declaration when
-// one is not present in the given file.
-func packageClauseCompletions(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, position protocol.Position) ([]CompletionItem, *Selection, error) {
-	// We know that the AST for this file will be empty due to the missing
-	// package declaration, but parse it anyway to get a mapper.
-	fset := snapshot.FileSet()
-	pgf, err := snapshot.ParseGo(ctx, fh, source.ParseFull)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	pos, err := pgf.Mapper.Pos(position)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	surrounding, err := packageCompletionSurrounding(fset, pgf, pos)
-	if err != nil {
-		return nil, nil, fmt.Errorf("invalid position for package completion: %w", err)
-	}
-
-	packageSuggestions, err := packageSuggestions(ctx, snapshot, fh.URI(), "")
-	if err != nil {
-		return nil, nil, err
-	}
-
-	var items []CompletionItem
-	for _, pkg := range packageSuggestions {
-		insertText := fmt.Sprintf("package %s", pkg.name)
-		items = append(items, CompletionItem{
-			Label:      insertText,
-			Kind:       protocol.ModuleCompletion,
-			InsertText: insertText,
-			Score:      pkg.score,
-		})
-	}
-
-	return items, surrounding, nil
-}
-
-// packageCompletionSurrounding returns surrounding for package completion if a
-// package completions can be suggested at a given position. A valid location
-// for package completion is above any declarations or import statements.
-func packageCompletionSurrounding(fset *token.FileSet, pgf *source.ParsedGoFile, pos token.Pos) (*Selection, error) {
-	// If the file lacks a package declaration, the parser will return an empty
-	// AST. As a work-around, try to parse an expression from the file contents.
-	filename := pgf.URI.Filename()
-	expr, _ := parser.ParseExprFrom(fset, filename, pgf.Src, parser.Mode(0))
-	if expr == nil {
-		return nil, fmt.Errorf("unparseable file (%s)", pgf.URI)
-	}
-	tok := fset.File(expr.Pos())
-	offset, err := safetoken.Offset(pgf.Tok, pos)
-	if err != nil {
-		return nil, err
-	}
-	if offset > tok.Size() {
-		// internal bug: we should never get an offset that exceeds the size of our
-		// file.
-		bug.Report("out of bounds cursor", bug.Data{
-			"offset": offset,
-			"URI":    pgf.URI,
-			"size":   tok.Size(),
-		})
-		return nil, fmt.Errorf("cursor out of bounds")
-	}
-	cursor := tok.Pos(offset)
-
-	// If we were able to parse out an identifier as the first expression from
-	// the file, it may be the beginning of a package declaration ("pack ").
-	// We can offer package completions if the cursor is in the identifier.
-	if name, ok := expr.(*ast.Ident); ok {
-		if cursor >= name.Pos() && cursor <= name.End() {
-			if !strings.HasPrefix(PACKAGE, name.Name) {
-				return nil, fmt.Errorf("cursor in non-matching ident")
-			}
-			return &Selection{
-				content: name.Name,
-				cursor:  cursor,
-				rng:     span.NewRange(tok, name.Pos(), name.End()),
-			}, nil
-		}
-	}
-
-	// The file is invalid, but it contains an expression that we were able to
-	// parse. We will use this expression to construct the cursor's
-	// "surrounding".
-
-	// First, consider the possibility that we have a valid "package" keyword
-	// with an empty package name ("package "). "package" is parsed as an
-	// *ast.BadDecl since it is a keyword. This logic would allow "package" to
-	// appear on any line of the file as long as it's the first code expression
-	// in the file.
-	lines := strings.Split(string(pgf.Src), "\n")
-	cursorLine := tok.Line(cursor)
-	if cursorLine <= 0 || cursorLine > len(lines) {
-		return nil, fmt.Errorf("invalid line number")
-	}
-	if safetoken.StartPosition(fset, expr.Pos()).Line == cursorLine {
-		words := strings.Fields(lines[cursorLine-1])
-		if len(words) > 0 && words[0] == PACKAGE {
-			content := PACKAGE
-			// Account for spaces if there are any.
-			if len(words) > 1 {
-				content += " "
-			}
-
-			start := expr.Pos()
-			end := token.Pos(int(expr.Pos()) + len(content) + 1)
-			// We have verified that we have a valid 'package' keyword as our
-			// first expression. Ensure that cursor is in this keyword or
-			// otherwise fallback to the general case.
-			if cursor >= start && cursor <= end {
-				return &Selection{
-					content: content,
-					cursor:  cursor,
-					rng:     span.NewRange(tok, start, end),
-				}, nil
-			}
-		}
-	}
-
-	// If the cursor is after the start of the expression, no package
-	// declaration will be valid.
-	if cursor > expr.Pos() {
-		return nil, fmt.Errorf("cursor after expression")
-	}
-
-	// If the cursor is in a comment, don't offer any completions.
-	if cursorInComment(fset.File(cursor), cursor, pgf.Src) {
-		return nil, fmt.Errorf("cursor in comment")
-	}
-
-	// The surrounding range in this case is the cursor except for empty file,
-	// in which case it's end of file - 1
-	start, end := cursor, cursor
-	if tok.Size() == 0 {
-		start, end = tok.Pos(0)-1, tok.Pos(0)-1
-	}
-
-	return &Selection{
-		content: "",
-		cursor:  cursor,
-		rng:     span.NewRange(tok, start, end),
-	}, nil
-}
-
-func cursorInComment(file *token.File, cursor token.Pos, src []byte) bool {
-	var s scanner.Scanner
-	s.Init(file, src, func(_ token.Position, _ string) {}, scanner.ScanComments)
-	for {
-		pos, tok, lit := s.Scan()
-		if pos <= cursor && cursor <= token.Pos(int(pos)+len(lit)) {
-			return tok == token.COMMENT
-		}
-		if tok == token.EOF {
-			break
-		}
-	}
-	return false
-}
-
-// packageNameCompletions returns name completions for a package clause using
-// the current name as prefix.
-func (c *completer) packageNameCompletions(ctx context.Context, fileURI span.URI, name *ast.Ident) error {
-	cursor := int(c.pos - name.NamePos)
-	if cursor < 0 || cursor > len(name.Name) {
-		return errors.New("cursor is not in package name identifier")
-	}
-
-	c.completionContext.packageCompletion = true
-
-	prefix := name.Name[:cursor]
-	packageSuggestions, err := packageSuggestions(ctx, c.snapshot, fileURI, prefix)
-	if err != nil {
-		return err
-	}
-
-	for _, pkg := range packageSuggestions {
-		c.deepState.enqueue(pkg)
-	}
-	return nil
-}
-
-// packageSuggestions returns a list of packages from workspace packages that
-// have the given prefix and are used in the same directory as the given
-// file. This also includes test packages for these packages (<pkg>_test) and
-// the directory name itself.
-func packageSuggestions(ctx context.Context, snapshot source.Snapshot, fileURI span.URI, prefix string) (packages []candidate, err error) {
-	active, err := snapshot.ActiveMetadata(ctx)
-	if err != nil {
-		return nil, err
-	}
-
-	toCandidate := func(name string, score float64) candidate {
-		obj := types.NewPkgName(0, nil, name, types.NewPackage("", name))
-		return candidate{obj: obj, name: name, detail: name, score: score}
-	}
-
-	matcher := fuzzy.NewMatcher(prefix)
-
-	// Always try to suggest a main package
-	defer func() {
-		if score := float64(matcher.Score("main")); score > 0 {
-			packages = append(packages, toCandidate("main", score*lowScore))
-		}
-	}()
-
-	dirPath := filepath.Dir(fileURI.Filename())
-	dirName := filepath.Base(dirPath)
-	if !isValidDirName(dirName) {
-		return packages, nil
-	}
-	pkgName := convertDirNameToPkgName(dirName)
-
-	seenPkgs := make(map[source.PackageName]struct{})
-
-	// The `go` command by default only allows one package per directory but we
-	// support multiple package suggestions since gopls is build system agnostic.
-	for _, m := range active {
-		if m.Name == "main" || m.Name == "" {
-			continue
-		}
-		if _, ok := seenPkgs[m.Name]; ok {
-			continue
-		}
-
-		// Only add packages that are previously used in the current directory.
-		var relevantPkg bool
-		for _, uri := range m.CompiledGoFiles {
-			if filepath.Dir(uri.Filename()) == dirPath {
-				relevantPkg = true
-				break
-			}
-		}
-		if !relevantPkg {
-			continue
-		}
-
-		// Add a found package used in current directory as a high relevance
-		// suggestion and the test package for it as a medium relevance
-		// suggestion.
-		if score := float64(matcher.Score(string(m.Name))); score > 0 {
-			packages = append(packages, toCandidate(string(m.Name), score*highScore))
-		}
-		seenPkgs[m.Name] = struct{}{}
-
-		testPkgName := m.Name + "_test"
-		if _, ok := seenPkgs[testPkgName]; ok || strings.HasSuffix(string(m.Name), "_test") {
-			continue
-		}
-		if score := float64(matcher.Score(string(testPkgName))); score > 0 {
-			packages = append(packages, toCandidate(string(testPkgName), score*stdScore))
-		}
-		seenPkgs[testPkgName] = struct{}{}
-	}
-
-	// Add current directory name as a low relevance suggestion.
-	if _, ok := seenPkgs[pkgName]; !ok {
-		if score := float64(matcher.Score(string(pkgName))); score > 0 {
-			packages = append(packages, toCandidate(string(pkgName), score*lowScore))
-		}
-
-		testPkgName := pkgName + "_test"
-		if score := float64(matcher.Score(string(testPkgName))); score > 0 {
-			packages = append(packages, toCandidate(string(testPkgName), score*lowScore))
-		}
-	}
-
-	return packages, nil
-}
-
-// isValidDirName checks whether the passed directory name can be used in
-// a package path. Requirements for a package path can be found here:
-// https://golang.org/ref/mod#go-mod-file-ident.
-func isValidDirName(dirName string) bool {
-	if dirName == "" {
-		return false
-	}
-
-	for i, ch := range dirName {
-		if isLetter(ch) || isDigit(ch) {
-			continue
-		}
-		if i == 0 {
-			// Directory name can start only with '_'. '.' is not allowed in module paths.
-			// '-' and '~' are not allowed because elements of package paths must be
-			// safe command-line arguments.
-			if ch == '_' {
-				continue
-			}
-		} else {
-			// Modules path elements can't end with '.'
-			if isAllowedPunctuation(ch) && (i != len(dirName)-1 || ch != '.') {
-				continue
-			}
-		}
-
-		return false
-	}
-	return true
-}
-
-// convertDirNameToPkgName converts a valid directory name to a valid package name.
-// It leaves only letters and digits. All letters are mapped to lower case.
-func convertDirNameToPkgName(dirName string) source.PackageName {
-	var buf bytes.Buffer
-	for _, ch := range dirName {
-		switch {
-		case isLetter(ch):
-			buf.WriteRune(unicode.ToLower(ch))
-
-		case buf.Len() != 0 && isDigit(ch):
-			buf.WriteRune(ch)
-		}
-	}
-	return source.PackageName(buf.String())
-}
-
-// isLetter and isDigit allow only ASCII characters because
-// "Each path element is a non-empty string made of up ASCII letters,
-// ASCII digits, and limited ASCII punctuation"
-// (see https://golang.org/ref/mod#go-mod-file-ident).
-
-func isLetter(ch rune) bool {
-	return 'a' <= ch && ch <= 'z' || 'A' <= ch && ch <= 'Z'
-}
-
-func isDigit(ch rune) bool {
-	return '0' <= ch && ch <= '9'
-}
-
-func isAllowedPunctuation(ch rune) bool {
-	return ch == '_' || ch == '-' || ch == '~' || ch == '.'
-}
diff -urN a/gopls/internal/lsp/source/completion/package_test.go b/gopls/internal/lsp/source/completion/package_test.go
--- a/gopls/internal/lsp/source/completion/package_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/package_test.go	1969-12-31 16:00:00
@@ -1,81 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func TestIsValidDirName(t *testing.T) {
-	tests := []struct {
-		dirName string
-		valid   bool
-	}{
-		{dirName: "", valid: false},
-		//
-		{dirName: "a", valid: true},
-		{dirName: "abcdef", valid: true},
-		{dirName: "AbCdEf", valid: true},
-		//
-		{dirName: "1a35", valid: true},
-		{dirName: "a16", valid: true},
-		//
-		{dirName: "_a", valid: true},
-		{dirName: "a_", valid: true},
-		//
-		{dirName: "~a", valid: false},
-		{dirName: "a~", valid: true},
-		//
-		{dirName: "-a", valid: false},
-		{dirName: "a-", valid: true},
-		//
-		{dirName: ".a", valid: false},
-		{dirName: "a.", valid: false},
-		//
-		{dirName: "a~_b--c.-e", valid: true},
-		{dirName: "~a~_b--c.-e", valid: false},
-		{dirName: "a~_b--c.-e--~", valid: true},
-		{dirName: "a~_b--2134dc42.-e6--~", valid: true},
-		{dirName: "abc`def", valid: false},
-		{dirName: "тест", valid: false},
-		{dirName: "你好", valid: false},
-	}
-	for _, tt := range tests {
-		valid := isValidDirName(tt.dirName)
-		if tt.valid != valid {
-			t.Errorf("%s: expected %v, got %v", tt.dirName, tt.valid, valid)
-		}
-	}
-}
-
-func TestConvertDirNameToPkgName(t *testing.T) {
-	tests := []struct {
-		dirName string
-		pkgName source.PackageName
-	}{
-		{dirName: "a", pkgName: "a"},
-		{dirName: "abcdef", pkgName: "abcdef"},
-		{dirName: "AbCdEf", pkgName: "abcdef"},
-		{dirName: "1a35", pkgName: "a35"},
-		{dirName: "14a35", pkgName: "a35"},
-		{dirName: "a16", pkgName: "a16"},
-		{dirName: "_a", pkgName: "a"},
-		{dirName: "a_", pkgName: "a"},
-		{dirName: "a~", pkgName: "a"},
-		{dirName: "a-", pkgName: "a"},
-		{dirName: "a~_b--c.-e", pkgName: "abce"},
-		{dirName: "a~_b--c.-e--~", pkgName: "abce"},
-		{dirName: "a~_b--2134dc42.-e6--~", pkgName: "ab2134dc42e6"},
-	}
-	for _, tt := range tests {
-		pkgName := convertDirNameToPkgName(tt.dirName)
-		if tt.pkgName != pkgName {
-			t.Errorf("%s: expected %v, got %v", tt.dirName, tt.pkgName, pkgName)
-			continue
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/postfix_snippets.go b/gopls/internal/lsp/source/completion/postfix_snippets.go
--- a/gopls/internal/lsp/source/completion/postfix_snippets.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/postfix_snippets.go	1969-12-31 16:00:00
@@ -1,471 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"log"
-	"reflect"
-	"strings"
-	"sync"
-	"text/template"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/imports"
-)
-
-// Postfix snippets are artificial methods that allow the user to
-// compose common operations in an "argument oriented" fashion. For
-// example, instead of "sort.Slice(someSlice, ...)" a user can expand
-// "someSlice.sort!".
-
-// postfixTmpl represents a postfix snippet completion candidate.
-type postfixTmpl struct {
-	// label is the completion candidate's label presented to the user.
-	label string
-
-	// details is passed along to the client as the candidate's details.
-	details string
-
-	// body is the template text. See postfixTmplArgs for details on the
-	// facilities available to the template.
-	body string
-
-	tmpl *template.Template
-}
-
-// postfixTmplArgs are the template execution arguments available to
-// the postfix snippet templates.
-type postfixTmplArgs struct {
-	// StmtOK is true if it is valid to replace the selector with a
-	// statement. For example:
-	//
-	//    func foo() {
-	//      bar.sort! // statement okay
-	//
-	//      someMethod(bar.sort!) // statement not okay
-	//    }
-	StmtOK bool
-
-	// X is the textual SelectorExpr.X. For example, when completing
-	// "foo.bar.print!", "X" is "foo.bar".
-	X string
-
-	// Obj is the types.Object of SelectorExpr.X, if any.
-	Obj types.Object
-
-	// Type is the type of "foo.bar" in "foo.bar.print!".
-	Type types.Type
-
-	scope          *types.Scope
-	snip           snippet.Builder
-	importIfNeeded func(pkgPath string, scope *types.Scope) (name string, edits []protocol.TextEdit, err error)
-	edits          []protocol.TextEdit
-	qf             types.Qualifier
-	varNames       map[string]bool
-}
-
-var postfixTmpls = []postfixTmpl{{
-	label:   "sort",
-	details: "sort.Slice()",
-	body: `{{if and (eq .Kind "slice") .StmtOK -}}
-{{.Import "sort"}}.Slice({{.X}}, func({{.VarName nil "i"}}, {{.VarName nil "j"}} int) bool {
-	{{.Cursor}}
-})
-{{- end}}`,
-}, {
-	label:   "last",
-	details: "s[len(s)-1]",
-	body: `{{if and (eq .Kind "slice") .Obj -}}
-{{.X}}[len({{.X}})-1]
-{{- end}}`,
-}, {
-	label:   "reverse",
-	details: "reverse slice",
-	body: `{{if and (eq .Kind "slice") .StmtOK -}}
-{{$i := .VarName nil "i"}}{{$j := .VarName nil "j" -}}
-for {{$i}}, {{$j}} := 0, len({{.X}})-1; {{$i}} < {{$j}}; {{$i}}, {{$j}} = {{$i}}+1, {{$j}}-1 {
-	{{.X}}[{{$i}}], {{.X}}[{{$j}}] = {{.X}}[{{$j}}], {{.X}}[{{$i}}]
-}
-{{end}}`,
-}, {
-	label:   "range",
-	details: "range over slice",
-	body: `{{if and (eq .Kind "slice") .StmtOK -}}
-for {{.VarName nil "i"}}, {{.VarName .ElemType "v"}} := range {{.X}} {
-	{{.Cursor}}
-}
-{{- end}}`,
-}, {
-	label:   "append",
-	details: "append and re-assign slice",
-	body: `{{if and (eq .Kind "slice") .StmtOK .Obj -}}
-{{.X}} = append({{.X}}, {{.Cursor}})
-{{- end}}`,
-}, {
-	label:   "append",
-	details: "append to slice",
-	body: `{{if and (eq .Kind "slice") (not .StmtOK) -}}
-append({{.X}}, {{.Cursor}})
-{{- end}}`,
-}, {
-	label:   "copy",
-	details: "duplicate slice",
-	body: `{{if and (eq .Kind "slice") .StmtOK .Obj -}}
-{{$v := (.VarName nil (printf "%sCopy" .X))}}{{$v}} := make([]{{.TypeName .ElemType}}, len({{.X}}))
-copy({{$v}}, {{.X}})
-{{end}}`,
-}, {
-	label:   "range",
-	details: "range over map",
-	body: `{{if and (eq .Kind "map") .StmtOK -}}
-for {{.VarName .KeyType "k"}}, {{.VarName .ElemType "v"}} := range {{.X}} {
-	{{.Cursor}}
-}
-{{- end}}`,
-}, {
-	label:   "clear",
-	details: "clear map contents",
-	body: `{{if and (eq .Kind "map") .StmtOK -}}
-{{$k := (.VarName .KeyType "k")}}for {{$k}} := range {{.X}} {
-	delete({{.X}}, {{$k}})
-}
-{{end}}`,
-}, {
-	label:   "keys",
-	details: "create slice of keys",
-	body: `{{if and (eq .Kind "map") .StmtOK -}}
-{{$keysVar := (.VarName nil "keys")}}{{$keysVar}} := make([]{{.TypeName .KeyType}}, 0, len({{.X}}))
-{{$k := (.VarName .KeyType "k")}}for {{$k}} := range {{.X}} {
-	{{$keysVar}} = append({{$keysVar}}, {{$k}})
-}
-{{end}}`,
-}, {
-	label:   "range",
-	details: "range over channel",
-	body: `{{if and (eq .Kind "chan") .StmtOK -}}
-for {{.VarName .ElemType "e"}} := range {{.X}} {
-	{{.Cursor}}
-}
-{{- end}}`,
-}, {
-	label:   "var",
-	details: "assign to variables",
-	body: `{{if and (eq .Kind "tuple") .StmtOK -}}
-{{$a := .}}{{range $i, $v := .Tuple}}{{if $i}}, {{end}}{{$a.VarName $v.Type $v.Name}}{{end}} := {{.X}}
-{{- end}}`,
-}, {
-	label:   "var",
-	details: "assign to variable",
-	body: `{{if and (ne .Kind "tuple") .StmtOK -}}
-{{.VarName .Type ""}} := {{.X}}
-{{- end}}`,
-}, {
-	label:   "print",
-	details: "print to stdout",
-	body: `{{if and (ne .Kind "tuple") .StmtOK -}}
-{{.Import "fmt"}}.Printf("{{.EscapeQuotes .X}}: %v\n", {{.X}})
-{{- end}}`,
-}, {
-	label:   "print",
-	details: "print to stdout",
-	body: `{{if and (eq .Kind "tuple") .StmtOK -}}
-{{.Import "fmt"}}.Println({{.X}})
-{{- end}}`,
-}, {
-	label:   "split",
-	details: "split string",
-	body: `{{if (eq (.TypeName .Type) "string") -}}
-{{.Import "strings"}}.Split({{.X}}, "{{.Cursor}}")
-{{- end}}`,
-}, {
-	label:   "join",
-	details: "join string slice",
-	body: `{{if and (eq .Kind "slice") (eq (.TypeName .ElemType) "string") -}}
-{{.Import "strings"}}.Join({{.X}}, "{{.Cursor}}")
-{{- end}}`,
-}}
-
-// Cursor indicates where the client's cursor should end up after the
-// snippet is done.
-func (a *postfixTmplArgs) Cursor() string {
-	a.snip.WriteFinalTabstop()
-	return ""
-}
-
-// Import makes sure the package corresponding to path is imported,
-// returning the identifier to use to refer to the package.
-func (a *postfixTmplArgs) Import(path string) (string, error) {
-	name, edits, err := a.importIfNeeded(path, a.scope)
-	if err != nil {
-		return "", fmt.Errorf("couldn't import %q: %w", path, err)
-	}
-	a.edits = append(a.edits, edits...)
-	return name, nil
-}
-
-func (a *postfixTmplArgs) EscapeQuotes(v string) string {
-	return strings.ReplaceAll(v, `"`, `\\"`)
-}
-
-// ElemType returns the Elem() type of xType, if applicable.
-func (a *postfixTmplArgs) ElemType() types.Type {
-	if e, _ := a.Type.(interface{ Elem() types.Type }); e != nil {
-		return e.Elem()
-	}
-	return nil
-}
-
-// Kind returns the underlying kind of type, e.g. "slice", "struct",
-// etc.
-func (a *postfixTmplArgs) Kind() string {
-	t := reflect.TypeOf(a.Type.Underlying())
-	return strings.ToLower(strings.TrimPrefix(t.String(), "*types."))
-}
-
-// KeyType returns the type of X's key. KeyType panics if X is not a
-// map.
-func (a *postfixTmplArgs) KeyType() types.Type {
-	return a.Type.Underlying().(*types.Map).Key()
-}
-
-// Tuple returns the tuple result vars if X is a call expression.
-func (a *postfixTmplArgs) Tuple() []*types.Var {
-	tuple, _ := a.Type.(*types.Tuple)
-	if tuple == nil {
-		return nil
-	}
-
-	typs := make([]*types.Var, 0, tuple.Len())
-	for i := 0; i < tuple.Len(); i++ {
-		typs = append(typs, tuple.At(i))
-	}
-	return typs
-}
-
-// TypeName returns the textual representation of type t.
-func (a *postfixTmplArgs) TypeName(t types.Type) (string, error) {
-	if t == nil || t == types.Typ[types.Invalid] {
-		return "", fmt.Errorf("invalid type: %v", t)
-	}
-	return types.TypeString(t, a.qf), nil
-}
-
-// VarName returns a suitable variable name for the type t. If t
-// implements the error interface, "err" is used. If t is not a named
-// type then nonNamedDefault is used. Otherwise a name is made by
-// abbreviating the type name. If the resultant name is already in
-// scope, an integer is appended to make a unique name.
-func (a *postfixTmplArgs) VarName(t types.Type, nonNamedDefault string) string {
-	if t == nil {
-		t = types.Typ[types.Invalid]
-	}
-
-	var name string
-	// go/types predicates are undefined on types.Typ[types.Invalid].
-	if !types.Identical(t, types.Typ[types.Invalid]) && types.Implements(t, errorIntf) {
-		name = "err"
-	} else if _, isNamed := source.Deref(t).(*types.Named); !isNamed {
-		name = nonNamedDefault
-	}
-
-	if name == "" {
-		name = types.TypeString(t, func(p *types.Package) string {
-			return ""
-		})
-		name = abbreviateTypeName(name)
-	}
-
-	if dot := strings.LastIndex(name, "."); dot > -1 {
-		name = name[dot+1:]
-	}
-
-	uniqueName := name
-	for i := 2; ; i++ {
-		if s, _ := a.scope.LookupParent(uniqueName, token.NoPos); s == nil && !a.varNames[uniqueName] {
-			break
-		}
-		uniqueName = fmt.Sprintf("%s%d", name, i)
-	}
-
-	a.varNames[uniqueName] = true
-
-	return uniqueName
-}
-
-func (c *completer) addPostfixSnippetCandidates(ctx context.Context, sel *ast.SelectorExpr) {
-	if !c.opts.postfix {
-		return
-	}
-
-	initPostfixRules()
-
-	if sel == nil || sel.Sel == nil {
-		return
-	}
-
-	selType := c.pkg.GetTypesInfo().TypeOf(sel.X)
-	if selType == nil {
-		return
-	}
-
-	// Skip empty tuples since there is no value to operate on.
-	if tuple, ok := selType.Underlying().(*types.Tuple); ok && tuple == nil {
-		return
-	}
-
-	tokFile := c.pkg.FileSet().File(c.pos)
-
-	// Only replace sel with a statement if sel is already a statement.
-	var stmtOK bool
-	for i, n := range c.path {
-		if n == sel && i < len(c.path)-1 {
-			switch p := c.path[i+1].(type) {
-			case *ast.ExprStmt:
-				stmtOK = true
-			case *ast.AssignStmt:
-				// In cases like:
-				//
-				//   foo.<>
-				//   bar = 123
-				//
-				// detect that "foo." makes up the entire statement since the
-				// apparent selector spans lines.
-				stmtOK = tokFile.Line(c.pos) < tokFile.Line(p.TokPos)
-			}
-			break
-		}
-	}
-
-	scope := c.pkg.GetTypes().Scope().Innermost(c.pos)
-	if scope == nil {
-		return
-	}
-
-	// afterDot is the position after selector dot, e.g. "|" in
-	// "foo.|print".
-	afterDot := sel.Sel.Pos()
-
-	// We must detect dangling selectors such as:
-	//
-	//    foo.<>
-	//    bar
-	//
-	// and adjust afterDot so that we don't mistakenly delete the
-	// newline thinking "bar" is part of our selector.
-	if startLine := tokFile.Line(sel.Pos()); startLine != tokFile.Line(afterDot) {
-		if tokFile.Line(c.pos) != startLine {
-			return
-		}
-		afterDot = c.pos
-	}
-
-	for _, rule := range postfixTmpls {
-		// When completing foo.print<>, "print" is naturally overwritten,
-		// but we need to also remove "foo." so the snippet has a clean
-		// slate.
-		edits, err := c.editText(sel.Pos(), afterDot, "")
-		if err != nil {
-			event.Error(ctx, "error calculating postfix edits", err)
-			return
-		}
-
-		tmplArgs := postfixTmplArgs{
-			X:              source.FormatNode(c.pkg.FileSet(), sel.X),
-			StmtOK:         stmtOK,
-			Obj:            exprObj(c.pkg.GetTypesInfo(), sel.X),
-			Type:           selType,
-			qf:             c.qf,
-			importIfNeeded: c.importIfNeeded,
-			scope:          scope,
-			varNames:       make(map[string]bool),
-		}
-
-		// Feed the template straight into the snippet builder. This
-		// allows templates to build snippets as they are executed.
-		err = rule.tmpl.Execute(&tmplArgs.snip, &tmplArgs)
-		if err != nil {
-			event.Error(ctx, "error executing postfix template", err)
-			continue
-		}
-
-		if strings.TrimSpace(tmplArgs.snip.String()) == "" {
-			continue
-		}
-
-		score := c.matcher.Score(rule.label)
-		if score <= 0 {
-			continue
-		}
-
-		c.items = append(c.items, CompletionItem{
-			Label:               rule.label + "!",
-			Detail:              rule.details,
-			Score:               float64(score) * 0.01,
-			Kind:                protocol.SnippetCompletion,
-			snippet:             &tmplArgs.snip,
-			AdditionalTextEdits: append(edits, tmplArgs.edits...),
-		})
-	}
-}
-
-var postfixRulesOnce sync.Once
-
-func initPostfixRules() {
-	postfixRulesOnce.Do(func() {
-		var idx int
-		for _, rule := range postfixTmpls {
-			var err error
-			rule.tmpl, err = template.New("postfix_snippet").Parse(rule.body)
-			if err != nil {
-				log.Panicf("error parsing postfix snippet template: %v", err)
-			}
-			postfixTmpls[idx] = rule
-			idx++
-		}
-		postfixTmpls = postfixTmpls[:idx]
-	})
-}
-
-// importIfNeeded returns the package identifier and any necessary
-// edits to import package pkgPath.
-func (c *completer) importIfNeeded(pkgPath string, scope *types.Scope) (string, []protocol.TextEdit, error) {
-	defaultName := imports.ImportPathToAssumedName(pkgPath)
-
-	// Check if file already imports pkgPath.
-	for _, s := range c.file.Imports {
-		// TODO(adonovan): what if pkgPath has a vendor/ suffix?
-		// This may be the cause of go.dev/issue/56291.
-		if source.UnquoteImportPath(s) == source.ImportPath(pkgPath) {
-			if s.Name == nil {
-				return defaultName, nil, nil
-			}
-			if s.Name.Name != "_" {
-				return s.Name.Name, nil, nil
-			}
-		}
-	}
-
-	// Give up if the package's name is already in use by another object.
-	if _, obj := scope.LookupParent(defaultName, token.NoPos); obj != nil {
-		return "", nil, fmt.Errorf("import name %q of %q already in use", defaultName, pkgPath)
-	}
-
-	edits, err := c.importEdits(&importInfo{
-		importPath: pkgPath,
-	})
-	if err != nil {
-		return "", nil, err
-	}
-
-	return defaultName, edits, nil
-}
diff -urN a/gopls/internal/lsp/source/completion/printf.go b/gopls/internal/lsp/source/completion/printf.go
--- a/gopls/internal/lsp/source/completion/printf.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/printf.go	1969-12-31 16:00:00
@@ -1,172 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/ast"
-	"go/constant"
-	"go/types"
-	"strconv"
-	"strings"
-	"unicode/utf8"
-)
-
-// printfArgKind returns the expected objKind when completing a
-// printf-like operand. call is the printf-like function call, and
-// argIdx is the index of call.Args being completed.
-func printfArgKind(info *types.Info, call *ast.CallExpr, argIdx int) objKind {
-	// Printf-like function name must end in "f".
-	fn := exprObj(info, call.Fun)
-	if fn == nil || !strings.HasSuffix(fn.Name(), "f") {
-		return kindAny
-	}
-
-	sig, _ := fn.Type().(*types.Signature)
-	if sig == nil {
-		return kindAny
-	}
-
-	// Must be variadic and take at least two params.
-	numParams := sig.Params().Len()
-	if !sig.Variadic() || numParams < 2 || argIdx < numParams-1 {
-		return kindAny
-	}
-
-	// Param preceding variadic args must be a (format) string.
-	if !types.Identical(sig.Params().At(numParams-2).Type(), types.Typ[types.String]) {
-		return kindAny
-	}
-
-	// Format string must be a constant.
-	strArg := info.Types[call.Args[numParams-2]].Value
-	if strArg == nil || strArg.Kind() != constant.String {
-		return kindAny
-	}
-
-	return formatOperandKind(constant.StringVal(strArg), argIdx-(numParams-1)+1)
-}
-
-// formatOperandKind returns the objKind corresponding to format's
-// operandIdx'th operand.
-func formatOperandKind(format string, operandIdx int) objKind {
-	var (
-		prevOperandIdx int
-		kind           = kindAny
-	)
-	for {
-		i := strings.Index(format, "%")
-		if i == -1 {
-			break
-		}
-
-		var operands []formatOperand
-		format, operands = parsePrintfVerb(format[i+1:], prevOperandIdx)
-
-		// Check if any this verb's operands correspond to our target
-		// operandIdx.
-		for _, v := range operands {
-			if v.idx == operandIdx {
-				if kind == kindAny {
-					kind = v.kind
-				} else if v.kind != kindAny {
-					// If multiple verbs refer to the same operand, take the
-					// intersection of their kinds.
-					kind &= v.kind
-				}
-			}
-
-			prevOperandIdx = v.idx
-		}
-	}
-	return kind
-}
-
-type formatOperand struct {
-	// idx is the one-based printf operand index.
-	idx int
-	// kind is a mask of expected kinds of objects for this operand.
-	kind objKind
-}
-
-// parsePrintfVerb parses the leading printf verb in f. The opening
-// "%" must already be trimmed from f. prevIdx is the previous
-// operand's index, or zero if this is the first verb. The format
-// string is returned with the leading verb removed. Multiple operands
-// can be returned in the case of dynamic widths such as "%*.*f".
-func parsePrintfVerb(f string, prevIdx int) (string, []formatOperand) {
-	var verbs []formatOperand
-
-	addVerb := func(k objKind) {
-		verbs = append(verbs, formatOperand{
-			idx:  prevIdx + 1,
-			kind: k,
-		})
-		prevIdx++
-	}
-
-	for len(f) > 0 {
-		// Trim first rune off of f so we are guaranteed to make progress.
-		r, l := utf8.DecodeRuneInString(f)
-		f = f[l:]
-
-		// We care about three things:
-		// 1. The verb, which maps directly to object kind.
-		// 2. Explicit operand indices like "%[2]s".
-		// 3. Dynamic widths using "*".
-		switch r {
-		case '%':
-			return f, nil
-		case '*':
-			addVerb(kindInt)
-			continue
-		case '[':
-			// Parse operand index as in "%[2]s".
-			i := strings.Index(f, "]")
-			if i == -1 {
-				return f, nil
-			}
-
-			idx, err := strconv.Atoi(f[:i])
-			f = f[i+1:]
-			if err != nil {
-				return f, nil
-			}
-
-			prevIdx = idx - 1
-			continue
-		case 'v', 'T':
-			addVerb(kindAny)
-		case 't':
-			addVerb(kindBool)
-		case 'c', 'd', 'o', 'O', 'U':
-			addVerb(kindInt)
-		case 'e', 'E', 'f', 'F', 'g', 'G':
-			addVerb(kindFloat | kindComplex)
-		case 'b':
-			addVerb(kindInt | kindFloat | kindComplex | kindBytes)
-		case 'q', 's':
-			addVerb(kindString | kindBytes | kindStringer | kindError)
-		case 'x', 'X':
-			// Omit kindStringer and kindError though technically allowed.
-			addVerb(kindString | kindBytes | kindInt | kindFloat | kindComplex)
-		case 'p':
-			addVerb(kindPtr | kindSlice)
-		case 'w':
-			addVerb(kindError)
-		case '+', '-', '#', ' ', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
-			// Flag or numeric width/precision value.
-			continue
-		default:
-			// Assume unrecognized rune is a custom fmt.Formatter verb.
-			addVerb(kindAny)
-		}
-
-		if len(verbs) > 0 {
-			break
-		}
-	}
-
-	return f, verbs
-}
diff -urN a/gopls/internal/lsp/source/completion/printf_test.go b/gopls/internal/lsp/source/completion/printf_test.go
--- a/gopls/internal/lsp/source/completion/printf_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/printf_test.go	1969-12-31 16:00:00
@@ -1,72 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"fmt"
-	"testing"
-)
-
-func TestFormatOperandKind(t *testing.T) {
-	cases := []struct {
-		f    string
-		idx  int
-		kind objKind
-	}{
-		{"", 1, kindAny},
-		{"%", 1, kindAny},
-		{"%%%", 1, kindAny},
-		{"%[1", 1, kindAny},
-		{"%[?%s", 2, kindAny},
-		{"%[abc]v", 1, kindAny},
-
-		{"%v", 1, kindAny},
-		{"%T", 1, kindAny},
-		{"%t", 1, kindBool},
-		{"%d", 1, kindInt},
-		{"%c", 1, kindInt},
-		{"%o", 1, kindInt},
-		{"%O", 1, kindInt},
-		{"%U", 1, kindInt},
-		{"%e", 1, kindFloat | kindComplex},
-		{"%E", 1, kindFloat | kindComplex},
-		{"%f", 1, kindFloat | kindComplex},
-		{"%F", 1, kindFloat | kindComplex},
-		{"%g", 1, kindFloat | kindComplex},
-		{"%G", 1, kindFloat | kindComplex},
-		{"%b", 1, kindInt | kindFloat | kindComplex | kindBytes},
-		{"%q", 1, kindString | kindBytes | kindStringer | kindError},
-		{"%s", 1, kindString | kindBytes | kindStringer | kindError},
-		{"%x", 1, kindString | kindBytes | kindInt | kindFloat | kindComplex},
-		{"%X", 1, kindString | kindBytes | kindInt | kindFloat | kindComplex},
-		{"%p", 1, kindPtr | kindSlice},
-		{"%w", 1, kindError},
-
-		{"%1.2f", 1, kindFloat | kindComplex},
-		{"%*f", 1, kindInt},
-		{"%*f", 2, kindFloat | kindComplex},
-		{"%*.*f", 1, kindInt},
-		{"%*.*f", 2, kindInt},
-		{"%*.*f", 3, kindFloat | kindComplex},
-		{"%[3]*.[2]*[1]f", 1, kindFloat | kindComplex},
-		{"%[3]*.[2]*[1]f", 2, kindInt},
-		{"%[3]*.[2]*[1]f", 3, kindInt},
-
-		{"foo %% %d", 1, kindInt},
-		{"%#-12.34f", 1, kindFloat | kindComplex},
-		{"% d", 1, kindInt},
-
-		{"%s %[1]X %d", 1, kindString | kindBytes},
-		{"%s %[1]X %d", 2, kindInt},
-	}
-
-	for _, c := range cases {
-		t.Run(fmt.Sprintf("%q#%d", c.f, c.idx), func(t *testing.T) {
-			if got := formatOperandKind(c.f, c.idx); got != c.kind {
-				t.Errorf("expected %d (%[1]b), got %d (%[2]b)", c.kind, got)
-			}
-		})
-	}
-}
diff -urN a/gopls/internal/lsp/source/completion/snippet.go b/gopls/internal/lsp/source/completion/snippet.go
--- a/gopls/internal/lsp/source/completion/snippet.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/snippet.go	1969-12-31 16:00:00
@@ -1,116 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/ast"
-
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-)
-
-// structFieldSnippets calculates the snippet for struct literal field names.
-func (c *completer) structFieldSnippet(cand candidate, detail string, snip *snippet.Builder) {
-	if !c.wantStructFieldCompletions() {
-		return
-	}
-
-	// If we are in a deep completion then we can't be completing a field
-	// name (e.g. "Foo{f<>}" completing to "Foo{f.Bar}" should not generate
-	// a snippet).
-	if len(cand.path) > 0 {
-		return
-	}
-
-	clInfo := c.enclosingCompositeLiteral
-
-	// If we are already in a key-value expression, we don't want a snippet.
-	if clInfo.kv != nil {
-		return
-	}
-
-	// A plain snippet turns "Foo{Ba<>" into "Foo{Bar: <>".
-	snip.WriteText(": ")
-	snip.WritePlaceholder(func(b *snippet.Builder) {
-		// A placeholder snippet turns "Foo{Ba<>" into "Foo{Bar: <*int*>".
-		if c.opts.placeholders {
-			b.WriteText(detail)
-		}
-	})
-
-	fset := c.pkg.FileSet()
-
-	// If the cursor position is on a different line from the literal's opening brace,
-	// we are in a multiline literal. Ignore line directives.
-	if safetoken.StartPosition(fset, c.pos).Line != safetoken.StartPosition(fset, clInfo.cl.Lbrace).Line {
-		snip.WriteText(",")
-	}
-}
-
-// functionCallSnippets calculates the snippet for function calls.
-func (c *completer) functionCallSnippet(name string, tparams, params []string, snip *snippet.Builder) {
-	// If there is no suffix then we need to reuse existing call parens
-	// "()" if present. If there is an identifier suffix then we always
-	// need to include "()" since we don't overwrite the suffix.
-	if c.surrounding != nil && c.surrounding.Suffix() == "" && len(c.path) > 1 {
-		// If we are the left side (i.e. "Fun") part of a call expression,
-		// we don't want a snippet since there are already parens present.
-		switch n := c.path[1].(type) {
-		case *ast.CallExpr:
-			// The Lparen != Rparen check detects fudged CallExprs we
-			// inserted when fixing the AST. In this case, we do still need
-			// to insert the calling "()" parens.
-			if n.Fun == c.path[0] && n.Lparen != n.Rparen {
-				return
-			}
-		case *ast.SelectorExpr:
-			if len(c.path) > 2 {
-				if call, ok := c.path[2].(*ast.CallExpr); ok && call.Fun == c.path[1] && call.Lparen != call.Rparen {
-					return
-				}
-			}
-		}
-	}
-
-	snip.WriteText(name)
-
-	if len(tparams) > 0 {
-		snip.WriteText("[")
-		if c.opts.placeholders {
-			for i, tp := range tparams {
-				if i > 0 {
-					snip.WriteText(", ")
-				}
-				snip.WritePlaceholder(func(b *snippet.Builder) {
-					b.WriteText(tp)
-				})
-			}
-		} else {
-			snip.WritePlaceholder(nil)
-		}
-		snip.WriteText("]")
-	}
-
-	snip.WriteText("(")
-
-	if c.opts.placeholders {
-		// A placeholder snippet turns "someFun<>" into "someFunc(<*i int*>, *s string*)".
-		for i, p := range params {
-			if i > 0 {
-				snip.WriteText(", ")
-			}
-			snip.WritePlaceholder(func(b *snippet.Builder) {
-				b.WriteText(p)
-			})
-		}
-	} else {
-		// A plain snippet turns "someFun<>" into "someFunc(<>)".
-		if len(params) > 0 {
-			snip.WritePlaceholder(nil)
-		}
-	}
-
-	snip.WriteText(")")
-}
diff -urN a/gopls/internal/lsp/source/completion/statements.go b/gopls/internal/lsp/source/completion/statements.go
--- a/gopls/internal/lsp/source/completion/statements.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/statements.go	1969-12-31 16:00:00
@@ -1,358 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/snippet"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-// addStatementCandidates adds full statement completion candidates
-// appropriate for the current context.
-func (c *completer) addStatementCandidates() {
-	c.addErrCheck()
-	c.addAssignAppend()
-}
-
-// addAssignAppend offers a completion candidate of the form:
-//
-//	someSlice = append(someSlice, )
-//
-// It will offer the "append" completion in either of two situations:
-//
-//  1. Position is in RHS of assign, prefix matches "append", and
-//     corresponding LHS object is a slice. For example,
-//     "foo = ap<>" completes to "foo = append(foo, )".
-//
-//  2. Prefix is an ident or selector in an *ast.ExprStmt (i.e.
-//     beginning of statement), and our best matching candidate is a
-//     slice. For example: "foo.ba" completes to "foo.bar = append(foo.bar, )".
-func (c *completer) addAssignAppend() {
-	if len(c.path) < 3 {
-		return
-	}
-
-	ident, _ := c.path[0].(*ast.Ident)
-	if ident == nil {
-		return
-	}
-
-	var (
-		// sliceText is the full name of our slice object, e.g. "s.abc" in
-		// "s.abc = app<>".
-		sliceText string
-		// needsLHS is true if we need to prepend the LHS slice name and
-		// "=" to our candidate.
-		needsLHS = false
-		fset     = c.pkg.FileSet()
-	)
-
-	switch n := c.path[1].(type) {
-	case *ast.AssignStmt:
-		// We are already in an assignment. Make sure our prefix matches "append".
-		if c.matcher.Score("append") <= 0 {
-			return
-		}
-
-		exprIdx := exprAtPos(c.pos, n.Rhs)
-		if exprIdx == len(n.Rhs) || exprIdx > len(n.Lhs)-1 {
-			return
-		}
-
-		lhsType := c.pkg.GetTypesInfo().TypeOf(n.Lhs[exprIdx])
-		if lhsType == nil {
-			return
-		}
-
-		// Make sure our corresponding LHS object is a slice.
-		if _, isSlice := lhsType.Underlying().(*types.Slice); !isSlice {
-			return
-		}
-
-		// The name or our slice is whatever's in the LHS expression.
-		sliceText = source.FormatNode(fset, n.Lhs[exprIdx])
-	case *ast.SelectorExpr:
-		// Make sure we are a selector at the beginning of a statement.
-		if _, parentIsExprtStmt := c.path[2].(*ast.ExprStmt); !parentIsExprtStmt {
-			return
-		}
-
-		// So far we only know the first part of our slice name. For
-		// example in "s.a<>" we only know our slice begins with "s."
-		// since the user could still be typing.
-		sliceText = source.FormatNode(fset, n.X) + "."
-		needsLHS = true
-	case *ast.ExprStmt:
-		needsLHS = true
-	default:
-		return
-	}
-
-	var (
-		label string
-		snip  snippet.Builder
-		score = highScore
-	)
-
-	if needsLHS {
-		// Offer the long form assign + append candidate if our best
-		// candidate is a slice.
-		bestItem := c.topCandidate()
-		if bestItem == nil || bestItem.obj == nil || bestItem.obj.Type() == nil {
-			return
-		}
-
-		if _, isSlice := bestItem.obj.Type().Underlying().(*types.Slice); !isSlice {
-			return
-		}
-
-		// Don't rank the full form assign + append candidate above the
-		// slice itself.
-		score = bestItem.Score - 0.01
-
-		// Fill in rest of sliceText now that we have the object name.
-		sliceText += bestItem.Label
-
-		// Fill in the candidate's LHS bits.
-		label = fmt.Sprintf("%s = ", bestItem.Label)
-		snip.WriteText(label)
-	}
-
-	snip.WriteText(fmt.Sprintf("append(%s, ", sliceText))
-	snip.WritePlaceholder(nil)
-	snip.WriteText(")")
-
-	c.items = append(c.items, CompletionItem{
-		Label:   label + fmt.Sprintf("append(%s, )", sliceText),
-		Kind:    protocol.FunctionCompletion,
-		Score:   score,
-		snippet: &snip,
-	})
-}
-
-// topCandidate returns the strictly highest scoring candidate
-// collected so far. If the top two candidates have the same score,
-// nil is returned.
-func (c *completer) topCandidate() *CompletionItem {
-	var bestItem, secondBestItem *CompletionItem
-	for i := range c.items {
-		if bestItem == nil || c.items[i].Score > bestItem.Score {
-			bestItem = &c.items[i]
-		} else if secondBestItem == nil || c.items[i].Score > secondBestItem.Score {
-			secondBestItem = &c.items[i]
-		}
-	}
-
-	// If secondBestItem has the same score, bestItem isn't
-	// the strict best.
-	if secondBestItem != nil && secondBestItem.Score == bestItem.Score {
-		return nil
-	}
-
-	return bestItem
-}
-
-// addErrCheck offers a completion candidate of the form:
-//
-//	if err != nil {
-//	  return nil, err
-//	}
-//
-// In the case of test functions, it offers a completion candidate of the form:
-//
-//	if err != nil {
-//	  t.Fatal(err)
-//	}
-//
-// The position must be in a function that returns an error, and the
-// statement preceding the position must be an assignment where the
-// final LHS object is an error. addErrCheck will synthesize
-// zero values as necessary to make the return statement valid.
-func (c *completer) addErrCheck() {
-	if len(c.path) < 2 || c.enclosingFunc == nil || !c.opts.placeholders {
-		return
-	}
-
-	var (
-		errorType        = types.Universe.Lookup("error").Type()
-		result           = c.enclosingFunc.sig.Results()
-		testVar          = getTestVar(c.enclosingFunc, c.pkg)
-		isTest           = testVar != ""
-		doesNotReturnErr = result.Len() == 0 || !types.Identical(result.At(result.Len()-1).Type(), errorType)
-	)
-	// Make sure our enclosing function is a Test func or returns an error.
-	if !isTest && doesNotReturnErr {
-		return
-	}
-
-	prevLine := prevStmt(c.pos, c.path)
-	if prevLine == nil {
-		return
-	}
-
-	// Make sure our preceding statement was as assignment.
-	assign, _ := prevLine.(*ast.AssignStmt)
-	if assign == nil || len(assign.Lhs) == 0 {
-		return
-	}
-
-	lastAssignee := assign.Lhs[len(assign.Lhs)-1]
-
-	// Make sure the final assignee is an error.
-	if !types.Identical(c.pkg.GetTypesInfo().TypeOf(lastAssignee), errorType) {
-		return
-	}
-
-	var (
-		// errVar is e.g. "err" in "foo, err := bar()".
-		errVar = source.FormatNode(c.pkg.FileSet(), lastAssignee)
-
-		// Whether we need to include the "if" keyword in our candidate.
-		needsIf = true
-	)
-
-	// If the returned error from the previous statement is "_", it is not a real object.
-	// If we don't have an error, and the function signature takes a testing.TB that is either ignored
-	// or an "_", then we also can't call t.Fatal(err).
-	if errVar == "_" {
-		return
-	}
-
-	// Below we try to detect if the user has already started typing "if
-	// err" so we can replace what they've typed with our complete
-	// statement.
-	switch n := c.path[0].(type) {
-	case *ast.Ident:
-		switch c.path[1].(type) {
-		case *ast.ExprStmt:
-			// This handles:
-			//
-			//     f, err := os.Open("foo")
-			//     i<>
-
-			// Make sure they are typing "if".
-			if c.matcher.Score("if") <= 0 {
-				return
-			}
-		case *ast.IfStmt:
-			// This handles:
-			//
-			//     f, err := os.Open("foo")
-			//     if er<>
-
-			// Make sure they are typing the error's name.
-			if c.matcher.Score(errVar) <= 0 {
-				return
-			}
-
-			needsIf = false
-		default:
-			return
-		}
-	case *ast.IfStmt:
-		// This handles:
-		//
-		//     f, err := os.Open("foo")
-		//     if <>
-
-		// Avoid false positives by ensuring the if's cond is a bad
-		// expression. For example, don't offer the completion in cases
-		// like "if <> somethingElse".
-		if _, bad := n.Cond.(*ast.BadExpr); !bad {
-			return
-		}
-
-		// If "if" is our direct prefix, we need to include it in our
-		// candidate since the existing "if" will be overwritten.
-		needsIf = c.pos == n.Pos()+token.Pos(len("if"))
-	}
-
-	// Build up a snippet that looks like:
-	//
-	//     if err != nil {
-	//       return <zero value>, ..., ${1:err}
-	//     }
-	//
-	// We make the error a placeholder so it is easy to alter the error.
-	var snip snippet.Builder
-	if needsIf {
-		snip.WriteText("if ")
-	}
-	snip.WriteText(fmt.Sprintf("%s != nil {\n\t", errVar))
-
-	var label string
-	if isTest {
-		snip.WriteText(fmt.Sprintf("%s.Fatal(%s)", testVar, errVar))
-		label = fmt.Sprintf("%[1]s != nil { %[2]s.Fatal(%[1]s) }", errVar, testVar)
-	} else {
-		snip.WriteText("return ")
-		for i := 0; i < result.Len()-1; i++ {
-			snip.WriteText(formatZeroValue(result.At(i).Type(), c.qf))
-			snip.WriteText(", ")
-		}
-		snip.WritePlaceholder(func(b *snippet.Builder) {
-			b.WriteText(errVar)
-		})
-		label = fmt.Sprintf("%[1]s != nil { return %[1]s }", errVar)
-	}
-
-	snip.WriteText("\n}")
-
-	if needsIf {
-		label = "if " + label
-	}
-
-	c.items = append(c.items, CompletionItem{
-		Label: label,
-		// There doesn't seem to be a more appropriate kind.
-		Kind:    protocol.KeywordCompletion,
-		Score:   highScore,
-		snippet: &snip,
-	})
-}
-
-// getTestVar checks the function signature's input parameters and returns
-// the name of the first parameter that implements "testing.TB". For example,
-// func someFunc(t *testing.T) returns the string "t", func someFunc(b *testing.B)
-// returns "b" etc. An empty string indicates that the function signature
-// does not take a testing.TB parameter or does so but is ignored such
-// as func someFunc(*testing.T).
-func getTestVar(enclosingFunc *funcInfo, pkg source.Package) string {
-	if enclosingFunc == nil || enclosingFunc.sig == nil {
-		return ""
-	}
-
-	sig := enclosingFunc.sig
-	for i := 0; i < sig.Params().Len(); i++ {
-		param := sig.Params().At(i)
-		if param.Name() == "_" {
-			continue
-		}
-		testingPkg, err := pkg.DirectDep("testing")
-		if err != nil {
-			continue
-		}
-		tbObj := testingPkg.GetTypes().Scope().Lookup("TB")
-		if tbObj == nil {
-			continue
-		}
-		iface, ok := tbObj.Type().Underlying().(*types.Interface)
-		if !ok {
-			continue
-		}
-		if !types.Implements(param.Type(), iface) {
-			continue
-		}
-		return param.Name()
-	}
-
-	return ""
-}
diff -urN a/gopls/internal/lsp/source/completion/util.go b/gopls/internal/lsp/source/completion/util.go
--- a/gopls/internal/lsp/source/completion/util.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/util.go	1969-12-31 16:00:00
@@ -1,348 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/go/types/typeutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// exprAtPos returns the index of the expression containing pos.
-func exprAtPos(pos token.Pos, args []ast.Expr) int {
-	for i, expr := range args {
-		if expr.Pos() <= pos && pos <= expr.End() {
-			return i
-		}
-	}
-	return len(args)
-}
-
-// eachField invokes fn for each field that can be selected from a
-// value of type T.
-func eachField(T types.Type, fn func(*types.Var)) {
-	// TODO(adonovan): this algorithm doesn't exclude ambiguous
-	// selections that match more than one field/method.
-	// types.NewSelectionSet should do that for us.
-
-	// for termination on recursive types
-	var seen typeutil.Map
-
-	var visit func(T types.Type)
-	visit = func(T types.Type) {
-		if T, ok := source.Deref(T).Underlying().(*types.Struct); ok {
-			if seen.At(T) != nil {
-				return
-			}
-
-			for i := 0; i < T.NumFields(); i++ {
-				f := T.Field(i)
-				fn(f)
-				if f.Anonymous() {
-					seen.Set(T, true)
-					visit(f.Type())
-				}
-			}
-		}
-	}
-	visit(T)
-}
-
-// typeIsValid reports whether typ doesn't contain any Invalid types.
-func typeIsValid(typ types.Type) bool {
-	// Check named types separately, because we don't want
-	// to call Underlying() on them to avoid problems with recursive types.
-	if _, ok := typ.(*types.Named); ok {
-		return true
-	}
-
-	switch typ := typ.Underlying().(type) {
-	case *types.Basic:
-		return typ.Kind() != types.Invalid
-	case *types.Array:
-		return typeIsValid(typ.Elem())
-	case *types.Slice:
-		return typeIsValid(typ.Elem())
-	case *types.Pointer:
-		return typeIsValid(typ.Elem())
-	case *types.Map:
-		return typeIsValid(typ.Key()) && typeIsValid(typ.Elem())
-	case *types.Chan:
-		return typeIsValid(typ.Elem())
-	case *types.Signature:
-		return typeIsValid(typ.Params()) && typeIsValid(typ.Results())
-	case *types.Tuple:
-		for i := 0; i < typ.Len(); i++ {
-			if !typeIsValid(typ.At(i).Type()) {
-				return false
-			}
-		}
-		return true
-	case *types.Struct, *types.Interface:
-		// Don't bother checking structs, interfaces for validity.
-		return true
-	default:
-		return false
-	}
-}
-
-// resolveInvalid traverses the node of the AST that defines the scope
-// containing the declaration of obj, and attempts to find a user-friendly
-// name for its invalid type. The resulting Object and its Type are fake.
-func resolveInvalid(fset *token.FileSet, obj types.Object, node ast.Node, info *types.Info) types.Object {
-	var resultExpr ast.Expr
-	ast.Inspect(node, func(node ast.Node) bool {
-		switch n := node.(type) {
-		case *ast.ValueSpec:
-			for _, name := range n.Names {
-				if info.Defs[name] == obj {
-					resultExpr = n.Type
-				}
-			}
-			return false
-		case *ast.Field: // This case handles parameters and results of a FuncDecl or FuncLit.
-			for _, name := range n.Names {
-				if info.Defs[name] == obj {
-					resultExpr = n.Type
-				}
-			}
-			return false
-		default:
-			return true
-		}
-	})
-	// Construct a fake type for the object and return a fake object with this type.
-	typename := source.FormatNode(fset, resultExpr)
-	typ := types.NewNamed(types.NewTypeName(token.NoPos, obj.Pkg(), typename, nil), types.Typ[types.Invalid], nil)
-	return types.NewVar(obj.Pos(), obj.Pkg(), obj.Name(), typ)
-}
-
-func isPointer(T types.Type) bool {
-	_, ok := T.(*types.Pointer)
-	return ok
-}
-
-func isVar(obj types.Object) bool {
-	_, ok := obj.(*types.Var)
-	return ok
-}
-
-func isTypeName(obj types.Object) bool {
-	_, ok := obj.(*types.TypeName)
-	return ok
-}
-
-func isFunc(obj types.Object) bool {
-	_, ok := obj.(*types.Func)
-	return ok
-}
-
-func isEmptyInterface(T types.Type) bool {
-	intf, _ := T.(*types.Interface)
-	return intf != nil && intf.NumMethods() == 0 && typeparams.IsMethodSet(intf)
-}
-
-func isUntyped(T types.Type) bool {
-	if basic, ok := T.(*types.Basic); ok {
-		return basic.Info()&types.IsUntyped > 0
-	}
-	return false
-}
-
-func isPkgName(obj types.Object) bool {
-	_, ok := obj.(*types.PkgName)
-	return ok
-}
-
-func isASTFile(n ast.Node) bool {
-	_, ok := n.(*ast.File)
-	return ok
-}
-
-func deslice(T types.Type) types.Type {
-	if slice, ok := T.Underlying().(*types.Slice); ok {
-		return slice.Elem()
-	}
-	return nil
-}
-
-// isSelector returns the enclosing *ast.SelectorExpr when pos is in the
-// selector.
-func enclosingSelector(path []ast.Node, pos token.Pos) *ast.SelectorExpr {
-	if len(path) == 0 {
-		return nil
-	}
-
-	if sel, ok := path[0].(*ast.SelectorExpr); ok {
-		return sel
-	}
-
-	if _, ok := path[0].(*ast.Ident); ok && len(path) > 1 {
-		if sel, ok := path[1].(*ast.SelectorExpr); ok && pos >= sel.Sel.Pos() {
-			return sel
-		}
-	}
-
-	return nil
-}
-
-// enclosingDeclLHS returns LHS idents from containing value spec or
-// assign statement.
-func enclosingDeclLHS(path []ast.Node) []*ast.Ident {
-	for _, n := range path {
-		switch n := n.(type) {
-		case *ast.ValueSpec:
-			return n.Names
-		case *ast.AssignStmt:
-			ids := make([]*ast.Ident, 0, len(n.Lhs))
-			for _, e := range n.Lhs {
-				if id, ok := e.(*ast.Ident); ok {
-					ids = append(ids, id)
-				}
-			}
-			return ids
-		}
-	}
-
-	return nil
-}
-
-// exprObj returns the types.Object associated with the *ast.Ident or
-// *ast.SelectorExpr e.
-func exprObj(info *types.Info, e ast.Expr) types.Object {
-	var ident *ast.Ident
-	switch expr := e.(type) {
-	case *ast.Ident:
-		ident = expr
-	case *ast.SelectorExpr:
-		ident = expr.Sel
-	default:
-		return nil
-	}
-
-	return info.ObjectOf(ident)
-}
-
-// typeConversion returns the type being converted to if call is a type
-// conversion expression.
-func typeConversion(call *ast.CallExpr, info *types.Info) types.Type {
-	// Type conversion (e.g. "float64(foo)").
-	if fun, _ := exprObj(info, call.Fun).(*types.TypeName); fun != nil {
-		return fun.Type()
-	}
-
-	return nil
-}
-
-// fieldsAccessible returns whether s has at least one field accessible by p.
-func fieldsAccessible(s *types.Struct, p *types.Package) bool {
-	for i := 0; i < s.NumFields(); i++ {
-		f := s.Field(i)
-		if f.Exported() || f.Pkg() == p {
-			return true
-		}
-	}
-	return false
-}
-
-// prevStmt returns the statement that precedes the statement containing pos.
-// For example:
-//
-//	foo := 1
-//	bar(1 + 2<>)
-//
-// If "<>" is pos, prevStmt returns "foo := 1"
-func prevStmt(pos token.Pos, path []ast.Node) ast.Stmt {
-	var blockLines []ast.Stmt
-	for i := 0; i < len(path) && blockLines == nil; i++ {
-		switch n := path[i].(type) {
-		case *ast.BlockStmt:
-			blockLines = n.List
-		case *ast.CommClause:
-			blockLines = n.Body
-		case *ast.CaseClause:
-			blockLines = n.Body
-		}
-	}
-
-	for i := len(blockLines) - 1; i >= 0; i-- {
-		if blockLines[i].End() < pos {
-			return blockLines[i]
-		}
-	}
-
-	return nil
-}
-
-// formatZeroValue produces Go code representing the zero value of T. It
-// returns the empty string if T is invalid.
-func formatZeroValue(T types.Type, qf types.Qualifier) string {
-	switch u := T.Underlying().(type) {
-	case *types.Basic:
-		switch {
-		case u.Info()&types.IsNumeric > 0:
-			return "0"
-		case u.Info()&types.IsString > 0:
-			return `""`
-		case u.Info()&types.IsBoolean > 0:
-			return "false"
-		default:
-			return ""
-		}
-	case *types.Pointer, *types.Interface, *types.Chan, *types.Map, *types.Slice, *types.Signature:
-		return "nil"
-	default:
-		return types.TypeString(T, qf) + "{}"
-	}
-}
-
-// isBasicKind returns whether t is a basic type of kind k.
-func isBasicKind(t types.Type, k types.BasicInfo) bool {
-	b, _ := t.Underlying().(*types.Basic)
-	return b != nil && b.Info()&k > 0
-}
-
-func (c *completer) editText(from, to token.Pos, newText string) ([]protocol.TextEdit, error) {
-	start, err := safetoken.Offset(c.tokFile, from)
-	if err != nil {
-		return nil, err // can't happen: from came from c
-	}
-	end, err := safetoken.Offset(c.tokFile, to)
-	if err != nil {
-		return nil, err // can't happen: to came from c
-	}
-	return source.ToProtocolEdits(c.mapper, []diff.Edit{{
-		Start: start,
-		End:   end,
-		New:   newText,
-	}})
-}
-
-// assignableTo is like types.AssignableTo, but returns false if
-// either type is invalid.
-func assignableTo(x, to types.Type) bool {
-	if x == types.Typ[types.Invalid] || to == types.Typ[types.Invalid] {
-		return false
-	}
-
-	return types.AssignableTo(x, to)
-}
-
-// convertibleTo is like types.ConvertibleTo, but returns false if
-// either type is invalid.
-func convertibleTo(x, to types.Type) bool {
-	if x == types.Typ[types.Invalid] || to == types.Typ[types.Invalid] {
-		return false
-	}
-
-	return types.ConvertibleTo(x, to)
-}
diff -urN a/gopls/internal/lsp/source/completion/util_test.go b/gopls/internal/lsp/source/completion/util_test.go
--- a/gopls/internal/lsp/source/completion/util_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/completion/util_test.go	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"go/types"
-	"testing"
-)
-
-func TestFormatZeroValue(t *testing.T) {
-	tests := []struct {
-		typ  types.Type
-		want string
-	}{
-		{types.Typ[types.String], `""`},
-		{types.Typ[types.Byte], "0"},
-		{types.Typ[types.Invalid], ""},
-		{types.Universe.Lookup("error").Type(), "nil"},
-	}
-
-	for _, test := range tests {
-		if got := formatZeroValue(test.typ, nil); got != test.want {
-			t.Errorf("formatZeroValue(%v) = %q, want %q", test.typ, got, test.want)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/source/diagnostics.go b/gopls/internal/lsp/source/diagnostics.go
--- a/gopls/internal/lsp/source/diagnostics.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/diagnostics.go	1969-12-31 16:00:00
@@ -1,141 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-type SuggestedFix struct {
-	Title      string
-	Edits      map[span.URI][]protocol.TextEdit
-	Command    *protocol.Command
-	ActionKind protocol.CodeActionKind
-}
-
-type RelatedInformation struct {
-	URI     span.URI
-	Range   protocol.Range
-	Message string
-}
-
-// Analyze reports go/analysis-framework diagnostics in the specified package.
-func Analyze(ctx context.Context, snapshot Snapshot, pkgid PackageID, includeConvenience bool) (map[span.URI][]*Diagnostic, error) {
-	// Exit early if the context has been canceled. This also protects us
-	// from a race on Options, see golang/go#36699.
-	if ctx.Err() != nil {
-		return nil, ctx.Err()
-	}
-
-	options := snapshot.View().Options()
-	categories := []map[string]*Analyzer{
-		options.DefaultAnalyzers,
-		options.StaticcheckAnalyzers,
-		options.TypeErrorAnalyzers,
-	}
-	if includeConvenience { // e.g. for codeAction
-		categories = append(categories, options.ConvenienceAnalyzers) // e.g. fillstruct
-	}
-
-	var analyzers []*Analyzer
-	for _, cat := range categories {
-		for _, a := range cat {
-			analyzers = append(analyzers, a)
-		}
-	}
-
-	analysisDiagnostics, err := snapshot.Analyze(ctx, pkgid, analyzers)
-	if err != nil {
-		return nil, err
-	}
-
-	// Report diagnostics and errors from root analyzers.
-	reports := make(map[span.URI][]*Diagnostic)
-	for _, diag := range analysisDiagnostics {
-		reports[diag.URI] = append(reports[diag.URI], diag)
-	}
-	return reports, nil
-}
-
-// FileDiagnostics reports diagnostics in the specified file,
-// as used by the "gopls check" command.
-//
-// TODO(adonovan): factor in common with (*Server).codeAction, which
-// executes { PackageForFile; Analyze } too?
-//
-// TODO(adonovan): opt: this function is called in a loop from the
-// "gopls/diagnoseFiles" nonstandard request handler. It would be more
-// efficient to compute the set of packages and TypeCheck and
-// Analyze them all at once.
-func FileDiagnostics(ctx context.Context, snapshot Snapshot, uri span.URI) (VersionedFileIdentity, []*Diagnostic, error) {
-	fh, err := snapshot.GetVersionedFile(ctx, uri)
-	if err != nil {
-		return VersionedFileIdentity{}, nil, err
-	}
-	pkg, _, err := PackageForFile(ctx, snapshot, uri, TypecheckFull, NarrowestPackage)
-	if err != nil {
-		return VersionedFileIdentity{}, nil, err
-	}
-	adiags, err := Analyze(ctx, snapshot, pkg.ID(), false)
-	if err != nil {
-		return VersionedFileIdentity{}, nil, err
-	}
-	var fileDiags []*Diagnostic // combine load/parse/type + analysis diagnostics
-	CombineDiagnostics(pkg, fh.URI(), adiags, &fileDiags, &fileDiags)
-	return fh.VersionedFileIdentity(), fileDiags, nil
-}
-
-// CombineDiagnostics combines and filters list/parse/type diagnostics
-// from pkg.DiagnosticsForFile(uri) with analysisDiagnostics[uri], and
-// appends the two lists to *outT and *outA, respectively.
-//
-// Type-error analyzers produce diagnostics that are redundant
-// with type checker diagnostics, but more detailed (e.g. fixes).
-// Rather than report two diagnostics for the same problem,
-// we combine them by augmenting the type-checker diagnostic
-// and discarding the analyzer diagnostic.
-//
-// If an analysis diagnostic has the same range and message as
-// a list/parse/type diagnostic, the suggested fix information
-// (et al) of the latter is merged into a copy of the former.
-// This handles the case where a type-error analyzer suggests
-// a fix to a type error, and avoids duplication.
-//
-// The use of out-slices, though irregular, allows the caller to
-// easily choose whether to keep the results separate or combined.
-//
-// The arguments are not modified.
-func CombineDiagnostics(pkg Package, uri span.URI, analysisDiagnostics map[span.URI][]*Diagnostic, outT, outA *[]*Diagnostic) {
-
-	// Build index of (list+parse+)type errors.
-	type key struct {
-		Range   protocol.Range
-		message string
-	}
-	index := make(map[key]int) // maps (Range,Message) to index in tdiags slice
-	tdiags := pkg.DiagnosticsForFile(uri)
-	for i, diag := range tdiags {
-		index[key{diag.Range, diag.Message}] = i
-	}
-
-	// Filter out analysis diagnostics that match type errors,
-	// retaining their suggested fix (etc) fields.
-	for _, diag := range analysisDiagnostics[uri] {
-		if i, ok := index[key{diag.Range, diag.Message}]; ok {
-			copy := *tdiags[i]
-			copy.SuggestedFixes = diag.SuggestedFixes
-			copy.Tags = diag.Tags
-			tdiags[i] = &copy
-			continue
-		}
-
-		*outA = append(*outA, diag)
-	}
-
-	*outT = append(*outT, tdiags...)
-}
diff -urN a/gopls/internal/lsp/source/extract.go b/gopls/internal/lsp/source/extract.go
--- a/gopls/internal/lsp/source/extract.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/extract.go	1969-12-31 16:00:00
@@ -1,1343 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"bytes"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"sort"
-	"strings"
-	"text/scanner"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/analysisinternal"
-	"golang.org/x/tools/internal/bug"
-)
-
-func extractVariable(fset *token.FileSet, rng span.Range, src []byte, file *ast.File, _ *types.Package, info *types.Info) (*analysis.SuggestedFix, error) {
-	tokFile := fset.File(file.Pos())
-	expr, path, ok, err := CanExtractVariable(rng, file)
-	if !ok {
-		return nil, fmt.Errorf("extractVariable: cannot extract %s: %v", safetoken.StartPosition(fset, rng.Start), err)
-	}
-
-	// Create new AST node for extracted code.
-	var lhsNames []string
-	switch expr := expr.(type) {
-	// TODO: stricter rules for selectorExpr.
-	case *ast.BasicLit, *ast.CompositeLit, *ast.IndexExpr, *ast.SliceExpr,
-		*ast.UnaryExpr, *ast.BinaryExpr, *ast.SelectorExpr:
-		lhsName, _ := generateAvailableIdentifier(expr.Pos(), file, path, info, "x", 0)
-		lhsNames = append(lhsNames, lhsName)
-	case *ast.CallExpr:
-		tup, ok := info.TypeOf(expr).(*types.Tuple)
-		if !ok {
-			// If the call expression only has one return value, we can treat it the
-			// same as our standard extract variable case.
-			lhsName, _ := generateAvailableIdentifier(expr.Pos(), file, path, info, "x", 0)
-			lhsNames = append(lhsNames, lhsName)
-			break
-		}
-		idx := 0
-		for i := 0; i < tup.Len(); i++ {
-			// Generate a unique variable for each return value.
-			var lhsName string
-			lhsName, idx = generateAvailableIdentifier(expr.Pos(), file, path, info, "x", idx)
-			lhsNames = append(lhsNames, lhsName)
-		}
-	default:
-		return nil, fmt.Errorf("cannot extract %T", expr)
-	}
-
-	insertBeforeStmt := analysisinternal.StmtToInsertVarBefore(path)
-	if insertBeforeStmt == nil {
-		return nil, fmt.Errorf("cannot find location to insert extraction")
-	}
-	indent, err := calculateIndentation(src, tokFile, insertBeforeStmt)
-	if err != nil {
-		return nil, err
-	}
-	newLineIndent := "\n" + indent
-
-	lhs := strings.Join(lhsNames, ", ")
-	assignStmt := &ast.AssignStmt{
-		Lhs: []ast.Expr{ast.NewIdent(lhs)},
-		Tok: token.DEFINE,
-		Rhs: []ast.Expr{expr},
-	}
-	var buf bytes.Buffer
-	if err := format.Node(&buf, fset, assignStmt); err != nil {
-		return nil, err
-	}
-	assignment := strings.ReplaceAll(buf.String(), "\n", newLineIndent) + newLineIndent
-
-	return &analysis.SuggestedFix{
-		TextEdits: []analysis.TextEdit{
-			{
-				Pos:     insertBeforeStmt.Pos(),
-				End:     insertBeforeStmt.Pos(),
-				NewText: []byte(assignment),
-			},
-			{
-				Pos:     rng.Start,
-				End:     rng.End,
-				NewText: []byte(lhs),
-			},
-		},
-	}, nil
-}
-
-// CanExtractVariable reports whether the code in the given range can be
-// extracted to a variable.
-func CanExtractVariable(rng span.Range, file *ast.File) (ast.Expr, []ast.Node, bool, error) {
-	if rng.Start == rng.End {
-		return nil, nil, false, fmt.Errorf("start and end are equal")
-	}
-	path, _ := astutil.PathEnclosingInterval(file, rng.Start, rng.End)
-	if len(path) == 0 {
-		return nil, nil, false, fmt.Errorf("no path enclosing interval")
-	}
-	for _, n := range path {
-		if _, ok := n.(*ast.ImportSpec); ok {
-			return nil, nil, false, fmt.Errorf("cannot extract variable in an import block")
-		}
-	}
-	node := path[0]
-	if rng.Start != node.Pos() || rng.End != node.End() {
-		return nil, nil, false, fmt.Errorf("range does not map to an AST node")
-	}
-	expr, ok := node.(ast.Expr)
-	if !ok {
-		return nil, nil, false, fmt.Errorf("node is not an expression")
-	}
-	switch expr.(type) {
-	case *ast.BasicLit, *ast.CompositeLit, *ast.IndexExpr, *ast.CallExpr,
-		*ast.SliceExpr, *ast.UnaryExpr, *ast.BinaryExpr, *ast.SelectorExpr:
-		return expr, path, true, nil
-	}
-	return nil, nil, false, fmt.Errorf("cannot extract an %T to a variable", expr)
-}
-
-// Calculate indentation for insertion.
-// When inserting lines of code, we must ensure that the lines have consistent
-// formatting (i.e. the proper indentation). To do so, we observe the indentation on the
-// line of code on which the insertion occurs.
-func calculateIndentation(content []byte, tok *token.File, insertBeforeStmt ast.Node) (string, error) {
-	line := tok.Line(insertBeforeStmt.Pos())
-	lineOffset, err := safetoken.Offset(tok, tok.LineStart(line))
-	if err != nil {
-		return "", err
-	}
-	stmtOffset, err := safetoken.Offset(tok, insertBeforeStmt.Pos())
-	if err != nil {
-		return "", err
-	}
-	return string(content[lineOffset:stmtOffset]), nil
-}
-
-// generateAvailableIdentifier adjusts the new function name until there are no collisions in scope.
-// Possible collisions include other function and variable names. Returns the next index to check for prefix.
-func generateAvailableIdentifier(pos token.Pos, file *ast.File, path []ast.Node, info *types.Info, prefix string, idx int) (string, int) {
-	scopes := CollectScopes(info, path, pos)
-	return generateIdentifier(idx, prefix, func(name string) bool {
-		return file.Scope.Lookup(name) != nil || !isValidName(name, scopes)
-	})
-}
-
-func generateIdentifier(idx int, prefix string, hasCollision func(string) bool) (string, int) {
-	name := prefix
-	if idx != 0 {
-		name += fmt.Sprintf("%d", idx)
-	}
-	for hasCollision(name) {
-		idx++
-		name = fmt.Sprintf("%v%d", prefix, idx)
-	}
-	return name, idx + 1
-}
-
-// isValidName checks for variable collision in scope.
-func isValidName(name string, scopes []*types.Scope) bool {
-	for _, scope := range scopes {
-		if scope == nil {
-			continue
-		}
-		if scope.Lookup(name) != nil {
-			return false
-		}
-	}
-	return true
-}
-
-// returnVariable keeps track of the information we need to properly introduce a new variable
-// that we will return in the extracted function.
-type returnVariable struct {
-	// name is the identifier that is used on the left-hand side of the call to
-	// the extracted function.
-	name ast.Expr
-	// decl is the declaration of the variable. It is used in the type signature of the
-	// extracted function and for variable declarations.
-	decl *ast.Field
-	// zeroVal is the "zero value" of the type of the variable. It is used in a return
-	// statement in the extracted function.
-	zeroVal ast.Expr
-}
-
-// extractMethod refactors the selected block of code into a new method.
-func extractMethod(fset *token.FileSet, rng span.Range, src []byte, file *ast.File, pkg *types.Package, info *types.Info) (*analysis.SuggestedFix, error) {
-	return extractFunctionMethod(fset, rng, src, file, pkg, info, true)
-}
-
-// extractFunction refactors the selected block of code into a new function.
-func extractFunction(fset *token.FileSet, rng span.Range, src []byte, file *ast.File, pkg *types.Package, info *types.Info) (*analysis.SuggestedFix, error) {
-	return extractFunctionMethod(fset, rng, src, file, pkg, info, false)
-}
-
-// extractFunctionMethod refactors the selected block of code into a new function/method.
-// It also replaces the selected block of code with a call to the extracted
-// function. First, we manually adjust the selection range. We remove trailing
-// and leading whitespace characters to ensure the range is precisely bounded
-// by AST nodes. Next, we determine the variables that will be the parameters
-// and return values of the extracted function/method. Lastly, we construct the call
-// of the function/method and insert this call as well as the extracted function/method into
-// their proper locations.
-func extractFunctionMethod(fset *token.FileSet, rng span.Range, src []byte, file *ast.File, pkg *types.Package, info *types.Info, isMethod bool) (*analysis.SuggestedFix, error) {
-	errorPrefix := "extractFunction"
-	if isMethod {
-		errorPrefix = "extractMethod"
-	}
-
-	tok := fset.File(file.Pos())
-	if tok == nil {
-		return nil, bug.Errorf("no file for position")
-	}
-	p, ok, methodOk, err := CanExtractFunction(tok, rng, src, file)
-	if (!ok && !isMethod) || (!methodOk && isMethod) {
-		return nil, fmt.Errorf("%s: cannot extract %s: %v", errorPrefix,
-			safetoken.StartPosition(fset, rng.Start), err)
-	}
-	tok, path, rng, outer, start := p.tok, p.path, p.rng, p.outer, p.start
-	fileScope := info.Scopes[file]
-	if fileScope == nil {
-		return nil, fmt.Errorf("%s: file scope is empty", errorPrefix)
-	}
-	pkgScope := fileScope.Parent()
-	if pkgScope == nil {
-		return nil, fmt.Errorf("%s: package scope is empty", errorPrefix)
-	}
-
-	// A return statement is non-nested if its parent node is equal to the parent node
-	// of the first node in the selection. These cases must be handled separately because
-	// non-nested return statements are guaranteed to execute.
-	var retStmts []*ast.ReturnStmt
-	var hasNonNestedReturn bool
-	startParent := findParent(outer, start)
-	ast.Inspect(outer, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		if n.Pos() < rng.Start || n.End() > rng.End {
-			return n.Pos() <= rng.End
-		}
-		ret, ok := n.(*ast.ReturnStmt)
-		if !ok {
-			return true
-		}
-		if findParent(outer, n) == startParent {
-			hasNonNestedReturn = true
-		}
-		retStmts = append(retStmts, ret)
-		return false
-	})
-	containsReturnStatement := len(retStmts) > 0
-
-	// Now that we have determined the correct range for the selection block,
-	// we must determine the signature of the extracted function. We will then replace
-	// the block with an assignment statement that calls the extracted function with
-	// the appropriate parameters and return values.
-	variables, err := collectFreeVars(info, file, fileScope, pkgScope, rng, path[0])
-	if err != nil {
-		return nil, err
-	}
-
-	var (
-		receiverUsed bool
-		receiver     *ast.Field
-		receiverName string
-		receiverObj  types.Object
-	)
-	if isMethod {
-		if outer == nil || outer.Recv == nil || len(outer.Recv.List) == 0 {
-			return nil, fmt.Errorf("%s: cannot extract need method receiver", errorPrefix)
-		}
-		receiver = outer.Recv.List[0]
-		if len(receiver.Names) == 0 || receiver.Names[0] == nil {
-			return nil, fmt.Errorf("%s: cannot extract need method receiver name", errorPrefix)
-		}
-		recvName := receiver.Names[0]
-		receiverName = recvName.Name
-		receiverObj = info.ObjectOf(recvName)
-	}
-
-	var (
-		params, returns         []ast.Expr     // used when calling the extracted function
-		paramTypes, returnTypes []*ast.Field   // used in the signature of the extracted function
-		uninitialized           []types.Object // vars we will need to initialize before the call
-	)
-
-	// Avoid duplicates while traversing vars and uninitialized.
-	seenVars := make(map[types.Object]ast.Expr)
-	seenUninitialized := make(map[types.Object]struct{})
-
-	// Some variables on the left-hand side of our assignment statement may be free. If our
-	// selection begins in the same scope in which the free variable is defined, we can
-	// redefine it in our assignment statement. See the following example, where 'b' and
-	// 'err' (both free variables) can be redefined in the second funcCall() while maintaining
-	// correctness.
-	//
-	//
-	// Not Redefined:
-	//
-	// a, err := funcCall()
-	// var b int
-	// b, err = funcCall()
-	//
-	// Redefined:
-	//
-	// a, err := funcCall()
-	// b, err := funcCall()
-	//
-	// We track the number of free variables that can be redefined to maintain our preference
-	// of using "x, y, z := fn()" style assignment statements.
-	var canRedefineCount int
-
-	// Each identifier in the selected block must become (1) a parameter to the
-	// extracted function, (2) a return value of the extracted function, or (3) a local
-	// variable in the extracted function. Determine the outcome(s) for each variable
-	// based on whether it is free, altered within the selected block, and used outside
-	// of the selected block.
-	for _, v := range variables {
-		if _, ok := seenVars[v.obj]; ok {
-			continue
-		}
-		if v.obj.Name() == "_" {
-			// The blank identifier is always a local variable
-			continue
-		}
-		typ := analysisinternal.TypeExpr(file, pkg, v.obj.Type())
-		if typ == nil {
-			return nil, fmt.Errorf("nil AST expression for type: %v", v.obj.Name())
-		}
-		seenVars[v.obj] = typ
-		identifier := ast.NewIdent(v.obj.Name())
-		// An identifier must meet three conditions to become a return value of the
-		// extracted function. (1) its value must be defined or reassigned within
-		// the selection (isAssigned), (2) it must be used at least once after the
-		// selection (isUsed), and (3) its first use after the selection
-		// cannot be its own reassignment or redefinition (objOverriden).
-		if v.obj.Parent() == nil {
-			return nil, fmt.Errorf("parent nil")
-		}
-		isUsed, firstUseAfter := objUsed(info, span.NewRange(tok, rng.End, v.obj.Parent().End()), v.obj)
-		if v.assigned && isUsed && !varOverridden(info, firstUseAfter, v.obj, v.free, outer) {
-			returnTypes = append(returnTypes, &ast.Field{Type: typ})
-			returns = append(returns, identifier)
-			if !v.free {
-				uninitialized = append(uninitialized, v.obj)
-			} else if v.obj.Parent().Pos() == startParent.Pos() {
-				canRedefineCount++
-			}
-		}
-		// An identifier must meet two conditions to become a parameter of the
-		// extracted function. (1) it must be free (isFree), and (2) its first
-		// use within the selection cannot be its own definition (isDefined).
-		if v.free && !v.defined {
-			// Skip the selector for a method.
-			if isMethod && v.obj == receiverObj {
-				receiverUsed = true
-				continue
-			}
-			params = append(params, identifier)
-			paramTypes = append(paramTypes, &ast.Field{
-				Names: []*ast.Ident{identifier},
-				Type:  typ,
-			})
-		}
-	}
-
-	// Find the function literal that encloses the selection. The enclosing function literal
-	// may not be the enclosing function declaration (i.e. 'outer'). For example, in the
-	// following block:
-	//
-	// func main() {
-	//     ast.Inspect(node, func(n ast.Node) bool {
-	//         v := 1 // this line extracted
-	//         return true
-	//     })
-	// }
-	//
-	// 'outer' is main(). However, the extracted selection most directly belongs to
-	// the anonymous function literal, the second argument of ast.Inspect(). We use the
-	// enclosing function literal to determine the proper return types for return statements
-	// within the selection. We still need the enclosing function declaration because this is
-	// the top-level declaration. We inspect the top-level declaration to look for variables
-	// as well as for code replacement.
-	enclosing := outer.Type
-	for _, p := range path {
-		if p == enclosing {
-			break
-		}
-		if fl, ok := p.(*ast.FuncLit); ok {
-			enclosing = fl.Type
-			break
-		}
-	}
-
-	// We put the selection in a constructed file. We can then traverse and edit
-	// the extracted selection without modifying the original AST.
-	startOffset, err := safetoken.Offset(tok, rng.Start)
-	if err != nil {
-		return nil, err
-	}
-	endOffset, err := safetoken.Offset(tok, rng.End)
-	if err != nil {
-		return nil, err
-	}
-	selection := src[startOffset:endOffset]
-	extractedBlock, err := parseBlockStmt(fset, selection)
-	if err != nil {
-		return nil, err
-	}
-
-	// We need to account for return statements in the selected block, as they will complicate
-	// the logical flow of the extracted function. See the following example, where ** denotes
-	// the range to be extracted.
-	//
-	// Before:
-	//
-	// func _() int {
-	//     a := 1
-	//     b := 2
-	//     **if a == b {
-	//         return a
-	//     }**
-	//     ...
-	// }
-	//
-	// After:
-	//
-	// func _() int {
-	//     a := 1
-	//     b := 2
-	//     cond0, ret0 := x0(a, b)
-	//     if cond0 {
-	//         return ret0
-	//     }
-	//     ...
-	// }
-	//
-	// func x0(a int, b int) (bool, int) {
-	//     if a == b {
-	//         return true, a
-	//     }
-	//     return false, 0
-	// }
-	//
-	// We handle returns by adding an additional boolean return value to the extracted function.
-	// This bool reports whether the original function would have returned. Because the
-	// extracted selection contains a return statement, we must also add the types in the
-	// return signature of the enclosing function to the return signature of the
-	// extracted function. We then add an extra if statement checking this boolean value
-	// in the original function. If the condition is met, the original function should
-	// return a value, mimicking the functionality of the original return statement(s)
-	// in the selection.
-	//
-	// If there is a return that is guaranteed to execute (hasNonNestedReturns=true), then
-	// we don't need to include this additional condition check and can simply return.
-	//
-	// Before:
-	//
-	// func _() int {
-	//     a := 1
-	//     b := 2
-	//     **if a == b {
-	//         return a
-	//     }
-	//	   return b**
-	// }
-	//
-	// After:
-	//
-	// func _() int {
-	//     a := 1
-	//     b := 2
-	//     return x0(a, b)
-	// }
-	//
-	// func x0(a int, b int) int {
-	//     if a == b {
-	//         return a
-	//     }
-	//     return b
-	// }
-
-	var retVars []*returnVariable
-	var ifReturn *ast.IfStmt
-	if containsReturnStatement {
-		if !hasNonNestedReturn {
-			// The selected block contained return statements, so we have to modify the
-			// signature of the extracted function as described above. Adjust all of
-			// the return statements in the extracted function to reflect this change in
-			// signature.
-			if err := adjustReturnStatements(returnTypes, seenVars, fset, file,
-				pkg, extractedBlock); err != nil {
-				return nil, err
-			}
-		}
-		// Collect the additional return values and types needed to accommodate return
-		// statements in the selection. Update the type signature of the extracted
-		// function and construct the if statement that will be inserted in the enclosing
-		// function.
-		retVars, ifReturn, err = generateReturnInfo(enclosing, pkg, path, file, info, fset, rng.Start, hasNonNestedReturn)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	// Add a return statement to the end of the new function. This return statement must include
-	// the values for the types of the original extracted function signature and (if a return
-	// statement is present in the selection) enclosing function signature.
-	// This only needs to be done if the selections does not have a non-nested return, otherwise
-	// it already terminates with a return statement.
-	hasReturnValues := len(returns)+len(retVars) > 0
-	if hasReturnValues && !hasNonNestedReturn {
-		extractedBlock.List = append(extractedBlock.List, &ast.ReturnStmt{
-			Results: append(returns, getZeroVals(retVars)...),
-		})
-	}
-
-	// Construct the appropriate call to the extracted function.
-	// We must meet two conditions to use ":=" instead of '='. (1) there must be at least
-	// one variable on the lhs that is uninitialized (non-free) prior to the assignment.
-	// (2) all of the initialized (free) variables on the lhs must be able to be redefined.
-	sym := token.ASSIGN
-	canDefineCount := len(uninitialized) + canRedefineCount
-	canDefine := len(uninitialized)+len(retVars) > 0 && canDefineCount == len(returns)
-	if canDefine {
-		sym = token.DEFINE
-	}
-	var name, funName string
-	if isMethod {
-		name = "newMethod"
-		// TODO(suzmue): generate a name that does not conflict for "newMethod".
-		funName = name
-	} else {
-		name = "newFunction"
-		funName, _ = generateAvailableIdentifier(rng.Start, file, path, info, name, 0)
-	}
-	extractedFunCall := generateFuncCall(hasNonNestedReturn, hasReturnValues, params,
-		append(returns, getNames(retVars)...), funName, sym, receiverName)
-
-	// Build the extracted function.
-	newFunc := &ast.FuncDecl{
-		Name: ast.NewIdent(funName),
-		Type: &ast.FuncType{
-			Params:  &ast.FieldList{List: paramTypes},
-			Results: &ast.FieldList{List: append(returnTypes, getDecls(retVars)...)},
-		},
-		Body: extractedBlock,
-	}
-	if isMethod {
-		var names []*ast.Ident
-		if receiverUsed {
-			names = append(names, ast.NewIdent(receiverName))
-		}
-		newFunc.Recv = &ast.FieldList{
-			List: []*ast.Field{{
-				Names: names,
-				Type:  receiver.Type,
-			}},
-		}
-	}
-
-	// Create variable declarations for any identifiers that need to be initialized prior to
-	// calling the extracted function. We do not manually initialize variables if every return
-	// value is uninitialized. We can use := to initialize the variables in this situation.
-	var declarations []ast.Stmt
-	if canDefineCount != len(returns) {
-		declarations = initializeVars(uninitialized, retVars, seenUninitialized, seenVars)
-	}
-
-	var declBuf, replaceBuf, newFuncBuf, ifBuf, commentBuf bytes.Buffer
-	if err := format.Node(&declBuf, fset, declarations); err != nil {
-		return nil, err
-	}
-	if err := format.Node(&replaceBuf, fset, extractedFunCall); err != nil {
-		return nil, err
-	}
-	if ifReturn != nil {
-		if err := format.Node(&ifBuf, fset, ifReturn); err != nil {
-			return nil, err
-		}
-	}
-	if err := format.Node(&newFuncBuf, fset, newFunc); err != nil {
-		return nil, err
-	}
-	// Find all the comments within the range and print them to be put somewhere.
-	// TODO(suzmue): print these in the extracted function at the correct place.
-	for _, cg := range file.Comments {
-		if cg.Pos().IsValid() && cg.Pos() < rng.End && cg.Pos() >= rng.Start {
-			for _, c := range cg.List {
-				fmt.Fprintln(&commentBuf, c.Text)
-			}
-		}
-	}
-
-	// We're going to replace the whole enclosing function,
-	// so preserve the text before and after the selected block.
-	outerStart, err := safetoken.Offset(tok, outer.Pos())
-	if err != nil {
-		return nil, err
-	}
-	outerEnd, err := safetoken.Offset(tok, outer.End())
-	if err != nil {
-		return nil, err
-	}
-	before := src[outerStart:startOffset]
-	after := src[endOffset:outerEnd]
-	indent, err := calculateIndentation(src, tok, start)
-	if err != nil {
-		return nil, err
-	}
-	newLineIndent := "\n" + indent
-
-	var fullReplacement strings.Builder
-	fullReplacement.Write(before)
-	if commentBuf.Len() > 0 {
-		comments := strings.ReplaceAll(commentBuf.String(), "\n", newLineIndent)
-		fullReplacement.WriteString(comments)
-	}
-	if declBuf.Len() > 0 { // add any initializations, if needed
-		initializations := strings.ReplaceAll(declBuf.String(), "\n", newLineIndent) +
-			newLineIndent
-		fullReplacement.WriteString(initializations)
-	}
-	fullReplacement.Write(replaceBuf.Bytes()) // call the extracted function
-	if ifBuf.Len() > 0 {                      // add the if statement below the function call, if needed
-		ifstatement := newLineIndent +
-			strings.ReplaceAll(ifBuf.String(), "\n", newLineIndent)
-		fullReplacement.WriteString(ifstatement)
-	}
-	fullReplacement.Write(after)
-	fullReplacement.WriteString("\n\n")       // add newlines after the enclosing function
-	fullReplacement.Write(newFuncBuf.Bytes()) // insert the extracted function
-
-	return &analysis.SuggestedFix{
-		TextEdits: []analysis.TextEdit{{
-			Pos:     outer.Pos(),
-			End:     outer.End(),
-			NewText: []byte(fullReplacement.String()),
-		}},
-	}, nil
-}
-
-// adjustRangeForCommentsAndWhiteSpace adjusts the given range to exclude unnecessary leading or
-// trailing whitespace characters from selection as well as leading or trailing comments.
-// In the following example, each line of the if statement is indented once. There are also two
-// extra spaces after the sclosing bracket before the line break and a comment.
-//
-// \tif (true) {
-// \t    _ = 1
-// \t} // hello \n
-//
-// By default, a valid range begins at 'if' and ends at the first whitespace character
-// after the '}'. But, users are likely to highlight full lines rather than adjusting
-// their cursors for whitespace. To support this use case, we must manually adjust the
-// ranges to match the correct AST node. In this particular example, we would adjust
-// rng.Start forward to the start of 'if' and rng.End backward to after '}'.
-func adjustRangeForCommentsAndWhiteSpace(rng span.Range, tok *token.File, content []byte, file *ast.File) (span.Range, error) {
-	// Adjust the end of the range to after leading whitespace and comments.
-	prevStart, start := token.NoPos, rng.Start
-	startComment := sort.Search(len(file.Comments), func(i int) bool {
-		// Find the index for the first comment that ends after range start.
-		return file.Comments[i].End() > rng.Start
-	})
-	for prevStart != start {
-		prevStart = start
-		// If start is within a comment, move start to the end
-		// of the comment group.
-		if startComment < len(file.Comments) && file.Comments[startComment].Pos() <= start && start < file.Comments[startComment].End() {
-			start = file.Comments[startComment].End()
-			startComment++
-		}
-		// Move forwards to find a non-whitespace character.
-		offset, err := safetoken.Offset(tok, start)
-		if err != nil {
-			return span.Range{}, err
-		}
-		for offset < len(content) && isGoWhiteSpace(content[offset]) {
-			offset++
-		}
-		start = tok.Pos(offset)
-	}
-
-	// Adjust the end of the range to before trailing whitespace and comments.
-	prevEnd, end := token.NoPos, rng.End
-	endComment := sort.Search(len(file.Comments), func(i int) bool {
-		// Find the index for the first comment that ends after the range end.
-		return file.Comments[i].End() >= rng.End
-	})
-	// Search will return n if not found, so we need to adjust if there are no
-	// comments that would match.
-	if endComment == len(file.Comments) {
-		endComment = -1
-	}
-	for prevEnd != end {
-		prevEnd = end
-		// If end is within a comment, move end to the start
-		// of the comment group.
-		if endComment >= 0 && file.Comments[endComment].Pos() < end && end <= file.Comments[endComment].End() {
-			end = file.Comments[endComment].Pos()
-			endComment--
-		}
-		// Move backwards to find a non-whitespace character.
-		offset, err := safetoken.Offset(tok, end)
-		if err != nil {
-			return span.Range{}, err
-		}
-		for offset > 0 && isGoWhiteSpace(content[offset-1]) {
-			offset--
-		}
-		end = tok.Pos(offset)
-	}
-
-	return span.NewRange(tok, start, end), nil
-}
-
-// isGoWhiteSpace returns true if b is a considered white space in
-// Go as defined by scanner.GoWhitespace.
-func isGoWhiteSpace(b byte) bool {
-	return uint64(scanner.GoWhitespace)&(1<<uint(b)) != 0
-}
-
-// findParent finds the parent AST node of the given target node, if the target is a
-// descendant of the starting node.
-func findParent(start ast.Node, target ast.Node) ast.Node {
-	var parent ast.Node
-	analysisinternal.WalkASTWithParent(start, func(n, p ast.Node) bool {
-		if n == target {
-			parent = p
-			return false
-		}
-		return true
-	})
-	return parent
-}
-
-// variable describes the status of a variable within a selection.
-type variable struct {
-	obj types.Object
-
-	// free reports whether the variable is a free variable, meaning it should
-	// be a parameter to the extracted function.
-	free bool
-
-	// assigned reports whether the variable is assigned to in the selection.
-	assigned bool
-
-	// defined reports whether the variable is defined in the selection.
-	defined bool
-}
-
-// collectFreeVars maps each identifier in the given range to whether it is "free."
-// Given a range, a variable in that range is defined as "free" if it is declared
-// outside of the range and neither at the file scope nor package scope. These free
-// variables will be used as arguments in the extracted function. It also returns a
-// list of identifiers that may need to be returned by the extracted function.
-// Some of the code in this function has been adapted from tools/cmd/guru/freevars.go.
-func collectFreeVars(info *types.Info, file *ast.File, fileScope, pkgScope *types.Scope, rng span.Range, node ast.Node) ([]*variable, error) {
-	// id returns non-nil if n denotes an object that is referenced by the span
-	// and defined either within the span or in the lexical environment. The bool
-	// return value acts as an indicator for where it was defined.
-	id := func(n *ast.Ident) (types.Object, bool) {
-		obj := info.Uses[n]
-		if obj == nil {
-			return info.Defs[n], false
-		}
-		if obj.Name() == "_" {
-			return nil, false // exclude objects denoting '_'
-		}
-		if _, ok := obj.(*types.PkgName); ok {
-			return nil, false // imported package
-		}
-		if !(file.Pos() <= obj.Pos() && obj.Pos() <= file.End()) {
-			return nil, false // not defined in this file
-		}
-		scope := obj.Parent()
-		if scope == nil {
-			return nil, false // e.g. interface method, struct field
-		}
-		if scope == fileScope || scope == pkgScope {
-			return nil, false // defined at file or package scope
-		}
-		if rng.Start <= obj.Pos() && obj.Pos() <= rng.End {
-			return obj, false // defined within selection => not free
-		}
-		return obj, true
-	}
-	// sel returns non-nil if n denotes a selection o.x.y that is referenced by the
-	// span and defined either within the span or in the lexical environment. The bool
-	// return value acts as an indicator for where it was defined.
-	var sel func(n *ast.SelectorExpr) (types.Object, bool)
-	sel = func(n *ast.SelectorExpr) (types.Object, bool) {
-		switch x := astutil.Unparen(n.X).(type) {
-		case *ast.SelectorExpr:
-			return sel(x)
-		case *ast.Ident:
-			return id(x)
-		}
-		return nil, false
-	}
-	seen := make(map[types.Object]*variable)
-	firstUseIn := make(map[types.Object]token.Pos)
-	var vars []types.Object
-	ast.Inspect(node, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		if rng.Start <= n.Pos() && n.End() <= rng.End {
-			var obj types.Object
-			var isFree, prune bool
-			switch n := n.(type) {
-			case *ast.Ident:
-				obj, isFree = id(n)
-			case *ast.SelectorExpr:
-				obj, isFree = sel(n)
-				prune = true
-			}
-			if obj != nil {
-				seen[obj] = &variable{
-					obj:  obj,
-					free: isFree,
-				}
-				vars = append(vars, obj)
-				// Find the first time that the object is used in the selection.
-				first, ok := firstUseIn[obj]
-				if !ok || n.Pos() < first {
-					firstUseIn[obj] = n.Pos()
-				}
-				if prune {
-					return false
-				}
-			}
-		}
-		return n.Pos() <= rng.End
-	})
-
-	// Find identifiers that are initialized or whose values are altered at some
-	// point in the selected block. For example, in a selected block from lines 2-4,
-	// variables x, y, and z are included in assigned. However, in a selected block
-	// from lines 3-4, only variables y and z are included in assigned.
-	//
-	// 1: var a int
-	// 2: var x int
-	// 3: y := 3
-	// 4: z := x + a
-	//
-	ast.Inspect(node, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		if n.Pos() < rng.Start || n.End() > rng.End {
-			return n.Pos() <= rng.End
-		}
-		switch n := n.(type) {
-		case *ast.AssignStmt:
-			for _, assignment := range n.Lhs {
-				lhs, ok := assignment.(*ast.Ident)
-				if !ok {
-					continue
-				}
-				obj, _ := id(lhs)
-				if obj == nil {
-					continue
-				}
-				if _, ok := seen[obj]; !ok {
-					continue
-				}
-				seen[obj].assigned = true
-				if n.Tok != token.DEFINE {
-					continue
-				}
-				// Find identifiers that are defined prior to being used
-				// elsewhere in the selection.
-				// TODO: Include identifiers that are assigned prior to being
-				// used elsewhere in the selection. Then, change the assignment
-				// to a definition in the extracted function.
-				if firstUseIn[obj] != lhs.Pos() {
-					continue
-				}
-				// Ensure that the object is not used in its own re-definition.
-				// For example:
-				// var f float64
-				// f, e := math.Frexp(f)
-				for _, expr := range n.Rhs {
-					if referencesObj(info, expr, obj) {
-						continue
-					}
-					if _, ok := seen[obj]; !ok {
-						continue
-					}
-					seen[obj].defined = true
-					break
-				}
-			}
-			return false
-		case *ast.DeclStmt:
-			gen, ok := n.Decl.(*ast.GenDecl)
-			if !ok {
-				return false
-			}
-			for _, spec := range gen.Specs {
-				vSpecs, ok := spec.(*ast.ValueSpec)
-				if !ok {
-					continue
-				}
-				for _, vSpec := range vSpecs.Names {
-					obj, _ := id(vSpec)
-					if obj == nil {
-						continue
-					}
-					if _, ok := seen[obj]; !ok {
-						continue
-					}
-					seen[obj].assigned = true
-				}
-			}
-			return false
-		case *ast.IncDecStmt:
-			if ident, ok := n.X.(*ast.Ident); !ok {
-				return false
-			} else if obj, _ := id(ident); obj == nil {
-				return false
-			} else {
-				if _, ok := seen[obj]; !ok {
-					return false
-				}
-				seen[obj].assigned = true
-			}
-		}
-		return true
-	})
-	var variables []*variable
-	for _, obj := range vars {
-		v, ok := seen[obj]
-		if !ok {
-			return nil, fmt.Errorf("no seen types.Object for %v", obj)
-		}
-		variables = append(variables, v)
-	}
-	return variables, nil
-}
-
-// referencesObj checks whether the given object appears in the given expression.
-func referencesObj(info *types.Info, expr ast.Expr, obj types.Object) bool {
-	var hasObj bool
-	ast.Inspect(expr, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		ident, ok := n.(*ast.Ident)
-		if !ok {
-			return true
-		}
-		objUse := info.Uses[ident]
-		if obj == objUse {
-			hasObj = true
-			return false
-		}
-		return false
-	})
-	return hasObj
-}
-
-type fnExtractParams struct {
-	tok   *token.File
-	path  []ast.Node
-	rng   span.Range
-	outer *ast.FuncDecl
-	start ast.Node
-}
-
-// CanExtractFunction reports whether the code in the given range can be
-// extracted to a function.
-func CanExtractFunction(tok *token.File, rng span.Range, src []byte, file *ast.File) (*fnExtractParams, bool, bool, error) {
-	if rng.Start == rng.End {
-		return nil, false, false, fmt.Errorf("start and end are equal")
-	}
-	var err error
-	rng, err = adjustRangeForCommentsAndWhiteSpace(rng, tok, src, file)
-	if err != nil {
-		return nil, false, false, err
-	}
-	path, _ := astutil.PathEnclosingInterval(file, rng.Start, rng.End)
-	if len(path) == 0 {
-		return nil, false, false, fmt.Errorf("no path enclosing interval")
-	}
-	// Node that encloses the selection must be a statement.
-	// TODO: Support function extraction for an expression.
-	_, ok := path[0].(ast.Stmt)
-	if !ok {
-		return nil, false, false, fmt.Errorf("node is not a statement")
-	}
-
-	// Find the function declaration that encloses the selection.
-	var outer *ast.FuncDecl
-	for _, p := range path {
-		if p, ok := p.(*ast.FuncDecl); ok {
-			outer = p
-			break
-		}
-	}
-	if outer == nil {
-		return nil, false, false, fmt.Errorf("no enclosing function")
-	}
-
-	// Find the nodes at the start and end of the selection.
-	var start, end ast.Node
-	ast.Inspect(outer, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		// Do not override 'start' with a node that begins at the same location
-		// but is nested further from 'outer'.
-		if start == nil && n.Pos() == rng.Start && n.End() <= rng.End {
-			start = n
-		}
-		if end == nil && n.End() == rng.End && n.Pos() >= rng.Start {
-			end = n
-		}
-		return n.Pos() <= rng.End
-	})
-	if start == nil || end == nil {
-		return nil, false, false, fmt.Errorf("range does not map to AST nodes")
-	}
-	// If the region is a blockStmt, use the first and last nodes in the block
-	// statement.
-	// <rng.start>{ ... }<rng.end> => { <rng.start>...<rng.end> }
-	if blockStmt, ok := start.(*ast.BlockStmt); ok {
-		if len(blockStmt.List) == 0 {
-			return nil, false, false, fmt.Errorf("range maps to empty block statement")
-		}
-		start, end = blockStmt.List[0], blockStmt.List[len(blockStmt.List)-1]
-		rng.Start, rng.End = start.Pos(), end.End()
-	}
-	return &fnExtractParams{
-		tok:   tok,
-		path:  path,
-		rng:   rng,
-		outer: outer,
-		start: start,
-	}, true, outer.Recv != nil, nil
-}
-
-// objUsed checks if the object is used within the range. It returns the first
-// occurrence of the object in the range, if it exists.
-func objUsed(info *types.Info, rng span.Range, obj types.Object) (bool, *ast.Ident) {
-	var firstUse *ast.Ident
-	for id, objUse := range info.Uses {
-		if obj != objUse {
-			continue
-		}
-		if id.Pos() < rng.Start || id.End() > rng.End {
-			continue
-		}
-		if firstUse == nil || id.Pos() < firstUse.Pos() {
-			firstUse = id
-		}
-	}
-	return firstUse != nil, firstUse
-}
-
-// varOverridden traverses the given AST node until we find the given identifier. Then, we
-// examine the occurrence of the given identifier and check for (1) whether the identifier
-// is being redefined. If the identifier is free, we also check for (2) whether the identifier
-// is being reassigned. We will not include an identifier in the return statement of the
-// extracted function if it meets one of the above conditions.
-func varOverridden(info *types.Info, firstUse *ast.Ident, obj types.Object, isFree bool, node ast.Node) bool {
-	var isOverriden bool
-	ast.Inspect(node, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		assignment, ok := n.(*ast.AssignStmt)
-		if !ok {
-			return true
-		}
-		// A free variable is initialized prior to the selection. We can always reassign
-		// this variable after the selection because it has already been defined.
-		// Conversely, a non-free variable is initialized within the selection. Thus, we
-		// cannot reassign this variable after the selection unless it is initialized and
-		// returned by the extracted function.
-		if !isFree && assignment.Tok == token.ASSIGN {
-			return false
-		}
-		for _, assigned := range assignment.Lhs {
-			ident, ok := assigned.(*ast.Ident)
-			// Check if we found the first use of the identifier.
-			if !ok || ident != firstUse {
-				continue
-			}
-			objUse := info.Uses[ident]
-			if objUse == nil || objUse != obj {
-				continue
-			}
-			// Ensure that the object is not used in its own definition.
-			// For example:
-			// var f float64
-			// f, e := math.Frexp(f)
-			for _, expr := range assignment.Rhs {
-				if referencesObj(info, expr, obj) {
-					return false
-				}
-			}
-			isOverriden = true
-			return false
-		}
-		return false
-	})
-	return isOverriden
-}
-
-// parseBlockStmt generates an AST file from the given text. We then return the portion of the
-// file that represents the text.
-func parseBlockStmt(fset *token.FileSet, src []byte) (*ast.BlockStmt, error) {
-	text := "package main\nfunc _() { " + string(src) + " }"
-	extract, err := parser.ParseFile(fset, "", text, 0)
-	if err != nil {
-		return nil, err
-	}
-	if len(extract.Decls) == 0 {
-		return nil, fmt.Errorf("parsed file does not contain any declarations")
-	}
-	decl, ok := extract.Decls[0].(*ast.FuncDecl)
-	if !ok {
-		return nil, fmt.Errorf("parsed file does not contain expected function declaration")
-	}
-	if decl.Body == nil {
-		return nil, fmt.Errorf("extracted function has no body")
-	}
-	return decl.Body, nil
-}
-
-// generateReturnInfo generates the information we need to adjust the return statements and
-// signature of the extracted function. We prepare names, signatures, and "zero values" that
-// represent the new variables. We also use this information to construct the if statement that
-// is inserted below the call to the extracted function.
-func generateReturnInfo(enclosing *ast.FuncType, pkg *types.Package, path []ast.Node, file *ast.File, info *types.Info, fset *token.FileSet, pos token.Pos, hasNonNestedReturns bool) ([]*returnVariable, *ast.IfStmt, error) {
-	var retVars []*returnVariable
-	var cond *ast.Ident
-	if !hasNonNestedReturns {
-		// Generate information for the added bool value.
-		name, _ := generateAvailableIdentifier(pos, file, path, info, "shouldReturn", 0)
-		cond = &ast.Ident{Name: name}
-		retVars = append(retVars, &returnVariable{
-			name:    cond,
-			decl:    &ast.Field{Type: ast.NewIdent("bool")},
-			zeroVal: ast.NewIdent("false"),
-		})
-	}
-	// Generate information for the values in the return signature of the enclosing function.
-	if enclosing.Results != nil {
-		idx := 0
-		for _, field := range enclosing.Results.List {
-			typ := info.TypeOf(field.Type)
-			if typ == nil {
-				return nil, nil, fmt.Errorf(
-					"failed type conversion, AST expression: %T", field.Type)
-			}
-			expr := analysisinternal.TypeExpr(file, pkg, typ)
-			if expr == nil {
-				return nil, nil, fmt.Errorf("nil AST expression")
-			}
-			var name string
-			name, idx = generateAvailableIdentifier(pos, file,
-				path, info, "returnValue", idx)
-			retVars = append(retVars, &returnVariable{
-				name:    ast.NewIdent(name),
-				decl:    &ast.Field{Type: expr},
-				zeroVal: analysisinternal.ZeroValue(file, pkg, typ),
-			})
-		}
-	}
-	var ifReturn *ast.IfStmt
-	if !hasNonNestedReturns {
-		// Create the return statement for the enclosing function. We must exclude the variable
-		// for the condition of the if statement (cond) from the return statement.
-		ifReturn = &ast.IfStmt{
-			Cond: cond,
-			Body: &ast.BlockStmt{
-				List: []ast.Stmt{&ast.ReturnStmt{Results: getNames(retVars)[1:]}},
-			},
-		}
-	}
-	return retVars, ifReturn, nil
-}
-
-// adjustReturnStatements adds "zero values" of the given types to each return statement
-// in the given AST node.
-func adjustReturnStatements(returnTypes []*ast.Field, seenVars map[types.Object]ast.Expr, fset *token.FileSet, file *ast.File, pkg *types.Package, extractedBlock *ast.BlockStmt) error {
-	var zeroVals []ast.Expr
-	// Create "zero values" for each type.
-	for _, returnType := range returnTypes {
-		var val ast.Expr
-		for obj, typ := range seenVars {
-			if typ != returnType.Type {
-				continue
-			}
-			val = analysisinternal.ZeroValue(file, pkg, obj.Type())
-			break
-		}
-		if val == nil {
-			return fmt.Errorf(
-				"could not find matching AST expression for %T", returnType.Type)
-		}
-		zeroVals = append(zeroVals, val)
-	}
-	// Add "zero values" to each return statement.
-	// The bool reports whether the enclosing function should return after calling the
-	// extracted function. We set the bool to 'true' because, if these return statements
-	// execute, the extracted function terminates early, and the enclosing function must
-	// return as well.
-	zeroVals = append(zeroVals, ast.NewIdent("true"))
-	ast.Inspect(extractedBlock, func(n ast.Node) bool {
-		if n == nil {
-			return false
-		}
-		if n, ok := n.(*ast.ReturnStmt); ok {
-			n.Results = append(zeroVals, n.Results...)
-			return false
-		}
-		return true
-	})
-	return nil
-}
-
-// generateFuncCall constructs a call expression for the extracted function, described by the
-// given parameters and return variables.
-func generateFuncCall(hasNonNestedReturn, hasReturnVals bool, params, returns []ast.Expr, name string, token token.Token, selector string) ast.Node {
-	var replace ast.Node
-	callExpr := &ast.CallExpr{
-		Fun:  ast.NewIdent(name),
-		Args: params,
-	}
-	if selector != "" {
-		callExpr = &ast.CallExpr{
-			Fun: &ast.SelectorExpr{
-				X:   ast.NewIdent(selector),
-				Sel: ast.NewIdent(name),
-			},
-			Args: params,
-		}
-	}
-	if hasReturnVals {
-		if hasNonNestedReturn {
-			// Create a return statement that returns the result of the function call.
-			replace = &ast.ReturnStmt{
-				Return:  0,
-				Results: []ast.Expr{callExpr},
-			}
-		} else {
-			// Assign the result of the function call.
-			replace = &ast.AssignStmt{
-				Lhs: returns,
-				Tok: token,
-				Rhs: []ast.Expr{callExpr},
-			}
-		}
-	} else {
-		replace = callExpr
-	}
-	return replace
-}
-
-// initializeVars creates variable declarations, if needed.
-// Our preference is to replace the selected block with an "x, y, z := fn()" style
-// assignment statement. We can use this style when all of the variables in the
-// extracted function's return statement are either not defined prior to the extracted block
-// or can be safely redefined. However, for example, if z is already defined
-// in a different scope, we replace the selected block with:
-//
-// var x int
-// var y string
-// x, y, z = fn()
-func initializeVars(uninitialized []types.Object, retVars []*returnVariable, seenUninitialized map[types.Object]struct{}, seenVars map[types.Object]ast.Expr) []ast.Stmt {
-	var declarations []ast.Stmt
-	for _, obj := range uninitialized {
-		if _, ok := seenUninitialized[obj]; ok {
-			continue
-		}
-		seenUninitialized[obj] = struct{}{}
-		valSpec := &ast.ValueSpec{
-			Names: []*ast.Ident{ast.NewIdent(obj.Name())},
-			Type:  seenVars[obj],
-		}
-		genDecl := &ast.GenDecl{
-			Tok:   token.VAR,
-			Specs: []ast.Spec{valSpec},
-		}
-		declarations = append(declarations, &ast.DeclStmt{Decl: genDecl})
-	}
-	// Each variable added from a return statement in the selection
-	// must be initialized.
-	for i, retVar := range retVars {
-		n := retVar.name.(*ast.Ident)
-		valSpec := &ast.ValueSpec{
-			Names: []*ast.Ident{n},
-			Type:  retVars[i].decl.Type,
-		}
-		genDecl := &ast.GenDecl{
-			Tok:   token.VAR,
-			Specs: []ast.Spec{valSpec},
-		}
-		declarations = append(declarations, &ast.DeclStmt{Decl: genDecl})
-	}
-	return declarations
-}
-
-// getNames returns the names from the given list of returnVariable.
-func getNames(retVars []*returnVariable) []ast.Expr {
-	var names []ast.Expr
-	for _, retVar := range retVars {
-		names = append(names, retVar.name)
-	}
-	return names
-}
-
-// getZeroVals returns the "zero values" from the given list of returnVariable.
-func getZeroVals(retVars []*returnVariable) []ast.Expr {
-	var zvs []ast.Expr
-	for _, retVar := range retVars {
-		zvs = append(zvs, retVar.zeroVal)
-	}
-	return zvs
-}
-
-// getDecls returns the declarations from the given list of returnVariable.
-func getDecls(retVars []*returnVariable) []*ast.Field {
-	var decls []*ast.Field
-	for _, retVar := range retVars {
-		decls = append(decls, retVar.decl)
-	}
-	return decls
-}
diff -urN a/gopls/internal/lsp/source/fix.go b/gopls/internal/lsp/source/fix.go
--- a/gopls/internal/lsp/source/fix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/fix.go	1969-12-31 16:00:00
@@ -1,145 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/fillstruct"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/undeclaredname"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-)
-
-type (
-	// SuggestedFixFunc is a function used to get the suggested fixes for a given
-	// gopls command, some of which are provided by go/analysis.Analyzers. Some of
-	// the analyzers in internal/lsp/analysis are not efficient enough to include
-	// suggested fixes with their diagnostics, so we have to compute them
-	// separately. Such analyzers should provide a function with a signature of
-	// SuggestedFixFunc.
-	SuggestedFixFunc  func(ctx context.Context, snapshot Snapshot, fh VersionedFileHandle, pRng protocol.Range) (*token.FileSet, *analysis.SuggestedFix, error)
-	singleFileFixFunc func(fset *token.FileSet, rng span.Range, src []byte, file *ast.File, pkg *types.Package, info *types.Info) (*analysis.SuggestedFix, error)
-)
-
-const (
-	FillStruct      = "fill_struct"
-	StubMethods     = "stub_methods"
-	UndeclaredName  = "undeclared_name"
-	ExtractVariable = "extract_variable"
-	ExtractFunction = "extract_function"
-	ExtractMethod   = "extract_method"
-)
-
-// suggestedFixes maps a suggested fix command id to its handler.
-var suggestedFixes = map[string]SuggestedFixFunc{
-	FillStruct:      singleFile(fillstruct.SuggestedFix),
-	UndeclaredName:  singleFile(undeclaredname.SuggestedFix),
-	ExtractVariable: singleFile(extractVariable),
-	ExtractFunction: singleFile(extractFunction),
-	ExtractMethod:   singleFile(extractMethod),
-	StubMethods:     stubSuggestedFixFunc,
-}
-
-// singleFile calls analyzers that expect inputs for a single file
-func singleFile(sf singleFileFixFunc) SuggestedFixFunc {
-	return func(ctx context.Context, snapshot Snapshot, fh VersionedFileHandle, pRng protocol.Range) (*token.FileSet, *analysis.SuggestedFix, error) {
-		fset, rng, src, file, pkg, info, err := getAllSuggestedFixInputs(ctx, snapshot, fh, pRng)
-		if err != nil {
-			return nil, nil, err
-		}
-		fix, err := sf(fset, rng, src, file, pkg, info)
-		return fset, fix, err
-	}
-}
-
-func SuggestedFixFromCommand(cmd protocol.Command, kind protocol.CodeActionKind) SuggestedFix {
-	return SuggestedFix{
-		Title:      cmd.Title,
-		Command:    &cmd,
-		ActionKind: kind,
-	}
-}
-
-// ApplyFix applies the command's suggested fix to the given file and
-// range, returning the resulting edits.
-func ApplyFix(ctx context.Context, fix string, snapshot Snapshot, fh VersionedFileHandle, pRng protocol.Range) ([]protocol.TextDocumentEdit, error) {
-	handler, ok := suggestedFixes[fix]
-	if !ok {
-		return nil, fmt.Errorf("no suggested fix function for %s", fix)
-	}
-	fset, suggestion, err := handler(ctx, snapshot, fh, pRng)
-	if err != nil {
-		return nil, err
-	}
-	if suggestion == nil {
-		return nil, nil
-	}
-	editsPerFile := map[span.URI]*protocol.TextDocumentEdit{}
-	for _, edit := range suggestion.TextEdits {
-		tokFile := fset.File(edit.Pos)
-		if tokFile == nil {
-			return nil, bug.Errorf("no file for edit position")
-		}
-		end := edit.End
-		if !end.IsValid() {
-			end = edit.Pos
-		}
-		fh, err := snapshot.GetVersionedFile(ctx, span.URIFromPath(tokFile.Name()))
-		if err != nil {
-			return nil, err
-		}
-		te, ok := editsPerFile[fh.URI()]
-		if !ok {
-			te = &protocol.TextDocumentEdit{
-				TextDocument: protocol.OptionalVersionedTextDocumentIdentifier{
-					Version: fh.Version(),
-					TextDocumentIdentifier: protocol.TextDocumentIdentifier{
-						URI: protocol.URIFromSpanURI(fh.URI()),
-					},
-				},
-			}
-			editsPerFile[fh.URI()] = te
-		}
-		content, err := fh.Read()
-		if err != nil {
-			return nil, err
-		}
-		m := protocol.ColumnMapper{URI: fh.URI(), TokFile: tokFile, Content: content}
-		rng, err := m.PosRange(edit.Pos, end)
-		if err != nil {
-			return nil, err
-		}
-		te.Edits = append(te.Edits, protocol.TextEdit{
-			Range:   rng,
-			NewText: string(edit.NewText),
-		})
-	}
-	var edits []protocol.TextDocumentEdit
-	for _, edit := range editsPerFile {
-		edits = append(edits, *edit)
-	}
-	return edits, nil
-}
-
-// getAllSuggestedFixInputs is a helper function to collect all possible needed
-// inputs for an AppliesFunc or SuggestedFixFunc.
-func getAllSuggestedFixInputs(ctx context.Context, snapshot Snapshot, fh FileHandle, pRng protocol.Range) (*token.FileSet, span.Range, []byte, *ast.File, *types.Package, *types.Info, error) {
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckWorkspace, NarrowestPackage)
-	if err != nil {
-		return nil, span.Range{}, nil, nil, nil, nil, fmt.Errorf("getting file for Identifier: %w", err)
-	}
-	rng, err := pgf.Mapper.RangeToSpanRange(pRng)
-	if err != nil {
-		return nil, span.Range{}, nil, nil, nil, nil, err
-	}
-	return pkg.FileSet(), rng, pgf.Src, pgf.File, pkg.GetTypes(), pkg.GetTypesInfo(), nil
-}
diff -urN a/gopls/internal/lsp/source/folding_range.go b/gopls/internal/lsp/source/folding_range.go
--- a/gopls/internal/lsp/source/folding_range.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/folding_range.go	1969-12-31 16:00:00
@@ -1,184 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"go/ast"
-	"go/token"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// FoldingRangeInfo holds range and kind info of folding for an ast.Node
-type FoldingRangeInfo struct {
-	MappedRange
-	Kind protocol.FoldingRangeKind
-}
-
-// FoldingRange gets all of the folding range for f.
-func FoldingRange(ctx context.Context, snapshot Snapshot, fh FileHandle, lineFoldingOnly bool) (ranges []*FoldingRangeInfo, err error) {
-	// TODO(suzmue): consider limiting the number of folding ranges returned, and
-	// implement a way to prioritize folding ranges in that case.
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, err
-	}
-
-	// With parse errors, we wouldn't be able to produce accurate folding info.
-	// LSP protocol (3.16) currently does not have a way to handle this case
-	// (https://github.com/microsoft/language-server-protocol/issues/1200).
-	// We cannot return an error either because we are afraid some editors
-	// may not handle errors nicely. As a workaround, we now return an empty
-	// result and let the client handle this case by double check the file
-	// contents (i.e. if the file is not empty and the folding range result
-	// is empty, raise an internal error).
-	if pgf.ParseErr != nil {
-		return nil, nil
-	}
-
-	// Get folding ranges for comments separately as they are not walked by ast.Inspect.
-	ranges = append(ranges, commentsFoldingRange(pgf.Mapper, pgf.File)...)
-
-	visit := func(n ast.Node) bool {
-		rng := foldingRangeFunc(pgf.Tok, pgf.Mapper, n, lineFoldingOnly)
-		if rng != nil {
-			ranges = append(ranges, rng)
-		}
-		return true
-	}
-	// Walk the ast and collect folding ranges.
-	ast.Inspect(pgf.File, visit)
-
-	sort.Slice(ranges, func(i, j int) bool {
-		irng, _ := ranges[i].Range()
-		jrng, _ := ranges[j].Range()
-		return protocol.CompareRange(irng, jrng) < 0
-	})
-
-	return ranges, nil
-}
-
-// foldingRangeFunc calculates the line folding range for ast.Node n
-func foldingRangeFunc(tokFile *token.File, m *protocol.ColumnMapper, n ast.Node, lineFoldingOnly bool) *FoldingRangeInfo {
-	// TODO(suzmue): include trailing empty lines before the closing
-	// parenthesis/brace.
-	var kind protocol.FoldingRangeKind
-	var start, end token.Pos
-	switch n := n.(type) {
-	case *ast.BlockStmt:
-		// Fold between positions of or lines between "{" and "}".
-		var startList, endList token.Pos
-		if num := len(n.List); num != 0 {
-			startList, endList = n.List[0].Pos(), n.List[num-1].End()
-		}
-		start, end = validLineFoldingRange(tokFile, n.Lbrace, n.Rbrace, startList, endList, lineFoldingOnly)
-	case *ast.CaseClause:
-		// Fold from position of ":" to end.
-		start, end = n.Colon+1, n.End()
-	case *ast.CommClause:
-		// Fold from position of ":" to end.
-		start, end = n.Colon+1, n.End()
-	case *ast.CallExpr:
-		// Fold from position of "(" to position of ")".
-		start, end = n.Lparen+1, n.Rparen
-	case *ast.FieldList:
-		// Fold between positions of or lines between opening parenthesis/brace and closing parenthesis/brace.
-		var startList, endList token.Pos
-		if num := len(n.List); num != 0 {
-			startList, endList = n.List[0].Pos(), n.List[num-1].End()
-		}
-		start, end = validLineFoldingRange(tokFile, n.Opening, n.Closing, startList, endList, lineFoldingOnly)
-	case *ast.GenDecl:
-		// If this is an import declaration, set the kind to be protocol.Imports.
-		if n.Tok == token.IMPORT {
-			kind = protocol.Imports
-		}
-		// Fold between positions of or lines between "(" and ")".
-		var startSpecs, endSpecs token.Pos
-		if num := len(n.Specs); num != 0 {
-			startSpecs, endSpecs = n.Specs[0].Pos(), n.Specs[num-1].End()
-		}
-		start, end = validLineFoldingRange(tokFile, n.Lparen, n.Rparen, startSpecs, endSpecs, lineFoldingOnly)
-	case *ast.BasicLit:
-		// Fold raw string literals from position of "`" to position of "`".
-		if n.Kind == token.STRING && len(n.Value) >= 2 && n.Value[0] == '`' && n.Value[len(n.Value)-1] == '`' {
-			start, end = n.Pos(), n.End()
-		}
-	case *ast.CompositeLit:
-		// Fold between positions of or lines between "{" and "}".
-		var startElts, endElts token.Pos
-		if num := len(n.Elts); num != 0 {
-			startElts, endElts = n.Elts[0].Pos(), n.Elts[num-1].End()
-		}
-		start, end = validLineFoldingRange(tokFile, n.Lbrace, n.Rbrace, startElts, endElts, lineFoldingOnly)
-	}
-
-	// Check that folding positions are valid.
-	if !start.IsValid() || !end.IsValid() {
-		return nil
-	}
-	// in line folding mode, do not fold if the start and end lines are the same.
-	if lineFoldingOnly && tokFile.Line(start) == tokFile.Line(end) {
-		return nil
-	}
-	return &FoldingRangeInfo{
-		MappedRange: NewMappedRange(m, start, end),
-		Kind:        kind,
-	}
-}
-
-// validLineFoldingRange returns start and end token.Pos for folding range if the range is valid.
-// returns token.NoPos otherwise, which fails token.IsValid check
-func validLineFoldingRange(tokFile *token.File, open, close, start, end token.Pos, lineFoldingOnly bool) (token.Pos, token.Pos) {
-	if lineFoldingOnly {
-		if !open.IsValid() || !close.IsValid() {
-			return token.NoPos, token.NoPos
-		}
-
-		// Don't want to fold if the start/end is on the same line as the open/close
-		// as an example, the example below should *not* fold:
-		// var x = [2]string{"d",
-		// "e" }
-		if tokFile.Line(open) == tokFile.Line(start) ||
-			tokFile.Line(close) == tokFile.Line(end) {
-			return token.NoPos, token.NoPos
-		}
-
-		return open + 1, end
-	}
-	return open + 1, close
-}
-
-// commentsFoldingRange returns the folding ranges for all comment blocks in file.
-// The folding range starts at the end of the first line of the comment block, and ends at the end of the
-// comment block and has kind protocol.Comment.
-func commentsFoldingRange(m *protocol.ColumnMapper, file *ast.File) (comments []*FoldingRangeInfo) {
-	tokFile := m.TokFile
-	for _, commentGrp := range file.Comments {
-		startGrpLine, endGrpLine := tokFile.Line(commentGrp.Pos()), tokFile.Line(commentGrp.End())
-		if startGrpLine == endGrpLine {
-			// Don't fold single line comments.
-			continue
-		}
-
-		firstComment := commentGrp.List[0]
-		startPos, endLinePos := firstComment.Pos(), firstComment.End()
-		startCmmntLine, endCmmntLine := tokFile.Line(startPos), tokFile.Line(endLinePos)
-		if startCmmntLine != endCmmntLine {
-			// If the first comment spans multiple lines, then we want to have the
-			// folding range start at the end of the first line.
-			endLinePos = token.Pos(int(startPos) + len(strings.Split(firstComment.Text, "\n")[0]))
-		}
-		comments = append(comments, &FoldingRangeInfo{
-			// Fold from the end of the first line comment to the end of the comment block.
-			MappedRange: NewMappedRange(m, endLinePos, commentGrp.End()),
-			Kind:        protocol.Comment,
-		})
-	}
-	return comments
-}
diff -urN a/gopls/internal/lsp/source/format.go b/gopls/internal/lsp/source/format.go
--- a/gopls/internal/lsp/source/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/format.go	1969-12-31 16:00:00
@@ -1,392 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package source provides core features for use by Go editors and tools.
-package source
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/parser"
-	"go/token"
-	"strings"
-	"text/scanner"
-
-	"golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/imports"
-)
-
-// Format formats a file with a given range.
-func Format(ctx context.Context, snapshot Snapshot, fh FileHandle) ([]protocol.TextEdit, error) {
-	ctx, done := event.Start(ctx, "source.Format")
-	defer done()
-
-	// Generated files shouldn't be edited. So, don't format them
-	if IsGenerated(ctx, snapshot, fh.URI()) {
-		return nil, fmt.Errorf("can't format %q: file is generated", fh.URI().Filename())
-	}
-
-	fset := snapshot.FileSet()
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, err
-	}
-	// Even if this file has parse errors, it might still be possible to format it.
-	// Using format.Node on an AST with errors may result in code being modified.
-	// Attempt to format the source of this file instead.
-	if pgf.ParseErr != nil {
-		formatted, err := formatSource(ctx, fh)
-		if err != nil {
-			return nil, err
-		}
-		return computeTextEdits(ctx, snapshot, pgf, string(formatted))
-	}
-
-	// format.Node changes slightly from one release to another, so the version
-	// of Go used to build the LSP server will determine how it formats code.
-	// This should be acceptable for all users, who likely be prompted to rebuild
-	// the LSP server on each Go release.
-	buf := &bytes.Buffer{}
-	if err := format.Node(buf, fset, pgf.File); err != nil {
-		return nil, err
-	}
-	formatted := buf.String()
-
-	// Apply additional formatting, if any is supported. Currently, the only
-	// supported additional formatter is gofumpt.
-	if format := snapshot.View().Options().GofumptFormat; snapshot.View().Options().Gofumpt && format != nil {
-		// gofumpt can customize formatting based on language version and module
-		// path, if available.
-		//
-		// Try to derive this information, but fall-back on the default behavior.
-		//
-		// TODO: under which circumstances can we fail to find module information?
-		// Can this, for example, result in inconsistent formatting across saves,
-		// due to pending calls to packages.Load?
-		var langVersion, modulePath string
-		mds, err := snapshot.MetadataForFile(ctx, fh.URI())
-		if err == nil && len(mds) > 0 {
-			if mi := mds[0].Module; mi != nil {
-				langVersion = mi.GoVersion
-				modulePath = mi.Path
-			}
-		}
-		b, err := format(ctx, langVersion, modulePath, buf.Bytes())
-		if err != nil {
-			return nil, err
-		}
-		formatted = string(b)
-	}
-	return computeTextEdits(ctx, snapshot, pgf, formatted)
-}
-
-func formatSource(ctx context.Context, fh FileHandle) ([]byte, error) {
-	_, done := event.Start(ctx, "source.formatSource")
-	defer done()
-
-	data, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	return format.Source(data)
-}
-
-type ImportFix struct {
-	Fix   *imports.ImportFix
-	Edits []protocol.TextEdit
-}
-
-// AllImportsFixes formats f for each possible fix to the imports.
-// In addition to returning the result of applying all edits,
-// it returns a list of fixes that could be applied to the file, with the
-// corresponding TextEdits that would be needed to apply that fix.
-func AllImportsFixes(ctx context.Context, snapshot Snapshot, fh FileHandle) (allFixEdits []protocol.TextEdit, editsPerFix []*ImportFix, err error) {
-	ctx, done := event.Start(ctx, "source.AllImportsFixes")
-	defer done()
-
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, nil, err
-	}
-	if err := snapshot.RunProcessEnvFunc(ctx, func(opts *imports.Options) error {
-		allFixEdits, editsPerFix, err = computeImportEdits(snapshot, pgf, opts)
-		return err
-	}); err != nil {
-		return nil, nil, fmt.Errorf("AllImportsFixes: %v", err)
-	}
-	return allFixEdits, editsPerFix, nil
-}
-
-// computeImportEdits computes a set of edits that perform one or all of the
-// necessary import fixes.
-func computeImportEdits(snapshot Snapshot, pgf *ParsedGoFile, options *imports.Options) (allFixEdits []protocol.TextEdit, editsPerFix []*ImportFix, err error) {
-	filename := pgf.URI.Filename()
-
-	// Build up basic information about the original file.
-	allFixes, err := imports.FixImports(filename, pgf.Src, options)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	allFixEdits, err = computeFixEdits(snapshot, pgf, options, allFixes)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	// Apply all of the import fixes to the file.
-	// Add the edits for each fix to the result.
-	for _, fix := range allFixes {
-		edits, err := computeFixEdits(snapshot, pgf, options, []*imports.ImportFix{fix})
-		if err != nil {
-			return nil, nil, err
-		}
-		editsPerFix = append(editsPerFix, &ImportFix{
-			Fix:   fix,
-			Edits: edits,
-		})
-	}
-	return allFixEdits, editsPerFix, nil
-}
-
-// ComputeOneImportFixEdits returns text edits for a single import fix.
-func ComputeOneImportFixEdits(snapshot Snapshot, pgf *ParsedGoFile, fix *imports.ImportFix) ([]protocol.TextEdit, error) {
-	options := &imports.Options{
-		LocalPrefix: snapshot.View().Options().Local,
-		// Defaults.
-		AllErrors:  true,
-		Comments:   true,
-		Fragment:   true,
-		FormatOnly: false,
-		TabIndent:  true,
-		TabWidth:   8,
-	}
-	return computeFixEdits(snapshot, pgf, options, []*imports.ImportFix{fix})
-}
-
-func computeFixEdits(snapshot Snapshot, pgf *ParsedGoFile, options *imports.Options, fixes []*imports.ImportFix) ([]protocol.TextEdit, error) {
-	// trim the original data to match fixedData
-	left, err := importPrefix(pgf.Src)
-	if err != nil {
-		return nil, err
-	}
-	extra := !strings.Contains(left, "\n") // one line may have more than imports
-	if extra {
-		left = string(pgf.Src)
-	}
-	if len(left) > 0 && left[len(left)-1] != '\n' {
-		left += "\n"
-	}
-	// Apply the fixes and re-parse the file so that we can locate the
-	// new imports.
-	flags := parser.ImportsOnly
-	if extra {
-		// used all of origData above, use all of it here too
-		flags = 0
-	}
-	fixedData, err := imports.ApplyFixes(fixes, "", pgf.Src, options, flags)
-	if err != nil {
-		return nil, err
-	}
-	if fixedData == nil || fixedData[len(fixedData)-1] != '\n' {
-		fixedData = append(fixedData, '\n') // ApplyFixes may miss the newline, go figure.
-	}
-	edits := snapshot.View().Options().ComputeEdits(left, string(fixedData))
-	return protocolEditsFromSource([]byte(left), edits, pgf.Mapper.TokFile)
-}
-
-// importPrefix returns the prefix of the given file content through the final
-// import statement. If there are no imports, the prefix is the package
-// statement and any comment groups below it.
-func importPrefix(src []byte) (string, error) {
-	fset := token.NewFileSet()
-	// do as little parsing as possible
-	f, err := parser.ParseFile(fset, "", src, parser.ImportsOnly|parser.ParseComments)
-	if err != nil { // This can happen if 'package' is misspelled
-		return "", fmt.Errorf("importPrefix: failed to parse: %s", err)
-	}
-	tok := fset.File(f.Pos())
-	var importEnd int
-	for _, d := range f.Decls {
-		if x, ok := d.(*ast.GenDecl); ok && x.Tok == token.IMPORT {
-			if e, err := safetoken.Offset(tok, d.End()); err != nil {
-				return "", fmt.Errorf("importPrefix: %s", err)
-			} else if e > importEnd {
-				importEnd = e
-			}
-		}
-	}
-
-	maybeAdjustToLineEnd := func(pos token.Pos, isCommentNode bool) int {
-		offset, err := safetoken.Offset(tok, pos)
-		if err != nil {
-			return -1
-		}
-
-		// Don't go past the end of the file.
-		if offset > len(src) {
-			offset = len(src)
-		}
-		// The go/ast package does not account for different line endings, and
-		// specifically, in the text of a comment, it will strip out \r\n line
-		// endings in favor of \n. To account for these differences, we try to
-		// return a position on the next line whenever possible.
-		switch line := tok.Line(tok.Pos(offset)); {
-		case line < tok.LineCount():
-			nextLineOffset, err := safetoken.Offset(tok, tok.LineStart(line+1))
-			if err != nil {
-				return -1
-			}
-			// If we found a position that is at the end of a line, move the
-			// offset to the start of the next line.
-			if offset+1 == nextLineOffset {
-				offset = nextLineOffset
-			}
-		case isCommentNode, offset+1 == tok.Size():
-			// If the last line of the file is a comment, or we are at the end
-			// of the file, the prefix is the entire file.
-			offset = len(src)
-		}
-		return offset
-	}
-	if importEnd == 0 {
-		pkgEnd := f.Name.End()
-		importEnd = maybeAdjustToLineEnd(pkgEnd, false)
-	}
-	for _, cgroup := range f.Comments {
-		for _, c := range cgroup.List {
-			if end, err := safetoken.Offset(tok, c.End()); err != nil {
-				return "", err
-			} else if end > importEnd {
-				startLine := safetoken.Position(tok, c.Pos()).Line
-				endLine := safetoken.Position(tok, c.End()).Line
-
-				// Work around golang/go#41197 by checking if the comment might
-				// contain "\r", and if so, find the actual end position of the
-				// comment by scanning the content of the file.
-				startOffset, err := safetoken.Offset(tok, c.Pos())
-				if err != nil {
-					return "", err
-				}
-				if startLine != endLine && bytes.Contains(src[startOffset:], []byte("\r")) {
-					if commentEnd := scanForCommentEnd(src[startOffset:]); commentEnd > 0 {
-						end = startOffset + commentEnd
-					}
-				}
-				importEnd = maybeAdjustToLineEnd(tok.Pos(end), true)
-			}
-		}
-	}
-	if importEnd > len(src) {
-		importEnd = len(src)
-	}
-	return string(src[:importEnd]), nil
-}
-
-// scanForCommentEnd returns the offset of the end of the multi-line comment
-// at the start of the given byte slice.
-func scanForCommentEnd(src []byte) int {
-	var s scanner.Scanner
-	s.Init(bytes.NewReader(src))
-	s.Mode ^= scanner.SkipComments
-
-	t := s.Scan()
-	if t == scanner.Comment {
-		return s.Pos().Offset
-	}
-	return 0
-}
-
-func computeTextEdits(ctx context.Context, snapshot Snapshot, pgf *ParsedGoFile, formatted string) ([]protocol.TextEdit, error) {
-	_, done := event.Start(ctx, "source.computeTextEdits")
-	defer done()
-
-	edits := snapshot.View().Options().ComputeEdits(string(pgf.Src), formatted)
-	return ToProtocolEdits(pgf.Mapper, edits)
-}
-
-// protocolEditsFromSource converts text edits to LSP edits using the original
-// source.
-func protocolEditsFromSource(src []byte, edits []diff.Edit, tf *token.File) ([]protocol.TextEdit, error) {
-	m := lsppos.NewMapper(src)
-	var result []protocol.TextEdit
-	for _, edit := range edits {
-		rng, err := m.Range(edit.Start, edit.End)
-		if err != nil {
-			return nil, err
-		}
-
-		if rng.Start == rng.End && edit.New == "" {
-			// Degenerate case, which may result from a diff tool wanting to delete
-			// '\r' in line endings. Filter it out.
-			continue
-		}
-		result = append(result, protocol.TextEdit{
-			Range:   rng,
-			NewText: edit.New,
-		})
-	}
-	return result, nil
-}
-
-// ToProtocolEdits converts diff.Edits to LSP TextEdits.
-// See https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textEditArray
-func ToProtocolEdits(m *protocol.ColumnMapper, edits []diff.Edit) ([]protocol.TextEdit, error) {
-	// LSP doesn't require TextEditArray to be sorted:
-	// this is the receiver's concern. But govim, and perhaps
-	// other clients have historically relied on the order.
-	edits = append([]diff.Edit(nil), edits...)
-	diff.SortEdits(edits)
-
-	result := make([]protocol.TextEdit, len(edits))
-	for i, edit := range edits {
-		rng, err := m.OffsetRange(edit.Start, edit.End)
-		if err != nil {
-			return nil, err
-		}
-		result[i] = protocol.TextEdit{
-			Range:   rng,
-			NewText: edit.New,
-		}
-	}
-	return result, nil
-}
-
-// FromProtocolEdits converts LSP TextEdits to diff.Edits.
-// See https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textEditArray
-func FromProtocolEdits(m *protocol.ColumnMapper, edits []protocol.TextEdit) ([]diff.Edit, error) {
-	if edits == nil {
-		return nil, nil
-	}
-	result := make([]diff.Edit, len(edits))
-	for i, edit := range edits {
-		spn, err := m.RangeSpan(edit.Range)
-		if err != nil {
-			return nil, err
-		}
-		result[i] = diff.Edit{
-			Start: spn.Start().Offset(),
-			End:   spn.End().Offset(),
-			New:   edit.NewText,
-		}
-	}
-	return result, nil
-}
-
-// ApplyProtocolEdits applies the patch (edits) to m.Content and returns the result.
-// It also returns the edits converted to diff-package form.
-func ApplyProtocolEdits(m *protocol.ColumnMapper, edits []protocol.TextEdit) (string, []diff.Edit, error) {
-	diffEdits, err := FromProtocolEdits(m, edits)
-	if err != nil {
-		return "", nil, err
-	}
-	out, err := diff.Apply(string(m.Content), diffEdits)
-	return out, diffEdits, err
-}
diff -urN a/gopls/internal/lsp/source/format_test.go b/gopls/internal/lsp/source/format_test.go
--- a/gopls/internal/lsp/source/format_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/format_test.go	1969-12-31 16:00:00
@@ -1,75 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-)
-
-func TestImportPrefix(t *testing.T) {
-	for i, tt := range []struct {
-		input, want string
-	}{
-		{"package foo", "package foo"},
-		{"package foo\n", "package foo\n"},
-		{"package foo\n\nfunc f(){}\n", "package foo\n"},
-		{"package foo\n\nimport \"fmt\"\n", "package foo\n\nimport \"fmt\""},
-		{"package foo\nimport (\n\"fmt\"\n)\n", "package foo\nimport (\n\"fmt\"\n)"},
-		{"\n\n\npackage foo\n", "\n\n\npackage foo\n"},
-		{"// hi \n\npackage foo //xx\nfunc _(){}\n", "// hi \n\npackage foo //xx\n"},
-		{"package foo //hi\n", "package foo //hi\n"},
-		{"//hi\npackage foo\n//a\n\n//b\n", "//hi\npackage foo\n//a\n\n//b\n"},
-		{
-			"package a\n\nimport (\n  \"fmt\"\n)\n//hi\n",
-			"package a\n\nimport (\n  \"fmt\"\n)\n//hi\n",
-		},
-		{`package a /*hi*/`, `package a /*hi*/`},
-		{"package main\r\n\r\nimport \"go/types\"\r\n\r\n/*\r\n\r\n */\r\n", "package main\r\n\r\nimport \"go/types\"\r\n\r\n/*\r\n\r\n */\r\n"},
-		{"package x; import \"os\"; func f() {}\n\n", "package x; import \"os\""},
-		{"package x; func f() {fmt.Println()}\n\n", "package x"},
-	} {
-		got, err := importPrefix([]byte(tt.input))
-		if err != nil {
-			t.Fatal(err)
-		}
-		if d := compare.Text(tt.want, got); d != "" {
-			t.Errorf("%d: failed for %q:\n%s", i, tt.input, d)
-		}
-	}
-}
-
-func TestCRLFFile(t *testing.T) {
-	for i, tt := range []struct {
-		input, want string
-	}{
-		{
-			input: `package main
-
-/*
-Hi description
-*/
-func Hi() {
-}
-`,
-			want: `package main
-
-/*
-Hi description
-*/`,
-		},
-	} {
-		got, err := importPrefix([]byte(strings.ReplaceAll(tt.input, "\n", "\r\n")))
-		if err != nil {
-			t.Fatal(err)
-		}
-		want := strings.ReplaceAll(tt.want, "\n", "\r\n")
-		if d := compare.Text(want, got); d != "" {
-			t.Errorf("%d: failed for %q:\n%s", i, tt.input, d)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/source/gc_annotations.go b/gopls/internal/lsp/source/gc_annotations.go
--- a/gopls/internal/lsp/source/gc_annotations.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/gc_annotations.go	1969-12-31 16:00:00
@@ -1,214 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/gocommand"
-)
-
-type Annotation string
-
-const (
-	// Nil controls nil checks.
-	Nil Annotation = "nil"
-
-	// Escape controls diagnostics about escape choices.
-	Escape Annotation = "escape"
-
-	// Inline controls diagnostics about inlining choices.
-	Inline Annotation = "inline"
-
-	// Bounds controls bounds checking diagnostics.
-	Bounds Annotation = "bounds"
-)
-
-func GCOptimizationDetails(ctx context.Context, snapshot Snapshot, m *Metadata) (map[VersionedFileIdentity][]*Diagnostic, error) {
-	if len(m.CompiledGoFiles) == 0 {
-		return nil, nil
-	}
-	pkgDir := filepath.Dir(m.CompiledGoFiles[0].Filename())
-	outDir := filepath.Join(os.TempDir(), fmt.Sprintf("gopls-%d.details", os.Getpid()))
-
-	if err := os.MkdirAll(outDir, 0700); err != nil {
-		return nil, err
-	}
-	tmpFile, err := ioutil.TempFile(os.TempDir(), "gopls-x")
-	if err != nil {
-		return nil, err
-	}
-	defer os.Remove(tmpFile.Name())
-
-	outDirURI := span.URIFromPath(outDir)
-	// GC details doesn't handle Windows URIs in the form of "file:///C:/...",
-	// so rewrite them to "file://C:/...". See golang/go#41614.
-	if !strings.HasPrefix(outDir, "/") {
-		outDirURI = span.URI(strings.Replace(string(outDirURI), "file:///", "file://", 1))
-	}
-	inv := &gocommand.Invocation{
-		Verb: "build",
-		Args: []string{
-			fmt.Sprintf("-gcflags=-json=0,%s", outDirURI),
-			fmt.Sprintf("-o=%s", tmpFile.Name()),
-			".",
-		},
-		WorkingDir: pkgDir,
-	}
-	_, err = snapshot.RunGoCommandDirect(ctx, Normal, inv)
-	if err != nil {
-		return nil, err
-	}
-	files, err := findJSONFiles(outDir)
-	if err != nil {
-		return nil, err
-	}
-	reports := make(map[VersionedFileIdentity][]*Diagnostic)
-	opts := snapshot.View().Options()
-	var parseError error
-	for _, fn := range files {
-		uri, diagnostics, err := parseDetailsFile(fn, opts)
-		if err != nil {
-			// expect errors for all the files, save 1
-			parseError = err
-		}
-		fh := snapshot.FindFile(uri)
-		if fh == nil {
-			continue
-		}
-		if pkgDir != filepath.Dir(fh.URI().Filename()) {
-			// https://github.com/golang/go/issues/42198
-			// sometimes the detail diagnostics generated for files
-			// outside the package can never be taken back.
-			continue
-		}
-		reports[fh.VersionedFileIdentity()] = diagnostics
-	}
-	return reports, parseError
-}
-
-func parseDetailsFile(filename string, options *Options) (span.URI, []*Diagnostic, error) {
-	buf, err := ioutil.ReadFile(filename)
-	if err != nil {
-		return "", nil, err
-	}
-	var (
-		uri         span.URI
-		i           int
-		diagnostics []*Diagnostic
-	)
-	type metadata struct {
-		File string `json:"file,omitempty"`
-	}
-	for dec := json.NewDecoder(bytes.NewReader(buf)); dec.More(); {
-		// The first element always contains metadata.
-		if i == 0 {
-			i++
-			m := new(metadata)
-			if err := dec.Decode(m); err != nil {
-				return "", nil, err
-			}
-			if !strings.HasSuffix(m.File, ".go") {
-				continue // <autogenerated>
-			}
-			uri = span.URIFromPath(m.File)
-			continue
-		}
-		d := new(protocol.Diagnostic)
-		if err := dec.Decode(d); err != nil {
-			return "", nil, err
-		}
-		msg := d.Code.(string)
-		if msg != "" {
-			msg = fmt.Sprintf("%s(%s)", msg, d.Message)
-		}
-		if !showDiagnostic(msg, d.Source, options) {
-			continue
-		}
-		var related []RelatedInformation
-		for _, ri := range d.RelatedInformation {
-			related = append(related, RelatedInformation{
-				URI:     ri.Location.URI.SpanURI(),
-				Range:   zeroIndexedRange(ri.Location.Range),
-				Message: ri.Message,
-			})
-		}
-		diagnostic := &Diagnostic{
-			URI:      uri,
-			Range:    zeroIndexedRange(d.Range),
-			Message:  msg,
-			Severity: d.Severity,
-			Source:   OptimizationDetailsError, // d.Source is always "go compiler" as of 1.16, use our own
-			Tags:     d.Tags,
-			Related:  related,
-		}
-		diagnostics = append(diagnostics, diagnostic)
-		i++
-	}
-	return uri, diagnostics, nil
-}
-
-// showDiagnostic reports whether a given diagnostic should be shown to the end
-// user, given the current options.
-func showDiagnostic(msg, source string, o *Options) bool {
-	if source != "go compiler" {
-		return false
-	}
-	if o.Annotations == nil {
-		return true
-	}
-	switch {
-	case strings.HasPrefix(msg, "canInline") ||
-		strings.HasPrefix(msg, "cannotInline") ||
-		strings.HasPrefix(msg, "inlineCall"):
-		return o.Annotations[Inline]
-	case strings.HasPrefix(msg, "escape") || msg == "leak":
-		return o.Annotations[Escape]
-	case strings.HasPrefix(msg, "nilcheck"):
-		return o.Annotations[Nil]
-	case strings.HasPrefix(msg, "isInBounds") ||
-		strings.HasPrefix(msg, "isSliceInBounds"):
-		return o.Annotations[Bounds]
-	}
-	return false
-}
-
-// The range produced by the compiler is 1-indexed, so subtract range by 1.
-func zeroIndexedRange(rng protocol.Range) protocol.Range {
-	return protocol.Range{
-		Start: protocol.Position{
-			Line:      rng.Start.Line - 1,
-			Character: rng.Start.Character - 1,
-		},
-		End: protocol.Position{
-			Line:      rng.End.Line - 1,
-			Character: rng.End.Character - 1,
-		},
-	}
-}
-
-func findJSONFiles(dir string) ([]string, error) {
-	ans := []string{}
-	f := func(path string, fi os.FileInfo, _ error) error {
-		if fi.IsDir() {
-			return nil
-		}
-		if strings.HasSuffix(path, ".json") {
-			ans = append(ans, path)
-		}
-		return nil
-	}
-	err := filepath.Walk(dir, f)
-	return ans, err
-}
diff -urN a/gopls/internal/lsp/source/highlight.go b/gopls/internal/lsp/source/highlight.go
--- a/gopls/internal/lsp/source/highlight.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/highlight.go	1969-12-31 16:00:00
@@ -1,499 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-)
-
-func Highlight(ctx context.Context, snapshot Snapshot, fh FileHandle, position protocol.Position) ([]protocol.Range, error) {
-	ctx, done := event.Start(ctx, "source.Highlight")
-	defer done()
-
-	// We always want fully parsed files for highlight, regardless
-	// of whether the file belongs to a workspace package.
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckFull, WidestPackage)
-	if err != nil {
-		return nil, fmt.Errorf("getting package for Highlight: %w", err)
-	}
-
-	pos, err := pgf.Mapper.Pos(position)
-	if err != nil {
-		return nil, err
-	}
-	path, _ := astutil.PathEnclosingInterval(pgf.File, pos, pos)
-	if len(path) == 0 {
-		return nil, fmt.Errorf("no enclosing position found for %v:%v", position.Line, position.Character)
-	}
-	// If start == end for astutil.PathEnclosingInterval, the 1-char interval
-	// following start is used instead. As a result, we might not get an exact
-	// match so we should check the 1-char interval to the left of the passed
-	// in position to see if that is an exact match.
-	if _, ok := path[0].(*ast.Ident); !ok {
-		if p, _ := astutil.PathEnclosingInterval(pgf.File, pos-1, pos-1); p != nil {
-			switch p[0].(type) {
-			case *ast.Ident, *ast.SelectorExpr:
-				path = p // use preceding ident/selector
-			}
-		}
-	}
-	result, err := highlightPath(pkg, path)
-	if err != nil {
-		return nil, err
-	}
-	var ranges []protocol.Range
-	for rng := range result {
-		mRng, err := posToMappedRange(pkg, rng.start, rng.end)
-		if err != nil {
-			return nil, err
-		}
-		pRng, err := mRng.Range()
-		if err != nil {
-			return nil, err
-		}
-		ranges = append(ranges, pRng)
-	}
-	return ranges, nil
-}
-
-func highlightPath(pkg Package, path []ast.Node) (map[posRange]struct{}, error) {
-	result := make(map[posRange]struct{})
-	switch node := path[0].(type) {
-	case *ast.BasicLit:
-		if len(path) > 1 {
-			if _, ok := path[1].(*ast.ImportSpec); ok {
-				err := highlightImportUses(pkg, path, result)
-				return result, err
-			}
-		}
-		highlightFuncControlFlow(path, result)
-	case *ast.ReturnStmt, *ast.FuncDecl, *ast.FuncType:
-		highlightFuncControlFlow(path, result)
-	case *ast.Ident:
-		highlightIdentifiers(pkg, path, result)
-	case *ast.ForStmt, *ast.RangeStmt:
-		highlightLoopControlFlow(path, result)
-	case *ast.SwitchStmt:
-		highlightSwitchFlow(path, result)
-	case *ast.BranchStmt:
-		// BREAK can exit a loop, switch or select, while CONTINUE exit a loop so
-		// these need to be handled separately. They can also be embedded in any
-		// other loop/switch/select if they have a label. TODO: add support for
-		// GOTO and FALLTHROUGH as well.
-		if node.Label != nil {
-			highlightLabeledFlow(node, result)
-		} else {
-			switch node.Tok {
-			case token.BREAK:
-				highlightUnlabeledBreakFlow(path, result)
-			case token.CONTINUE:
-				highlightLoopControlFlow(path, result)
-			}
-		}
-	default:
-		// If the cursor is in an unidentified area, return empty results.
-		return nil, nil
-	}
-	return result, nil
-}
-
-type posRange struct {
-	start, end token.Pos
-}
-
-func highlightFuncControlFlow(path []ast.Node, result map[posRange]struct{}) {
-	var enclosingFunc ast.Node
-	var returnStmt *ast.ReturnStmt
-	var resultsList *ast.FieldList
-	inReturnList := false
-
-Outer:
-	// Reverse walk the path till we get to the func block.
-	for i, n := range path {
-		switch node := n.(type) {
-		case *ast.KeyValueExpr:
-			// If cursor is in a key: value expr, we don't want control flow highlighting
-			return
-		case *ast.CallExpr:
-			// If cursor is an arg in a callExpr, we don't want control flow highlighting.
-			if i > 0 {
-				for _, arg := range node.Args {
-					if arg == path[i-1] {
-						return
-					}
-				}
-			}
-		case *ast.Field:
-			inReturnList = true
-		case *ast.FuncLit:
-			enclosingFunc = n
-			resultsList = node.Type.Results
-			break Outer
-		case *ast.FuncDecl:
-			enclosingFunc = n
-			resultsList = node.Type.Results
-			break Outer
-		case *ast.ReturnStmt:
-			returnStmt = node
-			// If the cursor is not directly in a *ast.ReturnStmt, then
-			// we need to know if it is within one of the values that is being returned.
-			inReturnList = inReturnList || path[0] != returnStmt
-		}
-	}
-	// Cursor is not in a function.
-	if enclosingFunc == nil {
-		return
-	}
-	// If the cursor is on a "return" or "func" keyword, we should highlight all of the exit
-	// points of the function, including the "return" and "func" keywords.
-	highlightAllReturnsAndFunc := path[0] == returnStmt || path[0] == enclosingFunc
-	switch path[0].(type) {
-	case *ast.Ident, *ast.BasicLit:
-		// Cursor is in an identifier and not in a return statement or in the results list.
-		if returnStmt == nil && !inReturnList {
-			return
-		}
-	case *ast.FuncType:
-		highlightAllReturnsAndFunc = true
-	}
-	// The user's cursor may be within the return statement of a function,
-	// or within the result section of a function's signature.
-	// index := -1
-	var nodes []ast.Node
-	if returnStmt != nil {
-		for _, n := range returnStmt.Results {
-			nodes = append(nodes, n)
-		}
-	} else if resultsList != nil {
-		for _, n := range resultsList.List {
-			nodes = append(nodes, n)
-		}
-	}
-	_, index := nodeAtPos(nodes, path[0].Pos())
-
-	// Highlight the correct argument in the function declaration return types.
-	if resultsList != nil && -1 < index && index < len(resultsList.List) {
-		rng := posRange{
-			start: resultsList.List[index].Pos(),
-			end:   resultsList.List[index].End(),
-		}
-		result[rng] = struct{}{}
-	}
-	// Add the "func" part of the func declaration.
-	if highlightAllReturnsAndFunc {
-		r := posRange{
-			start: enclosingFunc.Pos(),
-			end:   enclosingFunc.Pos() + token.Pos(len("func")),
-		}
-		result[r] = struct{}{}
-	}
-	ast.Inspect(enclosingFunc, func(n ast.Node) bool {
-		// Don't traverse any other functions.
-		switch n.(type) {
-		case *ast.FuncDecl, *ast.FuncLit:
-			return enclosingFunc == n
-		}
-		ret, ok := n.(*ast.ReturnStmt)
-		if !ok {
-			return true
-		}
-		var toAdd ast.Node
-		// Add the entire return statement, applies when highlight the word "return" or "func".
-		if highlightAllReturnsAndFunc {
-			toAdd = n
-		}
-		// Add the relevant field within the entire return statement.
-		if -1 < index && index < len(ret.Results) {
-			toAdd = ret.Results[index]
-		}
-		if toAdd != nil {
-			result[posRange{start: toAdd.Pos(), end: toAdd.End()}] = struct{}{}
-		}
-		return false
-	})
-}
-
-func highlightUnlabeledBreakFlow(path []ast.Node, result map[posRange]struct{}) {
-	// Reverse walk the path until we find closest loop, select, or switch.
-	for _, n := range path {
-		switch n.(type) {
-		case *ast.ForStmt, *ast.RangeStmt:
-			highlightLoopControlFlow(path, result)
-			return // only highlight the innermost statement
-		case *ast.SwitchStmt:
-			highlightSwitchFlow(path, result)
-			return
-		case *ast.SelectStmt:
-			// TODO: add highlight when breaking a select.
-			return
-		}
-	}
-}
-
-func highlightLabeledFlow(node *ast.BranchStmt, result map[posRange]struct{}) {
-	obj := node.Label.Obj
-	if obj == nil || obj.Decl == nil {
-		return
-	}
-	label, ok := obj.Decl.(*ast.LabeledStmt)
-	if !ok {
-		return
-	}
-	switch label.Stmt.(type) {
-	case *ast.ForStmt, *ast.RangeStmt:
-		highlightLoopControlFlow([]ast.Node{label.Stmt, label}, result)
-	case *ast.SwitchStmt:
-		highlightSwitchFlow([]ast.Node{label.Stmt, label}, result)
-	}
-}
-
-func labelFor(path []ast.Node) *ast.Ident {
-	if len(path) > 1 {
-		if n, ok := path[1].(*ast.LabeledStmt); ok {
-			return n.Label
-		}
-	}
-	return nil
-}
-
-func highlightLoopControlFlow(path []ast.Node, result map[posRange]struct{}) {
-	var loop ast.Node
-	var loopLabel *ast.Ident
-	stmtLabel := labelFor(path)
-Outer:
-	// Reverse walk the path till we get to the for loop.
-	for i := range path {
-		switch n := path[i].(type) {
-		case *ast.ForStmt, *ast.RangeStmt:
-			loopLabel = labelFor(path[i:])
-
-			if stmtLabel == nil || loopLabel == stmtLabel {
-				loop = n
-				break Outer
-			}
-		}
-	}
-	if loop == nil {
-		return
-	}
-
-	// Add the for statement.
-	rng := posRange{
-		start: loop.Pos(),
-		end:   loop.Pos() + token.Pos(len("for")),
-	}
-	result[rng] = struct{}{}
-
-	// Traverse AST to find branch statements within the same for-loop.
-	ast.Inspect(loop, func(n ast.Node) bool {
-		switch n.(type) {
-		case *ast.ForStmt, *ast.RangeStmt:
-			return loop == n
-		case *ast.SwitchStmt, *ast.SelectStmt:
-			return false
-		}
-		b, ok := n.(*ast.BranchStmt)
-		if !ok {
-			return true
-		}
-		if b.Label == nil || labelDecl(b.Label) == loopLabel {
-			result[posRange{start: b.Pos(), end: b.End()}] = struct{}{}
-		}
-		return true
-	})
-
-	// Find continue statements in the same loop or switches/selects.
-	ast.Inspect(loop, func(n ast.Node) bool {
-		switch n.(type) {
-		case *ast.ForStmt, *ast.RangeStmt:
-			return loop == n
-		}
-
-		if n, ok := n.(*ast.BranchStmt); ok && n.Tok == token.CONTINUE {
-			result[posRange{start: n.Pos(), end: n.End()}] = struct{}{}
-		}
-		return true
-	})
-
-	// We don't need to check other for loops if we aren't looking for labeled statements.
-	if loopLabel == nil {
-		return
-	}
-
-	// Find labeled branch statements in any loop.
-	ast.Inspect(loop, func(n ast.Node) bool {
-		b, ok := n.(*ast.BranchStmt)
-		if !ok {
-			return true
-		}
-		// statement with labels that matches the loop
-		if b.Label != nil && labelDecl(b.Label) == loopLabel {
-			result[posRange{start: b.Pos(), end: b.End()}] = struct{}{}
-		}
-		return true
-	})
-}
-
-func highlightSwitchFlow(path []ast.Node, result map[posRange]struct{}) {
-	var switchNode ast.Node
-	var switchNodeLabel *ast.Ident
-	stmtLabel := labelFor(path)
-Outer:
-	// Reverse walk the path till we get to the switch statement.
-	for i := range path {
-		switch n := path[i].(type) {
-		case *ast.SwitchStmt:
-			switchNodeLabel = labelFor(path[i:])
-			if stmtLabel == nil || switchNodeLabel == stmtLabel {
-				switchNode = n
-				break Outer
-			}
-		}
-	}
-	// Cursor is not in a switch statement
-	if switchNode == nil {
-		return
-	}
-
-	// Add the switch statement.
-	rng := posRange{
-		start: switchNode.Pos(),
-		end:   switchNode.Pos() + token.Pos(len("switch")),
-	}
-	result[rng] = struct{}{}
-
-	// Traverse AST to find break statements within the same switch.
-	ast.Inspect(switchNode, func(n ast.Node) bool {
-		switch n.(type) {
-		case *ast.SwitchStmt:
-			return switchNode == n
-		case *ast.ForStmt, *ast.RangeStmt, *ast.SelectStmt:
-			return false
-		}
-
-		b, ok := n.(*ast.BranchStmt)
-		if !ok || b.Tok != token.BREAK {
-			return true
-		}
-
-		if b.Label == nil || labelDecl(b.Label) == switchNodeLabel {
-			result[posRange{start: b.Pos(), end: b.End()}] = struct{}{}
-		}
-		return true
-	})
-
-	// We don't need to check other switches if we aren't looking for labeled statements.
-	if switchNodeLabel == nil {
-		return
-	}
-
-	// Find labeled break statements in any switch
-	ast.Inspect(switchNode, func(n ast.Node) bool {
-		b, ok := n.(*ast.BranchStmt)
-		if !ok || b.Tok != token.BREAK {
-			return true
-		}
-
-		if b.Label != nil && labelDecl(b.Label) == switchNodeLabel {
-			result[posRange{start: b.Pos(), end: b.End()}] = struct{}{}
-		}
-
-		return true
-	})
-}
-
-func labelDecl(n *ast.Ident) *ast.Ident {
-	if n == nil {
-		return nil
-	}
-	if n.Obj == nil {
-		return nil
-	}
-	if n.Obj.Decl == nil {
-		return nil
-	}
-	stmt, ok := n.Obj.Decl.(*ast.LabeledStmt)
-	if !ok {
-		return nil
-	}
-	return stmt.Label
-}
-
-func highlightImportUses(pkg Package, path []ast.Node, result map[posRange]struct{}) error {
-	basicLit, ok := path[0].(*ast.BasicLit)
-	if !ok {
-		return fmt.Errorf("highlightImportUses called with an ast.Node of type %T", basicLit)
-	}
-	ast.Inspect(path[len(path)-1], func(node ast.Node) bool {
-		if imp, ok := node.(*ast.ImportSpec); ok && imp.Path == basicLit {
-			result[posRange{start: node.Pos(), end: node.End()}] = struct{}{}
-			return false
-		}
-		n, ok := node.(*ast.Ident)
-		if !ok {
-			return true
-		}
-		obj, ok := pkg.GetTypesInfo().ObjectOf(n).(*types.PkgName)
-		if !ok {
-			return true
-		}
-		if !strings.Contains(basicLit.Value, obj.Name()) {
-			return true
-		}
-		result[posRange{start: n.Pos(), end: n.End()}] = struct{}{}
-		return false
-	})
-	return nil
-}
-
-func highlightIdentifiers(pkg Package, path []ast.Node, result map[posRange]struct{}) error {
-	id, ok := path[0].(*ast.Ident)
-	if !ok {
-		return fmt.Errorf("highlightIdentifiers called with an ast.Node of type %T", id)
-	}
-	// Check if ident is inside return or func decl.
-	highlightFuncControlFlow(path, result)
-
-	// TODO: maybe check if ident is a reserved word, if true then don't continue and return results.
-
-	idObj := pkg.GetTypesInfo().ObjectOf(id)
-	pkgObj, isImported := idObj.(*types.PkgName)
-	ast.Inspect(path[len(path)-1], func(node ast.Node) bool {
-		if imp, ok := node.(*ast.ImportSpec); ok && isImported {
-			highlightImport(pkgObj, imp, result)
-		}
-		n, ok := node.(*ast.Ident)
-		if !ok {
-			return true
-		}
-		if n.Name != id.Name {
-			return false
-		}
-		if nObj := pkg.GetTypesInfo().ObjectOf(n); nObj == idObj {
-			result[posRange{start: n.Pos(), end: n.End()}] = struct{}{}
-		}
-		return false
-	})
-	return nil
-}
-
-func highlightImport(obj *types.PkgName, imp *ast.ImportSpec, result map[posRange]struct{}) {
-	if imp.Name != nil || imp.Path == nil {
-		return
-	}
-	if !strings.Contains(imp.Path.Value, obj.Name()) {
-		return
-	}
-	result[posRange{start: imp.Path.Pos(), end: imp.Path.End()}] = struct{}{}
-}
diff -urN a/gopls/internal/lsp/source/hover.go b/gopls/internal/lsp/source/hover.go
--- a/gopls/internal/lsp/source/hover.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/hover.go	1969-12-31 16:00:00
@@ -1,987 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"encoding/json"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/constant"
-	"go/doc"
-	"go/format"
-	"go/token"
-	"go/types"
-	"strconv"
-	"strings"
-	"time"
-	"unicode/utf8"
-
-	"golang.org/x/text/unicode/runenames"
-	"golang.org/x/tools/go/types/typeutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// HoverContext contains context extracted from the syntax and type information
-// of a given node, for use in various summaries (hover, autocomplete,
-// signature help).
-type HoverContext struct {
-	// signatureSource is the object or node use to derive the hover signature.
-	//
-	// It may also hold a precomputed string.
-	// TODO(rfindley): pre-compute all signatures to avoid this indirection.
-	signatureSource interface{}
-
-	// comment is the most relevant comment group associated with the hovered object.
-	Comment *ast.CommentGroup
-}
-
-// HoverJSON contains information used by hover. It is also the JSON returned
-// for the "structured" hover format
-type HoverJSON struct {
-	// Synopsis is a single sentence synopsis of the symbol's documentation.
-	Synopsis string `json:"synopsis"`
-
-	// FullDocumentation is the symbol's full documentation.
-	FullDocumentation string `json:"fullDocumentation"`
-
-	// Signature is the symbol's signature.
-	Signature string `json:"signature"`
-
-	// SingleLine is a single line describing the symbol.
-	// This is recommended only for use in clients that show a single line for hover.
-	SingleLine string `json:"singleLine"`
-
-	// SymbolName is the types.Object.Name for the given symbol.
-	SymbolName string `json:"symbolName"`
-
-	// LinkPath is the pkg.go.dev link for the given symbol.
-	// For example, the "go/ast" part of "pkg.go.dev/go/ast#Node".
-	LinkPath string `json:"linkPath"`
-
-	// LinkAnchor is the pkg.go.dev link anchor for the given symbol.
-	// For example, the "Node" part of "pkg.go.dev/go/ast#Node".
-	LinkAnchor string `json:"linkAnchor"`
-}
-
-func Hover(ctx context.Context, snapshot Snapshot, fh FileHandle, position protocol.Position) (*protocol.Hover, error) {
-	ident, err := Identifier(ctx, snapshot, fh, position)
-	if err != nil {
-		if hover, innerErr := hoverRune(ctx, snapshot, fh, position); innerErr == nil {
-			return hover, nil
-		}
-		return nil, nil
-	}
-	h, err := HoverIdentifier(ctx, ident)
-	if err != nil {
-		return nil, err
-	}
-	rng, err := ident.Range()
-	if err != nil {
-		return nil, err
-	}
-	hover, err := FormatHover(h, snapshot.View().Options())
-	if err != nil {
-		return nil, err
-	}
-	return &protocol.Hover{
-		Contents: protocol.MarkupContent{
-			Kind:  snapshot.View().Options().PreferredContentFormat,
-			Value: hover,
-		},
-		Range: rng,
-	}, nil
-}
-
-func hoverRune(ctx context.Context, snapshot Snapshot, fh FileHandle, position protocol.Position) (*protocol.Hover, error) {
-	ctx, done := event.Start(ctx, "source.hoverRune")
-	defer done()
-
-	r, mrng, err := findRune(ctx, snapshot, fh, position)
-	if err != nil {
-		return nil, err
-	}
-	rng, err := mrng.Range()
-	if err != nil {
-		return nil, err
-	}
-
-	var desc string
-	runeName := runenames.Name(r)
-	if len(runeName) > 0 && runeName[0] == '<' {
-		// Check if the rune looks like an HTML tag. If so, trim the surrounding <>
-		// characters to work around https://github.com/microsoft/vscode/issues/124042.
-		runeName = strings.TrimRight(runeName[1:], ">")
-	}
-	if strconv.IsPrint(r) {
-		desc = fmt.Sprintf("'%s', U+%04X, %s", string(r), uint32(r), runeName)
-	} else {
-		desc = fmt.Sprintf("U+%04X, %s", uint32(r), runeName)
-	}
-	return &protocol.Hover{
-		Contents: protocol.MarkupContent{
-			Kind:  snapshot.View().Options().PreferredContentFormat,
-			Value: desc,
-		},
-		Range: rng,
-	}, nil
-}
-
-// ErrNoRuneFound is the error returned when no rune is found at a particular position.
-var ErrNoRuneFound = errors.New("no rune found")
-
-// findRune returns rune information for a position in a file.
-func findRune(ctx context.Context, snapshot Snapshot, fh FileHandle, position protocol.Position) (rune, MappedRange, error) {
-	fh, err := snapshot.GetFile(ctx, fh.URI())
-	if err != nil {
-		return 0, MappedRange{}, err
-	}
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return 0, MappedRange{}, err
-	}
-	pos, err := pgf.Mapper.Pos(position)
-	if err != nil {
-		return 0, MappedRange{}, err
-	}
-
-	// Find the basic literal enclosing the given position, if there is one.
-	var lit *ast.BasicLit
-	ast.Inspect(pgf.File, func(n ast.Node) bool {
-		if n == nil || // pop
-			lit != nil || // found: terminate the search
-			!(n.Pos() <= pos && pos < n.End()) { // subtree does not contain pos: skip
-			return false
-		}
-		if n, ok := n.(*ast.BasicLit); ok {
-			lit = n // found!
-		}
-		return lit == nil // descend unless target is found
-	})
-	if lit == nil {
-		return 0, MappedRange{}, ErrNoRuneFound
-	}
-
-	var r rune
-	var start, end token.Pos
-	switch lit.Kind {
-	case token.CHAR:
-		s, err := strconv.Unquote(lit.Value)
-		if err != nil {
-			// If the conversion fails, it's because of an invalid syntax, therefore
-			// there is no rune to be found.
-			return 0, MappedRange{}, ErrNoRuneFound
-		}
-		r, _ = utf8.DecodeRuneInString(s)
-		if r == utf8.RuneError {
-			return 0, MappedRange{}, fmt.Errorf("rune error")
-		}
-		start, end = lit.Pos(), lit.End()
-	case token.INT:
-		// It's an integer, scan only if it is a hex litteral whose bitsize in
-		// ranging from 8 to 32.
-		if !(strings.HasPrefix(lit.Value, "0x") && len(lit.Value[2:]) >= 2 && len(lit.Value[2:]) <= 8) {
-			return 0, MappedRange{}, ErrNoRuneFound
-		}
-		v, err := strconv.ParseUint(lit.Value[2:], 16, 32)
-		if err != nil {
-			return 0, MappedRange{}, err
-		}
-		r = rune(v)
-		if r == utf8.RuneError {
-			return 0, MappedRange{}, fmt.Errorf("rune error")
-		}
-		start, end = lit.Pos(), lit.End()
-	case token.STRING:
-		// It's a string, scan only if it contains a unicode escape sequence under or before the
-		// current cursor position.
-		var found bool
-		litOffset, err := safetoken.Offset(pgf.Tok, lit.Pos())
-		if err != nil {
-			return 0, MappedRange{}, err
-		}
-		offset, err := safetoken.Offset(pgf.Tok, pos)
-		if err != nil {
-			return 0, MappedRange{}, err
-		}
-		for i := offset - litOffset; i > 0; i-- {
-			// Start at the cursor position and search backward for the beginning of a rune escape sequence.
-			rr, _ := utf8.DecodeRuneInString(lit.Value[i:])
-			if rr == utf8.RuneError {
-				return 0, MappedRange{}, fmt.Errorf("rune error")
-			}
-			if rr == '\\' {
-				// Got the beginning, decode it.
-				var tail string
-				r, _, tail, err = strconv.UnquoteChar(lit.Value[i:], '"')
-				if err != nil {
-					// If the conversion fails, it's because of an invalid syntax, therefore is no rune to be found.
-					return 0, MappedRange{}, ErrNoRuneFound
-				}
-				// Only the rune escape sequence part of the string has to be highlighted, recompute the range.
-				runeLen := len(lit.Value) - (int(i) + len(tail))
-				start = token.Pos(int(lit.Pos()) + int(i))
-				end = token.Pos(int(start) + runeLen)
-				found = true
-				break
-			}
-		}
-		if !found {
-			// No escape sequence found
-			return 0, MappedRange{}, ErrNoRuneFound
-		}
-	default:
-		return 0, MappedRange{}, ErrNoRuneFound
-	}
-	return r, NewMappedRange(pgf.Mapper, start, end), nil
-}
-
-func HoverIdentifier(ctx context.Context, i *IdentifierInfo) (*HoverJSON, error) {
-	ctx, done := event.Start(ctx, "source.Hover")
-	defer done()
-
-	hoverCtx, err := FindHoverContext(ctx, i.Snapshot, i.pkg, i.Declaration.obj, i.Declaration.node, i.Declaration.fullDecl)
-	if err != nil {
-		return nil, err
-	}
-
-	h := &HoverJSON{
-		FullDocumentation: hoverCtx.Comment.Text(),
-		Synopsis:          doc.Synopsis(hoverCtx.Comment.Text()),
-	}
-
-	fset := i.pkg.FileSet()
-	// Determine the symbol's signature.
-	switch x := hoverCtx.signatureSource.(type) {
-	case string:
-		h.Signature = x // a pre-computed signature
-
-	case *ast.TypeSpec:
-		x2 := *x
-		// Don't duplicate comments when formatting type specs.
-		x2.Doc = nil
-		x2.Comment = nil
-		var b strings.Builder
-		b.WriteString("type ")
-		if err := format.Node(&b, fset, &x2); err != nil {
-			return nil, err
-		}
-
-		// Display the declared methods accessible from the identifier.
-		//
-		// (The format.Node call above displays any struct fields, public
-		// or private, in syntactic form. We choose not to recursively
-		// enumerate any fields and methods promoted from them.)
-		obj := i.Type.Object
-		if obj != nil && !types.IsInterface(obj.Type()) {
-			sep := "\n\n"
-			for _, m := range typeutil.IntuitiveMethodSet(obj.Type(), nil) {
-				if (m.Obj().Exported() || m.Obj().Pkg() == i.pkg.GetTypes()) && len(m.Index()) == 1 {
-					b.WriteString(sep)
-					sep = "\n"
-					b.WriteString(objectString(m.Obj(), i.qf, nil))
-				}
-			}
-		}
-
-		h.Signature = b.String()
-
-	case ast.Node:
-		var b strings.Builder
-		if err := format.Node(&b, fset, x); err != nil {
-			return nil, err
-		}
-		h.Signature = b.String()
-
-		// Check if the variable is an integer whose value we can present in a more
-		// user-friendly way, i.e. `var hex = 0xe34e` becomes `var hex = 58190`
-		if spec, ok := x.(*ast.ValueSpec); ok && len(spec.Values) > 0 {
-			if lit, ok := spec.Values[0].(*ast.BasicLit); ok && len(spec.Names) > 0 {
-				val := constant.MakeFromLiteral(types.ExprString(lit), lit.Kind, 0)
-				h.Signature = fmt.Sprintf("var %s = %s", spec.Names[0], val)
-			}
-		}
-
-	case types.Object:
-		// If the variable is implicitly declared in a type switch, we need to
-		// manually generate its object string.
-		if typ := i.Declaration.typeSwitchImplicit; typ != nil {
-			if v, ok := x.(*types.Var); ok {
-				h.Signature = fmt.Sprintf("var %s %s", v.Name(), types.TypeString(typ, i.qf))
-				break
-			}
-		}
-		h.Signature = objectString(x, i.qf, i.Inferred)
-	}
-	if obj := i.Declaration.obj; obj != nil {
-		h.SingleLine = objectString(obj, i.qf, nil)
-	}
-	obj := i.Declaration.obj
-	if obj == nil {
-		return h, nil
-	}
-
-	// Check if the identifier is test-only (and is therefore not part of a
-	// package's API). This is true if the request originated in a test package,
-	// and if the declaration is also found in the same test package.
-	if i.pkg != nil && obj.Pkg() != nil && i.pkg.ForTest() != "" {
-		if _, err := i.pkg.File(i.Declaration.MappedRange[0].URI()); err == nil {
-			return h, nil
-		}
-	}
-
-	h.SymbolName, h.LinkPath, h.LinkAnchor = linkData(obj, i.enclosing)
-
-	// See golang/go#36998: don't link to modules matching GOPRIVATE.
-	//
-	// The path returned by linkData is a package path.
-	if i.Snapshot.View().IsGoPrivatePath(h.LinkPath) {
-		h.LinkPath = ""
-	} else if mod, version, ok := moduleAtVersion(h.LinkPath, i); ok {
-		h.LinkPath = strings.Replace(h.LinkPath, mod, mod+"@"+version, 1)
-	}
-
-	return h, nil
-}
-
-// linkData returns the name, package path, and anchor to use in building links
-// to obj.
-//
-// If obj is not visible in documentation, the returned name will be empty.
-func linkData(obj types.Object, enclosing *types.TypeName) (name, packagePath, anchor string) {
-	// Package names simply link to the package.
-	if obj, ok := obj.(*types.PkgName); ok {
-		return obj.Name(), obj.Imported().Path(), ""
-	}
-
-	// Builtins link to the special builtin package.
-	if obj.Parent() == types.Universe {
-		return obj.Name(), "builtin", obj.Name()
-	}
-
-	// In all other cases, the object must be exported.
-	if !obj.Exported() {
-		return "", "", ""
-	}
-
-	var recv types.Object // If non-nil, the field or method receiver base.
-
-	switch obj := obj.(type) {
-	case *types.Var:
-		// If the object is a field, and we have an associated selector
-		// composite literal, or struct, we can determine the link.
-		if obj.IsField() && enclosing != nil {
-			recv = enclosing
-		}
-	case *types.Func:
-		typ, ok := obj.Type().(*types.Signature)
-		if !ok {
-			// Note: this should never happen. go/types guarantees that the type of
-			// *Funcs are Signatures.
-			//
-			// TODO(rfindley): given a 'debug' mode, we should panic here.
-			return "", "", ""
-		}
-		if r := typ.Recv(); r != nil {
-			if rtyp, _ := Deref(r.Type()).(*types.Named); rtyp != nil {
-				// If we have an unexported type, see if the enclosing type is
-				// exported (we may have an interface or struct we can link
-				// to). If not, don't show any link.
-				if !rtyp.Obj().Exported() {
-					if enclosing != nil {
-						recv = enclosing
-					} else {
-						return "", "", ""
-					}
-				} else {
-					recv = rtyp.Obj()
-				}
-			}
-		}
-	}
-
-	if recv != nil && !recv.Exported() {
-		return "", "", ""
-	}
-
-	// Either the object or its receiver must be in the package scope.
-	scopeObj := obj
-	if recv != nil {
-		scopeObj = recv
-	}
-	if scopeObj.Pkg() == nil || scopeObj.Pkg().Scope().Lookup(scopeObj.Name()) != scopeObj {
-		return "", "", ""
-	}
-
-	// golang/go#52211: somehow we get here with a nil obj.Pkg
-	if obj.Pkg() == nil {
-		bug.Report("object with nil pkg", bug.Data{
-			"name": obj.Name(),
-			"type": fmt.Sprintf("%T", obj),
-		})
-		return "", "", ""
-	}
-
-	packagePath = obj.Pkg().Path()
-	if recv != nil {
-		anchor = fmt.Sprintf("%s.%s", recv.Name(), obj.Name())
-		name = fmt.Sprintf("(%s.%s).%s", obj.Pkg().Name(), recv.Name(), obj.Name())
-	} else {
-		// For most cases, the link is "package/path#symbol".
-		anchor = obj.Name()
-		name = fmt.Sprintf("%s.%s", obj.Pkg().Name(), obj.Name())
-	}
-	return name, packagePath, anchor
-}
-
-func moduleAtVersion(path string, i *IdentifierInfo) (string, string, bool) {
-	// TODO(rfindley): moduleAtVersion should not be responsible for deciding
-	// whether or not the link target supports module version links.
-	if strings.ToLower(i.Snapshot.View().Options().LinkTarget) != "pkg.go.dev" {
-		return "", "", false
-	}
-	impPkg, err := i.pkg.DirectDep(PackagePath(path))
-	if err != nil {
-		return "", "", false
-	}
-	if impPkg.Version() == nil {
-		return "", "", false
-	}
-	version, modpath := impPkg.Version().Version, impPkg.Version().Path
-	if modpath == "" || version == "" {
-		return "", "", false
-	}
-	return modpath, version, true
-}
-
-// objectString is a wrapper around the types.ObjectString function.
-// It handles adding more information to the object string.
-func objectString(obj types.Object, qf types.Qualifier, inferred *types.Signature) string {
-	// If the signature type was inferred, prefer the preferred signature with a
-	// comment showing the generic signature.
-	if sig, _ := obj.Type().(*types.Signature); sig != nil && typeparams.ForSignature(sig).Len() > 0 && inferred != nil {
-		obj2 := types.NewFunc(obj.Pos(), obj.Pkg(), obj.Name(), inferred)
-		str := types.ObjectString(obj2, qf)
-		// Try to avoid overly long lines.
-		if len(str) > 60 {
-			str += "\n"
-		} else {
-			str += " "
-		}
-		str += "// " + types.TypeString(sig, qf)
-		return str
-	}
-	str := types.ObjectString(obj, qf)
-	switch obj := obj.(type) {
-	case *types.Const:
-		str = fmt.Sprintf("%s = %s", str, obj.Val())
-
-		// Try to add a formatted duration as an inline comment
-		typ, ok := obj.Type().(*types.Named)
-		if !ok {
-			break
-		}
-		pkg := typ.Obj().Pkg()
-		if pkg.Path() == "time" && typ.Obj().Name() == "Duration" {
-			if d, ok := constant.Int64Val(obj.Val()); ok {
-				str += " // " + time.Duration(d).String()
-			}
-		}
-	}
-	return str
-}
-
-// FindHoverContext returns a HoverContext struct for an AST node and its
-// declaration object. node should be the actual node used in type checking,
-// while fullNode could be a separate node with more complete syntactic
-// information.
-func FindHoverContext(ctx context.Context, s Snapshot, pkg Package, obj types.Object, pkgNode ast.Node, fullDecl ast.Decl) (*HoverContext, error) {
-	var info *HoverContext
-
-	// Type parameters get their signature from their declaration object.
-	if _, isTypeName := obj.(*types.TypeName); isTypeName {
-		if _, isTypeParam := obj.Type().(*typeparams.TypeParam); isTypeParam {
-			return &HoverContext{signatureSource: obj}, nil
-		}
-	}
-
-	// This is problematic for a number of reasons. We really need to have a more
-	// general mechanism to validate the coherency of AST with type information,
-	// but absent that we must do our best to ensure that we don't use fullNode
-	// when we actually need the node that was type checked.
-	//
-	// pkgNode may be nil, if it was eliminated from the type-checked syntax. In
-	// that case, use fullDecl if available.
-	node := pkgNode
-	if node == nil && fullDecl != nil {
-		node = fullDecl
-	}
-
-	switch node := node.(type) {
-	case *ast.Ident:
-		// The package declaration.
-		for _, f := range pkg.GetSyntax() {
-			if f.Name == pkgNode {
-				info = &HoverContext{Comment: f.Doc}
-			}
-		}
-	case *ast.ImportSpec:
-		// Try to find the package documentation for an imported package.
-		importPath, err := strconv.Unquote(node.Path.Value)
-		if err != nil {
-			return nil, err
-		}
-		imp, err := pkg.ResolveImportPath(ImportPath(importPath))
-		if err != nil {
-			return nil, err
-		}
-		// Assume that only one file will contain package documentation,
-		// so pick the first file that has a doc comment.
-		for _, file := range imp.GetSyntax() {
-			if file.Doc != nil {
-				info = &HoverContext{Comment: file.Doc}
-				if file.Name != nil {
-					info.signatureSource = "package " + file.Name.Name
-				}
-				break
-			}
-		}
-	case *ast.GenDecl:
-		switch obj := obj.(type) {
-		case *types.TypeName, *types.Var, *types.Const, *types.Func:
-			// Always use the full declaration here if we have it, because the
-			// dependent code doesn't rely on pointer identity. This is fragile.
-			if d, _ := fullDecl.(*ast.GenDecl); d != nil {
-				node = d
-			}
-			// obj may not have been produced by type checking the AST containing
-			// node, so we need to be careful about using token.Pos.
-			tok := pkg.FileSet().File(obj.Pos())
-			offset, err := safetoken.Offset(tok, obj.Pos())
-			if err != nil {
-				return nil, err
-			}
-
-			// fullTok and fullPos are the *token.File and object position in for the
-			// full AST.
-			fullTok := pkg.FileSet().File(node.Pos())
-			fullPos, err := safetoken.Pos(fullTok, offset)
-			if err != nil {
-				return nil, err
-			}
-
-			var spec ast.Spec
-			for _, s := range node.Specs {
-				// Avoid panics by guarding the calls to token.Offset (golang/go#48249).
-				start, err := safetoken.Offset(fullTok, s.Pos())
-				if err != nil {
-					return nil, err
-				}
-				end, err := safetoken.Offset(fullTok, s.End())
-				if err != nil {
-					return nil, err
-				}
-				if start <= offset && offset <= end {
-					spec = s
-					break
-				}
-			}
-
-			info, err = hoverGenDecl(node, spec, fullPos, obj)
-			if err != nil {
-				return nil, err
-			}
-		}
-	case *ast.TypeSpec:
-		if obj.Parent() == types.Universe {
-			if genDecl, ok := fullDecl.(*ast.GenDecl); ok {
-				info = hoverTypeSpec(node, genDecl)
-			}
-		}
-	case *ast.FuncDecl:
-		switch obj.(type) {
-		case *types.Func:
-			info = &HoverContext{signatureSource: obj, Comment: node.Doc}
-		case *types.Builtin:
-			info = &HoverContext{Comment: node.Doc}
-			if sig, err := NewBuiltinSignature(ctx, s, obj.Name()); err == nil {
-				info.signatureSource = "func " + sig.name + sig.Format()
-			} else {
-				// Fall back on the object as a signature source.
-				bug.Report("invalid builtin hover", bug.Data{
-					"err": err.Error(),
-				})
-				info.signatureSource = obj
-			}
-		case *types.Var:
-			// Object is a function param or the field of an anonymous struct
-			// declared with ':='. Skip the first one because only fields
-			// can have docs.
-			if isFunctionParam(obj, node) {
-				break
-			}
-
-			_, field := FindDeclAndField(pkg.GetSyntax(), obj.Pos())
-			if field != nil {
-				comment := field.Doc
-				if comment.Text() == "" {
-					comment = field.Comment
-				}
-				info = &HoverContext{signatureSource: obj, Comment: comment}
-			}
-		}
-	}
-
-	if info == nil {
-		info = &HoverContext{signatureSource: obj}
-	}
-
-	return info, nil
-}
-
-// isFunctionParam returns true if the passed object is either an incoming
-// or an outgoing function param
-func isFunctionParam(obj types.Object, node *ast.FuncDecl) bool {
-	for _, f := range node.Type.Params.List {
-		if f.Pos() == obj.Pos() {
-			return true
-		}
-	}
-	if node.Type.Results != nil {
-		for _, f := range node.Type.Results.List {
-			if f.Pos() == obj.Pos() {
-				return true
-			}
-		}
-	}
-	return false
-}
-
-// hoverGenDecl returns hover information an object declared via spec inside
-// of the GenDecl node. obj is the type-checked object corresponding to the
-// declaration, but may have been type-checked using a different AST than the
-// given nodes; fullPos is the position of obj in node's AST.
-func hoverGenDecl(node *ast.GenDecl, spec ast.Spec, fullPos token.Pos, obj types.Object) (*HoverContext, error) {
-	if spec == nil {
-		return nil, fmt.Errorf("no spec for node %v at position %v", node, fullPos)
-	}
-
-	// If we have a field or method.
-	switch obj.(type) {
-	case *types.Var, *types.Const, *types.Func:
-		return hoverVar(spec, fullPos, obj, node), nil
-	}
-	// Handle types.
-	switch spec := spec.(type) {
-	case *ast.TypeSpec:
-		return hoverTypeSpec(spec, node), nil
-	case *ast.ValueSpec:
-		return &HoverContext{signatureSource: spec, Comment: spec.Doc}, nil
-	case *ast.ImportSpec:
-		return &HoverContext{signatureSource: spec, Comment: spec.Doc}, nil
-	}
-	return nil, fmt.Errorf("unable to format spec %v (%T)", spec, spec)
-}
-
-// TODO(rfindley): rename this function.
-func hoverTypeSpec(spec *ast.TypeSpec, decl *ast.GenDecl) *HoverContext {
-	comment := spec.Doc
-	if comment == nil && decl != nil {
-		comment = decl.Doc
-	}
-	if comment == nil {
-		comment = spec.Comment
-	}
-	return &HoverContext{
-		signatureSource: spec,
-		Comment:         comment,
-	}
-}
-
-func hoverVar(node ast.Spec, fullPos token.Pos, obj types.Object, decl *ast.GenDecl) *HoverContext {
-	var fieldList *ast.FieldList
-	switch spec := node.(type) {
-	case *ast.TypeSpec:
-		switch t := spec.Type.(type) {
-		case *ast.StructType:
-			fieldList = t.Fields
-		case *ast.InterfaceType:
-			fieldList = t.Methods
-		}
-	case *ast.ValueSpec:
-		// Try to extract the field list of an anonymous struct
-		if fieldList = extractFieldList(spec.Type); fieldList != nil {
-			break
-		}
-
-		comment := spec.Doc
-		if comment == nil {
-			comment = decl.Doc
-		}
-		if comment == nil {
-			comment = spec.Comment
-		}
-
-		// We need the AST nodes for variable declarations of basic literals with
-		// associated values so that we can augment their hover with more information.
-		if _, ok := obj.(*types.Var); ok && spec.Type == nil && len(spec.Values) > 0 {
-			if _, ok := spec.Values[0].(*ast.BasicLit); ok {
-				return &HoverContext{signatureSource: spec, Comment: comment}
-			}
-		}
-
-		return &HoverContext{signatureSource: obj, Comment: comment}
-	}
-
-	if fieldList != nil {
-		comment := findFieldComment(fullPos, fieldList)
-		return &HoverContext{signatureSource: obj, Comment: comment}
-	}
-	return &HoverContext{signatureSource: obj, Comment: decl.Doc}
-}
-
-// extractFieldList recursively tries to extract a field list.
-// If it is not found, nil is returned.
-func extractFieldList(specType ast.Expr) *ast.FieldList {
-	switch t := specType.(type) {
-	case *ast.StructType:
-		return t.Fields
-	case *ast.InterfaceType:
-		return t.Methods
-	case *ast.ArrayType:
-		return extractFieldList(t.Elt)
-	case *ast.MapType:
-		// Map value has a greater chance to be a struct
-		if fields := extractFieldList(t.Value); fields != nil {
-			return fields
-		}
-		return extractFieldList(t.Key)
-	case *ast.ChanType:
-		return extractFieldList(t.Value)
-	}
-	return nil
-}
-
-// findFieldComment visits all fields in depth-first order and returns
-// the comment of a field with passed position. If no comment is found,
-// nil is returned.
-func findFieldComment(pos token.Pos, fieldList *ast.FieldList) *ast.CommentGroup {
-	for _, field := range fieldList.List {
-		if field.Pos() == pos {
-			if field.Doc.Text() != "" {
-				return field.Doc
-			}
-			return field.Comment
-		}
-
-		if nestedFieldList := extractFieldList(field.Type); nestedFieldList != nil {
-			if c := findFieldComment(pos, nestedFieldList); c != nil {
-				return c
-			}
-		}
-	}
-	return nil
-}
-
-func FormatHover(h *HoverJSON, options *Options) (string, error) {
-	signature := formatSignature(h, options)
-
-	switch options.HoverKind {
-	case SingleLine:
-		return h.SingleLine, nil
-	case NoDocumentation:
-		return signature, nil
-	case Structured:
-		b, err := json.Marshal(h)
-		if err != nil {
-			return "", err
-		}
-		return string(b), nil
-	}
-
-	link := formatLink(h, options)
-	doc := formatDoc(h, options)
-
-	var b strings.Builder
-	parts := []string{signature, doc, link}
-	for i, el := range parts {
-		if el != "" {
-			b.WriteString(el)
-
-			// If any elements of the remainder of the list are non-empty,
-			// write an extra newline.
-			if anyNonEmpty(parts[i+1:]) {
-				if options.PreferredContentFormat == protocol.Markdown {
-					b.WriteString("\n\n")
-				} else {
-					b.WriteRune('\n')
-				}
-			}
-		}
-	}
-	return b.String(), nil
-}
-
-func formatSignature(h *HoverJSON, options *Options) string {
-	signature := h.Signature
-	if signature != "" && options.PreferredContentFormat == protocol.Markdown {
-		signature = fmt.Sprintf("```go\n%s\n```", signature)
-	}
-	return signature
-}
-
-func formatLink(h *HoverJSON, options *Options) string {
-	if !options.LinksInHover || options.LinkTarget == "" || h.LinkPath == "" {
-		return ""
-	}
-	plainLink := BuildLink(options.LinkTarget, h.LinkPath, h.LinkAnchor)
-	switch options.PreferredContentFormat {
-	case protocol.Markdown:
-		return fmt.Sprintf("[`%s` on %s](%s)", h.SymbolName, options.LinkTarget, plainLink)
-	case protocol.PlainText:
-		return ""
-	default:
-		return plainLink
-	}
-}
-
-// BuildLink constructs a URL with the given target, path, and anchor.
-func BuildLink(target, path, anchor string) string {
-	link := fmt.Sprintf("https://%s/%s", target, path)
-	if anchor == "" {
-		return link
-	}
-	return link + "#" + anchor
-}
-
-func formatDoc(h *HoverJSON, options *Options) string {
-	var doc string
-	switch options.HoverKind {
-	case SynopsisDocumentation:
-		doc = h.Synopsis
-	case FullDocumentation:
-		doc = h.FullDocumentation
-	}
-	if options.PreferredContentFormat == protocol.Markdown {
-		return CommentToMarkdown(doc)
-	}
-	return doc
-}
-
-func anyNonEmpty(x []string) bool {
-	for _, el := range x {
-		if el != "" {
-			return true
-		}
-	}
-	return false
-}
-
-// FindDeclAndField returns the var/func/type/const Decl that declares
-// the identifier at pos, searching the given list of file syntax
-// trees. If pos is the position of an ast.Field or one of its Names
-// or Ellipsis.Elt, the field is returned, along with the innermost
-// enclosing Decl, which could be only loosely related---consider:
-//
-//	var decl = f(  func(field int) {}  )
-//
-// It returns (nil, nil) if no Field or Decl is found at pos.
-func FindDeclAndField(files []*ast.File, pos token.Pos) (decl ast.Decl, field *ast.Field) {
-	// panic(found{}) breaks off the traversal and
-	// causes the function to return normally.
-	type found struct{}
-	defer func() {
-		switch x := recover().(type) {
-		case nil:
-		case found:
-		default:
-			panic(x)
-		}
-	}()
-
-	// Visit the files in search of the node at pos.
-	stack := make([]ast.Node, 0, 20)
-	// Allocate the closure once, outside the loop.
-	f := func(n ast.Node) bool {
-		if n != nil {
-			stack = append(stack, n) // push
-		} else {
-			stack = stack[:len(stack)-1] // pop
-			return false
-		}
-
-		// Skip subtrees (incl. files) that don't contain the search point.
-		if !(n.Pos() <= pos && pos < n.End()) {
-			return false
-		}
-
-		switch n := n.(type) {
-		case *ast.Field:
-			checkField := func(f ast.Node) {
-				if f.Pos() == pos {
-					field = n
-					for i := len(stack) - 1; i >= 0; i-- {
-						if d, ok := stack[i].(ast.Decl); ok {
-							decl = d // innermost enclosing decl
-							break
-						}
-					}
-					panic(found{})
-				}
-			}
-
-			// Check *ast.Field itself. This handles embedded
-			// fields which have no associated *ast.Ident name.
-			checkField(n)
-
-			// Check each field name since you can have
-			// multiple names for the same type expression.
-			for _, name := range n.Names {
-				checkField(name)
-			}
-
-			// Also check "X" in "...X". This makes it easy
-			// to format variadic signature params properly.
-			if ell, ok := n.Type.(*ast.Ellipsis); ok && ell.Elt != nil {
-				checkField(ell.Elt)
-			}
-
-		case *ast.FuncDecl:
-			if n.Name.Pos() == pos {
-				decl = n
-				panic(found{})
-			}
-
-		case *ast.GenDecl:
-			for _, spec := range n.Specs {
-				switch spec := spec.(type) {
-				case *ast.TypeSpec:
-					if spec.Name.Pos() == pos {
-						decl = n
-						panic(found{})
-					}
-				case *ast.ValueSpec:
-					for _, id := range spec.Names {
-						if id.Pos() == pos {
-							decl = n
-							panic(found{})
-						}
-					}
-				}
-			}
-		}
-		return true
-	}
-	for _, file := range files {
-		ast.Inspect(file, f)
-	}
-
-	return nil, nil
-}
diff -urN a/gopls/internal/lsp/source/identifier.go b/gopls/internal/lsp/source/identifier.go
--- a/gopls/internal/lsp/source/identifier.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/identifier.go	1969-12-31 16:00:00
@@ -1,548 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"strconv"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// IdentifierInfo holds information about an identifier in Go source.
-type IdentifierInfo struct {
-	Name     string
-	Snapshot Snapshot // only needed for .View(); TODO(adonovan): reduce.
-	MappedRange
-
-	Type struct {
-		MappedRange
-		Object types.Object
-	}
-
-	Inferred *types.Signature
-
-	Declaration Declaration
-
-	ident *ast.Ident
-
-	// For struct fields or embedded interfaces, enclosing is the object
-	// corresponding to the outer type declaration, if it is exported, for use in
-	// documentation links.
-	enclosing *types.TypeName
-
-	pkg Package
-	qf  types.Qualifier
-}
-
-func (i *IdentifierInfo) IsImport() bool {
-	_, ok := i.Declaration.node.(*ast.ImportSpec)
-	return ok
-}
-
-type Declaration struct {
-	MappedRange []MappedRange
-
-	// The typechecked node.
-	node ast.Node
-
-	// Optional: the fully parsed node, to be used for formatting in cases where
-	// node has missing information. This could be the case when node was parsed
-	// in ParseExported mode.
-	fullDecl ast.Decl
-
-	// The typechecked object.
-	obj types.Object
-
-	// typeSwitchImplicit indicates that the declaration is in an implicit
-	// type switch. Its type is the type of the variable on the right-hand
-	// side of the type switch.
-	typeSwitchImplicit types.Type
-}
-
-// Identifier returns identifier information for a position
-// in a file, accounting for a potentially incomplete selector.
-func Identifier(ctx context.Context, snapshot Snapshot, fh FileHandle, position protocol.Position) (*IdentifierInfo, error) {
-	ctx, done := event.Start(ctx, "source.Identifier")
-	defer done()
-
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckFull, NarrowestPackage)
-	if err != nil {
-		return nil, err
-	}
-	pos, err := pgf.Mapper.Pos(position)
-	if err != nil {
-		return nil, err
-	}
-	return findIdentifier(ctx, snapshot, pkg, pgf, pos)
-}
-
-// ErrNoIdentFound is error returned when no identifier is found at a particular position
-var ErrNoIdentFound = errors.New("no identifier found")
-
-func findIdentifier(ctx context.Context, snapshot Snapshot, pkg Package, pgf *ParsedGoFile, pos token.Pos) (*IdentifierInfo, error) {
-	file := pgf.File
-	// Handle import specs separately, as there is no formal position for a
-	// package declaration.
-	if result, err := importSpec(snapshot, pkg, file, pos); result != nil || err != nil {
-		return result, err
-	}
-	path := pathEnclosingObjNode(file, pos)
-	if path == nil {
-		return nil, ErrNoIdentFound
-	}
-
-	qf := Qualifier(file, pkg.GetTypes(), pkg.GetTypesInfo())
-
-	ident, _ := path[0].(*ast.Ident)
-	if ident == nil {
-		return nil, ErrNoIdentFound
-	}
-	// Special case for package declarations, since they have no
-	// corresponding types.Object.
-	if ident == file.Name {
-		rng, err := posToMappedRange(pkg, file.Name.Pos(), file.Name.End())
-		if err != nil {
-			return nil, err
-		}
-		var declAST *ast.File
-		for _, pgf := range pkg.CompiledGoFiles() {
-			if pgf.File.Doc != nil {
-				declAST = pgf.File
-			}
-		}
-		// If there's no package documentation, just use current file.
-		if declAST == nil {
-			declAST = file
-		}
-		declRng, err := posToMappedRange(pkg, declAST.Name.Pos(), declAST.Name.End())
-		if err != nil {
-			return nil, err
-		}
-		return &IdentifierInfo{
-			Name:        file.Name.Name,
-			ident:       file.Name,
-			MappedRange: rng,
-			pkg:         pkg,
-			qf:          qf,
-			Snapshot:    snapshot,
-			Declaration: Declaration{
-				node:        declAST.Name,
-				MappedRange: []MappedRange{declRng},
-			},
-		}, nil
-	}
-
-	result := &IdentifierInfo{
-		Snapshot:  snapshot,
-		qf:        qf,
-		pkg:       pkg,
-		ident:     ident,
-		enclosing: searchForEnclosing(pkg.GetTypesInfo(), path),
-	}
-
-	result.Name = result.ident.Name
-	var err error
-	if result.MappedRange, err = posToMappedRange(pkg, result.ident.Pos(), result.ident.End()); err != nil {
-		return nil, err
-	}
-
-	result.Declaration.obj = pkg.GetTypesInfo().ObjectOf(result.ident)
-	if result.Declaration.obj == nil {
-		// If there was no types.Object for the declaration, there might be an
-		// implicit local variable declaration in a type switch.
-		if objs, typ := typeSwitchImplicits(pkg, path); len(objs) > 0 {
-			// There is no types.Object for the declaration of an implicit local variable,
-			// but all of the types.Objects associated with the usages of this variable can be
-			// used to connect it back to the declaration.
-			// Preserve the first of these objects and treat it as if it were the declaring object.
-			result.Declaration.obj = objs[0]
-			result.Declaration.typeSwitchImplicit = typ
-		} else {
-			// Probably a type error.
-			return nil, fmt.Errorf("%w for ident %v", errNoObjectFound, result.Name)
-		}
-	}
-
-	// Handle builtins separately.
-	if result.Declaration.obj.Parent() == types.Universe {
-		builtin, err := snapshot.BuiltinFile(ctx)
-		if err != nil {
-			return nil, err
-		}
-		builtinObj := builtin.File.Scope.Lookup(result.Name)
-		if builtinObj == nil {
-			return nil, fmt.Errorf("no builtin object for %s", result.Name)
-		}
-		decl, ok := builtinObj.Decl.(ast.Node)
-		if !ok {
-			return nil, fmt.Errorf("no declaration for %s", result.Name)
-		}
-		result.Declaration.node = decl
-		if typeSpec, ok := decl.(*ast.TypeSpec); ok {
-			// Find the GenDecl (which has the doc comments) for the TypeSpec.
-			result.Declaration.fullDecl = findGenDecl(builtin.File, typeSpec)
-		}
-
-		// The builtin package isn't in the dependency graph, so the usual
-		// utilities won't work here.
-		rng := NewMappedRange(builtin.Mapper, decl.Pos(), decl.Pos()+token.Pos(len(result.Name)))
-		result.Declaration.MappedRange = append(result.Declaration.MappedRange, rng)
-		return result, nil
-	}
-
-	// (error).Error is a special case of builtin. Lots of checks to confirm
-	// that this is the builtin Error.
-	if obj := result.Declaration.obj; obj.Parent() == nil && obj.Pkg() == nil && obj.Name() == "Error" {
-		if _, ok := obj.Type().(*types.Signature); ok {
-			builtin, err := snapshot.BuiltinFile(ctx)
-			if err != nil {
-				return nil, err
-			}
-			// Look up "error" and then navigate to its only method.
-			// The Error method does not appear in the builtin package's scope.log.Pri
-			const errorName = "error"
-			builtinObj := builtin.File.Scope.Lookup(errorName)
-			if builtinObj == nil {
-				return nil, fmt.Errorf("no builtin object for %s", errorName)
-			}
-			decl, ok := builtinObj.Decl.(ast.Node)
-			if !ok {
-				return nil, fmt.Errorf("no declaration for %s", errorName)
-			}
-			spec, ok := decl.(*ast.TypeSpec)
-			if !ok {
-				return nil, fmt.Errorf("no type spec for %s", errorName)
-			}
-			iface, ok := spec.Type.(*ast.InterfaceType)
-			if !ok {
-				return nil, fmt.Errorf("%s is not an interface", errorName)
-			}
-			if iface.Methods.NumFields() != 1 {
-				return nil, fmt.Errorf("expected 1 method for %s, got %v", errorName, iface.Methods.NumFields())
-			}
-			method := iface.Methods.List[0]
-			if len(method.Names) != 1 {
-				return nil, fmt.Errorf("expected 1 name for %v, got %v", method, len(method.Names))
-			}
-			name := method.Names[0].Name
-			result.Declaration.node = method
-			rng := NewMappedRange(builtin.Mapper, method.Pos(), method.Pos()+token.Pos(len(name)))
-			result.Declaration.MappedRange = append(result.Declaration.MappedRange, rng)
-			return result, nil
-		}
-	}
-
-	// If the original position was an embedded field, we want to jump
-	// to the field's type definition, not the field's definition.
-	if v, ok := result.Declaration.obj.(*types.Var); ok && v.Embedded() {
-		// types.Info.Uses contains the embedded field's *types.TypeName.
-		if typeName := pkg.GetTypesInfo().Uses[ident]; typeName != nil {
-			result.Declaration.obj = typeName
-		}
-	}
-
-	rng, err := objToMappedRange(pkg, result.Declaration.obj)
-	if err != nil {
-		return nil, err
-	}
-	result.Declaration.MappedRange = append(result.Declaration.MappedRange, rng)
-
-	declPkg, err := FindPackageFromPos(pkg, result.Declaration.obj.Pos())
-	if err != nil {
-		return nil, err
-	}
-	result.Declaration.node, _ = FindDeclAndField(declPkg.GetSyntax(), result.Declaration.obj.Pos()) // may be nil
-
-	// Ensure that we have the full declaration, in case the declaration was
-	// parsed in ParseExported and therefore could be missing information.
-	if result.Declaration.fullDecl, err = fullNode(pkg.FileSet(), result.Declaration.obj, declPkg); err != nil {
-		return nil, err
-	}
-	typ := pkg.GetTypesInfo().TypeOf(result.ident)
-	if typ == nil {
-		return result, nil
-	}
-
-	result.Inferred = inferredSignature(pkg.GetTypesInfo(), ident)
-
-	result.Type.Object = typeToObject(typ)
-	if result.Type.Object != nil {
-		// Identifiers with the type "error" are a special case with no position.
-		if hasErrorType(result.Type.Object) {
-			return result, nil
-		}
-		if result.Type.MappedRange, err = objToMappedRange(pkg, result.Type.Object); err != nil {
-			return nil, err
-		}
-	}
-	return result, nil
-}
-
-// findGenDecl determines the parent ast.GenDecl for a given ast.Spec.
-func findGenDecl(f *ast.File, spec ast.Spec) *ast.GenDecl {
-	for _, decl := range f.Decls {
-		if genDecl, ok := decl.(*ast.GenDecl); ok {
-			if genDecl.Pos() <= spec.Pos() && genDecl.End() >= spec.End() {
-				return genDecl
-			}
-		}
-	}
-	return nil
-}
-
-// fullNode tries to extract the full spec corresponding to obj's declaration.
-// If the package was not parsed in full, the declaration file will be
-// re-parsed to ensure it has complete syntax.
-func fullNode(fset *token.FileSet, obj types.Object, pkg Package) (ast.Decl, error) {
-	// declaration in a different package... make sure we have full AST information.
-	tok := fset.File(obj.Pos())
-	uri := span.URIFromPath(tok.Name())
-	pgf, err := pkg.File(uri)
-	if err != nil {
-		return nil, err
-	}
-	file := pgf.File
-	pos := obj.Pos()
-	if pgf.Mode != ParseFull {
-		file2, _ := parser.ParseFile(fset, tok.Name(), pgf.Src, parser.AllErrors|parser.ParseComments)
-		if file2 != nil {
-			offset, err := safetoken.Offset(tok, obj.Pos())
-			if err != nil {
-				return nil, err
-			}
-			file = file2
-			tok2 := fset.File(file2.Pos())
-			pos = tok2.Pos(offset)
-		}
-	}
-	path, _ := astutil.PathEnclosingInterval(file, pos, pos)
-	for _, n := range path {
-		if decl, ok := n.(ast.Decl); ok {
-			return decl, nil
-		}
-	}
-	return nil, nil
-}
-
-// inferredSignature determines the resolved non-generic signature for an
-// identifier in an instantiation expression.
-//
-// If no such signature exists, it returns nil.
-func inferredSignature(info *types.Info, id *ast.Ident) *types.Signature {
-	inst := typeparams.GetInstances(info)[id]
-	sig, _ := inst.Type.(*types.Signature)
-	return sig
-}
-
-func searchForEnclosing(info *types.Info, path []ast.Node) *types.TypeName {
-	for _, n := range path {
-		switch n := n.(type) {
-		case *ast.SelectorExpr:
-			if sel, ok := info.Selections[n]; ok {
-				recv := Deref(sel.Recv())
-
-				// Keep track of the last exported type seen.
-				var exported *types.TypeName
-				if named, ok := recv.(*types.Named); ok && named.Obj().Exported() {
-					exported = named.Obj()
-				}
-				// We don't want the last element, as that's the field or
-				// method itself.
-				for _, index := range sel.Index()[:len(sel.Index())-1] {
-					if r, ok := recv.Underlying().(*types.Struct); ok {
-						recv = Deref(r.Field(index).Type())
-						if named, ok := recv.(*types.Named); ok && named.Obj().Exported() {
-							exported = named.Obj()
-						}
-					}
-				}
-				return exported
-			}
-		case *ast.CompositeLit:
-			if t, ok := info.Types[n]; ok {
-				if named, _ := t.Type.(*types.Named); named != nil {
-					return named.Obj()
-				}
-			}
-		case *ast.TypeSpec:
-			if _, ok := n.Type.(*ast.StructType); ok {
-				if t, ok := info.Defs[n.Name]; ok {
-					if tname, _ := t.(*types.TypeName); tname != nil {
-						return tname
-					}
-				}
-			}
-		}
-	}
-	return nil
-}
-
-func typeToObject(typ types.Type) types.Object {
-	switch typ := typ.(type) {
-	case *types.Named:
-		return typ.Obj()
-	case *types.Pointer:
-		return typeToObject(typ.Elem())
-	case *types.Array:
-		return typeToObject(typ.Elem())
-	case *types.Slice:
-		return typeToObject(typ.Elem())
-	case *types.Chan:
-		return typeToObject(typ.Elem())
-	case *types.Signature:
-		// Try to find a return value of a named type. If there's only one
-		// such value, jump to its type definition.
-		var res types.Object
-
-		results := typ.Results()
-		for i := 0; i < results.Len(); i++ {
-			obj := typeToObject(results.At(i).Type())
-			if obj == nil || hasErrorType(obj) {
-				// Skip builtins.
-				continue
-			}
-			if res != nil {
-				// The function/method must have only one return value of a named type.
-				return nil
-			}
-
-			res = obj
-		}
-		return res
-	default:
-		return nil
-	}
-}
-
-func hasErrorType(obj types.Object) bool {
-	return types.IsInterface(obj.Type()) && obj.Pkg() == nil && obj.Name() == "error"
-}
-
-// importSpec handles positions inside of an *ast.ImportSpec.
-func importSpec(snapshot Snapshot, pkg Package, file *ast.File, pos token.Pos) (*IdentifierInfo, error) {
-	var imp *ast.ImportSpec
-	for _, spec := range file.Imports {
-		if spec.Path.Pos() <= pos && pos < spec.Path.End() {
-			imp = spec
-		}
-	}
-	if imp == nil {
-		return nil, nil
-	}
-	importPath, err := strconv.Unquote(imp.Path.Value)
-	if err != nil {
-		return nil, fmt.Errorf("import path not quoted: %s (%v)", imp.Path.Value, err)
-	}
-	imported, err := pkg.ResolveImportPath(ImportPath(importPath))
-	if err != nil {
-		return nil, err
-	}
-	result := &IdentifierInfo{
-		Snapshot: snapshot,
-		Name:     importPath, // should this perhaps be imported.PkgPath()?
-		pkg:      pkg,
-	}
-	if result.MappedRange, err = posToMappedRange(pkg, imp.Path.Pos(), imp.Path.End()); err != nil {
-		return nil, err
-	}
-	// Consider the "declaration" of an import spec to be the imported package.
-	// Return all of the files in the package as the definition of the import spec.
-	for _, dst := range imported.GetSyntax() {
-		rng, err := posToMappedRange(pkg, dst.Pos(), dst.End())
-		if err != nil {
-			return nil, err
-		}
-		result.Declaration.MappedRange = append(result.Declaration.MappedRange, rng)
-	}
-
-	result.Declaration.node = imp
-	return result, nil
-}
-
-// typeSwitchImplicits returns all the implicit type switch objects that
-// correspond to the leaf *ast.Ident. It also returns the original type
-// associated with the identifier (outside of a case clause).
-func typeSwitchImplicits(pkg Package, path []ast.Node) ([]types.Object, types.Type) {
-	ident, _ := path[0].(*ast.Ident)
-	if ident == nil {
-		return nil, nil
-	}
-
-	var (
-		ts     *ast.TypeSwitchStmt
-		assign *ast.AssignStmt
-		cc     *ast.CaseClause
-		obj    = pkg.GetTypesInfo().ObjectOf(ident)
-	)
-
-	// Walk our ancestors to determine if our leaf ident refers to a
-	// type switch variable, e.g. the "a" from "switch a := b.(type)".
-Outer:
-	for i := 1; i < len(path); i++ {
-		switch n := path[i].(type) {
-		case *ast.AssignStmt:
-			// Check if ident is the "a" in "a := foo.(type)". The "a" in
-			// this case has no types.Object, so check for ident equality.
-			if len(n.Lhs) == 1 && n.Lhs[0] == ident {
-				assign = n
-			}
-		case *ast.CaseClause:
-			// Check if ident is a use of "a" within a case clause. Each
-			// case clause implicitly maps "a" to a different types.Object,
-			// so check if ident's object is the case clause's implicit
-			// object.
-			if obj != nil && pkg.GetTypesInfo().Implicits[n] == obj {
-				cc = n
-			}
-		case *ast.TypeSwitchStmt:
-			// Look for the type switch that owns our previously found
-			// *ast.AssignStmt or *ast.CaseClause.
-			if n.Assign == assign {
-				ts = n
-				break Outer
-			}
-
-			for _, stmt := range n.Body.List {
-				if stmt == cc {
-					ts = n
-					break Outer
-				}
-			}
-		}
-	}
-	if ts == nil {
-		return nil, nil
-	}
-	// Our leaf ident refers to a type switch variable. Fan out to the
-	// type switch's implicit case clause objects.
-	var objs []types.Object
-	for _, cc := range ts.Body.List {
-		if ccObj := pkg.GetTypesInfo().Implicits[cc]; ccObj != nil {
-			objs = append(objs, ccObj)
-		}
-	}
-	// The right-hand side of a type switch should only have one
-	// element, and we need to track its type in order to generate
-	// hover information for implicit type switch variables.
-	var typ types.Type
-	if assign, ok := ts.Assign.(*ast.AssignStmt); ok && len(assign.Rhs) == 1 {
-		if rhs := assign.Rhs[0].(*ast.TypeAssertExpr); ok {
-			typ = pkg.GetTypesInfo().TypeOf(rhs.X)
-		}
-	}
-	return objs, typ
-}
diff -urN a/gopls/internal/lsp/source/identifier_test.go b/gopls/internal/lsp/source/identifier_test.go
--- a/gopls/internal/lsp/source/identifier_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/identifier_test.go	1969-12-31 16:00:00
@@ -1,128 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"bytes"
-	"go/ast"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"testing"
-)
-
-func TestSearchForEnclosing(t *testing.T) {
-	tests := []struct {
-		desc string
-		// For convenience, consider the first occurrence of the identifier "X" in
-		// src.
-		src string
-		// By convention, "" means no type found.
-		wantTypeName string
-	}{
-		{
-			desc:         "self enclosing",
-			src:          `package a; type X struct {}`,
-			wantTypeName: "X",
-		},
-		{
-			// TODO(rFindley): is this correct, or do we want to resolve I2 here?
-			desc:         "embedded interface in interface",
-			src:          `package a; var y = i1.X; type i1 interface {I2}; type I2 interface{X()}`,
-			wantTypeName: "",
-		},
-		{
-			desc:         "embedded interface in struct",
-			src:          `package a; var y = t.X; type t struct {I}; type I interface{X()}`,
-			wantTypeName: "I",
-		},
-		{
-			desc:         "double embedding",
-			src:          `package a; var y = t1.X; type t1 struct {t2}; type t2 struct {I}; type I interface{X()}`,
-			wantTypeName: "I",
-		},
-		{
-			desc:         "struct field",
-			src:          `package a; type T struct { X int }`,
-			wantTypeName: "T",
-		},
-		{
-			desc:         "nested struct field",
-			src:          `package a; type T struct { E struct { X int } }`,
-			wantTypeName: "T",
-		},
-		{
-			desc:         "slice entry",
-			src:          `package a; type T []int; var S = T{X}; var X int = 2`,
-			wantTypeName: "T",
-		},
-		{
-			desc:         "struct pointer literal",
-			src:          `package a; type T struct {i int}; var L = &T{X}; const X = 2`,
-			wantTypeName: "T",
-		},
-	}
-
-	for _, test := range tests {
-		test := test
-		t.Run(test.desc, func(t *testing.T) {
-			fset := token.NewFileSet()
-			file, err := parser.ParseFile(fset, "a.go", test.src, parser.AllErrors)
-			if err != nil {
-				t.Fatal(err)
-			}
-			column := 1 + bytes.IndexRune([]byte(test.src), 'X')
-			pos := posAt(1, column, fset, "a.go")
-			path := pathEnclosingObjNode(file, pos)
-			if path == nil {
-				t.Fatalf("no ident found at (1, %d)", column)
-			}
-			info := newInfo()
-			if _, err = (*types.Config)(nil).Check("p", fset, []*ast.File{file}, info); err != nil {
-				t.Fatal(err)
-			}
-			obj := searchForEnclosing(info, path)
-			if obj == nil {
-				if test.wantTypeName != "" {
-					t.Errorf("searchForEnclosing(...) = <nil>, want %q", test.wantTypeName)
-				}
-				return
-			}
-			if got := obj.Name(); got != test.wantTypeName {
-				t.Errorf("searchForEnclosing(...) = %q, want %q", got, test.wantTypeName)
-			}
-		})
-	}
-}
-
-// posAt returns the token.Pos corresponding to the 1-based (line, column)
-// coordinates in the file fname of fset.
-func posAt(line, column int, fset *token.FileSet, fname string) token.Pos {
-	var tok *token.File
-	fset.Iterate(func(tf *token.File) bool {
-		if tf.Name() == fname {
-			tok = tf
-			return false
-		}
-		return true
-	})
-	if tok == nil {
-		return token.NoPos
-	}
-	start := tok.LineStart(line)
-	return start + token.Pos(column-1)
-}
-
-// newInfo returns a types.Info with all maps populated.
-func newInfo() *types.Info {
-	return &types.Info{
-		Types:      make(map[ast.Expr]types.TypeAndValue),
-		Defs:       make(map[*ast.Ident]types.Object),
-		Uses:       make(map[*ast.Ident]types.Object),
-		Implicits:  make(map[ast.Node]types.Object),
-		Selections: make(map[*ast.SelectorExpr]*types.Selection),
-		Scopes:     make(map[ast.Node]*types.Scope),
-	}
-}
diff -urN a/gopls/internal/lsp/source/implementation.go b/gopls/internal/lsp/source/implementation.go
--- a/gopls/internal/lsp/source/implementation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/implementation.go	1969-12-31 16:00:00
@@ -1,493 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"sort"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-)
-
-func Implementation(ctx context.Context, snapshot Snapshot, f FileHandle, pp protocol.Position) ([]protocol.Location, error) {
-	ctx, done := event.Start(ctx, "source.Implementation")
-	defer done()
-
-	impls, err := implementations(ctx, snapshot, f, pp)
-	if err != nil {
-		return nil, err
-	}
-	var locations []protocol.Location
-	for _, impl := range impls {
-		if impl.pkg == nil || len(impl.pkg.CompiledGoFiles()) == 0 {
-			continue
-		}
-		rng, err := objToMappedRange(impl.pkg, impl.obj)
-		if err != nil {
-			return nil, err
-		}
-		pr, err := rng.Range()
-		if err != nil {
-			return nil, err
-		}
-		locations = append(locations, protocol.Location{
-			URI:   protocol.URIFromSpanURI(rng.URI()),
-			Range: pr,
-		})
-	}
-	sort.Slice(locations, func(i, j int) bool {
-		li, lj := locations[i], locations[j]
-		if li.URI == lj.URI {
-			return protocol.CompareRange(li.Range, lj.Range) < 0
-		}
-		return li.URI < lj.URI
-	})
-	return locations, nil
-}
-
-var ErrNotAType = errors.New("not a type name or method")
-
-// implementations returns the concrete implementations of the specified
-// interface, or the interfaces implemented by the specified concrete type.
-// It populates only the definition-related fields of qualifiedObject.
-// (Arguably it should return a smaller data type.)
-func implementations(ctx context.Context, s Snapshot, f FileHandle, pp protocol.Position) ([]qualifiedObject, error) {
-	// Find all named types, even local types
-	// (which can have methods due to promotion).
-	var (
-		allNamed []*types.Named
-		pkgs     = make(map[*types.Package]Package)
-	)
-	metas, err := s.AllMetadata(ctx)
-	if err != nil {
-		return nil, err
-	}
-	ids := make([]PackageID, len(metas))
-	for i, m := range metas {
-		ids[i] = m.ID
-	}
-	packages, err := s.TypeCheck(ctx, TypecheckFull, ids...)
-	if err != nil {
-		return nil, err
-	}
-	for _, pkg := range packages {
-		pkgs[pkg.GetTypes()] = pkg
-		for _, obj := range pkg.GetTypesInfo().Defs {
-			obj, ok := obj.(*types.TypeName)
-			// We ignore aliases 'type M = N' to avoid duplicate reporting
-			// of the Named type N.
-			if !ok || obj.IsAlias() {
-				continue
-			}
-			if named, ok := obj.Type().(*types.Named); ok {
-				allNamed = append(allNamed, named)
-			}
-		}
-	}
-
-	qos, err := qualifiedObjsAtProtocolPos(ctx, s, f.URI(), pp)
-	if err != nil {
-		return nil, err
-	}
-	var (
-		impls []qualifiedObject
-		seen  = make(map[token.Position]bool)
-	)
-	for _, qo := range qos {
-		// Ascertain the query identifier (type or method).
-		var (
-			queryType   types.Type
-			queryMethod *types.Func
-		)
-		switch obj := qo.obj.(type) {
-		case *types.Func:
-			queryMethod = obj
-			if recv := obj.Type().(*types.Signature).Recv(); recv != nil {
-				queryType = ensurePointer(recv.Type())
-			}
-		case *types.TypeName:
-			queryType = ensurePointer(obj.Type())
-		}
-
-		if queryType == nil {
-			return nil, ErrNotAType
-		}
-
-		if types.NewMethodSet(queryType).Len() == 0 {
-			return nil, nil
-		}
-
-		// Find all the named types that match our query.
-		for _, named := range allNamed {
-			var (
-				candObj  types.Object = named.Obj()
-				candType              = ensurePointer(named)
-			)
-
-			if !concreteImplementsIntf(candType, queryType) {
-				continue
-			}
-
-			ms := types.NewMethodSet(candType)
-			if ms.Len() == 0 {
-				// Skip empty interfaces.
-				continue
-			}
-
-			// If client queried a method, look up corresponding candType method.
-			if queryMethod != nil {
-				sel := ms.Lookup(queryMethod.Pkg(), queryMethod.Name())
-				if sel == nil {
-					continue
-				}
-				candObj = sel.Obj()
-			}
-
-			pos := safetoken.StartPosition(s.FileSet(), candObj.Pos())
-			if candObj == queryMethod || seen[pos] {
-				continue
-			}
-
-			pkg := pkgs[candObj.Pkg()] // may be nil (e.g. error)
-
-			// TODO(adonovan): the logic below assumes there is only one
-			// predeclared (pkg=nil) object of interest, the error type.
-			// That could change in a future version of Go.
-
-			var posn token.Position
-			if pkg != nil {
-				posn = safetoken.StartPosition(pkg.FileSet(), candObj.Pos())
-			}
-			if seen[posn] {
-				continue
-			}
-			seen[posn] = true
-
-			impls = append(impls, qualifiedObject{
-				obj: candObj,
-				pkg: pkg,
-			})
-		}
-	}
-
-	return impls, nil
-}
-
-// concreteImplementsIntf returns true if a is an interface type implemented by
-// concrete type b, or vice versa.
-func concreteImplementsIntf(a, b types.Type) bool {
-	aIsIntf, bIsIntf := IsInterface(a), IsInterface(b)
-
-	// Make sure exactly one is an interface type.
-	if aIsIntf == bIsIntf {
-		return false
-	}
-
-	// Rearrange if needed so "a" is the concrete type.
-	if aIsIntf {
-		a, b = b, a
-	}
-
-	return types.AssignableTo(a, b)
-}
-
-// ensurePointer wraps T in a *types.Pointer if T is a named, non-interface
-// type. This is useful to make sure you consider a named type's full method
-// set.
-func ensurePointer(T types.Type) types.Type {
-	if _, ok := T.(*types.Named); ok && !IsInterface(T) {
-		return types.NewPointer(T)
-	}
-
-	return T
-}
-
-// A qualifiedObject is the result of resolving a reference from an
-// identifier to an object.
-type qualifiedObject struct {
-	// definition
-	obj types.Object // the referenced object
-	pkg Package      // the Package that defines the object (nil => universe)
-
-	// reference (optional)
-	node      ast.Node // the reference (*ast.Ident or *ast.ImportSpec) to the object
-	sourcePkg Package  // the Package containing node
-}
-
-var (
-	errBuiltin       = errors.New("builtin object")
-	errNoObjectFound = errors.New("no object found")
-)
-
-// qualifiedObjsAtProtocolPos returns info for all the types.Objects referenced
-// at the given position, for the following selection of packages:
-//
-// 1. all packages (including all test variants), in their workspace parse mode
-// 2. if not included above, at least one package containing uri in full parse mode
-//
-// Finding objects in (1) ensures that we locate references within all
-// workspace packages, including in x_test packages. Including (2) ensures that
-// we find local references in the current package, for non-workspace packages
-// that may be open.
-func qualifiedObjsAtProtocolPos(ctx context.Context, s Snapshot, uri span.URI, pp protocol.Position) ([]qualifiedObject, error) {
-	fh, err := s.GetFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	content, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	m := protocol.NewColumnMapper(uri, content)
-	offset, err := m.Offset(pp)
-	if err != nil {
-		return nil, err
-	}
-	return qualifiedObjsAtLocation(ctx, s, positionKey{uri, offset}, map[positionKey]bool{})
-}
-
-// A positionKey identifies a byte offset within a file (URI).
-//
-// When a file has been parsed multiple times in the same FileSet,
-// there may be multiple token.Pos values denoting the same logical
-// position. In such situations, a positionKey may be used for
-// de-duplication.
-type positionKey struct {
-	uri    span.URI
-	offset int
-}
-
-// qualifiedObjsAtLocation finds all objects referenced at offset in uri,
-// across all packages in the snapshot.
-func qualifiedObjsAtLocation(ctx context.Context, s Snapshot, key positionKey, seen map[positionKey]bool) ([]qualifiedObject, error) {
-	if seen[key] {
-		return nil, nil
-	}
-	seen[key] = true
-
-	// We search for referenced objects starting with all packages containing the
-	// current location, and then repeating the search for every distinct object
-	// location discovered.
-	//
-	// In the common case, there should be at most one additional location to
-	// consider: the definition of the object referenced by the location. But we
-	// try to be comprehensive in case we ever support variations on build
-	// constraints.
-	metas, err := s.MetadataForFile(ctx, key.uri)
-	if err != nil {
-		return nil, err
-	}
-	ids := make([]PackageID, len(metas))
-	for i, m := range metas {
-		ids[i] = m.ID
-	}
-	pkgs, err := s.TypeCheck(ctx, TypecheckWorkspace, ids...)
-	if err != nil {
-		return nil, err
-	}
-
-	// In order to allow basic references/rename/implementations to function when
-	// non-workspace packages are open, ensure that we have at least one fully
-	// parsed package for the current file. This allows us to find references
-	// inside the open package. Use WidestPackage to capture references in test
-	// files.
-	hasFullPackage := false
-	for _, pkg := range pkgs {
-		if pkg.ParseMode() == ParseFull {
-			hasFullPackage = true
-			break
-		}
-	}
-	if !hasFullPackage {
-		pkg, _, err := PackageForFile(ctx, s, key.uri, TypecheckFull, WidestPackage)
-		if err != nil {
-			return nil, err
-		}
-		pkgs = append(pkgs, pkg)
-	}
-
-	// report objects in the order we encounter them. This ensures that the first
-	// result is at the cursor...
-	var qualifiedObjs []qualifiedObject
-	// ...but avoid duplicates.
-	seenObjs := map[types.Object]bool{}
-
-	for _, searchpkg := range pkgs {
-		pgf, err := searchpkg.File(key.uri)
-		if err != nil {
-			return nil, err
-		}
-		pos := pgf.Tok.Pos(key.offset)
-		path := pathEnclosingObjNode(pgf.File, pos)
-		if path == nil {
-			continue
-		}
-		var objs []types.Object
-		switch leaf := path[0].(type) {
-		case *ast.Ident:
-			// If leaf represents an implicit type switch object or the type
-			// switch "assign" variable, expand to all of the type switch's
-			// implicit objects.
-			if implicits, _ := typeSwitchImplicits(searchpkg, path); len(implicits) > 0 {
-				objs = append(objs, implicits...)
-			} else {
-				obj := searchpkg.GetTypesInfo().ObjectOf(leaf)
-				if obj == nil {
-					return nil, fmt.Errorf("%w for %q", errNoObjectFound, leaf.Name)
-				}
-				objs = append(objs, obj)
-			}
-		case *ast.ImportSpec:
-			// Look up the implicit *types.PkgName.
-			obj := searchpkg.GetTypesInfo().Implicits[leaf]
-			if obj == nil {
-				return nil, fmt.Errorf("%w for import %s", errNoObjectFound, UnquoteImportPath(leaf))
-			}
-			objs = append(objs, obj)
-		}
-		// Get all of the transitive dependencies of the search package.
-		pkgs := make(map[*types.Package]Package)
-		var addPkg func(pkg Package)
-		addPkg = func(pkg Package) {
-			pkgs[pkg.GetTypes()] = pkg
-			for _, imp := range pkg.Imports() {
-				if _, ok := pkgs[imp.GetTypes()]; !ok {
-					addPkg(imp)
-				}
-			}
-		}
-		addPkg(searchpkg)
-		for _, obj := range objs {
-			if obj.Parent() == types.Universe {
-				return nil, fmt.Errorf("%q: %w", obj.Name(), errBuiltin)
-			}
-			pkg, ok := pkgs[obj.Pkg()]
-			if !ok {
-				event.Error(ctx, fmt.Sprintf("no package for obj %s: %v", obj, obj.Pkg()), err)
-				continue
-			}
-			qualifiedObjs = append(qualifiedObjs, qualifiedObject{
-				obj:       obj,
-				pkg:       pkg,
-				sourcePkg: searchpkg,
-				node:      path[0],
-			})
-			seenObjs[obj] = true
-
-			// If the qualified object is in another file (or more likely, another
-			// package), it's possible that there is another copy of it in a package
-			// that we haven't searched, e.g. a test variant. See golang/go#47564.
-			//
-			// In order to be sure we've considered all packages, call
-			// qualifiedObjsAtLocation recursively for all locations we encounter. We
-			// could probably be more precise here, only continuing the search if obj
-			// is in another package, but this should be good enough to find all
-			// uses.
-
-			if key, found := packagePositionKey(pkg, obj.Pos()); found {
-				otherObjs, err := qualifiedObjsAtLocation(ctx, s, key, seen)
-				if err != nil {
-					return nil, err
-				}
-				for _, other := range otherObjs {
-					if !seenObjs[other.obj] {
-						qualifiedObjs = append(qualifiedObjs, other)
-						seenObjs[other.obj] = true
-					}
-				}
-			} else {
-				return nil, fmt.Errorf("missing file for position of %q in %q", obj.Name(), obj.Pkg().Name())
-			}
-		}
-	}
-	// Return an error if no objects were found since callers will assume that
-	// the slice has at least 1 element.
-	if len(qualifiedObjs) == 0 {
-		return nil, errNoObjectFound
-	}
-	return qualifiedObjs, nil
-}
-
-// packagePositionKey finds the positionKey for the given pos.
-//
-// The second result reports whether the position was found.
-func packagePositionKey(pkg Package, pos token.Pos) (positionKey, bool) {
-	for _, pgf := range pkg.CompiledGoFiles() {
-		offset, err := safetoken.Offset(pgf.Tok, pos)
-		if err == nil {
-			return positionKey{pgf.URI, offset}, true
-		}
-	}
-	return positionKey{}, false
-}
-
-// pathEnclosingObjNode returns the AST path to the object-defining
-// node associated with pos. "Object-defining" means either an
-// *ast.Ident mapped directly to a types.Object or an ast.Node mapped
-// implicitly to a types.Object.
-func pathEnclosingObjNode(f *ast.File, pos token.Pos) []ast.Node {
-	var (
-		path  []ast.Node
-		found bool
-	)
-
-	ast.Inspect(f, func(n ast.Node) bool {
-		if found {
-			return false
-		}
-
-		if n == nil {
-			path = path[:len(path)-1]
-			return false
-		}
-
-		path = append(path, n)
-
-		switch n := n.(type) {
-		case *ast.Ident:
-			// Include the position directly after identifier. This handles
-			// the common case where the cursor is right after the
-			// identifier the user is currently typing. Previously we
-			// handled this by calling astutil.PathEnclosingInterval twice,
-			// once for "pos" and once for "pos-1".
-			found = n.Pos() <= pos && pos <= n.End()
-		case *ast.ImportSpec:
-			if n.Path.Pos() <= pos && pos < n.Path.End() {
-				found = true
-				// If import spec has a name, add name to path even though
-				// position isn't in the name.
-				if n.Name != nil {
-					path = append(path, n.Name)
-				}
-			}
-		case *ast.StarExpr:
-			// Follow star expressions to the inner identifier.
-			if pos == n.Star {
-				pos = n.X.Pos()
-			}
-		}
-
-		return !found
-	})
-
-	if len(path) == 0 {
-		return nil
-	}
-
-	// Reverse path so leaf is first element.
-	for i := 0; i < len(path)/2; i++ {
-		path[i], path[len(path)-1-i] = path[len(path)-1-i], path[i]
-	}
-
-	return path
-}
diff -urN a/gopls/internal/lsp/source/inlay_hint.go b/gopls/internal/lsp/source/inlay_hint.go
--- a/gopls/internal/lsp/source/inlay_hint.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/inlay_hint.go	1969-12-31 16:00:00
@@ -1,396 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/constant"
-	"go/token"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-const (
-	maxLabelLength = 28
-)
-
-type InlayHintFunc func(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, q *types.Qualifier) []protocol.InlayHint
-
-type Hint struct {
-	Name string
-	Doc  string
-	Run  InlayHintFunc
-}
-
-const (
-	ParameterNames             = "parameterNames"
-	AssignVariableTypes        = "assignVariableTypes"
-	ConstantValues             = "constantValues"
-	RangeVariableTypes         = "rangeVariableTypes"
-	CompositeLiteralTypes      = "compositeLiteralTypes"
-	CompositeLiteralFieldNames = "compositeLiteralFields"
-	FunctionTypeParameters     = "functionTypeParameters"
-)
-
-var AllInlayHints = map[string]*Hint{
-	AssignVariableTypes: {
-		Name: AssignVariableTypes,
-		Doc:  "Enable/disable inlay hints for variable types in assign statements:\n```go\n\ti/* int*/, j/* int*/ := 0, len(r)-1\n```",
-		Run:  assignVariableTypes,
-	},
-	ParameterNames: {
-		Name: ParameterNames,
-		Doc:  "Enable/disable inlay hints for parameter names:\n```go\n\tparseInt(/* str: */ \"123\", /* radix: */ 8)\n```",
-		Run:  parameterNames,
-	},
-	ConstantValues: {
-		Name: ConstantValues,
-		Doc:  "Enable/disable inlay hints for constant values:\n```go\n\tconst (\n\t\tKindNone   Kind = iota/* = 0*/\n\t\tKindPrint/*  = 1*/\n\t\tKindPrintf/* = 2*/\n\t\tKindErrorf/* = 3*/\n\t)\n```",
-		Run:  constantValues,
-	},
-	RangeVariableTypes: {
-		Name: RangeVariableTypes,
-		Doc:  "Enable/disable inlay hints for variable types in range statements:\n```go\n\tfor k/* int*/, v/* string*/ := range []string{} {\n\t\tfmt.Println(k, v)\n\t}\n```",
-		Run:  rangeVariableTypes,
-	},
-	CompositeLiteralTypes: {
-		Name: CompositeLiteralTypes,
-		Doc:  "Enable/disable inlay hints for composite literal types:\n```go\n\tfor _, c := range []struct {\n\t\tin, want string\n\t}{\n\t\t/*struct{ in string; want string }*/{\"Hello, world\", \"dlrow ,olleH\"},\n\t}\n```",
-		Run:  compositeLiteralTypes,
-	},
-	CompositeLiteralFieldNames: {
-		Name: CompositeLiteralFieldNames,
-		Doc:  "Enable/disable inlay hints for composite literal field names:\n```go\n\t{/*in: */\"Hello, world\", /*want: */\"dlrow ,olleH\"}\n```",
-		Run:  compositeLiteralFields,
-	},
-	FunctionTypeParameters: {
-		Name: FunctionTypeParameters,
-		Doc:  "Enable/disable inlay hints for implicit type parameters on generic functions:\n```go\n\tmyFoo/*[int, string]*/(1, \"hello\")\n```",
-		Run:  funcTypeParams,
-	},
-}
-
-func InlayHint(ctx context.Context, snapshot Snapshot, fh FileHandle, pRng protocol.Range) ([]protocol.InlayHint, error) {
-	ctx, done := event.Start(ctx, "source.InlayHint")
-	defer done()
-
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckWorkspace, NarrowestPackage)
-	if err != nil {
-		return nil, fmt.Errorf("getting file for InlayHint: %w", err)
-	}
-
-	// Collect a list of the inlay hints that are enabled.
-	inlayHintOptions := snapshot.View().Options().InlayHintOptions
-	var enabledHints []InlayHintFunc
-	for hint, enabled := range inlayHintOptions.Hints {
-		if !enabled {
-			continue
-		}
-		if h, ok := AllInlayHints[hint]; ok {
-			enabledHints = append(enabledHints, h.Run)
-		}
-	}
-	if len(enabledHints) == 0 {
-		return nil, nil
-	}
-
-	tmap := lsppos.NewTokenMapper(pgf.Src, pgf.Tok)
-	info := pkg.GetTypesInfo()
-	q := Qualifier(pgf.File, pkg.GetTypes(), info)
-
-	// Set the range to the full file if the range is not valid.
-	start, end := pgf.File.Pos(), pgf.File.End()
-	if pRng.Start.Line < pRng.End.Line || pRng.Start.Character < pRng.End.Character {
-		// Adjust start and end for the specified range.
-		rng, err := pgf.Mapper.RangeToSpanRange(pRng)
-		if err != nil {
-			return nil, err
-		}
-		start, end = rng.Start, rng.End
-	}
-
-	var hints []protocol.InlayHint
-	ast.Inspect(pgf.File, func(node ast.Node) bool {
-		// If not in range, we can stop looking.
-		if node == nil || node.End() < start || node.Pos() > end {
-			return false
-		}
-		for _, fn := range enabledHints {
-			hints = append(hints, fn(node, tmap, info, &q)...)
-		}
-		return true
-	})
-	return hints, nil
-}
-
-func parameterNames(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, _ *types.Qualifier) []protocol.InlayHint {
-	callExpr, ok := node.(*ast.CallExpr)
-	if !ok {
-		return nil
-	}
-	signature, ok := info.TypeOf(callExpr.Fun).(*types.Signature)
-	if !ok {
-		return nil
-	}
-
-	var hints []protocol.InlayHint
-	for i, v := range callExpr.Args {
-		start, ok := tmap.Position(v.Pos())
-		if !ok {
-			continue
-		}
-		params := signature.Params()
-		// When a function has variadic params, we skip args after
-		// params.Len().
-		if i > params.Len()-1 {
-			break
-		}
-		param := params.At(i)
-		// param.Name is empty for built-ins like append
-		if param.Name() == "" {
-			continue
-		}
-		// Skip the parameter name hint if the arg matches the
-		// the parameter name.
-		if i, ok := v.(*ast.Ident); ok && i.Name == param.Name() {
-			continue
-		}
-
-		label := param.Name()
-		if signature.Variadic() && i == params.Len()-1 {
-			label = label + "..."
-		}
-		hints = append(hints, protocol.InlayHint{
-			Position:     &start,
-			Label:        buildLabel(label + ":"),
-			Kind:         protocol.Parameter,
-			PaddingRight: true,
-		})
-	}
-	return hints
-}
-
-func funcTypeParams(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, _ *types.Qualifier) []protocol.InlayHint {
-	ce, ok := node.(*ast.CallExpr)
-	if !ok {
-		return nil
-	}
-	id, ok := ce.Fun.(*ast.Ident)
-	if !ok {
-		return nil
-	}
-	inst := typeparams.GetInstances(info)[id]
-	if inst.TypeArgs == nil {
-		return nil
-	}
-	start, ok := tmap.Position(id.End())
-	if !ok {
-		return nil
-	}
-	var args []string
-	for i := 0; i < inst.TypeArgs.Len(); i++ {
-		args = append(args, inst.TypeArgs.At(i).String())
-	}
-	if len(args) == 0 {
-		return nil
-	}
-	return []protocol.InlayHint{{
-		Position: &start,
-		Label:    buildLabel("[" + strings.Join(args, ", ") + "]"),
-		Kind:     protocol.Type,
-	}}
-}
-
-func assignVariableTypes(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, q *types.Qualifier) []protocol.InlayHint {
-	stmt, ok := node.(*ast.AssignStmt)
-	if !ok || stmt.Tok != token.DEFINE {
-		return nil
-	}
-
-	var hints []protocol.InlayHint
-	for _, v := range stmt.Lhs {
-		if h := variableType(v, tmap, info, q); h != nil {
-			hints = append(hints, *h)
-		}
-	}
-	return hints
-}
-
-func rangeVariableTypes(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, q *types.Qualifier) []protocol.InlayHint {
-	rStmt, ok := node.(*ast.RangeStmt)
-	if !ok {
-		return nil
-	}
-	var hints []protocol.InlayHint
-	if h := variableType(rStmt.Key, tmap, info, q); h != nil {
-		hints = append(hints, *h)
-	}
-	if h := variableType(rStmt.Value, tmap, info, q); h != nil {
-		hints = append(hints, *h)
-	}
-	return hints
-}
-
-func variableType(e ast.Expr, tmap *lsppos.TokenMapper, info *types.Info, q *types.Qualifier) *protocol.InlayHint {
-	typ := info.TypeOf(e)
-	if typ == nil {
-		return nil
-	}
-	end, ok := tmap.Position(e.End())
-	if !ok {
-		return nil
-	}
-	return &protocol.InlayHint{
-		Position:    &end,
-		Label:       buildLabel(types.TypeString(typ, *q)),
-		Kind:        protocol.Type,
-		PaddingLeft: true,
-	}
-}
-
-func constantValues(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, _ *types.Qualifier) []protocol.InlayHint {
-	genDecl, ok := node.(*ast.GenDecl)
-	if !ok || genDecl.Tok != token.CONST {
-		return nil
-	}
-
-	var hints []protocol.InlayHint
-	for _, v := range genDecl.Specs {
-		spec, ok := v.(*ast.ValueSpec)
-		if !ok {
-			continue
-		}
-		end, ok := tmap.Position(v.End())
-		if !ok {
-			continue
-		}
-		// Show hints when values are missing or at least one value is not
-		// a basic literal.
-		showHints := len(spec.Values) == 0
-		checkValues := len(spec.Names) == len(spec.Values)
-		var values []string
-		for i, w := range spec.Names {
-			obj, ok := info.ObjectOf(w).(*types.Const)
-			if !ok || obj.Val().Kind() == constant.Unknown {
-				return nil
-			}
-			if checkValues {
-				switch spec.Values[i].(type) {
-				case *ast.BadExpr:
-					return nil
-				case *ast.BasicLit:
-				default:
-					if obj.Val().Kind() != constant.Bool {
-						showHints = true
-					}
-				}
-			}
-			values = append(values, fmt.Sprintf("%v", obj.Val()))
-		}
-		if !showHints || len(values) == 0 {
-			continue
-		}
-		hints = append(hints, protocol.InlayHint{
-			Position:    &end,
-			Label:       buildLabel("= " + strings.Join(values, ", ")),
-			PaddingLeft: true,
-		})
-	}
-	return hints
-}
-
-func compositeLiteralFields(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, q *types.Qualifier) []protocol.InlayHint {
-	compLit, ok := node.(*ast.CompositeLit)
-	if !ok {
-		return nil
-	}
-	typ := info.TypeOf(compLit)
-	if typ == nil {
-		return nil
-	}
-	if t, ok := typ.(*types.Pointer); ok {
-		typ = t.Elem()
-	}
-	strct, ok := typ.Underlying().(*types.Struct)
-	if !ok {
-		return nil
-	}
-
-	var hints []protocol.InlayHint
-	var allEdits []protocol.TextEdit
-	for i, v := range compLit.Elts {
-		if _, ok := v.(*ast.KeyValueExpr); !ok {
-			start, ok := tmap.Position(v.Pos())
-			if !ok {
-				continue
-			}
-			if i > strct.NumFields()-1 {
-				break
-			}
-			hints = append(hints, protocol.InlayHint{
-				Position:     &start,
-				Label:        buildLabel(strct.Field(i).Name() + ":"),
-				Kind:         protocol.Parameter,
-				PaddingRight: true,
-			})
-			allEdits = append(allEdits, protocol.TextEdit{
-				Range:   protocol.Range{Start: start, End: start},
-				NewText: strct.Field(i).Name() + ": ",
-			})
-		}
-	}
-	// It is not allowed to have a mix of keyed and unkeyed fields, so
-	// have the text edits add keys to all fields.
-	for i := range hints {
-		hints[i].TextEdits = allEdits
-	}
-	return hints
-}
-
-func compositeLiteralTypes(node ast.Node, tmap *lsppos.TokenMapper, info *types.Info, q *types.Qualifier) []protocol.InlayHint {
-	compLit, ok := node.(*ast.CompositeLit)
-	if !ok {
-		return nil
-	}
-	typ := info.TypeOf(compLit)
-	if typ == nil {
-		return nil
-	}
-	if compLit.Type != nil {
-		return nil
-	}
-	prefix := ""
-	if t, ok := typ.(*types.Pointer); ok {
-		typ = t.Elem()
-		prefix = "&"
-	}
-	// The type for this composite literal is implicit, add an inlay hint.
-	start, ok := tmap.Position(compLit.Lbrace)
-	if !ok {
-		return nil
-	}
-	return []protocol.InlayHint{{
-		Position: &start,
-		Label:    buildLabel(fmt.Sprintf("%s%s", prefix, types.TypeString(typ, *q))),
-		Kind:     protocol.Type,
-	}}
-}
-
-func buildLabel(s string) []protocol.InlayHintLabelPart {
-	label := protocol.InlayHintLabelPart{
-		Value: s,
-	}
-	if len(s) > maxLabelLength+len("...") {
-		label.Value = s[:maxLabelLength] + "..."
-	}
-	return []protocol.InlayHintLabelPart{label}
-}
diff -urN a/gopls/internal/lsp/source/known_packages.go b/gopls/internal/lsp/source/known_packages.go
--- a/gopls/internal/lsp/source/known_packages.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/known_packages.go	1969-12-31 16:00:00
@@ -1,140 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/parser"
-	"go/token"
-	"sort"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/imports"
-)
-
-// KnownPackagePaths returns a new list of package paths of all known
-// packages in the package graph that could potentially be imported by
-// the given file. The list is ordered lexicographically, except that
-// all dot-free paths (standard packages) appear before dotful ones.
-//
-// It is part of the gopls.list_known_packages command.
-func KnownPackagePaths(ctx context.Context, snapshot Snapshot, fh VersionedFileHandle) ([]PackagePath, error) {
-	// This algorithm is expressed in terms of Metadata, not Packages,
-	// so it doesn't cause or wait for type checking.
-
-	// Find a Metadata containing the file.
-	metas, err := snapshot.MetadataForFile(ctx, fh.URI())
-	if err != nil {
-		return nil, err // e.g. context cancelled
-	}
-	if len(metas) == 0 {
-		return nil, fmt.Errorf("no loaded package contain file %s", fh.URI())
-	}
-	current := metas[0] // pick one arbitrarily (they should all have the same package path)
-
-	// Parse the file's imports so we can compute which
-	// PackagePaths are imported by this specific file.
-	src, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	file, err := parser.ParseFile(token.NewFileSet(), fh.URI().Filename(), src, parser.ImportsOnly)
-	if err != nil {
-		return nil, err
-	}
-	imported := make(map[PackagePath]bool)
-	for _, imp := range file.Imports {
-		if id := current.DepsByImpPath[UnquoteImportPath(imp)]; id != "" {
-			if m := snapshot.Metadata(id); m != nil {
-				imported[m.PkgPath] = true
-			}
-		}
-	}
-
-	// Now find candidates among known packages.
-	knownPkgs, err := snapshot.AllMetadata(ctx)
-	if err != nil {
-		return nil, err
-	}
-	seen := make(map[PackagePath]bool)
-	for _, knownPkg := range knownPkgs {
-		// package main cannot be imported
-		if knownPkg.Name == "main" {
-			continue
-		}
-		// test packages cannot be imported
-		if knownPkg.ForTest != "" {
-			continue
-		}
-		// No need to import what the file already imports.
-		// This check is based on PackagePath, not PackageID,
-		// so that all test variants are filtered out too.
-		if imported[knownPkg.PkgPath] {
-			continue
-		}
-		// make sure internal packages are importable by the file
-		if !IsValidImport(current.PkgPath, knownPkg.PkgPath) {
-			continue
-		}
-		// naive check on cyclical imports
-		if isDirectlyCyclical(current, knownPkg) {
-			continue
-		}
-		// AllMetadata may have multiple variants of a pkg.
-		seen[knownPkg.PkgPath] = true
-	}
-
-	// Augment the set by invoking the goimports algorithm.
-	if err := snapshot.RunProcessEnvFunc(ctx, func(o *imports.Options) error {
-		ctx, cancel := context.WithTimeout(ctx, time.Millisecond*80)
-		defer cancel()
-		var seenMu sync.Mutex
-		wrapped := func(ifix imports.ImportFix) {
-			seenMu.Lock()
-			defer seenMu.Unlock()
-			// TODO(adonovan): what if the actual package path has a vendor/ prefix?
-			seen[PackagePath(ifix.StmtInfo.ImportPath)] = true
-		}
-		return imports.GetAllCandidates(ctx, wrapped, "", fh.URI().Filename(), string(current.Name), o.Env)
-	}); err != nil {
-		// If goimports failed, proceed with just the candidates from the metadata.
-		event.Error(ctx, "imports.GetAllCandidates", err)
-	}
-
-	// Sort lexicographically, but with std before non-std packages.
-	paths := make([]PackagePath, 0, len(seen))
-	for path := range seen {
-		paths = append(paths, path)
-	}
-	sort.Slice(paths, func(i, j int) bool {
-		importI, importJ := paths[i], paths[j]
-		iHasDot := strings.Contains(string(importI), ".")
-		jHasDot := strings.Contains(string(importJ), ".")
-		if iHasDot != jHasDot {
-			return jHasDot // dot-free paths (standard packages) compare less
-		}
-		return importI < importJ
-	})
-
-	return paths, nil
-}
-
-// isDirectlyCyclical checks if imported directly imports pkg.
-// It does not (yet) offer a full cyclical check because showing a user
-// a list of importable packages already generates a very large list
-// and having a few false positives in there could be worth the
-// performance snappiness.
-//
-// TODO(adonovan): ensure that metadata graph is always cyclic!
-// Many algorithms will get confused or even stuck in the
-// presence of cycles. Then replace this function by 'false'.
-func isDirectlyCyclical(pkg, imported *Metadata) bool {
-	_, ok := imported.DepsByPkgPath[pkg.PkgPath]
-	return ok
-}
diff -urN a/gopls/internal/lsp/source/options.go b/gopls/internal/lsp/source/options.go
--- a/gopls/internal/lsp/source/options.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/options.go	1969-12-31 16:00:00
@@ -1,1663 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"io"
-	"path/filepath"
-	"regexp"
-	"runtime"
-	"strings"
-	"sync"
-	"time"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/analysis/passes/asmdecl"
-	"golang.org/x/tools/go/analysis/passes/assign"
-	"golang.org/x/tools/go/analysis/passes/atomic"
-	"golang.org/x/tools/go/analysis/passes/atomicalign"
-	"golang.org/x/tools/go/analysis/passes/bools"
-	"golang.org/x/tools/go/analysis/passes/buildtag"
-	"golang.org/x/tools/go/analysis/passes/cgocall"
-	"golang.org/x/tools/go/analysis/passes/composite"
-	"golang.org/x/tools/go/analysis/passes/copylock"
-	"golang.org/x/tools/go/analysis/passes/deepequalerrors"
-	"golang.org/x/tools/go/analysis/passes/errorsas"
-	"golang.org/x/tools/go/analysis/passes/fieldalignment"
-	"golang.org/x/tools/go/analysis/passes/httpresponse"
-	"golang.org/x/tools/go/analysis/passes/ifaceassert"
-	"golang.org/x/tools/go/analysis/passes/loopclosure"
-	"golang.org/x/tools/go/analysis/passes/lostcancel"
-	"golang.org/x/tools/go/analysis/passes/nilfunc"
-	"golang.org/x/tools/go/analysis/passes/nilness"
-	"golang.org/x/tools/go/analysis/passes/printf"
-	"golang.org/x/tools/go/analysis/passes/shadow"
-	"golang.org/x/tools/go/analysis/passes/shift"
-	"golang.org/x/tools/go/analysis/passes/sortslice"
-	"golang.org/x/tools/go/analysis/passes/stdmethods"
-	"golang.org/x/tools/go/analysis/passes/stringintconv"
-	"golang.org/x/tools/go/analysis/passes/structtag"
-	"golang.org/x/tools/go/analysis/passes/testinggoroutine"
-	"golang.org/x/tools/go/analysis/passes/tests"
-	"golang.org/x/tools/go/analysis/passes/timeformat"
-	"golang.org/x/tools/go/analysis/passes/unmarshal"
-	"golang.org/x/tools/go/analysis/passes/unreachable"
-	"golang.org/x/tools/go/analysis/passes/unsafeptr"
-	"golang.org/x/tools/go/analysis/passes/unusedresult"
-	"golang.org/x/tools/go/analysis/passes/unusedwrite"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/embeddirective"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/fillreturns"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/fillstruct"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/infertypeargs"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/nonewvars"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/noresultvalues"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/simplifycompositelit"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/simplifyrange"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/simplifyslice"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/stubmethods"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/undeclaredname"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/unusedparams"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/unusedvariable"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/useany"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/diff/myers"
-)
-
-var (
-	optionsOnce    sync.Once
-	defaultOptions *Options
-)
-
-// DefaultOptions is the options that are used for Gopls execution independent
-// of any externally provided configuration (LSP initialization, command
-// invocation, etc.).
-func DefaultOptions() *Options {
-	optionsOnce.Do(func() {
-		var commands []string
-		for _, c := range command.Commands {
-			commands = append(commands, c.ID())
-		}
-		defaultOptions = &Options{
-			ClientOptions: ClientOptions{
-				InsertTextFormat:                           protocol.PlainTextTextFormat,
-				PreferredContentFormat:                     protocol.Markdown,
-				ConfigurationSupported:                     true,
-				DynamicConfigurationSupported:              true,
-				DynamicRegistrationSemanticTokensSupported: true,
-				DynamicWatchedFilesSupported:               true,
-				LineFoldingOnly:                            false,
-				HierarchicalDocumentSymbolSupport:          true,
-			},
-			ServerOptions: ServerOptions{
-				SupportedCodeActions: map[FileKind]map[protocol.CodeActionKind]bool{
-					Go: {
-						protocol.SourceFixAll:          true,
-						protocol.SourceOrganizeImports: true,
-						protocol.QuickFix:              true,
-						protocol.RefactorRewrite:       true,
-						protocol.RefactorExtract:       true,
-					},
-					Mod: {
-						protocol.SourceOrganizeImports: true,
-						protocol.QuickFix:              true,
-					},
-					Work: {},
-					Sum:  {},
-					Tmpl: {},
-				},
-				SupportedCommands: commands,
-			},
-			UserOptions: UserOptions{
-				BuildOptions: BuildOptions{
-					ExpandWorkspaceToModule:     true,
-					ExperimentalPackageCacheKey: true,
-					MemoryMode:                  ModeNormal,
-					DirectoryFilters:            []string{"-**/node_modules"},
-					TemplateExtensions:          []string{},
-					StandaloneTags:              []string{"ignore"},
-				},
-				UIOptions: UIOptions{
-					DiagnosticOptions: DiagnosticOptions{
-						DiagnosticsDelay: 250 * time.Millisecond,
-						Annotations: map[Annotation]bool{
-							Bounds: true,
-							Escape: true,
-							Inline: true,
-							Nil:    true,
-						},
-						Vulncheck: ModeVulncheckOff,
-					},
-					InlayHintOptions: InlayHintOptions{},
-					DocumentationOptions: DocumentationOptions{
-						HoverKind:    FullDocumentation,
-						LinkTarget:   "pkg.go.dev",
-						LinksInHover: true,
-					},
-					NavigationOptions: NavigationOptions{
-						ImportShortcut: Both,
-						SymbolMatcher:  SymbolFastFuzzy,
-						SymbolStyle:    DynamicSymbols,
-					},
-					CompletionOptions: CompletionOptions{
-						Matcher:                        Fuzzy,
-						CompletionBudget:               100 * time.Millisecond,
-						ExperimentalPostfixCompletions: true,
-					},
-					Codelenses: map[string]bool{
-						string(command.Generate):          true,
-						string(command.RegenerateCgo):     true,
-						string(command.Tidy):              true,
-						string(command.GCDetails):         false,
-						string(command.UpgradeDependency): true,
-						string(command.Vendor):            true,
-						// TODO(hyangah): enable command.RunGovulncheck.
-					},
-				},
-			},
-			InternalOptions: InternalOptions{
-				LiteralCompletions:      true,
-				TempModfile:             true,
-				CompleteUnimported:      true,
-				CompletionDocumentation: true,
-				DeepCompletion:          true,
-				ChattyDiagnostics:       true,
-				NewDiff:                 "both",
-			},
-			Hooks: Hooks{
-				// TODO(adonovan): switch to new diff.Strings implementation.
-				ComputeEdits:         myers.ComputeEdits,
-				URLRegexp:            urlRegexp(),
-				DefaultAnalyzers:     defaultAnalyzers(),
-				TypeErrorAnalyzers:   typeErrorAnalyzers(),
-				ConvenienceAnalyzers: convenienceAnalyzers(),
-				StaticcheckAnalyzers: map[string]*Analyzer{},
-				GoDiff:               true,
-			},
-		}
-	})
-	return defaultOptions
-}
-
-// Options holds various configuration that affects Gopls execution, organized
-// by the nature or origin of the settings.
-type Options struct {
-	ClientOptions
-	ServerOptions
-	UserOptions
-	InternalOptions
-	Hooks
-}
-
-// ClientOptions holds LSP-specific configuration that is provided by the
-// client.
-type ClientOptions struct {
-	InsertTextFormat                           protocol.InsertTextFormat
-	ConfigurationSupported                     bool
-	DynamicConfigurationSupported              bool
-	DynamicRegistrationSemanticTokensSupported bool
-	DynamicWatchedFilesSupported               bool
-	PreferredContentFormat                     protocol.MarkupKind
-	LineFoldingOnly                            bool
-	HierarchicalDocumentSymbolSupport          bool
-	SemanticTypes                              []string
-	SemanticMods                               []string
-	RelatedInformationSupported                bool
-	CompletionTags                             bool
-	CompletionDeprecated                       bool
-	SupportedResourceOperations                []protocol.ResourceOperationKind
-}
-
-// ServerOptions holds LSP-specific configuration that is provided by the
-// server.
-type ServerOptions struct {
-	SupportedCodeActions map[FileKind]map[protocol.CodeActionKind]bool
-	SupportedCommands    []string
-}
-
-type BuildOptions struct {
-	// BuildFlags is the set of flags passed on to the build system when invoked.
-	// It is applied to queries like `go list`, which is used when discovering files.
-	// The most common use is to set `-tags`.
-	BuildFlags []string
-
-	// Env adds environment variables to external commands run by `gopls`, most notably `go list`.
-	Env map[string]string
-
-	// DirectoryFilters can be used to exclude unwanted directories from the
-	// workspace. By default, all directories are included. Filters are an
-	// operator, `+` to include and `-` to exclude, followed by a path prefix
-	// relative to the workspace folder. They are evaluated in order, and
-	// the last filter that applies to a path controls whether it is included.
-	// The path prefix can be empty, so an initial `-` excludes everything.
-	//
-	// DirectoryFilters also supports the `**` operator to match 0 or more directories.
-	//
-	// Examples:
-	//
-	// Exclude node_modules at current depth: `-node_modules`
-	//
-	// Exclude node_modules at any depth: `-**/node_modules`
-	//
-	// Include only project_a: `-` (exclude everything), `+project_a`
-	//
-	// Include only project_a, but not node_modules inside it: `-`, `+project_a`, `-project_a/node_modules`
-	DirectoryFilters []string
-
-	// TemplateExtensions gives the extensions of file names that are treateed
-	// as template files. (The extension
-	// is the part of the file name after the final dot.)
-	TemplateExtensions []string
-
-	// MemoryMode controls the tradeoff `gopls` makes between memory usage and
-	// correctness.
-	//
-	// Values other than `Normal` are untested and may break in surprising ways.
-	MemoryMode MemoryMode `status:"experimental"`
-
-	// ExpandWorkspaceToModule instructs `gopls` to adjust the scope of the
-	// workspace to find the best available module root. `gopls` first looks for
-	// a go.mod file in any parent directory of the workspace folder, expanding
-	// the scope to that directory if it exists. If no viable parent directory is
-	// found, gopls will check if there is exactly one child directory containing
-	// a go.mod file, narrowing the scope to that directory if it exists.
-	ExpandWorkspaceToModule bool `status:"experimental"`
-
-	// ExperimentalWorkspaceModule opts a user into the experimental support
-	// for multi-module workspaces.
-	//
-	// Deprecated: this feature is deprecated and will be removed in a future
-	// version of gopls (https://go.dev/issue/55331).
-	ExperimentalWorkspaceModule bool `status:"experimental"`
-
-	// ExperimentalPackageCacheKey controls whether to use a coarser cache key
-	// for package type information to increase cache hits. This setting removes
-	// the user's environment, build flags, and working directory from the cache
-	// key, which should be a safe change as all relevant inputs into the type
-	// checking pass are already hashed into the key. This is temporarily guarded
-	// by an experiment because caching behavior is subtle and difficult to
-	// comprehensively test.
-	ExperimentalPackageCacheKey bool `status:"experimental"`
-
-	// AllowModfileModifications disables -mod=readonly, allowing imports from
-	// out-of-scope modules. This option will eventually be removed.
-	AllowModfileModifications bool `status:"experimental"`
-
-	// AllowImplicitNetworkAccess disables GOPROXY=off, allowing implicit module
-	// downloads rather than requiring user action. This option will eventually
-	// be removed.
-	AllowImplicitNetworkAccess bool `status:"experimental"`
-
-	// StandaloneTags specifies a set of build constraints that identify
-	// individual Go source files that make up the entire main package of an
-	// executable.
-	//
-	// A common example of standalone main files is the convention of using the
-	// directive `//go:build ignore` to denote files that are not intended to be
-	// included in any package, for example because they are invoked directly by
-	// the developer using `go run`.
-	//
-	// Gopls considers a file to be a standalone main file if and only if it has
-	// package name "main" and has a build directive of the exact form
-	// "//go:build tag" or "// +build tag", where tag is among the list of tags
-	// configured by this setting. Notably, if the build constraint is more
-	// complicated than a simple tag (such as the composite constraint
-	// `//go:build tag && go1.18`), the file is not considered to be a standalone
-	// main file.
-	//
-	// This setting is only supported when gopls is built with Go 1.16 or later.
-	StandaloneTags []string
-}
-
-type UIOptions struct {
-	DocumentationOptions
-	CompletionOptions
-	NavigationOptions
-	DiagnosticOptions
-	InlayHintOptions
-
-	// Codelenses overrides the enabled/disabled state of code lenses. See the
-	// "Code Lenses" section of the
-	// [Settings page](https://github.com/golang/tools/blob/master/gopls/doc/settings.md#code-lenses)
-	// for the list of supported lenses.
-	//
-	// Example Usage:
-	//
-	// ```json5
-	// "gopls": {
-	// ...
-	//   "codelenses": {
-	//     "generate": false,  // Don't show the `go generate` lens.
-	//     "gc_details": true  // Show a code lens toggling the display of gc's choices.
-	//   }
-	// ...
-	// }
-	// ```
-	Codelenses map[string]bool
-
-	// SemanticTokens controls whether the LSP server will send
-	// semantic tokens to the client.
-	SemanticTokens bool `status:"experimental"`
-
-	// NoSemanticString turns off the sending of the semantic token 'string'
-	NoSemanticString bool `status:"experimental"`
-
-	// NoSemanticNumber  turns off the sending of the semantic token 'number'
-	NoSemanticNumber bool `status:"experimental"`
-}
-
-type CompletionOptions struct {
-	// Placeholders enables placeholders for function parameters or struct
-	// fields in completion responses.
-	UsePlaceholders bool
-
-	// CompletionBudget is the soft latency goal for completion requests. Most
-	// requests finish in a couple milliseconds, but in some cases deep
-	// completions can take much longer. As we use up our budget we
-	// dynamically reduce the search scope to ensure we return timely
-	// results. Zero means unlimited.
-	CompletionBudget time.Duration `status:"debug"`
-
-	// Matcher sets the algorithm that is used when calculating completion
-	// candidates.
-	Matcher Matcher `status:"advanced"`
-
-	// ExperimentalPostfixCompletions enables artificial method snippets
-	// such as "someSlice.sort!".
-	ExperimentalPostfixCompletions bool `status:"experimental"`
-}
-
-type DocumentationOptions struct {
-	// HoverKind controls the information that appears in the hover text.
-	// SingleLine and Structured are intended for use only by authors of editor plugins.
-	HoverKind HoverKind
-
-	// LinkTarget controls where documentation links go.
-	// It might be one of:
-	//
-	// * `"godoc.org"`
-	// * `"pkg.go.dev"`
-	//
-	// If company chooses to use its own `godoc.org`, its address can be used as well.
-	//
-	// Modules matching the GOPRIVATE environment variable will not have
-	// documentation links in hover.
-	LinkTarget string
-
-	// LinksInHover toggles the presence of links to documentation in hover.
-	LinksInHover bool
-}
-
-type FormattingOptions struct {
-	// Local is the equivalent of the `goimports -local` flag, which puts
-	// imports beginning with this string after third-party packages. It should
-	// be the prefix of the import path whose imports should be grouped
-	// separately.
-	Local string
-
-	// Gofumpt indicates if we should run gofumpt formatting.
-	Gofumpt bool
-}
-
-type DiagnosticOptions struct {
-	// Analyses specify analyses that the user would like to enable or disable.
-	// A map of the names of analysis passes that should be enabled/disabled.
-	// A full list of analyzers that gopls uses can be found in
-	// [analyzers.md](https://github.com/golang/tools/blob/master/gopls/doc/analyzers.md).
-	//
-	// Example Usage:
-	//
-	// ```json5
-	// ...
-	// "analyses": {
-	//   "unreachable": false, // Disable the unreachable analyzer.
-	//   "unusedparams": true  // Enable the unusedparams analyzer.
-	// }
-	// ...
-	// ```
-	Analyses map[string]bool
-
-	// Staticcheck enables additional analyses from staticcheck.io.
-	// These analyses are documented on
-	// [Staticcheck's website](https://staticcheck.io/docs/checks/).
-	Staticcheck bool `status:"experimental"`
-
-	// Annotations specifies the various kinds of optimization diagnostics
-	// that should be reported by the gc_details command.
-	Annotations map[Annotation]bool `status:"experimental"`
-
-	// Vulncheck enables vulnerability scanning.
-	Vulncheck VulncheckMode `status:"experimental"`
-
-	// DiagnosticsDelay controls the amount of time that gopls waits
-	// after the most recent file modification before computing deep diagnostics.
-	// Simple diagnostics (parsing and type-checking) are always run immediately
-	// on recently modified packages.
-	//
-	// This option must be set to a valid duration string, for example `"250ms"`.
-	DiagnosticsDelay time.Duration `status:"advanced"`
-
-	// ExperimentalWatchedFileDelay controls the amount of time that gopls waits
-	// for additional workspace/didChangeWatchedFiles notifications to arrive,
-	// before processing all such notifications in a single batch. This is
-	// intended for use by LSP clients that don't support their own batching of
-	// file system notifications.
-	//
-	// This option must be set to a valid duration string, for example `"100ms"`.
-	//
-	// Deprecated: this setting is deprecated and will be removed in a future
-	// version of gopls (https://go.dev/issue/55332)
-	ExperimentalWatchedFileDelay time.Duration `status:"experimental"`
-}
-
-type InlayHintOptions struct {
-	// Hints specify inlay hints that users want to see. A full list of hints
-	// that gopls uses can be found in
-	// [inlayHints.md](https://github.com/golang/tools/blob/master/gopls/doc/inlayHints.md).
-	Hints map[string]bool `status:"experimental"`
-}
-
-type NavigationOptions struct {
-	// ImportShortcut specifies whether import statements should link to
-	// documentation or go to definitions.
-	ImportShortcut ImportShortcut
-
-	// SymbolMatcher sets the algorithm that is used when finding workspace symbols.
-	SymbolMatcher SymbolMatcher `status:"advanced"`
-
-	// SymbolStyle controls how symbols are qualified in symbol responses.
-	//
-	// Example Usage:
-	//
-	// ```json5
-	// "gopls": {
-	// ...
-	//   "symbolStyle": "Dynamic",
-	// ...
-	// }
-	// ```
-	SymbolStyle SymbolStyle `status:"advanced"`
-}
-
-// UserOptions holds custom Gopls configuration (not part of the LSP) that is
-// modified by the client.
-type UserOptions struct {
-	BuildOptions
-	UIOptions
-	FormattingOptions
-
-	// VerboseOutput enables additional debug logging.
-	VerboseOutput bool `status:"debug"`
-}
-
-// EnvSlice returns Env as a slice of k=v strings.
-func (u *UserOptions) EnvSlice() []string {
-	var result []string
-	for k, v := range u.Env {
-		result = append(result, fmt.Sprintf("%v=%v", k, v))
-	}
-	return result
-}
-
-// SetEnvSlice sets Env from a slice of k=v strings.
-func (u *UserOptions) SetEnvSlice(env []string) {
-	u.Env = map[string]string{}
-	for _, kv := range env {
-		split := strings.SplitN(kv, "=", 2)
-		if len(split) != 2 {
-			continue
-		}
-		u.Env[split[0]] = split[1]
-	}
-}
-
-// DiffFunction is the type for a function that produces a set of edits that
-// convert from the before content to the after content.
-type DiffFunction func(before, after string) []diff.Edit
-
-// Hooks contains configuration that is provided to the Gopls command by the
-// main package.
-type Hooks struct {
-	// LicensesText holds third party licenses for software used by gopls.
-	LicensesText string
-
-	// GoDiff is used in gopls/hooks to get Myers' diff
-	GoDiff bool
-
-	// Whether staticcheck is supported.
-	StaticcheckSupported bool
-
-	// ComputeEdits is used to compute edits between file versions.
-	ComputeEdits DiffFunction
-
-	// URLRegexp is used to find potential URLs in comments/strings.
-	//
-	// Not all matches are shown to the user: if the matched URL is not detected
-	// as valid, it will be skipped.
-	URLRegexp *regexp.Regexp
-
-	// GofumptFormat allows the gopls module to wire-in a call to
-	// gofumpt/format.Source. langVersion and modulePath are used for some
-	// Gofumpt formatting rules -- see the Gofumpt documentation for details.
-	GofumptFormat func(ctx context.Context, langVersion, modulePath string, src []byte) ([]byte, error)
-
-	DefaultAnalyzers     map[string]*Analyzer
-	TypeErrorAnalyzers   map[string]*Analyzer
-	ConvenienceAnalyzers map[string]*Analyzer
-	StaticcheckAnalyzers map[string]*Analyzer
-}
-
-// InternalOptions contains settings that are not intended for use by the
-// average user. These may be settings used by tests or outdated settings that
-// will soon be deprecated. Some of these settings may not even be configurable
-// by the user.
-type InternalOptions struct {
-	// LiteralCompletions controls whether literal candidates such as
-	// "&someStruct{}" are offered. Tests disable this flag to simplify
-	// their expected values.
-	LiteralCompletions bool
-
-	// VerboseWorkDoneProgress controls whether the LSP server should send
-	// progress reports for all work done outside the scope of an RPC.
-	// Used by the regression tests.
-	VerboseWorkDoneProgress bool
-
-	// The following options were previously available to users, but they
-	// really shouldn't be configured by anyone other than "power users".
-
-	// CompletionDocumentation enables documentation with completion results.
-	CompletionDocumentation bool
-
-	// CompleteUnimported enables completion for packages that you do not
-	// currently import.
-	CompleteUnimported bool
-
-	// DeepCompletion enables the ability to return completions from deep
-	// inside relevant entities, rather than just the locally accessible ones.
-	//
-	// Consider this example:
-	//
-	// ```go
-	// package main
-	//
-	// import "fmt"
-	//
-	// type wrapString struct {
-	//     str string
-	// }
-	//
-	// func main() {
-	//     x := wrapString{"hello world"}
-	//     fmt.Printf(<>)
-	// }
-	// ```
-	//
-	// At the location of the `<>` in this program, deep completion would suggest
-	// the result `x.str`.
-	DeepCompletion bool
-
-	// TempModfile controls the use of the -modfile flag in Go 1.14.
-	TempModfile bool
-
-	// ShowBugReports causes a message to be shown when the first bug is reported
-	// on the server.
-	// This option applies only during initialization.
-	ShowBugReports bool
-
-	// NewDiff controls the choice of the new diff implementation. It can be
-	// 'new', 'old', or 'both', which is the default. 'both' computes diffs with
-	// both algorithms, checks that the new algorithm has worked, and write some
-	// summary statistics to a file in os.TmpDir().
-	NewDiff string
-
-	// ChattyDiagnostics controls whether to report file diagnostics for each
-	// file change. If unset, gopls only reports diagnostics when they change, or
-	// when a file is opened or closed.
-	ChattyDiagnostics bool
-}
-
-type ImportShortcut string
-
-const (
-	Both       ImportShortcut = "Both"
-	Link       ImportShortcut = "Link"
-	Definition ImportShortcut = "Definition"
-)
-
-func (s ImportShortcut) ShowLinks() bool {
-	return s == Both || s == Link
-}
-
-func (s ImportShortcut) ShowDefinition() bool {
-	return s == Both || s == Definition
-}
-
-type Matcher string
-
-const (
-	Fuzzy           Matcher = "Fuzzy"
-	CaseInsensitive Matcher = "CaseInsensitive"
-	CaseSensitive   Matcher = "CaseSensitive"
-)
-
-type SymbolMatcher string
-
-const (
-	SymbolFuzzy           SymbolMatcher = "Fuzzy"
-	SymbolFastFuzzy       SymbolMatcher = "FastFuzzy"
-	SymbolCaseInsensitive SymbolMatcher = "CaseInsensitive"
-	SymbolCaseSensitive   SymbolMatcher = "CaseSensitive"
-)
-
-type SymbolStyle string
-
-const (
-	// PackageQualifiedSymbols is package qualified symbols i.e.
-	// "pkg.Foo.Field".
-	PackageQualifiedSymbols SymbolStyle = "Package"
-	// FullyQualifiedSymbols is fully qualified symbols, i.e.
-	// "path/to/pkg.Foo.Field".
-	FullyQualifiedSymbols SymbolStyle = "Full"
-	// DynamicSymbols uses whichever qualifier results in the highest scoring
-	// match for the given symbol query. Here a "qualifier" is any "/" or "."
-	// delimited suffix of the fully qualified symbol. i.e. "to/pkg.Foo.Field" or
-	// just "Foo.Field".
-	DynamicSymbols SymbolStyle = "Dynamic"
-)
-
-type HoverKind string
-
-const (
-	SingleLine            HoverKind = "SingleLine"
-	NoDocumentation       HoverKind = "NoDocumentation"
-	SynopsisDocumentation HoverKind = "SynopsisDocumentation"
-	FullDocumentation     HoverKind = "FullDocumentation"
-
-	// Structured is an experimental setting that returns a structured hover format.
-	// This format separates the signature from the documentation, so that the client
-	// can do more manipulation of these fields.
-	//
-	// This should only be used by clients that support this behavior.
-	Structured HoverKind = "Structured"
-)
-
-type MemoryMode string
-
-const (
-	ModeNormal MemoryMode = "Normal"
-	// In DegradeClosed mode, `gopls` will collect less information about
-	// packages without open files. As a result, features like Find
-	// References and Rename will miss results in such packages.
-	ModeDegradeClosed MemoryMode = "DegradeClosed"
-)
-
-type VulncheckMode string
-
-const (
-	// Disable vulnerability analysis.
-	ModeVulncheckOff VulncheckMode = "Off"
-	// In Imports mode, `gopls` will report vulnerabilities that affect packages
-	// directly and indirectly used by the analyzed main module.
-	ModeVulncheckImports VulncheckMode = "Imports"
-
-	// TODO: VulncheckRequire, VulncheckCallgraph
-)
-
-type OptionResults []OptionResult
-
-type OptionResult struct {
-	Name  string
-	Value interface{}
-	Error error
-}
-
-func SetOptions(options *Options, opts interface{}) OptionResults {
-	var results OptionResults
-	switch opts := opts.(type) {
-	case nil:
-	case map[string]interface{}:
-		// If the user's settings contains "allExperiments", set that first,
-		// and then let them override individual settings independently.
-		var enableExperiments bool
-		for name, value := range opts {
-			if b, ok := value.(bool); name == "allExperiments" && ok && b {
-				enableExperiments = true
-				options.EnableAllExperiments()
-			}
-		}
-		seen := map[string]struct{}{}
-		for name, value := range opts {
-			results = append(results, options.set(name, value, seen))
-		}
-		// Finally, enable any experimental features that are specified in
-		// maps, which allows users to individually toggle them on or off.
-		if enableExperiments {
-			options.enableAllExperimentMaps()
-		}
-	default:
-		results = append(results, OptionResult{
-			Value: opts,
-			Error: fmt.Errorf("Invalid options type %T", opts),
-		})
-	}
-	return results
-}
-
-func (o *Options) ForClientCapabilities(caps protocol.ClientCapabilities) {
-	// Check if the client supports snippets in completion items.
-	if caps.Workspace.WorkspaceEdit != nil {
-		o.SupportedResourceOperations = caps.Workspace.WorkspaceEdit.ResourceOperations
-	}
-	if c := caps.TextDocument.Completion; c.CompletionItem.SnippetSupport {
-		o.InsertTextFormat = protocol.SnippetTextFormat
-	}
-	// Check if the client supports configuration messages.
-	o.ConfigurationSupported = caps.Workspace.Configuration
-	o.DynamicConfigurationSupported = caps.Workspace.DidChangeConfiguration.DynamicRegistration
-	o.DynamicRegistrationSemanticTokensSupported = caps.TextDocument.SemanticTokens.DynamicRegistration
-	o.DynamicWatchedFilesSupported = caps.Workspace.DidChangeWatchedFiles.DynamicRegistration
-
-	// Check which types of content format are supported by this client.
-	if hover := caps.TextDocument.Hover; len(hover.ContentFormat) > 0 {
-		o.PreferredContentFormat = hover.ContentFormat[0]
-	}
-	// Check if the client supports only line folding.
-	fr := caps.TextDocument.FoldingRange
-	o.LineFoldingOnly = fr.LineFoldingOnly
-	// Check if the client supports hierarchical document symbols.
-	o.HierarchicalDocumentSymbolSupport = caps.TextDocument.DocumentSymbol.HierarchicalDocumentSymbolSupport
-	// Check if the client supports semantic tokens
-	o.SemanticTypes = caps.TextDocument.SemanticTokens.TokenTypes
-	o.SemanticMods = caps.TextDocument.SemanticTokens.TokenModifiers
-	// we don't need Requests, as we support full functionality
-	// we don't need Formats, as there is only one, for now
-
-	// Check if the client supports diagnostic related information.
-	o.RelatedInformationSupported = caps.TextDocument.PublishDiagnostics.RelatedInformation
-	// Check if the client completion support includes tags (preferred) or deprecation
-	if caps.TextDocument.Completion.CompletionItem.TagSupport.ValueSet != nil {
-		o.CompletionTags = true
-	} else if caps.TextDocument.Completion.CompletionItem.DeprecatedSupport {
-		o.CompletionDeprecated = true
-	}
-}
-
-func (o *Options) Clone() *Options {
-	// TODO(rfindley): has this function gone stale? It appears that there are
-	// settings that are incorrectly cloned here (such as TemplateExtensions).
-	result := &Options{
-		ClientOptions:   o.ClientOptions,
-		InternalOptions: o.InternalOptions,
-		Hooks: Hooks{
-			GoDiff:               o.GoDiff,
-			StaticcheckSupported: o.StaticcheckSupported,
-			ComputeEdits:         o.ComputeEdits,
-			GofumptFormat:        o.GofumptFormat,
-			URLRegexp:            o.URLRegexp,
-		},
-		ServerOptions: o.ServerOptions,
-		UserOptions:   o.UserOptions,
-	}
-	// Fully clone any slice or map fields. Only Hooks, ExperimentalOptions,
-	// and UserOptions can be modified.
-	copyStringMap := func(src map[string]bool) map[string]bool {
-		dst := make(map[string]bool)
-		for k, v := range src {
-			dst[k] = v
-		}
-		return dst
-	}
-	result.Analyses = copyStringMap(o.Analyses)
-	result.Codelenses = copyStringMap(o.Codelenses)
-
-	copySlice := func(src []string) []string {
-		dst := make([]string, len(src))
-		copy(dst, src)
-		return dst
-	}
-	result.SetEnvSlice(o.EnvSlice())
-	result.BuildFlags = copySlice(o.BuildFlags)
-	result.DirectoryFilters = copySlice(o.DirectoryFilters)
-	result.StandaloneTags = copySlice(o.StandaloneTags)
-
-	copyAnalyzerMap := func(src map[string]*Analyzer) map[string]*Analyzer {
-		dst := make(map[string]*Analyzer)
-		for k, v := range src {
-			dst[k] = v
-		}
-		return dst
-	}
-	result.DefaultAnalyzers = copyAnalyzerMap(o.DefaultAnalyzers)
-	result.TypeErrorAnalyzers = copyAnalyzerMap(o.TypeErrorAnalyzers)
-	result.ConvenienceAnalyzers = copyAnalyzerMap(o.ConvenienceAnalyzers)
-	result.StaticcheckAnalyzers = copyAnalyzerMap(o.StaticcheckAnalyzers)
-	return result
-}
-
-func (o *Options) AddStaticcheckAnalyzer(a *analysis.Analyzer, enabled bool, severity protocol.DiagnosticSeverity) {
-	o.StaticcheckAnalyzers[a.Name] = &Analyzer{
-		Analyzer: a,
-		Enabled:  enabled,
-		Severity: severity,
-	}
-}
-
-// EnableAllExperiments turns on all of the experimental "off-by-default"
-// features offered by gopls. Any experimental features specified in maps
-// should be enabled in enableAllExperimentMaps.
-func (o *Options) EnableAllExperiments() {
-	o.SemanticTokens = true
-}
-
-func (o *Options) enableAllExperimentMaps() {
-	if _, ok := o.Codelenses[string(command.GCDetails)]; !ok {
-		o.Codelenses[string(command.GCDetails)] = true
-	}
-	if _, ok := o.Codelenses[string(command.RunGovulncheck)]; !ok {
-		o.Codelenses[string(command.RunGovulncheck)] = true
-	}
-	if _, ok := o.Analyses[unusedparams.Analyzer.Name]; !ok {
-		o.Analyses[unusedparams.Analyzer.Name] = true
-	}
-	if _, ok := o.Analyses[unusedvariable.Analyzer.Name]; !ok {
-		o.Analyses[unusedvariable.Analyzer.Name] = true
-	}
-}
-
-// validateDirectoryFilter validates if the filter string
-// - is not empty
-// - start with either + or -
-// - doesn't contain currently unsupported glob operators: *, ?
-func validateDirectoryFilter(ifilter string) (string, error) {
-	filter := fmt.Sprint(ifilter)
-	if filter == "" || (filter[0] != '+' && filter[0] != '-') {
-		return "", fmt.Errorf("invalid filter %v, must start with + or -", filter)
-	}
-	segs := strings.Split(filter[1:], "/")
-	unsupportedOps := [...]string{"?", "*"}
-	for _, seg := range segs {
-		if seg != "**" {
-			for _, op := range unsupportedOps {
-				if strings.Contains(seg, op) {
-					return "", fmt.Errorf("invalid filter %v, operator %v not supported. If you want to have this operator supported, consider filing an issue.", filter, op)
-				}
-			}
-		}
-	}
-
-	return strings.TrimRight(filepath.FromSlash(filter), "/"), nil
-}
-
-func (o *Options) set(name string, value interface{}, seen map[string]struct{}) OptionResult {
-	// Flatten the name in case we get options with a hierarchy.
-	split := strings.Split(name, ".")
-	name = split[len(split)-1]
-
-	result := OptionResult{Name: name, Value: value}
-	if _, ok := seen[name]; ok {
-		result.parseErrorf("duplicate configuration for %s", name)
-	}
-	seen[name] = struct{}{}
-
-	switch name {
-	case "env":
-		menv, ok := value.(map[string]interface{})
-		if !ok {
-			result.parseErrorf("invalid type %T, expect map", value)
-			break
-		}
-		if o.Env == nil {
-			o.Env = make(map[string]string)
-		}
-		for k, v := range menv {
-			o.Env[k] = fmt.Sprint(v)
-		}
-
-	case "buildFlags":
-		// TODO(rfindley): use asStringSlice.
-		iflags, ok := value.([]interface{})
-		if !ok {
-			result.parseErrorf("invalid type %T, expect list", value)
-			break
-		}
-		flags := make([]string, 0, len(iflags))
-		for _, flag := range iflags {
-			flags = append(flags, fmt.Sprintf("%s", flag))
-		}
-		o.BuildFlags = flags
-
-	case "directoryFilters":
-		// TODO(rfindley): use asStringSlice.
-		ifilters, ok := value.([]interface{})
-		if !ok {
-			result.parseErrorf("invalid type %T, expect list", value)
-			break
-		}
-		var filters []string
-		for _, ifilter := range ifilters {
-			filter, err := validateDirectoryFilter(fmt.Sprintf("%v", ifilter))
-			if err != nil {
-				result.parseErrorf("%v", err)
-				return result
-			}
-			filters = append(filters, strings.TrimRight(filepath.FromSlash(filter), "/"))
-		}
-		o.DirectoryFilters = filters
-
-	case "memoryMode":
-		if s, ok := result.asOneOf(
-			string(ModeNormal),
-			string(ModeDegradeClosed),
-		); ok {
-			o.MemoryMode = MemoryMode(s)
-		}
-	case "completionDocumentation":
-		result.setBool(&o.CompletionDocumentation)
-	case "usePlaceholders":
-		result.setBool(&o.UsePlaceholders)
-	case "deepCompletion":
-		result.setBool(&o.DeepCompletion)
-	case "completeUnimported":
-		result.setBool(&o.CompleteUnimported)
-	case "completionBudget":
-		result.setDuration(&o.CompletionBudget)
-	case "matcher":
-		if s, ok := result.asOneOf(
-			string(Fuzzy),
-			string(CaseSensitive),
-			string(CaseInsensitive),
-		); ok {
-			o.Matcher = Matcher(s)
-		}
-
-	case "symbolMatcher":
-		if s, ok := result.asOneOf(
-			string(SymbolFuzzy),
-			string(SymbolFastFuzzy),
-			string(SymbolCaseInsensitive),
-			string(SymbolCaseSensitive),
-		); ok {
-			o.SymbolMatcher = SymbolMatcher(s)
-		}
-
-	case "symbolStyle":
-		if s, ok := result.asOneOf(
-			string(FullyQualifiedSymbols),
-			string(PackageQualifiedSymbols),
-			string(DynamicSymbols),
-		); ok {
-			o.SymbolStyle = SymbolStyle(s)
-		}
-
-	case "hoverKind":
-		if s, ok := result.asOneOf(
-			string(NoDocumentation),
-			string(SingleLine),
-			string(SynopsisDocumentation),
-			string(FullDocumentation),
-			string(Structured),
-		); ok {
-			o.HoverKind = HoverKind(s)
-		}
-
-	case "linkTarget":
-		result.setString(&o.LinkTarget)
-
-	case "linksInHover":
-		result.setBool(&o.LinksInHover)
-
-	case "importShortcut":
-		if s, ok := result.asOneOf(string(Both), string(Link), string(Definition)); ok {
-			o.ImportShortcut = ImportShortcut(s)
-		}
-
-	case "analyses":
-		result.setBoolMap(&o.Analyses)
-
-	case "hints":
-		result.setBoolMap(&o.Hints)
-
-	case "annotations":
-		result.setAnnotationMap(&o.Annotations)
-
-	case "vulncheck":
-		if s, ok := result.asOneOf(
-			string(ModeVulncheckOff),
-			string(ModeVulncheckImports),
-		); ok {
-			o.Vulncheck = VulncheckMode(s)
-		}
-
-	case "codelenses", "codelens":
-		var lensOverrides map[string]bool
-		result.setBoolMap(&lensOverrides)
-		if result.Error == nil {
-			if o.Codelenses == nil {
-				o.Codelenses = make(map[string]bool)
-			}
-			for lens, enabled := range lensOverrides {
-				o.Codelenses[lens] = enabled
-			}
-		}
-
-		// codelens is deprecated, but still works for now.
-		// TODO(rstambler): Remove this for the gopls/v0.7.0 release.
-		if name == "codelens" {
-			result.deprecated("codelenses")
-		}
-
-	case "staticcheck":
-		if v, ok := result.asBool(); ok {
-			o.Staticcheck = v
-			if v && !o.StaticcheckSupported {
-				result.Error = fmt.Errorf("applying setting %q: staticcheck is not supported at %s;"+
-					" rebuild gopls with a more recent version of Go", result.Name, runtime.Version())
-			}
-		}
-
-	case "local":
-		result.setString(&o.Local)
-
-	case "verboseOutput":
-		result.setBool(&o.VerboseOutput)
-
-	case "verboseWorkDoneProgress":
-		result.setBool(&o.VerboseWorkDoneProgress)
-
-	case "tempModfile":
-		result.setBool(&o.TempModfile)
-
-	case "showBugReports":
-		result.setBool(&o.ShowBugReports)
-
-	case "gofumpt":
-		if v, ok := result.asBool(); ok {
-			o.Gofumpt = v
-			if v && o.GofumptFormat == nil {
-				result.Error = fmt.Errorf("applying setting %q: gofumpt is not supported at %s;"+
-					" rebuild gopls with a more recent version of Go", result.Name, runtime.Version())
-			}
-		}
-
-	case "semanticTokens":
-		result.setBool(&o.SemanticTokens)
-
-	case "noSemanticString":
-		result.setBool(&o.NoSemanticString)
-
-	case "noSemanticNumber":
-		result.setBool(&o.NoSemanticNumber)
-
-	case "expandWorkspaceToModule":
-		result.setBool(&o.ExpandWorkspaceToModule)
-
-	case "experimentalPostfixCompletions":
-		result.setBool(&o.ExperimentalPostfixCompletions)
-
-	case "experimentalWorkspaceModule":
-		const msg = "experimentalWorkspaceModule has been replaced by go workspaces, " +
-			"and will be removed in a future version of gopls (https://go.dev/issue/55331) -- " +
-			"see https://github.com/golang/tools/blob/master/gopls/doc/workspace.md " +
-			"for information on setting up multi-module workspaces using go.work files"
-		result.softErrorf(msg)
-		result.setBool(&o.ExperimentalWorkspaceModule)
-
-	case "experimentalTemplateSupport": // TODO(pjw): remove after June 2022
-		result.deprecated("")
-
-	case "templateExtensions":
-		if iexts, ok := value.([]interface{}); ok {
-			ans := []string{}
-			for _, x := range iexts {
-				ans = append(ans, fmt.Sprint(x))
-			}
-			o.TemplateExtensions = ans
-			break
-		}
-		if value == nil {
-			o.TemplateExtensions = nil
-			break
-		}
-		result.parseErrorf("unexpected type %T not []string", value)
-
-	case "experimentalDiagnosticsDelay":
-		result.deprecated("diagnosticsDelay")
-
-	case "diagnosticsDelay":
-		result.setDuration(&o.DiagnosticsDelay)
-
-	case "experimentalWatchedFileDelay":
-		const msg = "experimentalWatchedFileDelay is deprecated, and will " +
-			"be removed in a future version of gopls (https://go.dev/issue/55332)"
-		result.softErrorf(msg)
-		result.setDuration(&o.ExperimentalWatchedFileDelay)
-
-	case "experimentalPackageCacheKey":
-		result.setBool(&o.ExperimentalPackageCacheKey)
-
-	case "allowModfileModifications":
-		result.setBool(&o.AllowModfileModifications)
-
-	case "allowImplicitNetworkAccess":
-		result.setBool(&o.AllowImplicitNetworkAccess)
-
-	case "experimentalUseInvalidMetadata":
-		result.deprecated("")
-
-	case "standaloneTags":
-		result.setStringSlice(&o.StandaloneTags)
-
-	case "allExperiments":
-		// This setting should be handled before all of the other options are
-		// processed, so do nothing here.
-
-	case "newDiff":
-		result.setString(&o.NewDiff)
-
-	case "chattyDiagnostics":
-		result.setBool(&o.ChattyDiagnostics)
-
-	// Replaced settings.
-	case "experimentalDisabledAnalyses":
-		result.deprecated("analyses")
-
-	case "disableDeepCompletion":
-		result.deprecated("deepCompletion")
-
-	case "disableFuzzyMatching":
-		result.deprecated("fuzzyMatching")
-
-	case "wantCompletionDocumentation":
-		result.deprecated("completionDocumentation")
-
-	case "wantUnimportedCompletions":
-		result.deprecated("completeUnimported")
-
-	case "fuzzyMatching":
-		result.deprecated("matcher")
-
-	case "caseSensitiveCompletion":
-		result.deprecated("matcher")
-
-	// Deprecated settings.
-	case "wantSuggestedFixes":
-		result.deprecated("")
-
-	case "noIncrementalSync":
-		result.deprecated("")
-
-	case "watchFileChanges":
-		result.deprecated("")
-
-	case "go-diff":
-		result.deprecated("")
-
-	default:
-		result.unexpected()
-	}
-	return result
-}
-
-// parseErrorf reports an error parsing the current configuration value.
-func (r *OptionResult) parseErrorf(msg string, values ...interface{}) {
-	if false {
-		_ = fmt.Sprintf(msg, values...) // this causes vet to check this like printf
-	}
-	prefix := fmt.Sprintf("parsing setting %q: ", r.Name)
-	r.Error = fmt.Errorf(prefix+msg, values...)
-}
-
-// A SoftError is an error that does not affect the functionality of gopls.
-type SoftError struct {
-	msg string
-}
-
-func (e *SoftError) Error() string {
-	return e.msg
-}
-
-// softErrorf reports an error that does not affect the functionality of gopls
-// (a warning in the UI).
-// The formatted message will be shown to the user unmodified.
-func (r *OptionResult) softErrorf(format string, values ...interface{}) {
-	msg := fmt.Sprintf(format, values...)
-	r.Error = &SoftError{msg}
-}
-
-// deprecated reports the current setting as deprecated. If 'replacement' is
-// non-nil, it is suggested to the user.
-func (r *OptionResult) deprecated(replacement string) {
-	msg := fmt.Sprintf("gopls setting %q is deprecated", r.Name)
-	if replacement != "" {
-		msg = fmt.Sprintf("%s, use %q instead", msg, replacement)
-	}
-	r.Error = &SoftError{msg}
-}
-
-// unexpected reports that the current setting is not known to gopls.
-func (r *OptionResult) unexpected() {
-	r.Error = fmt.Errorf("unexpected gopls setting %q", r.Name)
-}
-
-func (r *OptionResult) asBool() (bool, bool) {
-	b, ok := r.Value.(bool)
-	if !ok {
-		r.parseErrorf("invalid type %T, expect bool", r.Value)
-		return false, false
-	}
-	return b, true
-}
-
-func (r *OptionResult) setBool(b *bool) {
-	if v, ok := r.asBool(); ok {
-		*b = v
-	}
-}
-
-func (r *OptionResult) setDuration(d *time.Duration) {
-	if v, ok := r.asString(); ok {
-		parsed, err := time.ParseDuration(v)
-		if err != nil {
-			r.parseErrorf("failed to parse duration %q: %v", v, err)
-			return
-		}
-		*d = parsed
-	}
-}
-
-func (r *OptionResult) setBoolMap(bm *map[string]bool) {
-	m := r.asBoolMap()
-	*bm = m
-}
-
-func (r *OptionResult) setAnnotationMap(bm *map[Annotation]bool) {
-	all := r.asBoolMap()
-	if all == nil {
-		return
-	}
-	// Default to everything enabled by default.
-	m := make(map[Annotation]bool)
-	for k, enabled := range all {
-		a, err := asOneOf(
-			k,
-			string(Nil),
-			string(Escape),
-			string(Inline),
-			string(Bounds),
-		)
-		if err != nil {
-			// In case of an error, process any legacy values.
-			switch k {
-			case "noEscape":
-				m[Escape] = false
-				r.parseErrorf(`"noEscape" is deprecated, set "Escape: false" instead`)
-			case "noNilcheck":
-				m[Nil] = false
-				r.parseErrorf(`"noNilcheck" is deprecated, set "Nil: false" instead`)
-			case "noInline":
-				m[Inline] = false
-				r.parseErrorf(`"noInline" is deprecated, set "Inline: false" instead`)
-			case "noBounds":
-				m[Bounds] = false
-				r.parseErrorf(`"noBounds" is deprecated, set "Bounds: false" instead`)
-			default:
-				r.parseErrorf("%v", err)
-			}
-			continue
-		}
-		m[Annotation(a)] = enabled
-	}
-	*bm = m
-}
-
-func (r *OptionResult) asBoolMap() map[string]bool {
-	all, ok := r.Value.(map[string]interface{})
-	if !ok {
-		r.parseErrorf("invalid type %T for map[string]bool option", r.Value)
-		return nil
-	}
-	m := make(map[string]bool)
-	for a, enabled := range all {
-		if e, ok := enabled.(bool); ok {
-			m[a] = e
-		} else {
-			r.parseErrorf("invalid type %T for map key %q", enabled, a)
-			return m
-		}
-	}
-	return m
-}
-
-func (r *OptionResult) asString() (string, bool) {
-	b, ok := r.Value.(string)
-	if !ok {
-		r.parseErrorf("invalid type %T, expect string", r.Value)
-		return "", false
-	}
-	return b, true
-}
-
-func (r *OptionResult) asStringSlice() ([]string, bool) {
-	iList, ok := r.Value.([]interface{})
-	if !ok {
-		r.parseErrorf("invalid type %T, expect list", r.Value)
-		return nil, false
-	}
-	var list []string
-	for _, elem := range iList {
-		s, ok := elem.(string)
-		if !ok {
-			r.parseErrorf("invalid element type %T, expect string", elem)
-			return nil, false
-		}
-		list = append(list, s)
-	}
-	return list, true
-}
-
-func (r *OptionResult) asOneOf(options ...string) (string, bool) {
-	s, ok := r.asString()
-	if !ok {
-		return "", false
-	}
-	s, err := asOneOf(s, options...)
-	if err != nil {
-		r.parseErrorf("%v", err)
-	}
-	return s, err == nil
-}
-
-func asOneOf(str string, options ...string) (string, error) {
-	lower := strings.ToLower(str)
-	for _, opt := range options {
-		if strings.ToLower(opt) == lower {
-			return opt, nil
-		}
-	}
-	return "", fmt.Errorf("invalid option %q for enum", str)
-}
-
-func (r *OptionResult) setString(s *string) {
-	if v, ok := r.asString(); ok {
-		*s = v
-	}
-}
-
-func (r *OptionResult) setStringSlice(s *[]string) {
-	if v, ok := r.asStringSlice(); ok {
-		*s = v
-	}
-}
-
-func typeErrorAnalyzers() map[string]*Analyzer {
-	return map[string]*Analyzer{
-		fillreturns.Analyzer.Name: {
-			Analyzer:   fillreturns.Analyzer,
-			ActionKind: []protocol.CodeActionKind{protocol.SourceFixAll, protocol.QuickFix},
-			Enabled:    true,
-		},
-		nonewvars.Analyzer.Name: {
-			Analyzer: nonewvars.Analyzer,
-			Enabled:  true,
-		},
-		noresultvalues.Analyzer.Name: {
-			Analyzer: noresultvalues.Analyzer,
-			Enabled:  true,
-		},
-		undeclaredname.Analyzer.Name: {
-			Analyzer: undeclaredname.Analyzer,
-			Fix:      UndeclaredName,
-			Enabled:  true,
-		},
-		unusedvariable.Analyzer.Name: {
-			Analyzer: unusedvariable.Analyzer,
-			Enabled:  false,
-		},
-	}
-}
-
-func convenienceAnalyzers() map[string]*Analyzer {
-	return map[string]*Analyzer{
-		fillstruct.Analyzer.Name: {
-			Analyzer:   fillstruct.Analyzer,
-			Fix:        FillStruct,
-			Enabled:    true,
-			ActionKind: []protocol.CodeActionKind{protocol.RefactorRewrite},
-		},
-		stubmethods.Analyzer.Name: {
-			Analyzer:   stubmethods.Analyzer,
-			ActionKind: []protocol.CodeActionKind{protocol.RefactorRewrite},
-			Fix:        StubMethods,
-			Enabled:    true,
-		},
-	}
-}
-
-func defaultAnalyzers() map[string]*Analyzer {
-	return map[string]*Analyzer{
-		// The traditional vet suite:
-		asmdecl.Analyzer.Name:       {Analyzer: asmdecl.Analyzer, Enabled: true},
-		assign.Analyzer.Name:        {Analyzer: assign.Analyzer, Enabled: true},
-		atomic.Analyzer.Name:        {Analyzer: atomic.Analyzer, Enabled: true},
-		bools.Analyzer.Name:         {Analyzer: bools.Analyzer, Enabled: true},
-		buildtag.Analyzer.Name:      {Analyzer: buildtag.Analyzer, Enabled: true},
-		cgocall.Analyzer.Name:       {Analyzer: cgocall.Analyzer, Enabled: true},
-		composite.Analyzer.Name:     {Analyzer: composite.Analyzer, Enabled: true},
-		copylock.Analyzer.Name:      {Analyzer: copylock.Analyzer, Enabled: true},
-		errorsas.Analyzer.Name:      {Analyzer: errorsas.Analyzer, Enabled: true},
-		httpresponse.Analyzer.Name:  {Analyzer: httpresponse.Analyzer, Enabled: true},
-		ifaceassert.Analyzer.Name:   {Analyzer: ifaceassert.Analyzer, Enabled: true},
-		loopclosure.Analyzer.Name:   {Analyzer: loopclosure.Analyzer, Enabled: true},
-		lostcancel.Analyzer.Name:    {Analyzer: lostcancel.Analyzer, Enabled: true},
-		nilfunc.Analyzer.Name:       {Analyzer: nilfunc.Analyzer, Enabled: true},
-		printf.Analyzer.Name:        {Analyzer: printf.Analyzer, Enabled: true},
-		shift.Analyzer.Name:         {Analyzer: shift.Analyzer, Enabled: true},
-		stdmethods.Analyzer.Name:    {Analyzer: stdmethods.Analyzer, Enabled: true},
-		stringintconv.Analyzer.Name: {Analyzer: stringintconv.Analyzer, Enabled: true},
-		structtag.Analyzer.Name:     {Analyzer: structtag.Analyzer, Enabled: true},
-		tests.Analyzer.Name:         {Analyzer: tests.Analyzer, Enabled: true},
-		unmarshal.Analyzer.Name:     {Analyzer: unmarshal.Analyzer, Enabled: true},
-		unreachable.Analyzer.Name:   {Analyzer: unreachable.Analyzer, Enabled: true},
-		unsafeptr.Analyzer.Name:     {Analyzer: unsafeptr.Analyzer, Enabled: true},
-		unusedresult.Analyzer.Name:  {Analyzer: unusedresult.Analyzer, Enabled: true},
-
-		// Non-vet analyzers:
-		atomicalign.Analyzer.Name:      {Analyzer: atomicalign.Analyzer, Enabled: true},
-		deepequalerrors.Analyzer.Name:  {Analyzer: deepequalerrors.Analyzer, Enabled: true},
-		fieldalignment.Analyzer.Name:   {Analyzer: fieldalignment.Analyzer, Enabled: false},
-		nilness.Analyzer.Name:          {Analyzer: nilness.Analyzer, Enabled: false},
-		shadow.Analyzer.Name:           {Analyzer: shadow.Analyzer, Enabled: false},
-		sortslice.Analyzer.Name:        {Analyzer: sortslice.Analyzer, Enabled: true},
-		testinggoroutine.Analyzer.Name: {Analyzer: testinggoroutine.Analyzer, Enabled: true},
-		unusedparams.Analyzer.Name:     {Analyzer: unusedparams.Analyzer, Enabled: false},
-		unusedwrite.Analyzer.Name:      {Analyzer: unusedwrite.Analyzer, Enabled: false},
-		useany.Analyzer.Name:           {Analyzer: useany.Analyzer, Enabled: false},
-		infertypeargs.Analyzer.Name:    {Analyzer: infertypeargs.Analyzer, Enabled: true},
-		embeddirective.Analyzer.Name:   {Analyzer: embeddirective.Analyzer, Enabled: true},
-		timeformat.Analyzer.Name:       {Analyzer: timeformat.Analyzer, Enabled: true},
-
-		// gofmt -s suite:
-		simplifycompositelit.Analyzer.Name: {
-			Analyzer:   simplifycompositelit.Analyzer,
-			Enabled:    true,
-			ActionKind: []protocol.CodeActionKind{protocol.SourceFixAll, protocol.QuickFix},
-		},
-		simplifyrange.Analyzer.Name: {
-			Analyzer:   simplifyrange.Analyzer,
-			Enabled:    true,
-			ActionKind: []protocol.CodeActionKind{protocol.SourceFixAll, protocol.QuickFix},
-		},
-		simplifyslice.Analyzer.Name: {
-			Analyzer:   simplifyslice.Analyzer,
-			Enabled:    true,
-			ActionKind: []protocol.CodeActionKind{protocol.SourceFixAll, protocol.QuickFix},
-		},
-	}
-}
-
-func urlRegexp() *regexp.Regexp {
-	// Ensure links are matched as full words, not anywhere.
-	re := regexp.MustCompile(`\b(http|ftp|https)://([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?\b`)
-	re.Longest()
-	return re
-}
-
-type APIJSON struct {
-	Options   map[string][]*OptionJSON
-	Commands  []*CommandJSON
-	Lenses    []*LensJSON
-	Analyzers []*AnalyzerJSON
-	Hints     []*HintJSON
-}
-
-type OptionJSON struct {
-	Name       string
-	Type       string
-	Doc        string
-	EnumKeys   EnumKeys
-	EnumValues []EnumValue
-	Default    string
-	Status     string
-	Hierarchy  string
-}
-
-func (o *OptionJSON) String() string {
-	return o.Name
-}
-
-func (o *OptionJSON) Write(w io.Writer) {
-	fmt.Fprintf(w, "**%v** *%v*\n\n", o.Name, o.Type)
-	writeStatus(w, o.Status)
-	enumValues := collectEnums(o)
-	fmt.Fprintf(w, "%v%v\nDefault: `%v`.\n\n", o.Doc, enumValues, o.Default)
-}
-
-func writeStatus(section io.Writer, status string) {
-	switch status {
-	case "":
-	case "advanced":
-		fmt.Fprint(section, "**This is an advanced setting and should not be configured by most `gopls` users.**\n\n")
-	case "debug":
-		fmt.Fprint(section, "**This setting is for debugging purposes only.**\n\n")
-	case "experimental":
-		fmt.Fprint(section, "**This setting is experimental and may be deleted.**\n\n")
-	default:
-		fmt.Fprintf(section, "**Status: %s.**\n\n", status)
-	}
-}
-
-var parBreakRE = regexp.MustCompile("\n{2,}")
-
-func collectEnums(opt *OptionJSON) string {
-	var b strings.Builder
-	write := func(name, doc string, index, len int) {
-		if doc != "" {
-			unbroken := parBreakRE.ReplaceAllString(doc, "\\\n")
-			fmt.Fprintf(&b, "* %s\n", strings.TrimSpace(unbroken))
-		} else {
-			fmt.Fprintf(&b, "* `%s`\n", name)
-		}
-	}
-	if len(opt.EnumValues) > 0 && opt.Type == "enum" {
-		b.WriteString("\nMust be one of:\n\n")
-		for i, val := range opt.EnumValues {
-			write(val.Value, val.Doc, i, len(opt.EnumValues))
-		}
-	} else if len(opt.EnumKeys.Keys) > 0 && shouldShowEnumKeysInSettings(opt.Name) {
-		b.WriteString("\nCan contain any of:\n\n")
-		for i, val := range opt.EnumKeys.Keys {
-			write(val.Name, val.Doc, i, len(opt.EnumKeys.Keys))
-		}
-	}
-	return b.String()
-}
-
-func shouldShowEnumKeysInSettings(name string) bool {
-	// These fields have too many possible options to print.
-	return !(name == "analyses" || name == "codelenses" || name == "hints")
-}
-
-type EnumKeys struct {
-	ValueType string
-	Keys      []EnumKey
-}
-
-type EnumKey struct {
-	Name    string
-	Doc     string
-	Default string
-}
-
-type EnumValue struct {
-	Value string
-	Doc   string
-}
-
-type CommandJSON struct {
-	Command   string
-	Title     string
-	Doc       string
-	ArgDoc    string
-	ResultDoc string
-}
-
-func (c *CommandJSON) String() string {
-	return c.Command
-}
-
-func (c *CommandJSON) Write(w io.Writer) {
-	fmt.Fprintf(w, "### **%v**\nIdentifier: `%v`\n\n%v\n\n", c.Title, c.Command, c.Doc)
-	if c.ArgDoc != "" {
-		fmt.Fprintf(w, "Args:\n\n```\n%s\n```\n\n", c.ArgDoc)
-	}
-	if c.ResultDoc != "" {
-		fmt.Fprintf(w, "Result:\n\n```\n%s\n```\n\n", c.ResultDoc)
-	}
-}
-
-type LensJSON struct {
-	Lens  string
-	Title string
-	Doc   string
-}
-
-func (l *LensJSON) String() string {
-	return l.Title
-}
-
-func (l *LensJSON) Write(w io.Writer) {
-	fmt.Fprintf(w, "%s (%s): %s", l.Title, l.Lens, l.Doc)
-}
-
-type AnalyzerJSON struct {
-	Name    string
-	Doc     string
-	Default bool
-}
-
-func (a *AnalyzerJSON) String() string {
-	return a.Name
-}
-
-func (a *AnalyzerJSON) Write(w io.Writer) {
-	fmt.Fprintf(w, "%s (%s): %v", a.Name, a.Doc, a.Default)
-}
-
-type HintJSON struct {
-	Name    string
-	Doc     string
-	Default bool
-}
-
-func (h *HintJSON) String() string {
-	return h.Name
-}
-
-func (h *HintJSON) Write(w io.Writer) {
-	fmt.Fprintf(w, "%s (%s): %v", h.Name, h.Doc, h.Default)
-}
diff -urN a/gopls/internal/lsp/source/options_test.go b/gopls/internal/lsp/source/options_test.go
--- a/gopls/internal/lsp/source/options_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/options_test.go	1969-12-31 16:00:00
@@ -1,206 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"testing"
-	"time"
-)
-
-func TestSetOption(t *testing.T) {
-	tests := []struct {
-		name      string
-		value     interface{}
-		wantError bool
-		check     func(Options) bool
-	}{
-		{
-			name:  "symbolStyle",
-			value: "Dynamic",
-			check: func(o Options) bool { return o.SymbolStyle == DynamicSymbols },
-		},
-		{
-			name:      "symbolStyle",
-			value:     "",
-			wantError: true,
-			check:     func(o Options) bool { return o.SymbolStyle == "" },
-		},
-		{
-			name:      "symbolStyle",
-			value:     false,
-			wantError: true,
-			check:     func(o Options) bool { return o.SymbolStyle == "" },
-		},
-		{
-			name:  "symbolMatcher",
-			value: "caseInsensitive",
-			check: func(o Options) bool { return o.SymbolMatcher == SymbolCaseInsensitive },
-		},
-		{
-			name:  "completionBudget",
-			value: "2s",
-			check: func(o Options) bool { return o.CompletionBudget == 2*time.Second },
-		},
-		{
-			name:      "staticcheck",
-			value:     true,
-			check:     func(o Options) bool { return o.Staticcheck == true },
-			wantError: true, // o.StaticcheckSupported is unset
-		},
-		{
-			name:  "codelenses",
-			value: map[string]interface{}{"generate": true},
-			check: func(o Options) bool { return o.Codelenses["generate"] },
-		},
-		{
-			name:  "allExperiments",
-			value: true,
-			check: func(o Options) bool {
-				return true // just confirm that we handle this setting
-			},
-		},
-		{
-			name:  "hoverKind",
-			value: "FullDocumentation",
-			check: func(o Options) bool {
-				return o.HoverKind == FullDocumentation
-			},
-		},
-		{
-			name:  "hoverKind",
-			value: "NoDocumentation",
-			check: func(o Options) bool {
-				return o.HoverKind == NoDocumentation
-			},
-		},
-		{
-			name:  "hoverKind",
-			value: "SingleLine",
-			check: func(o Options) bool {
-				return o.HoverKind == SingleLine
-			},
-		},
-		{
-			name:  "hoverKind",
-			value: "Structured",
-			check: func(o Options) bool {
-				return o.HoverKind == Structured
-			},
-		},
-		{
-			name:  "ui.documentation.hoverKind",
-			value: "Structured",
-			check: func(o Options) bool {
-				return o.HoverKind == Structured
-			},
-		},
-		{
-			name:  "matcher",
-			value: "Fuzzy",
-			check: func(o Options) bool {
-				return o.Matcher == Fuzzy
-			},
-		},
-		{
-			name:  "matcher",
-			value: "CaseSensitive",
-			check: func(o Options) bool {
-				return o.Matcher == CaseSensitive
-			},
-		},
-		{
-			name:  "matcher",
-			value: "CaseInsensitive",
-			check: func(o Options) bool {
-				return o.Matcher == CaseInsensitive
-			},
-		},
-		{
-			name:  "env",
-			value: map[string]interface{}{"testing": "true"},
-			check: func(o Options) bool {
-				v, found := o.Env["testing"]
-				return found && v == "true"
-			},
-		},
-		{
-			name:      "env",
-			value:     []string{"invalid", "input"},
-			wantError: true,
-			check: func(o Options) bool {
-				return o.Env == nil
-			},
-		},
-		{
-			name:  "directoryFilters",
-			value: []interface{}{"-node_modules", "+project_a"},
-			check: func(o Options) bool {
-				return len(o.DirectoryFilters) == 2
-			},
-		},
-		{
-			name:      "directoryFilters",
-			value:     []interface{}{"invalid"},
-			wantError: true,
-			check: func(o Options) bool {
-				return len(o.DirectoryFilters) == 0
-			},
-		},
-		{
-			name:      "directoryFilters",
-			value:     []string{"-invalid", "+type"},
-			wantError: true,
-			check: func(o Options) bool {
-				return len(o.DirectoryFilters) == 0
-			},
-		},
-		{
-			name: "annotations",
-			value: map[string]interface{}{
-				"Nil":      false,
-				"noBounds": true,
-			},
-			wantError: true,
-			check: func(o Options) bool {
-				return !o.Annotations[Nil] && !o.Annotations[Bounds]
-			},
-		},
-		{
-			name:      "vulncheck",
-			value:     []interface{}{"invalid"},
-			wantError: true,
-			check: func(o Options) bool {
-				return o.Vulncheck == "" // For invalid value, default to 'off'.
-			},
-		},
-		{
-			name:  "vulncheck",
-			value: "Imports",
-			check: func(o Options) bool {
-				return o.Vulncheck == ModeVulncheckImports // For invalid value, default to 'off'.
-			},
-		},
-		{
-			name:  "vulncheck",
-			value: "imports",
-			check: func(o Options) bool {
-				return o.Vulncheck == ModeVulncheckImports
-			},
-		},
-	}
-
-	for _, test := range tests {
-		var opts Options
-		result := opts.set(test.name, test.value, map[string]struct{}{})
-		if (result.Error != nil) != test.wantError {
-			t.Fatalf("Options.set(%q, %v): result.Error = %v, want error: %t", test.name, test.value, result.Error, test.wantError)
-		}
-		// TODO: this could be made much better using cmp.Diff, if that becomes
-		// available in this module.
-		if !test.check(opts) {
-			t.Errorf("Options.set(%q, %v): unexpected result %+v", test.name, test.value, opts)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/source/references.go b/gopls/internal/lsp/source/references.go
--- a/gopls/internal/lsp/source/references.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/references.go	1969-12-31 16:00:00
@@ -1,311 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-)
-
-// ReferenceInfo holds information about reference to an identifier in Go source.
-type ReferenceInfo struct {
-	Name string
-	MappedRange
-	ident         *ast.Ident
-	obj           types.Object
-	pkg           Package
-	isDeclaration bool
-}
-
-// References returns a list of references for a given identifier within the packages
-// containing i.File. Declarations appear first in the result.
-func References(ctx context.Context, snapshot Snapshot, f FileHandle, pp protocol.Position, includeDeclaration bool) ([]*ReferenceInfo, error) {
-	ctx, done := event.Start(ctx, "source.References")
-	defer done()
-
-	// Is the cursor within the package name declaration?
-	pgf, inPackageName, err := parsePackageNameDecl(ctx, snapshot, f, pp)
-	if err != nil {
-		return nil, err
-	}
-	if inPackageName {
-		// TODO(rfindley): this is redundant with package renaming. Refactor to share logic.
-		metas, err := snapshot.MetadataForFile(ctx, f.URI())
-		if err != nil {
-			return nil, err
-		}
-		if len(metas) == 0 {
-			return nil, fmt.Errorf("found no package containing %s", f.URI())
-		}
-		targetPkg := metas[len(metas)-1] // widest package
-
-		// Find external direct references to the package (imports).
-		rdeps, err := snapshot.ReverseDependencies(ctx, targetPkg.ID, false)
-		if err != nil {
-			return nil, err
-		}
-
-		var refs []*ReferenceInfo
-		for _, rdep := range rdeps {
-			for _, uri := range rdep.CompiledGoFiles {
-				fh, err := snapshot.GetFile(ctx, uri)
-				if err != nil {
-					return nil, err
-				}
-				f, err := snapshot.ParseGo(ctx, fh, ParseHeader)
-				if err != nil {
-					return nil, err
-				}
-				for _, imp := range f.File.Imports {
-					if rdep.DepsByImpPath[UnquoteImportPath(imp)] == targetPkg.ID {
-						refs = append(refs, &ReferenceInfo{
-							Name:        pgf.File.Name.Name,
-							MappedRange: NewMappedRange(f.Mapper, imp.Pos(), imp.End()),
-						})
-					}
-				}
-			}
-		}
-
-		// Find the package declaration of each file in the target package itself.
-		for _, uri := range targetPkg.CompiledGoFiles {
-			fh, err := snapshot.GetFile(ctx, uri)
-			if err != nil {
-				return nil, err
-			}
-			f, err := snapshot.ParseGo(ctx, fh, ParseHeader)
-			if err != nil {
-				return nil, err
-			}
-			refs = append(refs, &ReferenceInfo{
-				Name:        pgf.File.Name.Name,
-				MappedRange: NewMappedRange(f.Mapper, f.File.Name.Pos(), f.File.Name.End()),
-			})
-		}
-
-		return refs, nil
-	}
-
-	qualifiedObjs, err := qualifiedObjsAtProtocolPos(ctx, snapshot, f.URI(), pp)
-	// Don't return references for builtin types.
-	if errors.Is(err, errBuiltin) {
-		return nil, nil
-	}
-	if err != nil {
-		return nil, err
-	}
-
-	refs, err := references(ctx, snapshot, qualifiedObjs, includeDeclaration, true, false)
-	if err != nil {
-		return nil, err
-	}
-
-	toSort := refs
-	if includeDeclaration {
-		toSort = refs[1:]
-	}
-	sort.Slice(toSort, func(i, j int) bool {
-		x, y := toSort[i], toSort[j]
-		if cmp := strings.Compare(string(x.URI()), string(y.URI())); cmp != 0 {
-			return cmp < 0
-		}
-		return x.ident.Pos() < y.ident.Pos()
-	})
-	return refs, nil
-}
-
-// parsePackageNameDecl is a convenience function that parses and
-// returns the package name declaration of file fh, and reports
-// whether the position ppos lies within it.
-func parsePackageNameDecl(ctx context.Context, snapshot Snapshot, fh FileHandle, ppos protocol.Position) (*ParsedGoFile, bool, error) {
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseHeader)
-	if err != nil {
-		return nil, false, err
-	}
-	// Careful: because we used ParseHeader,
-	// Mapper.Pos(ppos) may be beyond EOF => (0, err).
-	pos, _ := pgf.Mapper.Pos(ppos)
-	return pgf, pgf.File.Name.Pos() <= pos && pos <= pgf.File.Name.End(), nil
-}
-
-// references is a helper function to avoid recomputing qualifiedObjsAtProtocolPos.
-// The first element of qos is considered to be the declaration;
-// if isDeclaration, the first result is an extra item for it.
-// Only the definition-related fields of qualifiedObject are used.
-// (Arguably it should accept a smaller data type.)
-func references(ctx context.Context, snapshot Snapshot, qos []qualifiedObject, includeDeclaration, includeInterfaceRefs, includeEmbeddedRefs bool) ([]*ReferenceInfo, error) {
-	var (
-		references []*ReferenceInfo
-		seen       = make(map[positionKey]bool)
-	)
-
-	pos := qos[0].obj.Pos()
-	if pos == token.NoPos {
-		return nil, fmt.Errorf("no position for %s", qos[0].obj) // e.g. error.Error
-	}
-	// Inv: qos[0].pkg != nil, since Pos is valid.
-	// Inv: qos[*].pkg != nil, since all qos are logically the same declaration.
-	filename := safetoken.StartPosition(qos[0].pkg.FileSet(), pos).Filename
-	pgf, err := qos[0].pkg.File(span.URIFromPath(filename))
-	if err != nil {
-		return nil, err
-	}
-	declIdent, err := findIdentifier(ctx, snapshot, qos[0].pkg, pgf, qos[0].obj.Pos())
-	if err != nil {
-		return nil, err
-	}
-	// Make sure declaration is the first item in the response.
-	if includeDeclaration {
-		references = append(references, &ReferenceInfo{
-			MappedRange:   declIdent.MappedRange,
-			Name:          qos[0].obj.Name(),
-			ident:         declIdent.ident,
-			obj:           qos[0].obj,
-			pkg:           declIdent.pkg,
-			isDeclaration: true,
-		})
-	}
-
-	for _, qo := range qos {
-		var searchPkgs []Package
-
-		// Only search dependents if the object is exported.
-		if qo.obj.Exported() {
-			// If obj is a package-level object, we need only search
-			// among direct reverse dependencies.
-			// TODO(adonovan): opt: this will still spuriously search
-			// transitively for (e.g.) capitalized local variables.
-			// We could do better by checking for an objectpath.
-			transitive := qo.obj.Pkg().Scope().Lookup(qo.obj.Name()) != qo.obj
-			rdeps, err := snapshot.ReverseDependencies(ctx, qo.pkg.ID(), transitive)
-			if err != nil {
-				return nil, err
-			}
-			ids := make([]PackageID, 0, len(rdeps))
-			for _, rdep := range rdeps {
-				ids = append(ids, rdep.ID)
-			}
-			// TODO(adonovan): opt: build a search index
-			// that doesn't require type checking.
-			reverseDeps, err := snapshot.TypeCheck(ctx, TypecheckFull, ids...)
-			if err != nil {
-				return nil, err
-			}
-			searchPkgs = append(searchPkgs, reverseDeps...)
-		}
-		// Add the package in which the identifier is declared.
-		searchPkgs = append(searchPkgs, qo.pkg)
-		for _, pkg := range searchPkgs {
-			for ident, obj := range pkg.GetTypesInfo().Uses {
-				// For instantiated objects (as in methods or fields on instantiated
-				// types), we may not have pointer-identical objects but still want to
-				// consider them references.
-				if !equalOrigin(obj, qo.obj) {
-					// If ident is not a use of qo.obj, skip it, with one exception:
-					// uses of an embedded field can be considered references of the
-					// embedded type name
-					if !includeEmbeddedRefs {
-						continue
-					}
-					v, ok := obj.(*types.Var)
-					if !ok || !v.Embedded() {
-						continue
-					}
-					named, ok := v.Type().(*types.Named)
-					if !ok || named.Obj() != qo.obj {
-						continue
-					}
-				}
-				key, found := packagePositionKey(pkg, ident.Pos())
-				if !found {
-					bug.Reportf("ident %v (pos: %v) not found in package %v", ident.Name, ident.Pos(), pkg.Name())
-					continue
-				}
-				if seen[key] {
-					continue
-				}
-				seen[key] = true
-				rng, err := posToMappedRange(pkg, ident.Pos(), ident.End())
-				if err != nil {
-					return nil, err
-				}
-				references = append(references, &ReferenceInfo{
-					Name:        ident.Name,
-					ident:       ident,
-					pkg:         pkg,
-					obj:         obj,
-					MappedRange: rng,
-				})
-			}
-		}
-	}
-
-	// When searching on type name, don't include interface references -- they
-	// would be things like all references to Stringer for any type that
-	// happened to have a String method.
-	_, isType := declIdent.Declaration.obj.(*types.TypeName)
-	if includeInterfaceRefs && !isType {
-		// TODO(adonovan): opt: don't go back into the position domain:
-		// we have complete type information already.
-		declRange, err := declIdent.Range()
-		if err != nil {
-			return nil, err
-		}
-		fh, err := snapshot.GetFile(ctx, declIdent.URI())
-		if err != nil {
-			return nil, err
-		}
-		interfaceRefs, err := interfaceReferences(ctx, snapshot, fh, declRange.Start)
-		if err != nil {
-			return nil, err
-		}
-		references = append(references, interfaceRefs...)
-	}
-
-	return references, nil
-}
-
-// equalOrigin reports whether obj1 and obj2 have equivalent origin object.
-// This may be the case even if obj1 != obj2, if one or both of them is
-// instantiated.
-func equalOrigin(obj1, obj2 types.Object) bool {
-	return obj1.Pkg() == obj2.Pkg() && obj1.Pos() == obj2.Pos() && obj1.Name() == obj2.Name()
-}
-
-// interfaceReferences returns the references to the interfaces implemented by
-// the type or method at the given position.
-func interfaceReferences(ctx context.Context, s Snapshot, f FileHandle, pp protocol.Position) ([]*ReferenceInfo, error) {
-	implementations, err := implementations(ctx, s, f, pp)
-	if err != nil {
-		if errors.Is(err, ErrNotAType) {
-			return nil, nil
-		}
-		return nil, err
-	}
-
-	// Make a separate call to references() for each element
-	// since it treats the first qualifiedObject as a definition.
-	var refs []*ReferenceInfo
-	for _, impl := range implementations {
-		implRefs, err := references(ctx, s, []qualifiedObject{impl}, false, false, false)
-		if err != nil {
-			return nil, err
-		}
-		refs = append(refs, implRefs...)
-	}
-	return refs, nil
-}
diff -urN a/gopls/internal/lsp/source/rename.go b/gopls/internal/lsp/source/rename.go
--- a/gopls/internal/lsp/source/rename.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/rename.go	1969-12-31 16:00:00
@@ -1,827 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"path"
-	"path/filepath"
-	"regexp"
-	"sort"
-	"strconv"
-	"strings"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/go/types/typeutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/diff"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/refactor/satisfy"
-)
-
-type renamer struct {
-	ctx                context.Context
-	refs               []*ReferenceInfo
-	objsToUpdate       map[types.Object]bool
-	hadConflicts       bool
-	errors             string
-	from, to           string
-	satisfyConstraints map[satisfy.Constraint]bool
-	packages           map[*types.Package]Package // may include additional packages that are a dep of pkg.
-	msets              typeutil.MethodSetCache
-	changeMethods      bool
-}
-
-type PrepareItem struct {
-	Range protocol.Range
-	Text  string
-}
-
-// PrepareRename searches for a valid renaming at position pp.
-//
-// The returned usererr is intended to be displayed to the user to explain why
-// the prepare fails. Probably we could eliminate the redundancy in returning
-// two errors, but for now this is done defensively.
-func PrepareRename(ctx context.Context, snapshot Snapshot, f FileHandle, pp protocol.Position) (_ *PrepareItem, usererr, err error) {
-	// Find position of the package name declaration.
-	ctx, done := event.Start(ctx, "source.PrepareRename")
-	defer done()
-
-	// Is the cursor within the package name declaration?
-	pgf, inPackageName, err := parsePackageNameDecl(ctx, snapshot, f, pp)
-	if err != nil {
-		return nil, err, err
-	}
-	if inPackageName {
-		fileRenameSupported := false
-		for _, op := range snapshot.View().Options().SupportedResourceOperations {
-			if op == protocol.Rename {
-				fileRenameSupported = true
-				break
-			}
-		}
-
-		if !fileRenameSupported {
-			err := errors.New("can't rename package: LSP client does not support file renaming")
-			return nil, err, err
-		}
-		fileMeta, err := snapshot.MetadataForFile(ctx, f.URI())
-		if err != nil {
-			return nil, err, err
-		}
-
-		if len(fileMeta) == 0 {
-			err := fmt.Errorf("no packages found for file %q", f.URI())
-			return nil, err, err
-		}
-
-		meta := fileMeta[0]
-
-		if meta.Name == "main" {
-			err := errors.New("can't rename package \"main\"")
-			return nil, err, err
-		}
-
-		if strings.HasSuffix(string(meta.Name), "_test") {
-			err := errors.New("can't rename x_test packages")
-			return nil, err, err
-		}
-
-		if meta.Module == nil {
-			err := fmt.Errorf("can't rename package: missing module information for package %q", meta.PkgPath)
-			return nil, err, err
-		}
-
-		if meta.Module.Path == string(meta.PkgPath) {
-			err := fmt.Errorf("can't rename package: package path %q is the same as module path %q", meta.PkgPath, meta.Module.Path)
-			return nil, err, err
-		}
-
-		// Return the location of the package declaration.
-		rng, err := pgf.Mapper.PosRange(pgf.File.Name.Pos(), pgf.File.Name.End())
-		if err != nil {
-			return nil, err, err
-		}
-		return &PrepareItem{
-			Range: rng,
-			Text:  string(meta.Name),
-		}, nil, nil
-	}
-
-	qos, err := qualifiedObjsAtProtocolPos(ctx, snapshot, f.URI(), pp)
-	if err != nil {
-		return nil, nil, err
-	}
-	node, obj, pkg := qos[0].node, qos[0].obj, qos[0].sourcePkg
-	if err := checkRenamable(obj); err != nil {
-		return nil, nil, err
-	}
-	result, err := computePrepareRenameResp(snapshot, pkg, node, obj.Name())
-	if err != nil {
-		return nil, nil, err
-	}
-	return result, nil, nil
-}
-
-func computePrepareRenameResp(snapshot Snapshot, pkg Package, node ast.Node, text string) (*PrepareItem, error) {
-	mr, err := posToMappedRange(pkg, node.Pos(), node.End())
-	if err != nil {
-		return nil, err
-	}
-	rng, err := mr.Range()
-	if err != nil {
-		return nil, err
-	}
-	if _, isImport := node.(*ast.ImportSpec); isImport {
-		// We're not really renaming the import path.
-		rng.End = rng.Start
-	}
-	return &PrepareItem{
-		Range: rng,
-		Text:  text,
-	}, nil
-}
-
-// checkRenamable verifies if an obj may be renamed.
-func checkRenamable(obj types.Object) error {
-	if v, ok := obj.(*types.Var); ok && v.Embedded() {
-		return errors.New("can't rename embedded fields: rename the type directly or name the field")
-	}
-	if obj.Name() == "_" {
-		return errors.New("can't rename \"_\"")
-	}
-	return nil
-}
-
-// Rename returns a map of TextEdits for each file modified when renaming a
-// given identifier within a package and a boolean value of true for renaming
-// package and false otherwise.
-func Rename(ctx context.Context, s Snapshot, f FileHandle, pp protocol.Position, newName string) (map[span.URI][]protocol.TextEdit, bool, error) {
-	ctx, done := event.Start(ctx, "source.Rename")
-	defer done()
-
-	// Is the cursor within the package name declaration?
-	_, inPackageName, err := parsePackageNameDecl(ctx, s, f, pp)
-	if err != nil {
-		return nil, false, err
-	}
-	if inPackageName {
-		if !isValidIdentifier(newName) {
-			return nil, true, fmt.Errorf("%q is not a valid identifier", newName)
-		}
-
-		fileMeta, err := s.MetadataForFile(ctx, f.URI())
-		if err != nil {
-			return nil, true, err
-		}
-
-		if len(fileMeta) == 0 {
-			return nil, true, fmt.Errorf("no packages found for file %q", f.URI())
-		}
-
-		// We need metadata for the relevant package and module paths. These should
-		// be the same for all packages containing the file.
-		//
-		// TODO(rfindley): we mix package path and import path here haphazardly.
-		// Fix this.
-		meta := fileMeta[0]
-		oldPath := meta.PkgPath
-		var modulePath PackagePath
-		if mi := meta.Module; mi == nil {
-			return nil, true, fmt.Errorf("cannot rename package: missing module information for package %q", meta.PkgPath)
-		} else {
-			modulePath = PackagePath(mi.Path)
-		}
-
-		if strings.HasSuffix(newName, "_test") {
-			return nil, true, fmt.Errorf("cannot rename to _test package")
-		}
-
-		metadata, err := s.AllMetadata(ctx)
-		if err != nil {
-			return nil, true, err
-		}
-
-		renamingEdits, err := renamePackage(ctx, s, modulePath, oldPath, PackageName(newName), metadata)
-		if err != nil {
-			return nil, true, err
-		}
-
-		oldBase := filepath.Dir(span.URI.Filename(f.URI()))
-		newPkgDir := filepath.Join(filepath.Dir(oldBase), newName)
-
-		// TODO: should this operate on all go.mod files, irrespective of whether they are included in the workspace?
-		// Get all active mod files in the workspace
-		modFiles := s.ModFiles()
-		for _, m := range modFiles {
-			fh, err := s.GetFile(ctx, m)
-			if err != nil {
-				return nil, true, err
-			}
-			pm, err := s.ParseMod(ctx, fh)
-			if err != nil {
-				return nil, true, err
-			}
-
-			modFileDir := filepath.Dir(pm.URI.Filename())
-			affectedReplaces := []*modfile.Replace{}
-
-			// Check if any replace directives need to be fixed
-			for _, r := range pm.File.Replace {
-				if !strings.HasPrefix(r.New.Path, "/") && !strings.HasPrefix(r.New.Path, "./") && !strings.HasPrefix(r.New.Path, "../") {
-					continue
-				}
-
-				replacedPath := r.New.Path
-				if strings.HasPrefix(r.New.Path, "./") || strings.HasPrefix(r.New.Path, "../") {
-					replacedPath = filepath.Join(modFileDir, r.New.Path)
-				}
-
-				// TODO: Is there a risk of converting a '\' delimited replacement to a '/' delimited replacement?
-				if !strings.HasPrefix(filepath.ToSlash(replacedPath)+"/", filepath.ToSlash(oldBase)+"/") {
-					continue // not affected by the package renaming
-				}
-
-				affectedReplaces = append(affectedReplaces, r)
-			}
-
-			if len(affectedReplaces) == 0 {
-				continue
-			}
-			copied, err := modfile.Parse("", pm.Mapper.Content, nil)
-			if err != nil {
-				return nil, true, err
-			}
-
-			for _, r := range affectedReplaces {
-				replacedPath := r.New.Path
-				if strings.HasPrefix(r.New.Path, "./") || strings.HasPrefix(r.New.Path, "../") {
-					replacedPath = filepath.Join(modFileDir, r.New.Path)
-				}
-
-				suffix := strings.TrimPrefix(replacedPath, string(oldBase))
-
-				newReplacedPath, err := filepath.Rel(modFileDir, newPkgDir+suffix)
-				if err != nil {
-					return nil, true, err
-				}
-
-				newReplacedPath = filepath.ToSlash(newReplacedPath)
-
-				if !strings.HasPrefix(newReplacedPath, "/") && !strings.HasPrefix(newReplacedPath, "../") {
-					newReplacedPath = "./" + newReplacedPath
-				}
-
-				if err := copied.AddReplace(r.Old.Path, "", newReplacedPath, ""); err != nil {
-					return nil, true, err
-				}
-			}
-
-			copied.Cleanup()
-			newContent, err := copied.Format()
-			if err != nil {
-				return nil, true, err
-			}
-
-			// Calculate the edits to be made due to the change.
-			diff := s.View().Options().ComputeEdits(string(pm.Mapper.Content), string(newContent))
-			modFileEdits, err := ToProtocolEdits(pm.Mapper, diff)
-			if err != nil {
-				return nil, true, err
-			}
-
-			renamingEdits[pm.URI] = append(renamingEdits[pm.URI], modFileEdits...)
-		}
-
-		return renamingEdits, true, nil
-	}
-
-	qos, err := qualifiedObjsAtProtocolPos(ctx, s, f.URI(), pp)
-	if err != nil {
-		return nil, false, err
-	}
-	result, err := renameObj(ctx, s, newName, qos)
-	if err != nil {
-		return nil, false, err
-	}
-
-	return result, false, nil
-}
-
-// renamePackage computes all workspace edits required to rename the package
-// described by the given metadata, to newName, by renaming its package
-// directory.
-//
-// It updates package clauses and import paths for the renamed package as well
-// as any other packages affected by the directory renaming among packages
-// described by allMetadata.
-func renamePackage(ctx context.Context, s Snapshot, modulePath, oldPath PackagePath, newName PackageName, allMetadata []*Metadata) (map[span.URI][]protocol.TextEdit, error) {
-	if modulePath == oldPath {
-		return nil, fmt.Errorf("cannot rename package: module path %q is the same as the package path, so renaming the package directory would have no effect", modulePath)
-	}
-
-	newPathPrefix := path.Join(path.Dir(string(oldPath)), string(newName))
-
-	edits := make(map[span.URI][]protocol.TextEdit)
-	seen := make(seenPackageRename) // track per-file import renaming we've already processed
-
-	// Rename imports to the renamed package from other packages.
-	for _, m := range allMetadata {
-		// Special case: x_test packages for the renamed package will not have the
-		// package path as as a dir prefix, but still need their package clauses
-		// renamed.
-		if m.PkgPath == oldPath+"_test" {
-			newTestName := newName + "_test"
-
-			if err := renamePackageClause(ctx, m, s, newTestName, seen, edits); err != nil {
-				return nil, err
-			}
-			continue
-		}
-
-		// Subtle: check this condition before checking for valid module info
-		// below, because we should not fail this operation if unrelated packages
-		// lack module info.
-		if !strings.HasPrefix(string(m.PkgPath)+"/", string(oldPath)+"/") {
-			continue // not affected by the package renaming
-		}
-
-		if m.Module == nil {
-			// This check will always fail under Bazel.
-			return nil, fmt.Errorf("cannot rename package: missing module information for package %q", m.PkgPath)
-		}
-
-		if modulePath != PackagePath(m.Module.Path) {
-			continue // don't edit imports if nested package and renaming package have different module paths
-		}
-
-		// Renaming a package consists of changing its import path and package name.
-		suffix := strings.TrimPrefix(string(m.PkgPath), string(oldPath))
-		newPath := newPathPrefix + suffix
-
-		pkgName := m.Name
-		if m.PkgPath == PackagePath(oldPath) {
-			pkgName = newName
-
-			if err := renamePackageClause(ctx, m, s, newName, seen, edits); err != nil {
-				return nil, err
-			}
-		}
-
-		imp := ImportPath(newPath) // TODO(adonovan): what if newPath has vendor/ prefix?
-		if err := renameImports(ctx, s, m, imp, pkgName, seen, edits); err != nil {
-			return nil, err
-		}
-	}
-
-	return edits, nil
-}
-
-// seenPackageRename tracks import path renamings that have already been
-// processed.
-//
-// Due to test variants, files may appear multiple times in the reverse
-// transitive closure of a renamed package, or in the reverse transitive
-// closure of different variants of a renamed package (both are possible).
-// However, in all cases the resulting edits will be the same.
-type seenPackageRename map[seenPackageKey]bool
-type seenPackageKey struct {
-	uri  span.URI
-	path PackagePath
-}
-
-// add reports whether uri and importPath have been seen, and records them as
-// seen if not.
-func (s seenPackageRename) add(uri span.URI, path PackagePath) bool {
-	key := seenPackageKey{uri, path}
-	seen := s[key]
-	if !seen {
-		s[key] = true
-	}
-	return seen
-}
-
-// renamePackageClause computes edits renaming the package clause of files in
-// the package described by the given metadata, to newName.
-//
-// As files may belong to multiple packages, the seen map tracks files whose
-// package clause has already been updated, to prevent duplicate edits.
-//
-// Edits are written into the edits map.
-func renamePackageClause(ctx context.Context, m *Metadata, snapshot Snapshot, newName PackageName, seen seenPackageRename, edits map[span.URI][]protocol.TextEdit) error {
-	// Rename internal references to the package in the renaming package.
-	for _, uri := range m.CompiledGoFiles {
-		if seen.add(uri, m.PkgPath) {
-			continue
-		}
-		fh, err := snapshot.GetFile(ctx, uri)
-		if err != nil {
-			return err
-		}
-		f, err := snapshot.ParseGo(ctx, fh, ParseHeader)
-		if err != nil {
-			return err
-		}
-		if f.File.Name == nil {
-			continue // no package declaration
-		}
-		rng, err := f.Mapper.PosRange(f.File.Name.Pos(), f.File.Name.End())
-		if err != nil {
-			return err
-		}
-		edits[f.URI] = append(edits[f.URI], protocol.TextEdit{
-			Range:   rng,
-			NewText: string(newName),
-		})
-	}
-
-	return nil
-}
-
-// renameImports computes the set of edits to imports resulting from renaming
-// the package described by the given metadata, to a package with import path
-// newPath and name newName.
-//
-// Edits are written into the edits map.
-func renameImports(ctx context.Context, snapshot Snapshot, m *Metadata, newPath ImportPath, newName PackageName, seen seenPackageRename, edits map[span.URI][]protocol.TextEdit) error {
-	rdeps, err := snapshot.ReverseDependencies(ctx, m.ID, false) // find direct importers
-	if err != nil {
-		return err
-	}
-
-	// Pass 1: rename import paths in import declarations.
-	needsTypeCheck := make(map[PackageID][]span.URI)
-	for _, rdep := range rdeps {
-		if rdep.IsIntermediateTestVariant() {
-			continue // for renaming, these variants are redundant
-		}
-
-		for _, uri := range rdep.CompiledGoFiles {
-			if seen.add(uri, m.PkgPath) {
-				continue
-			}
-			fh, err := snapshot.GetFile(ctx, uri)
-			if err != nil {
-				return err
-			}
-			f, err := snapshot.ParseGo(ctx, fh, ParseHeader)
-			if err != nil {
-				return err
-			}
-			if f.File.Name == nil {
-				continue // no package declaration
-			}
-			for _, imp := range f.File.Imports {
-				if rdep.DepsByImpPath[UnquoteImportPath(imp)] != m.ID {
-					continue // not the import we're looking for
-				}
-
-				// If the import does not explicitly specify
-				// a local name, then we need to invoke the
-				// type checker to locate references to update.
-				if imp.Name == nil {
-					needsTypeCheck[rdep.ID] = append(needsTypeCheck[rdep.ID], uri)
-				}
-
-				// Create text edit for the import path (string literal).
-				impPathMappedRange := NewMappedRange(f.Mapper, imp.Path.Pos(), imp.Path.End())
-				rng, err := impPathMappedRange.Range()
-				if err != nil {
-					return err
-				}
-				edits[uri] = append(edits[uri], protocol.TextEdit{
-					Range:   rng,
-					NewText: strconv.Quote(string(newPath)),
-				})
-			}
-		}
-	}
-
-	// If the imported package's name hasn't changed,
-	// we don't need to rename references within each file.
-	if newName == m.Name {
-		return nil
-	}
-
-	// Pass 2: rename local name (types.PkgName) of imported
-	// package throughout one or more files of the package.
-	ids := make([]PackageID, 0, len(needsTypeCheck))
-	for id := range needsTypeCheck {
-		ids = append(ids, id)
-	}
-	pkgs, err := snapshot.TypeCheck(ctx, TypecheckFull, ids...)
-	if err != nil {
-		return err
-	}
-	for i, id := range ids {
-		pkg := pkgs[i]
-		for _, uri := range needsTypeCheck[id] {
-			f, err := pkg.File(uri)
-			if err != nil {
-				return err
-			}
-			for _, imp := range f.File.Imports {
-				if imp.Name != nil {
-					continue // has explicit local name
-				}
-				if rdeps[id].DepsByImpPath[UnquoteImportPath(imp)] != m.ID {
-					continue // not the import we're looking for
-				}
-
-				pkgname := pkg.GetTypesInfo().Implicits[imp].(*types.PkgName)
-				qos := []qualifiedObject{{obj: pkgname, pkg: pkg}}
-
-				pkgScope := pkg.GetTypes().Scope()
-				fileScope := pkg.GetTypesInfo().Scopes[f.File]
-
-				localName := string(newName)
-				try := 0
-
-				// Keep trying with fresh names until one succeeds.
-				for fileScope.Lookup(localName) != nil || pkgScope.Lookup(localName) != nil {
-					try++
-					localName = fmt.Sprintf("%s%d", newName, try)
-				}
-				changes, err := renameObj(ctx, snapshot, localName, qos)
-				if err != nil {
-					return err
-				}
-
-				// If the chosen local package name matches the package's
-				// new name, delete the change that would have inserted
-				// an explicit local name, which is always the lexically
-				// first change.
-				if localName == string(newName) {
-					v := changes[uri]
-					sort.Slice(v, func(i, j int) bool {
-						return protocol.CompareRange(v[i].Range, v[j].Range) < 0
-					})
-					changes[uri] = v[1:]
-				}
-				for uri, changeEdits := range changes {
-					edits[uri] = append(edits[uri], changeEdits...)
-				}
-			}
-		}
-	}
-	return nil
-}
-
-// renameObj returns a map of TextEdits for renaming an identifier within a file
-// and boolean value of true if there is no renaming conflicts and false otherwise.
-func renameObj(ctx context.Context, s Snapshot, newName string, qos []qualifiedObject) (map[span.URI][]protocol.TextEdit, error) {
-	obj := qos[0].obj
-
-	if err := checkRenamable(obj); err != nil {
-		return nil, err
-	}
-	if obj.Name() == newName {
-		return nil, fmt.Errorf("old and new names are the same: %s", newName)
-	}
-	if !isValidIdentifier(newName) {
-		return nil, fmt.Errorf("invalid identifier to rename: %q", newName)
-	}
-	refs, err := references(ctx, s, qos, true, false, true)
-	if err != nil {
-		return nil, err
-	}
-	r := renamer{
-		ctx:          ctx,
-		refs:         refs,
-		objsToUpdate: make(map[types.Object]bool),
-		from:         obj.Name(),
-		to:           newName,
-		packages:     make(map[*types.Package]Package),
-	}
-
-	// A renaming initiated at an interface method indicates the
-	// intention to rename abstract and concrete methods as needed
-	// to preserve assignability.
-	for _, ref := range refs {
-		if obj, ok := ref.obj.(*types.Func); ok {
-			recv := obj.Type().(*types.Signature).Recv()
-			if recv != nil && IsInterface(recv.Type().Underlying()) {
-				r.changeMethods = true
-				break
-			}
-		}
-	}
-	for _, from := range refs {
-		r.packages[from.pkg.GetTypes()] = from.pkg
-	}
-
-	// Check that the renaming of the identifier is ok.
-	for _, ref := range refs {
-		r.check(ref.obj)
-		if r.hadConflicts { // one error is enough.
-			break
-		}
-	}
-	if r.hadConflicts {
-		return nil, fmt.Errorf(r.errors)
-	}
-
-	changes, err := r.update()
-	if err != nil {
-		return nil, err
-	}
-
-	result := make(map[span.URI][]protocol.TextEdit)
-	for uri, edits := range changes {
-		// These edits should really be associated with FileHandles for maximal correctness.
-		// For now, this is good enough.
-		fh, err := s.GetFile(ctx, uri)
-		if err != nil {
-			return nil, err
-		}
-		data, err := fh.Read()
-		if err != nil {
-			return nil, err
-		}
-		m := protocol.NewColumnMapper(uri, data)
-		protocolEdits, err := ToProtocolEdits(m, edits)
-		if err != nil {
-			return nil, err
-		}
-		result[uri] = protocolEdits
-	}
-	return result, nil
-}
-
-// Rename all references to the identifier.
-func (r *renamer) update() (map[span.URI][]diff.Edit, error) {
-	result := make(map[span.URI][]diff.Edit)
-	seen := make(map[span.Span]bool)
-
-	docRegexp, err := regexp.Compile(`\b` + r.from + `\b`)
-	if err != nil {
-		return nil, err
-	}
-	for _, ref := range r.refs {
-		refSpan, err := ref.Span()
-		if err != nil {
-			return nil, err
-		}
-		if seen[refSpan] {
-			continue
-		}
-		seen[refSpan] = true
-
-		// Renaming a types.PkgName may result in the addition or removal of an identifier,
-		// so we deal with this separately.
-		if pkgName, ok := ref.obj.(*types.PkgName); ok && ref.isDeclaration {
-			edit, err := r.updatePkgName(pkgName)
-			if err != nil {
-				return nil, err
-			}
-			result[refSpan.URI()] = append(result[refSpan.URI()], *edit)
-			continue
-		}
-
-		// Replace the identifier with r.to.
-		edit := diff.Edit{
-			Start: refSpan.Start().Offset(),
-			End:   refSpan.End().Offset(),
-			New:   r.to,
-		}
-
-		result[refSpan.URI()] = append(result[refSpan.URI()], edit)
-
-		if !ref.isDeclaration || ref.ident == nil { // uses do not have doc comments to update.
-			continue
-		}
-
-		doc := r.docComment(ref.pkg, ref.ident)
-		if doc == nil {
-			continue
-		}
-
-		// Perform the rename in doc comments declared in the original package.
-		// go/parser strips out \r\n returns from the comment text, so go
-		// line-by-line through the comment text to get the correct positions.
-		for _, comment := range doc.List {
-			if isDirective(comment.Text) {
-				continue
-			}
-			// TODO(adonovan): why are we looping over lines?
-			// Just run the loop body once over the entire multiline comment.
-			lines := strings.Split(comment.Text, "\n")
-			tokFile := ref.pkg.FileSet().File(comment.Pos())
-			commentLine := tokFile.Line(comment.Pos())
-			uri := span.URIFromPath(tokFile.Name())
-			for i, line := range lines {
-				lineStart := comment.Pos()
-				if i > 0 {
-					lineStart = tokFile.LineStart(commentLine + i)
-				}
-				for _, locs := range docRegexp.FindAllIndex([]byte(line), -1) {
-					// The File.Offset static check complains
-					// even though these uses are manifestly safe.
-					start, _ := safetoken.Offset(tokFile, lineStart+token.Pos(locs[0]))
-					end, _ := safetoken.Offset(tokFile, lineStart+token.Pos(locs[1]))
-					result[uri] = append(result[uri], diff.Edit{
-						Start: start,
-						End:   end,
-						New:   r.to,
-					})
-				}
-			}
-		}
-	}
-
-	return result, nil
-}
-
-// docComment returns the doc for an identifier.
-func (r *renamer) docComment(pkg Package, id *ast.Ident) *ast.CommentGroup {
-	_, tokFile, nodes, _ := pathEnclosingInterval(pkg, id.Pos(), id.End())
-	for _, node := range nodes {
-		switch decl := node.(type) {
-		case *ast.FuncDecl:
-			return decl.Doc
-		case *ast.Field:
-			return decl.Doc
-		case *ast.GenDecl:
-			return decl.Doc
-		// For {Type,Value}Spec, if the doc on the spec is absent,
-		// search for the enclosing GenDecl
-		case *ast.TypeSpec:
-			if decl.Doc != nil {
-				return decl.Doc
-			}
-		case *ast.ValueSpec:
-			if decl.Doc != nil {
-				return decl.Doc
-			}
-		case *ast.Ident:
-		case *ast.AssignStmt:
-			// *ast.AssignStmt doesn't have an associated comment group.
-			// So, we try to find a comment just before the identifier.
-
-			// Try to find a comment group only for short variable declarations (:=).
-			if decl.Tok != token.DEFINE {
-				return nil
-			}
-
-			identLine := tokFile.Line(id.Pos())
-			for _, comment := range nodes[len(nodes)-1].(*ast.File).Comments {
-				if comment.Pos() > id.Pos() {
-					// Comment is after the identifier.
-					continue
-				}
-
-				lastCommentLine := tokFile.Line(comment.End())
-				if lastCommentLine+1 == identLine {
-					return comment
-				}
-			}
-		default:
-			return nil
-		}
-	}
-	return nil
-}
-
-// updatePkgName returns the updates to rename a pkgName in the import spec by
-// only modifying the package name portion of the import declaration.
-func (r *renamer) updatePkgName(pkgName *types.PkgName) (*diff.Edit, error) {
-	// Modify ImportSpec syntax to add or remove the Name as needed.
-	pkg := r.packages[pkgName.Pkg()]
-	_, tokFile, path, _ := pathEnclosingInterval(pkg, pkgName.Pos(), pkgName.Pos())
-	if len(path) < 2 {
-		return nil, fmt.Errorf("no path enclosing interval for %s", pkgName.Name())
-	}
-	spec, ok := path[1].(*ast.ImportSpec)
-	if !ok {
-		return nil, fmt.Errorf("failed to update PkgName for %s", pkgName.Name())
-	}
-
-	newText := ""
-	if pkgName.Imported().Name() != r.to {
-		newText = r.to + " "
-	}
-
-	// Replace the portion (possibly empty) of the spec before the path:
-	//     local "path"      or      "path"
-	//   ->      <-                -><-
-	rng := span.NewRange(tokFile, spec.Pos(), spec.Path.Pos())
-	spn, err := rng.Span()
-	if err != nil {
-		return nil, err
-	}
-
-	return &diff.Edit{
-		Start: spn.Start().Offset(),
-		End:   spn.End().Offset(),
-		New:   newText,
-	}, nil
-}
diff -urN a/gopls/internal/lsp/source/rename_check.go b/gopls/internal/lsp/source/rename_check.go
--- a/gopls/internal/lsp/source/rename_check.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/rename_check.go	1969-12-31 16:00:00
@@ -1,935 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-//
-// Taken from golang.org/x/tools/refactor/rename.
-
-package source
-
-import (
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-	"reflect"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/refactor/satisfy"
-)
-
-// errorf reports an error (e.g. conflict) and prevents file modification.
-func (r *renamer) errorf(pos token.Pos, format string, args ...interface{}) {
-	r.hadConflicts = true
-	r.errors += fmt.Sprintf(format, args...)
-}
-
-// check performs safety checks of the renaming of the 'from' object to r.to.
-func (r *renamer) check(from types.Object) {
-	if r.objsToUpdate[from] {
-		return
-	}
-	r.objsToUpdate[from] = true
-
-	// NB: order of conditions is important.
-	if from_, ok := from.(*types.PkgName); ok {
-		r.checkInFileBlock(from_)
-	} else if from_, ok := from.(*types.Label); ok {
-		r.checkLabel(from_)
-	} else if isPackageLevel(from) {
-		r.checkInPackageBlock(from)
-	} else if v, ok := from.(*types.Var); ok && v.IsField() {
-		r.checkStructField(v)
-	} else if f, ok := from.(*types.Func); ok && recv(f) != nil {
-		r.checkMethod(f)
-	} else if isLocal(from) {
-		r.checkInLocalScope(from)
-	} else {
-		r.errorf(from.Pos(), "unexpected %s object %q (please report a bug)\n",
-			objectKind(from), from)
-	}
-}
-
-// checkInFileBlock performs safety checks for renames of objects in the file block,
-// i.e. imported package names.
-func (r *renamer) checkInFileBlock(from *types.PkgName) {
-	// Check import name is not "init".
-	if r.to == "init" {
-		r.errorf(from.Pos(), "%q is not a valid imported package name", r.to)
-	}
-
-	// Check for conflicts between file and package block.
-	if prev := from.Pkg().Scope().Lookup(r.to); prev != nil {
-		r.errorf(from.Pos(), "renaming this %s %q to %q would conflict",
-			objectKind(from), from.Name(), r.to)
-		r.errorf(prev.Pos(), "\twith this package member %s",
-			objectKind(prev))
-		return // since checkInPackageBlock would report redundant errors
-	}
-
-	// Check for conflicts in lexical scope.
-	r.checkInLexicalScope(from, r.packages[from.Pkg()])
-}
-
-// checkInPackageBlock performs safety checks for renames of
-// func/var/const/type objects in the package block.
-func (r *renamer) checkInPackageBlock(from types.Object) {
-	// Check that there are no references to the name from another
-	// package if the renaming would make it unexported.
-	if ast.IsExported(from.Name()) && !ast.IsExported(r.to) {
-		for typ, pkg := range r.packages {
-			if typ == from.Pkg() {
-				continue
-			}
-			if id := someUse(pkg.GetTypesInfo(), from); id != nil &&
-				!r.checkExport(id, typ, from) {
-				break
-			}
-		}
-	}
-
-	pkg := r.packages[from.Pkg()]
-	if pkg == nil {
-		return
-	}
-
-	// Check that in the package block, "init" is a function, and never referenced.
-	if r.to == "init" {
-		kind := objectKind(from)
-		if kind == "func" {
-			// Reject if intra-package references to it exist.
-			for id, obj := range pkg.GetTypesInfo().Uses {
-				if obj == from {
-					r.errorf(from.Pos(),
-						"renaming this func %q to %q would make it a package initializer",
-						from.Name(), r.to)
-					r.errorf(id.Pos(), "\tbut references to it exist")
-					break
-				}
-			}
-		} else {
-			r.errorf(from.Pos(), "you cannot have a %s at package level named %q",
-				kind, r.to)
-		}
-	}
-
-	// Check for conflicts between package block and all file blocks.
-	for _, f := range pkg.GetSyntax() {
-		fileScope := pkg.GetTypesInfo().Scopes[f]
-		b, prev := fileScope.LookupParent(r.to, token.NoPos)
-		if b == fileScope {
-			r.errorf(from.Pos(), "renaming this %s %q to %q would conflict", objectKind(from), from.Name(), r.to)
-			var prevPos token.Pos
-			if prev != nil {
-				prevPos = prev.Pos()
-			}
-			r.errorf(prevPos, "\twith this %s", objectKind(prev))
-			return // since checkInPackageBlock would report redundant errors
-		}
-	}
-
-	// Check for conflicts in lexical scope.
-	if from.Exported() {
-		for _, pkg := range r.packages {
-			r.checkInLexicalScope(from, pkg)
-		}
-	} else {
-		r.checkInLexicalScope(from, pkg)
-	}
-}
-
-func (r *renamer) checkInLocalScope(from types.Object) {
-	pkg := r.packages[from.Pkg()]
-	r.checkInLexicalScope(from, pkg)
-}
-
-// checkInLexicalScope performs safety checks that a renaming does not
-// change the lexical reference structure of the specified package.
-//
-// For objects in lexical scope, there are three kinds of conflicts:
-// same-, sub-, and super-block conflicts.  We will illustrate all three
-// using this example:
-//
-//	var x int
-//	var z int
-//
-//	func f(y int) {
-//		print(x)
-//		print(y)
-//	}
-//
-// Renaming x to z encounters a SAME-BLOCK CONFLICT, because an object
-// with the new name already exists, defined in the same lexical block
-// as the old object.
-//
-// Renaming x to y encounters a SUB-BLOCK CONFLICT, because there exists
-// a reference to x from within (what would become) a hole in its scope.
-// The definition of y in an (inner) sub-block would cast a shadow in
-// the scope of the renamed variable.
-//
-// Renaming y to x encounters a SUPER-BLOCK CONFLICT.  This is the
-// converse situation: there is an existing definition of the new name
-// (x) in an (enclosing) super-block, and the renaming would create a
-// hole in its scope, within which there exist references to it.  The
-// new name casts a shadow in scope of the existing definition of x in
-// the super-block.
-//
-// Removing the old name (and all references to it) is always safe, and
-// requires no checks.
-func (r *renamer) checkInLexicalScope(from types.Object, pkg Package) {
-	b := from.Parent() // the block defining the 'from' object
-	if b != nil {
-		toBlock, to := b.LookupParent(r.to, from.Parent().End())
-		if toBlock == b {
-			// same-block conflict
-			r.errorf(from.Pos(), "renaming this %s %q to %q",
-				objectKind(from), from.Name(), r.to)
-			r.errorf(to.Pos(), "\tconflicts with %s in same block",
-				objectKind(to))
-			return
-		} else if toBlock != nil {
-			// Check for super-block conflict.
-			// The name r.to is defined in a superblock.
-			// Is that name referenced from within this block?
-			forEachLexicalRef(pkg, to, func(id *ast.Ident, block *types.Scope) bool {
-				_, obj := block.LookupParent(from.Name(), id.Pos())
-				if obj == from {
-					// super-block conflict
-					r.errorf(from.Pos(), "renaming this %s %q to %q",
-						objectKind(from), from.Name(), r.to)
-					r.errorf(id.Pos(), "\twould shadow this reference")
-					r.errorf(to.Pos(), "\tto the %s declared here",
-						objectKind(to))
-					return false // stop
-				}
-				return true
-			})
-		}
-	}
-	// Check for sub-block conflict.
-	// Is there an intervening definition of r.to between
-	// the block defining 'from' and some reference to it?
-	forEachLexicalRef(pkg, from, func(id *ast.Ident, block *types.Scope) bool {
-		// Find the block that defines the found reference.
-		// It may be an ancestor.
-		fromBlock, _ := block.LookupParent(from.Name(), id.Pos())
-		// See what r.to would resolve to in the same scope.
-		toBlock, to := block.LookupParent(r.to, id.Pos())
-		if to != nil {
-			// sub-block conflict
-			if deeper(toBlock, fromBlock) {
-				r.errorf(from.Pos(), "renaming this %s %q to %q",
-					objectKind(from), from.Name(), r.to)
-				r.errorf(id.Pos(), "\twould cause this reference to become shadowed")
-				r.errorf(to.Pos(), "\tby this intervening %s definition",
-					objectKind(to))
-				return false // stop
-			}
-		}
-		return true
-	})
-
-	// Renaming a type that is used as an embedded field
-	// requires renaming the field too. e.g.
-	// 	type T int // if we rename this to U..
-	// 	var s struct {T}
-	// 	print(s.T) // ...this must change too
-	if _, ok := from.(*types.TypeName); ok {
-		for id, obj := range pkg.GetTypesInfo().Uses {
-			if obj == from {
-				if field := pkg.GetTypesInfo().Defs[id]; field != nil {
-					r.check(field)
-				}
-			}
-		}
-	}
-}
-
-// deeper reports whether block x is lexically deeper than y.
-func deeper(x, y *types.Scope) bool {
-	if x == y || x == nil {
-		return false
-	} else if y == nil {
-		return true
-	} else {
-		return deeper(x.Parent(), y.Parent())
-	}
-}
-
-// forEachLexicalRef calls fn(id, block) for each identifier id in package
-// pkg that is a reference to obj in lexical scope.  block is the
-// lexical block enclosing the reference.  If fn returns false the
-// iteration is terminated and findLexicalRefs returns false.
-func forEachLexicalRef(pkg Package, obj types.Object, fn func(id *ast.Ident, block *types.Scope) bool) bool {
-	ok := true
-	var stack []ast.Node
-
-	var visit func(n ast.Node) bool
-	visit = func(n ast.Node) bool {
-		if n == nil {
-			stack = stack[:len(stack)-1] // pop
-			return false
-		}
-		if !ok {
-			return false // bail out
-		}
-
-		stack = append(stack, n) // push
-		switch n := n.(type) {
-		case *ast.Ident:
-			if pkg.GetTypesInfo().Uses[n] == obj {
-				block := enclosingBlock(pkg.GetTypesInfo(), stack)
-				if !fn(n, block) {
-					ok = false
-				}
-			}
-			return visit(nil) // pop stack
-
-		case *ast.SelectorExpr:
-			// don't visit n.Sel
-			ast.Inspect(n.X, visit)
-			return visit(nil) // pop stack, don't descend
-
-		case *ast.CompositeLit:
-			// Handle recursion ourselves for struct literals
-			// so we don't visit field identifiers.
-			tv, ok := pkg.GetTypesInfo().Types[n]
-			if !ok {
-				return visit(nil) // pop stack, don't descend
-			}
-			if _, ok := Deref(tv.Type).Underlying().(*types.Struct); ok {
-				if n.Type != nil {
-					ast.Inspect(n.Type, visit)
-				}
-				for _, elt := range n.Elts {
-					if kv, ok := elt.(*ast.KeyValueExpr); ok {
-						ast.Inspect(kv.Value, visit)
-					} else {
-						ast.Inspect(elt, visit)
-					}
-				}
-				return visit(nil) // pop stack, don't descend
-			}
-		}
-		return true
-	}
-
-	for _, f := range pkg.GetSyntax() {
-		ast.Inspect(f, visit)
-		if len(stack) != 0 {
-			panic(stack)
-		}
-		if !ok {
-			break
-		}
-	}
-	return ok
-}
-
-// enclosingBlock returns the innermost block enclosing the specified
-// AST node, specified in the form of a path from the root of the file,
-// [file...n].
-func enclosingBlock(info *types.Info, stack []ast.Node) *types.Scope {
-	for i := range stack {
-		n := stack[len(stack)-1-i]
-		// For some reason, go/types always associates a
-		// function's scope with its FuncType.
-		// TODO(adonovan): feature or a bug?
-		switch f := n.(type) {
-		case *ast.FuncDecl:
-			n = f.Type
-		case *ast.FuncLit:
-			n = f.Type
-		}
-		if b := info.Scopes[n]; b != nil {
-			return b
-		}
-	}
-	panic("no Scope for *ast.File")
-}
-
-func (r *renamer) checkLabel(label *types.Label) {
-	// Check there are no identical labels in the function's label block.
-	// (Label blocks don't nest, so this is easy.)
-	if prev := label.Parent().Lookup(r.to); prev != nil {
-		r.errorf(label.Pos(), "renaming this label %q to %q", label.Name(), prev.Name())
-		r.errorf(prev.Pos(), "\twould conflict with this one")
-	}
-}
-
-// checkStructField checks that the field renaming will not cause
-// conflicts at its declaration, or ambiguity or changes to any selection.
-func (r *renamer) checkStructField(from *types.Var) {
-	// Check that the struct declaration is free of field conflicts,
-	// and field/method conflicts.
-
-	// go/types offers no easy way to get from a field (or interface
-	// method) to its declaring struct (or interface), so we must
-	// ascend the AST.
-	fromPkg, ok := r.packages[from.Pkg()]
-	if !ok {
-		return
-	}
-	pkg, _, path, _ := pathEnclosingInterval(fromPkg, from.Pos(), from.Pos())
-	if pkg == nil || path == nil {
-		return
-	}
-	// path matches this pattern:
-	// [Ident SelectorExpr? StarExpr? Field FieldList StructType ParenExpr* ... File]
-
-	// Ascend to FieldList.
-	var i int
-	for {
-		if _, ok := path[i].(*ast.FieldList); ok {
-			break
-		}
-		i++
-	}
-	i++
-	tStruct := path[i].(*ast.StructType)
-	i++
-	// Ascend past parens (unlikely).
-	for {
-		_, ok := path[i].(*ast.ParenExpr)
-		if !ok {
-			break
-		}
-		i++
-	}
-	if spec, ok := path[i].(*ast.TypeSpec); ok {
-		// This struct is also a named type.
-		// We must check for direct (non-promoted) field/field
-		// and method/field conflicts.
-		named := pkg.GetTypesInfo().Defs[spec.Name].Type()
-		prev, indices, _ := types.LookupFieldOrMethod(named, true, pkg.GetTypes(), r.to)
-		if len(indices) == 1 {
-			r.errorf(from.Pos(), "renaming this field %q to %q",
-				from.Name(), r.to)
-			r.errorf(prev.Pos(), "\twould conflict with this %s",
-				objectKind(prev))
-			return // skip checkSelections to avoid redundant errors
-		}
-	} else {
-		// This struct is not a named type.
-		// We need only check for direct (non-promoted) field/field conflicts.
-		T := pkg.GetTypesInfo().Types[tStruct].Type.Underlying().(*types.Struct)
-		for i := 0; i < T.NumFields(); i++ {
-			if prev := T.Field(i); prev.Name() == r.to {
-				r.errorf(from.Pos(), "renaming this field %q to %q",
-					from.Name(), r.to)
-				r.errorf(prev.Pos(), "\twould conflict with this field")
-				return // skip checkSelections to avoid redundant errors
-			}
-		}
-	}
-
-	// Renaming an anonymous field requires renaming the type too. e.g.
-	// 	print(s.T)       // if we rename T to U,
-	// 	type T int       // this and
-	// 	var s struct {T} // this must change too.
-	if from.Anonymous() {
-		if named, ok := from.Type().(*types.Named); ok {
-			r.check(named.Obj())
-		} else if named, ok := Deref(from.Type()).(*types.Named); ok {
-			r.check(named.Obj())
-		}
-	}
-
-	// Check integrity of existing (field and method) selections.
-	r.checkSelections(from)
-}
-
-// checkSelection checks that all uses and selections that resolve to
-// the specified object would continue to do so after the renaming.
-func (r *renamer) checkSelections(from types.Object) {
-	for typ, pkg := range r.packages {
-		if id := someUse(pkg.GetTypesInfo(), from); id != nil {
-			if !r.checkExport(id, typ, from) {
-				return
-			}
-		}
-
-		for syntax, sel := range pkg.GetTypesInfo().Selections {
-			// There may be extant selections of only the old
-			// name or only the new name, so we must check both.
-			// (If neither, the renaming is sound.)
-			//
-			// In both cases, we wish to compare the lengths
-			// of the implicit field path (Selection.Index)
-			// to see if the renaming would change it.
-			//
-			// If a selection that resolves to 'from', when renamed,
-			// would yield a path of the same or shorter length,
-			// this indicates ambiguity or a changed referent,
-			// analogous to same- or sub-block lexical conflict.
-			//
-			// If a selection using the name 'to' would
-			// yield a path of the same or shorter length,
-			// this indicates ambiguity or shadowing,
-			// analogous to same- or super-block lexical conflict.
-
-			// TODO(adonovan): fix: derive from Types[syntax.X].Mode
-			// TODO(adonovan): test with pointer, value, addressable value.
-			isAddressable := true
-
-			if sel.Obj() == from {
-				if obj, indices, _ := types.LookupFieldOrMethod(sel.Recv(), isAddressable, from.Pkg(), r.to); obj != nil {
-					// Renaming this existing selection of
-					// 'from' may block access to an existing
-					// type member named 'to'.
-					delta := len(indices) - len(sel.Index())
-					if delta > 0 {
-						continue // no ambiguity
-					}
-					r.selectionConflict(from, delta, syntax, obj)
-					return
-				}
-			} else if sel.Obj().Name() == r.to {
-				if obj, indices, _ := types.LookupFieldOrMethod(sel.Recv(), isAddressable, from.Pkg(), from.Name()); obj == from {
-					// Renaming 'from' may cause this existing
-					// selection of the name 'to' to change
-					// its meaning.
-					delta := len(indices) - len(sel.Index())
-					if delta > 0 {
-						continue //  no ambiguity
-					}
-					r.selectionConflict(from, -delta, syntax, sel.Obj())
-					return
-				}
-			}
-		}
-	}
-}
-
-func (r *renamer) selectionConflict(from types.Object, delta int, syntax *ast.SelectorExpr, obj types.Object) {
-	r.errorf(from.Pos(), "renaming this %s %q to %q",
-		objectKind(from), from.Name(), r.to)
-
-	switch {
-	case delta < 0:
-		// analogous to sub-block conflict
-		r.errorf(syntax.Sel.Pos(),
-			"\twould change the referent of this selection")
-		r.errorf(obj.Pos(), "\tof this %s", objectKind(obj))
-	case delta == 0:
-		// analogous to same-block conflict
-		r.errorf(syntax.Sel.Pos(),
-			"\twould make this reference ambiguous")
-		r.errorf(obj.Pos(), "\twith this %s", objectKind(obj))
-	case delta > 0:
-		// analogous to super-block conflict
-		r.errorf(syntax.Sel.Pos(),
-			"\twould shadow this selection")
-		r.errorf(obj.Pos(), "\tof the %s declared here",
-			objectKind(obj))
-	}
-}
-
-// checkMethod performs safety checks for renaming a method.
-// There are three hazards:
-// - declaration conflicts
-// - selection ambiguity/changes
-// - entailed renamings of assignable concrete/interface types.
-//
-// We reject renamings initiated at concrete methods if it would
-// change the assignability relation.  For renamings of abstract
-// methods, we rename all methods transitively coupled to it via
-// assignability.
-func (r *renamer) checkMethod(from *types.Func) {
-	// e.g. error.Error
-	if from.Pkg() == nil {
-		r.errorf(from.Pos(), "you cannot rename built-in method %s", from)
-		return
-	}
-
-	// ASSIGNABILITY: We reject renamings of concrete methods that
-	// would break a 'satisfy' constraint; but renamings of abstract
-	// methods are allowed to proceed, and we rename affected
-	// concrete and abstract methods as necessary.  It is the
-	// initial method that determines the policy.
-
-	// Check for conflict at point of declaration.
-	// Check to ensure preservation of assignability requirements.
-	R := recv(from).Type()
-	if IsInterface(R) {
-		// Abstract method
-
-		// declaration
-		prev, _, _ := types.LookupFieldOrMethod(R, false, from.Pkg(), r.to)
-		if prev != nil {
-			r.errorf(from.Pos(), "renaming this interface method %q to %q",
-				from.Name(), r.to)
-			r.errorf(prev.Pos(), "\twould conflict with this method")
-			return
-		}
-
-		// Check all interfaces that embed this one for
-		// declaration conflicts too.
-		for _, pkg := range r.packages {
-			// Start with named interface types (better errors)
-			for _, obj := range pkg.GetTypesInfo().Defs {
-				if obj, ok := obj.(*types.TypeName); ok && IsInterface(obj.Type()) {
-					f, _, _ := types.LookupFieldOrMethod(
-						obj.Type(), false, from.Pkg(), from.Name())
-					if f == nil {
-						continue
-					}
-					t, _, _ := types.LookupFieldOrMethod(
-						obj.Type(), false, from.Pkg(), r.to)
-					if t == nil {
-						continue
-					}
-					r.errorf(from.Pos(), "renaming this interface method %q to %q",
-						from.Name(), r.to)
-					r.errorf(t.Pos(), "\twould conflict with this method")
-					r.errorf(obj.Pos(), "\tin named interface type %q", obj.Name())
-				}
-			}
-
-			// Now look at all literal interface types (includes named ones again).
-			for e, tv := range pkg.GetTypesInfo().Types {
-				if e, ok := e.(*ast.InterfaceType); ok {
-					_ = e
-					_ = tv.Type.(*types.Interface)
-					// TODO(adonovan): implement same check as above.
-				}
-			}
-		}
-
-		// assignability
-		//
-		// Find the set of concrete or abstract methods directly
-		// coupled to abstract method 'from' by some
-		// satisfy.Constraint, and rename them too.
-		for key := range r.satisfy() {
-			// key = (lhs, rhs) where lhs is always an interface.
-
-			lsel := r.msets.MethodSet(key.LHS).Lookup(from.Pkg(), from.Name())
-			if lsel == nil {
-				continue
-			}
-			rmethods := r.msets.MethodSet(key.RHS)
-			rsel := rmethods.Lookup(from.Pkg(), from.Name())
-			if rsel == nil {
-				continue
-			}
-
-			// If both sides have a method of this name,
-			// and one of them is m, the other must be coupled.
-			var coupled *types.Func
-			switch from {
-			case lsel.Obj():
-				coupled = rsel.Obj().(*types.Func)
-			case rsel.Obj():
-				coupled = lsel.Obj().(*types.Func)
-			default:
-				continue
-			}
-
-			// We must treat concrete-to-interface
-			// constraints like an implicit selection C.f of
-			// each interface method I.f, and check that the
-			// renaming leaves the selection unchanged and
-			// unambiguous.
-			//
-			// Fun fact: the implicit selection of C.f
-			// 	type I interface{f()}
-			// 	type C struct{I}
-			// 	func (C) g()
-			//      var _ I = C{} // here
-			// yields abstract method I.f.  This can make error
-			// messages less than obvious.
-			//
-			if !IsInterface(key.RHS) {
-				// The logic below was derived from checkSelections.
-
-				rtosel := rmethods.Lookup(from.Pkg(), r.to)
-				if rtosel != nil {
-					rto := rtosel.Obj().(*types.Func)
-					delta := len(rsel.Index()) - len(rtosel.Index())
-					if delta < 0 {
-						continue // no ambiguity
-					}
-
-					// TODO(adonovan): record the constraint's position.
-					keyPos := token.NoPos
-
-					r.errorf(from.Pos(), "renaming this method %q to %q",
-						from.Name(), r.to)
-					if delta == 0 {
-						// analogous to same-block conflict
-						r.errorf(keyPos, "\twould make the %s method of %s invoked via interface %s ambiguous",
-							r.to, key.RHS, key.LHS)
-						r.errorf(rto.Pos(), "\twith (%s).%s",
-							recv(rto).Type(), r.to)
-					} else {
-						// analogous to super-block conflict
-						r.errorf(keyPos, "\twould change the %s method of %s invoked via interface %s",
-							r.to, key.RHS, key.LHS)
-						r.errorf(coupled.Pos(), "\tfrom (%s).%s",
-							recv(coupled).Type(), r.to)
-						r.errorf(rto.Pos(), "\tto (%s).%s",
-							recv(rto).Type(), r.to)
-					}
-					return // one error is enough
-				}
-			}
-
-			if !r.changeMethods {
-				// This should be unreachable.
-				r.errorf(from.Pos(), "internal error: during renaming of abstract method %s", from)
-				r.errorf(coupled.Pos(), "\tchangedMethods=false, coupled method=%s", coupled)
-				r.errorf(from.Pos(), "\tPlease file a bug report")
-				return
-			}
-
-			// Rename the coupled method to preserve assignability.
-			r.check(coupled)
-		}
-	} else {
-		// Concrete method
-
-		// declaration
-		prev, indices, _ := types.LookupFieldOrMethod(R, true, from.Pkg(), r.to)
-		if prev != nil && len(indices) == 1 {
-			r.errorf(from.Pos(), "renaming this method %q to %q",
-				from.Name(), r.to)
-			r.errorf(prev.Pos(), "\twould conflict with this %s",
-				objectKind(prev))
-			return
-		}
-
-		// assignability
-		//
-		// Find the set of abstract methods coupled to concrete
-		// method 'from' by some satisfy.Constraint, and rename
-		// them too.
-		//
-		// Coupling may be indirect, e.g. I.f <-> C.f via type D.
-		//
-		// 	type I interface {f()}
-		//	type C int
-		//	type (C) f()
-		//	type D struct{C}
-		//	var _ I = D{}
-		//
-		for key := range r.satisfy() {
-			// key = (lhs, rhs) where lhs is always an interface.
-			if IsInterface(key.RHS) {
-				continue
-			}
-			rsel := r.msets.MethodSet(key.RHS).Lookup(from.Pkg(), from.Name())
-			if rsel == nil || rsel.Obj() != from {
-				continue // rhs does not have the method
-			}
-			lsel := r.msets.MethodSet(key.LHS).Lookup(from.Pkg(), from.Name())
-			if lsel == nil {
-				continue
-			}
-			imeth := lsel.Obj().(*types.Func)
-
-			// imeth is the abstract method (e.g. I.f)
-			// and key.RHS is the concrete coupling type (e.g. D).
-			if !r.changeMethods {
-				r.errorf(from.Pos(), "renaming this method %q to %q",
-					from.Name(), r.to)
-				var pos token.Pos
-				var iface string
-
-				I := recv(imeth).Type()
-				if named, ok := I.(*types.Named); ok {
-					pos = named.Obj().Pos()
-					iface = "interface " + named.Obj().Name()
-				} else {
-					pos = from.Pos()
-					iface = I.String()
-				}
-				r.errorf(pos, "\twould make %s no longer assignable to %s",
-					key.RHS, iface)
-				r.errorf(imeth.Pos(), "\t(rename %s.%s if you intend to change both types)",
-					I, from.Name())
-				return // one error is enough
-			}
-
-			// Rename the coupled interface method to preserve assignability.
-			r.check(imeth)
-		}
-	}
-
-	// Check integrity of existing (field and method) selections.
-	// We skip this if there were errors above, to avoid redundant errors.
-	r.checkSelections(from)
-}
-
-func (r *renamer) checkExport(id *ast.Ident, pkg *types.Package, from types.Object) bool {
-	// Reject cross-package references if r.to is unexported.
-	// (Such references may be qualified identifiers or field/method
-	// selections.)
-	if !ast.IsExported(r.to) && pkg != from.Pkg() {
-		r.errorf(from.Pos(),
-			"renaming %q to %q would make it unexported",
-			from.Name(), r.to)
-		r.errorf(id.Pos(), "\tbreaking references from packages such as %q",
-			pkg.Path())
-		return false
-	}
-	return true
-}
-
-// satisfy returns the set of interface satisfaction constraints.
-func (r *renamer) satisfy() map[satisfy.Constraint]bool {
-	if r.satisfyConstraints == nil {
-		// Compute on demand: it's expensive.
-		var f satisfy.Finder
-		for _, pkg := range r.packages {
-			// From satisfy.Finder documentation:
-			//
-			// The package must be free of type errors, and
-			// info.{Defs,Uses,Selections,Types} must have been populated by the
-			// type-checker.
-			//
-			// Only proceed if all packages have no errors.
-			if pkg.HasListOrParseErrors() || pkg.HasTypeErrors() {
-				r.errorf(token.NoPos, // we don't have a position for this error.
-					"renaming %q to %q not possible because %q has errors",
-					r.from, r.to, pkg.PkgPath())
-				return nil
-			}
-			f.Find(pkg.GetTypesInfo(), pkg.GetSyntax())
-		}
-		r.satisfyConstraints = f.Result
-	}
-	return r.satisfyConstraints
-}
-
-// -- helpers ----------------------------------------------------------
-
-// recv returns the method's receiver.
-func recv(meth *types.Func) *types.Var {
-	return meth.Type().(*types.Signature).Recv()
-}
-
-// someUse returns an arbitrary use of obj within info.
-func someUse(info *types.Info, obj types.Object) *ast.Ident {
-	for id, o := range info.Uses {
-		if o == obj {
-			return id
-		}
-	}
-	return nil
-}
-
-// pathEnclosingInterval returns the Package, token.File, and ast.Node that
-// contain source interval [start, end), and all the node's ancestors
-// up to the AST root.  It searches all ast.Files of all packages.
-// exact is defined as for astutil.PathEnclosingInterval.
-//
-// The zero value is returned if not found.
-func pathEnclosingInterval(pkg Package, start, end token.Pos) (resPkg Package, tokFile *token.File, path []ast.Node, exact bool) {
-	pkgs := []Package{pkg}
-	for _, f := range pkg.GetSyntax() {
-		for _, imp := range f.Imports {
-			if imp == nil {
-				continue
-			}
-			importPath := UnquoteImportPath(imp)
-			if importPath == "" {
-				continue
-			}
-			imported, err := pkg.ResolveImportPath(importPath)
-			if err != nil {
-				return nil, nil, nil, false
-			}
-			pkgs = append(pkgs, imported)
-		}
-	}
-	for _, p := range pkgs {
-		for _, f := range p.GetSyntax() {
-			if !f.Pos().IsValid() {
-				// This can happen if the parser saw
-				// too many errors and bailed out.
-				// (Use parser.AllErrors to prevent that.)
-				continue
-			}
-			tokFile := p.FileSet().File(f.Pos())
-			if !tokenFileContainsPos(tokFile, start) {
-				continue
-			}
-			if path, exact := astutil.PathEnclosingInterval(f, start, end); path != nil {
-				return pkg, tokFile, path, exact
-			}
-		}
-	}
-	return nil, nil, nil, false
-}
-
-// TODO(adonovan): make this a method: func (*token.File) Contains(token.Pos)
-func tokenFileContainsPos(tf *token.File, pos token.Pos) bool {
-	p := int(pos)
-	base := tf.Base()
-	return base <= p && p <= base+tf.Size()
-}
-
-func objectKind(obj types.Object) string {
-	if obj == nil {
-		return "nil object"
-	}
-	switch obj := obj.(type) {
-	case *types.PkgName:
-		return "imported package name"
-	case *types.TypeName:
-		return "type"
-	case *types.Var:
-		if obj.IsField() {
-			return "field"
-		}
-	case *types.Func:
-		if obj.Type().(*types.Signature).Recv() != nil {
-			return "method"
-		}
-	}
-	// label, func, var, const
-	return strings.ToLower(strings.TrimPrefix(reflect.TypeOf(obj).String(), "*types."))
-}
-
-// NB: for renamings, blank is not considered valid.
-func isValidIdentifier(id string) bool {
-	if id == "" || id == "_" {
-		return false
-	}
-	for i, r := range id {
-		if !isLetter(r) && (i == 0 || !isDigit(r)) {
-			return false
-		}
-	}
-	return token.Lookup(id) == token.IDENT
-}
-
-// isLocal reports whether obj is local to some function.
-// Precondition: not a struct field or interface method.
-func isLocal(obj types.Object) bool {
-	// [... 5=stmt 4=func 3=file 2=pkg 1=universe]
-	var depth int
-	for scope := obj.Parent(); scope != nil; scope = scope.Parent() {
-		depth++
-	}
-	return depth >= 4
-}
-
-func isPackageLevel(obj types.Object) bool {
-	if obj == nil {
-		return false
-	}
-	return obj.Pkg().Scope().Lookup(obj.Name()) == obj
-}
-
-// -- Plundered from go/scanner: ---------------------------------------
-
-func isLetter(ch rune) bool {
-	return 'a' <= ch && ch <= 'z' || 'A' <= ch && ch <= 'Z' || ch == '_' || ch >= 0x80 && unicode.IsLetter(ch)
-}
-
-func isDigit(ch rune) bool {
-	return '0' <= ch && ch <= '9' || ch >= 0x80 && unicode.IsDigit(ch)
-}
diff -urN a/gopls/internal/lsp/source/signature_help.go b/gopls/internal/lsp/source/signature_help.go
--- a/gopls/internal/lsp/source/signature_help.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/signature_help.go	1969-12-31 16:00:00
@@ -1,165 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-)
-
-func SignatureHelp(ctx context.Context, snapshot Snapshot, fh FileHandle, position protocol.Position) (*protocol.SignatureInformation, int, error) {
-	ctx, done := event.Start(ctx, "source.SignatureHelp")
-	defer done()
-
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckWorkspace, NarrowestPackage)
-	if err != nil {
-		return nil, 0, fmt.Errorf("getting file for SignatureHelp: %w", err)
-	}
-	pos, err := pgf.Mapper.Pos(position)
-	if err != nil {
-		return nil, 0, err
-	}
-	// Find a call expression surrounding the query position.
-	var callExpr *ast.CallExpr
-	path, _ := astutil.PathEnclosingInterval(pgf.File, pos, pos)
-	if path == nil {
-		return nil, 0, fmt.Errorf("cannot find node enclosing position")
-	}
-FindCall:
-	for _, node := range path {
-		switch node := node.(type) {
-		case *ast.CallExpr:
-			if pos >= node.Lparen && pos <= node.Rparen {
-				callExpr = node
-				break FindCall
-			}
-		case *ast.FuncLit, *ast.FuncType:
-			// The user is within an anonymous function,
-			// which may be the parameter to the *ast.CallExpr.
-			// Don't show signature help in this case.
-			return nil, 0, fmt.Errorf("no signature help within a function declaration")
-		case *ast.BasicLit:
-			if node.Kind == token.STRING {
-				return nil, 0, fmt.Errorf("no signature help within a string literal")
-			}
-		}
-
-	}
-	if callExpr == nil || callExpr.Fun == nil {
-		return nil, 0, fmt.Errorf("cannot find an enclosing function")
-	}
-
-	qf := Qualifier(pgf.File, pkg.GetTypes(), pkg.GetTypesInfo())
-
-	// Get the object representing the function, if available.
-	// There is no object in certain cases such as calling a function returned by
-	// a function (e.g. "foo()()").
-	var obj types.Object
-	switch t := callExpr.Fun.(type) {
-	case *ast.Ident:
-		obj = pkg.GetTypesInfo().ObjectOf(t)
-	case *ast.SelectorExpr:
-		obj = pkg.GetTypesInfo().ObjectOf(t.Sel)
-	}
-
-	// Handle builtin functions separately.
-	if obj, ok := obj.(*types.Builtin); ok {
-		return builtinSignature(ctx, snapshot, callExpr, obj.Name(), pos)
-	}
-
-	// Get the type information for the function being called.
-	sigType := pkg.GetTypesInfo().TypeOf(callExpr.Fun)
-	if sigType == nil {
-		return nil, 0, fmt.Errorf("cannot get type for Fun %[1]T (%[1]v)", callExpr.Fun)
-	}
-
-	sig, _ := sigType.Underlying().(*types.Signature)
-	if sig == nil {
-		return nil, 0, fmt.Errorf("cannot find signature for Fun %[1]T (%[1]v)", callExpr.Fun)
-	}
-
-	activeParam := activeParameter(callExpr, sig.Params().Len(), sig.Variadic(), pos)
-
-	var (
-		name    string
-		comment *ast.CommentGroup
-	)
-	if obj != nil {
-		declPkg, err := FindPackageFromPos(pkg, obj.Pos())
-		if err != nil {
-			return nil, 0, err
-		}
-		node, _ := FindDeclAndField(declPkg.GetSyntax(), obj.Pos()) // may be nil
-		d, err := FindHoverContext(ctx, snapshot, pkg, obj, node, nil)
-		if err != nil {
-			return nil, 0, err
-		}
-		name = obj.Name()
-		comment = d.Comment
-	} else {
-		name = "func"
-	}
-	s := NewSignature(ctx, snapshot, pkg, sig, comment, qf)
-	paramInfo := make([]protocol.ParameterInformation, 0, len(s.params))
-	for _, p := range s.params {
-		paramInfo = append(paramInfo, protocol.ParameterInformation{Label: p})
-	}
-	return &protocol.SignatureInformation{
-		Label:         name + s.Format(),
-		Documentation: s.doc,
-		Parameters:    paramInfo,
-	}, activeParam, nil
-}
-
-func builtinSignature(ctx context.Context, snapshot Snapshot, callExpr *ast.CallExpr, name string, pos token.Pos) (*protocol.SignatureInformation, int, error) {
-	sig, err := NewBuiltinSignature(ctx, snapshot, name)
-	if err != nil {
-		return nil, 0, err
-	}
-	paramInfo := make([]protocol.ParameterInformation, 0, len(sig.params))
-	for _, p := range sig.params {
-		paramInfo = append(paramInfo, protocol.ParameterInformation{Label: p})
-	}
-	activeParam := activeParameter(callExpr, len(sig.params), sig.variadic, pos)
-	return &protocol.SignatureInformation{
-		Label:         sig.name + sig.Format(),
-		Documentation: sig.doc,
-		Parameters:    paramInfo,
-	}, activeParam, nil
-
-}
-
-func activeParameter(callExpr *ast.CallExpr, numParams int, variadic bool, pos token.Pos) (activeParam int) {
-	if len(callExpr.Args) == 0 {
-		return 0
-	}
-	// First, check if the position is even in the range of the arguments.
-	start, end := callExpr.Lparen, callExpr.Rparen
-	if !(start <= pos && pos <= end) {
-		return 0
-	}
-	for _, expr := range callExpr.Args {
-		if start == token.NoPos {
-			start = expr.Pos()
-		}
-		end = expr.End()
-		if start <= pos && pos <= end {
-			break
-		}
-		// Don't advance the active parameter for the last parameter of a variadic function.
-		if !variadic || activeParam < numParams-1 {
-			activeParam++
-		}
-		start = expr.Pos() + 1 // to account for commas
-	}
-	return activeParam
-}
diff -urN a/gopls/internal/lsp/source/source_test.go b/gopls/internal/lsp/source/source_test.go
--- a/gopls/internal/lsp/source/source_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/source_test.go	1969-12-31 16:00:00
@@ -1,871 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source_test
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"os"
-	"os/exec"
-	"path/filepath"
-	"sort"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/source/completion"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/fuzzy"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	testenv.ExitIfSmallMachine()
-	os.Exit(m.Run())
-}
-
-func TestSource(t *testing.T) {
-	tests.RunTests(t, "../testdata", true, testSource)
-}
-
-type runner struct {
-	session     *cache.Session
-	view        *cache.View
-	snapshot    source.Snapshot
-	data        *tests.Data
-	ctx         context.Context
-	normalizers []tests.Normalizer
-}
-
-func testSource(t *testing.T, datum *tests.Data) {
-	ctx := tests.Context(t)
-
-	session := cache.NewSession(ctx, cache.New(nil, nil), nil)
-	options := source.DefaultOptions().Clone()
-	tests.DefaultOptions(options)
-	options.SetEnvSlice(datum.Config.Env)
-	view, _, release, err := session.NewView(ctx, "source_test", span.URIFromPath(datum.Config.Dir), options)
-	if err != nil {
-		t.Fatal(err)
-	}
-	release()
-	defer session.RemoveView(view)
-
-	// Enable type error analyses for tests.
-	// TODO(golang/go#38212): Delete this once they are enabled by default.
-	tests.EnableAllAnalyzers(options)
-	view, err = session.SetViewOptions(ctx, view, options)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	var modifications []source.FileModification
-	for filename, content := range datum.Config.Overlay {
-		if filepath.Ext(filename) != ".go" {
-			continue
-		}
-		modifications = append(modifications, source.FileModification{
-			URI:        span.URIFromPath(filename),
-			Action:     source.Open,
-			Version:    -1,
-			Text:       content,
-			LanguageID: "go",
-		})
-	}
-	if err := session.ModifyFiles(ctx, modifications); err != nil {
-		t.Fatal(err)
-	}
-	snapshot, release := view.Snapshot(ctx)
-	defer release()
-	r := &runner{
-		session:     session,
-		view:        view,
-		snapshot:    snapshot,
-		data:        datum,
-		ctx:         ctx,
-		normalizers: tests.CollectNormalizers(datum.Exported),
-	}
-	tests.Run(t, r, datum)
-}
-
-func (r *runner) CallHierarchy(t *testing.T, spn span.Span, expectedCalls *tests.CallHierarchyResult) {
-	mapper, err := r.data.Mapper(spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := mapper.Location(spn)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	items, err := source.PrepareCallHierarchy(r.ctx, r.snapshot, fh, loc.Range.Start)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if len(items) == 0 {
-		t.Fatalf("expected call hierarchy item to be returned for identifier at %v\n", loc.Range)
-	}
-
-	callLocation := protocol.Location{
-		URI:   items[0].URI,
-		Range: items[0].Range,
-	}
-	if callLocation != loc {
-		t.Fatalf("expected source.PrepareCallHierarchy to return identifier at %v but got %v\n", loc, callLocation)
-	}
-
-	incomingCalls, err := source.IncomingCalls(r.ctx, r.snapshot, fh, loc.Range.Start)
-	if err != nil {
-		t.Error(err)
-	}
-	var incomingCallItems []protocol.CallHierarchyItem
-	for _, item := range incomingCalls {
-		incomingCallItems = append(incomingCallItems, item.From)
-	}
-	msg := tests.DiffCallHierarchyItems(incomingCallItems, expectedCalls.IncomingCalls)
-	if msg != "" {
-		t.Error(fmt.Sprintf("incoming calls differ: %s", msg))
-	}
-
-	outgoingCalls, err := source.OutgoingCalls(r.ctx, r.snapshot, fh, loc.Range.Start)
-	if err != nil {
-		t.Error(err)
-	}
-	var outgoingCallItems []protocol.CallHierarchyItem
-	for _, item := range outgoingCalls {
-		outgoingCallItems = append(outgoingCallItems, item.To)
-	}
-	msg = tests.DiffCallHierarchyItems(outgoingCallItems, expectedCalls.OutgoingCalls)
-	if msg != "" {
-		t.Error(fmt.Sprintf("outgoing calls differ: %s", msg))
-	}
-}
-
-func (r *runner) Diagnostics(t *testing.T, uri span.URI, want []*source.Diagnostic) {
-	fileID, got, err := source.FileDiagnostics(r.ctx, r.snapshot, uri)
-	if err != nil {
-		t.Fatal(err)
-	}
-	tests.CompareDiagnostics(t, fileID.URI, want, got)
-}
-
-func (r *runner) Completion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		want = append(want, tests.ToProtocolCompletionItem(*items[pos]))
-	}
-	_, got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.Matcher = source.CaseInsensitive
-		opts.DeepCompletion = false
-		opts.CompleteUnimported = false
-		opts.InsertTextFormat = protocol.SnippetTextFormat
-		opts.LiteralCompletions = strings.Contains(string(src.URI()), "literal")
-		opts.ExperimentalPostfixCompletions = strings.Contains(string(src.URI()), "postfix")
-	})
-	got = tests.FilterBuiltins(src, got)
-	if diff := tests.DiffCompletionItems(want, got); diff != "" {
-		t.Errorf("%s: %s", src, diff)
-	}
-}
-
-func (r *runner) CompletionSnippet(t *testing.T, src span.Span, expected tests.CompletionSnippet, placeholders bool, items tests.CompletionItems) {
-	_, list := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.UsePlaceholders = placeholders
-		opts.DeepCompletion = true
-		opts.CompleteUnimported = false
-	})
-	got := tests.FindItem(list, *items[expected.CompletionItem])
-	want := expected.PlainSnippet
-	if placeholders {
-		want = expected.PlaceholderSnippet
-	}
-	if diff := tests.DiffSnippets(want, got); diff != "" {
-		t.Errorf("%s: %s", src, diff)
-	}
-}
-
-func (r *runner) UnimportedCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		want = append(want, tests.ToProtocolCompletionItem(*items[pos]))
-	}
-	_, got := r.callCompletion(t, src, func(opts *source.Options) {})
-	got = tests.FilterBuiltins(src, got)
-	if diff := tests.CheckCompletionOrder(want, got, false); diff != "" {
-		t.Errorf("%s: %s", src, diff)
-	}
-}
-
-func (r *runner) DeepCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		want = append(want, tests.ToProtocolCompletionItem(*items[pos]))
-	}
-	prefix, list := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = true
-		opts.Matcher = source.CaseInsensitive
-		opts.CompleteUnimported = false
-	})
-	list = tests.FilterBuiltins(src, list)
-	fuzzyMatcher := fuzzy.NewMatcher(prefix)
-	var got []protocol.CompletionItem
-	for _, item := range list {
-		if fuzzyMatcher.Score(item.Label) <= 0 {
-			continue
-		}
-		got = append(got, item)
-	}
-	if msg := tests.DiffCompletionItems(want, got); msg != "" {
-		t.Errorf("%s: %s", src, msg)
-	}
-}
-
-func (r *runner) FuzzyCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		want = append(want, tests.ToProtocolCompletionItem(*items[pos]))
-	}
-	_, got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = true
-		opts.Matcher = source.Fuzzy
-		opts.CompleteUnimported = false
-	})
-	got = tests.FilterBuiltins(src, got)
-	if msg := tests.DiffCompletionItems(want, got); msg != "" {
-		t.Errorf("%s: %s", src, msg)
-	}
-}
-
-func (r *runner) CaseSensitiveCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		want = append(want, tests.ToProtocolCompletionItem(*items[pos]))
-	}
-	_, list := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.Matcher = source.CaseSensitive
-		opts.CompleteUnimported = false
-	})
-	list = tests.FilterBuiltins(src, list)
-	if diff := tests.DiffCompletionItems(want, list); diff != "" {
-		t.Errorf("%s: %s", src, diff)
-	}
-}
-
-func (r *runner) RankCompletion(t *testing.T, src span.Span, test tests.Completion, items tests.CompletionItems) {
-	var want []protocol.CompletionItem
-	for _, pos := range test.CompletionItems {
-		want = append(want, tests.ToProtocolCompletionItem(*items[pos]))
-	}
-	_, got := r.callCompletion(t, src, func(opts *source.Options) {
-		opts.DeepCompletion = true
-		opts.Matcher = source.Fuzzy
-		opts.ExperimentalPostfixCompletions = true
-	})
-	if msg := tests.CheckCompletionOrder(want, got, true); msg != "" {
-		t.Errorf("%s: %s", src, msg)
-	}
-}
-
-func (r *runner) callCompletion(t *testing.T, src span.Span, options func(*source.Options)) (string, []protocol.CompletionItem) {
-	fh, err := r.snapshot.GetFile(r.ctx, src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	original := r.view.Options()
-	modified := original.Clone()
-	options(modified)
-	view, err := r.session.SetViewOptions(r.ctx, r.view, modified)
-	if view != r.view {
-		t.Fatalf("options change unexpectedly created new view")
-	}
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer r.session.SetViewOptions(r.ctx, view, original)
-
-	list, surrounding, err := completion.Completion(r.ctx, r.snapshot, fh, protocol.Position{
-		Line:      uint32(src.Start().Line() - 1),
-		Character: uint32(src.Start().Column() - 1),
-	}, protocol.CompletionContext{})
-	if err != nil && !errors.As(err, &completion.ErrIsDefinition{}) {
-		t.Fatalf("failed for %v: %v", src, err)
-	}
-	var prefix string
-	if surrounding != nil {
-		prefix = strings.ToLower(surrounding.Prefix())
-	}
-
-	var numDeepCompletionsSeen int
-	var items []completion.CompletionItem
-	// Apply deep completion filtering.
-	for _, item := range list {
-		if item.Depth > 0 {
-			if !modified.DeepCompletion {
-				continue
-			}
-			if numDeepCompletionsSeen >= completion.MaxDeepCompletions {
-				continue
-			}
-			numDeepCompletionsSeen++
-		}
-		items = append(items, item)
-	}
-	return prefix, tests.ToProtocolCompletionItems(items)
-}
-
-func (r *runner) FoldingRanges(t *testing.T, spn span.Span) {
-	uri := spn.URI()
-
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	data, err := fh.Read()
-	if err != nil {
-		t.Error(err)
-		return
-	}
-
-	// Test all folding ranges.
-	ranges, err := source.FoldingRange(r.ctx, r.snapshot, fh, false)
-	if err != nil {
-		t.Error(err)
-		return
-	}
-	r.foldingRanges(t, "foldingRange", uri, string(data), ranges)
-
-	// Test folding ranges with lineFoldingOnly
-	ranges, err = source.FoldingRange(r.ctx, r.snapshot, fh, true)
-	if err != nil {
-		t.Error(err)
-		return
-	}
-	r.foldingRanges(t, "foldingRange-lineFolding", uri, string(data), ranges)
-}
-
-func (r *runner) foldingRanges(t *testing.T, prefix string, uri span.URI, data string, ranges []*source.FoldingRangeInfo) {
-	t.Helper()
-	// Fold all ranges.
-	nonOverlapping := nonOverlappingRanges(t, ranges)
-	for i, rngs := range nonOverlapping {
-		got, err := foldRanges(string(data), rngs)
-		if err != nil {
-			t.Error(err)
-			continue
-		}
-		tag := fmt.Sprintf("%s-%d", prefix, i)
-		want := string(r.data.Golden(t, tag, uri.Filename(), func() ([]byte, error) {
-			return []byte(got), nil
-		}))
-
-		if diff := compare.Text(want, got); diff != "" {
-			t.Errorf("%s: foldingRanges failed for %s, diff:\n%v", tag, uri.Filename(), diff)
-		}
-	}
-
-	// Filter by kind.
-	kinds := []protocol.FoldingRangeKind{protocol.Imports, protocol.Comment}
-	for _, kind := range kinds {
-		var kindOnly []*source.FoldingRangeInfo
-		for _, fRng := range ranges {
-			if fRng.Kind == kind {
-				kindOnly = append(kindOnly, fRng)
-			}
-		}
-
-		nonOverlapping := nonOverlappingRanges(t, kindOnly)
-		for i, rngs := range nonOverlapping {
-			got, err := foldRanges(string(data), rngs)
-			if err != nil {
-				t.Error(err)
-				continue
-			}
-			tag := fmt.Sprintf("%s-%s-%d", prefix, kind, i)
-			want := string(r.data.Golden(t, tag, uri.Filename(), func() ([]byte, error) {
-				return []byte(got), nil
-			}))
-
-			if diff := compare.Text(want, got); diff != "" {
-				t.Errorf("%s: failed for %s, diff:\n%v", tag, uri.Filename(), diff)
-			}
-		}
-
-	}
-}
-
-func nonOverlappingRanges(t *testing.T, ranges []*source.FoldingRangeInfo) (res [][]*source.FoldingRangeInfo) {
-	for _, fRng := range ranges {
-		setNum := len(res)
-		for i := 0; i < len(res); i++ {
-			canInsert := true
-			for _, rng := range res[i] {
-				if conflict(t, rng, fRng) {
-					canInsert = false
-					break
-				}
-			}
-			if canInsert {
-				setNum = i
-				break
-			}
-		}
-		if setNum == len(res) {
-			res = append(res, []*source.FoldingRangeInfo{})
-		}
-		res[setNum] = append(res[setNum], fRng)
-	}
-	return res
-}
-
-func conflict(t *testing.T, a, b *source.FoldingRangeInfo) bool {
-	arng, err := a.Range()
-	if err != nil {
-		t.Fatal(err)
-	}
-	brng, err := b.Range()
-	if err != nil {
-		t.Fatal(err)
-	}
-	// a start position is <= b start positions
-	return protocol.ComparePosition(arng.Start, brng.Start) <= 0 && protocol.ComparePosition(arng.End, brng.Start) > 0
-}
-
-func foldRanges(contents string, ranges []*source.FoldingRangeInfo) (string, error) {
-	foldedText := "<>"
-	res := contents
-	// Apply the folds from the end of the file forward
-	// to preserve the offsets.
-	for i := len(ranges) - 1; i >= 0; i-- {
-		fRange := ranges[i]
-		spn, err := fRange.Span()
-		if err != nil {
-			return "", err
-		}
-		start := spn.Start().Offset()
-		end := spn.End().Offset()
-
-		tmp := res[0:start] + foldedText
-		res = tmp + res[end:]
-	}
-	return res, nil
-}
-
-func (r *runner) Format(t *testing.T, spn span.Span) {
-	gofmted := string(r.data.Golden(t, "gofmt", spn.URI().Filename(), func() ([]byte, error) {
-		cmd := exec.Command("gofmt", spn.URI().Filename())
-		out, _ := cmd.Output() // ignore error, sometimes we have intentionally ungofmt-able files
-		return out, nil
-	}))
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	edits, err := source.Format(r.ctx, r.snapshot, fh)
-	if err != nil {
-		if gofmted != "" {
-			t.Error(err)
-		}
-		return
-	}
-	m, err := r.data.Mapper(spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, _, err := source.ApplyProtocolEdits(m, edits)
-	if err != nil {
-		t.Error(err)
-	}
-	if gofmted != got {
-		t.Errorf("format failed for %s, expected:\n%v\ngot:\n%v", spn.URI().Filename(), gofmted, got)
-	}
-}
-
-func (r *runner) SemanticTokens(t *testing.T, spn span.Span) {
-	t.Skip("nothing to test in source")
-}
-
-func (r *runner) SelectionRanges(t *testing.T, spn span.Span) {
-	t.Skip("nothing to test in source")
-}
-
-func (r *runner) Import(t *testing.T, spn span.Span) {
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	edits, _, err := source.AllImportsFixes(r.ctx, r.snapshot, fh)
-	if err != nil {
-		t.Error(err)
-	}
-	m, err := r.data.Mapper(fh.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, _, err := source.ApplyProtocolEdits(m, edits)
-	if err != nil {
-		t.Error(err)
-	}
-	want := string(r.data.Golden(t, "goimports", spn.URI().Filename(), func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-	if d := compare.Text(got, want); d != "" {
-		t.Errorf("import failed for %s:\n%s", spn.URI().Filename(), d)
-	}
-}
-
-func (r *runner) Definition(t *testing.T, spn span.Span, d tests.Definition) {
-	_, srcRng, err := spanToRange(r.data, d.Src)
-	if err != nil {
-		t.Fatal(err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	ident, err := source.Identifier(r.ctx, r.snapshot, fh, srcRng.Start)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", d.Src, err)
-	}
-	h, err := source.HoverIdentifier(r.ctx, ident)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", d.Src, err)
-	}
-	hover, err := source.FormatHover(h, r.view.Options())
-	if err != nil {
-		t.Fatal(err)
-	}
-	rng, err := ident.Declaration.MappedRange[0].Range()
-	if err != nil {
-		t.Fatal(err)
-	}
-	if d.IsType {
-		rng, err = ident.Type.Range()
-		if err != nil {
-			t.Fatal(err)
-		}
-		hover = ""
-	}
-	didSomething := false
-	if hover != "" {
-		didSomething = true
-		tag := fmt.Sprintf("%s-hoverdef", d.Name)
-		expectHover := string(r.data.Golden(t, tag, d.Src.URI().Filename(), func() ([]byte, error) {
-			return []byte(hover), nil
-		}))
-		hover = tests.StripSubscripts(hover)
-		expectHover = tests.StripSubscripts(expectHover)
-		if hover != expectHover {
-			tests.CheckSameMarkdown(t, hover, expectHover)
-
-		}
-	}
-	if !d.OnlyHover {
-		didSomething = true
-		if _, defRng, err := spanToRange(r.data, d.Def); err != nil {
-			t.Fatal(err)
-		} else if rng != defRng {
-			t.Errorf("for %v got %v want %v", d.Src, rng, defRng)
-		}
-	}
-	if !didSomething {
-		t.Errorf("no tests ran for %s", d.Src.URI())
-	}
-}
-
-func (r *runner) Implementation(t *testing.T, spn span.Span, impls []span.Span) {
-	sm, err := r.data.Mapper(spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	loc, err := sm.Location(spn)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	locs, err := source.Implementation(r.ctx, r.snapshot, fh, loc.Range.Start)
-	if err != nil {
-		t.Fatalf("failed for %v: %v", spn, err)
-	}
-	if len(locs) != len(impls) {
-		t.Fatalf("got %d locations for implementation, expected %d", len(locs), len(impls))
-	}
-	var results []span.Span
-	for i := range locs {
-		locURI := locs[i].URI.SpanURI()
-		lm, err := r.data.Mapper(locURI)
-		if err != nil {
-			t.Fatal(err)
-		}
-		imp, err := lm.Span(locs[i])
-		if err != nil {
-			t.Fatalf("failed for %v: %v", locs[i], err)
-		}
-		results = append(results, imp)
-	}
-	span.SortSpans(results) // to make tests
-	span.SortSpans(impls)   // deterministic
-	for i := range results {
-		if results[i] != impls[i] {
-			t.Errorf("for %dth implementation of %v got %v want %v", i, spn, results[i], impls[i])
-		}
-	}
-}
-
-func (r *runner) Highlight(t *testing.T, src span.Span, locations []span.Span) {
-	ctx := r.ctx
-	m, srcRng, err := spanToRange(r.data, src)
-	if err != nil {
-		t.Fatal(err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	highlights, err := source.Highlight(ctx, r.snapshot, fh, srcRng.Start)
-	if err != nil {
-		t.Errorf("highlight failed for %s: %v", src.URI(), err)
-	}
-	if len(highlights) != len(locations) {
-		t.Fatalf("got %d highlights for highlight at %v:%v:%v, expected %d", len(highlights), src.URI().Filename(), src.Start().Line(), src.Start().Column(), len(locations))
-	}
-	// Check to make sure highlights have a valid range.
-	var results []span.Span
-	for i := range highlights {
-		h, err := m.RangeSpan(highlights[i])
-		if err != nil {
-			t.Fatalf("failed for %v: %v", highlights[i], err)
-		}
-		results = append(results, h)
-	}
-	// Sort results to make tests deterministic since DocumentHighlight uses a map.
-	span.SortSpans(results)
-	// Check to make sure all the expected highlights are found.
-	for i := range results {
-		if results[i] != locations[i] {
-			t.Errorf("want %v, got %v\n", locations[i], results[i])
-		}
-	}
-}
-
-func (r *runner) InlayHints(t *testing.T, src span.Span) {
-	// TODO(golang/go#53315): add source test
-}
-
-func (r *runner) Hover(t *testing.T, src span.Span, text string) {
-	ctx := r.ctx
-	_, srcRng, err := spanToRange(r.data, src)
-	if err != nil {
-		t.Fatal(err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	hover, err := source.Hover(ctx, r.snapshot, fh, srcRng.Start)
-	if err != nil {
-		t.Errorf("hover failed for %s: %v", src.URI(), err)
-	}
-	if text == "" {
-		if hover != nil {
-			t.Errorf("want nil, got %v\n", hover)
-		}
-	} else {
-		if hover == nil {
-			t.Fatalf("want hover result to not be nil")
-		}
-		if got := hover.Contents.Value; got != text {
-			t.Errorf("want %v, got %v\n", got, text)
-		}
-		if want, got := srcRng, hover.Range; want != got {
-			t.Errorf("want range %v, got %v instead", want, got)
-		}
-	}
-}
-
-func (r *runner) References(t *testing.T, src span.Span, itemList []span.Span) {
-	ctx := r.ctx
-	_, srcRng, err := spanToRange(r.data, src)
-	if err != nil {
-		t.Fatal(err)
-	}
-	snapshot := r.snapshot
-	fh, err := snapshot.GetFile(r.ctx, src.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	for _, includeDeclaration := range []bool{true, false} {
-		t.Run(fmt.Sprintf("refs-declaration-%v", includeDeclaration), func(t *testing.T) {
-			want := make(map[span.Span]bool)
-			for i, pos := range itemList {
-				// We don't want the first result if we aren't including the declaration.
-				if i == 0 && !includeDeclaration {
-					continue
-				}
-				want[pos] = true
-			}
-			refs, err := source.References(ctx, snapshot, fh, srcRng.Start, includeDeclaration)
-			if err != nil {
-				t.Fatalf("failed for %s: %v", src, err)
-			}
-			got := make(map[span.Span]bool)
-			for _, refInfo := range refs {
-				refSpan, err := refInfo.Span()
-				if err != nil {
-					t.Fatal(err)
-				}
-				got[refSpan] = true
-			}
-			if len(got) != len(want) {
-				t.Errorf("references failed: different lengths got %v want %v", len(got), len(want))
-			}
-			for spn := range got {
-				if !want[spn] {
-					t.Errorf("references failed: incorrect references got %v want locations %v", got, want)
-				}
-			}
-		})
-	}
-}
-
-func (r *runner) Rename(t *testing.T, spn span.Span, newText string) {
-	tag := fmt.Sprintf("%s-rename", newText)
-
-	_, srcRng, err := spanToRange(r.data, spn)
-	if err != nil {
-		t.Fatal(err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	changes, _, err := source.Rename(r.ctx, r.snapshot, fh, srcRng.Start, newText)
-	if err != nil {
-		renamed := string(r.data.Golden(t, tag, spn.URI().Filename(), func() ([]byte, error) {
-			return []byte(err.Error()), nil
-		}))
-		if err.Error() != renamed {
-			t.Errorf("rename failed for %s, expected:\n%v\ngot:\n%v\n", newText, renamed, err)
-		}
-		return
-	}
-
-	var res []string
-	for editURI, edits := range changes {
-		fh, err := r.snapshot.GetFile(r.ctx, editURI)
-		if err != nil {
-			t.Fatal(err)
-		}
-		m, err := r.data.Mapper(fh.URI())
-		if err != nil {
-			t.Fatal(err)
-		}
-		contents, _, err := source.ApplyProtocolEdits(m, edits)
-		if err != nil {
-			t.Fatal(err)
-		}
-		if len(changes) > 1 {
-			filename := filepath.Base(editURI.Filename())
-			contents = fmt.Sprintf("%s:\n%s", filename, contents)
-		}
-		res = append(res, contents)
-	}
-
-	// Sort on filename
-	sort.Strings(res)
-
-	var got string
-	for i, val := range res {
-		if i != 0 {
-			got += "\n"
-		}
-		got += val
-	}
-
-	renamed := string(r.data.Golden(t, tag, spn.URI().Filename(), func() ([]byte, error) {
-		return []byte(got), nil
-	}))
-
-	if renamed != got {
-		t.Errorf("rename failed for %s, expected:\n%v\ngot:\n%v", newText, renamed, got)
-	}
-}
-
-func (r *runner) PrepareRename(t *testing.T, src span.Span, want *source.PrepareItem) {
-	// Removed in favor of just using the lsp_test implementation. See ../lsp_test.go
-}
-
-func (r *runner) Symbols(t *testing.T, uri span.URI, expectedSymbols []protocol.DocumentSymbol) {
-	// Removed in favor of just using the lsp_test implementation. See ../lsp_test.go
-}
-
-func (r *runner) WorkspaceSymbols(t *testing.T, uri span.URI, query string, typ tests.WorkspaceSymbolsTestType) {
-	// Removed in favor of just using the lsp_test implementation. See ../lsp_test.go
-}
-
-func (r *runner) SignatureHelp(t *testing.T, spn span.Span, want *protocol.SignatureHelp) {
-	_, rng, err := spanToRange(r.data, spn)
-	if err != nil {
-		t.Fatal(err)
-	}
-	fh, err := r.snapshot.GetFile(r.ctx, spn.URI())
-	if err != nil {
-		t.Fatal(err)
-	}
-	gotSignature, gotActiveParameter, err := source.SignatureHelp(r.ctx, r.snapshot, fh, rng.Start)
-	if err != nil {
-		// Only fail if we got an error we did not expect.
-		if want != nil {
-			t.Fatalf("failed for %v: %v", spn, err)
-		}
-		return
-	}
-	if gotSignature == nil {
-		if want != nil {
-			t.Fatalf("got nil signature, but expected %v", want)
-		}
-		return
-	}
-	got := &protocol.SignatureHelp{
-		Signatures:      []protocol.SignatureInformation{*gotSignature},
-		ActiveParameter: uint32(gotActiveParameter),
-	}
-	if diff := tests.DiffSignatures(spn, want, got); diff != "" {
-		t.Error(diff)
-	}
-}
-
-// These are pure LSP features, no source level functionality to be tested.
-func (r *runner) Link(t *testing.T, uri span.URI, wantLinks []tests.Link)                          {}
-func (r *runner) SuggestedFix(t *testing.T, spn span.Span, actions []tests.SuggestedFix, want int) {}
-func (r *runner) FunctionExtraction(t *testing.T, start span.Span, end span.Span)                  {}
-func (r *runner) MethodExtraction(t *testing.T, start span.Span, end span.Span)                    {}
-func (r *runner) CodeLens(t *testing.T, uri span.URI, want []protocol.CodeLens)                    {}
-func (r *runner) AddImport(t *testing.T, uri span.URI, expectedImport string)                      {}
-
-func spanToRange(data *tests.Data, spn span.Span) (*protocol.ColumnMapper, protocol.Range, error) {
-	m, err := data.Mapper(spn.URI())
-	if err != nil {
-		return nil, protocol.Range{}, err
-	}
-	srcRng, err := m.Range(spn)
-	if err != nil {
-		return nil, protocol.Range{}, err
-	}
-	return m, srcRng, nil
-}
diff -urN a/gopls/internal/lsp/source/stub.go b/gopls/internal/lsp/source/stub.go
--- a/gopls/internal/lsp/source/stub.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/stub.go	1969-12-31 16:00:00
@@ -1,340 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/ast"
-	"go/format"
-	"go/parser"
-	"go/token"
-	"go/types"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/ast/astutil"
-	"golang.org/x/tools/gopls/internal/lsp/analysis/stubmethods"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func stubSuggestedFixFunc(ctx context.Context, snapshot Snapshot, fh VersionedFileHandle, rng protocol.Range) (*token.FileSet, *analysis.SuggestedFix, error) {
-	pkg, pgf, err := PackageForFile(ctx, snapshot, fh.URI(), TypecheckWorkspace, NarrowestPackage)
-	if err != nil {
-		return nil, nil, fmt.Errorf("GetTypedFile: %w", err)
-	}
-	nodes, pos, err := getStubNodes(pgf, rng)
-	if err != nil {
-		return nil, nil, fmt.Errorf("getNodes: %w", err)
-	}
-	si := stubmethods.GetStubInfo(pkg.GetTypesInfo(), nodes, pos)
-	if si == nil {
-		return nil, nil, fmt.Errorf("nil interface request")
-	}
-
-	// A function-local type cannot be stubbed
-	// since there's nowhere to put the methods.
-	conc := si.Concrete.Obj()
-	if conc != conc.Pkg().Scope().Lookup(conc.Name()) {
-		return nil, nil, fmt.Errorf("local type %q cannot be stubbed", conc.Name())
-	}
-
-	// Parse the file defining the concrete type.
-	concreteFilename := safetoken.StartPosition(snapshot.FileSet(), si.Concrete.Obj().Pos()).Filename
-	concreteFH, err := snapshot.GetFile(ctx, span.URIFromPath(concreteFilename))
-	if err != nil {
-		return nil, nil, err
-	}
-	parsedConcreteFile, err := snapshot.ParseGo(ctx, concreteFH, ParseFull)
-	if err != nil {
-		return nil, nil, fmt.Errorf("failed to parse file declaring implementation type: %w", err)
-	}
-	var (
-		methodsSrc  []byte
-		stubImports []*stubImport // additional imports needed for method stubs
-	)
-	if si.Interface.Pkg() == nil && si.Interface.Name() == "error" && si.Interface.Parent() == types.Universe {
-		methodsSrc = stubErr(ctx, parsedConcreteFile.File, si, snapshot)
-	} else {
-		methodsSrc, stubImports, err = stubMethods(ctx, parsedConcreteFile.File, si, snapshot)
-		if err != nil {
-			return nil, nil, fmt.Errorf("stubMethods: %w", err)
-		}
-	}
-
-	// Splice the methods into the file.
-	// The insertion point is after the top-level declaration
-	// enclosing the (package-level) type object.
-	insertPos := parsedConcreteFile.File.End()
-	for _, decl := range parsedConcreteFile.File.Decls {
-		if decl.End() > conc.Pos() {
-			insertPos = decl.End()
-			break
-		}
-	}
-	concreteSrc, err := concreteFH.Read()
-	if err != nil {
-		return nil, nil, fmt.Errorf("error reading concrete file source: %w", err)
-	}
-	insertOffset, err := safetoken.Offset(parsedConcreteFile.Tok, insertPos)
-	if err != nil || insertOffset >= len(concreteSrc) {
-		return nil, nil, fmt.Errorf("insertion position is past the end of the file")
-	}
-	var buf bytes.Buffer
-	buf.Write(concreteSrc[:insertOffset])
-	buf.WriteByte('\n')
-	buf.Write(methodsSrc)
-	buf.Write(concreteSrc[insertOffset:])
-
-	// Re-parse it, splice in imports, pretty-print it.
-	fset := token.NewFileSet()
-	newF, err := parser.ParseFile(fset, parsedConcreteFile.File.Name.Name, buf.Bytes(), parser.ParseComments)
-	if err != nil {
-		return nil, nil, fmt.Errorf("could not reparse file: %w", err)
-	}
-	for _, imp := range stubImports {
-		astutil.AddNamedImport(fset, newF, imp.Name, imp.Path)
-	}
-	var source strings.Builder
-	if err := format.Node(&source, fset, newF); err != nil {
-		return nil, nil, fmt.Errorf("format.Node: %w", err)
-	}
-
-	// Return the diff.
-	diffs := snapshot.View().Options().ComputeEdits(string(parsedConcreteFile.Src), source.String())
-	tf := parsedConcreteFile.Mapper.TokFile
-	var edits []analysis.TextEdit
-	for _, edit := range diffs {
-		edits = append(edits, analysis.TextEdit{
-			Pos:     tf.Pos(edit.Start),
-			End:     tf.Pos(edit.End),
-			NewText: []byte(edit.New),
-		})
-	}
-	return snapshot.FileSet(), // to match snapshot.ParseGo above
-		&analysis.SuggestedFix{TextEdits: edits},
-		nil
-}
-
-// stubMethods returns the Go code of all methods
-// that implement the given interface
-func stubMethods(ctx context.Context, concreteFile *ast.File, si *stubmethods.StubInfo, snapshot Snapshot) ([]byte, []*stubImport, error) {
-	concMS := types.NewMethodSet(types.NewPointer(si.Concrete.Obj().Type()))
-	missing, err := missingMethods(ctx, snapshot, concMS, si.Concrete.Obj().Pkg(), si.Interface, map[string]struct{}{})
-	if err != nil {
-		return nil, nil, fmt.Errorf("missingMethods: %w", err)
-	}
-	if len(missing) == 0 {
-		return nil, nil, fmt.Errorf("no missing methods found")
-	}
-	var (
-		stubImports   []*stubImport
-		methodsBuffer bytes.Buffer
-	)
-	for _, mi := range missing {
-		for _, m := range mi.missing {
-			// TODO(marwan-at-work): this should share the same logic with source.FormatVarType
-			// as it also accounts for type aliases.
-			sig := types.TypeString(m.Type(), stubmethods.RelativeToFiles(si.Concrete.Obj().Pkg(), concreteFile, mi.imports, func(name, path string) {
-				for _, imp := range stubImports {
-					if imp.Name == name && imp.Path == path {
-						return
-					}
-				}
-				stubImports = append(stubImports, &stubImport{name, path})
-			}))
-			_, err = methodsBuffer.Write(printStubMethod(methodData{
-				Method:    m.Name(),
-				Concrete:  getStubReceiver(si),
-				Interface: deduceIfaceName(si.Concrete.Obj().Pkg(), si.Interface.Pkg(), si.Interface),
-				Signature: strings.TrimPrefix(sig, "func"),
-			}))
-			if err != nil {
-				return nil, nil, fmt.Errorf("error printing method: %w", err)
-			}
-			methodsBuffer.WriteRune('\n')
-		}
-	}
-	return methodsBuffer.Bytes(), stubImports, nil
-}
-
-// stubErr reurns the Go code implementation
-// of an error interface relevant to the
-// concrete type
-func stubErr(ctx context.Context, concreteFile *ast.File, si *stubmethods.StubInfo, snapshot Snapshot) []byte {
-	return printStubMethod(methodData{
-		Method:    "Error",
-		Interface: "error",
-		Concrete:  getStubReceiver(si),
-		Signature: "() string",
-	})
-}
-
-// getStubReceiver returns the concrete type's name as a method receiver.
-// It accounts for type parameters if they exist.
-func getStubReceiver(si *stubmethods.StubInfo) string {
-	var concrete string
-	if si.Pointer {
-		concrete += "*"
-	}
-	concrete += si.Concrete.Obj().Name()
-	concrete += FormatTypeParams(typeparams.ForNamed(si.Concrete))
-	return concrete
-}
-
-type methodData struct {
-	Method    string
-	Interface string
-	Concrete  string
-	Signature string
-}
-
-// printStubMethod takes methodData and returns Go code that represents the given method such as:
-//
-//	// {{ .Method }} implements {{ .Interface }}
-//	func ({{ .Concrete }}) {{ .Method }}{{ .Signature }} {
-//		panic("unimplemented")
-//	}
-func printStubMethod(md methodData) []byte {
-	var b bytes.Buffer
-	fmt.Fprintf(&b, "// %s implements %s\n", md.Method, md.Interface)
-	fmt.Fprintf(&b, "func (%s) %s%s {\n\t", md.Concrete, md.Method, md.Signature)
-	fmt.Fprintln(&b, `panic("unimplemented")`)
-	fmt.Fprintln(&b, "}")
-	return b.Bytes()
-}
-
-func deduceIfaceName(concretePkg, ifacePkg *types.Package, ifaceObj types.Object) string {
-	if concretePkg.Path() == ifacePkg.Path() {
-		return ifaceObj.Name()
-	}
-	return fmt.Sprintf("%s.%s", ifacePkg.Name(), ifaceObj.Name())
-}
-
-func getStubNodes(pgf *ParsedGoFile, pRng protocol.Range) ([]ast.Node, token.Pos, error) {
-	spn, err := pgf.Mapper.RangeSpan(pRng)
-	if err != nil {
-		return nil, 0, err
-	}
-	rng, err := spn.Range(pgf.Mapper.TokFile)
-	if err != nil {
-		return nil, 0, err
-	}
-	nodes, _ := astutil.PathEnclosingInterval(pgf.File, rng.Start, rng.End)
-	return nodes, rng.Start, nil
-}
-
-/*
-missingMethods takes a concrete type and returns any missing methods for the given interface as well as
-any missing interface that might have been embedded to its parent. For example:
-
-	type I interface {
-		io.Writer
-		Hello()
-	}
-
-returns
-
-	[]*missingInterface{
-		{
-			iface: *types.Interface (io.Writer),
-			file: *ast.File: io.go,
-			missing []*types.Func{Write},
-		},
-		{
-			iface: *types.Interface (I),
-			file: *ast.File: myfile.go,
-			missing: []*types.Func{Hello}
-		},
-	}
-*/
-func missingMethods(ctx context.Context, snapshot Snapshot, concMS *types.MethodSet, concPkg *types.Package, ifaceObj *types.TypeName, visited map[string]struct{}) ([]*missingInterface, error) {
-	iface, ok := ifaceObj.Type().Underlying().(*types.Interface)
-	if !ok {
-		return nil, fmt.Errorf("expected %v to be an interface but got %T", iface, ifaceObj.Type().Underlying())
-	}
-	// Parse the imports from the file that declares the interface.
-	ifaceFilename := safetoken.StartPosition(snapshot.FileSet(), ifaceObj.Pos()).Filename
-	ifaceFH, err := snapshot.GetFile(ctx, span.URIFromPath(ifaceFilename))
-	if err != nil {
-		return nil, err
-	}
-	ifaceFile, err := snapshot.ParseGo(ctx, ifaceFH, ParseHeader)
-	if err != nil {
-		return nil, fmt.Errorf("error parsing imports from interface file: %w", err)
-	}
-
-	mi := &missingInterface{
-		iface:   ifaceObj,
-		imports: ifaceFile.File.Imports,
-	}
-
-	// Add all the interface methods not defined by the concrete type to mi.missing.
-	for i := 0; i < iface.NumExplicitMethods(); i++ {
-		method := iface.ExplicitMethod(i)
-		if sel := concMS.Lookup(concPkg, method.Name()); sel == nil {
-			// Concrete type does not have the interface method.
-			if _, ok := visited[method.Name()]; !ok {
-				mi.missing = append(mi.missing, method)
-				visited[method.Name()] = struct{}{}
-			}
-		} else {
-			// Concrete type does have the interface method.
-			implSig := sel.Type().(*types.Signature)
-			ifaceSig := method.Type().(*types.Signature)
-			if !types.Identical(ifaceSig, implSig) {
-				return nil, fmt.Errorf("mimsatched %q function signatures:\nhave: %s\nwant: %s", method.Name(), implSig, ifaceSig)
-			}
-		}
-	}
-
-	// Process embedded interfaces, recursively.
-	//
-	// TODO(adonovan): this whole computation could be expressed
-	// more simply without recursion, driven by the method
-	// sets of the interface and concrete types. Once the set
-	// difference (missing methods) is computed, the imports
-	// from the declaring file(s) could be loaded as needed.
-	var missing []*missingInterface
-	for i := 0; i < iface.NumEmbeddeds(); i++ {
-		eiface := iface.Embedded(i).Obj()
-		em, err := missingMethods(ctx, snapshot, concMS, concPkg, eiface, visited)
-		if err != nil {
-			return nil, err
-		}
-		missing = append(missing, em...)
-	}
-	// The type checker is deterministic, but its choice of
-	// ordering of embedded interfaces varies with Go version
-	// (e.g. go1.17 was sorted, go1.18 was lexical order).
-	// Sort to ensure test portability.
-	sort.Slice(missing, func(i, j int) bool {
-		return missing[i].iface.Id() < missing[j].iface.Id()
-	})
-
-	if len(mi.missing) > 0 {
-		missing = append(missing, mi)
-	}
-	return missing, nil
-}
-
-// missingInterface represents an interface
-// that has all or some of its methods missing
-// from the destination concrete type
-type missingInterface struct {
-	iface   *types.TypeName
-	imports []*ast.ImportSpec // the interface's import environment
-	missing []*types.Func
-}
-
-// stubImport represents a newly added import
-// statement to the concrete type. If name is not
-// empty, then that import is required to have that name.
-type stubImport struct{ Name, Path string }
diff -urN a/gopls/internal/lsp/source/symbols.go b/gopls/internal/lsp/source/symbols.go
--- a/gopls/internal/lsp/source/symbols.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/symbols.go	1969-12-31 16:00:00
@@ -1,235 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"go/types"
-
-	"golang.org/x/tools/gopls/internal/lsp/lsppos"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-)
-
-func DocumentSymbols(ctx context.Context, snapshot Snapshot, fh FileHandle) ([]protocol.DocumentSymbol, error) {
-	ctx, done := event.Start(ctx, "source.DocumentSymbols")
-	defer done()
-
-	content, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseFull)
-	if err != nil {
-		return nil, fmt.Errorf("getting file for DocumentSymbols: %w", err)
-	}
-
-	m := lsppos.NewTokenMapper(content, pgf.Tok)
-
-	// Build symbols for file declarations. When encountering a declaration with
-	// errors (typically because positions are invalid), we skip the declaration
-	// entirely. VS Code fails to show any symbols if one of the top-level
-	// symbols is missing position information.
-	var symbols []protocol.DocumentSymbol
-	for _, decl := range pgf.File.Decls {
-		switch decl := decl.(type) {
-		case *ast.FuncDecl:
-			if decl.Name.Name == "_" {
-				continue
-			}
-			fs, err := funcSymbol(m, decl)
-			if err == nil {
-				// If function is a method, prepend the type of the method.
-				if decl.Recv != nil && len(decl.Recv.List) > 0 {
-					fs.Name = fmt.Sprintf("(%s).%s", types.ExprString(decl.Recv.List[0].Type), fs.Name)
-				}
-				symbols = append(symbols, fs)
-			}
-		case *ast.GenDecl:
-			for _, spec := range decl.Specs {
-				switch spec := spec.(type) {
-				case *ast.TypeSpec:
-					if spec.Name.Name == "_" {
-						continue
-					}
-					ts, err := typeSymbol(m, spec)
-					if err == nil {
-						symbols = append(symbols, ts)
-					}
-				case *ast.ValueSpec:
-					for _, name := range spec.Names {
-						if name.Name == "_" {
-							continue
-						}
-						vs, err := varSymbol(m, spec, name, decl.Tok == token.CONST)
-						if err == nil {
-							symbols = append(symbols, vs)
-						}
-					}
-				}
-			}
-		}
-	}
-	return symbols, nil
-}
-
-func funcSymbol(m *lsppos.TokenMapper, decl *ast.FuncDecl) (protocol.DocumentSymbol, error) {
-	s := protocol.DocumentSymbol{
-		Name: decl.Name.Name,
-		Kind: protocol.Function,
-	}
-	if decl.Recv != nil {
-		s.Kind = protocol.Method
-	}
-	var err error
-	s.Range, err = m.Range(decl.Pos(), decl.End())
-	if err != nil {
-		return protocol.DocumentSymbol{}, err
-	}
-	s.SelectionRange, err = m.Range(decl.Name.Pos(), decl.Name.End())
-	if err != nil {
-		return protocol.DocumentSymbol{}, err
-	}
-	s.Detail = types.ExprString(decl.Type)
-	return s, nil
-}
-
-func typeSymbol(m *lsppos.TokenMapper, spec *ast.TypeSpec) (protocol.DocumentSymbol, error) {
-	s := protocol.DocumentSymbol{
-		Name: spec.Name.Name,
-	}
-	var err error
-	s.Range, err = m.NodeRange(spec)
-	if err != nil {
-		return protocol.DocumentSymbol{}, err
-	}
-	s.SelectionRange, err = m.NodeRange(spec.Name)
-	if err != nil {
-		return protocol.DocumentSymbol{}, err
-	}
-	s.Kind, s.Detail, s.Children = typeDetails(m, spec.Type)
-	return s, nil
-}
-
-func typeDetails(m *lsppos.TokenMapper, typExpr ast.Expr) (kind protocol.SymbolKind, detail string, children []protocol.DocumentSymbol) {
-	switch typExpr := typExpr.(type) {
-	case *ast.StructType:
-		kind = protocol.Struct
-		children = fieldListSymbols(m, typExpr.Fields, protocol.Field)
-		if len(children) > 0 {
-			detail = "struct{...}"
-		} else {
-			detail = "struct{}"
-		}
-
-		// Find interface methods and embedded types.
-	case *ast.InterfaceType:
-		kind = protocol.Interface
-		children = fieldListSymbols(m, typExpr.Methods, protocol.Method)
-		if len(children) > 0 {
-			detail = "interface{...}"
-		} else {
-			detail = "interface{}"
-		}
-
-	case *ast.FuncType:
-		kind = protocol.Function
-		detail = types.ExprString(typExpr)
-
-	default:
-		kind = protocol.Class // catch-all, for cases where we don't know the kind syntactically
-		detail = types.ExprString(typExpr)
-	}
-	return
-}
-
-func fieldListSymbols(m *lsppos.TokenMapper, fields *ast.FieldList, fieldKind protocol.SymbolKind) []protocol.DocumentSymbol {
-	if fields == nil {
-		return nil
-	}
-
-	var symbols []protocol.DocumentSymbol
-	for _, field := range fields.List {
-		detail, children := "", []protocol.DocumentSymbol(nil)
-		if field.Type != nil {
-			_, detail, children = typeDetails(m, field.Type)
-		}
-		if len(field.Names) == 0 { // embedded interface or struct field
-			// By default, use the formatted type details as the name of this field.
-			// This handles potentially invalid syntax, as well as type embeddings in
-			// interfaces.
-			child := protocol.DocumentSymbol{
-				Name:     detail,
-				Kind:     protocol.Field, // consider all embeddings to be fields
-				Children: children,
-			}
-
-			// If the field is a valid embedding, promote the type name to field
-			// name.
-			selection := field.Type
-			if id := embeddedIdent(field.Type); id != nil {
-				child.Name = id.Name
-				child.Detail = detail
-				selection = id
-			}
-
-			if rng, err := m.NodeRange(field.Type); err == nil {
-				child.Range = rng
-			}
-			if rng, err := m.NodeRange(selection); err == nil {
-				child.SelectionRange = rng
-			}
-
-			symbols = append(symbols, child)
-		} else {
-			for _, name := range field.Names {
-				child := protocol.DocumentSymbol{
-					Name:     name.Name,
-					Kind:     fieldKind,
-					Detail:   detail,
-					Children: children,
-				}
-
-				if rng, err := m.NodeRange(field); err == nil {
-					child.Range = rng
-				}
-				if rng, err := m.NodeRange(name); err == nil {
-					child.SelectionRange = rng
-				}
-
-				symbols = append(symbols, child)
-			}
-		}
-
-	}
-	return symbols
-}
-
-func varSymbol(m *lsppos.TokenMapper, spec *ast.ValueSpec, name *ast.Ident, isConst bool) (protocol.DocumentSymbol, error) {
-	s := protocol.DocumentSymbol{
-		Name: name.Name,
-		Kind: protocol.Variable,
-	}
-	if isConst {
-		s.Kind = protocol.Constant
-	}
-	var err error
-	s.Range, err = m.NodeRange(spec)
-	if err != nil {
-		return protocol.DocumentSymbol{}, err
-	}
-	s.SelectionRange, err = m.NodeRange(name)
-	if err != nil {
-		return protocol.DocumentSymbol{}, err
-	}
-	if spec.Type != nil { // type may be missing from the syntax
-		_, s.Detail, s.Children = typeDetails(m, spec.Type)
-	}
-	return s, nil
-}
diff -urN a/gopls/internal/lsp/source/types_format.go b/gopls/internal/lsp/source/types_format.go
--- a/gopls/internal/lsp/source/types_format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/types_format.go	1969-12-31 16:00:00
@@ -1,451 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/ast"
-	"go/doc"
-	"go/printer"
-	"go/token"
-	"go/types"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// FormatType returns the detail and kind for a types.Type.
-func FormatType(typ types.Type, qf types.Qualifier) (detail string, kind protocol.CompletionItemKind) {
-	if types.IsInterface(typ) {
-		detail = "interface{...}"
-		kind = protocol.InterfaceCompletion
-	} else if _, ok := typ.(*types.Struct); ok {
-		detail = "struct{...}"
-		kind = protocol.StructCompletion
-	} else if typ != typ.Underlying() {
-		detail, kind = FormatType(typ.Underlying(), qf)
-	} else {
-		detail = types.TypeString(typ, qf)
-		kind = protocol.ClassCompletion
-	}
-	return detail, kind
-}
-
-type signature struct {
-	name, doc                   string
-	typeParams, params, results []string
-	variadic                    bool
-	needResultParens            bool
-}
-
-func (s *signature) Format() string {
-	var b strings.Builder
-	b.WriteByte('(')
-	for i, p := range s.params {
-		if i > 0 {
-			b.WriteString(", ")
-		}
-		b.WriteString(p)
-	}
-	b.WriteByte(')')
-
-	// Add space between parameters and results.
-	if len(s.results) > 0 {
-		b.WriteByte(' ')
-	}
-	if s.needResultParens {
-		b.WriteByte('(')
-	}
-	for i, r := range s.results {
-		if i > 0 {
-			b.WriteString(", ")
-		}
-		b.WriteString(r)
-	}
-	if s.needResultParens {
-		b.WriteByte(')')
-	}
-	return b.String()
-}
-
-func (s *signature) TypeParams() []string {
-	return s.typeParams
-}
-
-func (s *signature) Params() []string {
-	return s.params
-}
-
-// NewBuiltinSignature returns signature for the builtin object with a given
-// name, if a builtin object with the name exists.
-func NewBuiltinSignature(ctx context.Context, s Snapshot, name string) (*signature, error) {
-	fset := s.FileSet()
-	builtin, err := s.BuiltinFile(ctx)
-	if err != nil {
-		return nil, err
-	}
-	obj := builtin.File.Scope.Lookup(name)
-	if obj == nil {
-		return nil, fmt.Errorf("no builtin object for %s", name)
-	}
-	decl, ok := obj.Decl.(*ast.FuncDecl)
-	if !ok {
-		return nil, fmt.Errorf("no function declaration for builtin: %s", name)
-	}
-	if decl.Type == nil {
-		return nil, fmt.Errorf("no type for builtin decl %s", decl.Name)
-	}
-	var variadic bool
-	if decl.Type.Params.List != nil {
-		numParams := len(decl.Type.Params.List)
-		lastParam := decl.Type.Params.List[numParams-1]
-		if _, ok := lastParam.Type.(*ast.Ellipsis); ok {
-			variadic = true
-		}
-	}
-	params, _ := formatFieldList(ctx, fset, decl.Type.Params, variadic)
-	results, needResultParens := formatFieldList(ctx, fset, decl.Type.Results, false)
-	d := decl.Doc.Text()
-	switch s.View().Options().HoverKind {
-	case SynopsisDocumentation:
-		d = doc.Synopsis(d)
-	case NoDocumentation:
-		d = ""
-	}
-	return &signature{
-		doc:              d,
-		name:             name,
-		needResultParens: needResultParens,
-		params:           params,
-		results:          results,
-		variadic:         variadic,
-	}, nil
-}
-
-var replacer = strings.NewReplacer(
-	`ComplexType`, `complex128`,
-	`FloatType`, `float64`,
-	`IntegerType`, `int`,
-)
-
-func formatFieldList(ctx context.Context, fset *token.FileSet, list *ast.FieldList, variadic bool) ([]string, bool) {
-	if list == nil {
-		return nil, false
-	}
-	var writeResultParens bool
-	var result []string
-	for i := 0; i < len(list.List); i++ {
-		if i >= 1 {
-			writeResultParens = true
-		}
-		p := list.List[i]
-		cfg := printer.Config{Mode: printer.UseSpaces | printer.TabIndent, Tabwidth: 4}
-		b := &bytes.Buffer{}
-		if err := cfg.Fprint(b, fset, p.Type); err != nil {
-			event.Error(ctx, "unable to print type", nil, tag.Type.Of(p.Type))
-			continue
-		}
-		typ := replacer.Replace(b.String())
-		if len(p.Names) == 0 {
-			result = append(result, typ)
-		}
-		for _, name := range p.Names {
-			if name.Name != "" {
-				if i == 0 {
-					writeResultParens = true
-				}
-				result = append(result, fmt.Sprintf("%s %s", name.Name, typ))
-			} else {
-				result = append(result, typ)
-			}
-		}
-	}
-	if variadic {
-		result[len(result)-1] = strings.Replace(result[len(result)-1], "[]", "...", 1)
-	}
-	return result, writeResultParens
-}
-
-// FormatTypeParams turns TypeParamList into its Go representation, such as:
-// [T, Y]. Note that it does not print constraints as this is mainly used for
-// formatting type params in method receivers.
-func FormatTypeParams(tparams *typeparams.TypeParamList) string {
-	if tparams == nil || tparams.Len() == 0 {
-		return ""
-	}
-	var buf bytes.Buffer
-	buf.WriteByte('[')
-	for i := 0; i < tparams.Len(); i++ {
-		if i > 0 {
-			buf.WriteString(", ")
-		}
-		buf.WriteString(tparams.At(i).Obj().Name())
-	}
-	buf.WriteByte(']')
-	return buf.String()
-}
-
-// NewSignature returns formatted signature for a types.Signature struct.
-func NewSignature(ctx context.Context, s Snapshot, pkg Package, sig *types.Signature, comment *ast.CommentGroup, qf types.Qualifier) *signature {
-	var tparams []string
-	tpList := typeparams.ForSignature(sig)
-	for i := 0; i < tpList.Len(); i++ {
-		tparam := tpList.At(i)
-		// TODO: is it possible to reuse the logic from FormatVarType here?
-		s := tparam.Obj().Name() + " " + tparam.Constraint().String()
-		tparams = append(tparams, s)
-	}
-
-	params := make([]string, 0, sig.Params().Len())
-	for i := 0; i < sig.Params().Len(); i++ {
-		el := sig.Params().At(i)
-		typ := FormatVarType(pkg, el, qf)
-		p := typ
-		if el.Name() != "" {
-			p = el.Name() + " " + typ
-		}
-		params = append(params, p)
-	}
-
-	var needResultParens bool
-	results := make([]string, 0, sig.Results().Len())
-	for i := 0; i < sig.Results().Len(); i++ {
-		if i >= 1 {
-			needResultParens = true
-		}
-		el := sig.Results().At(i)
-		typ := FormatVarType(pkg, el, qf)
-		if el.Name() == "" {
-			results = append(results, typ)
-		} else {
-			if i == 0 {
-				needResultParens = true
-			}
-			results = append(results, el.Name()+" "+typ)
-		}
-	}
-	var d string
-	if comment != nil {
-		d = comment.Text()
-	}
-	switch s.View().Options().HoverKind {
-	case SynopsisDocumentation:
-		d = doc.Synopsis(d)
-	case NoDocumentation:
-		d = ""
-	}
-	return &signature{
-		doc:              d,
-		typeParams:       tparams,
-		params:           params,
-		results:          results,
-		variadic:         sig.Variadic(),
-		needResultParens: needResultParens,
-	}
-}
-
-// FormatVarType formats a *types.Var, accounting for type aliases.
-// To do this, it looks in the AST of the file in which the object is declared.
-// On any errors, it always falls back to types.TypeString.
-func FormatVarType(srcpkg Package, obj *types.Var, qf types.Qualifier) string {
-	pkg, err := FindPackageFromPos(srcpkg, obj.Pos())
-	if err != nil {
-		return types.TypeString(obj.Type(), qf)
-	}
-
-	_, field := FindDeclAndField(pkg.GetSyntax(), obj.Pos())
-	if field == nil {
-		return types.TypeString(obj.Type(), qf)
-	}
-	expr := field.Type
-
-	// If the given expr refers to a type parameter, then use the
-	// object's Type instead of the type parameter declaration. This helps
-	// format the instantiated type as opposed to the original undeclared
-	// generic type.
-	if typeparams.IsTypeParam(pkg.GetTypesInfo().Types[expr].Type) {
-		return types.TypeString(obj.Type(), qf)
-	}
-
-	// The type names in the AST may not be correctly qualified.
-	// Determine the package name to use based on the package that originated
-	// the query and the package in which the type is declared.
-	// We then qualify the value by cloning the AST node and editing it.
-	clonedInfo := make(map[token.Pos]*types.PkgName)
-	qualified := cloneExpr(expr, pkg.GetTypesInfo(), clonedInfo)
-
-	// If the request came from a different package than the one in which the
-	// types are defined, we may need to modify the qualifiers.
-	qualified = qualifyExpr(qualified, srcpkg, pkg, clonedInfo, qf)
-	fmted := FormatNode(srcpkg.FileSet(), qualified)
-	return fmted
-}
-
-// qualifyExpr applies the "pkgName." prefix to any *ast.Ident in the expr.
-func qualifyExpr(expr ast.Expr, srcpkg, pkg Package, clonedInfo map[token.Pos]*types.PkgName, qf types.Qualifier) ast.Expr {
-	ast.Inspect(expr, func(n ast.Node) bool {
-		switch n := n.(type) {
-		case *ast.ArrayType, *ast.ChanType, *ast.Ellipsis,
-			*ast.FuncType, *ast.MapType, *ast.ParenExpr,
-			*ast.StarExpr, *ast.StructType, *ast.FieldList, *ast.Field:
-			// These are the only types that are cloned by cloneExpr below,
-			// so these are the only types that we can traverse and potentially
-			// modify. This is not an ideal approach, but it works for now.
-
-			// TODO(rFindley): can we eliminate this filtering entirely? This caused
-			// bugs in the past (golang/go#50539)
-			return true
-		case *ast.SelectorExpr:
-			// We may need to change any selectors in which the X is a package
-			// name and the Sel is exported.
-			x, ok := n.X.(*ast.Ident)
-			if !ok {
-				return false
-			}
-			obj, ok := clonedInfo[x.Pos()]
-			if !ok {
-				return false
-			}
-			x.Name = qf(obj.Imported())
-			return false
-		case *ast.Ident:
-			if srcpkg == pkg {
-				return false
-			}
-			// Only add the qualifier if the identifier is exported.
-			if ast.IsExported(n.Name) {
-				pkgName := qf(pkg.GetTypes())
-				n.Name = pkgName + "." + n.Name
-			}
-		}
-		return false
-	})
-	return expr
-}
-
-// cloneExpr only clones expressions that appear in the parameters or return
-// values of a function declaration. The original expression may be returned
-// to the caller in 2 cases:
-//
-//  1. The expression has no pointer fields.
-//  2. The expression cannot appear in an *ast.FuncType, making it
-//     unnecessary to clone.
-//
-// This function also keeps track of selector expressions in which the X is a
-// package name and marks them in a map along with their type information, so
-// that this information can be used when rewriting the expression.
-//
-// NOTE: This function is tailored to the use case of qualifyExpr, and should
-// be used with caution.
-func cloneExpr(expr ast.Expr, info *types.Info, clonedInfo map[token.Pos]*types.PkgName) ast.Expr {
-	switch expr := expr.(type) {
-	case *ast.ArrayType:
-		return &ast.ArrayType{
-			Lbrack: expr.Lbrack,
-			Elt:    cloneExpr(expr.Elt, info, clonedInfo),
-			Len:    expr.Len,
-		}
-	case *ast.ChanType:
-		return &ast.ChanType{
-			Arrow: expr.Arrow,
-			Begin: expr.Begin,
-			Dir:   expr.Dir,
-			Value: cloneExpr(expr.Value, info, clonedInfo),
-		}
-	case *ast.Ellipsis:
-		return &ast.Ellipsis{
-			Ellipsis: expr.Ellipsis,
-			Elt:      cloneExpr(expr.Elt, info, clonedInfo),
-		}
-	case *ast.FuncType:
-		return &ast.FuncType{
-			Func:    expr.Func,
-			Params:  cloneFieldList(expr.Params, info, clonedInfo),
-			Results: cloneFieldList(expr.Results, info, clonedInfo),
-		}
-	case *ast.Ident:
-		return cloneIdent(expr)
-	case *ast.MapType:
-		return &ast.MapType{
-			Map:   expr.Map,
-			Key:   cloneExpr(expr.Key, info, clonedInfo),
-			Value: cloneExpr(expr.Value, info, clonedInfo),
-		}
-	case *ast.ParenExpr:
-		return &ast.ParenExpr{
-			Lparen: expr.Lparen,
-			Rparen: expr.Rparen,
-			X:      cloneExpr(expr.X, info, clonedInfo),
-		}
-	case *ast.SelectorExpr:
-		s := &ast.SelectorExpr{
-			Sel: cloneIdent(expr.Sel),
-			X:   cloneExpr(expr.X, info, clonedInfo),
-		}
-		if x, ok := expr.X.(*ast.Ident); ok && ast.IsExported(expr.Sel.Name) {
-			if obj, ok := info.ObjectOf(x).(*types.PkgName); ok {
-				clonedInfo[s.X.Pos()] = obj
-			}
-		}
-		return s
-	case *ast.StarExpr:
-		return &ast.StarExpr{
-			Star: expr.Star,
-			X:    cloneExpr(expr.X, info, clonedInfo),
-		}
-	case *ast.StructType:
-		return &ast.StructType{
-			Struct:     expr.Struct,
-			Fields:     cloneFieldList(expr.Fields, info, clonedInfo),
-			Incomplete: expr.Incomplete,
-		}
-	default:
-		return expr
-	}
-}
-
-func cloneFieldList(fl *ast.FieldList, info *types.Info, clonedInfo map[token.Pos]*types.PkgName) *ast.FieldList {
-	if fl == nil {
-		return nil
-	}
-	if fl.List == nil {
-		return &ast.FieldList{
-			Closing: fl.Closing,
-			Opening: fl.Opening,
-		}
-	}
-	list := make([]*ast.Field, 0, len(fl.List))
-	for _, f := range fl.List {
-		var names []*ast.Ident
-		for _, n := range f.Names {
-			names = append(names, cloneIdent(n))
-		}
-		list = append(list, &ast.Field{
-			Comment: f.Comment,
-			Doc:     f.Doc,
-			Names:   names,
-			Tag:     f.Tag,
-			Type:    cloneExpr(f.Type, info, clonedInfo),
-		})
-	}
-	return &ast.FieldList{
-		Closing: fl.Closing,
-		Opening: fl.Opening,
-		List:    list,
-	}
-}
-
-func cloneIdent(ident *ast.Ident) *ast.Ident {
-	return &ast.Ident{
-		NamePos: ident.NamePos,
-		Name:    ident.Name,
-		Obj:     ident.Obj,
-	}
-}
diff -urN a/gopls/internal/lsp/source/util.go b/gopls/internal/lsp/source/util.go
--- a/gopls/internal/lsp/source/util.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/util.go	1969-12-31 16:00:00
@@ -1,519 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/ast"
-	"go/printer"
-	"go/token"
-	"go/types"
-	"path/filepath"
-	"regexp"
-	"sort"
-	"strconv"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-// MappedRange provides mapped protocol.Range for a span.Range, accounting for
-// UTF-16 code points.
-//
-// TOOD(adonovan): eliminate this type. Replace all uses by an
-// explicit pair (span.Range, protocol.ColumnMapper), and an operation
-// to map both to a protocol.Range.
-type MappedRange struct {
-	spanRange span.Range             // the range in the compiled source (package.CompiledGoFiles)
-	m         *protocol.ColumnMapper // a mapper of the edited source (package.GoFiles)
-}
-
-// NewMappedRange returns a MappedRange for the given file and
-// start/end positions, which must be valid within m.TokFile.
-func NewMappedRange(m *protocol.ColumnMapper, start, end token.Pos) MappedRange {
-	return MappedRange{
-		spanRange: span.NewRange(m.TokFile, start, end),
-		m:         m,
-	}
-}
-
-// Range returns the LSP range in the edited source.
-//
-// See the documentation of NewMappedRange for information on edited vs
-// compiled source.
-func (s MappedRange) Range() (protocol.Range, error) {
-	if s.m == nil {
-		return protocol.Range{}, bug.Errorf("invalid range")
-	}
-	spn, err := span.FileSpan(s.spanRange.TokFile, s.spanRange.Start, s.spanRange.End)
-	if err != nil {
-		return protocol.Range{}, err
-	}
-	return s.m.Range(spn)
-}
-
-// Span returns the span corresponding to the mapped range in the edited
-// source.
-//
-// See the documentation of NewMappedRange for information on edited vs
-// compiled source.
-func (s MappedRange) Span() (span.Span, error) {
-	// In the past, some code-paths have relied on Span returning an error if s
-	// is the zero value (i.e. s.m is nil). But this should be treated as a bug:
-	// observe that s.URI() would panic in this case.
-	if s.m == nil {
-		return span.Span{}, bug.Errorf("invalid range")
-	}
-	return span.FileSpan(s.spanRange.TokFile, s.spanRange.Start, s.spanRange.End)
-}
-
-// URI returns the URI of the edited file.
-//
-// See the documentation of NewMappedRange for information on edited vs
-// compiled source.
-func (s MappedRange) URI() span.URI {
-	return s.m.URI
-}
-
-func IsGenerated(ctx context.Context, snapshot Snapshot, uri span.URI) bool {
-	fh, err := snapshot.GetFile(ctx, uri)
-	if err != nil {
-		return false
-	}
-	pgf, err := snapshot.ParseGo(ctx, fh, ParseHeader)
-	if err != nil {
-		return false
-	}
-	for _, commentGroup := range pgf.File.Comments {
-		for _, comment := range commentGroup.List {
-			if matched := generatedRx.MatchString(comment.Text); matched {
-				// Check if comment is at the beginning of the line in source.
-				if safetoken.Position(pgf.Tok, comment.Slash).Column == 1 {
-					return true
-				}
-			}
-		}
-	}
-	return false
-}
-
-func objToMappedRange(pkg Package, obj types.Object) (MappedRange, error) {
-	nameLen := len(obj.Name())
-	if pkgName, ok := obj.(*types.PkgName); ok {
-		// An imported Go package has a package-local, unqualified name.
-		// When the name matches the imported package name, there is no
-		// identifier in the import spec with the local package name.
-		//
-		// For example:
-		// 		import "go/ast" 	// name "ast" matches package name
-		// 		import a "go/ast"  	// name "a" does not match package name
-		//
-		// When the identifier does not appear in the source, have the range
-		// of the object be the import path, including quotes.
-		if pkgName.Imported().Name() == pkgName.Name() {
-			nameLen = len(pkgName.Imported().Path()) + len(`""`)
-		}
-	}
-	return posToMappedRange(pkg, obj.Pos(), obj.Pos()+token.Pos(nameLen))
-}
-
-// posToMappedRange returns the MappedRange for the given [start, end) span,
-// which must be among the transitive dependencies of pkg.
-func posToMappedRange(pkg Package, pos, end token.Pos) (MappedRange, error) {
-	if !pos.IsValid() {
-		return MappedRange{}, fmt.Errorf("invalid start position")
-	}
-	if !end.IsValid() {
-		return MappedRange{}, fmt.Errorf("invalid end position")
-	}
-
-	logicalFilename := pkg.FileSet().File(pos).Name() // ignore line directives
-	pgf, _, err := findFileInDeps(pkg, span.URIFromPath(logicalFilename))
-	if err != nil {
-		return MappedRange{}, err
-	}
-	return NewMappedRange(pgf.Mapper, pos, end), nil
-}
-
-// FindPackageFromPos returns the Package for the given position, which must be
-// among the transitive dependencies of pkg.
-//
-// TODO(rfindley): is this the best factoring of this API? This function is
-// really a trivial wrapper around findFileInDeps, which may be a more useful
-// function to expose.
-func FindPackageFromPos(pkg Package, pos token.Pos) (Package, error) {
-	if !pos.IsValid() {
-		return nil, fmt.Errorf("invalid position")
-	}
-	fileName := pkg.FileSet().File(pos).Name()
-	uri := span.URIFromPath(fileName)
-	_, pkg, err := findFileInDeps(pkg, uri)
-	return pkg, err
-}
-
-// Matches cgo generated comment as well as the proposed standard:
-//
-//	https://golang.org/s/generatedcode
-var generatedRx = regexp.MustCompile(`// .*DO NOT EDIT\.?`)
-
-// FileKindForLang returns the file kind associated with the given language ID,
-// or UnknownKind if the language ID is not recognized.
-func FileKindForLang(langID string) FileKind {
-	switch langID {
-	case "go":
-		return Go
-	case "go.mod":
-		return Mod
-	case "go.sum":
-		return Sum
-	case "tmpl", "gotmpl":
-		return Tmpl
-	case "go.work":
-		return Work
-	default:
-		return UnknownKind
-	}
-}
-
-func (k FileKind) String() string {
-	switch k {
-	case Go:
-		return "go"
-	case Mod:
-		return "go.mod"
-	case Sum:
-		return "go.sum"
-	case Tmpl:
-		return "tmpl"
-	case Work:
-		return "go.work"
-	default:
-		return fmt.Sprintf("unk%d", k)
-	}
-}
-
-// nodeAtPos returns the index and the node whose position is contained inside
-// the node list.
-func nodeAtPos(nodes []ast.Node, pos token.Pos) (ast.Node, int) {
-	if nodes == nil {
-		return nil, -1
-	}
-	for i, node := range nodes {
-		if node.Pos() <= pos && pos <= node.End() {
-			return node, i
-		}
-	}
-	return nil, -1
-}
-
-// IsInterface returns if a types.Type is an interface
-func IsInterface(T types.Type) bool {
-	return T != nil && types.IsInterface(T)
-}
-
-// FormatNode returns the "pretty-print" output for an ast node.
-func FormatNode(fset *token.FileSet, n ast.Node) string {
-	var buf strings.Builder
-	if err := printer.Fprint(&buf, fset, n); err != nil {
-		return ""
-	}
-	return buf.String()
-}
-
-// Deref returns a pointer's element type, traversing as many levels as needed.
-// Otherwise it returns typ.
-//
-// It can return a pointer type for cyclic types (see golang/go#45510).
-func Deref(typ types.Type) types.Type {
-	var seen map[types.Type]struct{}
-	for {
-		p, ok := typ.Underlying().(*types.Pointer)
-		if !ok {
-			return typ
-		}
-		if _, ok := seen[p.Elem()]; ok {
-			return typ
-		}
-
-		typ = p.Elem()
-
-		if seen == nil {
-			seen = make(map[types.Type]struct{})
-		}
-		seen[typ] = struct{}{}
-	}
-}
-
-func SortDiagnostics(d []*Diagnostic) {
-	sort.Slice(d, func(i int, j int) bool {
-		return CompareDiagnostic(d[i], d[j]) < 0
-	})
-}
-
-func CompareDiagnostic(a, b *Diagnostic) int {
-	if r := protocol.CompareRange(a.Range, b.Range); r != 0 {
-		return r
-	}
-	if a.Source < b.Source {
-		return -1
-	}
-	if a.Source > b.Source {
-		return +1
-	}
-	if a.Message < b.Message {
-		return -1
-	}
-	if a.Message > b.Message {
-		return +1
-	}
-	return 0
-}
-
-// findFileInDeps finds uri in pkg or its dependencies.
-func findFileInDeps(pkg Package, uri span.URI) (*ParsedGoFile, Package, error) {
-	queue := []Package{pkg}
-	seen := make(map[PackageID]bool)
-
-	for len(queue) > 0 {
-		pkg := queue[0]
-		queue = queue[1:]
-		seen[pkg.ID()] = true
-
-		if pgf, err := pkg.File(uri); err == nil {
-			return pgf, pkg, nil
-		}
-		for _, dep := range pkg.Imports() {
-			if !seen[dep.ID()] {
-				queue = append(queue, dep)
-			}
-		}
-	}
-	return nil, nil, fmt.Errorf("no file for %s in package %s", uri, pkg.ID())
-}
-
-// UnquoteImportPath returns the unquoted import path of s,
-// or "" if the path is not properly quoted.
-func UnquoteImportPath(s *ast.ImportSpec) ImportPath {
-	path, err := strconv.Unquote(s.Path.Value)
-	if err != nil {
-		return ""
-	}
-	return ImportPath(path)
-}
-
-// NodeContains returns true if a node encloses a given position pos.
-func NodeContains(n ast.Node, pos token.Pos) bool {
-	return n != nil && n.Pos() <= pos && pos <= n.End()
-}
-
-// CollectScopes returns all scopes in an ast path, ordered as innermost scope
-// first.
-func CollectScopes(info *types.Info, path []ast.Node, pos token.Pos) []*types.Scope {
-	// scopes[i], where i<len(path), is the possibly nil Scope of path[i].
-	var scopes []*types.Scope
-	for _, n := range path {
-		// Include *FuncType scope if pos is inside the function body.
-		switch node := n.(type) {
-		case *ast.FuncDecl:
-			if node.Body != nil && NodeContains(node.Body, pos) {
-				n = node.Type
-			}
-		case *ast.FuncLit:
-			if node.Body != nil && NodeContains(node.Body, pos) {
-				n = node.Type
-			}
-		}
-		scopes = append(scopes, info.Scopes[n])
-	}
-	return scopes
-}
-
-// Qualifier returns a function that appropriately formats a types.PkgName
-// appearing in a *ast.File.
-func Qualifier(f *ast.File, pkg *types.Package, info *types.Info) types.Qualifier {
-	// Construct mapping of import paths to their defined or implicit names.
-	imports := make(map[*types.Package]string)
-	for _, imp := range f.Imports {
-		var obj types.Object
-		if imp.Name != nil {
-			obj = info.Defs[imp.Name]
-		} else {
-			obj = info.Implicits[imp]
-		}
-		if pkgname, ok := obj.(*types.PkgName); ok {
-			imports[pkgname.Imported()] = pkgname.Name()
-		}
-	}
-	// Define qualifier to replace full package paths with names of the imports.
-	return func(p *types.Package) string {
-		if p == pkg {
-			return ""
-		}
-		if name, ok := imports[p]; ok {
-			if name == "." {
-				return ""
-			}
-			return name
-		}
-		return p.Name()
-	}
-}
-
-// isDirective reports whether c is a comment directive.
-//
-// Copied and adapted from go/src/go/ast/ast.go.
-func isDirective(c string) bool {
-	if len(c) < 3 {
-		return false
-	}
-	if c[1] != '/' {
-		return false
-	}
-	//-style comment (no newline at the end)
-	c = c[2:]
-	if len(c) == 0 {
-		// empty line
-		return false
-	}
-	// "//line " is a line directive.
-	// (The // has been removed.)
-	if strings.HasPrefix(c, "line ") {
-		return true
-	}
-
-	// "//[a-z0-9]+:[a-z0-9]"
-	// (The // has been removed.)
-	colon := strings.Index(c, ":")
-	if colon <= 0 || colon+1 >= len(c) {
-		return false
-	}
-	for i := 0; i <= colon+1; i++ {
-		if i == colon {
-			continue
-		}
-		b := c[i]
-		if !('a' <= b && b <= 'z' || '0' <= b && b <= '9') {
-			return false
-		}
-	}
-	return true
-}
-
-// InDir checks whether path is in the file tree rooted at dir.
-// It checks only the lexical form of the file names.
-// It does not consider symbolic links.
-//
-// Copied from go/src/cmd/go/internal/search/search.go.
-func InDir(dir, path string) bool {
-	pv := strings.ToUpper(filepath.VolumeName(path))
-	dv := strings.ToUpper(filepath.VolumeName(dir))
-	path = path[len(pv):]
-	dir = dir[len(dv):]
-	switch {
-	default:
-		return false
-	case pv != dv:
-		return false
-	case len(path) == len(dir):
-		if path == dir {
-			return true
-		}
-		return false
-	case dir == "":
-		return path != ""
-	case len(path) > len(dir):
-		if dir[len(dir)-1] == filepath.Separator {
-			if path[:len(dir)] == dir {
-				return path[len(dir):] != ""
-			}
-			return false
-		}
-		if path[len(dir)] == filepath.Separator && path[:len(dir)] == dir {
-			if len(path) == len(dir)+1 {
-				return true
-			}
-			return path[len(dir)+1:] != ""
-		}
-		return false
-	}
-}
-
-// IsValidImport returns whether importPkgPath is importable
-// by pkgPath
-func IsValidImport(pkgPath, importPkgPath PackagePath) bool {
-	i := strings.LastIndex(string(importPkgPath), "/internal/")
-	if i == -1 {
-		return true
-	}
-	// TODO(rfindley): this looks wrong: IsCommandLineArguments is meant to
-	// operate on package IDs, not package paths.
-	if IsCommandLineArguments(PackageID(pkgPath)) {
-		return true
-	}
-	// TODO(rfindley): this is wrong. mod.testx/p should not be able to
-	// import mod.test/internal: https://go.dev/play/p/-Ca6P-E4V4q
-	return strings.HasPrefix(string(pkgPath), string(importPkgPath[:i]))
-}
-
-// IsCommandLineArguments reports whether a given value denotes
-// "command-line-arguments" package, which is a package with an unknown ID
-// created by the go command. It can have a test variant, which is why callers
-// should not check that a value equals "command-line-arguments" directly.
-func IsCommandLineArguments(id PackageID) bool {
-	return strings.Contains(string(id), "command-line-arguments")
-}
-
-// RecvIdent returns the type identifier of a method receiver.
-// e.g. A for all of A, *A, A[T], *A[T], etc.
-func RecvIdent(recv *ast.FieldList) *ast.Ident {
-	if recv == nil || len(recv.List) == 0 {
-		return nil
-	}
-	x := recv.List[0].Type
-	if star, ok := x.(*ast.StarExpr); ok {
-		x = star.X
-	}
-	switch ix := x.(type) { // check for instantiated receivers
-	case *ast.IndexExpr:
-		x = ix.X
-	case *typeparams.IndexListExpr:
-		x = ix.X
-	}
-	if ident, ok := x.(*ast.Ident); ok {
-		return ident
-	}
-	return nil
-}
-
-// embeddedIdent returns the type name identifier for an embedding x, if x in a
-// valid embedding. Otherwise, it returns nil.
-//
-// Spec: An embedded field must be specified as a type name T or as a pointer
-// to a non-interface type name *T
-func embeddedIdent(x ast.Expr) *ast.Ident {
-	if star, ok := x.(*ast.StarExpr); ok {
-		x = star.X
-	}
-	switch ix := x.(type) { // check for instantiated receivers
-	case *ast.IndexExpr:
-		x = ix.X
-	case *typeparams.IndexListExpr:
-		x = ix.X
-	}
-	switch x := x.(type) {
-	case *ast.Ident:
-		return x
-	case *ast.SelectorExpr:
-		if _, ok := x.X.(*ast.Ident); ok {
-			return x.Sel
-		}
-	}
-	return nil
-}
diff -urN a/gopls/internal/lsp/source/view.go b/gopls/internal/lsp/source/view.go
--- a/gopls/internal/lsp/source/view.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/view.go	1969-12-31 16:00:00
@@ -1,835 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"bytes"
-	"context"
-	"crypto/sha256"
-	"errors"
-	"fmt"
-	"go/ast"
-	"go/scanner"
-	"go/token"
-	"go/types"
-	"io"
-	"strings"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/module"
-	"golang.org/x/tools/go/analysis"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event/label"
-	"golang.org/x/tools/internal/event/tag"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/imports"
-	"golang.org/x/tools/internal/packagesinternal"
-)
-
-// A GlobalSnapshotID uniquely identifies a snapshot within this process and
-// increases monotonically with snapshot creation time.
-//
-// We use a distinct integral type for global IDs to help enforce correct
-// usage.
-type GlobalSnapshotID uint64
-
-// Snapshot represents the current state for the given view.
-type Snapshot interface {
-	// SequenceID is the sequence id of this snapshot within its containing
-	// view.
-	//
-	// Relative to their view sequence ids are monotonically increasing, but this
-	// does not hold globally: when new views are created their initial snapshot
-	// has sequence ID 0. For operations that span multiple views, use global
-	// IDs.
-	SequenceID() uint64
-
-	// GlobalID is a globally unique identifier for this snapshot. Global IDs are
-	// monotonic: subsequent snapshots will have higher global ID, though
-	// subsequent snapshots in a view may not have adjacent global IDs.
-	GlobalID() GlobalSnapshotID
-
-	// View returns the View associated with this snapshot.
-	View() View
-
-	// BackgroundContext returns a context used for all background processing
-	// on behalf of this snapshot.
-	BackgroundContext() context.Context
-
-	// Fileset returns the Fileset used to parse all the Go files in this snapshot.
-	//
-	// If the files are known to belong to a specific Package, use
-	// Package.FileSet instead. (We plan to eliminate the
-	// Snapshot's cache of parsed files, and thus the need for a
-	// snapshot-wide FileSet.)
-	FileSet() *token.FileSet
-
-	// ValidBuildConfiguration returns true if there is some error in the
-	// user's workspace. In particular, if they are both outside of a module
-	// and their GOPATH.
-	ValidBuildConfiguration() bool
-
-	// FindFile returns the FileHandle for the given URI, if it is already
-	// in the given snapshot.
-	FindFile(uri span.URI) VersionedFileHandle
-
-	// GetVersionedFile returns the VersionedFileHandle for a given URI,
-	// initializing it if it is not already part of the snapshot.
-	GetVersionedFile(ctx context.Context, uri span.URI) (VersionedFileHandle, error)
-
-	// GetFile returns the FileHandle for a given URI, initializing it if it is
-	// not already part of the snapshot.
-	GetFile(ctx context.Context, uri span.URI) (FileHandle, error)
-
-	// AwaitInitialized waits until the snapshot's view is initialized.
-	AwaitInitialized(ctx context.Context)
-
-	// IsOpen returns whether the editor currently has a file open.
-	IsOpen(uri span.URI) bool
-
-	// IgnoredFile reports if a file would be ignored by a `go list` of the whole
-	// workspace.
-	IgnoredFile(uri span.URI) bool
-
-	// Templates returns the .tmpl files
-	Templates() map[span.URI]VersionedFileHandle
-
-	// ParseGo returns the parsed AST for the file.
-	// If the file is not available, returns nil and an error.
-	// Position information is added to FileSet().
-	ParseGo(ctx context.Context, fh FileHandle, mode ParseMode) (*ParsedGoFile, error)
-
-	// Analyze runs the specified analyzers on the given package at this snapshot.
-	Analyze(ctx context.Context, id PackageID, analyzers []*Analyzer) ([]*Diagnostic, error)
-
-	// RunGoCommandPiped runs the given `go` command, writing its output
-	// to stdout and stderr. Verb, Args, and WorkingDir must be specified.
-	//
-	// RunGoCommandPiped runs the command serially using gocommand.RunPiped,
-	// enforcing that this command executes exclusively to other commands on the
-	// server.
-	RunGoCommandPiped(ctx context.Context, mode InvocationFlags, inv *gocommand.Invocation, stdout, stderr io.Writer) error
-
-	// RunGoCommandDirect runs the given `go` command. Verb, Args, and
-	// WorkingDir must be specified.
-	RunGoCommandDirect(ctx context.Context, mode InvocationFlags, inv *gocommand.Invocation) (*bytes.Buffer, error)
-
-	// RunGoCommands runs a series of `go` commands that updates the go.mod
-	// and go.sum file for wd, and returns their updated contents.
-	RunGoCommands(ctx context.Context, allowNetwork bool, wd string, run func(invoke func(...string) (*bytes.Buffer, error)) error) (bool, []byte, []byte, error)
-
-	// RunProcessEnvFunc runs fn with the process env for this snapshot's view.
-	// Note: the process env contains cached module and filesystem state.
-	RunProcessEnvFunc(ctx context.Context, fn func(*imports.Options) error) error
-
-	// ModFiles are the go.mod files enclosed in the snapshot's view and known
-	// to the snapshot.
-	ModFiles() []span.URI
-
-	// ParseMod is used to parse go.mod files.
-	ParseMod(ctx context.Context, fh FileHandle) (*ParsedModule, error)
-
-	// ModWhy returns the results of `go mod why` for the module specified by
-	// the given go.mod file.
-	ModWhy(ctx context.Context, fh FileHandle) (map[string]string, error)
-
-	// ModTidy returns the results of `go mod tidy` for the module specified by
-	// the given go.mod file.
-	ModTidy(ctx context.Context, pm *ParsedModule) (*TidiedModule, error)
-
-	// ModVuln returns import vulnerability analysis for the given go.mod URI.
-	// Concurrent requests are combined into a single command.
-	ModVuln(ctx context.Context, modURI span.URI) (*govulncheck.Result, error)
-
-	// GoModForFile returns the URI of the go.mod file for the given URI.
-	GoModForFile(uri span.URI) span.URI
-
-	// WorkFile, if non-empty, is the go.work file for the workspace.
-	WorkFile() span.URI
-
-	// ParseWork is used to parse go.work files.
-	ParseWork(ctx context.Context, fh FileHandle) (*ParsedWorkFile, error)
-
-	// BuiltinFile returns information about the special builtin package.
-	BuiltinFile(ctx context.Context) (*ParsedGoFile, error)
-
-	// IsBuiltin reports whether uri is part of the builtin package.
-	IsBuiltin(ctx context.Context, uri span.URI) bool
-
-	// ReverseDependencies returns a new mapping whose entries are
-	// the ID and Metadata of each package in the workspace that
-	// directly or transitively depend on the package denoted by id,
-	// excluding id itself.
-	ReverseDependencies(ctx context.Context, id PackageID, transitive bool) (map[PackageID]*Metadata, error)
-
-	// CachedImportPaths returns all the imported packages loaded in this
-	// snapshot, indexed by their package path (not import path, despite the name)
-	// and checked in TypecheckWorkspace mode.
-	//
-	// To reduce latency, it does not wait for type-checking to complete.
-	// It is intended for use only in completions.
-	CachedImportPaths(ctx context.Context) (map[PackagePath]Package, error)
-
-	// ActiveMetadata returns a new, unordered slice containing
-	// metadata for all packages considered 'active' in the workspace.
-	//
-	// In normal memory mode, this is all workspace packages. In degraded memory
-	// mode, this is just the reverse transitive closure of open packages.
-	ActiveMetadata(ctx context.Context) ([]*Metadata, error)
-
-	// AllMetadata returns a new unordered array of metadata for all packages in the workspace.
-	AllMetadata(ctx context.Context) ([]*Metadata, error)
-
-	// Symbols returns all symbols in the snapshot.
-	Symbols(ctx context.Context) map[span.URI][]Symbol
-
-	// Metadata returns the metadata for the specified package,
-	// or nil if it was not found.
-	Metadata(id PackageID) *Metadata
-
-	// MetadataForFile returns a new slice containing metadata for each
-	// package containing the Go file identified by uri, ordered by the
-	// number of CompiledGoFiles (i.e. "narrowest" to "widest" package).
-	// The result may include tests and intermediate test variants of
-	// importable packages.
-	// It returns an error if the context was cancelled.
-	MetadataForFile(ctx context.Context, uri span.URI) ([]*Metadata, error)
-
-	// TypeCheck parses and type-checks the specified packages,
-	// and returns them in the same order as the ids.
-	TypeCheck(ctx context.Context, mode TypecheckMode, ids ...PackageID) ([]Package, error)
-
-	// GetCriticalError returns any critical errors in the workspace.
-	//
-	// A nil result may mean success, or context cancellation.
-	GetCriticalError(ctx context.Context) *CriticalError
-
-	// BuildGoplsMod generates a go.mod file for all modules in the workspace.
-	// It bypasses any existing gopls.mod.
-	BuildGoplsMod(ctx context.Context) (*modfile.File, error)
-}
-
-// SnapshotLabels returns a new slice of labels that should be used for events
-// related to a snapshot.
-func SnapshotLabels(snapshot Snapshot) []label.Label {
-	return []label.Label{tag.Snapshot.Of(snapshot.SequenceID()), tag.Directory.Of(snapshot.View().Folder())}
-}
-
-// PackageForFile is a convenience function that selects a package to
-// which this file belongs (narrowest or widest), type-checks it in
-// the requested mode (full or workspace), and returns it, along with
-// the parse tree of that file.
-//
-// Type-checking is expensive. Call snapshot.ParseGo if all you need
-// is a parse tree, or snapshot.MetadataForFile if you only need metadata.
-func PackageForFile(ctx context.Context, snapshot Snapshot, uri span.URI, mode TypecheckMode, pkgSel PackageSelector) (Package, *ParsedGoFile, error) {
-	metas, err := snapshot.MetadataForFile(ctx, uri)
-	if err != nil {
-		return nil, nil, err
-	}
-	if len(metas) == 0 {
-		return nil, nil, fmt.Errorf("no package metadata for file %s", uri)
-	}
-	switch pkgSel {
-	case NarrowestPackage:
-		metas = metas[:1]
-	case WidestPackage:
-		metas = metas[len(metas)-1:]
-	}
-	pkgs, err := snapshot.TypeCheck(ctx, mode, metas[0].ID)
-	if err != nil {
-		return nil, nil, err
-	}
-	pkg := pkgs[0]
-	pgf, err := pkg.File(uri)
-	if err != nil {
-		return nil, nil, err // "can't happen"
-	}
-	return pkg, pgf, err
-}
-
-// PackageSelector sets how a package is selected out from a set of packages
-// containing a given file.
-type PackageSelector int
-
-const (
-	// NarrowestPackage picks the "narrowest" package for a given file.
-	// By "narrowest" package, we mean the package with the fewest number of
-	// files that includes the given file. This solves the problem of test
-	// variants, as the test will have more files than the non-test package.
-	NarrowestPackage PackageSelector = iota
-
-	// WidestPackage returns the Package containing the most files.
-	// This is useful for something like diagnostics, where we'd prefer to
-	// offer diagnostics for as many files as possible.
-	WidestPackage
-)
-
-// InvocationFlags represents the settings of a particular go command invocation.
-// It is a mode, plus a set of flag bits.
-type InvocationFlags int
-
-const (
-	// Normal is appropriate for commands that might be run by a user and don't
-	// deliberately modify go.mod files, e.g. `go test`.
-	Normal InvocationFlags = iota
-	// WriteTemporaryModFile is for commands that need information from a
-	// modified version of the user's go.mod file, e.g. `go mod tidy` used to
-	// generate diagnostics.
-	WriteTemporaryModFile
-	// LoadWorkspace is for packages.Load, and other operations that should
-	// consider the whole workspace at once.
-	LoadWorkspace
-
-	// AllowNetwork is a flag bit that indicates the invocation should be
-	// allowed to access the network.
-	AllowNetwork InvocationFlags = 1 << 10
-)
-
-func (m InvocationFlags) Mode() InvocationFlags {
-	return m & (AllowNetwork - 1)
-}
-
-func (m InvocationFlags) AllowNetwork() bool {
-	return m&AllowNetwork != 0
-}
-
-// View represents a single workspace.
-// This is the level at which we maintain configuration like working directory
-// and build tags.
-type View interface {
-	// Name returns the name this view was constructed with.
-	Name() string
-
-	// Folder returns the folder with which this view was created.
-	Folder() span.URI
-
-	// Options returns a copy of the Options for this view.
-	Options() *Options
-
-	// Snapshot returns the current snapshot for the view, and a
-	// release function that must be called when the Snapshot is
-	// no longer needed.
-	Snapshot(ctx context.Context) (Snapshot, func())
-
-	// IsGoPrivatePath reports whether target is a private import path, as identified
-	// by the GOPRIVATE environment variable.
-	IsGoPrivatePath(path string) bool
-
-	// ModuleUpgrades returns known module upgrades for the dependencies of
-	// modfile.
-	ModuleUpgrades(modfile span.URI) map[string]string
-
-	// RegisterModuleUpgrades registers that upgrades exist for the given modules
-	// required by modfile.
-	RegisterModuleUpgrades(modfile span.URI, upgrades map[string]string)
-
-	// ClearModuleUpgrades clears all upgrades for the modules in modfile.
-	ClearModuleUpgrades(modfile span.URI)
-
-	// Vulnerabilites returns known vulnerabilities for the given modfile.
-	// TODO(suzmue): replace command.Vuln with a different type, maybe
-	// https://pkg.go.dev/golang.org/x/vuln/cmd/govulncheck/govulnchecklib#Summary?
-	Vulnerabilities(modfile ...span.URI) map[span.URI]*govulncheck.Result
-
-	// SetVulnerabilities resets the list of vulnerabilites that exists for the given modules
-	// required by modfile.
-	SetVulnerabilities(modfile span.URI, vulncheckResult *govulncheck.Result)
-
-	// FileKind returns the type of a file.
-	//
-	// We can't reliably deduce the kind from the file name alone,
-	// as some editors can be told to interpret a buffer as
-	// language different from the file name heuristic, e.g. that
-	// an .html file actually contains Go "html/template" syntax,
-	// or even that a .go file contains Python.
-	FileKind(FileHandle) FileKind
-
-	// GoVersion returns the configured Go version for this view.
-	GoVersion() int
-
-	// GoVersionString returns the go version string configured for this view.
-	// Unlike [GoVersion], this encodes the minor version and commit hash information.
-	GoVersionString() string
-}
-
-// A FileSource maps uris to FileHandles. This abstraction exists both for
-// testability, and so that algorithms can be run equally on session and
-// snapshot files.
-type FileSource interface {
-	// GetFile returns the FileHandle for a given URI.
-	GetFile(ctx context.Context, uri span.URI) (FileHandle, error)
-}
-
-// A ParsedGoFile contains the results of parsing a Go file.
-type ParsedGoFile struct {
-	URI  span.URI
-	Mode ParseMode
-	File *ast.File
-	Tok  *token.File
-	// Source code used to build the AST. It may be different from the
-	// actual content of the file if we have fixed the AST.
-	Src      []byte
-	Fixed    bool
-	Mapper   *protocol.ColumnMapper
-	ParseErr scanner.ErrorList
-}
-
-// A ParsedModule contains the results of parsing a go.mod file.
-type ParsedModule struct {
-	URI         span.URI
-	File        *modfile.File
-	Mapper      *protocol.ColumnMapper
-	ParseErrors []*Diagnostic
-}
-
-// A ParsedWorkFile contains the results of parsing a go.work file.
-type ParsedWorkFile struct {
-	URI         span.URI
-	File        *modfile.WorkFile
-	Mapper      *protocol.ColumnMapper
-	ParseErrors []*Diagnostic
-}
-
-// A TidiedModule contains the results of running `go mod tidy` on a module.
-type TidiedModule struct {
-	// Diagnostics representing changes made by `go mod tidy`.
-	Diagnostics []*Diagnostic
-	// The bytes of the go.mod file after it was tidied.
-	TidiedContent []byte
-}
-
-// Metadata represents package metadata retrieved from go/packages.
-type Metadata struct {
-	ID              PackageID
-	PkgPath         PackagePath
-	Name            PackageName
-	GoFiles         []span.URI
-	CompiledGoFiles []span.URI
-	ForTest         PackagePath // package path under test, or ""
-	TypesSizes      types.Sizes
-	Errors          []packages.Error
-	DepsByImpPath   map[ImportPath]PackageID  // may contain dups; empty ID => missing
-	DepsByPkgPath   map[PackagePath]PackageID // values are unique and non-empty
-	Module          *packages.Module
-	DepsErrors      []*packagesinternal.PackageError
-
-	// Config is the *packages.Config associated with the loaded package.
-	Config *packages.Config
-}
-
-// IsIntermediateTestVariant reports whether the given package is an
-// intermediate test variant, e.g. "net/http [net/url.test]".
-//
-// Such test variants arise when an x_test package (in this case net/url_test)
-// imports a package (in this case net/http) that itself imports the the
-// non-x_test package (in this case net/url).
-//
-// This is done so that the forward transitive closure of net/url_test has
-// only one package for the "net/url" import.
-// The intermediate test variant exists to hold the test variant import:
-//
-// net/url_test [net/url.test]
-//
-//	| "net/http" -> net/http [net/url.test]
-//	| "net/url" -> net/url [net/url.test]
-//	| ...
-//
-// net/http [net/url.test]
-//
-//	| "net/url" -> net/url [net/url.test]
-//	| ...
-//
-// This restriction propagates throughout the import graph of net/http: for
-// every package imported by net/http that imports net/url, there must be an
-// intermediate test variant that instead imports "net/url [net/url.test]".
-//
-// As one can see from the example of net/url and net/http, intermediate test
-// variants can result in many additional packages that are essentially (but
-// not quite) identical. For this reason, we filter these variants wherever
-// possible.
-func (m *Metadata) IsIntermediateTestVariant() bool {
-	return m.ForTest != "" && m.ForTest != m.PkgPath && m.ForTest+"_test" != m.PkgPath
-}
-
-// RemoveIntermediateTestVariants removes intermediate test variants, modifying the array.
-func RemoveIntermediateTestVariants(metas []*Metadata) []*Metadata {
-	res := metas[:0]
-	for _, m := range metas {
-		if !m.IsIntermediateTestVariant() {
-			res = append(res, m)
-		}
-	}
-	return res
-}
-
-var ErrViewExists = errors.New("view already exists for session")
-
-// Overlay is the type for a file held in memory on a session.
-type Overlay interface {
-	Kind() FileKind
-	VersionedFileHandle
-}
-
-// FileModification represents a modification to a file.
-type FileModification struct {
-	URI    span.URI
-	Action FileAction
-
-	// OnDisk is true if a watched file is changed on disk.
-	// If true, Version will be -1 and Text will be nil.
-	OnDisk bool
-
-	// Version will be -1 and Text will be nil when they are not supplied,
-	// specifically on textDocument/didClose and for on-disk changes.
-	Version int32
-	Text    []byte
-
-	// LanguageID is only sent from the language client on textDocument/didOpen.
-	LanguageID string
-}
-
-type FileAction int
-
-const (
-	UnknownFileAction = FileAction(iota)
-	Open
-	Change
-	Close
-	Save
-	Create
-	Delete
-	InvalidateMetadata
-)
-
-func (a FileAction) String() string {
-	switch a {
-	case Open:
-		return "Open"
-	case Change:
-		return "Change"
-	case Close:
-		return "Close"
-	case Save:
-		return "Save"
-	case Create:
-		return "Create"
-	case Delete:
-		return "Delete"
-	case InvalidateMetadata:
-		return "InvalidateMetadata"
-	default:
-		return "Unknown"
-	}
-}
-
-var ErrTmpModfileUnsupported = errors.New("-modfile is unsupported for this Go version")
-var ErrNoModOnDisk = errors.New("go.mod file is not on disk")
-
-func IsNonFatalGoModError(err error) bool {
-	return err == ErrTmpModfileUnsupported || err == ErrNoModOnDisk
-}
-
-// ParseMode controls the content of the AST produced when parsing a source file.
-type ParseMode int
-
-const (
-	// ParseHeader specifies that the main package declaration and imports are needed.
-	// This is the mode used when attempting to examine the package graph structure.
-	ParseHeader ParseMode = iota
-
-	// ParseExported specifies that the package is used only as a dependency,
-	// and only its exported declarations are needed. More may be included if
-	// necessary to avoid type errors.
-	ParseExported
-
-	// ParseFull specifies the full AST is needed.
-	// This is used for files of direct interest where the entire contents must
-	// be considered.
-	ParseFull
-)
-
-// AllParseModes contains all possible values of ParseMode.
-// It is used for cache invalidation on a file content change.
-var AllParseModes = []ParseMode{ParseHeader, ParseExported, ParseFull}
-
-// TypecheckMode controls what kind of parsing should be done (see ParseMode)
-// while type checking a package.
-type TypecheckMode int
-
-const (
-	// TypecheckFull means to use ParseFull.
-	TypecheckFull TypecheckMode = iota
-	// TypecheckWorkspace means to use ParseFull for workspace packages, and
-	// ParseExported for others.
-	TypecheckWorkspace
-)
-
-type VersionedFileHandle interface {
-	FileHandle
-	Version() int32
-	Session() string
-
-	// LSPIdentity returns the version identity of a file.
-	VersionedFileIdentity() VersionedFileIdentity
-}
-
-type VersionedFileIdentity struct {
-	URI span.URI
-
-	// SessionID is the ID of the LSP session.
-	SessionID string
-
-	// Version is the version of the file, as specified by the client. It should
-	// only be set in combination with SessionID.
-	Version int32
-}
-
-// FileHandle represents a handle to a specific version of a single file.
-type FileHandle interface {
-	URI() span.URI
-
-	// FileIdentity returns a FileIdentity for the file, even if there was an
-	// error reading it.
-	FileIdentity() FileIdentity
-	// Read reads the contents of a file.
-	// If the file is not available, returns a nil slice and an error.
-	Read() ([]byte, error)
-	// Saved reports whether the file has the same content on disk.
-	Saved() bool
-}
-
-// A Hash is a cryptographic digest of the contents of a file.
-// (Although at 32B it is larger than a 16B string header, it is smaller
-// and has better locality than the string header + 64B of hex digits.)
-type Hash [sha256.Size]byte
-
-// HashOf returns the hash of some data.
-func HashOf(data []byte) Hash {
-	return Hash(sha256.Sum256(data))
-}
-
-// Hashf returns the hash of a printf-formatted string.
-func Hashf(format string, args ...interface{}) Hash {
-	// Although this looks alloc-heavy, it is faster than using
-	// Fprintf on sha256.New() because the allocations don't escape.
-	return HashOf([]byte(fmt.Sprintf(format, args...)))
-}
-
-// String returns the digest as a string of hex digits.
-func (h Hash) String() string {
-	return fmt.Sprintf("%64x", [sha256.Size]byte(h))
-}
-
-// Less returns true if the given hash is less than the other.
-func (h Hash) Less(other Hash) bool {
-	return bytes.Compare(h[:], other[:]) < 0
-}
-
-// XORWith updates *h to *h XOR h2.
-func (h *Hash) XORWith(h2 Hash) {
-	// Small enough that we don't need crypto/subtle.XORBytes.
-	for i := range h {
-		h[i] ^= h2[i]
-	}
-}
-
-// FileIdentity uniquely identifies a file at a version from a FileSystem.
-type FileIdentity struct {
-	URI  span.URI
-	Hash Hash // digest of file contents
-}
-
-func (id FileIdentity) String() string {
-	return fmt.Sprintf("%s%s", id.URI, id.Hash)
-}
-
-// FileKind describes the kind of the file in question.
-// It can be one of Go,mod, Sum, or Tmpl.
-type FileKind int
-
-const (
-	// UnknownKind is a file type we don't know about.
-	UnknownKind = FileKind(iota)
-
-	// Go is a normal go source file.
-	Go
-	// Mod is a go.mod file.
-	Mod
-	// Sum is a go.sum file.
-	Sum
-	// Tmpl is a template file.
-	Tmpl
-	// Work is a go.work file.
-	Work
-)
-
-// Analyzer represents a go/analysis analyzer with some boolean properties
-// that let the user know how to use the analyzer.
-type Analyzer struct {
-	Analyzer *analysis.Analyzer
-
-	// Enabled reports whether the analyzer is enabled. This value can be
-	// configured per-analysis in user settings. For staticcheck analyzers,
-	// the value of the Staticcheck setting overrides this field.
-	//
-	// Most clients should use the IsEnabled method.
-	Enabled bool
-
-	// Fix is the name of the suggested fix name used to invoke the suggested
-	// fixes for the analyzer. It is non-empty if we expect this analyzer to
-	// provide its fix separately from its diagnostics. That is, we should apply
-	// the analyzer's suggested fixes through a Command, not a TextEdit.
-	Fix string
-
-	// ActionKind is the kind of code action this analyzer produces. If
-	// unspecified the type defaults to quickfix.
-	ActionKind []protocol.CodeActionKind
-
-	// Severity is the severity set for diagnostics reported by this
-	// analyzer. If left unset it defaults to Warning.
-	Severity protocol.DiagnosticSeverity
-}
-
-func (a *Analyzer) String() string { return a.Analyzer.String() }
-
-// IsEnabled reports whether this analyzer is enabled by the given options.
-func (a Analyzer) IsEnabled(options *Options) bool {
-	// Staticcheck analyzers can only be enabled when staticcheck is on.
-	if _, ok := options.StaticcheckAnalyzers[a.Analyzer.Name]; ok {
-		if !options.Staticcheck {
-			return false
-		}
-	}
-	if enabled, ok := options.Analyses[a.Analyzer.Name]; ok {
-		return enabled
-	}
-	return a.Enabled
-}
-
-// Declare explicit types for package paths, names, and IDs to ensure that we
-// never use an ID where a path belongs, and vice versa. If we confused these,
-// it would result in confusing errors because package IDs often look like
-// package paths.
-type (
-	PackageID   string // go list's unique identifier for a package (e.g. "vendor/example.com/foo [vendor/example.com/bar.test]")
-	PackagePath string // name used to prefix linker symbols (e.g. "vendor/example.com/foo")
-	PackageName string // identifier in 'package' declaration (e.g. "foo")
-	ImportPath  string // path that appears in an import declaration (e.g. "example.com/foo")
-)
-
-// Package represents a Go package that has been parsed and type-checked.
-// It maintains only the relevant fields of a *go/packages.Package.
-type Package interface {
-	// Metadata:
-	ID() PackageID
-	Name() PackageName
-	PkgPath() PackagePath
-	GetTypesSizes() types.Sizes
-	ForTest() string
-	Version() *module.Version // may differ from Metadata.Module.Version
-
-	// Results of parsing:
-	FileSet() *token.FileSet
-	ParseMode() ParseMode
-	CompiledGoFiles() []*ParsedGoFile // (borrowed)
-	File(uri span.URI) (*ParsedGoFile, error)
-	GetSyntax() []*ast.File // (borrowed)
-	HasListOrParseErrors() bool
-
-	// Results of type checking:
-	GetTypes() *types.Package
-	GetTypesInfo() *types.Info
-	DirectDep(path PackagePath) (Package, error)
-	ResolveImportPath(path ImportPath) (Package, error)
-	Imports() []Package // new slice of all direct dependencies, unordered
-	HasTypeErrors() bool
-	DiagnosticsForFile(uri span.URI) []*Diagnostic // new array of list/parse/type errors
-}
-
-// A CriticalError is a workspace-wide error that generally prevents gopls from
-// functioning correctly. In the presence of critical errors, other diagnostics
-// in the workspace may not make sense.
-type CriticalError struct {
-	// MainError is the primary error. Must be non-nil.
-	MainError error
-
-	// Diagnostics contains any supplemental (structured) diagnostics.
-	Diagnostics []*Diagnostic
-}
-
-// An Diagnostic corresponds to an LSP Diagnostic.
-// https://microsoft.github.io/language-server-protocol/specification#diagnostic
-type Diagnostic struct {
-	URI      span.URI
-	Range    protocol.Range
-	Severity protocol.DiagnosticSeverity
-	Code     string
-	CodeHref string
-
-	// Source is a human-readable description of the source of the error.
-	// Diagnostics generated by an analysis.Analyzer set it to Analyzer.Name.
-	Source DiagnosticSource
-
-	Message string
-
-	Tags    []protocol.DiagnosticTag
-	Related []RelatedInformation
-
-	// Fields below are used internally to generate quick fixes. They aren't
-	// part of the LSP spec and don't leave the server.
-	SuggestedFixes []SuggestedFix
-}
-
-func (d *Diagnostic) String() string {
-	return fmt.Sprintf("%v: %s", d.Range, d.Message)
-}
-
-type DiagnosticSource string
-
-const (
-	UnknownError             DiagnosticSource = "<Unknown source>"
-	ListError                DiagnosticSource = "go list"
-	ParseError               DiagnosticSource = "syntax"
-	TypeError                DiagnosticSource = "compiler"
-	ModTidyError             DiagnosticSource = "go mod tidy"
-	OptimizationDetailsError DiagnosticSource = "optimizer details"
-	UpgradeNotification      DiagnosticSource = "upgrade available"
-	Vulncheck                DiagnosticSource = "govulncheck"
-	TemplateError            DiagnosticSource = "template"
-	WorkFileError            DiagnosticSource = "go.work file"
-)
-
-func AnalyzerErrorKind(name string) DiagnosticSource {
-	return DiagnosticSource(name)
-}
-
-// WorkspaceModuleVersion is the nonexistent pseudoversion suffix used in the
-// construction of the workspace module. It is exported so that we can make
-// sure not to show this version to end users in error messages, to avoid
-// confusion.
-// The major version is not included, as that depends on the module path.
-//
-// If workspace module A is dependent on workspace module B, we need our
-// nonexistent version to be greater than the version A mentions.
-// Otherwise, the go command will try to update to that version. Use a very
-// high minor version to make that more likely.
-const workspaceModuleVersion = ".9999999.0-goplsworkspace"
-
-func IsWorkspaceModuleVersion(version string) bool {
-	return strings.HasSuffix(version, workspaceModuleVersion)
-}
-
-func WorkspaceModuleVersion(majorVersion string) string {
-	// Use the highest compatible major version to avoid unwanted upgrades.
-	// See the comment on workspaceModuleVersion.
-	if majorVersion == "v0" {
-		majorVersion = "v1"
-	}
-	return majorVersion + workspaceModuleVersion
-}
diff -urN a/gopls/internal/lsp/source/workspace_symbol.go b/gopls/internal/lsp/source/workspace_symbol.go
--- a/gopls/internal/lsp/source/workspace_symbol.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/workspace_symbol.go	1969-12-31 16:00:00
@@ -1,626 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"context"
-	"fmt"
-	"go/types"
-	"path"
-	"path/filepath"
-	"regexp"
-	"runtime"
-	"sort"
-	"strings"
-	"unicode"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/fuzzy"
-)
-
-// Symbol holds a precomputed symbol value. Note: we avoid using the
-// protocol.SymbolInformation struct here in order to reduce the size of each
-// symbol.
-type Symbol struct {
-	Name  string
-	Kind  protocol.SymbolKind
-	Range protocol.Range
-}
-
-// maxSymbols defines the maximum number of symbol results that should ever be
-// sent in response to a client.
-const maxSymbols = 100
-
-// WorkspaceSymbols matches symbols across all views using the given query,
-// according to the match semantics parameterized by matcherType and style.
-//
-// The workspace symbol method is defined in the spec as follows:
-//
-//	The workspace symbol request is sent from the client to the server to
-//	list project-wide symbols matching the query string.
-//
-// It is unclear what "project-wide" means here, but given the parameters of
-// workspace/symbol do not include any workspace identifier, then it has to be
-// assumed that "project-wide" means "across all workspaces".  Hence why
-// WorkspaceSymbols receives the views []View.
-//
-// However, it then becomes unclear what it would mean to call WorkspaceSymbols
-// with a different configured SymbolMatcher per View. Therefore we assume that
-// Session level configuration will define the SymbolMatcher to be used for the
-// WorkspaceSymbols method.
-func WorkspaceSymbols(ctx context.Context, matcher SymbolMatcher, style SymbolStyle, views []View, query string) ([]protocol.SymbolInformation, error) {
-	ctx, done := event.Start(ctx, "source.WorkspaceSymbols")
-	defer done()
-	if query == "" {
-		return nil, nil
-	}
-
-	var s symbolizer
-	switch style {
-	case DynamicSymbols:
-		s = dynamicSymbolMatch
-	case FullyQualifiedSymbols:
-		s = fullyQualifiedSymbolMatch
-	case PackageQualifiedSymbols:
-		s = packageSymbolMatch
-	default:
-		panic(fmt.Errorf("unknown symbol style: %v", style))
-	}
-
-	return collectSymbols(ctx, views, matcher, s, query)
-}
-
-// A matcherFunc returns the index and score of a symbol match.
-//
-// See the comment for symbolCollector for more information.
-type matcherFunc func(chunks []string) (int, float64)
-
-// A symbolizer returns the best symbol match for a name with pkg, according to
-// some heuristic. The symbol name is passed as the slice nameParts of logical
-// name pieces. For example, for myType.field the caller can pass either
-// []string{"myType.field"} or []string{"myType.", "field"}.
-//
-// See the comment for symbolCollector for more information.
-//
-// The space argument is an empty slice with spare capacity that may be used
-// to allocate the result.
-type symbolizer func(space []string, name string, pkg *Metadata, m matcherFunc) ([]string, float64)
-
-func fullyQualifiedSymbolMatch(space []string, name string, pkg *Metadata, matcher matcherFunc) ([]string, float64) {
-	if _, score := dynamicSymbolMatch(space, name, pkg, matcher); score > 0 {
-		return append(space, string(pkg.PkgPath), ".", name), score
-	}
-	return nil, 0
-}
-
-func dynamicSymbolMatch(space []string, name string, pkg *Metadata, matcher matcherFunc) ([]string, float64) {
-	if IsCommandLineArguments(pkg.ID) {
-		// command-line-arguments packages have a non-sensical package path, so
-		// just use their package name.
-		return packageSymbolMatch(space, name, pkg, matcher)
-	}
-
-	var score float64
-
-	endsInPkgName := strings.HasSuffix(string(pkg.PkgPath), string(pkg.Name))
-
-	// If the package path does not end in the package name, we need to check the
-	// package-qualified symbol as an extra pass first.
-	if !endsInPkgName {
-		pkgQualified := append(space, string(pkg.Name), ".", name)
-		idx, score := matcher(pkgQualified)
-		nameStart := len(pkg.Name) + 1
-		if score > 0 {
-			// If our match is contained entirely within the unqualified portion,
-			// just return that.
-			if idx >= nameStart {
-				return append(space, name), score
-			}
-			// Lower the score for matches that include the package name.
-			return pkgQualified, score * 0.8
-		}
-	}
-
-	// Now try matching the fully qualified symbol.
-	fullyQualified := append(space, string(pkg.PkgPath), ".", name)
-	idx, score := matcher(fullyQualified)
-
-	// As above, check if we matched just the unqualified symbol name.
-	nameStart := len(pkg.PkgPath) + 1
-	if idx >= nameStart {
-		return append(space, name), score
-	}
-
-	// If our package path ends in the package name, we'll have skipped the
-	// initial pass above, so check if we matched just the package-qualified
-	// name.
-	if endsInPkgName && idx >= 0 {
-		pkgStart := len(pkg.PkgPath) - len(pkg.Name)
-		if idx >= pkgStart {
-			return append(space, string(pkg.Name), ".", name), score
-		}
-	}
-
-	// Our match was not contained within the unqualified or package qualified
-	// symbol. Return the fully qualified symbol but discount the score.
-	return fullyQualified, score * 0.6
-}
-
-func packageSymbolMatch(space []string, name string, pkg *Metadata, matcher matcherFunc) ([]string, float64) {
-	qualified := append(space, string(pkg.Name), ".", name)
-	if _, s := matcher(qualified); s > 0 {
-		return qualified, s
-	}
-	return nil, 0
-}
-
-func buildMatcher(matcher SymbolMatcher, query string) matcherFunc {
-	switch matcher {
-	case SymbolFuzzy:
-		return parseQuery(query, newFuzzyMatcher)
-	case SymbolFastFuzzy:
-		return parseQuery(query, func(query string) matcherFunc {
-			return fuzzy.NewSymbolMatcher(query).Match
-		})
-	case SymbolCaseSensitive:
-		return matchExact(query)
-	case SymbolCaseInsensitive:
-		q := strings.ToLower(query)
-		exact := matchExact(q)
-		wrapper := []string{""}
-		return func(chunks []string) (int, float64) {
-			s := strings.Join(chunks, "")
-			wrapper[0] = strings.ToLower(s)
-			return exact(wrapper)
-		}
-	}
-	panic(fmt.Errorf("unknown symbol matcher: %v", matcher))
-}
-
-func newFuzzyMatcher(query string) matcherFunc {
-	fm := fuzzy.NewMatcher(query)
-	return func(chunks []string) (int, float64) {
-		score := float64(fm.ScoreChunks(chunks))
-		ranges := fm.MatchedRanges()
-		if len(ranges) > 0 {
-			return ranges[0], score
-		}
-		return -1, score
-	}
-}
-
-// parseQuery parses a field-separated symbol query, extracting the special
-// characters listed below, and returns a matcherFunc corresponding to the AND
-// of all field queries.
-//
-// Special characters:
-//
-//	^  match exact prefix
-//	$  match exact suffix
-//	'  match exact
-//
-// In all three of these special queries, matches are 'smart-cased', meaning
-// they are case sensitive if the symbol query contains any upper-case
-// characters, and case insensitive otherwise.
-func parseQuery(q string, newMatcher func(string) matcherFunc) matcherFunc {
-	fields := strings.Fields(q)
-	if len(fields) == 0 {
-		return func([]string) (int, float64) { return -1, 0 }
-	}
-	var funcs []matcherFunc
-	for _, field := range fields {
-		var f matcherFunc
-		switch {
-		case strings.HasPrefix(field, "^"):
-			prefix := field[1:]
-			f = smartCase(prefix, func(chunks []string) (int, float64) {
-				s := strings.Join(chunks, "")
-				if strings.HasPrefix(s, prefix) {
-					return 0, 1
-				}
-				return -1, 0
-			})
-		case strings.HasPrefix(field, "'"):
-			exact := field[1:]
-			f = smartCase(exact, matchExact(exact))
-		case strings.HasSuffix(field, "$"):
-			suffix := field[0 : len(field)-1]
-			f = smartCase(suffix, func(chunks []string) (int, float64) {
-				s := strings.Join(chunks, "")
-				if strings.HasSuffix(s, suffix) {
-					return len(s) - len(suffix), 1
-				}
-				return -1, 0
-			})
-		default:
-			f = newMatcher(field)
-		}
-		funcs = append(funcs, f)
-	}
-	if len(funcs) == 1 {
-		return funcs[0]
-	}
-	return comboMatcher(funcs).match
-}
-
-func matchExact(exact string) matcherFunc {
-	return func(chunks []string) (int, float64) {
-		s := strings.Join(chunks, "")
-		if idx := strings.LastIndex(s, exact); idx >= 0 {
-			return idx, 1
-		}
-		return -1, 0
-	}
-}
-
-// smartCase returns a matcherFunc that is case-sensitive if q contains any
-// upper-case characters, and case-insensitive otherwise.
-func smartCase(q string, m matcherFunc) matcherFunc {
-	insensitive := strings.ToLower(q) == q
-	wrapper := []string{""}
-	return func(chunks []string) (int, float64) {
-		s := strings.Join(chunks, "")
-		if insensitive {
-			s = strings.ToLower(s)
-		}
-		wrapper[0] = s
-		return m(wrapper)
-	}
-}
-
-type comboMatcher []matcherFunc
-
-func (c comboMatcher) match(chunks []string) (int, float64) {
-	score := 1.0
-	first := 0
-	for _, f := range c {
-		idx, s := f(chunks)
-		if idx < first {
-			first = idx
-		}
-		score *= s
-	}
-	return first, score
-}
-
-// collectSymbols calls snapshot.Symbols to walk the syntax trees of
-// all files in the views' current snapshots, and returns a sorted,
-// scored list of symbols that best match the parameters.
-//
-// How it matches symbols is parameterized by two interfaces:
-//   - A matcherFunc determines how well a string symbol matches a query. It
-//     returns a non-negative score indicating the quality of the match. A score
-//     of zero indicates no match.
-//   - A symbolizer determines how we extract the symbol for an object. This
-//     enables the 'symbolStyle' configuration option.
-func collectSymbols(ctx context.Context, views []View, matcherType SymbolMatcher, symbolizer symbolizer, query string) ([]protocol.SymbolInformation, error) {
-
-	// Extract symbols from all files.
-	var work []symbolFile
-	var roots []string
-	seen := make(map[span.URI]bool)
-	// TODO(adonovan): opt: parallelize this loop? How often is len > 1?
-	for _, v := range views {
-		snapshot, release := v.Snapshot(ctx)
-		defer release()
-
-		// Use the root view URIs for determining (lexically)
-		// whether a URI is in any open workspace.
-		roots = append(roots, strings.TrimRight(string(v.Folder()), "/"))
-
-		filters := v.Options().DirectoryFilters
-		filterer := NewFilterer(filters)
-		folder := filepath.ToSlash(v.Folder().Filename())
-		for uri, syms := range snapshot.Symbols(ctx) {
-			norm := filepath.ToSlash(uri.Filename())
-			nm := strings.TrimPrefix(norm, folder)
-			if filterer.Disallow(nm) {
-				continue
-			}
-			// Only scan each file once.
-			if seen[uri] {
-				continue
-			}
-			mds, err := snapshot.MetadataForFile(ctx, uri)
-			if err != nil {
-				event.Error(ctx, fmt.Sprintf("missing metadata for %q", uri), err)
-				continue
-			}
-			if len(mds) == 0 {
-				// TODO: should use the bug reporting API
-				continue
-			}
-			seen[uri] = true
-			work = append(work, symbolFile{uri, mds[0], syms})
-		}
-	}
-
-	// Match symbols in parallel.
-	// Each worker has its own symbolStore,
-	// which we merge at the end.
-	nmatchers := runtime.GOMAXPROCS(-1) // matching is CPU bound
-	results := make(chan *symbolStore)
-	for i := 0; i < nmatchers; i++ {
-		go func(i int) {
-			matcher := buildMatcher(matcherType, query)
-			store := new(symbolStore)
-			// Assign files to workers in round-robin fashion.
-			for j := i; j < len(work); j += nmatchers {
-				matchFile(store, symbolizer, matcher, roots, work[j])
-			}
-			results <- store
-		}(i)
-	}
-
-	// Gather and merge results as they arrive.
-	var unified symbolStore
-	for i := 0; i < nmatchers; i++ {
-		store := <-results
-		for _, syms := range store.res {
-			unified.store(syms)
-		}
-	}
-	return unified.results(), nil
-}
-
-type Filterer struct {
-	// Whether a filter is excluded depends on the operator (first char of the raw filter).
-	// Slices filters and excluded then should have the same length.
-	filters  []*regexp.Regexp
-	excluded []bool
-}
-
-// NewFilterer computes regular expression form of all raw filters
-func NewFilterer(rawFilters []string) *Filterer {
-	var f Filterer
-	for _, filter := range rawFilters {
-		filter = path.Clean(filepath.ToSlash(filter))
-		// TODO(dungtuanle): fix: validate [+-] prefix.
-		op, prefix := filter[0], filter[1:]
-		// convertFilterToRegexp adds "/" at the end of prefix to handle cases where a filter is a prefix of another filter.
-		// For example, it prevents [+foobar, -foo] from excluding "foobar".
-		f.filters = append(f.filters, convertFilterToRegexp(filepath.ToSlash(prefix)))
-		f.excluded = append(f.excluded, op == '-')
-	}
-
-	return &f
-}
-
-// Disallow return true if the path is excluded from the filterer's filters.
-func (f *Filterer) Disallow(path string) bool {
-	// Ensure trailing but not leading slash.
-	path = strings.TrimPrefix(path, "/")
-	if !strings.HasSuffix(path, "/") {
-		path += "/"
-	}
-
-	// TODO(adonovan): opt: iterate in reverse and break at first match.
-	excluded := false
-	for i, filter := range f.filters {
-		if filter.MatchString(path) {
-			excluded = f.excluded[i] // last match wins
-		}
-	}
-	return excluded
-}
-
-// convertFilterToRegexp replaces glob-like operator substrings in a string file path to their equivalent regex forms.
-// Supporting glob-like operators:
-//   - **: match zero or more complete path segments
-func convertFilterToRegexp(filter string) *regexp.Regexp {
-	if filter == "" {
-		return regexp.MustCompile(".*")
-	}
-	var ret strings.Builder
-	ret.WriteString("^")
-	segs := strings.Split(filter, "/")
-	for _, seg := range segs {
-		// Inv: seg != "" since path is clean.
-		if seg == "**" {
-			ret.WriteString(".*")
-		} else {
-			ret.WriteString(regexp.QuoteMeta(seg))
-		}
-		ret.WriteString("/")
-	}
-	pattern := ret.String()
-
-	// Remove unnecessary "^.*" prefix, which increased
-	// BenchmarkWorkspaceSymbols time by ~20% (even though
-	// filter CPU time increased by only by ~2.5%) when the
-	// default filter was changed to "**/node_modules".
-	pattern = strings.TrimPrefix(pattern, "^.*")
-
-	return regexp.MustCompile(pattern)
-}
-
-// symbolFile holds symbol information for a single file.
-type symbolFile struct {
-	uri  span.URI
-	md   *Metadata
-	syms []Symbol
-}
-
-// matchFile scans a symbol file and adds matching symbols to the store.
-func matchFile(store *symbolStore, symbolizer symbolizer, matcher matcherFunc, roots []string, i symbolFile) {
-	space := make([]string, 0, 3)
-	for _, sym := range i.syms {
-		symbolParts, score := symbolizer(space, sym.Name, i.md, matcher)
-
-		// Check if the score is too low before applying any downranking.
-		if store.tooLow(score) {
-			continue
-		}
-
-		// Factors to apply to the match score for the purpose of downranking
-		// results.
-		//
-		// These numbers were crudely calibrated based on trial-and-error using a
-		// small number of sample queries. Adjust as necessary.
-		//
-		// All factors are multiplicative, meaning if more than one applies they are
-		// multiplied together.
-		const (
-			// nonWorkspaceFactor is applied to symbols outside of any active
-			// workspace. Developers are less likely to want to jump to code that they
-			// are not actively working on.
-			nonWorkspaceFactor = 0.5
-			// nonWorkspaceUnexportedFactor is applied to unexported symbols outside of
-			// any active workspace. Since one wouldn't usually jump to unexported
-			// symbols to understand a package API, they are particularly irrelevant.
-			nonWorkspaceUnexportedFactor = 0.5
-			// every field or method nesting level to access the field decreases
-			// the score by a factor of 1.0 - depth*depthFactor, up to a depth of
-			// 3.
-			depthFactor = 0.2
-		)
-
-		startWord := true
-		exported := true
-		depth := 0.0
-		for _, r := range sym.Name {
-			if startWord && !unicode.IsUpper(r) {
-				exported = false
-			}
-			if r == '.' {
-				startWord = true
-				depth++
-			} else {
-				startWord = false
-			}
-		}
-
-		inWorkspace := false
-		for _, root := range roots {
-			if strings.HasPrefix(string(i.uri), root) {
-				inWorkspace = true
-				break
-			}
-		}
-
-		// Apply downranking based on workspace position.
-		if !inWorkspace {
-			score *= nonWorkspaceFactor
-			if !exported {
-				score *= nonWorkspaceUnexportedFactor
-			}
-		}
-
-		// Apply downranking based on symbol depth.
-		if depth > 3 {
-			depth = 3
-		}
-		score *= 1.0 - depth*depthFactor
-
-		if store.tooLow(score) {
-			continue
-		}
-
-		si := symbolInformation{
-			score:     score,
-			symbol:    strings.Join(symbolParts, ""),
-			kind:      sym.Kind,
-			uri:       i.uri,
-			rng:       sym.Range,
-			container: string(i.md.PkgPath),
-		}
-		store.store(si)
-	}
-}
-
-type symbolStore struct {
-	res [maxSymbols]symbolInformation
-}
-
-// store inserts si into the sorted results, if si has a high enough score.
-func (sc *symbolStore) store(si symbolInformation) {
-	if sc.tooLow(si.score) {
-		return
-	}
-	insertAt := sort.Search(len(sc.res), func(i int) bool {
-		// Sort by score, then symbol length, and finally lexically.
-		if sc.res[i].score != si.score {
-			return sc.res[i].score < si.score
-		}
-		if len(sc.res[i].symbol) != len(si.symbol) {
-			return len(sc.res[i].symbol) > len(si.symbol)
-		}
-		return sc.res[i].symbol > si.symbol
-	})
-	if insertAt < len(sc.res)-1 {
-		copy(sc.res[insertAt+1:], sc.res[insertAt:len(sc.res)-1])
-	}
-	sc.res[insertAt] = si
-}
-
-func (sc *symbolStore) tooLow(score float64) bool {
-	return score <= sc.res[len(sc.res)-1].score
-}
-
-func (sc *symbolStore) results() []protocol.SymbolInformation {
-	var res []protocol.SymbolInformation
-	for _, si := range sc.res {
-		if si.score <= 0 {
-			return res
-		}
-		res = append(res, si.asProtocolSymbolInformation())
-	}
-	return res
-}
-
-func typeToKind(typ types.Type) protocol.SymbolKind {
-	switch typ := typ.Underlying().(type) {
-	case *types.Interface:
-		return protocol.Interface
-	case *types.Struct:
-		return protocol.Struct
-	case *types.Signature:
-		if typ.Recv() != nil {
-			return protocol.Method
-		}
-		return protocol.Function
-	case *types.Named:
-		return typeToKind(typ.Underlying())
-	case *types.Basic:
-		i := typ.Info()
-		switch {
-		case i&types.IsNumeric != 0:
-			return protocol.Number
-		case i&types.IsBoolean != 0:
-			return protocol.Boolean
-		case i&types.IsString != 0:
-			return protocol.String
-		}
-	}
-	return protocol.Variable
-}
-
-// symbolInformation is a cut-down version of protocol.SymbolInformation that
-// allows struct values of this type to be used as map keys.
-type symbolInformation struct {
-	score     float64
-	symbol    string
-	container string
-	kind      protocol.SymbolKind
-	uri       span.URI
-	rng       protocol.Range
-}
-
-// asProtocolSymbolInformation converts s to a protocol.SymbolInformation value.
-//
-// TODO: work out how to handle tags if/when they are needed.
-func (s symbolInformation) asProtocolSymbolInformation() protocol.SymbolInformation {
-	return protocol.SymbolInformation{
-		Name: s.symbol,
-		Kind: s.kind,
-		Location: protocol.Location{
-			URI:   protocol.URIFromSpanURI(s.uri),
-			Range: s.rng,
-		},
-		ContainerName: s.container,
-	}
-}
diff -urN a/gopls/internal/lsp/source/workspace_symbol_test.go b/gopls/internal/lsp/source/workspace_symbol_test.go
--- a/gopls/internal/lsp/source/workspace_symbol_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/source/workspace_symbol_test.go	1969-12-31 16:00:00
@@ -1,136 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package source
-
-import (
-	"testing"
-)
-
-func TestParseQuery(t *testing.T) {
-	tests := []struct {
-		query, s  string
-		wantMatch bool
-	}{
-		{"", "anything", false},
-		{"any", "anything", true},
-		{"any$", "anything", false},
-		{"ing$", "anything", true},
-		{"ing$", "anythinG", true},
-		{"inG$", "anything", false},
-		{"^any", "anything", true},
-		{"^any", "Anything", true},
-		{"^Any", "anything", false},
-		{"at", "anything", true},
-		// TODO: this appears to be a bug in the fuzzy matching algorithm. 'At'
-		// should cause a case-sensitive match.
-		// {"At", "anything", false},
-		{"At", "Anything", true},
-		{"'yth", "Anything", true},
-		{"'yti", "Anything", false},
-		{"'any 'thing", "Anything", true},
-		{"anythn nythg", "Anything", true},
-		{"ntx", "Anything", false},
-		{"anythn", "anything", true},
-		{"ing", "anything", true},
-		{"anythn nythgx", "anything", false},
-	}
-
-	for _, test := range tests {
-		matcher := parseQuery(test.query, newFuzzyMatcher)
-		if _, score := matcher([]string{test.s}); score > 0 != test.wantMatch {
-			t.Errorf("parseQuery(%q) match for %q: %.2g, want match: %t", test.query, test.s, score, test.wantMatch)
-		}
-	}
-}
-
-func TestFiltererDisallow(t *testing.T) {
-	tests := []struct {
-		filters  []string
-		included []string
-		excluded []string
-	}{
-		{
-			[]string{"+**/c.go"},
-			[]string{"a/c.go", "a/b/c.go"},
-			[]string{},
-		},
-		{
-			[]string{"+a/**/c.go"},
-			[]string{"a/b/c.go", "a/b/d/c.go", "a/c.go"},
-			[]string{},
-		},
-		{
-			[]string{"-a/c.go", "+a/**"},
-			[]string{"a/c.go"},
-			[]string{},
-		},
-		{
-			[]string{"+a/**/c.go", "-**/c.go"},
-			[]string{},
-			[]string{"a/b/c.go"},
-		},
-		{
-			[]string{"+a/**/c.go", "-a/**"},
-			[]string{},
-			[]string{"a/b/c.go"},
-		},
-		{
-			[]string{"+**/c.go", "-a/**/c.go"},
-			[]string{},
-			[]string{"a/b/c.go"},
-		},
-		{
-			[]string{"+foobar", "-foo"},
-			[]string{"foobar", "foobar/a"},
-			[]string{"foo", "foo/a"},
-		},
-		{
-			[]string{"+", "-"},
-			[]string{},
-			[]string{"foobar", "foobar/a", "foo", "foo/a"},
-		},
-		{
-			[]string{"-", "+"},
-			[]string{"foobar", "foobar/a", "foo", "foo/a"},
-			[]string{},
-		},
-		{
-			[]string{"-a/**/b/**/c.go"},
-			[]string{},
-			[]string{"a/x/y/z/b/f/g/h/c.go"},
-		},
-		// tests for unsupported glob operators
-		{
-			[]string{"+**/c.go", "-a/*/c.go"},
-			[]string{"a/b/c.go"},
-			[]string{},
-		},
-		{
-			[]string{"+**/c.go", "-a/?/c.go"},
-			[]string{"a/b/c.go"},
-			[]string{},
-		},
-		{
-			[]string{"-b"}, // should only filter paths prefixed with the "b" directory
-			[]string{"a/b/c.go", "bb"},
-			[]string{"b/c/d.go", "b"},
-		},
-	}
-
-	for _, test := range tests {
-		filterer := NewFilterer(test.filters)
-		for _, inc := range test.included {
-			if filterer.Disallow(inc) {
-				t.Errorf("Filters %v excluded %v, wanted included", test.filters, inc)
-			}
-		}
-
-		for _, exc := range test.excluded {
-			if !filterer.Disallow(exc) {
-				t.Errorf("Filters %v included %v, wanted excluded", test.filters, exc)
-			}
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/symbols.go b/gopls/internal/lsp/symbols.go
--- a/gopls/internal/lsp/symbols.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/symbols.go	1969-12-31 16:00:00
@@ -1,60 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/template"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/event/tag"
-)
-
-func (s *Server) documentSymbol(ctx context.Context, params *protocol.DocumentSymbolParams) ([]interface{}, error) {
-	ctx, done := event.Start(ctx, "lsp.Server.documentSymbol")
-	defer done()
-
-	snapshot, fh, ok, release, err := s.beginFileRequest(ctx, params.TextDocument.URI, source.UnknownKind)
-	defer release()
-	if !ok {
-		return []interface{}{}, err
-	}
-	var docSymbols []protocol.DocumentSymbol
-	switch snapshot.View().FileKind(fh) {
-	case source.Tmpl:
-		docSymbols, err = template.DocumentSymbols(snapshot, fh)
-	case source.Go:
-		docSymbols, err = source.DocumentSymbols(ctx, snapshot, fh)
-	default:
-		return []interface{}{}, nil
-	}
-	if err != nil {
-		event.Error(ctx, "DocumentSymbols failed", err, tag.URI.Of(fh.URI()))
-		return []interface{}{}, nil
-	}
-	// Convert the symbols to an interface array.
-	// TODO: Remove this once the lsp deprecates SymbolInformation.
-	symbols := make([]interface{}, len(docSymbols))
-	for i, s := range docSymbols {
-		if snapshot.View().Options().HierarchicalDocumentSymbolSupport {
-			symbols[i] = s
-			continue
-		}
-		// If the client does not support hierarchical document symbols, then
-		// we need to be backwards compatible for now and return SymbolInformation.
-		symbols[i] = protocol.SymbolInformation{
-			Name:       s.Name,
-			Kind:       s.Kind,
-			Deprecated: s.Deprecated,
-			Location: protocol.Location{
-				URI:   params.TextDocument.URI,
-				Range: s.Range,
-			},
-		}
-	}
-	return symbols, nil
-}
diff -urN a/gopls/internal/lsp/template/completion.go b/gopls/internal/lsp/template/completion.go
--- a/gopls/internal/lsp/template/completion.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/completion.go	1969-12-31 16:00:00
@@ -1,287 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/scanner"
-	"go/token"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-// information needed for completion
-type completer struct {
-	p      *Parsed
-	pos    protocol.Position
-	offset int // offset of the start of the Token
-	ctx    protocol.CompletionContext
-	syms   map[string]symbol
-}
-
-func Completion(ctx context.Context, snapshot source.Snapshot, fh source.VersionedFileHandle, pos protocol.Position, context protocol.CompletionContext) (*protocol.CompletionList, error) {
-	all := New(snapshot.Templates())
-	var start int // the beginning of the Token (completed or not)
-	syms := make(map[string]symbol)
-	var p *Parsed
-	for fn, fc := range all.files {
-		// collect symbols from all template files
-		filterSyms(syms, fc.symbols)
-		if fn.Filename() != fh.URI().Filename() {
-			continue
-		}
-		if start = inTemplate(fc, pos); start == -1 {
-			return nil, nil
-		}
-		p = fc
-	}
-	if p == nil {
-		// this cannot happen unless the search missed a template file
-		return nil, fmt.Errorf("%s not found", fh.FileIdentity().URI.Filename())
-	}
-	c := completer{
-		p:      p,
-		pos:    pos,
-		offset: start + len(Left),
-		ctx:    context,
-		syms:   syms,
-	}
-	return c.complete()
-}
-
-func filterSyms(syms map[string]symbol, ns []symbol) {
-	for _, xsym := range ns {
-		switch xsym.kind {
-		case protocol.Method, protocol.Package, protocol.Boolean, protocol.Namespace,
-			protocol.Function:
-			syms[xsym.name] = xsym // we don't care which symbol we get
-		case protocol.Variable:
-			if xsym.name != "dot" {
-				syms[xsym.name] = xsym
-			}
-		case protocol.Constant:
-			if xsym.name == "nil" {
-				syms[xsym.name] = xsym
-			}
-		}
-	}
-}
-
-// return the starting position of the enclosing token, or -1 if none
-func inTemplate(fc *Parsed, pos protocol.Position) int {
-	// pos is the pos-th character. if the cursor is at the beginning
-	// of the file, pos is 0. That is, we've only seen characters before pos
-	// 1. pos might be in a Token, return tk.Start
-	// 2. pos might be after an elided but before a Token, return elided
-	// 3. return -1 for false
-	offset := fc.FromPosition(pos)
-	// this could be a binary search, as the tokens are ordered
-	for _, tk := range fc.tokens {
-		if tk.Start < offset && offset <= tk.End {
-			return tk.Start
-		}
-	}
-	for _, x := range fc.elided {
-		if x > offset {
-			// fc.elided is sorted
-			break
-		}
-		// If the interval [x,offset] does not contain Left or Right
-		// then provide completions. (do we need the test for Right?)
-		if !bytes.Contains(fc.buf[x:offset], []byte(Left)) && !bytes.Contains(fc.buf[x:offset], []byte(Right)) {
-			return x
-		}
-	}
-	return -1
-}
-
-var (
-	keywords = []string{"if", "with", "else", "block", "range", "template", "end}}", "end"}
-	globals  = []string{"and", "call", "html", "index", "slice", "js", "len", "not", "or",
-		"urlquery", "printf", "println", "print", "eq", "ne", "le", "lt", "ge", "gt"}
-)
-
-// find the completions. start is the offset of either the Token enclosing pos, or where
-// the incomplete token starts.
-// The error return is always nil.
-func (c *completer) complete() (*protocol.CompletionList, error) {
-	ans := &protocol.CompletionList{IsIncomplete: true, Items: []protocol.CompletionItem{}}
-	start := c.p.FromPosition(c.pos)
-	sofar := c.p.buf[c.offset:start]
-	if len(sofar) == 0 || sofar[len(sofar)-1] == ' ' || sofar[len(sofar)-1] == '\t' {
-		return ans, nil
-	}
-	// sofar could be parsed by either c.analyzer() or scan(). The latter is precise
-	// and slower, but fast enough
-	words := scan(sofar)
-	// 1. if pattern starts $, show variables
-	// 2. if pattern starts ., show methods (and . by itself?)
-	// 3. if len(words) == 1, show firstWords (but if it were a |, show functions and globals)
-	// 4. ...? (parenthetical expressions, arguments, ...) (packages, namespaces, nil?)
-	if len(words) == 0 {
-		return nil, nil // if this happens, why were we called?
-	}
-	pattern := string(words[len(words)-1])
-	if pattern[0] == '$' {
-		// should we also return a raw "$"?
-		for _, s := range c.syms {
-			if s.kind == protocol.Variable && weakMatch(s.name, pattern) > 0 {
-				ans.Items = append(ans.Items, protocol.CompletionItem{
-					Label:  s.name,
-					Kind:   protocol.VariableCompletion,
-					Detail: "Variable",
-				})
-			}
-		}
-		return ans, nil
-	}
-	if pattern[0] == '.' {
-		for _, s := range c.syms {
-			if s.kind == protocol.Method && weakMatch("."+s.name, pattern) > 0 {
-				ans.Items = append(ans.Items, protocol.CompletionItem{
-					Label:  s.name,
-					Kind:   protocol.MethodCompletion,
-					Detail: "Method/member",
-				})
-			}
-		}
-		return ans, nil
-	}
-	// could we get completion attempts in strings or numbers, and if so, do we care?
-	// globals
-	for _, kw := range globals {
-		if weakMatch(kw, string(pattern)) != 0 {
-			ans.Items = append(ans.Items, protocol.CompletionItem{
-				Label:  kw,
-				Kind:   protocol.KeywordCompletion,
-				Detail: "Function",
-			})
-		}
-	}
-	// and functions
-	for _, s := range c.syms {
-		if s.kind == protocol.Function && weakMatch(s.name, pattern) != 0 {
-			ans.Items = append(ans.Items, protocol.CompletionItem{
-				Label:  s.name,
-				Kind:   protocol.FunctionCompletion,
-				Detail: "Function",
-			})
-		}
-	}
-	// keywords if we're at the beginning
-	if len(words) <= 1 || len(words[len(words)-2]) == 1 && words[len(words)-2][0] == '|' {
-		for _, kw := range keywords {
-			if weakMatch(kw, string(pattern)) != 0 {
-				ans.Items = append(ans.Items, protocol.CompletionItem{
-					Label:  kw,
-					Kind:   protocol.KeywordCompletion,
-					Detail: "keyword",
-				})
-			}
-		}
-	}
-	return ans, nil
-}
-
-// someday think about comments, strings, backslashes, etc
-// this would repeat some of the template parsing, but because the user is typing
-// there may be no parse tree here.
-// (go/scanner will report 2 tokens for $a, as $ is not a legal go identifier character)
-// (go/scanner is about 2.7 times more expensive)
-func (c *completer) analyze(buf []byte) [][]byte {
-	// we want to split on whitespace and before dots
-	var working []byte
-	var ans [][]byte
-	for _, ch := range buf {
-		if ch == '.' && len(working) > 0 {
-			ans = append(ans, working)
-			working = []byte{'.'}
-			continue
-		}
-		if ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r' {
-			if len(working) > 0 {
-				ans = append(ans, working)
-				working = []byte{}
-				continue
-			}
-		}
-		working = append(working, ch)
-	}
-	if len(working) > 0 {
-		ans = append(ans, working)
-	}
-	ch := buf[len(buf)-1]
-	if ch == ' ' || ch == '\t' {
-		// avoid completing on whitespace
-		ans = append(ans, []byte{ch})
-	}
-	return ans
-}
-
-// version of c.analyze that uses go/scanner.
-func scan(buf []byte) []string {
-	fset := token.NewFileSet()
-	fp := fset.AddFile("", -1, len(buf))
-	var sc scanner.Scanner
-	sc.Init(fp, buf, func(pos token.Position, msg string) {}, scanner.ScanComments)
-	ans := make([]string, 0, 10) // preallocating gives a measurable savings
-	for {
-		_, tok, lit := sc.Scan() // tok is an int
-		if tok == token.EOF {
-			break // done
-		} else if tok == token.SEMICOLON && lit == "\n" {
-			continue // don't care, but probably can't happen
-		} else if tok == token.PERIOD {
-			ans = append(ans, ".") // lit is empty
-		} else if tok == token.IDENT && len(ans) > 0 && ans[len(ans)-1] == "." {
-			ans[len(ans)-1] = "." + lit
-		} else if tok == token.IDENT && len(ans) > 0 && ans[len(ans)-1] == "$" {
-			ans[len(ans)-1] = "$" + lit
-		} else if lit != "" {
-			ans = append(ans, lit)
-		}
-	}
-	return ans
-}
-
-// pattern is what the user has typed
-func weakMatch(choice, pattern string) float64 {
-	lower := strings.ToLower(choice)
-	// for now, use only lower-case everywhere
-	pattern = strings.ToLower(pattern)
-	// The first char has to match
-	if pattern[0] != lower[0] {
-		return 0
-	}
-	// If they start with ., then the second char has to match
-	from := 1
-	if pattern[0] == '.' {
-		if len(pattern) < 2 {
-			return 1 // pattern just a ., so it matches
-		}
-		if pattern[1] != lower[1] {
-			return 0
-		}
-		from = 2
-	}
-	// check that all the characters of pattern occur as a subsequence of choice
-	i, j := from, from
-	for ; i < len(lower) && j < len(pattern); j++ {
-		if pattern[j] == lower[i] {
-			i++
-			if i >= len(lower) {
-				return 0
-			}
-		}
-	}
-	if j < len(pattern) {
-		return 0
-	}
-	return 1
-}
diff -urN a/gopls/internal/lsp/template/completion_test.go b/gopls/internal/lsp/template/completion_test.go
--- a/gopls/internal/lsp/template/completion_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/completion_test.go	1969-12-31 16:00:00
@@ -1,102 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"log"
-	"sort"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func init() {
-	log.SetFlags(log.Lshortfile)
-}
-
-type tparse struct {
-	marked string   // ^ shows where to ask for completions. (The user just typed the following character.)
-	wanted []string // expected completions
-}
-
-// Test completions in templates that parse enough (if completion needs symbols)
-// Seen characters up to the ^
-func TestParsed(t *testing.T) {
-	var tests = []tparse{
-		{"{{x}}{{12. xx^", nil}, // https://github.com/golang/go/issues/50430
-		{`<table class="chroma" data-new-comment-url="{{if $.PageIsPullFiles}}{{$.Issue.HTMLURL}}/files/reviews/new_comment{{else}}{{$.CommitHTML}}/new_comment^{{end}}">`, nil},
-		{"{{i^f}}", []string{"index", "if"}},
-		{"{{if .}}{{e^ {{end}}", []string{"eq", "end}}", "else", "end"}},
-		{"{{foo}}{{f^", []string{"foo"}},
-		{"{{$^}}", []string{"$"}},
-		{"{{$x:=4}}{{$^", []string{"$x"}},
-		{"{{$x:=4}}{{$ ^ ", []string{}},
-		{"{{len .Modified}}{{.^Mo", []string{"Modified"}},
-		{"{{len .Modified}}{{.mf^", []string{"Modified"}},
-		{"{{$^ }}", []string{"$"}},
-		{"{{$a =3}}{{$^", []string{"$a"}},
-		// .two is not good here: fix someday
-		{`{{.Modified}}{{.^{{if $.one.two}}xxx{{end}}`, []string{"Modified", "one", "two"}},
-		{`{{.Modified}}{{.o^{{if $.one.two}}xxx{{end}}`, []string{"one"}},
-		{"{{.Modiifed}}{{.one.t^{{if $.one.two}}xxx{{end}}", []string{"two"}},
-		{`{{block "foo" .}}{{i^`, []string{"index", "if"}},
-		{"{{in^{{Internal}}", []string{"index", "Internal", "if"}},
-		// simple number has no completions
-		{"{{4^e", []string{}},
-		// simple string has no completions
-		{"{{`e^", []string{}},
-		{"{{`No i^", []string{}}, // example of why go/scanner is used
-		{"{{xavier}}{{12. x^", []string{"xavier"}},
-	}
-	for _, tx := range tests {
-		c := testCompleter(t, tx)
-		var v []string
-		if c != nil {
-			ans, _ := c.complete()
-			for _, a := range ans.Items {
-				v = append(v, a.Label)
-			}
-		}
-		if len(v) != len(tx.wanted) {
-			t.Errorf("%q: got %q, wanted %q %d,%d", tx.marked, v, tx.wanted, len(v), len(tx.wanted))
-			continue
-		}
-		sort.Strings(tx.wanted)
-		sort.Strings(v)
-		for i := 0; i < len(v); i++ {
-			if tx.wanted[i] != v[i] {
-				t.Errorf("%q at %d: got %v, wanted %v", tx.marked, i, v, tx.wanted)
-				break
-			}
-		}
-	}
-}
-
-func testCompleter(t *testing.T, tx tparse) *completer {
-	t.Helper()
-	// seen chars up to ^
-	col := strings.Index(tx.marked, "^")
-	buf := strings.Replace(tx.marked, "^", "", 1)
-	p := parseBuffer([]byte(buf))
-	pos := protocol.Position{Line: 0, Character: uint32(col)}
-	if p.ParseErr != nil {
-		log.Printf("%q: %v", tx.marked, p.ParseErr)
-	}
-	offset := inTemplate(p, pos)
-	if offset == -1 {
-		return nil
-	}
-	syms := make(map[string]symbol)
-	filterSyms(syms, p.symbols)
-	c := &completer{
-		p:      p,
-		pos:    protocol.Position{Line: 0, Character: uint32(col)},
-		offset: offset + len(Left),
-		ctx:    protocol.CompletionContext{TriggerKind: protocol.Invoked},
-		syms:   syms,
-	}
-	return c
-}
diff -urN a/gopls/internal/lsp/template/highlight.go b/gopls/internal/lsp/template/highlight.go
--- a/gopls/internal/lsp/template/highlight.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/highlight.go	1969-12-31 16:00:00
@@ -1,96 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"context"
-	"fmt"
-	"regexp"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func Highlight(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, loc protocol.Position) ([]protocol.DocumentHighlight, error) {
-	buf, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	p := parseBuffer(buf)
-	pos := p.FromPosition(loc)
-	var ans []protocol.DocumentHighlight
-	if p.ParseErr == nil {
-		for _, s := range p.symbols {
-			if s.start <= pos && pos < s.start+s.length {
-				return markSymbols(p, s)
-			}
-		}
-	}
-	// these tokens exist whether or not there was a parse error
-	// (symbols require a successful parse)
-	for _, tok := range p.tokens {
-		if tok.Start <= pos && pos < tok.End {
-			wordAt := findWordAt(p, pos)
-			if len(wordAt) > 0 {
-				return markWordInToken(p, wordAt)
-			}
-		}
-	}
-	// find the 'word' at pos, etc: someday
-	// until then we get the default action, which doesn't respect word boundaries
-	return ans, nil
-}
-
-func markSymbols(p *Parsed, sym symbol) ([]protocol.DocumentHighlight, error) {
-	var ans []protocol.DocumentHighlight
-	for _, s := range p.symbols {
-		if s.name == sym.name {
-			kind := protocol.Read
-			if s.vardef {
-				kind = protocol.Write
-			}
-			ans = append(ans, protocol.DocumentHighlight{
-				Range: p.Range(s.start, s.length),
-				Kind:  kind,
-			})
-		}
-	}
-	return ans, nil
-}
-
-// A token is {{...}}, and this marks words in the token that equal the give word
-func markWordInToken(p *Parsed, wordAt string) ([]protocol.DocumentHighlight, error) {
-	var ans []protocol.DocumentHighlight
-	pat, err := regexp.Compile(fmt.Sprintf(`\b%s\b`, wordAt))
-	if err != nil {
-		return nil, fmt.Errorf("%q: unmatchable word (%v)", wordAt, err)
-	}
-	for _, tok := range p.tokens {
-		got := pat.FindAllIndex(p.buf[tok.Start:tok.End], -1)
-		for i := 0; i < len(got); i++ {
-			ans = append(ans, protocol.DocumentHighlight{
-				Range: p.Range(got[i][0], got[i][1]-got[i][0]),
-				Kind:  protocol.Text,
-			})
-		}
-	}
-	return ans, nil
-}
-
-var wordRe = regexp.MustCompile(`[$]?\w+$`)
-var moreRe = regexp.MustCompile(`^[$]?\w+`)
-
-// findWordAt finds the word the cursor is in (meaning in or just before)
-func findWordAt(p *Parsed, pos int) string {
-	if pos >= len(p.buf) {
-		return "" // can't happen, as we are called with pos < tok.End
-	}
-	after := moreRe.Find(p.buf[pos:])
-	if len(after) == 0 {
-		return "" // end of the word
-	}
-	got := wordRe.Find(p.buf[:pos+len(after)])
-	return string(got)
-}
diff -urN a/gopls/internal/lsp/template/implementations.go b/gopls/internal/lsp/template/implementations.go
--- a/gopls/internal/lsp/template/implementations.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/implementations.go	1969-12-31 16:00:00
@@ -1,189 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"context"
-	"fmt"
-	"regexp"
-	"strconv"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// line number (1-based) and message
-var errRe = regexp.MustCompile(`template.*:(\d+): (.*)`)
-
-// Diagnose returns parse errors. There is only one.
-// The errors are not always helpful. For instance { {end}}
-// will likely point to the end of the file.
-func Diagnose(f source.VersionedFileHandle) []*source.Diagnostic {
-	// no need for skipTemplate check, as Diagnose is called on the
-	// snapshot's template files
-	buf, err := f.Read()
-	if err != nil {
-		// Is a Diagnostic with no Range useful? event.Error also?
-		msg := fmt.Sprintf("failed to read %s (%v)", f.URI().Filename(), err)
-		d := source.Diagnostic{Message: msg, Severity: protocol.SeverityError, URI: f.URI(),
-			Source: source.TemplateError}
-		return []*source.Diagnostic{&d}
-	}
-	p := parseBuffer(buf)
-	if p.ParseErr == nil {
-		return nil
-	}
-	unknownError := func(msg string) []*source.Diagnostic {
-		s := fmt.Sprintf("malformed template error %q: %s", p.ParseErr.Error(), msg)
-		d := source.Diagnostic{
-			Message: s, Severity: protocol.SeverityError, Range: p.Range(p.nls[0], 1),
-			URI: f.URI(), Source: source.TemplateError}
-		return []*source.Diagnostic{&d}
-	}
-	// errors look like `template: :40: unexpected "}" in operand`
-	// so the string needs to be parsed
-	matches := errRe.FindStringSubmatch(p.ParseErr.Error())
-	if len(matches) != 3 {
-		msg := fmt.Sprintf("expected 3 matches, got %d (%v)", len(matches), matches)
-		return unknownError(msg)
-	}
-	lineno, err := strconv.Atoi(matches[1])
-	if err != nil {
-		msg := fmt.Sprintf("couldn't convert %q to int, %v", matches[1], err)
-		return unknownError(msg)
-	}
-	msg := matches[2]
-	d := source.Diagnostic{Message: msg, Severity: protocol.SeverityError,
-		Source: source.TemplateError}
-	start := p.nls[lineno-1]
-	if lineno < len(p.nls) {
-		size := p.nls[lineno] - start
-		d.Range = p.Range(start, size)
-	} else {
-		d.Range = p.Range(start, 1)
-	}
-	return []*source.Diagnostic{&d}
-}
-
-// Definition finds the definitions of the symbol at loc. It
-// does not understand scoping (if any) in templates. This code is
-// for definitions, type definitions, and implementations.
-// Results only for variables and templates.
-func Definition(snapshot source.Snapshot, fh source.VersionedFileHandle, loc protocol.Position) ([]protocol.Location, error) {
-	x, _, err := symAtPosition(fh, loc)
-	if err != nil {
-		return nil, err
-	}
-	sym := x.name
-	ans := []protocol.Location{}
-	// PJW: this is probably a pattern to abstract
-	a := New(snapshot.Templates())
-	for k, p := range a.files {
-		for _, s := range p.symbols {
-			if !s.vardef || s.name != sym {
-				continue
-			}
-			ans = append(ans, protocol.Location{URI: protocol.DocumentURI(k), Range: p.Range(s.start, s.length)})
-		}
-	}
-	return ans, nil
-}
-
-func Hover(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, position protocol.Position) (*protocol.Hover, error) {
-	sym, p, err := symAtPosition(fh, position)
-	if sym == nil || err != nil {
-		return nil, err
-	}
-	ans := protocol.Hover{Range: p.Range(sym.start, sym.length), Contents: protocol.MarkupContent{Kind: protocol.Markdown}}
-	switch sym.kind {
-	case protocol.Function:
-		ans.Contents.Value = fmt.Sprintf("function: %s", sym.name)
-	case protocol.Variable:
-		ans.Contents.Value = fmt.Sprintf("variable: %s", sym.name)
-	case protocol.Constant:
-		ans.Contents.Value = fmt.Sprintf("constant %s", sym.name)
-	case protocol.Method: // field or method
-		ans.Contents.Value = fmt.Sprintf("%s: field or method", sym.name)
-	case protocol.Package: // template use, template def (PJW: do we want two?)
-		ans.Contents.Value = fmt.Sprintf("template %s\n(add definition)", sym.name)
-	case protocol.Namespace:
-		ans.Contents.Value = fmt.Sprintf("template %s defined", sym.name)
-	case protocol.Number:
-		ans.Contents.Value = "number"
-	case protocol.String:
-		ans.Contents.Value = "string"
-	case protocol.Boolean:
-		ans.Contents.Value = "boolean"
-	default:
-		ans.Contents.Value = fmt.Sprintf("oops, sym=%#v", sym)
-	}
-	return &ans, nil
-}
-
-func References(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, params *protocol.ReferenceParams) ([]protocol.Location, error) {
-	sym, _, err := symAtPosition(fh, params.Position)
-	if sym == nil || err != nil || sym.name == "" {
-		return nil, err
-	}
-	ans := []protocol.Location{}
-
-	a := New(snapshot.Templates())
-	for k, p := range a.files {
-		for _, s := range p.symbols {
-			if s.name != sym.name {
-				continue
-			}
-			if s.vardef && !params.Context.IncludeDeclaration {
-				continue
-			}
-			ans = append(ans, protocol.Location{URI: protocol.DocumentURI(k), Range: p.Range(s.start, s.length)})
-		}
-	}
-	// do these need to be sorted? (a.files is a map)
-	return ans, nil
-}
-
-func SemanticTokens(ctx context.Context, snapshot source.Snapshot, spn span.URI, add func(line, start, len uint32), d func() []uint32) (*protocol.SemanticTokens, error) {
-	fh, err := snapshot.GetFile(ctx, spn)
-	if err != nil {
-		return nil, err
-	}
-	buf, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	p := parseBuffer(buf)
-
-	for _, t := range p.Tokens() {
-		if t.Multiline {
-			la, ca := p.LineCol(t.Start)
-			lb, cb := p.LineCol(t.End)
-			add(la, ca, p.RuneCount(la, ca, 0))
-			for l := la + 1; l < lb; l++ {
-				add(l, 0, p.RuneCount(l, 0, 0))
-			}
-			add(lb, 0, p.RuneCount(lb, 0, cb))
-			continue
-		}
-		sz, err := p.TokenSize(t)
-		if err != nil {
-			return nil, err
-		}
-		line, col := p.LineCol(t.Start)
-		add(line, col, uint32(sz))
-	}
-	data := d()
-	ans := &protocol.SemanticTokens{
-		Data: data,
-		// for small cache, some day. for now, the LSP client ignores this
-		// (that is, when the LSP client starts returning these, we can cache)
-		ResultID: fmt.Sprintf("%v", time.Now()),
-	}
-	return ans, nil
-}
-
-// still need to do rename, etc
diff -urN a/gopls/internal/lsp/template/parse.go b/gopls/internal/lsp/template/parse.go
--- a/gopls/internal/lsp/template/parse.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/parse.go	1969-12-31 16:00:00
@@ -1,506 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package template contains code for dealing with templates
-package template
-
-// template files are small enough that the code reprocesses them each time
-// this may be a bad choice for projects with lots of template files.
-
-// This file contains the parsing code, some debugging printing, and
-// implementations for Diagnose, Definition, Hover, References
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"io"
-	"log"
-	"regexp"
-	"runtime"
-	"sort"
-	"text/template"
-	"text/template/parse"
-	"unicode/utf8"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-)
-
-var (
-	Left  = []byte("{{")
-	Right = []byte("}}")
-)
-
-type Parsed struct {
-	buf    []byte   //contents
-	lines  [][]byte // needed?, other than for debugging?
-	elided []int    // offsets where Left was replaced by blanks
-
-	// tokens are matched Left-Right pairs, computed before trying to parse
-	tokens []Token
-
-	// result of parsing
-	named    []*template.Template // the template and embedded templates
-	ParseErr error
-	symbols  []symbol
-	stack    []parse.Node // used while computing symbols
-
-	// for mapping from offsets in buf to LSP coordinates
-	// See FromPosition() and LineCol()
-	nls      []int // offset of newlines before each line (nls[0]==-1)
-	lastnl   int   // last line seen
-	check    int   // used to decide whether to use lastnl or search through nls
-	nonASCII bool  // are there any non-ascii runes in buf?
-}
-
-// Token is a single {{...}}. More precisely, Left...Right
-type Token struct {
-	Start, End int // offset from start of template
-	Multiline  bool
-}
-
-// All contains the Parse of all the template files
-type All struct {
-	files map[span.URI]*Parsed
-}
-
-// New returns the Parses of the snapshot's tmpl files
-// (maybe cache these, but then avoiding import cycles needs code rearrangements)
-func New(tmpls map[span.URI]source.VersionedFileHandle) *All {
-	all := make(map[span.URI]*Parsed)
-	for k, v := range tmpls {
-		buf, err := v.Read()
-		if err != nil { // PJW: decide what to do with these errors
-			log.Printf("failed to read %s (%v)", v.URI().Filename(), err)
-			continue
-		}
-		all[k] = parseBuffer(buf)
-	}
-	return &All{files: all}
-}
-
-func parseBuffer(buf []byte) *Parsed {
-	ans := &Parsed{
-		buf:   buf,
-		check: -1,
-		nls:   []int{-1},
-	}
-	if len(buf) == 0 {
-		return ans
-	}
-	// how to compute allAscii...
-	for _, b := range buf {
-		if b >= utf8.RuneSelf {
-			ans.nonASCII = true
-			break
-		}
-	}
-	if buf[len(buf)-1] != '\n' {
-		ans.buf = append(buf, '\n')
-	}
-	for i, p := range ans.buf {
-		if p == '\n' {
-			ans.nls = append(ans.nls, i)
-		}
-	}
-	ans.setTokens() // ans.buf may be a new []byte
-	ans.lines = bytes.Split(ans.buf, []byte{'\n'})
-	t, err := template.New("").Parse(string(ans.buf))
-	if err != nil {
-		funcs := make(template.FuncMap)
-		for t == nil && ans.ParseErr == nil {
-			// in 1.17 it may be possible to avoid getting this error
-			//  template: :2: function "foo" not defined
-			matches := parseErrR.FindStringSubmatch(err.Error())
-			if len(matches) == 2 {
-				// suppress the error by giving it a function with the right name
-				funcs[matches[1]] = func() interface{} { return nil }
-				t, err = template.New("").Funcs(funcs).Parse(string(ans.buf))
-				continue
-			}
-			ans.ParseErr = err // unfixed error
-			return ans
-		}
-	}
-	ans.named = t.Templates()
-	// set the symbols
-	for _, t := range ans.named {
-		ans.stack = append(ans.stack, t.Root)
-		ans.findSymbols()
-		if t.Name() != "" {
-			// defining a template. The pos is just after {{define...}} (or {{block...}}?)
-			at, sz := ans.FindLiteralBefore(int(t.Root.Pos))
-			s := symbol{start: at, length: sz, name: t.Name(), kind: protocol.Namespace, vardef: true}
-			ans.symbols = append(ans.symbols, s)
-		}
-	}
-
-	sort.Slice(ans.symbols, func(i, j int) bool {
-		left, right := ans.symbols[i], ans.symbols[j]
-		if left.start != right.start {
-			return left.start < right.start
-		}
-		if left.vardef != right.vardef {
-			return left.vardef
-		}
-		return left.kind < right.kind
-	})
-	return ans
-}
-
-// FindLiteralBefore locates the first preceding string literal
-// returning its position and length in buf
-// or returns -1 if there is none.
-// Assume double-quoted string rather than backquoted string for now.
-func (p *Parsed) FindLiteralBefore(pos int) (int, int) {
-	left, right := -1, -1
-	for i := pos - 1; i >= 0; i-- {
-		if p.buf[i] != '"' {
-			continue
-		}
-		if right == -1 {
-			right = i
-			continue
-		}
-		left = i
-		break
-	}
-	if left == -1 {
-		return -1, 0
-	}
-	return left + 1, right - left - 1
-}
-
-var (
-	parseErrR = regexp.MustCompile(`template:.*function "([^"]+)" not defined`)
-)
-
-func (p *Parsed) setTokens() {
-	const (
-		// InRaw and InString only occur inside an action (SeenLeft)
-		Start = iota
-		InRaw
-		InString
-		SeenLeft
-	)
-	state := Start
-	var left, oldState int
-	for n := 0; n < len(p.buf); n++ {
-		c := p.buf[n]
-		switch state {
-		case InRaw:
-			if c == '`' {
-				state = oldState
-			}
-		case InString:
-			if c == '"' && !isEscaped(p.buf[:n]) {
-				state = oldState
-			}
-		case SeenLeft:
-			if c == '`' {
-				oldState = state // it's SeenLeft, but a little clearer this way
-				state = InRaw
-				continue
-			}
-			if c == '"' {
-				oldState = state
-				state = InString
-				continue
-			}
-			if bytes.HasPrefix(p.buf[n:], Right) {
-				right := n + len(Right)
-				tok := Token{Start: left,
-					End:       right,
-					Multiline: bytes.Contains(p.buf[left:right], []byte{'\n'}),
-				}
-				p.tokens = append(p.tokens, tok)
-				state = Start
-			}
-			// If we see (unquoted) Left then the original left is probably the user
-			// typing. Suppress the original left
-			if bytes.HasPrefix(p.buf[n:], Left) {
-				p.elideAt(left)
-				left = n
-				n += len(Left) - 1 // skip the rest
-			}
-		case Start:
-			if bytes.HasPrefix(p.buf[n:], Left) {
-				left = n
-				state = SeenLeft
-				n += len(Left) - 1 // skip the rest (avoids {{{ bug)
-			}
-		}
-	}
-	// this error occurs after typing {{ at the end of the file
-	if state != Start {
-		// Unclosed Left. remove the Left at left
-		p.elideAt(left)
-	}
-}
-
-func (p *Parsed) elideAt(left int) {
-	if p.elided == nil {
-		// p.buf is the same buffer that v.Read() returns, so copy it.
-		// (otherwise the next time it's parsed, elided information is lost)
-		b := make([]byte, len(p.buf))
-		copy(b, p.buf)
-		p.buf = b
-	}
-	for i := 0; i < len(Left); i++ {
-		p.buf[left+i] = ' '
-	}
-	p.elided = append(p.elided, left)
-}
-
-// isEscaped reports whether the byte after buf is escaped
-func isEscaped(buf []byte) bool {
-	backSlashes := 0
-	for j := len(buf) - 1; j >= 0 && buf[j] == '\\'; j-- {
-		backSlashes++
-	}
-	return backSlashes%2 == 1
-}
-
-func (p *Parsed) Tokens() []Token {
-	return p.tokens
-}
-
-func (p *Parsed) utf16len(buf []byte) int {
-	cnt := 0
-	if !p.nonASCII {
-		return len(buf)
-	}
-	// we need a utf16len(rune), but we don't have it
-	for _, r := range string(buf) {
-		cnt++
-		if r >= 1<<16 {
-			cnt++
-		}
-	}
-	return cnt
-}
-
-func (p *Parsed) TokenSize(t Token) (int, error) {
-	if t.Multiline {
-		return -1, fmt.Errorf("TokenSize called with Multiline token %#v", t)
-	}
-	ans := p.utf16len(p.buf[t.Start:t.End])
-	return ans, nil
-}
-
-// RuneCount counts runes in line l, from col s to e
-// (e==0 for end of line. called only for multiline tokens)
-func (p *Parsed) RuneCount(l, s, e uint32) uint32 {
-	start := p.nls[l] + 1 + int(s)
-	end := p.nls[l] + 1 + int(e)
-	if e == 0 || end > p.nls[l+1] {
-		end = p.nls[l+1]
-	}
-	return uint32(utf8.RuneCount(p.buf[start:end]))
-}
-
-// LineCol converts from a 0-based byte offset to 0-based line, col. col in runes
-func (p *Parsed) LineCol(x int) (uint32, uint32) {
-	if x < p.check {
-		p.lastnl = 0
-	}
-	p.check = x
-	for i := p.lastnl; i < len(p.nls); i++ {
-		if p.nls[i] <= x {
-			continue
-		}
-		p.lastnl = i
-		var count int
-		if i > 0 && x == p.nls[i-1] { // \n
-			count = 0
-		} else {
-			count = p.utf16len(p.buf[p.nls[i-1]+1 : x])
-		}
-		return uint32(i - 1), uint32(count)
-	}
-	if x == len(p.buf)-1 { // trailing \n
-		return uint32(len(p.nls) - 1), 0
-	}
-	// shouldn't happen
-	for i := 1; i < 4; i++ {
-		_, f, l, ok := runtime.Caller(i)
-		if !ok {
-			break
-		}
-		log.Printf("%d: %s:%d", i, f, l)
-	}
-
-	msg := fmt.Errorf("LineCol off the end, %d of %d, nls=%v, %q", x, len(p.buf), p.nls, p.buf[x:])
-	event.Error(context.Background(), "internal error", msg)
-	return 0, 0
-}
-
-// Position produces a protocol.Position from an offset in the template
-func (p *Parsed) Position(pos int) protocol.Position {
-	line, col := p.LineCol(pos)
-	return protocol.Position{Line: line, Character: col}
-}
-
-func (p *Parsed) Range(x, length int) protocol.Range {
-	line, col := p.LineCol(x)
-	ans := protocol.Range{
-		Start: protocol.Position{Line: line, Character: col},
-		End:   protocol.Position{Line: line, Character: col + uint32(length)},
-	}
-	return ans
-}
-
-// FromPosition translates a protocol.Position into an offset into the template
-func (p *Parsed) FromPosition(x protocol.Position) int {
-	l, c := int(x.Line), int(x.Character)
-	if l >= len(p.nls) || p.nls[l]+1 >= len(p.buf) {
-		// paranoia to avoid panic. return the largest offset
-		return len(p.buf)
-	}
-	line := p.buf[p.nls[l]+1:]
-	cnt := 0
-	for w := range string(line) {
-		if cnt >= c {
-			return w + p.nls[l] + 1
-		}
-		cnt++
-	}
-	// do we get here? NO
-	pos := int(x.Character) + p.nls[int(x.Line)] + 1
-	event.Error(context.Background(), "internal error", fmt.Errorf("surprise %#v", x))
-	return pos
-}
-
-func symAtPosition(fh source.FileHandle, loc protocol.Position) (*symbol, *Parsed, error) {
-	buf, err := fh.Read()
-	if err != nil {
-		return nil, nil, err
-	}
-	p := parseBuffer(buf)
-	pos := p.FromPosition(loc)
-	syms := p.SymsAtPos(pos)
-	if len(syms) == 0 {
-		return nil, p, fmt.Errorf("no symbol found")
-	}
-	if len(syms) > 1 {
-		log.Printf("Hover: %d syms, not 1 %v", len(syms), syms)
-	}
-	sym := syms[0]
-	return &sym, p, nil
-}
-
-func (p *Parsed) SymsAtPos(pos int) []symbol {
-	ans := []symbol{}
-	for _, s := range p.symbols {
-		if s.start <= pos && pos < s.start+s.length {
-			ans = append(ans, s)
-		}
-	}
-	return ans
-}
-
-type wrNode struct {
-	p *Parsed
-	w io.Writer
-}
-
-// WriteNode is for debugging
-func (p *Parsed) WriteNode(w io.Writer, n parse.Node) {
-	wr := wrNode{p: p, w: w}
-	wr.writeNode(n, "")
-}
-
-func (wr wrNode) writeNode(n parse.Node, indent string) {
-	if n == nil {
-		return
-	}
-	at := func(pos parse.Pos) string {
-		line, col := wr.p.LineCol(int(pos))
-		return fmt.Sprintf("(%d)%v:%v", pos, line, col)
-	}
-	switch x := n.(type) {
-	case *parse.ActionNode:
-		fmt.Fprintf(wr.w, "%sActionNode at %s\n", indent, at(x.Pos))
-		wr.writeNode(x.Pipe, indent+". ")
-	case *parse.BoolNode:
-		fmt.Fprintf(wr.w, "%sBoolNode at %s, %v\n", indent, at(x.Pos), x.True)
-	case *parse.BranchNode:
-		fmt.Fprintf(wr.w, "%sBranchNode at %s\n", indent, at(x.Pos))
-		wr.writeNode(x.Pipe, indent+"Pipe. ")
-		wr.writeNode(x.List, indent+"List. ")
-		wr.writeNode(x.ElseList, indent+"Else. ")
-	case *parse.ChainNode:
-		fmt.Fprintf(wr.w, "%sChainNode at %s, %v\n", indent, at(x.Pos), x.Field)
-	case *parse.CommandNode:
-		fmt.Fprintf(wr.w, "%sCommandNode at %s, %d children\n", indent, at(x.Pos), len(x.Args))
-		for _, a := range x.Args {
-			wr.writeNode(a, indent+". ")
-		}
-	//case *parse.CommentNode: // 1.16
-	case *parse.DotNode:
-		fmt.Fprintf(wr.w, "%sDotNode at %s\n", indent, at(x.Pos))
-	case *parse.FieldNode:
-		fmt.Fprintf(wr.w, "%sFieldNode at %s, %v\n", indent, at(x.Pos), x.Ident)
-	case *parse.IdentifierNode:
-		fmt.Fprintf(wr.w, "%sIdentifierNode at %s, %v\n", indent, at(x.Pos), x.Ident)
-	case *parse.IfNode:
-		fmt.Fprintf(wr.w, "%sIfNode at %s\n", indent, at(x.Pos))
-		wr.writeNode(&x.BranchNode, indent+". ")
-	case *parse.ListNode:
-		if x == nil {
-			return // nil BranchNode.ElseList
-		}
-		fmt.Fprintf(wr.w, "%sListNode at %s, %d children\n", indent, at(x.Pos), len(x.Nodes))
-		for _, n := range x.Nodes {
-			wr.writeNode(n, indent+". ")
-		}
-	case *parse.NilNode:
-		fmt.Fprintf(wr.w, "%sNilNode at %s\n", indent, at(x.Pos))
-	case *parse.NumberNode:
-		fmt.Fprintf(wr.w, "%sNumberNode at %s, %s\n", indent, at(x.Pos), x.Text)
-	case *parse.PipeNode:
-		if x == nil {
-			return // {{template "xxx"}}
-		}
-		fmt.Fprintf(wr.w, "%sPipeNode at %s, %d vars, %d cmds, IsAssign:%v\n",
-			indent, at(x.Pos), len(x.Decl), len(x.Cmds), x.IsAssign)
-		for _, d := range x.Decl {
-			wr.writeNode(d, indent+"Decl. ")
-		}
-		for _, c := range x.Cmds {
-			wr.writeNode(c, indent+"Cmd. ")
-		}
-	case *parse.RangeNode:
-		fmt.Fprintf(wr.w, "%sRangeNode at %s\n", indent, at(x.Pos))
-		wr.writeNode(&x.BranchNode, indent+". ")
-	case *parse.StringNode:
-		fmt.Fprintf(wr.w, "%sStringNode at %s, %s\n", indent, at(x.Pos), x.Quoted)
-	case *parse.TemplateNode:
-		fmt.Fprintf(wr.w, "%sTemplateNode at %s, %s\n", indent, at(x.Pos), x.Name)
-		wr.writeNode(x.Pipe, indent+". ")
-	case *parse.TextNode:
-		fmt.Fprintf(wr.w, "%sTextNode at %s, len %d\n", indent, at(x.Pos), len(x.Text))
-	case *parse.VariableNode:
-		fmt.Fprintf(wr.w, "%sVariableNode at %s, %v\n", indent, at(x.Pos), x.Ident)
-	case *parse.WithNode:
-		fmt.Fprintf(wr.w, "%sWithNode at %s\n", indent, at(x.Pos))
-		wr.writeNode(&x.BranchNode, indent+". ")
-	}
-}
-
-var kindNames = []string{"", "File", "Module", "Namespace", "Package", "Class", "Method", "Property",
-	"Field", "Constructor", "Enum", "Interface", "Function", "Variable", "Constant", "String",
-	"Number", "Boolean", "Array", "Object", "Key", "Null", "EnumMember", "Struct", "Event",
-	"Operator", "TypeParameter"}
-
-func kindStr(k protocol.SymbolKind) string {
-	n := int(k)
-	if n < 1 || n >= len(kindNames) {
-		return fmt.Sprintf("?SymbolKind %d?", n)
-	}
-	return kindNames[n]
-}
diff -urN a/gopls/internal/lsp/template/parse_test.go b/gopls/internal/lsp/template/parse_test.go
--- a/gopls/internal/lsp/template/parse_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/parse_test.go	1969-12-31 16:00:00
@@ -1,238 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"strings"
-	"testing"
-)
-
-type datum struct {
-	buf  string
-	cnt  int
-	syms []string // the symbols in the parse of buf
-}
-
-var tmpl = []datum{{`
-{{if (foo .X.Y)}}{{$A := "hi"}}{{.Z $A}}{{else}}
-{{$A.X 12}}
-{{foo (.X.Y) 23 ($A.Zü)}}
-{{end}}`, 1, []string{"{7,3,foo,Function,false}", "{12,1,X,Method,false}",
-	"{14,1,Y,Method,false}", "{21,2,$A,Variable,true}", "{26,2,,String,false}",
-	"{35,1,Z,Method,false}", "{38,2,$A,Variable,false}",
-	"{53,2,$A,Variable,false}", "{56,1,X,Method,false}", "{57,2,,Number,false}",
-	"{64,3,foo,Function,false}", "{70,1,X,Method,false}",
-	"{72,1,Y,Method,false}", "{75,2,,Number,false}", "{80,2,$A,Variable,false}",
-	"{83,2,Zü,Method,false}", "{94,3,,Constant,false}"}},
-
-	{`{{define "zzz"}}{{.}}{{end}}
-{{template "zzz"}}`, 2, []string{"{10,3,zzz,Namespace,true}", "{18,1,dot,Variable,false}",
-		"{41,3,zzz,Package,false}"}},
-
-	{`{{block "aaa" foo}}b{{end}}`, 2, []string{"{9,3,aaa,Namespace,true}",
-		"{9,3,aaa,Package,false}", "{14,3,foo,Function,false}", "{19,1,,Constant,false}"}},
-	{"", 0, nil},
-}
-
-func TestSymbols(t *testing.T) {
-	for i, x := range tmpl {
-		got := parseBuffer([]byte(x.buf))
-		if got.ParseErr != nil {
-			t.Errorf("error:%v", got.ParseErr)
-			continue
-		}
-		if len(got.named) != x.cnt {
-			t.Errorf("%d: got %d, expected %d", i, len(got.named), x.cnt)
-		}
-		for n, s := range got.symbols {
-			if s.String() != x.syms[n] {
-				t.Errorf("%d: got %s, expected %s", i, s.String(), x.syms[n])
-			}
-		}
-	}
-}
-
-func TestWordAt(t *testing.T) {
-	want := []string{"", "", "$A", "$A", "", "", "", "", "", "",
-		"", "", "", "if", "if", "", "$A", "$A", "", "",
-		"B", "", "", "end", "end", "end", "", "", ""}
-	p := parseBuffer([]byte("{{$A := .}}{{if $A}}B{{end}}"))
-	for i := 0; i < len(p.buf); i++ {
-		got := findWordAt(p, i)
-		if got != want[i] {
-			t.Errorf("for %d, got %q, wanted %q", i, got, want[i])
-		}
-	}
-}
-
-func TestNLS(t *testing.T) {
-	buf := `{{if (foÜx .X.Y)}}{{$A := "hi"}}{{.Z $A}}{{else}}
-	{{$A.X 12}}
-	{{foo (.X.Y) 23 ($A.Z)}}
-	{{end}}
-	`
-	p := parseBuffer([]byte(buf))
-	if p.ParseErr != nil {
-		t.Fatal(p.ParseErr)
-	}
-	// line 0 doesn't have a \n in front of it
-	for i := 1; i < len(p.nls)-1; i++ {
-		if buf[p.nls[i]] != '\n' {
-			t.Errorf("line %d got %c", i, buf[p.nls[i]])
-		}
-	}
-	// fake line at end of file
-	if p.nls[len(p.nls)-1] != len(buf) {
-		t.Errorf("got %d expected %d", p.nls[len(p.nls)-1], len(buf))
-	}
-}
-
-func TestLineCol(t *testing.T) {
-	buf := `{{if (foÜx .X.Y)}}{{$A := "hi"}}{{.Z $A}}{{else}}
-	{{$A.X 12}}
-	{{foo (.X.Y) 23 ($A.Z)}}
-	{{end}}`
-	if false {
-		t.Error(buf)
-	}
-	for n, cx := range tmpl {
-		buf := cx.buf
-		p := parseBuffer([]byte(buf))
-		if p.ParseErr != nil {
-			t.Fatal(p.ParseErr)
-		}
-		type loc struct {
-			offset int
-			l, c   uint32
-		}
-		saved := []loc{}
-		// forwards
-		var lastl, lastc uint32
-		for offset := range buf {
-			l, c := p.LineCol(offset)
-			saved = append(saved, loc{offset, l, c})
-			if l > lastl {
-				lastl = l
-				if c != 0 {
-					t.Errorf("line %d, got %d instead of 0", l, c)
-				}
-			}
-			if c > lastc {
-				lastc = c
-			}
-		}
-		lines := strings.Split(buf, "\n")
-		mxlen := -1
-		for _, l := range lines {
-			if len(l) > mxlen {
-				mxlen = len(l)
-			}
-		}
-		if int(lastl) != len(lines)-1 && int(lastc) != mxlen {
-			// lastl is 0 if there is only 1 line(?)
-			t.Errorf("expected %d, %d, got %d, %d for case %d", len(lines)-1, mxlen, lastl, lastc, n)
-		}
-		// backwards
-		for j := len(saved) - 1; j >= 0; j-- {
-			s := saved[j]
-			xl, xc := p.LineCol(s.offset)
-			if xl != s.l || xc != s.c {
-				t.Errorf("at offset %d(%d), got (%d,%d), expected (%d,%d)", s.offset, j, xl, xc, s.l, s.c)
-			}
-		}
-	}
-}
-
-func TestLineColNL(t *testing.T) {
-	buf := "\n\n\n\n\n"
-	p := parseBuffer([]byte(buf))
-	if p.ParseErr != nil {
-		t.Fatal(p.ParseErr)
-	}
-	for i := 0; i < len(buf); i++ {
-		l, c := p.LineCol(i)
-		if c != 0 || int(l) != i+1 {
-			t.Errorf("got (%d,%d), expected (%d,0)", l, c, i)
-		}
-	}
-}
-
-func TestPos(t *testing.T) {
-	buf := `
-	{{if (foÜx .X.Y)}}{{$A := "hi"}}{{.Z $A}}{{else}}
-	{{$A.X 12}}
-	{{foo (.X.Y) 23 ($A.Z)}}
-	{{end}}`
-	p := parseBuffer([]byte(buf))
-	if p.ParseErr != nil {
-		t.Fatal(p.ParseErr)
-	}
-	for pos, r := range buf {
-		if r == '\n' {
-			continue
-		}
-		x := p.Position(pos)
-		n := p.FromPosition(x)
-		if n != pos {
-			// once it's wrong, it will be wrong forever
-			t.Fatalf("at pos %d (rune %c) got %d {%#v]", pos, r, n, x)
-		}
-
-	}
-}
-func TestLen(t *testing.T) {
-	data := []struct {
-		cnt int
-		v   string
-	}{{1, "a"}, {1, "膈"}, {4, "😆🥸"}, {7, "3😀4567"}}
-	p := &Parsed{nonASCII: true}
-	for _, d := range data {
-		got := p.utf16len([]byte(d.v))
-		if got != d.cnt {
-			t.Errorf("%v, got %d wanted %d", d, got, d.cnt)
-		}
-	}
-}
-
-func TestUtf16(t *testing.T) {
-	buf := `
-	{{if (foÜx .X.Y)}}😀{{$A := "hi"}}{{.Z $A}}{{else}}
-	{{$A.X 12}}
-	{{foo (.X.Y) 23 ($A.Z)}}
-	{{end}}`
-	p := parseBuffer([]byte(buf))
-	if p.nonASCII == false {
-		t.Error("expected nonASCII to be true")
-	}
-}
-
-type ttest struct {
-	tmpl      string
-	tokCnt    int
-	elidedCnt int8
-}
-
-func TestQuotes(t *testing.T) {
-	tsts := []ttest{
-		{"{{- /*comment*/ -}}", 1, 0},
-		{"{{/*`\ncomment\n`*/}}", 1, 0},
-		//{"{{foo\nbar}}\n", 1, 0}, // this action spanning lines parses in 1.16
-		{"{{\"{{foo}}{{\"}}", 1, 0},
-		{"{{\n{{- when}}", 1, 1},          // corrected
-		{"{{{{if .}}xx{{\n{{end}}", 2, 2}, // corrected
-	}
-	for _, s := range tsts {
-		p := parseBuffer([]byte(s.tmpl))
-		if len(p.tokens) != s.tokCnt {
-			t.Errorf("%q: got %d tokens, expected %d", s, len(p.tokens), s.tokCnt)
-		}
-		if p.ParseErr != nil {
-			t.Errorf("%q: %v", string(p.buf), p.ParseErr)
-		}
-		if len(p.elided) != int(s.elidedCnt) {
-			t.Errorf("%q: elided %d, expected %d", s, len(p.elided), s.elidedCnt)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/template/symbols.go b/gopls/internal/lsp/template/symbols.go
--- a/gopls/internal/lsp/template/symbols.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/template/symbols.go	1969-12-31 16:00:00
@@ -1,230 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"text/template/parse"
-	"unicode/utf8"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-// in local coordinates, to be translated to protocol.DocumentSymbol
-type symbol struct {
-	start  int // for sorting
-	length int // in runes (unicode code points)
-	name   string
-	kind   protocol.SymbolKind
-	vardef bool // is this a variable definition?
-	// do we care about selection range, or children?
-	// no children yet, and selection range is the same as range
-}
-
-func (s symbol) String() string {
-	return fmt.Sprintf("{%d,%d,%s,%s,%v}", s.start, s.length, s.name, s.kind, s.vardef)
-}
-
-// for FieldNode or VariableNode (or ChainNode?)
-func (p *Parsed) fields(flds []string, x parse.Node) []symbol {
-	ans := []symbol{}
-	// guessing that there are no embedded blanks allowed. The doc is unclear
-	lookfor := ""
-	switch x.(type) {
-	case *parse.FieldNode:
-		for _, f := range flds {
-			lookfor += "." + f // quadratic, but probably ok
-		}
-	case *parse.VariableNode:
-		lookfor = flds[0]
-		for i := 1; i < len(flds); i++ {
-			lookfor += "." + flds[i]
-		}
-	case *parse.ChainNode: // PJW, what are these?
-		for _, f := range flds {
-			lookfor += "." + f // quadratic, but probably ok
-		}
-	default:
-		// If these happen they will happen even if gopls is restarted
-		// and the users does the same thing, so it is better not to panic.
-		// context.Background() is used because we don't have access
-		// to any other context. [we could, but it would be complicated]
-		event.Log(context.Background(), fmt.Sprintf("%T unexpected in fields()", x))
-		return nil
-	}
-	if len(lookfor) == 0 {
-		event.Log(context.Background(), fmt.Sprintf("no strings in fields() %#v", x))
-		return nil
-	}
-	startsAt := int(x.Position())
-	ix := bytes.Index(p.buf[startsAt:], []byte(lookfor)) // HasPrefix? PJW?
-	if ix < 0 || ix > len(lookfor) {                     // lookfor expected to be at start (or so)
-		// probably golang.go/#43388, so back up
-		startsAt -= len(flds[0]) + 1
-		ix = bytes.Index(p.buf[startsAt:], []byte(lookfor)) // ix might be 1? PJW
-		if ix < 0 {
-			return ans
-		}
-	}
-	at := ix + startsAt
-	for _, f := range flds {
-		at += 1 // .
-		kind := protocol.Method
-		if f[0] == '$' {
-			kind = protocol.Variable
-		}
-		sym := symbol{name: f, kind: kind, start: at, length: utf8.RuneCount([]byte(f))}
-		if kind == protocol.Variable && len(p.stack) > 1 {
-			if pipe, ok := p.stack[len(p.stack)-2].(*parse.PipeNode); ok {
-				for _, y := range pipe.Decl {
-					if x == y {
-						sym.vardef = true
-					}
-				}
-			}
-		}
-		ans = append(ans, sym)
-		at += len(f)
-	}
-	return ans
-}
-
-func (p *Parsed) findSymbols() {
-	if len(p.stack) == 0 {
-		return
-	}
-	n := p.stack[len(p.stack)-1]
-	pop := func() {
-		p.stack = p.stack[:len(p.stack)-1]
-	}
-	if n == nil { // allowing nil simplifies the code
-		pop()
-		return
-	}
-	nxt := func(nd parse.Node) {
-		p.stack = append(p.stack, nd)
-		p.findSymbols()
-	}
-	switch x := n.(type) {
-	case *parse.ActionNode:
-		nxt(x.Pipe)
-	case *parse.BoolNode:
-		// need to compute the length from the value
-		msg := fmt.Sprintf("%v", x.True)
-		p.symbols = append(p.symbols, symbol{start: int(x.Pos), length: len(msg), kind: protocol.Boolean})
-	case *parse.BranchNode:
-		nxt(x.Pipe)
-		nxt(x.List)
-		nxt(x.ElseList)
-	case *parse.ChainNode:
-		p.symbols = append(p.symbols, p.fields(x.Field, x)...)
-		nxt(x.Node)
-	case *parse.CommandNode:
-		for _, a := range x.Args {
-			nxt(a)
-		}
-	//case *parse.CommentNode: // go 1.16
-	//	log.Printf("implement %d", x.Type())
-	case *parse.DotNode:
-		sym := symbol{name: "dot", kind: protocol.Variable, start: int(x.Pos), length: 1}
-		p.symbols = append(p.symbols, sym)
-	case *parse.FieldNode:
-		p.symbols = append(p.symbols, p.fields(x.Ident, x)...)
-	case *parse.IdentifierNode:
-		sym := symbol{name: x.Ident, kind: protocol.Function, start: int(x.Pos),
-			length: utf8.RuneCount([]byte(x.Ident))}
-		p.symbols = append(p.symbols, sym)
-	case *parse.IfNode:
-		nxt(&x.BranchNode)
-	case *parse.ListNode:
-		if x != nil { // wretched typed nils. Node should have an IfNil
-			for _, nd := range x.Nodes {
-				nxt(nd)
-			}
-		}
-	case *parse.NilNode:
-		sym := symbol{name: "nil", kind: protocol.Constant, start: int(x.Pos), length: 3}
-		p.symbols = append(p.symbols, sym)
-	case *parse.NumberNode:
-		// no name; ascii
-		p.symbols = append(p.symbols, symbol{start: int(x.Pos), length: len(x.Text), kind: protocol.Number})
-	case *parse.PipeNode:
-		if x == nil { // {{template "foo"}}
-			return
-		}
-		for _, d := range x.Decl {
-			nxt(d)
-		}
-		for _, c := range x.Cmds {
-			nxt(c)
-		}
-	case *parse.RangeNode:
-		nxt(&x.BranchNode)
-	case *parse.StringNode:
-		// no name
-		sz := utf8.RuneCount([]byte(x.Text))
-		p.symbols = append(p.symbols, symbol{start: int(x.Pos), length: sz, kind: protocol.String})
-	case *parse.TemplateNode: // invoking a template
-		// x.Pos points to the quote before the name
-		p.symbols = append(p.symbols, symbol{name: x.Name, kind: protocol.Package, start: int(x.Pos) + 1,
-			length: utf8.RuneCount([]byte(x.Name))})
-		nxt(x.Pipe)
-	case *parse.TextNode:
-		if len(x.Text) == 1 && x.Text[0] == '\n' {
-			break
-		}
-		// nothing to report, but build one for hover
-		sz := utf8.RuneCount([]byte(x.Text))
-		p.symbols = append(p.symbols, symbol{start: int(x.Pos), length: sz, kind: protocol.Constant})
-	case *parse.VariableNode:
-		p.symbols = append(p.symbols, p.fields(x.Ident, x)...)
-	case *parse.WithNode:
-		nxt(&x.BranchNode)
-
-	}
-	pop()
-}
-
-// DocumentSymbols returns a hierarchy of the symbols defined in a template file.
-// (The hierarchy is flat. SymbolInformation might be better.)
-func DocumentSymbols(snapshot source.Snapshot, fh source.FileHandle) ([]protocol.DocumentSymbol, error) {
-	buf, err := fh.Read()
-	if err != nil {
-		return nil, err
-	}
-	p := parseBuffer(buf)
-	if p.ParseErr != nil {
-		return nil, p.ParseErr
-	}
-	var ans []protocol.DocumentSymbol
-	for _, s := range p.symbols {
-		if s.kind == protocol.Constant {
-			continue
-		}
-		d := kindStr(s.kind)
-		if d == "Namespace" {
-			d = "Template"
-		}
-		if s.vardef {
-			d += "(def)"
-		} else {
-			d += "(use)"
-		}
-		r := p.Range(s.start, s.length)
-		y := protocol.DocumentSymbol{
-			Name:           s.name,
-			Detail:         d,
-			Kind:           s.kind,
-			Range:          r,
-			SelectionRange: r, // or should this be the entire {{...}}?
-		}
-		ans = append(ans, y)
-	}
-	return ans, nil
-}
diff -urN a/gopls/internal/lsp/testdata/%percent/perc%ent.go b/gopls/internal/lsp/testdata/%percent/perc%ent.go
--- a/gopls/internal/lsp/testdata/%percent/perc%ent.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/%percent/perc%ent.go	1969-12-31 16:00:00
@@ -1 +0,0 @@
-package percent
diff -urN a/gopls/internal/lsp/testdata/addimport/addimport.go.golden b/gopls/internal/lsp/testdata/addimport/addimport.go.golden
--- a/gopls/internal/lsp/testdata/addimport/addimport.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/addimport/addimport.go.golden	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
--- addimport --
-package addimport //@addimport("", "bytes")
-
-import "bytes"
-
-func main() {}
-
diff -urN a/gopls/internal/lsp/testdata/addimport/addimport.go.in b/gopls/internal/lsp/testdata/addimport/addimport.go.in
--- a/gopls/internal/lsp/testdata/addimport/addimport.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/addimport/addimport.go.in	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
-package addimport //@addimport("", "bytes")
-
-func main() {}
diff -urN a/gopls/internal/lsp/testdata/address/address.go b/gopls/internal/lsp/testdata/address/address.go
--- a/gopls/internal/lsp/testdata/address/address.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/address/address.go	1969-12-31 16:00:00
@@ -1,78 +0,0 @@
-package address
-
-func wantsPtr(*int)            {}
-func wantsVariadicPtr(...*int) {}
-
-func wantsVariadic(...int) {}
-
-type foo struct{ c int } //@item(addrFieldC, "c", "int", "field")
-
-func _() {
-	var (
-		a string //@item(addrA, "a", "string", "var")
-		b int    //@item(addrB, "b", "int", "var")
-	)
-
-	wantsPtr()   //@rank(")", addrB, addrA),snippet(")", addrB, "&b", "&b")
-	wantsPtr(&b) //@snippet(")", addrB, "b", "b")
-
-	wantsVariadicPtr() //@rank(")", addrB, addrA),snippet(")", addrB, "&b", "&b")
-
-	var s foo
-	s.c          //@item(addrDeepC, "s.c", "int", "field")
-	wantsPtr()   //@snippet(")", addrDeepC, "&s.c", "&s.c")
-	wantsPtr(s)  //@snippet(")", addrDeepC, "&s.c", "&s.c")
-	wantsPtr(&s) //@snippet(")", addrDeepC, "s.c", "s.c")
-
-	// don't add "&" in item (it gets added as an additional edit)
-	wantsPtr(&s.c) //@snippet(")", addrFieldC, "c", "c")
-
-	// check dereferencing as well
-	var c *int    //@item(addrCPtr, "c", "*int", "var")
-	var _ int = _ //@rank("_ //", addrCPtr, addrA),snippet("_ //", addrCPtr, "*c", "*c")
-
-	wantsVariadic() //@rank(")", addrCPtr, addrA),snippet(")", addrCPtr, "*c", "*c")
-
-	var d **int   //@item(addrDPtr, "d", "**int", "var")
-	var _ int = _ //@rank("_ //", addrDPtr, addrA),snippet("_ //", addrDPtr, "**d", "**d")
-
-	type namedPtr *int
-	var np namedPtr //@item(addrNamedPtr, "np", "namedPtr", "var")
-
-	var _ int = _ //@rank("_ //", addrNamedPtr, addrA)
-
-	// don't get tripped up by recursive pointer type
-	type dontMessUp *dontMessUp
-	var dmu *dontMessUp //@item(addrDMU, "dmu", "*dontMessUp", "var")
-
-	var _ int = dmu //@complete(" //", addrDMU)
-}
-
-func (f foo) ptr() *foo { return &f }
-
-func _() {
-	getFoo := func() foo { return foo{} }
-
-	// not addressable
-	getFoo().c //@item(addrGetFooC, "getFoo().c", "int", "field")
-
-	// addressable
-	getFoo().ptr().c //@item(addrGetFooPtrC, "getFoo().ptr().c", "int", "field")
-
-	wantsPtr()   //@rank(addrGetFooPtrC, addrGetFooC),snippet(")", addrGetFooPtrC, "&getFoo().ptr().c", "&getFoo().ptr().c")
-	wantsPtr(&g) //@rank(addrGetFooPtrC, addrGetFooC),snippet(")", addrGetFooPtrC, "getFoo().ptr().c", "getFoo().ptr().c")
-}
-
-type nested struct {
-	f foo
-}
-
-func _() {
-	getNested := func() nested { return nested{} }
-
-	getNested().f.c       //@item(addrNestedC, "getNested().f.c", "int", "field")
-	getNested().f.ptr().c //@item(addrNestedPtrC, "getNested().f.ptr().c", "int", "field")
-
-	// addrNestedC is not addressable, so rank lower
-	wantsPtr(getNestedfc) //@fuzzy(")", addrNestedPtrC, addrNestedC)
-}
diff -urN a/gopls/internal/lsp/testdata/analyzer/bad_test.go b/gopls/internal/lsp/testdata/analyzer/bad_test.go
--- a/gopls/internal/lsp/testdata/analyzer/bad_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/analyzer/bad_test.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-package analyzer
-
-import (
-	"fmt"
-	"sync"
-	"testing"
-	"time"
-)
-
-func Testbad(t *testing.T) { //@diag("", "tests", "Testbad has malformed name: first letter after 'Test' must not be lowercase", "warning")
-	var x sync.Mutex
-	_ = x //@diag("x", "copylocks", "assignment copies lock value to _: sync.Mutex", "warning")
-
-	printfWrapper("%s") //@diag(re`printfWrapper\(.*\)`, "printf", "golang.org/lsptests/analyzer.printfWrapper format %s reads arg #1, but call has 0 args", "warning")
-}
-
-func printfWrapper(format string, args ...interface{}) {
-	fmt.Printf(format, args...)
-}
-
-func _() {
-	now := time.Now()
-	fmt.Println(now.Format("2006-02-01")) //@diag("2006-02-01", "timeformat", "2006-02-01 should be 2006-01-02", "warning")
-}
diff -urN a/gopls/internal/lsp/testdata/anon/anon.go.in b/gopls/internal/lsp/testdata/anon/anon.go.in
--- a/gopls/internal/lsp/testdata/anon/anon.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/anon/anon.go.in	1969-12-31 16:00:00
@@ -1,23 +0,0 @@
-package anon
-
-func _() {
-	for _, _ := range []struct {
-		i, j int //@item(anonI, "i", "int", "field"),item(anonJ, "j", "int", "field")
-	}{
-		{
-			i: 1,
-			//@complete("", anonJ)
-		},
-		{
-			//@complete("", anonI, anonJ)
-		},
-	} {
-		continue
-	}
-
-	s := struct{ f int }{  } //@item(anonF, "f", "int", "field"),item(structS, "s", "struct{...}", "var"),complete("  }", anonF)
-
-	_ = map[struct{ x int }]int{ //@item(anonX, "x", "int", "field")
-		struct{ x int }{  }: 1, //@complete("  }", anonX, structS)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/append/append.go b/gopls/internal/lsp/testdata/append/append.go
--- a/gopls/internal/lsp/testdata/append/append.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/append/append.go	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-package append
-
-func foo([]string)  {}
-func bar(...string) {}
-
-func _() {
-	var (
-		aInt     []int    //@item(appendInt, "aInt", "[]int", "var")
-		aStrings []string //@item(appendStrings, "aStrings", "[]string", "var")
-		aString  string   //@item(appendString, "aString", "string", "var")
-	)
-
-	append(aStrings, a)                     //@rank(")", appendString, appendInt)
-	var _ interface{} = append(aStrings, a) //@rank(")", appendString, appendInt)
-	var _ []string = append(oops, a)        //@rank(")", appendString, appendInt)
-
-	foo(append())                  //@rank("))", appendStrings, appendInt),rank("))", appendStrings, appendString)
-	foo(append([]string{}, a))     //@rank("))", appendStrings, appendInt),rank("))", appendString, appendInt),snippet("))", appendStrings, "aStrings...", "aStrings...")
-	foo(append([]string{}, "", a)) //@rank("))", appendString, appendInt),rank("))", appendString, appendStrings)
-
-	// Don't add "..." to append() argument.
-	bar(append()) //@snippet("))", appendStrings, "aStrings", "aStrings")
-
-	type baz struct{}
-	baz{}                       //@item(appendBazLiteral, "baz{}", "", "var")
-	var bazzes []baz            //@item(appendBazzes, "bazzes", "[]baz", "var")
-	var bazzy baz               //@item(appendBazzy, "bazzy", "baz", "var")
-	bazzes = append(bazzes, ba) //@rank(")", appendBazzy, appendBazLiteral, appendBazzes)
-
-	var b struct{ b []baz }
-	b.b                  //@item(appendNestedBaz, "b.b", "[]baz", "field")
-	b.b = append(b.b, b) //@rank(")", appendBazzy, appendBazLiteral, appendNestedBaz)
-
-	var aStringsPtr *[]string  //@item(appendStringsPtr, "aStringsPtr", "*[]string", "var")
-	foo(append([]string{}, a)) //@snippet("))", appendStringsPtr, "*aStringsPtr...", "*aStringsPtr...")
-
-	foo(append([]string{}, *a)) //@snippet("))", appendStringsPtr, "aStringsPtr...", "aStringsPtr...")
-}
diff -urN a/gopls/internal/lsp/testdata/append/append2.go.in b/gopls/internal/lsp/testdata/append/append2.go.in
--- a/gopls/internal/lsp/testdata/append/append2.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/append/append2.go.in	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package append
-
-func _() {
-	_ = append(a, struct) //@complete(")")
-}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/arraytype/array_type.go.in b/gopls/internal/lsp/testdata/arraytype/array_type.go.in
--- a/gopls/internal/lsp/testdata/arraytype/array_type.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/arraytype/array_type.go.in	1969-12-31 16:00:00
@@ -1,50 +0,0 @@
-package arraytype
-
-import (
-	"golang.org/lsptests/foo"
-)
-
-func _() {
-	var (
-		val string //@item(atVal, "val", "string", "var")
-	)
-
-	// disabled - see issue #54822
-	[] // complete(" //", PackageFoo)
-
-	[]val //@complete(" //")
-
-	[]foo.StructFoo //@complete(" //", StructFoo)
-
-	[]foo.StructFoo(nil) //@complete("(", StructFoo)
-
-	[]*foo.StructFoo //@complete(" //", StructFoo)
-
-	[...]foo.StructFoo //@complete(" //", StructFoo)
-
-	[2][][4]foo.StructFoo //@complete(" //", StructFoo)
-
-	[]struct { f []foo.StructFoo } //@complete(" }", StructFoo)
-}
-
-func _() {
-	type myInt int //@item(atMyInt, "myInt", "int", "type")
-
-	var mark []myInt //@item(atMark, "mark", "[]myInt", "var")
-
-	var s []myInt //@item(atS, "s", "[]myInt", "var")
-	s = []m //@complete(" //", atMyInt)
-	// disabled - see issue #54822
-	s = [] // complete(" //", atMyInt, PackageFoo)
-
-	var a [1]myInt
-	a = [1]m //@complete(" //", atMyInt)
-
-	var ds [][]myInt
-	ds = [][]m //@complete(" //", atMyInt)
-}
-
-func _() {
-	var b [0]byte //@item(atByte, "b", "[0]byte", "var")
-	var _ []byte = b //@snippet(" //", atByte, "b[:]", "b[:]")
-}
diff -urN a/gopls/internal/lsp/testdata/assign/assign.go.in b/gopls/internal/lsp/testdata/assign/assign.go.in
--- a/gopls/internal/lsp/testdata/assign/assign.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/assign/assign.go.in	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-package assign
-
-import "golang.org/lsptests/assign/internal/secret"
-
-func _() {
-	secret.Hello()
-	var (
-		myInt int //@item(assignInt, "myInt", "int", "var")
-		myStr string //@item(assignStr, "myStr", "string", "var")
-	)
-
-	var _ string = my //@rank(" //", assignStr, assignInt)
-	var _ string = //@rank(" //", assignStr, assignInt)
-}
-
-func _() {
-	var a string = a //@complete(" //")
-}
-
-func _() {
-	fooBar := fooBa //@complete(" //"),item(assignFooBar, "fooBar", "", "var")
-	abc, fooBar := 123, fooBa //@complete(" //", assignFooBar)
-	{
-		fooBar := fooBa //@complete(" //", assignFooBar)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/assign/internal/secret/secret.go b/gopls/internal/lsp/testdata/assign/internal/secret/secret.go
--- a/gopls/internal/lsp/testdata/assign/internal/secret/secret.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/assign/internal/secret/secret.go	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
-package secret
-
-func Hello() {}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/bad/bad0.go b/gopls/internal/lsp/testdata/bad/bad0.go
--- a/gopls/internal/lsp/testdata/bad/bad0.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/bad/bad0.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-//go:build go1.11
-// +build go1.11
-
-package bad
-
-import _ "golang.org/lsptests/assign/internal/secret" //@diag("\"golang.org/lsptests/assign/internal/secret\"", "compiler", "could not import golang.org/lsptests/assign/internal/secret \\(invalid use of internal package golang.org/lsptests/assign/internal/secret\\)", "error")
-
-func stuff() { //@item(stuff, "stuff", "func()", "func")
-	x := "heeeeyyyy"
-	random2(x) //@diag("x", "compiler", "cannot use x \\(variable of type string\\) as int value in argument to random2", "error")
-	random2(1) //@complete("dom", random, random2, random3)
-	y := 3     //@diag("y", "compiler", "y declared (and|but) not used", "error")
-}
-
-type bob struct { //@item(bob, "bob", "struct{...}", "struct")
-	x int
-}
-
-func _() {
-	var q int
-	_ = &bob{
-		f: q, //@diag("f: q", "compiler", "unknown field f in struct literal", "error")
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/bad/bad1.go b/gopls/internal/lsp/testdata/bad/bad1.go
--- a/gopls/internal/lsp/testdata/bad/bad1.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/bad/bad1.go	1969-12-31 16:00:00
@@ -1,34 +0,0 @@
-//go:build go1.11
-// +build go1.11
-
-package bad
-
-// See #36637
-type stateFunc func() stateFunc //@item(stateFunc, "stateFunc", "func() stateFunc", "type")
-
-var a unknown //@item(global_a, "a", "unknown", "var"),diag("unknown", "compiler", "(undeclared name|undefined): unknown", "error")
-
-func random() int { //@item(random, "random", "func() int", "func")
-	//@complete("", global_a, bob, random, random2, random3, stateFunc, stuff)
-	return 0
-}
-
-func random2(y int) int { //@item(random2, "random2", "func(y int) int", "func"),item(bad_y_param, "y", "int", "var")
-	x := 6       //@item(x, "x", "int", "var"),diag("x", "compiler", "x declared (and|but) not used", "error")
-	var q blah   //@item(q, "q", "blah", "var"),diag("q", "compiler", "q declared (and|but) not used", "error"),diag("blah", "compiler", "(undeclared name|undefined): blah", "error")
-	var t **blob //@item(t, "t", "**blob", "var"),diag("t", "compiler", "t declared (and|but) not used", "error"),diag("blob", "compiler", "(undeclared name|undefined): blob", "error")
-	//@complete("", q, t, x, bad_y_param, global_a, bob, random, random2, random3, stateFunc, stuff)
-
-	return y
-}
-
-func random3(y ...int) { //@item(random3, "random3", "func(y ...int)", "func"),item(y_variadic_param, "y", "[]int", "var")
-	//@complete("", y_variadic_param, global_a, bob, random, random2, random3, stateFunc, stuff)
-
-	var ch chan (favType1)   //@item(ch, "ch", "chan (favType1)", "var"),diag("ch", "compiler", "ch declared (and|but) not used", "error"),diag("favType1", "compiler", "(undeclared name|undefined): favType1", "error")
-	var m map[keyType]int    //@item(m, "m", "map[keyType]int", "var"),diag("m", "compiler", "m declared (and|but) not used", "error"),diag("keyType", "compiler", "(undeclared name|undefined): keyType", "error")
-	var arr []favType2       //@item(arr, "arr", "[]favType2", "var"),diag("arr", "compiler", "arr declared (and|but) not used", "error"),diag("favType2", "compiler", "(undeclared name|undefined): favType2", "error")
-	var fn1 func() badResult //@item(fn1, "fn1", "func() badResult", "var"),diag("fn1", "compiler", "fn1 declared (and|but) not used", "error"),diag("badResult", "compiler", "(undeclared name|undefined): badResult", "error")
-	var fn2 func(badParam)   //@item(fn2, "fn2", "func(badParam)", "var"),diag("fn2", "compiler", "fn2 declared (and|but) not used", "error"),diag("badParam", "compiler", "(undeclared name|undefined): badParam", "error")
-	//@complete("", arr, ch, fn1, fn2, m, y_variadic_param, global_a, bob, random, random2, random3, stateFunc, stuff)
-}
diff -urN a/gopls/internal/lsp/testdata/badstmt/badstmt.go.in b/gopls/internal/lsp/testdata/badstmt/badstmt.go.in
--- a/gopls/internal/lsp/testdata/badstmt/badstmt.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/badstmt/badstmt.go.in	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-package badstmt
-
-import (
-	"golang.org/lsptests/foo"
-)
-
-// The nonewvars expectation asserts that the go/analysis framework ran.
-// See comments in noparse.
-
-func _(x int) {
-	defer foo.F //@complete(" //", Foo),diag(" //", "syntax", "function must be invoked in defer statement|expression in defer must be function call", "error")
-	defer foo.F //@complete(" //", Foo)
-	x := 123 //@diag(":=", "nonewvars", "no new variables", "warning")
-}
-
-func _() {
-	switch true {
-	case true:
-		go foo.F //@complete(" //", Foo)
-	}
-}
-
-func _() {
-	defer func() {
-		foo.F //@complete(" //", Foo),snippet(" //", Foo, "Foo()", "Foo()")
-
-		foo. //@rank(" //", Foo)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/badstmt/badstmt_2.go.in b/gopls/internal/lsp/testdata/badstmt/badstmt_2.go.in
--- a/gopls/internal/lsp/testdata/badstmt/badstmt_2.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/badstmt/badstmt_2.go.in	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package badstmt
-
-import (
-	"golang.org/lsptests/foo"
-)
-
-func _() {
-	defer func() { foo. } //@rank(" }", Foo)
-}
diff -urN a/gopls/internal/lsp/testdata/badstmt/badstmt_3.go.in b/gopls/internal/lsp/testdata/badstmt/badstmt_3.go.in
--- a/gopls/internal/lsp/testdata/badstmt/badstmt_3.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/badstmt/badstmt_3.go.in	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package badstmt
-
-import (
-	"golang.org/lsptests/foo"
-)
-
-func _() {
-	go foo. //@rank(" //", Foo, IntFoo),snippet(" //", Foo, "Foo()", "Foo()")
-}
diff -urN a/gopls/internal/lsp/testdata/badstmt/badstmt_4.go.in b/gopls/internal/lsp/testdata/badstmt/badstmt_4.go.in
--- a/gopls/internal/lsp/testdata/badstmt/badstmt_4.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/badstmt/badstmt_4.go.in	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package badstmt
-
-import (
-	"golang.org/lsptests/foo"
-)
-
-func _() {
-	go func() {
-		defer foo. //@rank(" //", Foo, IntFoo)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/bar/bar.go.in b/gopls/internal/lsp/testdata/bar/bar.go.in
--- a/gopls/internal/lsp/testdata/bar/bar.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/bar/bar.go.in	1969-12-31 16:00:00
@@ -1,47 +0,0 @@
-// +build go1.11
-
-package bar
-
-import (
-	"golang.org/lsptests/foo" //@item(foo, "foo", "\"golang.org/lsptests/foo\"", "package")
-)
-
-func helper(i foo.IntFoo) {} //@item(helper, "helper", "func(i foo.IntFoo)", "func")
-
-func _() {
-	help //@complete("l", helper)
-	_ = foo.StructFoo{} //@complete("S", IntFoo, StructFoo)
-}
-
-// Bar is a function.
-func Bar() { //@item(Bar, "Bar", "func()", "func", "Bar is a function.")
-	foo.Foo()        //@complete("F", Foo, IntFoo, StructFoo)
-	var _ foo.IntFoo //@complete("I", IntFoo, StructFoo)
-	foo.()           //@complete("(", Foo, IntFoo, StructFoo)
-}
-
-func _() {
-	var Valentine int //@item(Valentine, "Valentine", "int", "var")
-
-	_ = foo.StructFoo{
-		Valu //@complete(" //", Value)
-	}
-  	_ = foo.StructFoo{
-		Va        //@complete("a", Value, Valentine)
-	}
-	_ = foo.StructFoo{
-		Value: 5, //@complete("a", Value)
-	}
-	_ = foo.StructFoo{
-		//@complete("", Value, Valentine, foo, helper, Bar)
-	}
-	_ = foo.StructFoo{
-		Value: Valen //@complete("le", Valentine)
-	}
-	_ = foo.StructFoo{
-		Value:       //@complete(" //", Valentine, foo, helper, Bar)
-	}
-	_ = foo.StructFoo{
-		Value:       //@complete(" ", Valentine, foo, helper, Bar)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/basiclit/basiclit.go b/gopls/internal/lsp/testdata/basiclit/basiclit.go
--- a/gopls/internal/lsp/testdata/basiclit/basiclit.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/basiclit/basiclit.go	1969-12-31 16:00:00
@@ -1,56 +0,0 @@
-package basiclit
-
-func _() {
-	var a int // something for lexical completions
-
-	_ = "hello." //@complete(".")
-
-	_ = 1 //@complete(" //")
-
-	_ = 1. //@complete(".")
-
-	_ = 'a' //@complete("' ")
-
-	_ = 'a' //@hover("'a'", "'a', U+0061, LATIN SMALL LETTER A")
-	_ = 0x61 //@hover("0x61", "'a', U+0061, LATIN SMALL LETTER A")
-
-	_ = '\u2211' //@hover("'\\u2211'", "'∑', U+2211, N-ARY SUMMATION")
-	_ = 0x2211 //@hover("0x2211", "'∑', U+2211, N-ARY SUMMATION")
-	_ = "foo \u2211 bar" //@hover("\\u2211", "'∑', U+2211, N-ARY SUMMATION")
-
-	_ = '\a' //@hover("'\\a'", "U+0007, control")
-	_ = "foo \a bar" //@hover("\\a", "U+0007, control")
-
-	_ = '\U0001F30A' //@hover("'\\U0001F30A'", "'🌊', U+1F30A, WATER WAVE")
-	_ = 0x0001F30A //@hover("0x0001F30A", "'🌊', U+1F30A, WATER WAVE")
-	_ = "foo \U0001F30A bar" //@hover("\\U0001F30A", "'🌊', U+1F30A, WATER WAVE")
-
-	_ = '\x7E' //@hover("'\\x7E'", "'~', U+007E, TILDE")
-	_ = "foo \x7E bar" //@hover("\\x7E", "'~', U+007E, TILDE")
-	_ = "foo \a bar" //@hover("\\a", "U+0007, control")
-
-	_ = '\173' //@hover("'\\173'", "'{', U+007B, LEFT CURLY BRACKET")
-	_ = "foo \173 bar" //@hover("\\173", "'{', U+007B, LEFT CURLY BRACKET")
-	_ = "foo \173 bar \u2211 baz" //@hover("\\173", "'{', U+007B, LEFT CURLY BRACKET")
-	_ = "foo \173 bar \u2211 baz" //@hover("\\u2211", "'∑', U+2211, N-ARY SUMMATION")
-	_ = "foo\173bar\u2211baz" //@hover("\\173", "'{', U+007B, LEFT CURLY BRACKET")
-	_ = "foo\173bar\u2211baz" //@hover("\\u2211", "'∑', U+2211, N-ARY SUMMATION")
-
-	// search for runes in string only if there is an escaped sequence
-	_ = "hello" //@hover("\"hello\"", "")
-
-	// incorrect escaped rune sequences
-	_ = '\0' //@hover("'\\0'", "")
-	_ = '\u22111' //@hover("'\\u22111'", "")
-	_ = '\U00110000' //@hover("'\\U00110000'", "")
-	_ = '\u12e45'//@hover("'\\u12e45'", "")
-	_ = '\xa' //@hover("'\\xa'", "")
-	_ = 'aa' //@hover("'aa'", "")
-
-	// other basic lits
-	_ = 1 //@hover("1", "")
-	_ = 1.2 //@hover("1.2", "")
-	_ = 1.2i //@hover("1.2i", "")
-	_ = 0123 //@hover("0123", "")
-	_ = 0x1234567890 //@hover("0x1234567890", "")
-}
diff -urN a/gopls/internal/lsp/testdata/baz/baz.go.in b/gopls/internal/lsp/testdata/baz/baz.go.in
--- a/gopls/internal/lsp/testdata/baz/baz.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/baz/baz.go.in	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-// +build go1.11
-
-package baz
-
-import (
-	"golang.org/lsptests/bar"
-
-	f "golang.org/lsptests/foo"
-)
-
-var FooStruct f.StructFoo
-
-func Baz() {
-	defer bar.Bar() //@complete("B", Bar)
-	// TODO(rstambler): Test completion here.
-	defer bar.B
-	var x f.IntFoo  //@complete("n", IntFoo),typdef("x", IntFoo)
-	bar.Bar()       //@complete("B", Bar)
-}
-
-func _() {
-	bob := f.StructFoo{Value: 5}
-	if x := bob. //@complete(" //", Value)
-	switch true == false {
-		case true:
-			if x := bob. //@complete(" //", Value)
-		case false:
-	}
-	if x := bob.Va //@complete("a", Value)
-	switch true == true {
-		default:
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/builtins/builtin_args.go b/gopls/internal/lsp/testdata/builtins/builtin_args.go
--- a/gopls/internal/lsp/testdata/builtins/builtin_args.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/builtins/builtin_args.go	1969-12-31 16:00:00
@@ -1,62 +0,0 @@
-package builtins
-
-func _() {
-	var (
-		aSlice    []int          //@item(builtinSlice, "aSlice", "[]int", "var")
-		aMap      map[string]int //@item(builtinMap, "aMap", "map[string]int", "var")
-		aString   string         //@item(builtinString, "aString", "string", "var")
-		aArray    [0]int         //@item(builtinArray, "aArray", "[0]int", "var")
-		aArrayPtr *[0]int        //@item(builtinArrayPtr, "aArrayPtr", "*[0]int", "var")
-		aChan     chan int       //@item(builtinChan, "aChan", "chan int", "var")
-		aPtr      *int           //@item(builtinPtr, "aPtr", "*int", "var")
-		aInt      int            //@item(builtinInt, "aInt", "int", "var")
-	)
-
-	type (
-		aSliceType []int          //@item(builtinSliceType, "aSliceType", "[]int", "type")
-		aChanType  chan int       //@item(builtinChanType, "aChanType", "chan int", "type")
-		aMapType   map[string]int //@item(builtinMapType, "aMapType", "map[string]int", "type")
-	)
-
-	close() //@rank(")", builtinChan, builtinSlice)
-
-	append() //@rank(")", builtinSlice, builtinChan)
-
-	var _ []byte = append([]byte(nil), ""...) //@rank(") //")
-
-	copy()           //@rank(")", builtinSlice, builtinChan)
-	copy(aSlice, aS) //@rank(")", builtinSlice, builtinString)
-	copy(aS, aSlice) //@rank(",", builtinSlice, builtinString)
-
-	delete()         //@rank(")", builtinMap, builtinChan)
-	delete(aMap, aS) //@rank(")", builtinString, builtinSlice)
-
-	aMapFunc := func() map[int]int { //@item(builtinMapFunc, "aMapFunc", "func() map[int]int", "var")
-		return nil
-	}
-	delete() //@rank(")", builtinMapFunc, builtinSlice)
-
-	len() //@rank(")", builtinSlice, builtinInt),rank(")", builtinMap, builtinInt),rank(")", builtinString, builtinInt),rank(")", builtinArray, builtinInt),rank(")", builtinArrayPtr, builtinPtr),rank(")", builtinChan, builtinInt)
-
-	cap() //@rank(")", builtinSlice, builtinMap),rank(")", builtinArray, builtinString),rank(")", builtinArrayPtr, builtinPtr),rank(")", builtinChan, builtinInt)
-
-	make()              //@rank(")", builtinMapType, int),rank(")", builtinChanType, int),rank(")", builtinSliceType, int),rank(")", builtinMapType, int)
-	make(aSliceType, a) //@rank(")", builtinInt, builtinSlice)
-
-	type myInt int
-	var mi myInt        //@item(builtinMyInt, "mi", "myInt", "var")
-	make(aSliceType, m) //@snippet(")", builtinMyInt, "mi", "mi")
-
-	var _ []int = make() //@rank(")", builtinSliceType, builtinMapType)
-
-	type myStruct struct{}  //@item(builtinStructType, "myStruct", "struct{...}", "struct")
-	var _ *myStruct = new() //@rank(")", builtinStructType, int)
-
-	for k := range a { //@rank(" {", builtinSlice, builtinInt),rank(" {", builtinString, builtinInt),rank(" {", builtinChan, builtinInt),rank(" {", builtinArray, builtinInt),rank(" {", builtinArrayPtr, builtinInt),rank(" {", builtinMap, builtinInt),
-	}
-
-	for k, v := range a { //@rank(" {", builtinSlice, builtinChan)
-	}
-
-	<-a //@rank(" //", builtinChan, builtinInt)
-}
diff -urN a/gopls/internal/lsp/testdata/builtins/builtin_types.go b/gopls/internal/lsp/testdata/builtins/builtin_types.go
--- a/gopls/internal/lsp/testdata/builtins/builtin_types.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/builtins/builtin_types.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package builtins
-
-func _() {
-	var _ []bool //@item(builtinBoolSliceType, "[]bool", "[]bool", "type")
-
-	var _ []bool = make() //@rank(")", builtinBoolSliceType, int)
-
-	var _ []bool = make([], 0) //@rank(",", bool, int)
-
-	var _ [][]bool = make([][], 0) //@rank(",", bool, int)
-}
diff -urN a/gopls/internal/lsp/testdata/builtins/builtins.go b/gopls/internal/lsp/testdata/builtins/builtins.go
--- a/gopls/internal/lsp/testdata/builtins/builtins.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/builtins/builtins.go	1969-12-31 16:00:00
@@ -1,46 +0,0 @@
-package builtins
-
-func _() {
-	//@complete("", append, bool, byte, cap, close, complex, complex128, complex64, copy, delete, error, _false, float32, float64, imag, int, int16, int32, int64, int8, len, make, new, panic, print, println, real, recover, rune, string, _true, uint, uint16, uint32, uint64, uint8, uintptr, _nil)
-}
-
-/* Create markers for builtin types. Only for use by this test.
-/* append(slice []Type, elems ...Type) []Type */ //@item(append, "append", "func(slice []Type, elems ...Type) []Type", "func")
-/* bool */ //@item(bool, "bool", "", "type")
-/* byte */ //@item(byte, "byte", "", "type")
-/* cap(v Type) int */ //@item(cap, "cap", "func(v Type) int", "func")
-/* close(c chan<- Type) */ //@item(close, "close", "func(c chan<- Type)", "func")
-/* complex(r float64, i float64) */ //@item(complex, "complex", "func(r float64, i float64) complex128", "func")
-/* complex128 */ //@item(complex128, "complex128", "", "type")
-/* complex64 */ //@item(complex64, "complex64", "", "type")
-/* copy(dst []Type, src []Type) int */ //@item(copy, "copy", "func(dst []Type, src []Type) int", "func")
-/* delete(m map[Type]Type1, key Type) */ //@item(delete, "delete", "func(m map[Type]Type1, key Type)", "func")
-/* error */ //@item(error, "error", "", "interface")
-/* false */ //@item(_false, "false", "", "const")
-/* float32 */ //@item(float32, "float32", "", "type")
-/* float64 */ //@item(float64, "float64", "", "type")
-/* imag(c complex128) float64 */ //@item(imag, "imag", "func(c complex128) float64", "func")
-/* int */ //@item(int, "int", "", "type")
-/* int16 */ //@item(int16, "int16", "", "type")
-/* int32 */ //@item(int32, "int32", "", "type")
-/* int64 */ //@item(int64, "int64", "", "type")
-/* int8 */ //@item(int8, "int8", "", "type")
-/* iota */ //@item(iota, "iota", "", "const")
-/* len(v Type) int */ //@item(len, "len", "func(v Type) int", "func")
-/* make(t Type, size ...int) Type */ //@item(make, "make", "func(t Type, size ...int) Type", "func")
-/* new(Type) *Type */ //@item(new, "new", "func(Type) *Type", "func")
-/* nil */ //@item(_nil, "nil", "", "var")
-/* panic(v interface{}) */ //@item(panic, "panic", "func(v interface{})", "func")
-/* print(args ...Type) */ //@item(print, "print", "func(args ...Type)", "func")
-/* println(args ...Type) */ //@item(println, "println", "func(args ...Type)", "func")
-/* real(c complex128) float64 */ //@item(real, "real", "func(c complex128) float64", "func")
-/* recover() interface{} */ //@item(recover, "recover", "func() interface{}", "func")
-/* rune */ //@item(rune, "rune", "", "type")
-/* string */ //@item(string, "string", "", "type")
-/* true */ //@item(_true, "true", "", "const")
-/* uint */ //@item(uint, "uint", "", "type")
-/* uint16 */ //@item(uint16, "uint16", "", "type")
-/* uint32 */ //@item(uint32, "uint32", "", "type")
-/* uint64 */ //@item(uint64, "uint64", "", "type")
-/* uint8 */ //@item(uint8, "uint8", "", "type")
-/* uintptr */ //@item(uintptr, "uintptr", "", "type")
diff -urN a/gopls/internal/lsp/testdata/builtins/constants.go b/gopls/internal/lsp/testdata/builtins/constants.go
--- a/gopls/internal/lsp/testdata/builtins/constants.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/builtins/constants.go	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
-package builtins
-
-func _() {
-	const (
-		foo = iota //@complete(" //", iota)
-	)
-
-	iota //@complete(" //")
-
-	var iota int //@item(iotaVar, "iota", "int", "var")
-
-	iota //@complete(" //", iotaVar)
-}
-
-func _() {
-	var twoRedUpEnd bool //@item(TRUEVar, "twoRedUpEnd", "bool", "var")
-
-	var _ bool = true //@rank(" //", _true, TRUEVar)
-}
diff -urN a/gopls/internal/lsp/testdata/callhierarchy/callhierarchy.go b/gopls/internal/lsp/testdata/callhierarchy/callhierarchy.go
--- a/gopls/internal/lsp/testdata/callhierarchy/callhierarchy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/callhierarchy/callhierarchy.go	1969-12-31 16:00:00
@@ -1,70 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package callhierarchy
-
-import "golang.org/lsptests/callhierarchy/outgoing"
-
-func a() { //@mark(hierarchyA, "a")
-	D()
-}
-
-func b() { //@mark(hierarchyB, "b")
-	D()
-}
-
-// C is an exported function
-func C() { //@mark(hierarchyC, "C")
-	D()
-	D()
-}
-
-// To test hierarchy across function literals
-var x = func() { //@mark(hierarchyLiteral, "func"),mark(hierarchyLiteralOut, "x")
-	D()
-}
-
-// D is exported to test incoming/outgoing calls across packages
-func D() { //@mark(hierarchyD, "D"),incomingcalls(hierarchyD, hierarchyA, hierarchyB, hierarchyC, hierarchyLiteral, incomingA),outgoingcalls(hierarchyD, hierarchyE, hierarchyF, hierarchyG, hierarchyLiteralOut, outgoingB, hierarchyFoo, hierarchyH, hierarchyI, hierarchyJ, hierarchyK)
-	e()
-	x()
-	F()
-	outgoing.B()
-	foo := func() {} //@mark(hierarchyFoo, "foo"),incomingcalls(hierarchyFoo, hierarchyD),outgoingcalls(hierarchyFoo)
-	foo()
-
-	func() {
-		g()
-	}()
-
-	var i Interface = impl{}
-	i.H()
-	i.I()
-
-	s := Struct{}
-	s.J()
-	s.K()
-}
-
-func e() {} //@mark(hierarchyE, "e")
-
-// F is an exported function
-func F() {} //@mark(hierarchyF, "F")
-
-func g() {} //@mark(hierarchyG, "g")
-
-type Interface interface {
-	H() //@mark(hierarchyH, "H")
-	I() //@mark(hierarchyI, "I")
-}
-
-type impl struct{}
-
-func (i impl) H() {}
-func (i impl) I() {}
-
-type Struct struct {
-	J func() //@mark(hierarchyJ, "J")
-	K func() //@mark(hierarchyK, "K")
-}
diff -urN a/gopls/internal/lsp/testdata/callhierarchy/incoming/incoming.go b/gopls/internal/lsp/testdata/callhierarchy/incoming/incoming.go
--- a/gopls/internal/lsp/testdata/callhierarchy/incoming/incoming.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/callhierarchy/incoming/incoming.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package incoming
-
-import "golang.org/lsptests/callhierarchy"
-
-// A is exported to test incoming calls across packages
-func A() { //@mark(incomingA, "A")
-	callhierarchy.D()
-}
diff -urN a/gopls/internal/lsp/testdata/callhierarchy/outgoing/outgoing.go b/gopls/internal/lsp/testdata/callhierarchy/outgoing/outgoing.go
--- a/gopls/internal/lsp/testdata/callhierarchy/outgoing/outgoing.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/callhierarchy/outgoing/outgoing.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package outgoing
-
-// B is exported to test outgoing calls across packages
-func B() { //@mark(outgoingB, "B")
-}
diff -urN a/gopls/internal/lsp/testdata/casesensitive/casesensitive.go b/gopls/internal/lsp/testdata/casesensitive/casesensitive.go
--- a/gopls/internal/lsp/testdata/casesensitive/casesensitive.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/casesensitive/casesensitive.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package casesensitive
-
-func _() {
-	var lower int //@item(lower, "lower", "int", "var")
-	var Upper int //@item(upper, "Upper", "int", "var")
-
-	l //@casesensitive(" //", lower)
-	U //@casesensitive(" //", upper)
-
-	L //@casesensitive(" //")
-	u //@casesensitive(" //")
-}
diff -urN a/gopls/internal/lsp/testdata/cast/cast.go.in b/gopls/internal/lsp/testdata/cast/cast.go.in
--- a/gopls/internal/lsp/testdata/cast/cast.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/cast/cast.go.in	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package cast
-
-func _() {
-	foo := struct{x int}{x: 1} //@item(x_field, "x", "int", "field")
-	_ = float64(foo.x) //@complete("x", x_field)
-}
-
-func _() {
-	foo := struct{x int}{x: 1}
-	_ = float64(foo. //@complete(" /", x_field)
-}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/cgo/declarecgo.go b/gopls/internal/lsp/testdata/cgo/declarecgo.go
--- a/gopls/internal/lsp/testdata/cgo/declarecgo.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/cgo/declarecgo.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package cgo
-
-/*
-#include <stdio.h>
-#include <stdlib.h>
-
-void myprint(char* s) {
-	printf("%s\n", s);
-}
-*/
-import "C"
-
-import (
-	"fmt"
-	"unsafe"
-)
-
-func Example() { //@mark(funccgoexample, "Example"),item(funccgoexample, "Example", "func()", "func")
-	fmt.Println()
-	cs := C.CString("Hello from stdio\n")
-	C.myprint(cs)
-	C.free(unsafe.Pointer(cs))
-}
-
-func _() {
-	Example() //@godef("ample", funccgoexample),complete("ample", funccgoexample)
-}
diff -urN a/gopls/internal/lsp/testdata/cgo/declarecgo.go.golden b/gopls/internal/lsp/testdata/cgo/declarecgo.go.golden
--- a/gopls/internal/lsp/testdata/cgo/declarecgo.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/cgo/declarecgo.go.golden	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
--- funccgoexample-definition --
-cgo/declarecgo.go:18:6-13: defined here as ```go
-func Example()
-```
-
-[`cgo.Example` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/cgo#Example)
--- funccgoexample-definition-json --
-{
-	"span": {
-		"uri": "file://cgo/declarecgo.go",
-		"start": {
-			"line": 18,
-			"column": 6,
-			"offset": 151
-		},
-		"end": {
-			"line": 18,
-			"column": 13,
-			"offset": 158
-		}
-	},
-	"description": "```go\nfunc Example()\n```\n\n[`cgo.Example` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/cgo#Example)"
-}
-
--- funccgoexample-hoverdef --
-```go
-func Example()
-```
-
-[`cgo.Example` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/cgo#Example)
diff -urN a/gopls/internal/lsp/testdata/cgo/declarecgo_nocgo.go b/gopls/internal/lsp/testdata/cgo/declarecgo_nocgo.go
--- a/gopls/internal/lsp/testdata/cgo/declarecgo_nocgo.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/cgo/declarecgo_nocgo.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-//+build !cgo
-
-package cgo
-
-// Set a dummy marker to keep the test framework happy. The tests should be skipped.
-var _ = "Example" //@mark(funccgoexample, "Example"),godef("ample", funccgoexample),complete("ample", funccgoexample)
diff -urN a/gopls/internal/lsp/testdata/cgoimport/usecgo.go.golden b/gopls/internal/lsp/testdata/cgoimport/usecgo.go.golden
--- a/gopls/internal/lsp/testdata/cgoimport/usecgo.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/cgoimport/usecgo.go.golden	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
--- funccgoexample-definition --
-cgo/declarecgo.go:18:6-13: defined here as ```go
-func cgo.Example()
-```
-
-[`cgo.Example` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/cgo#Example)
--- funccgoexample-definition-json --
-{
-	"span": {
-		"uri": "file://cgo/declarecgo.go",
-		"start": {
-			"line": 18,
-			"column": 6,
-			"offset": 151
-		},
-		"end": {
-			"line": 18,
-			"column": 13,
-			"offset": 158
-		}
-	},
-	"description": "```go\nfunc cgo.Example()\n```\n\n[`cgo.Example` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/cgo#Example)"
-}
-
--- funccgoexample-hoverdef --
-```go
-func cgo.Example()
-```
-
-[`cgo.Example` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/cgo#Example)
diff -urN a/gopls/internal/lsp/testdata/cgoimport/usecgo.go.in b/gopls/internal/lsp/testdata/cgoimport/usecgo.go.in
--- a/gopls/internal/lsp/testdata/cgoimport/usecgo.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/cgoimport/usecgo.go.in	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package cgoimport
-
-import (
-	"golang.org/lsptests/cgo"
-)
-
-func _() {
-	cgo.Example() //@godef("ample", funccgoexample),complete("ample", funccgoexample)
-}
diff -urN a/gopls/internal/lsp/testdata/channel/channel.go b/gopls/internal/lsp/testdata/channel/channel.go
--- a/gopls/internal/lsp/testdata/channel/channel.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/channel/channel.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-package channel
-
-func _() {
-	var (
-		aa = "123" //@item(channelAA, "aa", "string", "var")
-		ab = 123   //@item(channelAB, "ab", "int", "var")
-	)
-
-	{
-		type myChan chan int
-		var mc myChan
-		mc <- a //@complete(" //", channelAB, channelAA)
-	}
-
-	{
-		var ac chan int //@item(channelAC, "ac", "chan int", "var")
-		a <- a //@complete(" <-", channelAC, channelAA, channelAB)
-	}
-
-	{
-		var foo chan int //@item(channelFoo, "foo", "chan int", "var")
-		wantsInt := func(int) {} //@item(channelWantsInt, "wantsInt", "func(int)", "var")
-		wantsInt(<-) //@rank(")", channelFoo, channelAB)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/codelens/codelens_test.go b/gopls/internal/lsp/testdata/codelens/codelens_test.go
--- a/gopls/internal/lsp/testdata/codelens/codelens_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/codelens/codelens_test.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-package codelens //@codelens("package codelens", "run file benchmarks", "test")
-
-import "testing"
-
-func TestMain(m *testing.M) {} // no code lens for TestMain
-
-func TestFuncWithCodeLens(t *testing.T) { //@codelens("func", "run test", "test")
-}
-
-func thisShouldNotHaveACodeLens(t *testing.T) {
-}
-
-func BenchmarkFuncWithCodeLens(b *testing.B) { //@codelens("func", "run benchmark", "test")
-}
-
-func helper() {} // expect no code lens
diff -urN a/gopls/internal/lsp/testdata/comment_completion/comment_completion.go.in b/gopls/internal/lsp/testdata/comment_completion/comment_completion.go.in
--- a/gopls/internal/lsp/testdata/comment_completion/comment_completion.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/comment_completion/comment_completion.go.in	1969-12-31 16:00:00
@@ -1,70 +0,0 @@
-package comment_completion
-
-var p bool
-
-//@complete(re"$")
-
-func _() {
-	var a int
-
-	switch a {
-	case 1:
-		//@complete(re"$")
-		_ = a
-	}
-
-	var b chan int
-	select {
-	case <-b:
-		//@complete(re"$")
-		_ = b
-	}
-
-	var (
-		//@complete(re"$")
-		_ = a
-	)
-}
-
-// //@complete(" ", variableC)
-var C string //@item(variableC, "C", "string", "var") //@complete(" ", variableC)
-
-// //@complete(" ", constant)
-const Constant = "example" //@item(constant, "Constant", "string", "const") //@complete(" ", constant)
-
-// //@complete(" ", structType, fieldB, fieldA)
-type StructType struct { //@item(structType, "StructType", "struct{...}", "struct") //@complete(" ", structType, fieldA, fieldB)
-	// //@complete(" ", fieldA, structType, fieldB)
-	A string //@item(fieldA, "A", "string", "field") //@complete(" ", fieldA, structType, fieldB)
-	b int    //@item(fieldB, "b", "int", "field") //@complete(" ", fieldB, structType, fieldA)
-}
-
-// //@complete(" ", method, structRecv, paramX, resultY, fieldB, fieldA)
-func (structType *StructType) Method(X int) (Y int) { //@item(structRecv, "structType", "*StructType", "var"),item(method, "Method", "func(X int) (Y int)", "method"),item(paramX, "X", "int", "var"),item(resultY, "Y", "int", "var")
-	// //@complete(" ", method, structRecv, paramX, resultY, fieldB, fieldA)
-	return
-}
-
-// //@complete(" ", newType)
-type NewType string //@item(newType, "NewType", "string", "type") //@complete(" ", newType)
-
-// //@complete(" ", testInterface, testA, testB)
-type TestInterface interface { //@item(testInterface, "TestInterface", "interface{...}", "interface")
-	// //@complete(" ", testA, testInterface, testB)
-	TestA(L string) (M int) //@item(testA, "TestA", "func(L string) (M int)", "method"),item(paramL, "L", "var", "string"),item(resM, "M", "var", "int") //@complete(" ", testA, testInterface, testB)
-	TestB(N int) bool       //@item(testB, "TestB", "func(N int) bool", "method"),item(paramN, "N", "var", "int") //@complete(" ", testB, testInterface, testA)
-}
-
-// //@complete(" ", function)
-func Function() int { //@item(function, "Function", "func() int", "func") //@complete(" ", function)
-	// //@complete(" ", function)
-	return 0
-}
-
-// This tests multiline block comments and completion with prefix
-// Lorem Ipsum Multili//@complete("Multi", multiline)
-// Lorem ipsum dolor sit ametom
-func Multiline() int { //@item(multiline, "Multiline", "func() int", "func")
-	// //@complete(" ", multiline)
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/complit/complit.go.in b/gopls/internal/lsp/testdata/complit/complit.go.in
--- a/gopls/internal/lsp/testdata/complit/complit.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/complit/complit.go.in	1969-12-31 16:00:00
@@ -1,90 +0,0 @@
-package complit
-
-// general completions
-
-type position struct { //@item(structPosition, "position", "struct{...}", "struct")
-	X, Y int //@item(fieldX, "X", "int", "field"),item(fieldY, "Y", "int", "field")
-}
-
-func _() {
-	_ = position{
-		//@complete("", fieldX, fieldY, structPosition)
-	}
-	_ = position{
-		X: 1,
-		//@complete("", fieldY)
-	}
-	_ = position{
-		//@complete("", fieldX)
-		Y: 1,
-	}
-	_ = []*position{
-        {
-            //@complete("", fieldX, fieldY, structPosition)
-        },
-	}
-}
-
-func _() {
-	var (
-		aa string //@item(aaVar, "aa", "string", "var")
-		ab int    //@item(abVar, "ab", "int", "var")
-	)
-
-	_ = map[int]int{
-		a: a, //@complete(":", abVar, aaVar),complete(",", abVar, aaVar)
-	}
-
-	_ = map[int]int{
-		//@complete("", abVar, aaVar, structPosition)
-	}
-
-	_ = []string{a: ""} //@complete(":", abVar, aaVar)
-	_ = [1]string{a: ""} //@complete(":", abVar, aaVar)
-
-	_ = position{X: a}   //@complete("}", abVar, aaVar)
-	_ = position{a}      //@complete("}", abVar, aaVar)
-	_ = position{a, }      //@complete("}", abVar, aaVar, structPosition)
-
-	_ = []int{a}  //@complete("}", abVar, aaVar)
-	_ = [1]int{a} //@complete("}", abVar, aaVar)
-
-	type myStruct struct {
-		AA int    //@item(fieldAA, "AA", "int", "field")
-		AB string //@item(fieldAB, "AB", "string", "field")
-	}
-
-	_ = myStruct{
-		AB: a, //@complete(",", aaVar, abVar)
-	}
-
-	var s myStruct
-
-	_ = map[int]string{1: "" + s.A}                                //@complete("}", fieldAB, fieldAA)
-	_ = map[int]string{1: (func(i int) string { return "" })(s.A)} //@complete(")}", fieldAA, fieldAB)
-	_ = map[int]string{1: func() string { s.A }}                   //@complete(" }", fieldAA, fieldAB)
-
-	_ = position{s.A} //@complete("}", fieldAA, fieldAB)
-
-	var X int //@item(varX, "X", "int", "var")
-	_ = position{X}      //@complete("}", fieldX, varX)
-}
-
-func _() {
-	type foo struct{} //@item(complitFoo, "foo", "struct{...}", "struct")
-
-	var _ *foo = &fo{} //@snippet("{", complitFoo, "foo", "foo")
-	var _ *foo = fo{} //@snippet("{", complitFoo, "&foo", "&foo")
-
-	struct { a, b *foo }{
-		a: &fo{}, //@rank("{", complitFoo)
-		b: fo{}, //@snippet("{", complitFoo, "&foo", "&foo")
-	}
-}
-
-func _() {
-	_ := position{
-		X: 1, //@complete("X", fieldX),complete(" 1", structPosition)
-		Y: ,  //@complete(":", fieldY),complete(" ,", structPosition)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/constant/constant.go b/gopls/internal/lsp/testdata/constant/constant.go
--- a/gopls/internal/lsp/testdata/constant/constant.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/constant/constant.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-package constant
-
-const x = 1 //@item(constX, "x", "int", "const")
-
-const (
-	a int = iota << 2 //@item(constA, "a", "int", "const")
-	b                 //@item(constB, "b", "int", "const")
-	c                 //@item(constC, "c", "int", "const")
-)
-
-func _() {
-	const y = "hi" //@item(constY, "y", "string", "const")
-	//@complete("", constY, constA, constB, constC, constX)
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_for.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_for.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_for.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_for.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	for bar //@rank(" //", danglingBar)
-}
-
-func bar() bool { //@item(danglingBar, "bar", "func() bool", "func")
-	return true
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	for i := bar //@rank(" //", danglingBar2)
-}
-
-func bar2() int { //@item(danglingBar2, "bar2", "func() int", "func")
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	for i := bar3(); i > bar //@rank(" //", danglingBar3)
-}
-
-func bar3() int { //@item(danglingBar3, "bar3", "func() int", "func")
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond_post.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond_post.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond_post.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_for_init_cond_post.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	for i := bar4(); i > bar4(); i += bar //@rank(" //", danglingBar4)
-}
-
-func bar4() int { //@item(danglingBar4, "bar4", "func() int", "func")
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_if.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_if.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_if.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_if.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	if foo //@rank(" //", danglingFoo)
-}
-
-func foo() bool { //@item(danglingFoo, "foo", "func() bool", "func")
-	return true
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_if_eof.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_if_eof.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_if_eof.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_if_eof.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package danglingstmt
-
-func bar5() bool { //@item(danglingBar5, "bar5", "func() bool", "func")
-	return true
-}
-
-func _() {
-	if b //@rank(" //", danglingBar5)
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	if i := foo //@rank(" //", danglingFoo2)
-}
-
-func foo2() bool { //@item(danglingFoo2, "foo2", "func() bool", "func")
-	return true
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init_cond.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init_cond.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init_cond.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_if_init_cond.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	if i := 123; foo //@rank(" //", danglingFoo3)
-}
-
-func foo3() bool { //@item(danglingFoo3, "foo3", "func() bool", "func")
-	return true
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_multiline_if.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_multiline_if.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_multiline_if.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_multiline_if.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package danglingstmt
-
-func walrus() bool { //@item(danglingWalrus, "walrus", "func() bool", "func")
-	return true
-}
-
-func _() {
-	if true &&
-		walrus //@complete(" //", danglingWalrus)
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_1.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_1.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_1.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_1.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package danglingstmt
-
-func _() {
-	x. //@rank(" //", danglingI)
-}
-
-var x struct { i int } //@item(danglingI, "i", "int", "field")
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_2.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_2.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_2.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_selector_2.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package danglingstmt
-
-import "golang.org/lsptests/foo"
-
-func _() {
-	foo. //@rank(" //", Foo)
-	var _ = []string{foo.} //@rank("}", Foo)
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	switch i := baz //@rank(" //", danglingBaz)
-}
-
-func baz() int { //@item(danglingBaz, "baz", "func() int", "func")
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init_tag.go b/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init_tag.go
--- a/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init_tag.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/danglingstmt/dangling_switch_init_tag.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package danglingstmt
-
-func _() {
-	switch i := 0; baz //@rank(" //", danglingBaz2)
-}
-
-func baz2() int { //@item(danglingBaz2, "baz2", "func() int", "func")
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/deep/deep.go b/gopls/internal/lsp/testdata/deep/deep.go
--- a/gopls/internal/lsp/testdata/deep/deep.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/deep/deep.go	1969-12-31 16:00:00
@@ -1,142 +0,0 @@
-package deep
-
-import "context"
-
-type deepA struct {
-	b deepB //@item(deepBField, "b", "deepB", "field")
-}
-
-type deepB struct {
-}
-
-func wantsDeepB(deepB) {}
-
-func _() {
-	var a deepA   //@item(deepAVar, "a", "deepA", "var")
-	a.b           //@item(deepABField, "a.b", "deepB", "field")
-	wantsDeepB(a) //@deep(")", deepABField, deepAVar)
-
-	deepA{a} //@snippet("}", deepABField, "a.b", "a.b")
-}
-
-func wantsContext(context.Context) {}
-
-func _() {
-	context.Background() //@item(ctxBackground, "context.Background", "func() context.Context", "func", "Background returns a non-nil, empty Context.")
-	context.TODO()       //@item(ctxTODO, "context.TODO", "func() context.Context", "func", "TODO returns a non-nil, empty Context.")
-
-	wantsContext(c) //@rank(")", ctxBackground),rank(")", ctxTODO)
-}
-
-func _() {
-	var cork struct{ err error }
-	cork.err         //@item(deepCorkErr, "cork.err", "error", "field")
-	context          //@item(deepContextPkg, "context", "\"context\"", "package")
-	var _ error = co //@rank(" //", deepCorkErr, deepContextPkg)
-}
-
-func _() {
-	// deepCircle is circular.
-	type deepCircle struct {
-		*deepCircle
-	}
-	var circle deepCircle   //@item(deepCircle, "circle", "deepCircle", "var")
-	circle.deepCircle       //@item(deepCircleField, "circle.deepCircle", "*deepCircle", "field")
-	var _ deepCircle = circ //@deep(" //", deepCircle, deepCircleField),snippet(" //", deepCircleField, "*circle.deepCircle", "*circle.deepCircle")
-}
-
-func _() {
-	type deepEmbedC struct {
-	}
-	type deepEmbedB struct {
-		deepEmbedC
-	}
-	type deepEmbedA struct {
-		deepEmbedB
-	}
-
-	wantsC := func(deepEmbedC) {}
-
-	var a deepEmbedA //@item(deepEmbedA, "a", "deepEmbedA", "var")
-	a.deepEmbedB     //@item(deepEmbedB, "a.deepEmbedB", "deepEmbedB", "field")
-	a.deepEmbedC     //@item(deepEmbedC, "a.deepEmbedC", "deepEmbedC", "field")
-	wantsC(a)        //@deep(")", deepEmbedC, deepEmbedA, deepEmbedB)
-}
-
-func _() {
-	type nested struct {
-		a int
-		n *nested //@item(deepNestedField, "n", "*nested", "field")
-	}
-
-	nested{
-		a: 123, //@deep(" //", deepNestedField)
-	}
-}
-
-func _() {
-	var a struct {
-		b struct {
-			c int
-		}
-		d int
-	}
-
-	a.d   //@item(deepAD, "a.d", "int", "field")
-	a.b.c //@item(deepABC, "a.b.c", "int", "field")
-	a.b   //@item(deepAB, "a.b", "struct{...}", "field")
-	a     //@item(deepA, "a", "struct{...}", "var")
-
-	// "a.d" should be ranked above the deeper "a.b.c"
-	var i int
-	i = a //@deep(" //", deepAD, deepABC, deepA, deepAB)
-}
-
-type foo struct {
-	b bar
-}
-
-func (f foo) bar() bar {
-	return f.b
-}
-
-func (f foo) barPtr() *bar {
-	return &f.b
-}
-
-type bar struct{}
-
-func (b bar) valueReceiver() int {
-	return 0
-}
-
-func (b *bar) ptrReceiver() int {
-	return 0
-}
-
-func _() {
-	var (
-		i int
-		f foo
-	)
-
-	f.bar().valueReceiver    //@item(deepBarValue, "f.bar().valueReceiver", "func() int", "method")
-	f.barPtr().ptrReceiver   //@item(deepBarPtrPtr, "f.barPtr().ptrReceiver", "func() int", "method")
-	f.barPtr().valueReceiver //@item(deepBarPtrValue, "f.barPtr().valueReceiver", "func() int", "method")
-
-	i = fbar //@fuzzy(" //", deepBarValue, deepBarPtrPtr, deepBarPtrValue)
-}
-
-func (b baz) Thing() struct{ val int } {
-	return b.thing
-}
-
-type baz struct {
-	thing struct{ val int }
-}
-
-func (b baz) _() {
-	b.Thing().val    //@item(deepBazMethVal, "b.Thing().val", "int", "field")
-	b.thing.val      //@item(deepBazFieldVal, "b.thing.val", "int", "field")
-	var _ int = bval //@rank(" //", deepBazFieldVal, deepBazMethVal)
-}
diff -urN a/gopls/internal/lsp/testdata/errors/errors.go b/gopls/internal/lsp/testdata/errors/errors.go
--- a/gopls/internal/lsp/testdata/errors/errors.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/errors/errors.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package errors
-
-import (
-	"golang.org/lsptests/types"
-)
-
-func _() {
-	bob.Bob() //@complete(".")
-	types.b //@complete(" //", Bob_interface)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package extract
-
-func _() {
-	a := 1
-	a = 5     //@mark(exSt0, "a")
-	a = a + 2 //@mark(exEn0, "2")
-	//@extractfunc(exSt0, exEn0)
-	b := a * 2 //@mark(exB, "	b")
-	_ = 3 + 4  //@mark(exEnd, "4")
-	//@extractfunc(exB, exEnd)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_args_returns.go.golden	1969-12-31 16:00:00
@@ -1,37 +0,0 @@
--- functionextraction_extract_args_returns_5_2 --
-package extract
-
-func _() {
-	a := 1
-	//@mark(exSt0, "a")
-	a = newFunction(a) //@mark(exEn0, "2")
-	//@extractfunc(exSt0, exEn0)
-	b := a * 2 //@mark(exB, "	b")
-	_ = 3 + 4  //@mark(exEnd, "4")
-	//@extractfunc(exB, exEnd)
-}
-
-func newFunction(a int) int {
-	a = 5
-	a = a + 2
-	return a
-}
-
--- functionextraction_extract_args_returns_8_1 --
-package extract
-
-func _() {
-	a := 1
-	a = 5     //@mark(exSt0, "a")
-	a = a + 2 //@mark(exEn0, "2")
-	//@extractfunc(exSt0, exEn0)
-	//@mark(exB, "	b")
-	newFunction(a)  //@mark(exEnd, "4")
-	//@extractfunc(exB, exEnd)
-}
-
-func newFunction(a int) {
-	b := a * 2
-	_ = 3 + 4
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package extract
-
-func _() { //@mark(exSt25, "{")
-	a := 1    //@mark(exSt1, "a")
-	_ = 3 + 4 //@mark(exEn1, "4")
-	//@extractfunc(exSt1, exEn1)
-	//@extractfunc(exSt25, exEn25)
-} //@mark(exEn25, "}")
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic.go.golden	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
--- functionextraction_extract_basic_3_10 --
-package extract
-
-func _() { //@mark(exSt25, "{")
-	//@mark(exSt1, "a")
-	newFunction() //@mark(exEn1, "4")
-	//@extractfunc(exSt1, exEn1)
-	//@extractfunc(exSt25, exEn25)
-}
-
-func newFunction() {
-	a := 1
-	_ = 3 + 4
-} //@mark(exEn25, "}")
-
--- functionextraction_extract_basic_4_2 --
-package extract
-
-func _() { //@mark(exSt25, "{")
-	//@mark(exSt1, "a")
-	newFunction() //@mark(exEn1, "4")
-	//@extractfunc(exSt1, exEn1)
-	//@extractfunc(exSt25, exEn25)
-}
-
-func newFunction() {
-	a := 1
-	_ = 3 + 4
-} //@mark(exEn25, "}")
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package extract
-
-func _() {
-	a := /* comment in the middle of a line */ 1 //@mark(exSt18, "a")
-	// Comment on its own line  //@mark(exSt19, "Comment")
-	_ = 3 + 4 //@mark(exEn18, "4"),mark(exEn19, "4"),mark(exSt20, "_")
-	// Comment right after 3 + 4
-
-	// Comment after with space //@mark(exEn20, "Comment")
-
-	//@extractfunc(exSt18, exEn18),extractfunc(exSt19, exEn19),extractfunc(exSt20, exEn20)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_basic_comment.go.golden	1969-12-31 16:00:00
@@ -1,57 +0,0 @@
--- functionextraction_extract_basic_comment_4_2 --
-package extract
-
-func _() {
-	/* comment in the middle of a line */
-	//@mark(exSt18, "a")
-	// Comment on its own line  //@mark(exSt19, "Comment")
-	newFunction() //@mark(exEn18, "4"),mark(exEn19, "4"),mark(exSt20, "_")
-	// Comment right after 3 + 4
-
-	// Comment after with space //@mark(exEn20, "Comment")
-
-	//@extractfunc(exSt18, exEn18),extractfunc(exSt19, exEn19),extractfunc(exSt20, exEn20)
-}
-
-func newFunction() {
-	a := 1
-
-	_ = 3 + 4
-}
-
--- functionextraction_extract_basic_comment_5_5 --
-package extract
-
-func _() {
-	a := /* comment in the middle of a line */ 1 //@mark(exSt18, "a")
-	// Comment on its own line  //@mark(exSt19, "Comment")
-	newFunction() //@mark(exEn18, "4"),mark(exEn19, "4"),mark(exSt20, "_")
-	// Comment right after 3 + 4
-
-	// Comment after with space //@mark(exEn20, "Comment")
-
-	//@extractfunc(exSt18, exEn18),extractfunc(exSt19, exEn19),extractfunc(exSt20, exEn20)
-}
-
-func newFunction() {
-	_ = 3 + 4
-}
-
--- functionextraction_extract_basic_comment_6_2 --
-package extract
-
-func _() {
-	a := /* comment in the middle of a line */ 1 //@mark(exSt18, "a")
-	// Comment on its own line  //@mark(exSt19, "Comment")
-	newFunction() //@mark(exEn18, "4"),mark(exEn19, "4"),mark(exSt20, "_")
-	// Comment right after 3 + 4
-
-	// Comment after with space //@mark(exEn20, "Comment")
-
-	//@extractfunc(exSt18, exEn18),extractfunc(exSt19, exEn19),extractfunc(exSt20, exEn20)
-}
-
-func newFunction() {
-	_ = 3 + 4
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package extract
-
-import "fmt"
-
-func main() {
-	x := []rune{} //@mark(exSt9, "x")
-	s := "HELLO"
-	for _, c := range s {
-		x = append(x, c)
-	} //@mark(exEn9, "}")
-	//@extractfunc(exSt9, exEn9)
-	fmt.Printf("%x\n", x)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_issue_44813.go.golden	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
--- functionextraction_extract_issue_44813_6_2 --
-package extract
-
-import "fmt"
-
-func main() {
-	//@mark(exSt9, "x")
-	x := newFunction() //@mark(exEn9, "}")
-	//@extractfunc(exSt9, exEn9)
-	fmt.Printf("%x\n", x)
-}
-
-func newFunction() []rune {
-	x := []rune{}
-	s := "HELLO"
-	for _, c := range s {
-		x = append(x, c)
-	}
-	return x
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package extract
-
-import "strconv"
-
-func _() {
-	i, err := strconv.Atoi("1")
-	u, err := strconv.Atoi("2") //@extractfunc("u", ")")
-	if i == u || err == nil {
-		return
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_redefine.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- functionextraction_extract_redefine_7_2 --
-package extract
-
-import "strconv"
-
-func _() {
-	i, err := strconv.Atoi("1")
-	u, err := newFunction() //@extractfunc("u", ")")
-	if i == u || err == nil {
-		return
-	}
-}
-
-func newFunction() (int, error) {
-	u, err := strconv.Atoi("2")
-	return u, err
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package extract
-
-func _() bool {
-	x := 1
-	if x == 0 { //@mark(exSt2, "if")
-		return true
-	} //@mark(exEn2, "}")
-	return false
-	//@extractfunc(exSt2, exEn2)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic.go.golden	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
--- functionextraction_extract_return_basic_5_2 --
-package extract
-
-func _() bool {
-	x := 1
-	//@mark(exSt2, "if")
-	shouldReturn, returnValue := newFunction(x)
-	if shouldReturn {
-		return returnValue
-	} //@mark(exEn2, "}")
-	return false
-	//@extractfunc(exSt2, exEn2)
-}
-
-func newFunction(x int) (bool, bool) {
-	if x == 0 {
-		return true, true
-	}
-	return false, false
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package extract
-
-func _() bool {
-	x := 1 //@mark(exSt13, "x")
-	if x == 0 {
-		return true
-	}
-	return false //@mark(exEn13, "false")
-	//@extractfunc(exSt13, exEn13)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_basic_nonnested.go.golden	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
--- functionextraction_extract_return_basic_nonnested_4_2 --
-package extract
-
-func _() bool {
-	//@mark(exSt13, "x")
-	return newFunction() //@mark(exEn13, "false")
-	//@extractfunc(exSt13, exEn13)
-}
-
-func newFunction() bool {
-	x := 1
-	if x == 0 {
-		return true
-	}
-	return false
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-package extract
-
-import "fmt"
-
-func _() (int, string, error) {
-	x := 1
-	y := "hello"
-	z := "bye" //@mark(exSt3, "z")
-	if y == z {
-		return x, y, fmt.Errorf("same")
-	} else {
-		z = "hi"
-		return x, z, nil
-	} //@mark(exEn3, "}")
-	return x, z, nil
-	//@extractfunc(exSt3, exEn3)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex.go.golden	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
--- functionextraction_extract_return_complex_8_2 --
-package extract
-
-import "fmt"
-
-func _() (int, string, error) {
-	x := 1
-	y := "hello"
-	//@mark(exSt3, "z")
-	z, shouldReturn, returnValue, returnValue1, returnValue2 := newFunction(y, x)
-	if shouldReturn {
-		return returnValue, returnValue1, returnValue2
-	} //@mark(exEn3, "}")
-	return x, z, nil
-	//@extractfunc(exSt3, exEn3)
-}
-
-func newFunction(y string, x int) (string, bool, int, string, error) {
-	z := "bye"
-	if y == z {
-		return "", true, x, y, fmt.Errorf("same")
-	} else {
-		z = "hi"
-		return "", true, x, z, nil
-	}
-	return z, false, 0, "", nil
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-package extract
-
-import "fmt"
-
-func _() (int, string, error) {
-	x := 1
-	y := "hello"
-	z := "bye" //@mark(exSt10, "z")
-	if y == z {
-		return x, y, fmt.Errorf("same")
-	} else {
-		z = "hi"
-		return x, z, nil
-	}
-	return x, z, nil //@mark(exEn10, "nil")
-	//@extractfunc(exSt10, exEn10)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_complex_nonnested.go.golden	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
--- functionextraction_extract_return_complex_nonnested_8_2 --
-package extract
-
-import "fmt"
-
-func _() (int, string, error) {
-	x := 1
-	y := "hello"
-	//@mark(exSt10, "z")
-	return newFunction(y, x) //@mark(exEn10, "nil")
-	//@extractfunc(exSt10, exEn10)
-}
-
-func newFunction(y string, x int) (int, string, error) {
-	z := "bye"
-	if y == z {
-		return x, y, fmt.Errorf("same")
-	} else {
-		z = "hi"
-		return x, z, nil
-	}
-	return x, z, nil
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package extract
-
-import "go/ast"
-
-func _() {
-	ast.Inspect(ast.NewIdent("a"), func(n ast.Node) bool {
-		if n == nil { //@mark(exSt4, "if")
-			return true
-		} //@mark(exEn4, "}")
-		return false
-	})
-	//@extractfunc(exSt4, exEn4)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit.go.golden	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
--- functionextraction_extract_return_func_lit_7_3 --
-package extract
-
-import "go/ast"
-
-func _() {
-	ast.Inspect(ast.NewIdent("a"), func(n ast.Node) bool {
-		//@mark(exSt4, "if")
-		shouldReturn, returnValue := newFunction(n)
-		if shouldReturn {
-			return returnValue
-		} //@mark(exEn4, "}")
-		return false
-	})
-	//@extractfunc(exSt4, exEn4)
-}
-
-func newFunction(n ast.Node) (bool, bool) {
-	if n == nil {
-		return true, true
-	}
-	return false, false
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package extract
-
-import "go/ast"
-
-func _() {
-	ast.Inspect(ast.NewIdent("a"), func(n ast.Node) bool {
-		if n == nil { //@mark(exSt11, "if")
-			return true
-		}
-		return false //@mark(exEn11, "false")
-	})
-	//@extractfunc(exSt11, exEn11)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_func_lit_nonnested.go.golden	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
--- functionextraction_extract_return_func_lit_nonnested_7_3 --
-package extract
-
-import "go/ast"
-
-func _() {
-	ast.Inspect(ast.NewIdent("a"), func(n ast.Node) bool {
-		//@mark(exSt11, "if")
-		return newFunction(n) //@mark(exEn11, "false")
-	})
-	//@extractfunc(exSt11, exEn11)
-}
-
-func newFunction(n ast.Node) bool {
-	if n == nil {
-		return true
-	}
-	return false
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package extract
-
-func _() string {
-	x := 1
-	if x == 0 { //@mark(exSt5, "if")
-		x = 3
-		return "a"
-	} //@mark(exEn5, "}")
-	x = 2
-	return "b"
-	//@extractfunc(exSt5, exEn5)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init.go.golden	1969-12-31 16:00:00
@@ -1,23 +0,0 @@
--- functionextraction_extract_return_init_5_2 --
-package extract
-
-func _() string {
-	x := 1
-	//@mark(exSt5, "if")
-	shouldReturn, returnValue := newFunction(x)
-	if shouldReturn {
-		return returnValue
-	} //@mark(exEn5, "}")
-	x = 2
-	return "b"
-	//@extractfunc(exSt5, exEn5)
-}
-
-func newFunction(x int) (bool, string) {
-	if x == 0 {
-		x = 3
-		return true, "a"
-	}
-	return false, ""
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package extract
-
-func _() string {
-	x := 1
-	if x == 0 { //@mark(exSt12, "if")
-		x = 3
-		return "a"
-	}
-	x = 2
-	return "b" //@mark(exEn12, "\"b\"")
-	//@extractfunc(exSt12, exEn12)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_return_init_nonnested.go.golden	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
--- functionextraction_extract_return_init_nonnested_5_2 --
-package extract
-
-func _() string {
-	x := 1
-	//@mark(exSt12, "if")
-	return newFunction(x) //@mark(exEn12, "\"b\"")
-	//@extractfunc(exSt12, exEn12)
-}
-
-func newFunction(x int) string {
-	if x == 0 {
-		x = 3
-		return "a"
-	}
-	x = 2
-	return "b"
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package extract
-
-func _() {
-	newFunction := 1
-	a := newFunction //@extractfunc("a", "newFunction")
-}
-
-func newFunction1() int {
-	return 1
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_scope.go.golden	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
--- functionextraction_extract_scope_5_2 --
-package extract
-
-func _() {
-	newFunction := 1
-	newFunction2(newFunction) //@extractfunc("a", "newFunction")
-}
-
-func newFunction2(newFunction int) {
-	a := newFunction
-}
-
-func newFunction1() int {
-	return 1
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package extract
-
-func _() {
-	var a []int
-	a = append(a, 2) //@mark(exSt6, "a")
-	b := 4           //@mark(exEn6, "4")
-	//@extractfunc(exSt6, exEn6)
-	a = append(a, b)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_initialization.go.golden	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
--- functionextraction_extract_smart_initialization_5_2 --
-package extract
-
-func _() {
-	var a []int
-	//@mark(exSt6, "a")
-	a, b := newFunction(a)           //@mark(exEn6, "4")
-	//@extractfunc(exSt6, exEn6)
-	a = append(a, b)
-}
-
-func newFunction(a []int) ([]int, int) {
-	a = append(a, 2)
-	b := 4
-	return a, b
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package extract
-
-func _() {
-	var b []int
-	var a int
-	a = 2 //@mark(exSt7, "a")
-	b = []int{}
-	b = append(b, a) //@mark(exEn7, ")")
-	b[0] = 1
-	//@extractfunc(exSt7, exEn7)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_smart_return.go.golden	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
--- functionextraction_extract_smart_return_6_2 --
-package extract
-
-func _() {
-	var b []int
-	var a int
-	//@mark(exSt7, "a")
-	b = newFunction(a, b) //@mark(exEn7, ")")
-	b[0] = 1
-	//@extractfunc(exSt7, exEn7)
-}
-
-func newFunction(a int, b []int) []int {
-	a = 2
-	b = []int{}
-	b = append(b, a)
-	return b
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go b/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-package extract
-
-func _() {
-	var b []int
-	var a int
-	a := 2 //@mark(exSt8, "a")
-	b = []int{}
-	b = append(b, a) //@mark(exEn8, ")")
-	b[0] = 1
-	if a == 2 {
-		return
-	}
-	//@extractfunc(exSt8, exEn8)
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go.golden b/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_function/extract_unnecessary_param.go.golden	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
--- functionextraction_extract_unnecessary_param_6_2 --
-package extract
-
-func _() {
-	var b []int
-	var a int
-	//@mark(exSt8, "a")
-	a, b = newFunction(b) //@mark(exEn8, ")")
-	b[0] = 1
-	if a == 2 {
-		return
-	}
-	//@extractfunc(exSt8, exEn8)
-}
-
-func newFunction(b []int) (int, []int) {
-	a := 2
-	b = []int{}
-	b = append(b, a)
-	return a, b
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go b/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go
--- a/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go.golden b/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_method/extract_basic.go.golden	1969-12-31 16:00:00
@@ -1,364 +0,0 @@
--- functionextraction_extract_basic_13_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := newFunction(a) //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func newFunction(a *A) int {
-	sum := a.x + a.y
-	return sum
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- functionextraction_extract_basic_14_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return newFunction(sum)       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func newFunction(sum int) int {
-	return sum
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- functionextraction_extract_basic_18_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return newFunction(a) //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func newFunction(a A) bool {
-	return a.x < a.y
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- functionextraction_extract_basic_22_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := newFunction(a) //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func newFunction(a A) int {
-	sum := a.x + a.y
-	return sum
-}
-
--- functionextraction_extract_basic_23_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return newFunction(sum)       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func newFunction(sum int) int {
-	return sum
-}
-
--- functionextraction_extract_basic_9_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return newFunction(a) //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func newFunction(a *A) bool {
-	return a.x < a.y
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- methodextraction_extract_basic_13_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.newMethod() //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a *A) newMethod() int {
-	sum := a.x + a.y
-	return sum
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- methodextraction_extract_basic_14_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return a.newMethod(sum)       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (*A) newMethod(sum int) int {
-	return sum
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- methodextraction_extract_basic_18_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.newMethod() //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) newMethod() bool {
-	return a.x < a.y
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
--- methodextraction_extract_basic_22_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.newMethod() //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) newMethod() int {
-	sum := a.x + a.y
-	return sum
-}
-
--- methodextraction_extract_basic_23_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return a.newMethod(sum)       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (A) newMethod(sum int) int {
-	return sum
-}
-
--- methodextraction_extract_basic_9_2 --
-package extract
-
-type A struct {
-	x int
-	y int
-}
-
-func (a *A) XLessThanYP() bool {
-	return a.newMethod() //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a *A) newMethod() bool {
-	return a.x < a.y
-}
-
-func (a *A) AddP() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
-func (a A) XLessThanY() bool {
-	return a.x < a.y //@extractmethod("return", "a.y"),extractfunc("return", "a.y")
-}
-
-func (a A) Add() int {
-	sum := a.x + a.y //@extractmethod("sum", "a.y"),extractfunc("sum", "a.y")
-	return sum       //@extractmethod("return", "sum"),extractfunc("return", "sum")
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go b/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go
--- a/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package extract
-
-func _() {
-	var _ = 1 + 2 //@suggestedfix("1", "refactor.extract", "")
-	var _ = 3 + 4 //@suggestedfix("3 + 4", "refactor.extract", "")
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go.golden b/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_variable/extract_basic_lit.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- suggestedfix_extract_basic_lit_4_10 --
-package extract
-
-func _() {
-	x := 1
-	var _ = x + 2 //@suggestedfix("1", "refactor.extract", "")
-	var _ = 3 + 4 //@suggestedfix("3 + 4", "refactor.extract", "")
-}
-
--- suggestedfix_extract_basic_lit_5_10 --
-package extract
-
-func _() {
-	var _ = 1 + 2 //@suggestedfix("1", "refactor.extract", "")
-	x := 3 + 4
-	var _ = x //@suggestedfix("3 + 4", "refactor.extract", "")
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go b/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go
--- a/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package extract
-
-import "strconv"
-
-func _() {
-	x0 := append([]int{}, 1) //@suggestedfix("append([]int{}, 1)", "refactor.extract", "")
-	str := "1"
-	b, err := strconv.Atoi(str) //@suggestedfix("strconv.Atoi(str)", "refactor.extract", "")
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go.golden b/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_variable/extract_func_call.go.golden	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
--- suggestedfix_extract_func_call_6_8 --
-package extract
-
-import "strconv"
-
-func _() {
-	x := append([]int{}, 1)
-	x0 := x //@suggestedfix("append([]int{}, 1)", "refactor.extract", "")
-	str := "1"
-	b, err := strconv.Atoi(str) //@suggestedfix("strconv.Atoi(str)", "refactor.extract", "")
-}
-
--- suggestedfix_extract_func_call_8_12 --
-package extract
-
-import "strconv"
-
-func _() {
-	x0 := append([]int{}, 1) //@suggestedfix("append([]int{}, 1)", "refactor.extract", "")
-	str := "1"
-	x, x1 := strconv.Atoi(str)
-	b, err := x, x1 //@suggestedfix("strconv.Atoi(str)", "refactor.extract", "")
-}
-
diff -urN a/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go b/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go
--- a/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package extract
-
-import "go/ast"
-
-func _() {
-	x0 := 0
-	if true {
-		y := ast.CompositeLit{} //@suggestedfix("ast.CompositeLit{}", "refactor.extract", "")
-	}
-	if true {
-		x1 := !false //@suggestedfix("!false", "refactor.extract", "")
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go.golden b/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go.golden
--- a/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/extract/extract_variable/extract_scope.go.golden	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
--- suggestedfix_extract_scope_11_9 --
-package extract
-
-import "go/ast"
-
-func _() {
-	x0 := 0
-	if true {
-		y := ast.CompositeLit{} //@suggestedfix("ast.CompositeLit{}", "refactor.extract", "")
-	}
-	if true {
-		x := !false
-		x1 := x //@suggestedfix("!false", "refactor.extract", "")
-	}
-}
-
--- suggestedfix_extract_scope_8_8 --
-package extract
-
-import "go/ast"
-
-func _() {
-	x0 := 0
-	if true {
-		x := ast.CompositeLit{}
-		y := x //@suggestedfix("ast.CompositeLit{}", "refactor.extract", "")
-	}
-	if true {
-		x1 := !false //@suggestedfix("!false", "refactor.extract", "")
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/fieldlist/field_list.go b/gopls/internal/lsp/testdata/fieldlist/field_list.go
--- a/gopls/internal/lsp/testdata/fieldlist/field_list.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fieldlist/field_list.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package fieldlist
-
-var myInt int   //@item(flVar, "myInt", "int", "var")
-type myType int //@item(flType, "myType", "int", "type")
-
-func (my) _()    {} //@complete(") _", flType)
-func (my my) _() {} //@complete(" my)"),complete(") _", flType)
-
-func (myType) _() {} //@complete(") {", flType)
-
-func (myType) _(my my) {} //@complete(" my)"),complete(") {", flType)
-
-func (myType) _() my {} //@complete(" {", flType)
-
-func (myType) _() (my my) {} //@complete(" my"),complete(") {", flType)
-
-func _() {
-	var _ struct {
-		//@complete("", flType)
-		m my //@complete(" my"),complete(" //", flType)
-	}
-
-	var _ interface {
-		//@complete("", flType)
-		m() my //@complete("("),complete(" //", flType)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a.go b/gopls/internal/lsp/testdata/fillstruct/a.go
--- a/gopls/internal/lsp/testdata/fillstruct/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package fillstruct
-
-import (
-	"golang.org/lsptests/fillstruct/data"
-)
-
-type basicStruct struct {
-	foo int
-}
-
-var _ = basicStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStruct struct {
-	foo int
-	bar string
-}
-
-var _ = twoArgStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct
-}
-
-var _ = nestedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = data.B{} //@suggestedfix("}", "refactor.rewrite", "Fill")
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a.go.golden b/gopls/internal/lsp/testdata/fillstruct/a.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a.go.golden	1969-12-31 16:00:00
@@ -1,126 +0,0 @@
--- suggestedfix_a_11_21 --
-package fillstruct
-
-import (
-	"golang.org/lsptests/fillstruct/data"
-)
-
-type basicStruct struct {
-	foo int
-}
-
-var _ = basicStruct{
-	foo: 0,
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStruct struct {
-	foo int
-	bar string
-}
-
-var _ = twoArgStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct
-}
-
-var _ = nestedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = data.B{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a_18_22 --
-package fillstruct
-
-import (
-	"golang.org/lsptests/fillstruct/data"
-)
-
-type basicStruct struct {
-	foo int
-}
-
-var _ = basicStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStruct struct {
-	foo int
-	bar string
-}
-
-var _ = twoArgStruct{
-	foo: 0,
-	bar: "",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct
-}
-
-var _ = nestedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = data.B{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a_25_22 --
-package fillstruct
-
-import (
-	"golang.org/lsptests/fillstruct/data"
-)
-
-type basicStruct struct {
-	foo int
-}
-
-var _ = basicStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStruct struct {
-	foo int
-	bar string
-}
-
-var _ = twoArgStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct
-}
-
-var _ = nestedStruct{
-	bar:   "",
-	basic: basicStruct{},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = data.B{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a_27_16 --
-package fillstruct
-
-import (
-	"golang.org/lsptests/fillstruct/data"
-)
-
-type basicStruct struct {
-	foo int
-}
-
-var _ = basicStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStruct struct {
-	foo int
-	bar string
-}
-
-var _ = twoArgStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStruct struct {
-	bar   string
-	basic basicStruct
-}
-
-var _ = nestedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = data.B{
-	ExportedInt: 0,
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a2.go b/gopls/internal/lsp/testdata/fillstruct/a2.go
--- a/gopls/internal/lsp/testdata/fillstruct/a2.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a2.go	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-package fillstruct
-
-type typedStruct struct {
-	m  map[string]int
-	s  []int
-	c  chan int
-	c1 <-chan int
-	a  [2]string
-}
-
-var _ = typedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStruct struct {
-	fn func(i int) int
-}
-
-var _ = funStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructCompex struct {
-	fn func(i int, s string) (string, int)
-}
-
-var _ = funStructCompex{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructEmpty struct {
-	fn func()
-}
-
-var _ = funStructEmpty{} //@suggestedfix("}", "refactor.rewrite", "Fill")
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a2.go.golden b/gopls/internal/lsp/testdata/fillstruct/a2.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/a2.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a2.go.golden	1969-12-31 16:00:00
@@ -1,139 +0,0 @@
--- suggestedfix_a2_11_21 --
-package fillstruct
-
-type typedStruct struct {
-	m  map[string]int
-	s  []int
-	c  chan int
-	c1 <-chan int
-	a  [2]string
-}
-
-var _ = typedStruct{
-	m:  map[string]int{},
-	s:  []int{},
-	c:  make(chan int),
-	c1: make(<-chan int),
-	a:  [2]string{},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStruct struct {
-	fn func(i int) int
-}
-
-var _ = funStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructCompex struct {
-	fn func(i int, s string) (string, int)
-}
-
-var _ = funStructCompex{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructEmpty struct {
-	fn func()
-}
-
-var _ = funStructEmpty{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a2_17_19 --
-package fillstruct
-
-type typedStruct struct {
-	m  map[string]int
-	s  []int
-	c  chan int
-	c1 <-chan int
-	a  [2]string
-}
-
-var _ = typedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStruct struct {
-	fn func(i int) int
-}
-
-var _ = funStruct{
-	fn: func(i int) int {
-	},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructCompex struct {
-	fn func(i int, s string) (string, int)
-}
-
-var _ = funStructCompex{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructEmpty struct {
-	fn func()
-}
-
-var _ = funStructEmpty{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a2_23_25 --
-package fillstruct
-
-type typedStruct struct {
-	m  map[string]int
-	s  []int
-	c  chan int
-	c1 <-chan int
-	a  [2]string
-}
-
-var _ = typedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStruct struct {
-	fn func(i int) int
-}
-
-var _ = funStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructCompex struct {
-	fn func(i int, s string) (string, int)
-}
-
-var _ = funStructCompex{
-	fn: func(i int, s string) (string, int) {
-	},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructEmpty struct {
-	fn func()
-}
-
-var _ = funStructEmpty{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a2_29_24 --
-package fillstruct
-
-type typedStruct struct {
-	m  map[string]int
-	s  []int
-	c  chan int
-	c1 <-chan int
-	a  [2]string
-}
-
-var _ = typedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStruct struct {
-	fn func(i int) int
-}
-
-var _ = funStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructCompex struct {
-	fn func(i int, s string) (string, int)
-}
-
-var _ = funStructCompex{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type funStructEmpty struct {
-	fn func()
-}
-
-var _ = funStructEmpty{
-	fn: func() {
-	},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a3.go b/gopls/internal/lsp/testdata/fillstruct/a3.go
--- a/gopls/internal/lsp/testdata/fillstruct/a3.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a3.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-package fillstruct
-
-import (
-	"go/ast"
-	"go/token"
-)
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = []ast.BasicLit{
-	{}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
-var _ = []ast.BasicLit{{}} //@suggestedfix("}", "refactor.rewrite", "Fill")
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a3.go.golden b/gopls/internal/lsp/testdata/fillstruct/a3.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/a3.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a3.go.golden	1969-12-31 16:00:00
@@ -1,243 +0,0 @@
--- suggestedfix_a3_17_13 --
-package fillstruct
-
-import (
-	"go/ast"
-	"go/token"
-)
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{
-	X: &Foo{},
-	Y: &Foo{},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = []ast.BasicLit{
-	{}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
-var _ = []ast.BasicLit{{}} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a3_28_24 --
-package fillstruct
-
-import (
-	"go/ast"
-	"go/token"
-)
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{
-	m: map[*ast.CompositeLit]ast.Field{},
-	s: []ast.BadExpr{},
-	a: [3]token.Token{},
-	c: make(chan ast.EmptyStmt),
-	fn: func(ast_decl ast.DeclStmt) ast.Ellipsis {
-	},
-	st: ast.CompositeLit{},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = []ast.BasicLit{
-	{}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
-var _ = []ast.BasicLit{{}} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a3_36_30 --
-package fillstruct
-
-import (
-	"go/ast"
-	"go/token"
-)
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{
-	b: new(bool),
-	s: new(string),
-	i: new(int),
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = []ast.BasicLit{
-	{}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
-var _ = []ast.BasicLit{{}} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a3_39_3 --
-package fillstruct
-
-import (
-	"go/ast"
-	"go/token"
-)
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = []ast.BasicLit{
-	{
-		ValuePos: 0,
-		Kind:     0,
-		Value:    "",
-	}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
-var _ = []ast.BasicLit{{}} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
--- suggestedfix_a3_42_25 --
-package fillstruct
-
-import (
-	"go/ast"
-	"go/token"
-)
-
-type Foo struct {
-	A int
-}
-
-type Bar struct {
-	X *Foo
-	Y *Foo
-}
-
-var _ = Bar{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type importedStruct struct {
-	m  map[*ast.CompositeLit]ast.Field
-	s  []ast.BadExpr
-	a  [3]token.Token
-	c  chan ast.EmptyStmt
-	fn func(ast_decl ast.DeclStmt) ast.Ellipsis
-	st ast.CompositeLit
-}
-
-var _ = importedStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type pointerBuiltinStruct struct {
-	b *bool
-	s *string
-	i *int
-}
-
-var _ = pointerBuiltinStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = []ast.BasicLit{
-	{}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
-var _ = []ast.BasicLit{{
-	ValuePos: 0,
-	Kind:     0,
-	Value:    "",
-}} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a4.go b/gopls/internal/lsp/testdata/fillstruct/a4.go
--- a/gopls/internal/lsp/testdata/fillstruct/a4.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a4.go	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
-package fillstruct
-
-import "go/ast"
-
-type iStruct struct {
-	X int
-}
-
-type sStruct struct {
-	str string
-}
-
-type multiFill struct {
-	num   int
-	strin string
-	arr   []int
-}
-
-type assignStruct struct {
-	n ast.Node
-}
-
-func fill() {
-	var x int
-	var _ = iStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var s string
-	var _ = sStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var n int
-	_ = []int{}
-	if true {
-		arr := []int{1, 2}
-	}
-	var _ = multiFill{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var node *ast.CompositeLit
-	var _ = assignStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/a4.go.golden b/gopls/internal/lsp/testdata/fillstruct/a4.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/a4.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/a4.go.golden	1969-12-31 16:00:00
@@ -1,174 +0,0 @@
--- suggestedfix_a4_25_18 --
-package fillstruct
-
-import "go/ast"
-
-type iStruct struct {
-	X int
-}
-
-type sStruct struct {
-	str string
-}
-
-type multiFill struct {
-	num   int
-	strin string
-	arr   []int
-}
-
-type assignStruct struct {
-	n ast.Node
-}
-
-func fill() {
-	var x int
-	var _ = iStruct{
-		X: x,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var s string
-	var _ = sStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var n int
-	_ = []int{}
-	if true {
-		arr := []int{1, 2}
-	}
-	var _ = multiFill{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var node *ast.CompositeLit
-	var _ = assignStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_a4_28_18 --
-package fillstruct
-
-import "go/ast"
-
-type iStruct struct {
-	X int
-}
-
-type sStruct struct {
-	str string
-}
-
-type multiFill struct {
-	num   int
-	strin string
-	arr   []int
-}
-
-type assignStruct struct {
-	n ast.Node
-}
-
-func fill() {
-	var x int
-	var _ = iStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var s string
-	var _ = sStruct{
-		str: s,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var n int
-	_ = []int{}
-	if true {
-		arr := []int{1, 2}
-	}
-	var _ = multiFill{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var node *ast.CompositeLit
-	var _ = assignStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_a4_35_20 --
-package fillstruct
-
-import "go/ast"
-
-type iStruct struct {
-	X int
-}
-
-type sStruct struct {
-	str string
-}
-
-type multiFill struct {
-	num   int
-	strin string
-	arr   []int
-}
-
-type assignStruct struct {
-	n ast.Node
-}
-
-func fill() {
-	var x int
-	var _ = iStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var s string
-	var _ = sStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var n int
-	_ = []int{}
-	if true {
-		arr := []int{1, 2}
-	}
-	var _ = multiFill{
-		num:   n,
-		strin: s,
-		arr:   []int{},
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var node *ast.CompositeLit
-	var _ = assignStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_a4_38_23 --
-package fillstruct
-
-import "go/ast"
-
-type iStruct struct {
-	X int
-}
-
-type sStruct struct {
-	str string
-}
-
-type multiFill struct {
-	num   int
-	strin string
-	arr   []int
-}
-
-type assignStruct struct {
-	n ast.Node
-}
-
-func fill() {
-	var x int
-	var _ = iStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var s string
-	var _ = sStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var n int
-	_ = []int{}
-	if true {
-		arr := []int{1, 2}
-	}
-	var _ = multiFill{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-	var node *ast.CompositeLit
-	var _ = assignStruct{
-		n: node,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/data/a.go b/gopls/internal/lsp/testdata/fillstruct/data/a.go
--- a/gopls/internal/lsp/testdata/fillstruct/data/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/data/a.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package data
-
-type B struct {
-	ExportedInt   int
-	unexportedInt int
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-package fillstruct
-
-type StructA struct {
-	unexportedIntField int
-	ExportedIntField   int
-	MapA               map[int]string
-	Array              []int
-	StructB
-}
-
-type StructA2 struct {
-	B *StructB
-}
-
-type StructA3 struct {
-	B StructB
-}
-
-func fill() {
-	a := StructA{}  //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructA2{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	c := StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	if true {
-		_ = StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct.go.golden	1969-12-31 16:00:00
@@ -1,124 +0,0 @@
--- suggestedfix_fill_struct_20_15 --
-package fillstruct
-
-type StructA struct {
-	unexportedIntField int
-	ExportedIntField   int
-	MapA               map[int]string
-	Array              []int
-	StructB
-}
-
-type StructA2 struct {
-	B *StructB
-}
-
-type StructA3 struct {
-	B StructB
-}
-
-func fill() {
-	a := StructA{
-		unexportedIntField: 0,
-		ExportedIntField:   0,
-		MapA:               map[int]string{},
-		Array:              []int{},
-		StructB:            StructB{},
-	}  //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructA2{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	c := StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	if true {
-		_ = StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
-
--- suggestedfix_fill_struct_21_16 --
-package fillstruct
-
-type StructA struct {
-	unexportedIntField int
-	ExportedIntField   int
-	MapA               map[int]string
-	Array              []int
-	StructB
-}
-
-type StructA2 struct {
-	B *StructB
-}
-
-type StructA3 struct {
-	B StructB
-}
-
-func fill() {
-	a := StructA{}  //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructA2{
-		B: &StructB{},
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	c := StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	if true {
-		_ = StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
-
--- suggestedfix_fill_struct_22_16 --
-package fillstruct
-
-type StructA struct {
-	unexportedIntField int
-	ExportedIntField   int
-	MapA               map[int]string
-	Array              []int
-	StructB
-}
-
-type StructA2 struct {
-	B *StructB
-}
-
-type StructA3 struct {
-	B StructB
-}
-
-func fill() {
-	a := StructA{}  //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructA2{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	c := StructA3{
-		B: StructB{},
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	if true {
-		_ = StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
-
--- suggestedfix_fill_struct_24_16 --
-package fillstruct
-
-type StructA struct {
-	unexportedIntField int
-	ExportedIntField   int
-	MapA               map[int]string
-	Array              []int
-	StructB
-}
-
-type StructA2 struct {
-	B *StructB
-}
-
-type StructA3 struct {
-	B StructB
-}
-
-func fill() {
-	a := StructA{}  //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructA2{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	c := StructA3{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	if true {
-		_ = StructA3{
-			B: StructB{},
-		} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-package fillstruct
-
-type StructAnon struct {
-	a struct{}
-	b map[string]interface{}
-	c map[string]struct {
-		d int
-		e bool
-	}
-}
-
-func fill() {
-	_ := StructAnon{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_anon.go.golden	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
--- suggestedfix_fill_struct_anon_13_18 --
-package fillstruct
-
-type StructAnon struct {
-	a struct{}
-	b map[string]interface{}
-	c map[string]struct {
-		d int
-		e bool
-	}
-}
-
-func fill() {
-	_ := StructAnon{
-		a: struct{}{},
-		b: map[string]interface{}{},
-		c: map[string]struct{d int; e bool}{},
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-package fillstruct
-
-type StructB struct {
-	StructC
-}
-
-type StructC struct {
-	unexportedInt int
-}
-
-func nested() {
-	c := StructB{
-		StructC: StructC{}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_nested.go.golden	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
--- suggestedfix_fill_struct_nested_13_20 --
-package fillstruct
-
-type StructB struct {
-	StructC
-}
-
-type StructC struct {
-	unexportedInt int
-}
-
-func nested() {
-	c := StructB{
-		StructC: StructC{
-			unexportedInt: 0,
-		}, //@suggestedfix("}", "refactor.rewrite", "Fill")
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package fillstruct
-
-import (
-	h2 "net/http"
-
-	"golang.org/lsptests/fillstruct/data"
-)
-
-func unexported() {
-	a := data.B{}   //@suggestedfix("}", "refactor.rewrite", "Fill")
-	_ = h2.Client{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_package.go.golden	1969-12-31 16:00:00
@@ -1,36 +0,0 @@
--- suggestedfix_fill_struct_package_10_14 --
-package fillstruct
-
-import (
-	h2 "net/http"
-
-	"golang.org/lsptests/fillstruct/data"
-)
-
-func unexported() {
-	a := data.B{
-		ExportedInt: 0,
-	}   //@suggestedfix("}", "refactor.rewrite", "Fill")
-	_ = h2.Client{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_fill_struct_package_11_16 --
-package fillstruct
-
-import (
-	h2 "net/http"
-
-	"golang.org/lsptests/fillstruct/data"
-)
-
-func unexported() {
-	a := data.B{}   //@suggestedfix("}", "refactor.rewrite", "Fill")
-	_ = h2.Client{
-		Transport: nil,
-		CheckRedirect: func(req *h2.Request, via []*h2.Request) error {
-		},
-		Jar:     nil,
-		Timeout: 0,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-package fillstruct
-
-type StructPartialA struct {
-	PrefilledInt int
-	UnfilledInt  int
-	StructPartialB
-}
-
-type StructPartialB struct {
-	PrefilledInt int
-	UnfilledInt  int
-}
-
-func fill() {
-	a := StructPartialA{
-		PrefilledInt: 5,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructPartialB{
-		/* this comment should disappear */
-		PrefilledInt: 7, // This comment should be blown away.
-		/* As should
-		this one */
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_partial.go.golden	1969-12-31 16:00:00
@@ -1,52 +0,0 @@
--- suggestedfix_fill_struct_partial_17_2 --
-package fillstruct
-
-type StructPartialA struct {
-	PrefilledInt int
-	UnfilledInt  int
-	StructPartialB
-}
-
-type StructPartialB struct {
-	PrefilledInt int
-	UnfilledInt  int
-}
-
-func fill() {
-	a := StructPartialA{
-		PrefilledInt:   5,
-		UnfilledInt:    0,
-		StructPartialB: StructPartialB{},
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructPartialB{
-		/* this comment should disappear */
-		PrefilledInt: 7, // This comment should be blown away.
-		/* As should
-		this one */
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_fill_struct_partial_23_2 --
-package fillstruct
-
-type StructPartialA struct {
-	PrefilledInt int
-	UnfilledInt  int
-	StructPartialB
-}
-
-type StructPartialB struct {
-	PrefilledInt int
-	UnfilledInt  int
-}
-
-func fill() {
-	a := StructPartialA{
-		PrefilledInt: 5,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-	b := StructPartialB{
-		PrefilledInt: 7,
-		UnfilledInt:  0,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package fillstruct
-
-type StructD struct {
-	ExportedIntField int
-}
-
-func spaces() {
-	d := StructD{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_spaces.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- suggestedfix_fill_struct_spaces_8_15 --
-package fillstruct
-
-type StructD struct {
-	ExportedIntField int
-}
-
-func spaces() {
-	d := StructD{
-		ExportedIntField: 0,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go b/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package fillstruct
-
-import "unsafe"
-
-type unsafeStruct struct {
-	x int
-	p unsafe.Pointer
-}
-
-func fill() {
-	_ := unsafeStruct{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go.golden b/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/fill_struct_unsafe.go.golden	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
--- suggestedfix_fill_struct_unsafe_11_20 --
-package fillstruct
-
-import "unsafe"
-
-type unsafeStruct struct {
-	x int
-	p unsafe.Pointer
-}
-
-func fill() {
-	_ := unsafeStruct{
-		x: 0,
-		p: nil,
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/fillstruct/typeparams.go b/gopls/internal/lsp/testdata/fillstruct/typeparams.go
--- a/gopls/internal/lsp/testdata/fillstruct/typeparams.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/typeparams.go	1969-12-31 16:00:00
@@ -1,37 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package fillstruct
-
-type emptyStructWithTypeParams[A any] struct{}
-
-var _ = emptyStructWithTypeParams[int]{} // no suggested fix
-
-type basicStructWithTypeParams[T any] struct {
-	foo T
-}
-
-var _ = basicStructWithTypeParams[int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStructWithTypeParams[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStructWithTypeParams[string, int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = twoArgStructWithTypeParams[int, string]{
-	bar: "bar",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStructWithTypeParams struct {
-	bar   string
-	basic basicStructWithTypeParams[int]
-}
-
-var _ = nestedStructWithTypeParams{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-func _[T any]() {
-	type S struct{ t T }
-	_ = S{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
diff -urN a/gopls/internal/lsp/testdata/fillstruct/typeparams.go.golden b/gopls/internal/lsp/testdata/fillstruct/typeparams.go.golden
--- a/gopls/internal/lsp/testdata/fillstruct/typeparams.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fillstruct/typeparams.go.golden	1969-12-31 16:00:00
@@ -1,206 +0,0 @@
--- suggestedfix_typeparams_14_40 --
-//go:build go1.18
-// +build go1.18
-
-package fillstruct
-
-type emptyStructWithTypeParams[A any] struct{}
-
-var _ = emptyStructWithTypeParams[int]{} // no suggested fix
-
-type basicStructWithTypeParams[T any] struct {
-	foo T
-}
-
-var _ = basicStructWithTypeParams[int]{
-	foo: 0,
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStructWithTypeParams[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStructWithTypeParams[string, int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = twoArgStructWithTypeParams[int, string]{
-	bar: "bar",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStructWithTypeParams struct {
-	bar   string
-	basic basicStructWithTypeParams[int]
-}
-
-var _ = nestedStructWithTypeParams{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-func _[T any]() {
-	type S struct{ t T }
-	_ = S{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_typeparams_21_49 --
-//go:build go1.18
-// +build go1.18
-
-package fillstruct
-
-type emptyStructWithTypeParams[A any] struct{}
-
-var _ = emptyStructWithTypeParams[int]{} // no suggested fix
-
-type basicStructWithTypeParams[T any] struct {
-	foo T
-}
-
-var _ = basicStructWithTypeParams[int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStructWithTypeParams[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStructWithTypeParams[string, int]{
-	foo: "",
-	bar: 0,
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = twoArgStructWithTypeParams[int, string]{
-	bar: "bar",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStructWithTypeParams struct {
-	bar   string
-	basic basicStructWithTypeParams[int]
-}
-
-var _ = nestedStructWithTypeParams{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-func _[T any]() {
-	type S struct{ t T }
-	_ = S{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_typeparams_25_1 --
-//go:build go1.18
-// +build go1.18
-
-package fillstruct
-
-type emptyStructWithTypeParams[A any] struct{}
-
-var _ = emptyStructWithTypeParams[int]{} // no suggested fix
-
-type basicStructWithTypeParams[T any] struct {
-	foo T
-}
-
-var _ = basicStructWithTypeParams[int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStructWithTypeParams[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStructWithTypeParams[string, int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = twoArgStructWithTypeParams[int, string]{
-	foo: 0,
-	bar: "bar",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStructWithTypeParams struct {
-	bar   string
-	basic basicStructWithTypeParams[int]
-}
-
-var _ = nestedStructWithTypeParams{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-func _[T any]() {
-	type S struct{ t T }
-	_ = S{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_typeparams_32_36 --
-//go:build go1.18
-// +build go1.18
-
-package fillstruct
-
-type emptyStructWithTypeParams[A any] struct{}
-
-var _ = emptyStructWithTypeParams[int]{} // no suggested fix
-
-type basicStructWithTypeParams[T any] struct {
-	foo T
-}
-
-var _ = basicStructWithTypeParams[int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStructWithTypeParams[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStructWithTypeParams[string, int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = twoArgStructWithTypeParams[int, string]{
-	bar: "bar",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStructWithTypeParams struct {
-	bar   string
-	basic basicStructWithTypeParams[int]
-}
-
-var _ = nestedStructWithTypeParams{
-	bar:   "",
-	basic: basicStructWithTypeParams{},
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-func _[T any]() {
-	type S struct{ t T }
-	_ = S{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
--- suggestedfix_typeparams_36_8 --
-//go:build go1.18
-// +build go1.18
-
-package fillstruct
-
-type emptyStructWithTypeParams[A any] struct{}
-
-var _ = emptyStructWithTypeParams[int]{} // no suggested fix
-
-type basicStructWithTypeParams[T any] struct {
-	foo T
-}
-
-var _ = basicStructWithTypeParams[int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type twoArgStructWithTypeParams[F, B any] struct {
-	foo F
-	bar B
-}
-
-var _ = twoArgStructWithTypeParams[string, int]{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-var _ = twoArgStructWithTypeParams[int, string]{
-	bar: "bar",
-} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-type nestedStructWithTypeParams struct {
-	bar   string
-	basic basicStructWithTypeParams[int]
-}
-
-var _ = nestedStructWithTypeParams{} //@suggestedfix("}", "refactor.rewrite", "Fill")
-
-func _[T any]() {
-	type S struct{ t T }
-	_ = S{
-		t: *new(T),
-	} //@suggestedfix("}", "refactor.rewrite", "Fill")
-}
-
diff -urN a/gopls/internal/lsp/testdata/folding/a.go b/gopls/internal/lsp/testdata/folding/a.go
--- a/gopls/internal/lsp/testdata/folding/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/folding/a.go	1969-12-31 16:00:00
@@ -1,75 +0,0 @@
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {
-			fmt.Println("true")
-		} else {
-			fmt.Println("false")
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {
-			fmt.Println("true from x")
-		} else {
-			fmt.Println("false from x")
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
diff -urN a/gopls/internal/lsp/testdata/folding/a.go.golden b/gopls/internal/lsp/testdata/folding/a.go.golden
--- a/gopls/internal/lsp/testdata/folding/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/folding/a.go.golden	1969-12-31 16:00:00
@@ -1,759 +0,0 @@
--- foldingRange-0 --
-package folding //@fold("package")
-
-import (<>)
-
-import _ "os"
-
-// bar is a function.<>
-func bar(<>) string {<>}
-
--- foldingRange-1 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {<>}
-	/* This is a multiline<>
-
-	/* This is a multiline<>
-	_ = []int{<>}
-	_ = [2]string{<>}
-	_ = map[string]int{<>}
-	type T struct {<>}
-	_ = T{<>}
-	x, y := make(<>), make(<>)
-	select {<>}
-	// This is a multiline comment<>
-	return <>
-}
-
--- foldingRange-2 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:<>
-	case false:<>
-	default:<>
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:<>
-	case <-y:<>
-	default:<>
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-3 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {<>} else {<>}
-	case false:
-		fmt.Println(<>)
-	default:
-		fmt.Println(<>)
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {<>} else {<>}
-	case <-y:
-		fmt.Println(<>)
-	default:
-		fmt.Println(<>)
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-4 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {
-			fmt.Println(<>)
-		} else {
-			fmt.Println(<>)
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {
-			fmt.Println(<>)
-		} else {
-			fmt.Println(<>)
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-cmd --
-3:9-6:0
-10:22-11:32
-12:10-12:9
-12:20-75:0
-14:10-25:1
-15:12-20:3
-16:12-18:2
-17:16-17:21
-18:11-20:2
-19:16-19:22
-21:13-22:22
-22:15-22:21
-23:10-24:24
-24:15-24:23
-26:24-28:11
-30:24-33:32
-34:12-38:1
-39:16-41:1
-42:21-46:1
-47:17-51:1
-52:8-56:1
-57:15-57:23
-57:32-57:40
-58:10-69:1
-59:18-64:3
-60:11-62:2
-61:16-61:28
-62:11-64:2
-63:16-63:29
-65:11-66:18
-66:15-66:17
-67:10-68:24
-68:15-68:23
-70:32-71:30
-72:9-74:16
-
--- foldingRange-comment-0 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.<>
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {
-			fmt.Println("true")
-		} else {
-			fmt.Println("false")
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline<>
-
-	/* This is a multiline<>
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {
-			fmt.Println("true from x")
-		} else {
-			fmt.Println("false from x")
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment<>
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-imports-0 --
-package folding //@fold("package")
-
-import (<>)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {
-			fmt.Println("true")
-		} else {
-			fmt.Println("false")
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {
-			fmt.Println("true from x")
-		} else {
-			fmt.Println("false from x")
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-lineFolding-0 --
-package folding //@fold("package")
-
-import (<>
-)
-
-import _ "os"
-
-// bar is a function.<>
-func bar() string {<>
-}
-
--- foldingRange-lineFolding-1 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {<>
-	}
-	/* This is a multiline<>
-
-	/* This is a multiline<>
-	_ = []int{<>,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{<>,
-	}
-	type T struct {<>
-	}
-	_ = T{<>,
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {<>
-	}
-	// This is a multiline comment<>
-	return <>
-}
-
--- foldingRange-lineFolding-2 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:<>
-	case false:<>
-	default:<>
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:<>
-	case <-y:<>
-	default:<>
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-lineFolding-3 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {<>
-		} else {<>
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {<>
-		} else {<>
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-lineFolding-comment-0 --
-package folding //@fold("package")
-
-import (
-	"fmt"
-	_ "log"
-)
-
-import _ "os"
-
-// bar is a function.<>
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {
-			fmt.Println("true")
-		} else {
-			fmt.Println("false")
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline<>
-
-	/* This is a multiline<>
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {
-			fmt.Println("true from x")
-		} else {
-			fmt.Println("false from x")
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment<>
-	return `
-this string
-is not indented`
-}
-
--- foldingRange-lineFolding-imports-0 --
-package folding //@fold("package")
-
-import (<>
-)
-
-import _ "os"
-
-// bar is a function.
-// With a multiline doc comment.
-func bar() string {
-	/* This is a single line comment */
-	switch {
-	case true:
-		if true {
-			fmt.Println("true")
-		} else {
-			fmt.Println("false")
-		}
-	case false:
-		fmt.Println("false")
-	default:
-		fmt.Println("default")
-	}
-	/* This is a multiline
-	block
-	comment */
-
-	/* This is a multiline
-	block
-	comment */
-	// Followed by another comment.
-	_ = []int{
-		1,
-		2,
-		3,
-	}
-	_ = [2]string{"d",
-		"e",
-	}
-	_ = map[string]int{
-		"a": 1,
-		"b": 2,
-		"c": 3,
-	}
-	type T struct {
-		f string
-		g int
-		h string
-	}
-	_ = T{
-		f: "j",
-		g: 4,
-		h: "i",
-	}
-	x, y := make(chan bool), make(chan bool)
-	select {
-	case val := <-x:
-		if val {
-			fmt.Println("true from x")
-		} else {
-			fmt.Println("false from x")
-		}
-	case <-y:
-		fmt.Println("y")
-	default:
-		fmt.Println("default")
-	}
-	// This is a multiline comment
-	// that is not a doc comment.
-	return `
-this string
-is not indented`
-}
-
diff -urN a/gopls/internal/lsp/testdata/folding/bad.go.golden b/gopls/internal/lsp/testdata/folding/bad.go.golden
--- a/gopls/internal/lsp/testdata/folding/bad.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/folding/bad.go.golden	1969-12-31 16:00:00
@@ -1,91 +0,0 @@
--- foldingRange-0 --
-package folding //@fold("package")
-
-import (<>)
-
-import (<>)
-	
-// badBar is a function.
-func badBar(<>) string {<>}
-
--- foldingRange-1 --
-package folding //@fold("package")
-
-import ( "fmt"
-	_ "log"
-)
-
-import ( 
-	_ "os" )
-	
-// badBar is a function.
-func badBar() string { x := true
-	if x {<>} else {<>}
-	return
-}
-
--- foldingRange-2 --
-package folding //@fold("package")
-
-import ( "fmt"
-	_ "log"
-)
-
-import ( 
-	_ "os" )
-	
-// badBar is a function.
-func badBar() string { x := true
-	if x { 
-		// This is the only foldable thing in this file when lineFoldingOnly
-		fmt.Println(<>)
-	} else {
-		fmt.Println(<>) }
-	return
-}
-
--- foldingRange-cmd --
-3:9-5:0
-7:9-8:8
-11:13-11:12
-11:23-18:0
-12:8-15:1
-14:15-14:20
-15:10-16:23
-16:15-16:21
-
--- foldingRange-imports-0 --
-package folding //@fold("package")
-
-import (<>)
-
-import (<>)
-	
-// badBar is a function.
-func badBar() string { x := true
-	if x { 
-		// This is the only foldable thing in this file when lineFoldingOnly
-		fmt.Println("true")
-	} else {
-		fmt.Println("false") }
-	return
-}
-
--- foldingRange-lineFolding-0 --
-package folding //@fold("package")
-
-import ( "fmt"
-	_ "log"
-)
-
-import ( 
-	_ "os" )
-	
-// badBar is a function.
-func badBar() string { x := true
-	if x {<>
-	} else {
-		fmt.Println("false") }
-	return
-}
-
diff -urN a/gopls/internal/lsp/testdata/folding/bad.go.in b/gopls/internal/lsp/testdata/folding/bad.go.in
--- a/gopls/internal/lsp/testdata/folding/bad.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/folding/bad.go.in	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-package folding //@fold("package")
-
-import ( "fmt"
-	_ "log"
-)
-
-import ( 
-	_ "os" )
-	
-// badBar is a function.
-func badBar() string { x := true
-	if x { 
-		// This is the only foldable thing in this file when lineFoldingOnly
-		fmt.Println("true")
-	} else {
-		fmt.Println("false") }
-	return
-}
diff -urN a/gopls/internal/lsp/testdata/foo/foo.go b/gopls/internal/lsp/testdata/foo/foo.go
--- a/gopls/internal/lsp/testdata/foo/foo.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/foo/foo.go	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-package foo //@mark(PackageFoo, "foo"),item(PackageFoo, "foo", "\"golang.org/lsptests/foo\"", "package")
-
-type StructFoo struct { //@item(StructFoo, "StructFoo", "struct{...}", "struct")
-	Value int //@item(Value, "Value", "int", "field")
-}
-
-// Pre-set this marker, as we don't have a "source" for it in this package.
-/* Error() */ //@item(Error, "Error", "func() string", "method")
-
-func Foo() { //@item(Foo, "Foo", "func()", "func")
-	var err error
-	err.Error() //@complete("E", Error)
-}
-
-func _() {
-	var sFoo StructFoo           //@mark(sFoo1, "sFoo"),complete("t", StructFoo)
-	if x := sFoo; x.Value == 1 { //@mark(sFoo2, "sFoo"),complete("V", Value),typdef("sFoo", StructFoo),refs("sFo", sFoo1, sFoo2)
-		return
-	}
-}
-
-func _() {
-	shadowed := 123
-	{
-		shadowed := "hi" //@item(shadowed, "shadowed", "string", "var"),refs("shadowed", shadowed)
-		sha              //@complete("a", shadowed)
-	}
-}
-
-type IntFoo int //@item(IntFoo, "IntFoo", "int", "type")
diff -urN a/gopls/internal/lsp/testdata/format/bad_format.go.golden b/gopls/internal/lsp/testdata/format/bad_format.go.golden
--- a/gopls/internal/lsp/testdata/format/bad_format.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/bad_format.go.golden	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
--- gofmt --
-package format //@format("package")
-
-import (
-	"fmt"
-	"log"
-	"runtime"
-)
-
-func hello() {
-
-	var x int //@diag("x", "compiler", "x declared (and|but) not used", "error")
-}
-
-func hi() {
-	runtime.GOROOT()
-	fmt.Printf("")
-
-	log.Printf("")
-}
-
diff -urN a/gopls/internal/lsp/testdata/format/bad_format.go.in b/gopls/internal/lsp/testdata/format/bad_format.go.in
--- a/gopls/internal/lsp/testdata/format/bad_format.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/bad_format.go.in	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-package format //@format("package")
-
-import (
-	"runtime"
-	"fmt"
-	"log"
-)
-
-func hello() {
-
-
-
-
-	var x int //@diag("x", "compiler", "x declared (and|but) not used", "error")
-}
-
-func hi() {
-	runtime.GOROOT()
-	fmt.Printf("")
-
-	log.Printf("")
-}
diff -urN a/gopls/internal/lsp/testdata/format/good_format.go b/gopls/internal/lsp/testdata/format/good_format.go
--- a/gopls/internal/lsp/testdata/format/good_format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/good_format.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package format //@format("package")
-
-import (
-	"log"
-)
-
-func goodbye() {
-	log.Printf("byeeeee")
-}
diff -urN a/gopls/internal/lsp/testdata/format/good_format.go.golden b/gopls/internal/lsp/testdata/format/good_format.go.golden
--- a/gopls/internal/lsp/testdata/format/good_format.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/good_format.go.golden	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
--- gofmt --
-package format //@format("package")
-
-import (
-	"log"
-)
-
-func goodbye() {
-	log.Printf("byeeeee")
-}
-
diff -urN a/gopls/internal/lsp/testdata/format/newline_format.go.golden b/gopls/internal/lsp/testdata/format/newline_format.go.golden
--- a/gopls/internal/lsp/testdata/format/newline_format.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/newline_format.go.golden	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
--- gofmt --
-package format //@format("package")
-func _()       {}
-
diff -urN a/gopls/internal/lsp/testdata/format/newline_format.go.in b/gopls/internal/lsp/testdata/format/newline_format.go.in
--- a/gopls/internal/lsp/testdata/format/newline_format.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/newline_format.go.in	1969-12-31 16:00:00
@@ -1,2 +0,0 @@
-package format //@format("package")
-func _() {}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/format/one_line.go.golden b/gopls/internal/lsp/testdata/format/one_line.go.golden
--- a/gopls/internal/lsp/testdata/format/one_line.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/one_line.go.golden	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
--- gofmt --
-package format //@format("package")
-
diff -urN a/gopls/internal/lsp/testdata/format/one_line.go.in b/gopls/internal/lsp/testdata/format/one_line.go.in
--- a/gopls/internal/lsp/testdata/format/one_line.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/format/one_line.go.in	1969-12-31 16:00:00
@@ -1 +0,0 @@
-package format //@format("package")
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/func_rank/func_rank.go.in b/gopls/internal/lsp/testdata/func_rank/func_rank.go.in
--- a/gopls/internal/lsp/testdata/func_rank/func_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/func_rank/func_rank.go.in	1969-12-31 16:00:00
@@ -1,70 +0,0 @@
-package func_rank
-
-import "net/http"
-
-var stringAVar = "var"    //@item(stringAVar, "stringAVar", "string", "var")
-func stringBFunc() string { return "str" } //@item(stringBFunc, "stringBFunc", "func() string", "func")
-type stringer struct{}    //@item(stringer, "stringer", "struct{...}", "struct")
-
-func _() stringer //@complete("tr", stringer)
-
-func _(val stringer) {} //@complete("tr", stringer)
-
-func (stringer) _() {} //@complete("tr", stringer)
-
-func _() {
-	var s struct {
-		AA int    //@item(rankAA, "AA", "int", "field")
-		AB string //@item(rankAB, "AB", "string", "field")
-		AC int    //@item(rankAC, "AC", "int", "field")
-	}
-	fnStr := func(string) {}
-	fnStr(s.A)      //@complete(")", rankAB, rankAA, rankAC)
-	fnStr("" + s.A) //@complete(")", rankAB, rankAA, rankAC)
-
-	fnInt := func(int) {}
-	fnInt(-s.A) //@complete(")", rankAA, rankAC, rankAB)
-
-	// no expected type
-	fnInt(func() int { s.A }) //@complete(" }", rankAA, rankAB, rankAC)
-	fnInt(s.A())              //@complete("()", rankAA, rankAC, rankAB)
-	fnInt([]int{}[s.A])       //@complete("])", rankAA, rankAC, rankAB)
-	fnInt([]int{}[:s.A])      //@complete("])", rankAA, rankAC, rankAB)
-
-	fnInt(s.A.(int)) //@complete(".(", rankAA, rankAC, rankAB)
-
-	fnPtr := func(*string) {}
-	fnPtr(&s.A) //@complete(")", rankAB, rankAA, rankAC)
-
-	var aaPtr *string //@item(rankAAPtr, "aaPtr", "*string", "var")
-	var abPtr *int    //@item(rankABPtr, "abPtr", "*int", "var")
-	fnInt(*a)         //@complete(")", rankABPtr, rankAAPtr)
-
-	_ = func() string {
-		return s.A //@complete(" //", rankAB, rankAA, rankAC)
-	}
-}
-
-type foo struct {
-	fooPrivateField int //@item(rankFooPrivField, "fooPrivateField", "int", "field")
-	FooPublicField  int //@item(rankFooPubField, "FooPublicField", "int", "field")
-}
-
-func (foo) fooPrivateMethod() int { //@item(rankFooPrivMeth, "fooPrivateMethod", "func() int", "method")
-	return 0
-}
-
-func (foo) FooPublicMethod() int { //@item(rankFooPubMeth, "FooPublicMethod", "func() int", "method")
-	return 0
-}
-
-func _() {
-	var _ int = foo{}. //@rank(" //", rankFooPrivField, rankFooPubField),rank(" //", rankFooPrivMeth, rankFooPubMeth),rank(" //", rankFooPrivField, rankFooPrivMeth)
-}
-
-func _() {
-	HandleFunc //@item(httpHandleFunc, "HandleFunc", "func(pattern string, handler func(http.ResponseWriter, *http.Request))", "func")
-	HandlerFunc //@item(httpHandlerFunc, "HandlerFunc", "func(http.ResponseWriter, *http.Request)", "type")
-
-	http.HandleFunc //@rank(" //", httpHandleFunc, httpHandlerFunc)
-}
diff -urN a/gopls/internal/lsp/testdata/funcsig/func_sig.go b/gopls/internal/lsp/testdata/funcsig/func_sig.go
--- a/gopls/internal/lsp/testdata/funcsig/func_sig.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/funcsig/func_sig.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package funcsig
-
-type someType int //@item(sigSomeType, "someType", "int", "type")
-
-// Don't complete "foo" in signature.
-func (foo someType) _() { //@item(sigFoo, "foo", "someType", "var"),complete(") {", sigSomeType)
-
-	//@complete("", sigFoo, sigSomeType)
-}
diff -urN a/gopls/internal/lsp/testdata/funcvalue/func_value.go b/gopls/internal/lsp/testdata/funcvalue/func_value.go
--- a/gopls/internal/lsp/testdata/funcvalue/func_value.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/funcvalue/func_value.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package funcvalue
-
-func fooFunc() int { //@item(fvFooFunc, "fooFunc", "func() int", "func")
-	return 0
-}
-
-var _ = fooFunc() //@item(fvFooFuncCall, "fooFunc", "func() int", "func")
-
-var fooVar = func() int { //@item(fvFooVar, "fooVar", "func() int", "var")
-	return 0
-}
-
-var _ = fooVar() //@item(fvFooVarCall, "fooVar", "func() int", "var")
-
-type myFunc func() int
-
-var fooType myFunc = fooVar //@item(fvFooType, "fooType", "myFunc", "var")
-
-var _ = fooType() //@item(fvFooTypeCall, "fooType", "func() int", "var")
-
-func _() {
-	var f func() int
-	f = foo //@complete(" //", fvFooFunc, fvFooType, fvFooVar)
-
-	var i int
-	i = foo //@complete(" //", fvFooFuncCall, fvFooTypeCall, fvFooVarCall)
-}
diff -urN a/gopls/internal/lsp/testdata/fuzzymatch/fuzzymatch.go b/gopls/internal/lsp/testdata/fuzzymatch/fuzzymatch.go
--- a/gopls/internal/lsp/testdata/fuzzymatch/fuzzymatch.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/fuzzymatch/fuzzymatch.go	1969-12-31 16:00:00
@@ -1,48 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package fuzzy
-
-func _() {
-	var a struct {
-		fabar  int
-		fooBar string
-	}
-
-	a.fabar  //@item(fuzzFabarField, "a.fabar", "int", "field")
-	a.fooBar //@item(fuzzFooBarField, "a.fooBar", "string", "field")
-
-	afa //@fuzzy(" //", fuzzFabarField, fuzzFooBarField)
-	afb //@fuzzy(" //", fuzzFooBarField, fuzzFabarField)
-
-	fab //@fuzzy(" //", fuzzFabarField)
-
-	var myString string
-	myString = af //@fuzzy(" //", fuzzFooBarField, fuzzFabarField)
-
-	var b struct {
-		c struct {
-			d struct {
-				e struct {
-					abc string
-				}
-				abc float32
-			}
-			abc bool
-		}
-		abc int
-	}
-
-	b.abc       //@item(fuzzABCInt, "b.abc", "int", "field")
-	b.c.abc     //@item(fuzzABCbool, "b.c.abc", "bool", "field")
-	b.c.d.abc   //@item(fuzzABCfloat, "b.c.d.abc", "float32", "field")
-	b.c.d.e.abc //@item(fuzzABCstring, "b.c.d.e.abc", "string", "field")
-
-	// in depth order by default
-	abc //@fuzzy(" //", fuzzABCInt, fuzzABCbool, fuzzABCfloat)
-
-	// deep candidate that matches expected type should still ranked first
-	var s string
-	s = abc //@fuzzy(" //", fuzzABCstring, fuzzABCInt, fuzzABCbool)
-}
diff -urN a/gopls/internal/lsp/testdata/generate/generate.go b/gopls/internal/lsp/testdata/generate/generate.go
--- a/gopls/internal/lsp/testdata/generate/generate.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/generate/generate.go	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
-package generate
-
-//go:generate echo Hi //@ codelens("//go:generate", "run go generate", "generate"), codelens("//go:generate", "run go generate ./...", "generate")
-//go:generate echo I shall have no CodeLens
diff -urN a/gopls/internal/lsp/testdata/generated/generated.go b/gopls/internal/lsp/testdata/generated/generated.go
--- a/gopls/internal/lsp/testdata/generated/generated.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/generated/generated.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package generated
-
-// Code generated by generator.go. DO NOT EDIT.
-
-func _() {
-	var y int //@diag("y", "compiler", "y declared (and|but) not used", "error")
-}
diff -urN a/gopls/internal/lsp/testdata/generated/generator.go b/gopls/internal/lsp/testdata/generated/generator.go
--- a/gopls/internal/lsp/testdata/generated/generator.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/generated/generator.go	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package generated
-
-func _() {
-	var x int //@diag("x", "compiler", "x declared (and|but) not used", "error")
-}
diff -urN a/gopls/internal/lsp/testdata/godef/a/a.go b/gopls/internal/lsp/testdata/godef/a/a.go
--- a/gopls/internal/lsp/testdata/godef/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/a.go	1969-12-31 16:00:00
@@ -1,111 +0,0 @@
-// Package a is a package for testing go to definition.
-package a //@mark(aPackage, "a "),hoverdef("a ", aPackage)
-
-import (
-	"fmt"
-	"go/types"
-	"sync"
-)
-
-var (
-	// x is a variable.
-	x string //@x,hoverdef("x", x)
-)
-
-// Constant block. When I hover on h, I should see this comment.
-const (
-	// When I hover on g, I should see this comment.
-	g = 1 //@g,hoverdef("g", g)
-
-	h = 2 //@h,hoverdef("h", h)
-)
-
-// z is a variable too.
-var z string //@z,hoverdef("z", z)
-
-type A string //@mark(AString, "A")
-
-func AStuff() { //@AStuff
-	x := 5
-	Random2(x) //@godef("dom2", Random2)
-	Random()   //@godef("()", Random)
-
-	var err error         //@err
-	fmt.Printf("%v", err) //@godef("err", err)
-
-	var y string       //@string,hoverdef("string", string)
-	_ = make([]int, 0) //@make,hoverdef("make", make)
-
-	var mu sync.Mutex
-	mu.Lock() //@Lock,hoverdef("Lock", Lock)
-
-	var typ *types.Named //@mark(typesImport, "types"),hoverdef("types", typesImport)
-	typ.Obj().Name()     //@Name,hoverdef("Name", Name)
-}
-
-type A struct {
-}
-
-func (_ A) Hi() {} //@mark(AHi, "Hi")
-
-type S struct {
-	Field int //@mark(AField, "Field")
-	R         // embed a struct
-	H         // embed an interface
-}
-
-type R struct {
-	Field2 int //@mark(AField2, "Field2")
-}
-
-func (_ R) Hey() {} //@mark(AHey, "Hey")
-
-type H interface { //@H
-	Goodbye() //@mark(AGoodbye, "Goodbye")
-}
-
-type I interface { //@I
-	B() //@mark(AB, "B")
-	J
-}
-
-type J interface { //@J
-	Hello() //@mark(AHello, "Hello")
-}
-
-func _() {
-	// 1st type declaration block
-	type (
-		a struct { //@mark(declBlockA, "a"),hoverdef("a", declBlockA)
-			x string
-		}
-	)
-
-	// 2nd type declaration block
-	type (
-		// b has a comment
-		b struct{} //@mark(declBlockB, "b"),hoverdef("b", declBlockB)
-	)
-
-	// 3rd type declaration block
-	type (
-		// c is a struct
-		c struct { //@mark(declBlockC, "c"),hoverdef("c", declBlockC)
-			f string
-		}
-
-		d string //@mark(declBlockD, "d"),hoverdef("d", declBlockD)
-	)
-
-	type (
-		e struct { //@mark(declBlockE, "e"),hoverdef("e", declBlockE)
-			f float64
-		} // e has a comment
-	)
-}
-
-var (
-	hh H //@hoverdef("H", H)
-	ii I //@hoverdef("I", I)
-	jj J //@hoverdef("J", J)
-)
diff -urN a/gopls/internal/lsp/testdata/godef/a/a.go.golden b/gopls/internal/lsp/testdata/godef/a/a.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/a.go.golden	1969-12-31 16:00:00
@@ -1,230 +0,0 @@
--- H-hoverdef --
-```go
-type H interface {
-	Goodbye() //@mark(AGoodbye, "Goodbye")
-}
-```
-
-[`a.H` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#H)
--- I-hoverdef --
-```go
-type I interface {
-	B() //@mark(AB, "B")
-	J
-}
-```
-
-[`a.I` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#I)
--- J-hoverdef --
-```go
-type J interface {
-	Hello() //@mark(AHello, "Hello")
-}
-```
-
-[`a.J` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#J)
--- Lock-hoverdef --
-```go
-func (*sync.Mutex).Lock()
-```
-
-Lock locks m.
-
-
-[`(sync.Mutex).Lock` on pkg.go.dev](https://pkg.go.dev/sync#Mutex.Lock)
--- Name-hoverdef --
-```go
-func (*types.object).Name() string
-```
-
-Name returns the object's (package-local, unqualified) name.
-
-
-[`(types.TypeName).Name` on pkg.go.dev](https://pkg.go.dev/go/types#TypeName.Name)
--- Random-definition --
-godef/a/random.go:3:6-12: defined here as ```go
-func Random() int
-```
-
-[`a.Random` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Random)
--- Random-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/random.go",
-		"start": {
-			"line": 3,
-			"column": 6,
-			"offset": 16
-		},
-		"end": {
-			"line": 3,
-			"column": 12,
-			"offset": 22
-		}
-	},
-	"description": "```go\nfunc Random() int\n```\n\n[`a.Random` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Random)"
-}
-
--- Random-hoverdef --
-```go
-func Random() int
-```
-
-[`a.Random` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Random)
--- Random2-definition --
-godef/a/random.go:8:6-13: defined here as ```go
-func Random2(y int) int
-```
-
-[`a.Random2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Random2)
--- Random2-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/random.go",
-		"start": {
-			"line": 8,
-			"column": 6,
-			"offset": 71
-		},
-		"end": {
-			"line": 8,
-			"column": 13,
-			"offset": 78
-		}
-	},
-	"description": "```go\nfunc Random2(y int) int\n```\n\n[`a.Random2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Random2)"
-}
-
--- Random2-hoverdef --
-```go
-func Random2(y int) int
-```
-
-[`a.Random2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Random2)
--- aPackage-hoverdef --
-Package a is a package for testing go to definition.
-
--- declBlockA-hoverdef --
-```go
-type a struct {
-	x string
-}
-```
-
-1st type declaration block
-
--- declBlockB-hoverdef --
-```go
-type b struct{}
-```
-
-b has a comment
-
--- declBlockC-hoverdef --
-```go
-type c struct {
-	f string
-}
-```
-
-c is a struct
-
--- declBlockD-hoverdef --
-```go
-type d string
-```
-
-3rd type declaration block
-
--- declBlockE-hoverdef --
-```go
-type e struct {
-	f float64
-}
-```
-
-e has a comment
-
--- err-definition --
-godef/a/a.go:33:6-9: defined here as ```go
-var err error
-```
-
-@err
--- err-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/a.go",
-		"start": {
-			"line": 33,
-			"column": 6,
-			"offset": 612
-		},
-		"end": {
-			"line": 33,
-			"column": 9,
-			"offset": 615
-		}
-	},
-	"description": "```go\nvar err error\n```\n\n@err"
-}
-
--- err-hoverdef --
-```go
-var err error
-```
-
-@err
-
--- g-hoverdef --
-```go
-const g untyped int = 1
-```
-
-When I hover on g, I should see this comment.
-
--- h-hoverdef --
-```go
-const h untyped int = 2
-```
-
-Constant block.
-
--- make-hoverdef --
-```go
-func make(t Type, size ...int) Type
-```
-
-The make built-in function allocates and initializes an object of type slice, map, or chan (only).
-
-
-[`make` on pkg.go.dev](https://pkg.go.dev/builtin#make)
--- string-hoverdef --
-```go
-type string string
-```
-
-string is the set of all strings of 8-bit bytes, conventionally but not necessarily representing UTF-8-encoded text.
-
-
-[`string` on pkg.go.dev](https://pkg.go.dev/builtin#string)
--- typesImport-hoverdef --
-```go
-package types ("go/types")
-```
-
-[`types` on pkg.go.dev](https://pkg.go.dev/go/types)
--- x-hoverdef --
-```go
-var x string
-```
-
-x is a variable.
-
--- z-hoverdef --
-```go
-var z string
-```
-
-z is a variable too.
-
diff -urN a/gopls/internal/lsp/testdata/godef/a/a_test.go b/gopls/internal/lsp/testdata/godef/a/a_test.go
--- a/gopls/internal/lsp/testdata/godef/a/a_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/a_test.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package a
-
-import (
-	"testing"
-)
-
-func TestA(t *testing.T) { //@TestA,godef(TestA, TestA)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/a/a_test.go.golden b/gopls/internal/lsp/testdata/godef/a/a_test.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/a_test.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/a_test.go.golden	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
--- TestA-definition --
-godef/a/a_test.go:7:6-11: defined here as ```go
-func TestA(t *testing.T)
-```
--- TestA-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/a_test.go",
-		"start": {
-			"line": 7,
-			"column": 6,
-			"offset": 39
-		},
-		"end": {
-			"line": 7,
-			"column": 11,
-			"offset": 44
-		}
-	},
-	"description": "```go\nfunc TestA(t *testing.T)\n```"
-}
-
--- TestA-hoverdef --
-```go
-func TestA(t *testing.T)
-```
diff -urN a/gopls/internal/lsp/testdata/godef/a/a_x_test.go b/gopls/internal/lsp/testdata/godef/a/a_x_test.go
--- a/gopls/internal/lsp/testdata/godef/a/a_x_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/a_x_test.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package a_test
-
-import (
-	"testing"
-)
-
-func TestA2(t *testing.T) { //@TestA2,godef(TestA2, TestA2)
-	Nonexistant() //@diag("Nonexistant", "compiler", "(undeclared name|undefined): Nonexistant", "error")
-}
diff -urN a/gopls/internal/lsp/testdata/godef/a/a_x_test.go.golden b/gopls/internal/lsp/testdata/godef/a/a_x_test.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/a_x_test.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/a_x_test.go.golden	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
--- TestA2-definition --
-godef/a/a_x_test.go:7:6-12: defined here as ```go
-func TestA2(t *testing.T)
-```
--- TestA2-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/a_x_test.go",
-		"start": {
-			"line": 7,
-			"column": 6,
-			"offset": 44
-		},
-		"end": {
-			"line": 7,
-			"column": 12,
-			"offset": 50
-		}
-	},
-	"description": "```go\nfunc TestA2(t *testing.T)\n```"
-}
-
--- TestA2-hoverdef --
-```go
-func TestA2(t *testing.T)
-```
diff -urN a/gopls/internal/lsp/testdata/godef/a/d.go b/gopls/internal/lsp/testdata/godef/a/d.go
--- a/gopls/internal/lsp/testdata/godef/a/d.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/d.go	1969-12-31 16:00:00
@@ -1,69 +0,0 @@
-package a //@mark(a, "a "),hoverdef("a ", a)
-
-import "fmt"
-
-type Thing struct { //@Thing
-	Member string //@Member
-}
-
-var Other Thing //@Other
-
-func Things(val []string) []Thing { //@Things
-	return nil
-}
-
-func (t Thing) Method(i int) string { //@Method
-	return t.Member
-}
-
-func (t Thing) Method3() {
-}
-
-func (t *Thing) Method2(i int, j int) (error, string) {
-	return nil, t.Member
-}
-
-func (t *Thing) private() {
-}
-
-func useThings() {
-	t := Thing{ //@mark(aStructType, "ing")
-		Member: "string", //@mark(fMember, "ember")
-	}
-	fmt.Print(t.Member) //@mark(aMember, "ember")
-	fmt.Print(Other)    //@mark(aVar, "ther")
-	Things()            //@mark(aFunc, "ings")
-	t.Method()          //@mark(aMethod, "eth")
-}
-
-type NextThing struct { //@NextThing
-	Thing
-	Value int
-}
-
-func (n NextThing) another() string {
-	return n.Member
-}
-
-// Shadows Thing.Method3
-func (n *NextThing) Method3() int {
-	return n.Value
-}
-
-var nextThing NextThing //@hoverdef("NextThing", NextThing)
-
-/*@
-godef(aStructType, Thing)
-godef(aMember, Member)
-godef(aVar, Other)
-godef(aFunc, Things)
-godef(aMethod, Method)
-godef(fMember, Member)
-godef(Member, Member)
-
-//param
-//package name
-//const
-//anon field
-
-*/
diff -urN a/gopls/internal/lsp/testdata/godef/a/d.go.golden b/gopls/internal/lsp/testdata/godef/a/d.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/d.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/d.go.golden	1969-12-31 16:00:00
@@ -1,191 +0,0 @@
--- Member-definition --
-godef/a/d.go:6:2-8: defined here as ```go
-field Member string
-```
-
-@Member
-
-
-[`(a.Thing).Member` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Member)
--- Member-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 6,
-			"column": 2,
-			"offset": 90
-		},
-		"end": {
-			"line": 6,
-			"column": 8,
-			"offset": 96
-		}
-	},
-	"description": "```go\nfield Member string\n```\n\n@Member\n\n\n[`(a.Thing).Member` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Member)"
-}
-
--- Member-hoverdef --
-```go
-field Member string
-```
-
-@Member
-
-
-[`(a.Thing).Member` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Member)
--- Method-definition --
-godef/a/d.go:15:16-22: defined here as ```go
-func (Thing).Method(i int) string
-```
-
-[`(a.Thing).Method` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Method)
--- Method-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 15,
-			"column": 16,
-			"offset": 219
-		},
-		"end": {
-			"line": 15,
-			"column": 22,
-			"offset": 225
-		}
-	},
-	"description": "```go\nfunc (Thing).Method(i int) string\n```\n\n[`(a.Thing).Method` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Method)"
-}
-
--- Method-hoverdef --
-```go
-func (Thing).Method(i int) string
-```
-
-[`(a.Thing).Method` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Method)
--- NextThing-hoverdef --
-```go
-type NextThing struct {
-	Thing
-	Value int
-}
-
-func (*NextThing).Method3() int
-func (NextThing).another() string
-```
-
-[`a.NextThing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#NextThing)
--- Other-definition --
-godef/a/d.go:9:5-10: defined here as ```go
-var Other Thing
-```
-
-@Other
-
-
-[`a.Other` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Other)
--- Other-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 9,
-			"column": 5,
-			"offset": 121
-		},
-		"end": {
-			"line": 9,
-			"column": 10,
-			"offset": 126
-		}
-	},
-	"description": "```go\nvar Other Thing\n```\n\n@Other\n\n\n[`a.Other` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Other)"
-}
-
--- Other-hoverdef --
-```go
-var Other Thing
-```
-
-@Other
-
-
-[`a.Other` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Other)
--- Thing-definition --
-godef/a/d.go:5:6-11: defined here as ```go
-type Thing struct {
-	Member string //@Member
-}
-
-func (Thing).Method(i int) string
-func (*Thing).Method2(i int, j int) (error, string)
-func (Thing).Method3()
-func (*Thing).private()
-```
-
-[`a.Thing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing)
--- Thing-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 5,
-			"column": 6,
-			"offset": 65
-		},
-		"end": {
-			"line": 5,
-			"column": 11,
-			"offset": 70
-		}
-	},
-	"description": "```go\ntype Thing struct {\n\tMember string //@Member\n}\n\nfunc (Thing).Method(i int) string\nfunc (*Thing).Method2(i int, j int) (error, string)\nfunc (Thing).Method3()\nfunc (*Thing).private()\n```\n\n[`a.Thing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing)"
-}
-
--- Thing-hoverdef --
-```go
-type Thing struct {
-	Member string //@Member
-}
-
-func (Thing).Method(i int) string
-func (*Thing).Method2(i int, j int) (error, string)
-func (Thing).Method3()
-func (*Thing).private()
-```
-
-[`a.Thing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing)
--- Things-definition --
-godef/a/d.go:11:6-12: defined here as ```go
-func Things(val []string) []Thing
-```
-
-[`a.Things` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Things)
--- Things-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 11,
-			"column": 6,
-			"offset": 148
-		},
-		"end": {
-			"line": 11,
-			"column": 12,
-			"offset": 154
-		}
-	},
-	"description": "```go\nfunc Things(val []string) []Thing\n```\n\n[`a.Things` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Things)"
-}
-
--- Things-hoverdef --
-```go
-func Things(val []string) []Thing
-```
-
-[`a.Things` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Things)
--- a-hoverdef --
-Package a is a package for testing go to definition.
-
diff -urN a/gopls/internal/lsp/testdata/godef/a/f.go b/gopls/internal/lsp/testdata/godef/a/f.go
--- a/gopls/internal/lsp/testdata/godef/a/f.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/f.go	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-package a
-
-import "fmt"
-
-func TypeStuff() { //@Stuff
-	var x string
-
-	switch y := interface{}(x).(type) { //@mark(switchY, "y"),godef("y", switchY)
-	case int: //@mark(intY, "int")
-		fmt.Printf("%v", y) //@hoverdef("y", intY)
-	case string: //@mark(stringY, "string")
-		fmt.Printf("%v", y) //@hoverdef("y", stringY)
-	}
-
-}
diff -urN a/gopls/internal/lsp/testdata/godef/a/f.go.golden b/gopls/internal/lsp/testdata/godef/a/f.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/f.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/f.go.golden	1969-12-31 16:00:00
@@ -1,34 +0,0 @@
--- intY-hoverdef --
-```go
-var y int
-```
--- stringY-hoverdef --
-```go
-var y string
-```
--- switchY-definition --
-godef/a/f.go:8:9-10: defined here as ```go
-var y interface{}
-```
--- switchY-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/f.go",
-		"start": {
-			"line": 8,
-			"column": 9,
-			"offset": 76
-		},
-		"end": {
-			"line": 8,
-			"column": 10,
-			"offset": 77
-		}
-	},
-	"description": "```go\nvar y interface{}\n```"
-}
-
--- switchY-hoverdef --
-```go
-var y interface{}
-```
diff -urN a/gopls/internal/lsp/testdata/godef/a/g.go b/gopls/internal/lsp/testdata/godef/a/g.go
--- a/gopls/internal/lsp/testdata/godef/a/g.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/g.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package a
-
-import "time"
-
-// dur is a constant of type time.Duration.
-const dur = 15*time.Minute + 10*time.Second + 350*time.Millisecond //@dur,hoverdef("dur", dur)
diff -urN a/gopls/internal/lsp/testdata/godef/a/g.go.golden b/gopls/internal/lsp/testdata/godef/a/g.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/g.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/g.go.golden	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
--- dur-hoverdef --
-```go
-const dur time.Duration = 910350000000 // 15m10.35s
-```
-
-dur is a constant of type time.Duration.
-
diff -urN a/gopls/internal/lsp/testdata/godef/a/h.go b/gopls/internal/lsp/testdata/godef/a/h.go
--- a/gopls/internal/lsp/testdata/godef/a/h.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/h.go	1969-12-31 16:00:00
@@ -1,147 +0,0 @@
-package a
-
-func _() {
-	type s struct {
-		nested struct {
-			// nested number
-			number int64 //@mark(nestedNumber, "number")
-		}
-		nested2 []struct {
-			// nested string
-			str string //@mark(nestedString, "str")
-		}
-		x struct {
-			x struct {
-				x struct {
-					x struct {
-						x struct {
-							// nested map
-							m map[string]float64 //@mark(nestedMap, "m")
-						}
-					}
-				}
-			}
-		}
-	}
-
-	var t s
-	_ = t.nested.number  //@hoverdef("number", nestedNumber)
-	_ = t.nested2[0].str //@hoverdef("str", nestedString)
-	_ = t.x.x.x.x.x.m    //@hoverdef("m", nestedMap)
-}
-
-func _() {
-	var s struct {
-		// a field
-		a int //@mark(structA, "a")
-		// b nested struct
-		b struct { //@mark(structB, "b")
-			// c field of nested struct
-			c int //@mark(structC, "c")
-		}
-	}
-	_ = s.a   //@hoverdef("a", structA)
-	_ = s.b   //@hoverdef("b", structB)
-	_ = s.b.c //@hoverdef("c", structC)
-
-	var arr []struct {
-		// d field
-		d int //@mark(arrD, "d")
-		// e nested struct
-		e struct { //@mark(arrE, "e")
-			// f field of nested struct
-			f int //@mark(arrF, "f")
-		}
-	}
-	_ = arr[0].d   //@hoverdef("d", arrD)
-	_ = arr[0].e   //@hoverdef("e", arrE)
-	_ = arr[0].e.f //@hoverdef("f", arrF)
-
-	var complex []struct {
-		c <-chan map[string][]struct {
-			// h field
-			h int //@mark(complexH, "h")
-			// i nested struct
-			i struct { //@mark(complexI, "i")
-				// j field of nested struct
-				j int //@mark(complexJ, "j")
-			}
-		}
-	}
-	_ = (<-complex[0].c)["0"][0].h   //@hoverdef("h", complexH)
-	_ = (<-complex[0].c)["0"][0].i   //@hoverdef("i", complexI)
-	_ = (<-complex[0].c)["0"][0].i.j //@hoverdef("j", complexJ)
-
-	var mapWithStructKey map[struct {
-		// X key field
-		x []string //@mark(mapStructKeyX, "x")
-	}]int
-	for k := range mapWithStructKey {
-		_ = k.x //@hoverdef("x", mapStructKeyX)
-	}
-
-	var mapWithStructKeyAndValue map[struct {
-		// Y key field
-		y string //@mark(mapStructKeyY, "y")
-	}]struct {
-		// X value field
-		x string //@mark(mapStructValueX, "x")
-	}
-	for k, v := range mapWithStructKeyAndValue {
-		// TODO: we don't show docs for y field because both map key and value
-		// are structs. And in this case, we parse only map value
-		_ = k.y //@hoverdef("y", mapStructKeyY)
-		_ = v.x //@hoverdef("x", mapStructValueX)
-	}
-
-	var i []map[string]interface {
-		// open method comment
-		open() error //@mark(openMethod, "open")
-	}
-	i[0]["1"].open() //@hoverdef("open", openMethod)
-}
-
-func _() {
-	test := struct {
-		// test description
-		desc string //@mark(testDescription, "desc")
-	}{}
-	_ = test.desc //@hoverdef("desc", testDescription)
-
-	for _, tt := range []struct {
-		// test input
-		in map[string][]struct { //@mark(testInput, "in")
-			// test key
-			key string //@mark(testInputKey, "key")
-			// test value
-			value interface{} //@mark(testInputValue, "value")
-		}
-		result struct {
-			v <-chan struct {
-				// expected test value
-				value int //@mark(testResultValue, "value")
-			}
-		}
-	}{} {
-		_ = tt.in               //@hoverdef("in", testInput)
-		_ = tt.in["0"][0].key   //@hoverdef("key", testInputKey)
-		_ = tt.in["0"][0].value //@hoverdef("value", testInputValue)
-
-		_ = (<-tt.result.v).value //@hoverdef("value", testResultValue)
-	}
-}
-
-func _() {
-	getPoints := func() []struct {
-		// X coord
-		x int //@mark(returnX, "x")
-		// Y coord
-		y int //@mark(returnY, "y")
-	} {
-		return nil
-	}
-
-	r := getPoints()
-	r[0].x //@hoverdef("x", returnX)
-	r[0].y //@hoverdef("y", returnY)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/a/h.go.golden b/gopls/internal/lsp/testdata/godef/a/h.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/h.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/h.go.golden	1969-12-31 16:00:00
@@ -1,158 +0,0 @@
--- arrD-hoverdef --
-```go
-field d int
-```
-
-d field
-
--- arrE-hoverdef --
-```go
-field e struct{f int}
-```
-
-e nested struct
-
--- arrF-hoverdef --
-```go
-field f int
-```
-
-f field of nested struct
-
--- complexH-hoverdef --
-```go
-field h int
-```
-
-h field
-
--- complexI-hoverdef --
-```go
-field i struct{j int}
-```
-
-i nested struct
-
--- complexJ-hoverdef --
-```go
-field j int
-```
-
-j field of nested struct
-
--- mapStructKeyX-hoverdef --
-```go
-field x []string
-```
-
-X key field
-
--- mapStructKeyY-hoverdef --
-```go
-field y string
-```
--- mapStructValueX-hoverdef --
-```go
-field x string
-```
-
-X value field
-
--- nestedMap-hoverdef --
-```go
-field m map[string]float64
-```
-
-nested map
-
--- nestedNumber-hoverdef --
-```go
-field number int64
-```
-
-nested number
-
--- nestedString-hoverdef --
-```go
-field str string
-```
-
-nested string
-
--- openMethod-hoverdef --
-```go
-func (interface).open() error
-```
-
-open method comment
-
--- returnX-hoverdef --
-```go
-field x int
-```
-
-X coord
-
--- returnY-hoverdef --
-```go
-field y int
-```
-
-Y coord
-
--- structA-hoverdef --
-```go
-field a int
-```
-
-a field
-
--- structB-hoverdef --
-```go
-field b struct{c int}
-```
-
-b nested struct
-
--- structC-hoverdef --
-```go
-field c int
-```
-
-c field of nested struct
-
--- testDescription-hoverdef --
-```go
-field desc string
-```
-
-test description
-
--- testInput-hoverdef --
-```go
-field in map[string][]struct{key string; value interface{}}
-```
-
-test input
-
--- testInputKey-hoverdef --
-```go
-field key string
-```
-
-test key
-
--- testInputValue-hoverdef --
-```go
-field value interface{}
-```
-
-test value
-
--- testResultValue-hoverdef --
-```go
-field value int
-```
-
-expected test value
-
diff -urN a/gopls/internal/lsp/testdata/godef/a/random.go b/gopls/internal/lsp/testdata/godef/a/random.go
--- a/gopls/internal/lsp/testdata/godef/a/random.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/random.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-package a
-
-func Random() int { //@Random
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@Random2,mark(RandomParamY, "y")
-	return y //@godef("y", RandomParamY)
-}
-
-type Pos struct {
-	x, y int //@mark(PosX, "x"),mark(PosY, "y")
-}
-
-// Typ has a comment. Its fields do not.
-type Typ struct{ field string } //@mark(TypField, "field")
-
-func _() {
-	x := &Typ{}
-	x.field //@godef("field", TypField)
-}
-
-func (p *Pos) Sum() int { //@mark(PosSum, "Sum")
-	return p.x + p.y //@godef("x", PosX)
-}
-
-func _() {
-	var p Pos
-	_ = p.Sum() //@godef("()", PosSum)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/a/random.go.golden b/gopls/internal/lsp/testdata/godef/a/random.go.golden
--- a/gopls/internal/lsp/testdata/godef/a/random.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/a/random.go.golden	1969-12-31 16:00:00
@@ -1,113 +0,0 @@
--- PosSum-definition --
-godef/a/random.go:24:15-18: defined here as ```go
-func (*Pos).Sum() int
-```
-
-[`(a.Pos).Sum` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Pos.Sum)
--- PosSum-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/random.go",
-		"start": {
-			"line": 24,
-			"column": 15,
-			"offset": 413
-		},
-		"end": {
-			"line": 24,
-			"column": 18,
-			"offset": 416
-		}
-	},
-	"description": "```go\nfunc (*Pos).Sum() int\n```\n\n[`(a.Pos).Sum` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Pos.Sum)"
-}
-
--- PosSum-hoverdef --
-```go
-func (*Pos).Sum() int
-```
-
-[`(a.Pos).Sum` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Pos.Sum)
--- PosX-definition --
-godef/a/random.go:13:2-3: defined here as ```go
-field x int
-```
-
-@mark(PosX, "x"),mark(PosY, "y")
--- PosX-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/random.go",
-		"start": {
-			"line": 13,
-			"column": 2,
-			"offset": 187
-		},
-		"end": {
-			"line": 13,
-			"column": 3,
-			"offset": 188
-		}
-	},
-	"description": "```go\nfield x int\n```\n\n@mark(PosX, \"x\"),mark(PosY, \"y\")"
-}
-
--- PosX-hoverdef --
-```go
-field x int
-```
-
-@mark(PosX, "x"),mark(PosY, "y")
-
--- RandomParamY-definition --
-godef/a/random.go:8:14-15: defined here as ```go
-var y int
-```
--- RandomParamY-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/random.go",
-		"start": {
-			"line": 8,
-			"column": 14,
-			"offset": 79
-		},
-		"end": {
-			"line": 8,
-			"column": 15,
-			"offset": 80
-		}
-	},
-	"description": "```go\nvar y int\n```"
-}
-
--- RandomParamY-hoverdef --
-```go
-var y int
-```
--- TypField-definition --
-godef/a/random.go:17:18-23: defined here as ```go
-field field string
-```
--- TypField-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/random.go",
-		"start": {
-			"line": 17,
-			"column": 18,
-			"offset": 292
-		},
-		"end": {
-			"line": 17,
-			"column": 23,
-			"offset": 297
-		}
-	},
-	"description": "```go\nfield field string\n```"
-}
-
--- TypField-hoverdef --
-```go
-field field string
-```
diff -urN a/gopls/internal/lsp/testdata/godef/b/b.go b/gopls/internal/lsp/testdata/godef/b/b.go
--- a/gopls/internal/lsp/testdata/godef/b/b.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/b.go	1969-12-31 16:00:00
@@ -1,57 +0,0 @@
-package b
-
-import (
-	myFoo "golang.org/lsptests/foo" //@mark(myFoo, "myFoo"),godef("myFoo", myFoo)
-	"golang.org/lsptests/godef/a"   //@mark(AImport, re"\".*\"")
-)
-
-type Embed struct {
-	*a.A
-	a.I
-	a.S
-}
-
-func _() {
-	e := Embed{}
-	e.Hi()      //@hoverdef("Hi", AHi)
-	e.B()       //@hoverdef("B", AB)
-	e.Field     //@hoverdef("Field", AField)
-	e.Field2    //@hoverdef("Field2", AField2)
-	e.Hello()   //@hoverdef("Hello", AHello)
-	e.Hey()     //@hoverdef("Hey", AHey)
-	e.Goodbye() //@hoverdef("Goodbye", AGoodbye)
-}
-
-type aAlias = a.A //@mark(aAlias, "aAlias")
-
-type S1 struct { //@S1
-	F1     int //@mark(S1F1, "F1")
-	S2         //@godef("S2", S2),mark(S1S2, "S2")
-	a.A        //@godef("A", AString)
-	aAlias     //@godef("a", aAlias)
-}
-
-type S2 struct { //@S2
-	F1   string //@mark(S2F1, "F1")
-	F2   int    //@mark(S2F2, "F2")
-	*a.A        //@godef("A", AString),godef("a",AImport)
-}
-
-type S3 struct {
-	F1 struct {
-		a.A //@godef("A", AString)
-	}
-}
-
-func Bar() {
-	a.AStuff()  //@godef("AStuff", AStuff)
-	var x S1    //@godef("S1", S1)
-	_ = x.S2    //@godef("S2", S1S2)
-	_ = x.F1    //@godef("F1", S1F1)
-	_ = x.F2    //@godef("F2", S2F2)
-	_ = x.S2.F1 //@godef("F1", S2F1)
-
-	var _ *myFoo.StructFoo //@godef("myFoo", myFoo)
-}
-
-const X = 0 //@mark(bX, "X"),godef("X", bX)
diff -urN a/gopls/internal/lsp/testdata/godef/b/b.go.golden b/gopls/internal/lsp/testdata/godef/b/b.go.golden
--- a/gopls/internal/lsp/testdata/godef/b/b.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/b.go.golden	1969-12-31 16:00:00
@@ -1,480 +0,0 @@
--- AB-hoverdef --
-```go
-func (a.I).B()
-```
-
-@mark(AB, "B")
-
-
-[`(a.I).B` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#I.B)
--- AField-hoverdef --
-```go
-field Field int
-```
-
-@mark(AField, "Field")
-
-
-[`(a.S).Field` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#S.Field)
--- AField2-hoverdef --
-```go
-field Field2 int
-```
-
-@mark(AField2, "Field2")
-
-
-[`(a.R).Field2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#R.Field2)
--- AGoodbye-hoverdef --
-```go
-func (a.H).Goodbye()
-```
-
-@mark(AGoodbye, "Goodbye")
-
-
-[`(a.H).Goodbye` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#H.Goodbye)
--- AHello-hoverdef --
-```go
-func (a.J).Hello()
-```
-
-@mark(AHello, "Hello")
-
-
-[`(a.J).Hello` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#J.Hello)
--- AHey-hoverdef --
-```go
-func (a.R).Hey()
-```
-
-[`(a.R).Hey` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#R.Hey)
--- AHi-hoverdef --
-```go
-func (a.A).Hi()
-```
-
-[`(a.A).Hi` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#A.Hi)
--- AImport-definition --
-godef/b/b.go:5:2-31: defined here as ```go
-package a ("golang.org/lsptests/godef/a")
-```
-
-[`a` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a)
--- AImport-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 5,
-			"column": 2,
-			"offset": 100
-		},
-		"end": {
-			"line": 5,
-			"column": 31,
-			"offset": 129
-		}
-	},
-	"description": "```go\npackage a (\"golang.org/lsptests/godef/a\")\n```\n\n[`a` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a)"
-}
-
--- AImport-hoverdef --
-```go
-package a ("golang.org/lsptests/godef/a")
-```
-
-[`a` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a)
--- AString-definition --
-godef/a/a.go:26:6-7: defined here as ```go
-type A string
-
-func (a.A).Hi()
-```
-
-@mark(AString, "A")
-
-
-[`a.A` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#A)
--- AString-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/a.go",
-		"start": {
-			"line": 26,
-			"column": 6,
-			"offset": 467
-		},
-		"end": {
-			"line": 26,
-			"column": 7,
-			"offset": 468
-		}
-	},
-	"description": "```go\ntype A string\n\nfunc (a.A).Hi()\n```\n\n@mark(AString, \"A\")\n\n\n[`a.A` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#A)"
-}
-
--- AString-hoverdef --
-```go
-type A string
-
-func (a.A).Hi()
-```
-
-@mark(AString, "A")
-
-
-[`a.A` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#A)
--- AStuff-definition --
-godef/a/a.go:28:6-12: defined here as ```go
-func a.AStuff()
-```
-
-[`a.AStuff` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#AStuff)
--- AStuff-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/a.go",
-		"start": {
-			"line": 28,
-			"column": 6,
-			"offset": 504
-		},
-		"end": {
-			"line": 28,
-			"column": 12,
-			"offset": 510
-		}
-	},
-	"description": "```go\nfunc a.AStuff()\n```\n\n[`a.AStuff` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#AStuff)"
-}
-
--- AStuff-hoverdef --
-```go
-func a.AStuff()
-```
-
-[`a.AStuff` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#AStuff)
--- S1-definition --
-godef/b/b.go:27:6-8: defined here as ```go
-type S1 struct {
-	F1     int //@mark(S1F1, "F1")
-	S2         //@godef("S2", S2),mark(S1S2, "S2")
-	a.A        //@godef("A", AString)
-	aAlias     //@godef("a", aAlias)
-}
-```
-
-[`b.S1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1)
--- S1-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 27,
-			"column": 6,
-			"offset": 563
-		},
-		"end": {
-			"line": 27,
-			"column": 8,
-			"offset": 565
-		}
-	},
-	"description": "```go\ntype S1 struct {\n\tF1     int //@mark(S1F1, \"F1\")\n\tS2         //@godef(\"S2\", S2),mark(S1S2, \"S2\")\n\ta.A        //@godef(\"A\", AString)\n\taAlias     //@godef(\"a\", aAlias)\n}\n```\n\n[`b.S1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1)"
-}
-
--- S1-hoverdef --
-```go
-type S1 struct {
-	F1     int //@mark(S1F1, "F1")
-	S2         //@godef("S2", S2),mark(S1S2, "S2")
-	a.A        //@godef("A", AString)
-	aAlias     //@godef("a", aAlias)
-}
-```
-
-[`b.S1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1)
--- S1F1-definition --
-godef/b/b.go:28:2-4: defined here as ```go
-field F1 int
-```
-
-@mark(S1F1, "F1")
-
-
-[`(b.S1).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.F1)
--- S1F1-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 28,
-			"column": 2,
-			"offset": 582
-		},
-		"end": {
-			"line": 28,
-			"column": 4,
-			"offset": 584
-		}
-	},
-	"description": "```go\nfield F1 int\n```\n\n@mark(S1F1, \"F1\")\n\n\n[`(b.S1).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.F1)"
-}
-
--- S1F1-hoverdef --
-```go
-field F1 int
-```
-
-@mark(S1F1, "F1")
-
-
-[`(b.S1).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.F1)
--- S1S2-definition --
-godef/b/b.go:29:2-4: defined here as ```go
-field S2 S2
-```
-
-@godef("S2", S2),mark(S1S2, "S2")
-
-
-[`(b.S1).S2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.S2)
--- S1S2-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 29,
-			"column": 2,
-			"offset": 614
-		},
-		"end": {
-			"line": 29,
-			"column": 4,
-			"offset": 616
-		}
-	},
-	"description": "```go\nfield S2 S2\n```\n\n@godef(\"S2\", S2),mark(S1S2, \"S2\")\n\n\n[`(b.S1).S2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.S2)"
-}
-
--- S1S2-hoverdef --
-```go
-field S2 S2
-```
-
-@godef("S2", S2),mark(S1S2, "S2")
-
-
-[`(b.S1).S2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.S2)
--- S2-definition --
-godef/b/b.go:34:6-8: defined here as ```go
-type S2 struct {
-	F1   string //@mark(S2F1, "F1")
-	F2   int    //@mark(S2F2, "F2")
-	*a.A        //@godef("A", AString),godef("a",AImport)
-}
-```
-
-[`b.S2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2)
--- S2-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 34,
-			"column": 6,
-			"offset": 738
-		},
-		"end": {
-			"line": 34,
-			"column": 8,
-			"offset": 740
-		}
-	},
-	"description": "```go\ntype S2 struct {\n\tF1   string //@mark(S2F1, \"F1\")\n\tF2   int    //@mark(S2F2, \"F2\")\n\t*a.A        //@godef(\"A\", AString),godef(\"a\",AImport)\n}\n```\n\n[`b.S2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2)"
-}
-
--- S2-hoverdef --
-```go
-type S2 struct {
-	F1   string //@mark(S2F1, "F1")
-	F2   int    //@mark(S2F2, "F2")
-	*a.A        //@godef("A", AString),godef("a",AImport)
-}
-```
-
-[`b.S2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2)
--- S2F1-definition --
-godef/b/b.go:35:2-4: defined here as ```go
-field F1 string
-```
-
-@mark(S2F1, "F1")
-
-
-[`(b.S2).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2.F1)
--- S2F1-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 35,
-			"column": 2,
-			"offset": 757
-		},
-		"end": {
-			"line": 35,
-			"column": 4,
-			"offset": 759
-		}
-	},
-	"description": "```go\nfield F1 string\n```\n\n@mark(S2F1, \"F1\")\n\n\n[`(b.S2).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2.F1)"
-}
-
--- S2F1-hoverdef --
-```go
-field F1 string
-```
-
-@mark(S2F1, "F1")
-
-
-[`(b.S2).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2.F1)
--- S2F2-definition --
-godef/b/b.go:36:2-4: defined here as ```go
-field F2 int
-```
-
-@mark(S2F2, "F2")
-
-
-[`(b.S2).F2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2.F2)
--- S2F2-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 36,
-			"column": 2,
-			"offset": 790
-		},
-		"end": {
-			"line": 36,
-			"column": 4,
-			"offset": 792
-		}
-	},
-	"description": "```go\nfield F2 int\n```\n\n@mark(S2F2, \"F2\")\n\n\n[`(b.S2).F2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2.F2)"
-}
-
--- S2F2-hoverdef --
-```go
-field F2 int
-```
-
-@mark(S2F2, "F2")
-
-
-[`(b.S2).F2` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S2.F2)
--- aAlias-definition --
-godef/b/b.go:25:6-12: defined here as ```go
-type aAlias = a.A
-
-func (a.A).Hi()
-```
-
-@mark(aAlias, "aAlias")
--- aAlias-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 25,
-			"column": 6,
-			"offset": 518
-		},
-		"end": {
-			"line": 25,
-			"column": 12,
-			"offset": 524
-		}
-	},
-	"description": "```go\ntype aAlias = a.A\n\nfunc (a.A).Hi()\n```\n\n@mark(aAlias, \"aAlias\")"
-}
-
--- aAlias-hoverdef --
-```go
-type aAlias = a.A
-
-func (a.A).Hi()
-```
-
-@mark(aAlias, "aAlias")
-
--- bX-definition --
-godef/b/b.go:57:7-8: defined here as ```go
-const X untyped int = 0
-```
-
-@mark(bX, "X"),godef("X", bX)
-
-
-[`b.X` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#X)
--- bX-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 57,
-			"column": 7,
-			"offset": 1225
-		},
-		"end": {
-			"line": 57,
-			"column": 8,
-			"offset": 1226
-		}
-	},
-	"description": "```go\nconst X untyped int = 0\n```\n\n@mark(bX, \"X\"),godef(\"X\", bX)\n\n\n[`b.X` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#X)"
-}
-
--- bX-hoverdef --
-```go
-const X untyped int = 0
-```
-
-@mark(bX, "X"),godef("X", bX)
-
-
-[`b.X` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#X)
--- myFoo-definition --
-godef/b/b.go:4:2-7: defined here as ```go
-package myFoo ("golang.org/lsptests/foo")
-```
-
-[`myFoo` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/foo)
--- myFoo-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 4,
-			"column": 2,
-			"offset": 21
-		},
-		"end": {
-			"line": 4,
-			"column": 7,
-			"offset": 26
-		}
-	},
-	"description": "```go\npackage myFoo (\"golang.org/lsptests/foo\")\n```\n\n[`myFoo` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/foo)"
-}
-
--- myFoo-hoverdef --
-```go
-package myFoo ("golang.org/lsptests/foo")
-```
-
-[`myFoo` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/foo)
diff -urN a/gopls/internal/lsp/testdata/godef/b/c.go b/gopls/internal/lsp/testdata/godef/b/c.go
--- a/gopls/internal/lsp/testdata/godef/b/c.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/c.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package b
-
-// This is the in-editor version of the file.
-// The on-disk version is in c.go.saved.
-
-var _ = S1{ //@godef("S1", S1)
-	F1: 99, //@godef("F1", S1F1)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/b/c.go.golden b/gopls/internal/lsp/testdata/godef/b/c.go.golden
--- a/gopls/internal/lsp/testdata/godef/b/c.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/c.go.golden	1969-12-31 16:00:00
@@ -1,76 +0,0 @@
--- S1-definition --
-godef/b/b.go:27:6-8: defined here as ```go
-type S1 struct {
-	F1     int //@mark(S1F1, "F1")
-	S2         //@godef("S2", S2),mark(S1S2, "S2")
-	a.A        //@godef("A", AString)
-	aAlias     //@godef("a", aAlias)
-}
-```
-
-[`b.S1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1)
--- S1-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 27,
-			"column": 6,
-			"offset": 563
-		},
-		"end": {
-			"line": 27,
-			"column": 8,
-			"offset": 565
-		}
-	},
-	"description": "```go\ntype S1 struct {\n\tF1     int //@mark(S1F1, \"F1\")\n\tS2         //@godef(\"S2\", S2),mark(S1S2, \"S2\")\n\ta.A        //@godef(\"A\", AString)\n\taAlias     //@godef(\"a\", aAlias)\n}\n```\n\n[`b.S1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1)"
-}
-
--- S1-hoverdef --
-```go
-type S1 struct {
-	F1     int //@mark(S1F1, "F1")
-	S2         //@godef("S2", S2),mark(S1S2, "S2")
-	a.A        //@godef("A", AString)
-	aAlias     //@godef("a", aAlias)
-}
-```
-
-[`b.S1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1)
--- S1F1-definition --
-godef/b/b.go:28:2-4: defined here as ```go
-field F1 int
-```
-
-@mark(S1F1, "F1")
-
-
-[`(b.S1).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.F1)
--- S1F1-definition-json --
-{
-	"span": {
-		"uri": "file://godef/b/b.go",
-		"start": {
-			"line": 28,
-			"column": 2,
-			"offset": 582
-		},
-		"end": {
-			"line": 28,
-			"column": 4,
-			"offset": 584
-		}
-	},
-	"description": "```go\nfield F1 int\n```\n\n@mark(S1F1, \"F1\")\n\n\n[`(b.S1).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.F1)"
-}
-
--- S1F1-hoverdef --
-```go
-field F1 int
-```
-
-@mark(S1F1, "F1")
-
-
-[`(b.S1).F1` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/b#S1.F1)
diff -urN a/gopls/internal/lsp/testdata/godef/b/c.go.saved b/gopls/internal/lsp/testdata/godef/b/c.go.saved
--- a/gopls/internal/lsp/testdata/godef/b/c.go.saved	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/c.go.saved	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package b
-
-// This is the on-disk version of c.go, which represents
-// the in-editor version of the file.
-
-}
-
diff -urN a/gopls/internal/lsp/testdata/godef/b/e.go b/gopls/internal/lsp/testdata/godef/b/e.go
--- a/gopls/internal/lsp/testdata/godef/b/e.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/e.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-package b
-
-import (
-	"fmt"
-
-	"golang.org/lsptests/godef/a"
-)
-
-func useThings() {
-	t := a.Thing{}      //@mark(bStructType, "ing")
-	fmt.Print(t.Member) //@mark(bMember, "ember")
-	fmt.Print(a.Other)  //@mark(bVar, "ther")
-	a.Things()          //@mark(bFunc, "ings")
-}
-
-/*@
-godef(bStructType, Thing)
-godef(bMember, Member)
-godef(bVar, Other)
-godef(bFunc, Things)
-*/
-
-func _() {
-	var x interface{}      //@mark(eInterface, "interface{}")
-	switch x := x.(type) { //@hoverdef("x", eInterface)
-	case string: //@mark(eString, "string")
-		fmt.Println(x) //@hoverdef("x", eString)
-	case int: //@mark(eInt, "int")
-		fmt.Println(x) //@hoverdef("x", eInt)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/godef/b/e.go.golden b/gopls/internal/lsp/testdata/godef/b/e.go.golden
--- a/gopls/internal/lsp/testdata/godef/b/e.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/e.go.golden	1969-12-31 16:00:00
@@ -1,156 +0,0 @@
--- Member-definition --
-godef/a/d.go:6:2-8: defined here as ```go
-field Member string
-```
-
-@Member
-
-
-[`(a.Thing).Member` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Member)
--- Member-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 6,
-			"column": 2,
-			"offset": 90
-		},
-		"end": {
-			"line": 6,
-			"column": 8,
-			"offset": 96
-		}
-	},
-	"description": "```go\nfield Member string\n```\n\n@Member\n\n\n[`(a.Thing).Member` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Member)"
-}
-
--- Member-hoverdef --
-```go
-field Member string
-```
-
-@Member
-
-
-[`(a.Thing).Member` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing.Member)
--- Other-definition --
-godef/a/d.go:9:5-10: defined here as ```go
-var a.Other a.Thing
-```
-
-@Other
-
-
-[`a.Other` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Other)
--- Other-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 9,
-			"column": 5,
-			"offset": 121
-		},
-		"end": {
-			"line": 9,
-			"column": 10,
-			"offset": 126
-		}
-	},
-	"description": "```go\nvar a.Other a.Thing\n```\n\n@Other\n\n\n[`a.Other` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Other)"
-}
-
--- Other-hoverdef --
-```go
-var a.Other a.Thing
-```
-
-@Other
-
-
-[`a.Other` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Other)
--- Thing-definition --
-godef/a/d.go:5:6-11: defined here as ```go
-type Thing struct {
-	Member string //@Member
-}
-
-func (a.Thing).Method(i int) string
-func (*a.Thing).Method2(i int, j int) (error, string)
-func (a.Thing).Method3()
-```
-
-[`a.Thing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing)
--- Thing-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 5,
-			"column": 6,
-			"offset": 65
-		},
-		"end": {
-			"line": 5,
-			"column": 11,
-			"offset": 70
-		}
-	},
-	"description": "```go\ntype Thing struct {\n\tMember string //@Member\n}\n\nfunc (a.Thing).Method(i int) string\nfunc (*a.Thing).Method2(i int, j int) (error, string)\nfunc (a.Thing).Method3()\n```\n\n[`a.Thing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing)"
-}
-
--- Thing-hoverdef --
-```go
-type Thing struct {
-	Member string //@Member
-}
-
-func (a.Thing).Method(i int) string
-func (*a.Thing).Method2(i int, j int) (error, string)
-func (a.Thing).Method3()
-```
-
-[`a.Thing` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Thing)
--- Things-definition --
-godef/a/d.go:11:6-12: defined here as ```go
-func a.Things(val []string) []a.Thing
-```
-
-[`a.Things` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Things)
--- Things-definition-json --
-{
-	"span": {
-		"uri": "file://godef/a/d.go",
-		"start": {
-			"line": 11,
-			"column": 6,
-			"offset": 148
-		},
-		"end": {
-			"line": 11,
-			"column": 12,
-			"offset": 154
-		}
-	},
-	"description": "```go\nfunc a.Things(val []string) []a.Thing\n```\n\n[`a.Things` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Things)"
-}
-
--- Things-hoverdef --
-```go
-func a.Things(val []string) []a.Thing
-```
-
-[`a.Things` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#Things)
--- eInt-hoverdef --
-```go
-var x int
-```
--- eInterface-hoverdef --
-```go
-var x interface{}
-```
--- eString-hoverdef --
-```go
-var x string
-```
diff -urN a/gopls/internal/lsp/testdata/godef/b/h.go b/gopls/internal/lsp/testdata/godef/b/h.go
--- a/gopls/internal/lsp/testdata/godef/b/h.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/h.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package b
-
-import . "golang.org/lsptests/godef/a"
-
-func _() {
-	// variable of type a.A
-	var _ A //@mark(AVariable, "_"),hoverdef("_", AVariable)
-
-	AStuff() //@hoverdef("AStuff", AStuff)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/b/h.go.golden b/gopls/internal/lsp/testdata/godef/b/h.go.golden
--- a/gopls/internal/lsp/testdata/godef/b/h.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/b/h.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- AStuff-hoverdef --
-```go
-func AStuff()
-```
-
-[`a.AStuff` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/a#AStuff)
--- AVariable-hoverdef --
-```go
-var _ A
-```
-
-variable of type a.A
-
diff -urN a/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.golden b/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.golden
--- a/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.golden	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
--- myUnclosedIf-definition --
-godef/broken/unclosedIf.go:7:7-19: defined here as ```go
-var myUnclosedIf string
-```
-
-@myUnclosedIf
--- myUnclosedIf-definition-json --
-{
-	"span": {
-		"uri": "file://godef/broken/unclosedIf.go",
-		"start": {
-			"line": 7,
-			"column": 7,
-			"offset": 68
-		},
-		"end": {
-			"line": 7,
-			"column": 19,
-			"offset": 80
-		}
-	},
-	"description": "```go\nvar myUnclosedIf string\n```\n\n@myUnclosedIf"
-}
-
--- myUnclosedIf-hoverdef --
-```go
-var myUnclosedIf string
-```
-
-@myUnclosedIf
-
diff -urN a/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.in b/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.in
--- a/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/broken/unclosedIf.go.in	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package broken
-
-import "fmt"
-
-func unclosedIf() {
-	if false {
-		var myUnclosedIf string              //@myUnclosedIf
-		fmt.Printf("s = %v\n", myUnclosedIf) //@godef("my", myUnclosedIf)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/hover_generics/hover.go b/gopls/internal/lsp/testdata/godef/hover_generics/hover.go
--- a/gopls/internal/lsp/testdata/godef/hover_generics/hover.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/hover_generics/hover.go	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
-package hover
-
-type value[T any] struct { //@mark(value, "value"),hoverdef("value", value),mark(valueTdecl, "T"),hoverdef("T",valueTdecl)
-	val T   //@mark(valueTparam, "T"),hoverdef("T", valueTparam)
-	Q   int //@mark(valueQfield, "Q"),hoverdef("Q", valueQfield)
-}
-
-type Value[T any] struct { //@mark(ValueTdecl, "T"),hoverdef("T",ValueTdecl)
-	val T   //@mark(ValueTparam, "T"),hoverdef("T", ValueTparam)
-	Q   int //@mark(ValueQfield, "Q"),hoverdef("Q", ValueQfield)
-}
-
-// disabled - see issue #54822
-func F[P interface{ ~int | string }]() { // mark(Pparam, "P"),hoverdef("P",Pparam)
-	// disabled - see issue #54822
-	var _ P // mark(Pvar, "P"),hoverdef("P",Pvar)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/hover_generics/hover.go.golden b/gopls/internal/lsp/testdata/godef/hover_generics/hover.go.golden
--- a/gopls/internal/lsp/testdata/godef/hover_generics/hover.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/hover_generics/hover.go.golden	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
--- ValueQfield-hoverdef --
-```go
-field Q int
-```
-
-@mark(ValueQfield, "Q"),hoverdef("Q", ValueQfield)
-
-
-[`(hover.Value).Q` on pkg.go.dev](https://pkg.go.dev/golang.org/lsptests/godef/hover_generics#Value.Q)
--- ValueTdecl-hoverdef --
-```go
-type parameter T any
-```
--- ValueTparam-hoverdef --
-```go
-type parameter T any
-```
--- value-hoverdef --
-```go
-type value[T any] struct {
-	val T   //@mark(valueTparam, "T"),hoverdef("T", valueTparam)
-	Q   int //@mark(valueQfield, "Q"),hoverdef("Q", valueQfield)
-}
-```
--- valueQfield-hoverdef --
-```go
-field Q int
-```
-
-@mark(valueQfield, "Q"),hoverdef("Q", valueQfield)
-
--- valueTdecl-hoverdef --
-```go
-type parameter T any
-```
--- valueTparam-hoverdef --
-```go
-type parameter T any
-```
diff -urN a/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go b/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go
--- a/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package inferred
-
-func app[S interface{ ~[]E }, E interface{}](s S, e E) S {
-	return append(s, e)
-}
-
-func _() {
-	_ = app[[]int]             //@mark(constrInfer, "app"),hoverdef("app", constrInfer)
-	_ = app[[]int, int]        //@mark(instance, "app"),hoverdef("app", instance)
-	_ = app[[]int]([]int{}, 0) //@mark(partialInfer, "app"),hoverdef("app", partialInfer)
-	_ = app([]int{}, 0)        //@mark(argInfer, "app"),hoverdef("app", argInfer)
-}
diff -urN a/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go.golden b/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go.golden
--- a/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/godef/infer_generics/inferred.go.golden	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
--- argInfer-hoverdef --
-```go
-func app(s []int, e int) []int // func[S interface{~[]E}, E interface{}](s S, e E) S
-```
--- constrInfer-hoverdef --
-```go
-func app(s []int, e int) []int // func[S interface{~[]E}, E interface{}](s S, e E) S
-```
--- instance-hoverdef --
-```go
-func app(s []int, e int) []int // func[S interface{~[]E}, E interface{}](s S, e E) S
-```
--- partialInfer-hoverdef --
-```go
-func app(s []int, e int) []int // func[S interface{~[]E}, E interface{}](s S, e E) S
-```
diff -urN a/gopls/internal/lsp/testdata/good/good0.go b/gopls/internal/lsp/testdata/good/good0.go
--- a/gopls/internal/lsp/testdata/good/good0.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/good/good0.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package good //@diag("package", "no_diagnostics", "", "error")
-
-func stuff() { //@item(good_stuff, "stuff", "func()", "func"),prepare("stu", "stuff", "stuff")
-	x := 5
-	random2(x) //@prepare("dom", "random2", "random2")
-}
diff -urN a/gopls/internal/lsp/testdata/good/good1.go b/gopls/internal/lsp/testdata/good/good1.go
--- a/gopls/internal/lsp/testdata/good/good1.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/good/good1.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-package good //@diag("package", "no_diagnostics", "", "error")
-
-import (
-	"golang.org/lsptests/types" //@item(types_import, "types", "\"golang.org/lsptests/types\"", "package")
-)
-
-func random() int { //@item(good_random, "random", "func() int", "func")
-	_ = "random() int" //@prepare("random", "", "")
-	y := 6 + 7         //@prepare("7", "", "")
-	return y           //@prepare("return", "","")
-}
-
-func random2(y int) int { //@item(good_random2, "random2", "func(y int) int", "func"),item(good_y_param, "y", "int", "var")
-	//@complete("", good_y_param, types_import, good_random, good_random2, good_stuff)
-	var b types.Bob = &types.X{}   //@prepare("ypes","types", "types")
-	if _, ok := b.(*types.X); ok { //@complete("X", X_struct, Y_struct, Bob_interface, CoolAlias)
-		_ = 0 // suppress "empty branch" diagnostic
-	}
-
-	return y
-}
diff -urN a/gopls/internal/lsp/testdata/highlights/highlights.go b/gopls/internal/lsp/testdata/highlights/highlights.go
--- a/gopls/internal/lsp/testdata/highlights/highlights.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/highlights/highlights.go	1969-12-31 16:00:00
@@ -1,151 +0,0 @@
-package highlights
-
-import (
-	"fmt"         //@mark(fmtImp, "\"fmt\""),highlight(fmtImp, fmtImp, fmt1, fmt2, fmt3, fmt4)
-	h2 "net/http" //@mark(hImp, "h2"),highlight(hImp, hImp, hUse)
-	"sort"
-)
-
-type F struct{ bar int } //@mark(barDeclaration, "bar"),highlight(barDeclaration, barDeclaration, bar1, bar2, bar3)
-
-func _() F {
-	return F{
-		bar: 123, //@mark(bar1, "bar"),highlight(bar1, barDeclaration, bar1, bar2, bar3)
-	}
-}
-
-var foo = F{bar: 52} //@mark(fooDeclaration, "foo"),mark(bar2, "bar"),highlight(fooDeclaration, fooDeclaration, fooUse),highlight(bar2, barDeclaration, bar1, bar2, bar3)
-
-func Print() { //@mark(printFunc, "Print"),highlight(printFunc, printFunc, printTest)
-	_ = h2.Client{} //@mark(hUse, "h2"),highlight(hUse, hImp, hUse)
-
-	fmt.Println(foo) //@mark(fooUse, "foo"),highlight(fooUse, fooDeclaration, fooUse),mark(fmt1, "fmt"),highlight(fmt1, fmtImp, fmt1, fmt2, fmt3, fmt4)
-	fmt.Print("yo")  //@mark(printSep, "Print"),highlight(printSep, printSep, print1, print2),mark(fmt2, "fmt"),highlight(fmt2, fmtImp, fmt1, fmt2, fmt3, fmt4)
-}
-
-func (x *F) Inc() { //@mark(xRightDecl, "x"),mark(xLeftDecl, " *"),highlight(xRightDecl, xRightDecl, xUse),highlight(xLeftDecl, xRightDecl, xUse)
-	x.bar++ //@mark(xUse, "x"),mark(bar3, "bar"),highlight(xUse, xRightDecl, xUse),highlight(bar3, barDeclaration, bar1, bar2, bar3)
-}
-
-func testFunctions() {
-	fmt.Print("main start") //@mark(print1, "Print"),highlight(print1, printSep, print1, print2),mark(fmt3, "fmt"),highlight(fmt3, fmtImp, fmt1, fmt2, fmt3, fmt4)
-	fmt.Print("ok")         //@mark(print2, "Print"),highlight(print2, printSep, print1, print2),mark(fmt4, "fmt"),highlight(fmt4, fmtImp, fmt1, fmt2, fmt3, fmt4)
-	Print()                 //@mark(printTest, "Print"),highlight(printTest, printFunc, printTest)
-}
-
-func toProtocolHighlight(rngs []int) []DocumentHighlight { //@mark(doc1, "DocumentHighlight"),mark(docRet1, "[]DocumentHighlight"),highlight(doc1, docRet1, doc1, doc2, doc3, result)
-	result := make([]DocumentHighlight, 0, len(rngs)) //@mark(doc2, "DocumentHighlight"),highlight(doc2, doc1, doc2, doc3)
-	for _, rng := range rngs {
-		result = append(result, DocumentHighlight{ //@mark(doc3, "DocumentHighlight"),highlight(doc3, doc1, doc2, doc3)
-			Range: rng,
-		})
-	}
-	return result //@mark(result, "result")
-}
-
-func testForLoops() {
-	for i := 0; i < 10; i++ { //@mark(forDecl1, "for"),highlight(forDecl1, forDecl1, brk1, cont1)
-		if i > 8 {
-			break //@mark(brk1, "break"),highlight(brk1, forDecl1, brk1, cont1)
-		}
-		if i < 2 {
-			for j := 1; j < 10; j++ { //@mark(forDecl2, "for"),highlight(forDecl2, forDecl2, cont2)
-				if j < 3 {
-					for k := 1; k < 10; k++ { //@mark(forDecl3, "for"),highlight(forDecl3, forDecl3, cont3)
-						if k < 3 {
-							continue //@mark(cont3, "continue"),highlight(cont3, forDecl3, cont3)
-						}
-					}
-					continue //@mark(cont2, "continue"),highlight(cont2, forDecl2, cont2)
-				}
-			}
-			continue //@mark(cont1, "continue"),highlight(cont1, forDecl1, brk1, cont1)
-		}
-	}
-
-	arr := []int{}
-	for i := range arr { //@mark(forDecl4, "for"),highlight(forDecl4, forDecl4, brk4, cont4)
-		if i > 8 {
-			break //@mark(brk4, "break"),highlight(brk4, forDecl4, brk4, cont4)
-		}
-		if i < 4 {
-			continue //@mark(cont4, "continue"),highlight(cont4, forDecl4, brk4, cont4)
-		}
-	}
-
-Outer:
-	for i := 0; i < 10; i++ { //@mark(forDecl5, "for"),highlight(forDecl5, forDecl5, brk5, brk6, brk8)
-		break //@mark(brk5, "break"),highlight(brk5, forDecl5, brk5, brk6, brk8)
-		for { //@mark(forDecl6, "for"),highlight(forDecl6, forDecl6, cont5)
-			if i == 1 {
-				break Outer //@mark(brk6, "break Outer"),highlight(brk6, forDecl5, brk5, brk6, brk8)
-			}
-			switch i { //@mark(switch1, "switch"),highlight(switch1, switch1, brk7)
-			case 5:
-				break //@mark(brk7, "break"),highlight(brk7, switch1, brk7)
-			case 6:
-				continue //@mark(cont5, "continue"),highlight(cont5, forDecl6, cont5)
-			case 7:
-				break Outer //@mark(brk8, "break Outer"),highlight(brk8, forDecl5, brk5, brk6, brk8)
-			}
-		}
-	}
-}
-
-func testSwitch() {
-	var i, j int
-
-L1:
-	for { //@mark(forDecl7, "for"),highlight(forDecl7, forDecl7, brk10, cont6)
-	L2:
-		switch i { //@mark(switch2, "switch"),highlight(switch2, switch2, brk11, brk12, brk13)
-		case 1:
-			switch j { //@mark(switch3, "switch"),highlight(switch3, switch3, brk9)
-			case 1:
-				break //@mark(brk9, "break"),highlight(brk9, switch3, brk9)
-			case 2:
-				break L1 //@mark(brk10, "break L1"),highlight(brk10, forDecl7, brk10, cont6)
-			case 3:
-				break L2 //@mark(brk11, "break L2"),highlight(brk11, switch2, brk11, brk12, brk13)
-			default:
-				continue //@mark(cont6, "continue"),highlight(cont6, forDecl7, brk10, cont6)
-			}
-		case 2:
-			break //@mark(brk12, "break"),highlight(brk12, switch2, brk11, brk12, brk13)
-		default:
-			break L2 //@mark(brk13, "break L2"),highlight(brk13, switch2, brk11, brk12, brk13)
-		}
-	}
-}
-
-func testReturn() bool { //@mark(func1, "func"),mark(bool1, "bool"),highlight(func1, func1, fullRet11, fullRet12),highlight(bool1, bool1, false1, bool2, true1)
-	if 1 < 2 {
-		return false //@mark(ret11, "return"),mark(fullRet11, "return false"),mark(false1, "false"),highlight(ret11, func1, fullRet11, fullRet12)
-	}
-	candidates := []int{}
-	sort.SliceStable(candidates, func(i, j int) bool { //@mark(func2, "func"),mark(bool2, "bool"),highlight(func2, func2, fullRet2)
-		return candidates[i] > candidates[j] //@mark(ret2, "return"),mark(fullRet2, "return candidates[i] > candidates[j]"),highlight(ret2, func2, fullRet2)
-	})
-	return true //@mark(ret12, "return"),mark(fullRet12, "return true"),mark(true1, "true"),highlight(ret12, func1, fullRet11, fullRet12)
-}
-
-func testReturnFields() float64 { //@mark(retVal1, "float64"),highlight(retVal1, retVal1, retVal11, retVal21)
-	if 1 < 2 {
-		return 20.1 //@mark(retVal11, "20.1"),highlight(retVal11, retVal1, retVal11, retVal21)
-	}
-	z := 4.3 //@mark(zDecl, "z")
-	return z //@mark(retVal21, "z"),highlight(retVal21, retVal1, retVal11, zDecl, retVal21)
-}
-
-func testReturnMultipleFields() (float32, string) { //@mark(retVal31, "float32"),mark(retVal32, "string"),highlight(retVal31, retVal31, retVal41, retVal51),highlight(retVal32, retVal32, retVal42, retVal52)
-	y := "im a var" //@mark(yDecl, "y"),
-	if 1 < 2 {
-		return 20.1, y //@mark(retVal41, "20.1"),mark(retVal42, "y"),highlight(retVal41, retVal31, retVal41, retVal51),highlight(retVal42, retVal32, yDecl, retVal42, retVal52)
-	}
-	return 4.9, "test" //@mark(retVal51, "4.9"),mark(retVal52, "\"test\""),highlight(retVal51, retVal31, retVal41, retVal51),highlight(retVal52, retVal32, retVal42, retVal52)
-}
-
-func testReturnFunc() int32 { //@mark(retCall, "int32")
-	mulch := 1          //@mark(mulchDec, "mulch"),highlight(mulchDec, mulchDec, mulchRet)
-	return int32(mulch) //@mark(mulchRet, "mulch"),mark(retFunc, "int32"),mark(retTotal, "int32(mulch)"),highlight(mulchRet, mulchDec, mulchRet),highlight(retFunc, retCall, retFunc, retTotal)
-}
diff -urN a/gopls/internal/lsp/testdata/implementation/implementation.go b/gopls/internal/lsp/testdata/implementation/implementation.go
--- a/gopls/internal/lsp/testdata/implementation/implementation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/implementation/implementation.go	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-package implementation
-
-import "golang.org/lsptests/implementation/other"
-
-type ImpP struct{} //@ImpP,implementations("ImpP", Laugher, OtherLaugher)
-
-func (*ImpP) Laugh() { //@mark(LaughP, "Laugh"),implementations("Laugh", Laugh, OtherLaugh)
-}
-
-type ImpS struct{} //@ImpS,implementations("ImpS", Laugher, OtherLaugher)
-
-func (ImpS) Laugh() { //@mark(LaughS, "Laugh"),implementations("Laugh", Laugh, OtherLaugh)
-}
-
-type Laugher interface { //@Laugher,implementations("Laugher", ImpP, OtherImpP, ImpS, OtherImpS)
-	Laugh() //@Laugh,implementations("Laugh", LaughP, OtherLaughP, LaughS, OtherLaughS)
-}
-
-type Foo struct { //@implementations("Foo", Joker)
-	other.Foo
-}
-
-type Joker interface { //@Joker
-	Joke() //@Joke,implementations("Joke", ImpJoker)
-}
-
-type cryer int //@implementations("cryer", Cryer)
-
-func (cryer) Cry(other.CryType) {} //@mark(CryImpl, "Cry"),implementations("Cry", Cry)
-
-type Empty interface{} //@implementations("Empty")
diff -urN a/gopls/internal/lsp/testdata/implementation/other/other.go b/gopls/internal/lsp/testdata/implementation/other/other.go
--- a/gopls/internal/lsp/testdata/implementation/other/other.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/implementation/other/other.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package other
-
-type ImpP struct{} //@mark(OtherImpP, "ImpP")
-
-func (*ImpP) Laugh() { //@mark(OtherLaughP, "Laugh")
-}
-
-type ImpS struct{} //@mark(OtherImpS, "ImpS")
-
-func (ImpS) Laugh() { //@mark(OtherLaughS, "Laugh")
-}
-
-type ImpI interface { //@mark(OtherLaugher, "ImpI")
-	Laugh() //@mark(OtherLaugh, "Laugh")
-}
-
-type Foo struct { //@implementations("Foo", Joker)
-}
-
-func (Foo) Joke() { //@mark(ImpJoker, "Joke"),implementations("Joke", Joke)
-}
-
-type CryType int
-
-type Cryer interface { //@Cryer
-	Cry(CryType) //@Cry,implementations("Cry", CryImpl)
-}
diff -urN a/gopls/internal/lsp/testdata/implementation/other/other_test.go b/gopls/internal/lsp/testdata/implementation/other/other_test.go
--- a/gopls/internal/lsp/testdata/implementation/other/other_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/implementation/other/other_test.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package other
-
-import (
-	"testing"
-)
-
-// This exists so the other.test package comes into existence.
-
-func TestOther(t *testing.T) {
-}
diff -urN a/gopls/internal/lsp/testdata/importedcomplit/imported_complit.go.in b/gopls/internal/lsp/testdata/importedcomplit/imported_complit.go.in
--- a/gopls/internal/lsp/testdata/importedcomplit/imported_complit.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/importedcomplit/imported_complit.go.in	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-package importedcomplit
-
-import (
-	"golang.org/lsptests/foo"
-
-	// import completions
-	"fm" //@complete("\" //", fmtImport)
-	"go/pars" //@complete("\" //", parserImport)
-	"golang.org/lsptests/signa" //@complete("na\" //", signatureImport)
-	"golang.org/lspte" //@complete("\" //", lsptestsImport)
-	"crypto/elli" //@complete("\" //", cryptoImport)
-	"golang.org/lsptests/sign" //@complete("\" //", signatureImport)
-	"golang.org/lsptests/sign" //@complete("ests", lsptestsImport)
-	namedParser "go/pars" //@complete("\" //", parserImport)
-)
-
-func _() {
-	var V int //@item(icVVar, "V", "int", "var")
-	_ = foo.StructFoo{V} //@complete("}", Value, icVVar)
-}
-
-func _() {
-	var (
-		aa string //@item(icAAVar, "aa", "string", "var")
-		ab int    //@item(icABVar, "ab", "int", "var")
-	)
-
-	_ = foo.StructFoo{a} //@complete("}", abVar, aaVar)
-
-	var s struct {
-		AA string //@item(icFieldAA, "AA", "string", "field")
-		AB int    //@item(icFieldAB, "AB", "int", "field")
-	}
-
-	_ = foo.StructFoo{s.} //@complete("}", icFieldAB, icFieldAA)
-}
-
-/* "fmt" */ //@item(fmtImport, "fmt", "\"fmt\"", "package")
-/* "go/parser" */ //@item(parserImport, "parser", "\"go/parser\"", "package")
-/* "golang.org/lsptests/signature" */ //@item(signatureImport, "signature", "\"golang.org/lsptests/signature\"", "package")
-/* "golang.org/lsptests/" */ //@item(lsptestsImport, "lsptests/", "\"golang.org/lsptests/\"", "package")
-/* "crypto/elliptic" */ //@item(cryptoImport, "elliptic", "\"crypto/elliptic\"", "package")
diff -urN a/gopls/internal/lsp/testdata/imports/add_import.go.golden b/gopls/internal/lsp/testdata/imports/add_import.go.golden
--- a/gopls/internal/lsp/testdata/imports/add_import.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/add_import.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- goimports --
-package imports //@import("package")
-
-import (
-	"bytes"
-	"fmt"
-)
-
-func _() {
-	fmt.Println("")
-	bytes.NewBuffer(nil)
-}
-
diff -urN a/gopls/internal/lsp/testdata/imports/add_import.go.in b/gopls/internal/lsp/testdata/imports/add_import.go.in
--- a/gopls/internal/lsp/testdata/imports/add_import.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/add_import.go.in	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package imports //@import("package")
-
-import (
-	"fmt"
-)
-
-func _() {
-	fmt.Println("")
-	bytes.NewBuffer(nil)
-}
diff -urN a/gopls/internal/lsp/testdata/imports/good_imports.go.golden b/gopls/internal/lsp/testdata/imports/good_imports.go.golden
--- a/gopls/internal/lsp/testdata/imports/good_imports.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/good_imports.go.golden	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
--- goimports --
-package imports //@import("package")
-
-import "fmt"
-
-func _() {
-fmt.Println("")
-}
-
diff -urN a/gopls/internal/lsp/testdata/imports/good_imports.go.in b/gopls/internal/lsp/testdata/imports/good_imports.go.in
--- a/gopls/internal/lsp/testdata/imports/good_imports.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/good_imports.go.in	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package imports //@import("package")
-
-import "fmt"
-
-func _() {
-fmt.Println("")
-}
diff -urN a/gopls/internal/lsp/testdata/imports/issue35458.go.golden b/gopls/internal/lsp/testdata/imports/issue35458.go.golden
--- a/gopls/internal/lsp/testdata/imports/issue35458.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/issue35458.go.golden	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
--- goimports --
-// package doc
-package imports //@import("package")
-
-
-
-
-
-
-func _() {
-	println("Hello, world!")
-}
-
-
-
-
-
-
-
-
diff -urN a/gopls/internal/lsp/testdata/imports/issue35458.go.in b/gopls/internal/lsp/testdata/imports/issue35458.go.in
--- a/gopls/internal/lsp/testdata/imports/issue35458.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/issue35458.go.in	1969-12-31 16:00:00
@@ -1,23 +0,0 @@
-
-
-
-
-
-// package doc
-package imports //@import("package")
-
-
-
-
-
-
-func _() {
-	println("Hello, world!")
-}
-
-
-
-
-
-
-
diff -urN a/gopls/internal/lsp/testdata/imports/multiple_blocks.go.golden b/gopls/internal/lsp/testdata/imports/multiple_blocks.go.golden
--- a/gopls/internal/lsp/testdata/imports/multiple_blocks.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/multiple_blocks.go.golden	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
--- goimports --
-package imports //@import("package")
-
-import "fmt"
-
-func _() {
-	fmt.Println("")
-}
-
diff -urN a/gopls/internal/lsp/testdata/imports/multiple_blocks.go.in b/gopls/internal/lsp/testdata/imports/multiple_blocks.go.in
--- a/gopls/internal/lsp/testdata/imports/multiple_blocks.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/multiple_blocks.go.in	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package imports //@import("package")
-
-import "fmt"
-
-import "bytes"
-
-func _() {
-	fmt.Println("")
-}
diff -urN a/gopls/internal/lsp/testdata/imports/needs_imports.go.golden b/gopls/internal/lsp/testdata/imports/needs_imports.go.golden
--- a/gopls/internal/lsp/testdata/imports/needs_imports.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/needs_imports.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- goimports --
-package imports //@import("package")
-
-import (
-	"fmt"
-	"log"
-)
-
-func goodbye() {
-	fmt.Printf("HI")
-	log.Printf("byeeeee")
-}
-
diff -urN a/gopls/internal/lsp/testdata/imports/needs_imports.go.in b/gopls/internal/lsp/testdata/imports/needs_imports.go.in
--- a/gopls/internal/lsp/testdata/imports/needs_imports.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/needs_imports.go.in	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package imports //@import("package")
-
-func goodbye() {
-	fmt.Printf("HI")
-	log.Printf("byeeeee")
-}
diff -urN a/gopls/internal/lsp/testdata/imports/remove_import.go.golden b/gopls/internal/lsp/testdata/imports/remove_import.go.golden
--- a/gopls/internal/lsp/testdata/imports/remove_import.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/remove_import.go.golden	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
--- goimports --
-package imports //@import("package")
-
-import (
-	"fmt"
-)
-
-func _() {
-	fmt.Println("")
-}
-
diff -urN a/gopls/internal/lsp/testdata/imports/remove_import.go.in b/gopls/internal/lsp/testdata/imports/remove_import.go.in
--- a/gopls/internal/lsp/testdata/imports/remove_import.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/remove_import.go.in	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package imports //@import("package")
-
-import (
-	"bytes"
-	"fmt"
-)
-
-func _() {
-	fmt.Println("")
-}
diff -urN a/gopls/internal/lsp/testdata/imports/remove_imports.go.golden b/gopls/internal/lsp/testdata/imports/remove_imports.go.golden
--- a/gopls/internal/lsp/testdata/imports/remove_imports.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/remove_imports.go.golden	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
--- goimports --
-package imports //@import("package")
-
-func _() {
-}
-
diff -urN a/gopls/internal/lsp/testdata/imports/remove_imports.go.in b/gopls/internal/lsp/testdata/imports/remove_imports.go.in
--- a/gopls/internal/lsp/testdata/imports/remove_imports.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/remove_imports.go.in	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package imports //@import("package")
-
-import (
-	"bytes"
-	"fmt"
-)
-
-func _() {
-}
diff -urN a/gopls/internal/lsp/testdata/imports/two_lines.go.golden b/gopls/internal/lsp/testdata/imports/two_lines.go.golden
--- a/gopls/internal/lsp/testdata/imports/two_lines.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/two_lines.go.golden	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
--- goimports --
-package main
-func main()  {} //@import("main")
-
diff -urN a/gopls/internal/lsp/testdata/imports/two_lines.go.in b/gopls/internal/lsp/testdata/imports/two_lines.go.in
--- a/gopls/internal/lsp/testdata/imports/two_lines.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/imports/two_lines.go.in	1969-12-31 16:00:00
@@ -1,2 +0,0 @@
-package main
-func main()  {} //@import("main")
diff -urN a/gopls/internal/lsp/testdata/index/index.go b/gopls/internal/lsp/testdata/index/index.go
--- a/gopls/internal/lsp/testdata/index/index.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/index/index.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-package index
-
-func _() {
-	var (
-		aa = "123" //@item(indexAA, "aa", "string", "var")
-		ab = 123   //@item(indexAB, "ab", "int", "var")
-	)
-
-	var foo [1]int
-	foo[a]  //@complete("]", indexAB, indexAA)
-	foo[:a] //@complete("]", indexAB, indexAA)
-	a[:a]   //@complete("[", indexAA, indexAB)
-	a[a]    //@complete("[", indexAA, indexAB)
-
-	var bar map[string]int
-	bar[a] //@complete("]", indexAA, indexAB)
-
-	type myMap map[string]int
-	var baz myMap
-	baz[a] //@complete("]", indexAA, indexAB)
-
-	type myInt int
-	var mi myInt //@item(indexMyInt, "mi", "myInt", "var")
-	foo[m]       //@snippet("]", indexMyInt, "mi", "mi")
-}
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go b/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go
--- a/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package inlayHint //@inlayHint("package")
-
-import "fmt"
-
-func fieldNames() {
-	for _, c := range []struct {
-		in, want string
-	}{
-		struct{ in, want string }{"Hello, world", "dlrow ,olleH"},
-		{"Hello, 世界", "界世 ,olleH"},
-		{"", ""},
-	} {
-		fmt.Println(c.in == c.want)
-	}
-}
-
-func fieldNamesPointers() {
-	for _, c := range []*struct {
-		in, want string
-	}{
-		&struct{ in, want string }{"Hello, world", "dlrow ,olleH"},
-		{"Hello, 世界", "界世 ,olleH"},
-		{"", ""},
-	} {
-		fmt.Println(c.in == c.want)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go.golden b/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go.golden
--- a/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/composite_literals.go.golden	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
--- inlayHint --
-package inlayHint //@inlayHint("package")
-
-import "fmt"
-
-func fieldNames() {
-	for _< int>, c< struct{in string; want string}> := range []struct {
-		in, want string
-	}{
-		struct{ in, want string }{<in: >"Hello, world", <want: >"dlrow ,olleH"},
-		<struct{in string; want string}>{<in: >"Hello, 世界", <want: >"界世 ,olleH"},
-		<struct{in string; want string}>{<in: >"", <want: >""},
-	} {
-		fmt.Println(<a...: >c.in == c.want)
-	}
-}
-
-func fieldNamesPointers() {
-	for _< int>, c< *struct{in string; want string}> := range []*struct {
-		in, want string
-	}{
-		&struct{ in, want string }{<in: >"Hello, world", <want: >"dlrow ,olleH"},
-		<&struct{in string; want string}>{<in: >"Hello, 世界", <want: >"界世 ,olleH"},
-		<&struct{in string; want string}>{<in: >"", <want: >""},
-	} {
-		fmt.Println(<a...: >c.in == c.want)
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/constant_values.go b/gopls/internal/lsp/testdata/inlay_hint/constant_values.go
--- a/gopls/internal/lsp/testdata/inlay_hint/constant_values.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/constant_values.go	1969-12-31 16:00:00
@@ -1,45 +0,0 @@
-package inlayHint //@inlayHint("package")
-
-const True = true
-
-type Kind int
-
-const (
-	KindNone Kind = iota
-	KindPrint
-	KindPrintf
-	KindErrorf
-)
-
-const (
-	u         = iota * 4
-	v float64 = iota * 42
-	w         = iota * 42
-)
-
-const (
-	a, b = 1, 2
-	c, d
-	e, f = 5 * 5, "hello" + "world"
-	g, h
-	i, j = true, f
-)
-
-// No hint
-const (
-	Int     = 3
-	Float   = 3.14
-	Bool    = true
-	Rune    = '3'
-	Complex = 2.7i
-	String  = "Hello, world!"
-)
-
-var (
-	varInt     = 3
-	varFloat   = 3.14
-	varBool    = true
-	varRune    = '3' + '4'
-	varComplex = 2.7i
-	varString  = "Hello, world!"
-)
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/constant_values.go.golden b/gopls/internal/lsp/testdata/inlay_hint/constant_values.go.golden
--- a/gopls/internal/lsp/testdata/inlay_hint/constant_values.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/constant_values.go.golden	1969-12-31 16:00:00
@@ -1,47 +0,0 @@
--- inlayHint --
-package inlayHint //@inlayHint("package")
-
-const True = true
-
-type Kind int
-
-const (
-	KindNone Kind = iota< = 0>
-	KindPrint< = 1>
-	KindPrintf< = 2>
-	KindErrorf< = 3>
-)
-
-const (
-	u         = iota * 4< = 0>
-	v float64 = iota * 42< = 42>
-	w         = iota * 42< = 84>
-)
-
-const (
-	a, b = 1, 2
-	c, d< = 1, 2>
-	e, f = 5 * 5, "hello" + "world"< = 25, "helloworld">
-	g, h< = 25, "helloworld">
-	i, j = true, f< = true, "helloworld">
-)
-
-// No hint
-const (
-	Int     = 3
-	Float   = 3.14
-	Bool    = true
-	Rune    = '3'
-	Complex = 2.7i
-	String  = "Hello, world!"
-)
-
-var (
-	varInt     = 3
-	varFloat   = 3.14
-	varBool    = true
-	varRune    = '3' + '4'
-	varComplex = 2.7i
-	varString  = "Hello, world!"
-)
-
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go b/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go
--- a/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go	1969-12-31 16:00:00
@@ -1,50 +0,0 @@
-package inlayHint //@inlayHint("package")
-
-import "fmt"
-
-func hello(name string) string {
-	return "Hello " + name
-}
-
-func helloWorld() string {
-	return hello("World")
-}
-
-type foo struct{}
-
-func (*foo) bar(baz string, qux int) int {
-	if baz != "" {
-		return qux + 1
-	}
-	return qux
-}
-
-func kase(foo int, bar bool, baz ...string) {
-	fmt.Println(foo, bar, baz)
-}
-
-func kipp(foo string, bar, baz string) {
-	fmt.Println(foo, bar, baz)
-}
-
-func plex(foo, bar string, baz string) {
-	fmt.Println(foo, bar, baz)
-}
-
-func tars(foo string, bar, baz string) {
-	fmt.Println(foo, bar, baz)
-}
-
-func foobar() {
-	var x foo
-	x.bar("", 1)
-	kase(0, true, "c", "d", "e")
-	kipp("a", "b", "c")
-	plex("a", "b", "c")
-	tars("a", "b", "c")
-	foo, bar, baz := "a", "b", "c"
-	kipp(foo, bar, baz)
-	plex("a", bar, baz)
-	tars(foo+foo, (bar), "c")
-
-}
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go.golden b/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go.golden
--- a/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/parameter_names.go.golden	1969-12-31 16:00:00
@@ -1,52 +0,0 @@
--- inlayHint --
-package inlayHint //@inlayHint("package")
-
-import "fmt"
-
-func hello(name string) string {
-	return "Hello " + name
-}
-
-func helloWorld() string {
-	return hello(<name: >"World")
-}
-
-type foo struct{}
-
-func (*foo) bar(baz string, qux int) int {
-	if baz != "" {
-		return qux + 1
-	}
-	return qux
-}
-
-func kase(foo int, bar bool, baz ...string) {
-	fmt.Println(<a...: >foo, bar, baz)
-}
-
-func kipp(foo string, bar, baz string) {
-	fmt.Println(<a...: >foo, bar, baz)
-}
-
-func plex(foo, bar string, baz string) {
-	fmt.Println(<a...: >foo, bar, baz)
-}
-
-func tars(foo string, bar, baz string) {
-	fmt.Println(<a...: >foo, bar, baz)
-}
-
-func foobar() {
-	var x foo
-	x.bar(<baz: >"", <qux: >1)
-	kase(<foo: >0, <bar: >true, <baz...: >"c", "d", "e")
-	kipp(<foo: >"a", <bar: >"b", <baz: >"c")
-	plex(<foo: >"a", <bar: >"b", <baz: >"c")
-	tars(<foo: >"a", <bar: >"b", <baz: >"c")
-	foo< string>, bar< string>, baz< string> := "a", "b", "c"
-	kipp(foo, bar, baz)
-	plex(<foo: >"a", bar, baz)
-	tars(<foo: >foo+foo, <bar: >(bar), <baz: >"c")
-
-}
-
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/type_params.go b/gopls/internal/lsp/testdata/inlay_hint/type_params.go
--- a/gopls/internal/lsp/testdata/inlay_hint/type_params.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/type_params.go	1969-12-31 16:00:00
@@ -1,45 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package inlayHint //@inlayHint("package")
-
-func main() {
-	ints := map[string]int64{
-		"first":  34,
-		"second": 12,
-	}
-
-	floats := map[string]float64{
-		"first":  35.98,
-		"second": 26.99,
-	}
-
-	SumIntsOrFloats[string, int64](ints)
-	SumIntsOrFloats[string, float64](floats)
-
-	SumIntsOrFloats(ints)
-	SumIntsOrFloats(floats)
-
-	SumNumbers(ints)
-	SumNumbers(floats)
-}
-
-type Number interface {
-	int64 | float64
-}
-
-func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V {
-	var s V
-	for _, v := range m {
-		s += v
-	}
-	return s
-}
-
-func SumNumbers[K comparable, V Number](m map[K]V) V {
-	var s V
-	for _, v := range m {
-		s += v
-	}
-	return s
-}
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/type_params.go.golden b/gopls/internal/lsp/testdata/inlay_hint/type_params.go.golden
--- a/gopls/internal/lsp/testdata/inlay_hint/type_params.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/type_params.go.golden	1969-12-31 16:00:00
@@ -1,47 +0,0 @@
--- inlayHint --
-//go:build go1.18
-// +build go1.18
-
-package inlayHint //@inlayHint("package")
-
-func main() {
-	ints< map[string]int64> := map[string]int64{
-		"first":  34,
-		"second": 12,
-	}
-
-	floats< map[string]float64> := map[string]float64{
-		"first":  35.98,
-		"second": 26.99,
-	}
-
-	SumIntsOrFloats[string, int64](<m: >ints)
-	SumIntsOrFloats[string, float64](<m: >floats)
-
-	SumIntsOrFloats<[string, int64]>(<m: >ints)
-	SumIntsOrFloats<[string, float64]>(<m: >floats)
-
-	SumNumbers<[string, int64]>(<m: >ints)
-	SumNumbers<[string, float64]>(<m: >floats)
-}
-
-type Number interface {
-	int64 | float64
-}
-
-func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V {
-	var s V
-	for _< K>, v< V> := range m {
-		s += v
-	}
-	return s
-}
-
-func SumNumbers[K comparable, V Number](m map[K]V) V {
-	var s V
-	for _< K>, v< V> := range m {
-		s += v
-	}
-	return s
-}
-
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/variable_types.go b/gopls/internal/lsp/testdata/inlay_hint/variable_types.go
--- a/gopls/internal/lsp/testdata/inlay_hint/variable_types.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/variable_types.go	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-package inlayHint //@inlayHint("package")
-
-func assignTypes() {
-	i, j := 0, len([]string{})-1
-	println(i, j)
-}
-
-func rangeTypes() {
-	for k, v := range []string{} {
-		println(k, v)
-	}
-}
-
-func funcLitType() {
-	myFunc := func(a string) string { return "" }
-}
-
-func compositeLitType() {
-	foo := map[string]interface{}{"": ""}
-}
diff -urN a/gopls/internal/lsp/testdata/inlay_hint/variable_types.go.golden b/gopls/internal/lsp/testdata/inlay_hint/variable_types.go.golden
--- a/gopls/internal/lsp/testdata/inlay_hint/variable_types.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/inlay_hint/variable_types.go.golden	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
--- inlayHint --
-package inlayHint //@inlayHint("package")
-
-func assignTypes() {
-	i< int>, j< int> := 0, len([]string{})-1
-	println(i, j)
-}
-
-func rangeTypes() {
-	for k< int>, v< string> := range []string{} {
-		println(k, v)
-	}
-}
-
-func funcLitType() {
-	myFunc< func(a string) string> := func(a string) string { return "" }
-}
-
-func compositeLitType() {
-	foo< map[string]interface{}> := map[string]interface{}{"": ""}
-}
-
diff -urN a/gopls/internal/lsp/testdata/interfacerank/interface_rank.go b/gopls/internal/lsp/testdata/interfacerank/interface_rank.go
--- a/gopls/internal/lsp/testdata/interfacerank/interface_rank.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/interfacerank/interface_rank.go	1969-12-31 16:00:00
@@ -1,23 +0,0 @@
-package interfacerank
-
-type foo interface {
-	foo()
-}
-
-type fooImpl int
-
-func (*fooImpl) foo() {}
-
-func wantsFoo(foo) {}
-
-func _() {
-	var (
-		aa string   //@item(irAA, "aa", "string", "var")
-		ab *fooImpl //@item(irAB, "ab", "*fooImpl", "var")
-	)
-
-	wantsFoo(a) //@complete(")", irAB, irAA)
-
-	var ac fooImpl //@item(irAC, "ac", "fooImpl", "var")
-	wantsFoo(&a)   //@complete(")", irAC, irAA, irAB)
-}
diff -urN a/gopls/internal/lsp/testdata/issues/issue56505.go b/gopls/internal/lsp/testdata/issues/issue56505.go
--- a/gopls/internal/lsp/testdata/issues/issue56505.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/issues/issue56505.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package issues
-
-// Test for golang/go#56505: completion on variables of type *error should not
-// panic.
-func _() {
-	var e *error
-	e.x //@complete(" //")
-}
diff -urN a/gopls/internal/lsp/testdata/keywords/accidental_keywords.go.in b/gopls/internal/lsp/testdata/keywords/accidental_keywords.go.in
--- a/gopls/internal/lsp/testdata/keywords/accidental_keywords.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/keywords/accidental_keywords.go.in	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-package keywords
-
-// non-matching candidate - shouldn't show up as completion
-var apple = "apple"
-
-func _() {
-	foo.bar() // insert some extra statements to exercise our AST surgery
-	variance := 123 //@item(kwVariance, "variance", "int", "var")
-	foo.bar()
-	println(var) //@complete(")", kwVariance)
-}
-
-func _() {
-	foo.bar()
-	var s struct { variance int } //@item(kwVarianceField, "variance", "int", "field")
-	foo.bar()
-	s.var //@complete(" //", kwVarianceField)
-}
-
-func _() {
-	channel := 123 //@item(kwChannel, "channel", "int", "var")
-	chan //@complete(" //", kwChannel)
-	foo.bar()
-}
-
-func _() {
-	foo.bar()
-	var typeName string //@item(kwTypeName, "typeName", "string", "var")
-	foo.bar()
-	type //@complete(" //", kwTypeName)
-}
diff -urN a/gopls/internal/lsp/testdata/keywords/empty_select.go b/gopls/internal/lsp/testdata/keywords/empty_select.go
--- a/gopls/internal/lsp/testdata/keywords/empty_select.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/keywords/empty_select.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package keywords
-
-func _() {
-	select {
-		c //@complete(" //", case)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/keywords/empty_switch.go b/gopls/internal/lsp/testdata/keywords/empty_switch.go
--- a/gopls/internal/lsp/testdata/keywords/empty_switch.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/keywords/empty_switch.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package keywords
-
-func _() {
-	switch {
-		//@complete("", case, default)
-	}
-
-	switch test.(type) {
-		d //@complete(" //", default)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/keywords/keywords.go b/gopls/internal/lsp/testdata/keywords/keywords.go
--- a/gopls/internal/lsp/testdata/keywords/keywords.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/keywords/keywords.go	1969-12-31 16:00:00
@@ -1,100 +0,0 @@
-package keywords
-
-//@rank("", type),rank("", func),rank("", var),rank("", const),rank("", import)
-
-func _() {
-	var test int //@rank(" //", int, interface)
-	var tChan chan int
-	var _ m //@complete(" //", map)
-	var _ f //@complete(" //", func)
-	var _ c //@complete(" //", chan)
-
-	var _ str //@rank(" //", string, struct)
-
-	type _ int //@rank(" //", interface, int)
-
-	type _ str //@rank(" //", struct, string)
-
-	switch test {
-	case 1: // TODO: trying to complete case here will break because the parser wont return *ast.Ident
-		b //@complete(" //", break)
-	case 2:
-		f //@complete(" //", fallthrough, for)
-		r //@complete(" //", return)
-		d //@complete(" //", default, defer)
-		c //@complete(" //", case, const)
-	}
-
-	switch test.(type) {
-	case fo: //@complete(":")
-	case int:
-		b //@complete(" //", break)
-	case int32:
-		f //@complete(" //", for)
-		d //@complete(" //", default, defer)
-		r //@complete(" //", return)
-		c //@complete(" //", case, const)
-	}
-
-	select {
-	case <-tChan:
-		b //@complete(" //", break)
-		c //@complete(" //", case, const)
-	}
-
-	for index := 0; index < test; index++ {
-		c //@complete(" //", const, continue)
-		b //@complete(" //", break)
-	}
-
-	for range []int{} {
-		c //@complete(" //", const, continue)
-		b //@complete(" //", break)
-	}
-
-	// Test function level keywords
-
-	//Using 2 characters to test because map output order is random
-	sw //@complete(" //", switch)
-	se //@complete(" //", select)
-
-	f //@complete(" //", for)
-	d //@complete(" //", defer)
-	g //@rank(" //", go),rank(" //", goto)
-	r //@complete(" //", return)
-	i //@complete(" //", if)
-	e //@complete(" //", else)
-	v //@complete(" //", var)
-	c //@complete(" //", const)
-
-	for i := r //@complete(" //", range)
-}
-
-/* package */ //@item(package, "package", "", "keyword")
-/* import */ //@item(import, "import", "", "keyword")
-/* func */ //@item(func, "func", "", "keyword")
-/* type */ //@item(type, "type", "", "keyword")
-/* var */ //@item(var, "var", "", "keyword")
-/* const */ //@item(const, "const", "", "keyword")
-/* break */ //@item(break, "break", "", "keyword")
-/* default */ //@item(default, "default", "", "keyword")
-/* case */ //@item(case, "case", "", "keyword")
-/* defer */ //@item(defer, "defer", "", "keyword")
-/* go */ //@item(go, "go", "", "keyword")
-/* for */ //@item(for, "for", "", "keyword")
-/* if */ //@item(if, "if", "", "keyword")
-/* else */ //@item(else, "else", "", "keyword")
-/* switch */ //@item(switch, "switch", "", "keyword")
-/* select */ //@item(select, "select", "", "keyword")
-/* fallthrough */ //@item(fallthrough, "fallthrough", "", "keyword")
-/* continue */ //@item(continue, "continue", "", "keyword")
-/* return */ //@item(return, "return", "", "keyword")
-/* var */ //@item(var, "var", "", "keyword")
-/* const */ //@item(const, "const", "", "keyword")
-/* goto */ //@item(goto, "goto", "", "keyword")
-/* struct */ //@item(struct, "struct", "", "keyword")
-/* interface */ //@item(interface, "interface", "", "keyword")
-/* map */ //@item(map, "map", "", "keyword")
-/* func */ //@item(func, "func", "", "keyword")
-/* chan */ //@item(chan, "chan", "", "keyword")
-/* range */ //@item(range, "range", "", "keyword")
diff -urN a/gopls/internal/lsp/testdata/labels/labels.go b/gopls/internal/lsp/testdata/labels/labels.go
--- a/gopls/internal/lsp/testdata/labels/labels.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/labels/labels.go	1969-12-31 16:00:00
@@ -1,49 +0,0 @@
-package labels
-
-func _() {
-	goto F //@complete(" //", label1, label5)
-
-Foo1: //@item(label1, "Foo1", "label", "const")
-	for a, b := range []int{} {
-	Foo2: //@item(label2, "Foo2", "label", "const")
-		switch {
-		case true:
-			break F //@complete(" //", label2, label1)
-
-			continue F //@complete(" //", label1)
-
-			{
-			FooUnjumpable:
-			}
-
-			goto F //@complete(" //", label1, label2, label4, label5)
-
-			func() {
-				goto F //@complete(" //", label3)
-
-				break F //@complete(" //")
-
-				continue F //@complete(" //")
-
-			Foo3: //@item(label3, "Foo3", "label", "const")
-			}()
-		}
-
-	Foo4: //@item(label4, "Foo4", "label", "const")
-		switch interface{}(a).(type) {
-		case int:
-			break F //@complete(" //", label4, label1)
-		}
-	}
-
-	break F //@complete(" //")
-
-	continue F //@complete(" //")
-
-Foo5: //@item(label5, "Foo5", "label", "const")
-	for {
-		break F //@complete(" //", label5)
-	}
-
-	return
-}
diff -urN a/gopls/internal/lsp/testdata/links/links.go b/gopls/internal/lsp/testdata/links/links.go
--- a/gopls/internal/lsp/testdata/links/links.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/links/links.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-package links
-
-import (
-	"fmt" //@link(`fmt`,"https://pkg.go.dev/fmt")
-
-	"golang.org/lsptests/foo" //@link(`golang.org/lsptests/foo`,`https://pkg.go.dev/golang.org/lsptests/foo`)
-
-	_ "database/sql" //@link(`database/sql`, `https://pkg.go.dev/database/sql`)
-)
-
-var (
-	_ fmt.Formatter
-	_ foo.StructFoo
-	_ errors.Formatter
-)
-
-// Foo function
-func Foo() string {
-	/*https://example.com/comment */ //@link("https://example.com/comment","https://example.com/comment")
-
-	url := "https://example.com/string_literal" //@link("https://example.com/string_literal","https://example.com/string_literal")
-	return url
-
-	// TODO(golang/go#1234): Link the relevant issue. //@link("golang/go#1234", "https://github.com/golang/go/issues/1234")
-	// TODO(microsoft/vscode-go#12): Another issue. //@link("microsoft/vscode-go#12", "https://github.com/microsoft/vscode-go/issues/12")
-}
diff -urN a/gopls/internal/lsp/testdata/maps/maps.go.in b/gopls/internal/lsp/testdata/maps/maps.go.in
--- a/gopls/internal/lsp/testdata/maps/maps.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/maps/maps.go.in	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-package maps
-
-func _() {
-	var aVar int          //@item(mapVar, "aVar", "int", "var")
-
-	// not comparabale
-	type aSlice []int     //@item(mapSliceType, "aSlice", "[]int", "type")
-
-	*aSlice     //@item(mapSliceTypePtr, "*aSlice", "[]int", "type")
-
-	// comparable
-	type aStruct struct{} //@item(mapStructType, "aStruct", "struct{...}", "struct")
-
-	map[]a{} //@complete("]", mapSliceType, mapStructType),snippet("]", mapSliceType, "*aSlice", "*aSlice")
-
-	map[a]a{} //@complete("]", mapSliceType, mapStructType)
-	map[a]a{} //@complete("{", mapSliceType, mapStructType)
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/channels.go b/gopls/internal/lsp/testdata/missingfunction/channels.go
--- a/gopls/internal/lsp/testdata/missingfunction/channels.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/channels.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package missingfunction
-
-func channels(s string) {
-	undefinedChannels(c()) //@suggestedfix("undefinedChannels", "quickfix", "")
-}
-
-func c() (<-chan string, chan string) {
-	return make(<-chan string), make(chan string)
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/channels.go.golden b/gopls/internal/lsp/testdata/missingfunction/channels.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/channels.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/channels.go.golden	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
--- suggestedfix_channels_4_2 --
-package missingfunction
-
-func channels(s string) {
-	undefinedChannels(c()) //@suggestedfix("undefinedChannels", "quickfix", "")
-}
-
-func undefinedChannels(ch1 <-chan string, ch2 chan string) {
-	panic("unimplemented")
-}
-
-func c() (<-chan string, chan string) {
-	return make(<-chan string), make(chan string)
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go b/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go
--- a/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package missingfunction
-
-func consecutiveParams() {
-	var s string
-	undefinedConsecutiveParams(s, s) //@suggestedfix("undefinedConsecutiveParams", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go.golden b/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/consecutive_params.go.golden	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
--- suggestedfix_consecutive_params_5_2 --
-package missingfunction
-
-func consecutiveParams() {
-	var s string
-	undefinedConsecutiveParams(s, s) //@suggestedfix("undefinedConsecutiveParams", "quickfix", "")
-}
-
-func undefinedConsecutiveParams(s1, s2 string) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/error_param.go b/gopls/internal/lsp/testdata/missingfunction/error_param.go
--- a/gopls/internal/lsp/testdata/missingfunction/error_param.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/error_param.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package missingfunction
-
-func errorParam() {
-	var err error
-	undefinedErrorParam(err) //@suggestedfix("undefinedErrorParam", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/error_param.go.golden b/gopls/internal/lsp/testdata/missingfunction/error_param.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/error_param.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/error_param.go.golden	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
--- suggestedfix_error_param_5_2 --
-package missingfunction
-
-func errorParam() {
-	var err error
-	undefinedErrorParam(err) //@suggestedfix("undefinedErrorParam", "quickfix", "")
-}
-
-func undefinedErrorParam(err error) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/literals.go b/gopls/internal/lsp/testdata/missingfunction/literals.go
--- a/gopls/internal/lsp/testdata/missingfunction/literals.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/literals.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package missingfunction
-
-type T struct{}
-
-func literals() {
-	undefinedLiterals("hey compiler", T{}, &T{}) //@suggestedfix("undefinedLiterals", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/literals.go.golden b/gopls/internal/lsp/testdata/missingfunction/literals.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/literals.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/literals.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- suggestedfix_literals_6_2 --
-package missingfunction
-
-type T struct{}
-
-func literals() {
-	undefinedLiterals("hey compiler", T{}, &T{}) //@suggestedfix("undefinedLiterals", "quickfix", "")
-}
-
-func undefinedLiterals(s string, t1 T, t2 *T) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/operation.go b/gopls/internal/lsp/testdata/missingfunction/operation.go
--- a/gopls/internal/lsp/testdata/missingfunction/operation.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/operation.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package missingfunction
-
-import "time"
-
-func operation() {
-	undefinedOperation(10 * time.Second) //@suggestedfix("undefinedOperation", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/operation.go.golden b/gopls/internal/lsp/testdata/missingfunction/operation.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/operation.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/operation.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- suggestedfix_operation_6_2 --
-package missingfunction
-
-import "time"
-
-func operation() {
-	undefinedOperation(10 * time.Second) //@suggestedfix("undefinedOperation", "quickfix", "")
-}
-
-func undefinedOperation(duration time.Duration) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/selector.go b/gopls/internal/lsp/testdata/missingfunction/selector.go
--- a/gopls/internal/lsp/testdata/missingfunction/selector.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/selector.go	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package missingfunction
-
-func selector() {
-	m := map[int]bool{}
-	undefinedSelector(m[1]) //@suggestedfix("undefinedSelector", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/selector.go.golden b/gopls/internal/lsp/testdata/missingfunction/selector.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/selector.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/selector.go.golden	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
--- suggestedfix_selector_5_2 --
-package missingfunction
-
-func selector() {
-	m := map[int]bool{}
-	undefinedSelector(m[1]) //@suggestedfix("undefinedSelector", "quickfix", "")
-}
-
-func undefinedSelector(b bool) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/slice.go b/gopls/internal/lsp/testdata/missingfunction/slice.go
--- a/gopls/internal/lsp/testdata/missingfunction/slice.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/slice.go	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package missingfunction
-
-func slice() {
-	undefinedSlice([]int{1, 2}) //@suggestedfix("undefinedSlice", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/slice.go.golden b/gopls/internal/lsp/testdata/missingfunction/slice.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/slice.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/slice.go.golden	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
--- suggestedfix_slice_4_2 --
-package missingfunction
-
-func slice() {
-	undefinedSlice([]int{1, 2}) //@suggestedfix("undefinedSlice", "quickfix", "")
-}
-
-func undefinedSlice(i []int) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/tuple.go b/gopls/internal/lsp/testdata/missingfunction/tuple.go
--- a/gopls/internal/lsp/testdata/missingfunction/tuple.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/tuple.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package missingfunction
-
-func tuple() {
-	undefinedTuple(b()) //@suggestedfix("undefinedTuple", "quickfix", "")
-}
-
-func b() (string, error) {
-	return "", nil
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/tuple.go.golden b/gopls/internal/lsp/testdata/missingfunction/tuple.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/tuple.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/tuple.go.golden	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
--- suggestedfix_tuple_4_2 --
-package missingfunction
-
-func tuple() {
-	undefinedTuple(b()) //@suggestedfix("undefinedTuple", "quickfix", "")
-}
-
-func undefinedTuple(s string, err error) {
-	panic("unimplemented")
-}
-
-func b() (string, error) {
-	return "", nil
-}
-
diff -urN a/gopls/internal/lsp/testdata/missingfunction/unique_params.go b/gopls/internal/lsp/testdata/missingfunction/unique_params.go
--- a/gopls/internal/lsp/testdata/missingfunction/unique_params.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/unique_params.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package missingfunction
-
-func uniqueArguments() {
-	var s string
-	var i int
-	undefinedUniqueArguments(s, i, s) //@suggestedfix("undefinedUniqueArguments", "quickfix", "")
-}
diff -urN a/gopls/internal/lsp/testdata/missingfunction/unique_params.go.golden b/gopls/internal/lsp/testdata/missingfunction/unique_params.go.golden
--- a/gopls/internal/lsp/testdata/missingfunction/unique_params.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/missingfunction/unique_params.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- suggestedfix_unique_params_6_2 --
-package missingfunction
-
-func uniqueArguments() {
-	var s string
-	var i int
-	undefinedUniqueArguments(s, i, s) //@suggestedfix("undefinedUniqueArguments", "quickfix", "")
-}
-
-func undefinedUniqueArguments(s1 string, i int, s2 string) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/multireturn/multi_return.go.in b/gopls/internal/lsp/testdata/multireturn/multi_return.go.in
--- a/gopls/internal/lsp/testdata/multireturn/multi_return.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/multireturn/multi_return.go.in	1969-12-31 16:00:00
@@ -1,48 +0,0 @@
-package multireturn
-
-func f0() {} //@item(multiF0, "f0", "func()", "func")
-
-func f1(int) int { return 0 } //@item(multiF1, "f1", "func(int) int", "func")
-
-func f2(int, int) (int, int) { return 0, 0 } //@item(multiF2, "f2", "func(int, int) (int, int)", "func")
-
-func f2Str(string, string) (string, string) { return "", "" } //@item(multiF2Str, "f2Str", "func(string, string) (string, string)", "func")
-
-func f3(int, int, int) (int, int, int) { return 0, 0, 0 } //@item(multiF3, "f3", "func(int, int, int) (int, int, int)", "func")
-
-func _() {
-	_ := f //@rank(" //", multiF1, multiF2)
-
-	_, _ := f //@rank(" //", multiF2, multiF0),rank(" //", multiF1, multiF0)
-
-	_, _ := _, f //@rank(" //", multiF1, multiF2),rank(" //", multiF1, multiF0)
-
-	_, _ := f, abc //@rank(", abc", multiF1, multiF2)
-
-	f1()     //@rank(")", multiF1, multiF0)
-	f1(f)    //@rank(")", multiF1, multiF2)
-	f2(f)    //@rank(")", multiF2, multiF3),rank(")", multiF1, multiF3)
-	f2(1, f) //@rank(")", multiF1, multiF2),rank(")", multiF1, multiF0)
-	f2(1, )  //@rank(")", multiF1, multiF2),rank(")", multiF1, multiF0)
-	f2Str()  //@rank(")", multiF2Str, multiF2)
-
-	var i int
-	i, _ := f //@rank(" //", multiF2, multiF2Str)
-
-	var s string
-	_, s := f //@rank(" //", multiF2Str, multiF2)
-
-	banana, s = f //@rank(" //", multiF2, multiF3)
-
-	var variadic func(int, ...int)
-	variadic() //@rank(")", multiF1, multiF0),rank(")", multiF2, multiF0),rank(")", multiF3, multiF0)
-}
-
-func _() {
-	var baz func(...interface{})
-
-	var otterNap func() (int, int) //@item(multiTwo, "otterNap", "func() (int, int)", "var")
-	var one int                    //@item(multiOne, "one", "int", "var")
-
-	baz(on) //@rank(")", multiOne, multiTwo)
-}
diff -urN a/gopls/internal/lsp/testdata/nested_complit/nested_complit.go.in b/gopls/internal/lsp/testdata/nested_complit/nested_complit.go.in
--- a/gopls/internal/lsp/testdata/nested_complit/nested_complit.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/nested_complit/nested_complit.go.in	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-package nested_complit
-
-type ncFoo struct {} //@item(structNCFoo, "ncFoo", "struct{...}", "struct")
-
-type ncBar struct { //@item(structNCBar, "ncBar", "struct{...}", "struct")
-	baz []ncFoo
-}
-
-func _() {
-	[]ncFoo{} //@item(litNCFoo, "[]ncFoo{}", "", "var")
-	_ := ncBar{
-		// disabled - see issue #54822
-		baz: [] // complete(" //", structNCFoo, structNCBar)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/nodisk/empty b/gopls/internal/lsp/testdata/nodisk/empty
--- a/gopls/internal/lsp/testdata/nodisk/empty	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/nodisk/empty	1969-12-31 16:00:00
@@ -1 +0,0 @@
-an empty file so that this directory exists
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/nodisk/nodisk.overlay.go b/gopls/internal/lsp/testdata/nodisk/nodisk.overlay.go
--- a/gopls/internal/lsp/testdata/nodisk/nodisk.overlay.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/nodisk/nodisk.overlay.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package nodisk
-
-import (
-	"golang.org/lsptests/foo"
-)
-
-func _() {
-	foo.Foo() //@complete("F", Foo, IntFoo, StructFoo)
-}
diff -urN a/gopls/internal/lsp/testdata/noparse/noparse.go.in b/gopls/internal/lsp/testdata/noparse/noparse.go.in
--- a/gopls/internal/lsp/testdata/noparse/noparse.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/noparse/noparse.go.in	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-package noparse
-
-// The type error was chosen carefully to exercise a type-error analyzer.
-// We use the 'nonewvars' analyzer because the other candidates are tricky:
-//
-// - The 'unusedvariable' analyzer is disabled by default, so it is not
-//   consistently enabled across Test{LSP,CommandLine} tests, which
-//   both process this file.
-// - The 'undeclaredname' analyzer depends on the text of the go/types
-//   "undeclared name" error, which changed in go1.20.
-// - The 'noresultvalues' analyzer produces a diagnostic containing newlines,
-//   which breaks the parser used by TestCommandLine.
-//
-// This comment is all that remains of my afternoon.
-
-func bye(x int) {
-	x := 123 //@diag(":=", "nonewvars", "no new variables", "warning")
-}
-
-func stuff() {
-	
-}
-
-func .() {} //@diag(".", "syntax", "expected 'IDENT', found '.'", "error")
diff -urN a/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.golden b/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.golden
--- a/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.golden	1969-12-31 16:00:00
@@ -1,2 +0,0 @@
--- gofmt --
-
diff -urN a/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.in b/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.in
--- a/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/noparse_format/noparse_format.go.in	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-// +build go1.11
-
-package noparse_format //@format("package")
-
-// The nonewvars expectation asserts that the go/analysis framework ran.
-// See comments in badstmt.
-
-func what() {
-	var hi func()
-	if {		hi() //@diag("{", "syntax", "missing condition in if statement", "error")
-	}
-	hi := nil //@diag(":=", "nonewvars", "no new variables", "warning")
-}
-
diff -urN a/gopls/internal/lsp/testdata/noparse_format/parse_format.go.golden b/gopls/internal/lsp/testdata/noparse_format/parse_format.go.golden
--- a/gopls/internal/lsp/testdata/noparse_format/parse_format.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/noparse_format/parse_format.go.golden	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
--- gofmt --
-package noparse_format //@format("package")
-
-func _() {
-	f()
-}
-
diff -urN a/gopls/internal/lsp/testdata/noparse_format/parse_format.go.in b/gopls/internal/lsp/testdata/noparse_format/parse_format.go.in
--- a/gopls/internal/lsp/testdata/noparse_format/parse_format.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/noparse_format/parse_format.go.in	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package noparse_format //@format("package")
-
-func _() {
-f()
-}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/printf/printf.go b/gopls/internal/lsp/testdata/printf/printf.go
--- a/gopls/internal/lsp/testdata/printf/printf.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/printf/printf.go	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-package printf
-
-import "fmt"
-
-func myPrintf(string, ...interface{}) {}
-
-func _() {
-	var (
-		aInt      int          //@item(printfInt, "aInt", "int", "var")
-		aFloat    float64      //@item(printfFloat, "aFloat", "float64", "var")
-		aString   string       //@item(printfString, "aString", "string", "var")
-		aBytes    []byte       //@item(printfBytes, "aBytes", "[]byte", "var")
-		aStringer fmt.Stringer //@item(printfStringer, "aStringer", "fmt.Stringer", "var")
-		aError    error        //@item(printfError, "aError", "error", "var")
-		aBool     bool         //@item(printfBool, "aBool", "bool", "var")
-	)
-
-	myPrintf("%d", a)       //@rank(")", printfInt, printfFloat)
-	myPrintf("%s", a)       //@rank(")", printfString, printfInt),rank(")", printfBytes, printfInt),rank(")", printfStringer, printfInt),rank(")", printfError, printfInt)
-	myPrintf("%w", a)       //@rank(")", printfError, printfInt)
-	myPrintf("%x %[1]b", a) //@rank(")", printfInt, printfString)
-
-	fmt.Printf("%t", a) //@rank(")", printfBool, printfInt)
-
-	fmt.Fprintf(nil, "%f", a) //@rank(")", printfFloat, printfInt)
-
-	fmt.Sprintf("%[2]q %[1]*.[3]*[4]f",
-		a, //@rank(",", printfInt, printfFloat)
-		a, //@rank(",", printfString, printfFloat)
-		a, //@rank(",", printfInt, printfFloat)
-		a, //@rank(",", printfFloat, printfInt)
-	)
-}
diff -urN a/gopls/internal/lsp/testdata/rank/assign_rank.go.in b/gopls/internal/lsp/testdata/rank/assign_rank.go.in
--- a/gopls/internal/lsp/testdata/rank/assign_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/assign_rank.go.in	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
-package rank
-
-var (
-	apple int = 3         //@item(apple, "apple", "int", "var")
-	pear string = "hello" //@item(pear, "pear", "string", "var")
-)
-
-func _() {
-	orange := 1      //@item(orange, "orange", "int", "var")
-	grape := "hello" //@item(grape, "grape", "string", "var")
-	orange, grape = 2, "hello"  //@complete(" \"", grape, pear, orange, apple)
-}
-
-func _() {
-	var pineapple int //@item(pineapple, "pineapple", "int", "var")
-	pineapple = 1    //@complete(" 1", pineapple, apple, pear)
-
-	y := //@complete(" /", pineapple, apple, pear)
-}
diff -urN a/gopls/internal/lsp/testdata/rank/binexpr_rank.go.in b/gopls/internal/lsp/testdata/rank/binexpr_rank.go.in
--- a/gopls/internal/lsp/testdata/rank/binexpr_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/binexpr_rank.go.in	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package rank
-
-func _() {
-  _ = 5 +  ; //@complete(" ;", apple, pear)
-  y :=  + 5; //@complete(" +", apple, pear)
-
-  if 6 ==  {} //@complete(" {", apple, pear)
-}
diff -urN a/gopls/internal/lsp/testdata/rank/boolexpr_rank.go b/gopls/internal/lsp/testdata/rank/boolexpr_rank.go
--- a/gopls/internal/lsp/testdata/rank/boolexpr_rank.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/boolexpr_rank.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package rank
-
-func _() {
-	someRandomBoolFunc := func() bool { //@item(boolExprFunc, "someRandomBoolFunc", "func() bool", "var")
-		return true
-	}
-
-	var foo, bar int     //@item(boolExprBar, "bar", "int", "var")
-	if foo == 123 && b { //@rank(" {", boolExprBar, boolExprFunc)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/rank/convert_rank.go.in b/gopls/internal/lsp/testdata/rank/convert_rank.go.in
--- a/gopls/internal/lsp/testdata/rank/convert_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/convert_rank.go.in	1969-12-31 16:00:00
@@ -1,54 +0,0 @@
-package rank
-
-import "time"
-
-func _() {
-	type strList []string
-	wantsStrList := func(strList) {}
-
-	var (
-		convA string   //@item(convertA, "convA", "string", "var")
-		convB []string //@item(convertB, "convB", "[]string", "var")
-	)
-	wantsStrList(strList(conv)) //@complete("))", convertB, convertA)
-}
-
-func _() {
-	type myInt int
-
-	const (
-		convC        = "hi"    //@item(convertC, "convC", "string", "const")
-		convD        = 123     //@item(convertD, "convD", "int", "const")
-		convE int    = 123     //@item(convertE, "convE", "int", "const")
-		convF string = "there" //@item(convertF, "convF", "string", "const")
-		convG myInt  = 123     //@item(convertG, "convG", "myInt", "const")
-	)
-
-	var foo int
-	foo = conv //@rank(" //", convertE, convertD)
-
-	var mi myInt
-	mi = conv //@rank(" //", convertG, convertD, convertE)
-	mi + conv //@rank(" //", convertG, convertD, convertE)
-
-	1 + conv //@rank(" //", convertD, convertC),rank(" //", convertE, convertC),rank(" //", convertG, convertC)
-
-	type myString string
-	var ms myString
-	ms = conv //@rank(" //", convertC, convertF)
-
-	type myUint uint32
-	var mu myUint
-	mu = conv //@rank(" //", convertD, convertE)
-
-	// don't downrank constants when assigning to interface{}
-	var _ interface{} = c //@rank(" //", convertD, complex)
-
-	var _ time.Duration = conv //@rank(" //", convertD, convertE),snippet(" //", convertE, "time.Duration(convE)", "time.Duration(convE)")
-
-	var convP myInt   //@item(convertP, "convP", "myInt", "var")
-	var _ *int = conv //@snippet(" //", convertP, "(*int)(&convP)", "(*int)(&convP)")
-
-	var ff float64 //@item(convertFloat, "ff", "float64", "var")
-	f == convD     //@snippet(" =", convertFloat, "ff", "ff")
-}
diff -urN a/gopls/internal/lsp/testdata/rank/struct/struct_rank.go b/gopls/internal/lsp/testdata/rank/struct/struct_rank.go
--- a/gopls/internal/lsp/testdata/rank/struct/struct_rank.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/struct/struct_rank.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package struct_rank
-
-type foo struct {
-	c int //@item(c_rank, "c", "int", "field")
-	b int //@item(b_rank, "b", "int", "field")
-	a int //@item(a_rank, "a", "int", "field")
-}
-
-func f() {
-	foo := foo{} //@rank("}", c_rank, b_rank, a_rank)
-}
diff -urN a/gopls/internal/lsp/testdata/rank/switch_rank.go.in b/gopls/internal/lsp/testdata/rank/switch_rank.go.in
--- a/gopls/internal/lsp/testdata/rank/switch_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/switch_rank.go.in	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-package rank
-
-import "time"
-
-func _() {
-	switch pear {
-	case _: //@rank("_", pear, apple)
-	}
-
-	time.Monday //@item(timeMonday, "time.Monday", "time.Weekday", "const"),item(monday ,"Monday", "time.Weekday", "const")
-	time.Friday //@item(timeFriday, "time.Friday", "time.Weekday", "const"),item(friday ,"Friday", "time.Weekday", "const")
-
-	now := time.Now()
-	now.Weekday //@item(nowWeekday, "now.Weekday", "func() time.Weekday", "method")
-
-	then := time.Now()
-	then.Weekday //@item(thenWeekday, "then.Weekday", "func() time.Weekday", "method")
-
-	switch time.Weekday(0) {
-	case time.Monday, time.Tuesday:
-	case time.Wednesday, time.Thursday:
-	case time.Saturday, time.Sunday:
-	case t: //@rank(":", timeFriday, timeMonday)
-	case time.: //@rank(":", friday, monday)
-
-	case now.Weekday():
-	case week: //@rank(":", thenWeekday, nowWeekday)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/rank/type_assert_rank.go.in b/gopls/internal/lsp/testdata/rank/type_assert_rank.go.in
--- a/gopls/internal/lsp/testdata/rank/type_assert_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/type_assert_rank.go.in	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package rank
-
-func _() {
-	type flower int //@item(flower, "flower", "int", "type")
-	var fig string  //@item(fig, "fig", "string", "var")
-
-	_ = interface{}(nil).(f) //@complete(") //", flower)
-}
diff -urN a/gopls/internal/lsp/testdata/rank/type_switch_rank.go.in b/gopls/internal/lsp/testdata/rank/type_switch_rank.go.in
--- a/gopls/internal/lsp/testdata/rank/type_switch_rank.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rank/type_switch_rank.go.in	1969-12-31 16:00:00
@@ -1,31 +0,0 @@
-package rank
-
-import (
-	"fmt"
-	"go/ast"
-)
-
-func _() {
-	type basket int   //@item(basket, "basket", "int", "type")
-	var banana string //@item(banana, "banana", "string", "var")
-
-	switch interface{}(pear).(type) {
-	case b: //@complete(":", basket)
-		b //@complete(" //", banana, basket)
-	}
-
-	Ident  //@item(astIdent, "Ident", "struct{...}", "struct")
-	IfStmt //@item(astIfStmt, "IfStmt", "struct{...}", "struct")
-
-	switch ast.Node(nil).(type) {
-	case *ast.Ident:
-	case *ast.I: //@rank(":", astIfStmt, astIdent)
-	}
-
-	Stringer   //@item(fmtStringer, "Stringer", "interface{...}", "interface")
-	GoStringer //@item(fmtGoStringer, "GoStringer", "interface{...}", "interface")
-
-	switch interface{}(nil).(type) {
-	case fmt.Stringer: //@rank(":", fmtStringer, fmtGoStringer)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/references/another/another.go b/gopls/internal/lsp/testdata/references/another/another.go
--- a/gopls/internal/lsp/testdata/references/another/another.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/references/another/another.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-// Package another has another type.
-package another
-
-import (
-	other "golang.org/lsptests/references/other"
-)
-
-func _() {
-	xes := other.GetXes()
-	for _, x := range xes { //@mark(defX, "x")
-		_ = x.Y //@mark(useX, "x"),mark(anotherXY, "Y"),refs("Y", typeXY, anotherXY, GetXesY),refs(".", defX, useX),refs("x", defX, useX)
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/references/interfaces/interfaces.go b/gopls/internal/lsp/testdata/references/interfaces/interfaces.go
--- a/gopls/internal/lsp/testdata/references/interfaces/interfaces.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/references/interfaces/interfaces.go	1969-12-31 16:00:00
@@ -1,34 +0,0 @@
-package interfaces
-
-type first interface {
-	common() //@mark(firCommon, "common"),refs("common", firCommon, xCommon, zCommon)
-	firstMethod() //@mark(firMethod, "firstMethod"),refs("firstMethod", firMethod, xfMethod, zfMethod)
-}
-
-type second interface {
-	common() //@mark(secCommon, "common"),refs("common", secCommon, yCommon, zCommon)
-	secondMethod() //@mark(secMethod, "secondMethod"),refs("secondMethod", secMethod, ysMethod, zsMethod)
-}
-
-type s struct {}
-
-func (*s) common() {} //@mark(sCommon, "common"),refs("common", sCommon, xCommon, yCommon, zCommon)
-
-func (*s) firstMethod() {} //@mark(sfMethod, "firstMethod"),refs("firstMethod", sfMethod, xfMethod, zfMethod)
-
-func (*s) secondMethod() {} //@mark(ssMethod, "secondMethod"),refs("secondMethod", ssMethod, ysMethod, zsMethod)
-
-func main() {
-	var x first = &s{}
-	var y second = &s{}
-
-	x.common() //@mark(xCommon, "common"),refs("common", firCommon, xCommon, zCommon)
-	x.firstMethod() //@mark(xfMethod, "firstMethod"),refs("firstMethod", firMethod, xfMethod, zfMethod)
-	y.common() //@mark(yCommon, "common"),refs("common", secCommon, yCommon, zCommon)
-	y.secondMethod() //@mark(ysMethod, "secondMethod"),refs("secondMethod", secMethod, ysMethod, zsMethod)
-
-	var z *s = &s{}
-	z.firstMethod() //@mark(zfMethod, "firstMethod"),refs("firstMethod", sfMethod, xfMethod, zfMethod)
-	z.secondMethod() //@mark(zsMethod, "secondMethod"),refs("secondMethod", ssMethod, ysMethod, zsMethod)
-	z.common() //@mark(zCommon, "common"),refs("common", sCommon, xCommon, yCommon, zCommon)
-}
diff -urN a/gopls/internal/lsp/testdata/references/other/other.go b/gopls/internal/lsp/testdata/references/other/other.go
--- a/gopls/internal/lsp/testdata/references/other/other.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/references/other/other.go	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
-package other
-
-import (
-	references "golang.org/lsptests/references"
-)
-
-func GetXes() []references.X {
-	return []references.X{
-		{
-			Y: 1, //@mark(GetXesY, "Y"),refs("Y", typeXY, GetXesY, anotherXY)
-		},
-	}
-}
-
-func _() {
-	references.Q = "hello" //@mark(assignExpQ, "Q")
-	bob := func(_ string) {}
-	bob(references.Q) //@mark(bobExpQ, "Q")
-}
diff -urN a/gopls/internal/lsp/testdata/references/refs.go b/gopls/internal/lsp/testdata/references/refs.go
--- a/gopls/internal/lsp/testdata/references/refs.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/references/refs.go	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-// Package refs is a package used to test find references.
-package refs
-
-type i int //@mark(typeI, "i"),refs("i", typeI, argI, returnI, embeddedI)
-
-type X struct {
-	Y int //@mark(typeXY, "Y")
-}
-
-func _(_ i) []bool { //@mark(argI, "i")
-	return nil
-}
-
-func _(_ []byte) i { //@mark(returnI, "i")
-	return 0
-}
-
-var q string //@mark(declQ, "q"),refs("q", declQ, assignQ, bobQ)
-
-var Q string //@mark(declExpQ, "Q"),refs("Q", declExpQ, assignExpQ, bobExpQ)
-
-func _() {
-	q = "hello" //@mark(assignQ, "q")
-	bob := func(_ string) {}
-	bob(q) //@mark(bobQ, "q")
-}
-
-type e struct {
-	i //@mark(embeddedI, "i"),refs("i", embeddedI, embeddedIUse)
-}
-
-func _() {
-	_ = e{}.i //@mark(embeddedIUse, "i")
-}
-
-const (
-	foo = iota //@refs("iota")
-)
diff -urN a/gopls/internal/lsp/testdata/references/refs_test.go b/gopls/internal/lsp/testdata/references/refs_test.go
--- a/gopls/internal/lsp/testdata/references/refs_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/references/refs_test.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package references
-
-import (
-	"testing"
-)
-
-// This test exists to bring the test package into existence.
-
-func TestReferences(t *testing.T) {
-}
diff -urN a/gopls/internal/lsp/testdata/rename/a/random.go.golden b/gopls/internal/lsp/testdata/rename/a/random.go.golden
--- a/gopls/internal/lsp/testdata/rename/a/random.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/a/random.go.golden	1969-12-31 16:00:00
@@ -1,616 +0,0 @@
--- GetSum-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) GetSum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.GetSum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- f2name-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2name "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2name.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- f2y-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2y "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2y.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- fmt2-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	fmt2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		fmt2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- fmty-rename --
-package a
-
-import (
-	lg "log"
-	fmty "fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmty.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- format-rename --
-package a
-
-import (
-	lg "log"
-	format "fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		format.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- log-rename --
-package a
-
-import (
-	"log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		log.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- myX-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	myX, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.myX + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- pos-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var pos Pos   //@rename("p", "pos")
-	_ = pos.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- y0-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y0 := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y0) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y0) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y0) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- y1-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y1 := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y1) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y1) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y1) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- y2-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y2 := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y2) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y2) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y2) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- y3-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y3 := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y3) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y3) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y3) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
--- z-rename --
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(z int) int { //@rename("y", "z")
-	return z
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/a/random.go.in b/gopls/internal/lsp/testdata/rename/a/random.go.in
--- a/gopls/internal/lsp/testdata/rename/a/random.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/a/random.go.in	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-package a
-
-import (
-	lg "log"
-	"fmt" //@rename("fmt", "fmty")
-	f2 "fmt" //@rename("f2", "f2name"),rename("fmt","f2y")
-)
-
-func Random() int {
-	y := 6 + 7
-	return y
-}
-
-func Random2(y int) int { //@rename("y", "z")
-	return y
-}
-
-type Pos struct {
-	x, y int
-}
-
-func (p *Pos) Sum() int {
-	return p.x + p.y //@rename("x", "myX")
-}
-
-func _() {
-	var p Pos   //@rename("p", "pos")
-	_ = p.Sum() //@rename("Sum", "GetSum")
-}
-
-func sw() {
-	var x interface{}
-
-	switch y := x.(type) { //@rename("y", "y0")
-	case int:
-		fmt.Printf("%d", y) //@rename("y", "y1"),rename("fmt", "format")
-	case string:
-		lg.Printf("%s", y) //@rename("y", "y2"),rename("lg","log")
-	default:
-		f2.Printf("%v", y) //@rename("y", "y3"),rename("f2","fmt2")
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/rename/b/b.go b/gopls/internal/lsp/testdata/rename/b/b.go
--- a/gopls/internal/lsp/testdata/rename/b/b.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/b/b.go	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-package b
-
-var c int //@rename("int", "uint")
-
-func _() {
-	a := 1 //@rename("a", "error")
-	a = 2
-	_ = a
-}
-
-var (
-	// Hello there.
-	// Foo does the thing.
-	Foo int //@rename("Foo", "Bob")
-)
-
-/*
-Hello description
-*/
-func Hello() {} //@rename("Hello", "Goodbye")
diff -urN a/gopls/internal/lsp/testdata/rename/b/b.go.golden b/gopls/internal/lsp/testdata/rename/b/b.go.golden
--- a/gopls/internal/lsp/testdata/rename/b/b.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/b/b.go.golden	1969-12-31 16:00:00
@@ -1,78 +0,0 @@
--- Bob-rename --
-package b
-
-var c int //@rename("int", "uint")
-
-func _() {
-	a := 1 //@rename("a", "error")
-	a = 2
-	_ = a
-}
-
-var (
-	// Hello there.
-	// Bob does the thing.
-	Bob int //@rename("Foo", "Bob")
-)
-
-/*
-Hello description
-*/
-func Hello() {} //@rename("Hello", "Goodbye")
-
--- Goodbye-rename --
-b.go:
-package b
-
-var c int //@rename("int", "uint")
-
-func _() {
-	a := 1 //@rename("a", "error")
-	a = 2
-	_ = a
-}
-
-var (
-	// Hello there.
-	// Foo does the thing.
-	Foo int //@rename("Foo", "Bob")
-)
-
-/*
-Goodbye description
-*/
-func Goodbye() {} //@rename("Hello", "Goodbye")
-
-c.go:
-package c
-
-import "golang.org/lsptests/rename/b"
-
-func _() {
-	b.Goodbye() //@rename("Hello", "Goodbye")
-}
-
--- error-rename --
-package b
-
-var c int //@rename("int", "uint")
-
-func _() {
-	error := 1 //@rename("a", "error")
-	error = 2
-	_ = error
-}
-
-var (
-	// Hello there.
-	// Foo does the thing.
-	Foo int //@rename("Foo", "Bob")
-)
-
-/*
-Hello description
-*/
-func Hello() {} //@rename("Hello", "Goodbye")
-
--- uint-rename --
-"int": builtin object
diff -urN a/gopls/internal/lsp/testdata/rename/bad/bad.go.golden b/gopls/internal/lsp/testdata/rename/bad/bad.go.golden
--- a/gopls/internal/lsp/testdata/rename/bad/bad.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/bad/bad.go.golden	1969-12-31 16:00:00
@@ -1,2 +0,0 @@
--- rFunc-rename --
-renaming "sFunc" to "rFunc" not possible because "golang.org/lsptests/rename/bad" has errors
diff -urN a/gopls/internal/lsp/testdata/rename/bad/bad.go.in b/gopls/internal/lsp/testdata/rename/bad/bad.go.in
--- a/gopls/internal/lsp/testdata/rename/bad/bad.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/bad/bad.go.in	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package bad
-
-type myStruct struct {
-}
-
-func (s *myStruct) sFunc() bool { //@rename("sFunc", "rFunc")
-	return s.Bad
-}
diff -urN a/gopls/internal/lsp/testdata/rename/bad/bad_test.go.in b/gopls/internal/lsp/testdata/rename/bad/bad_test.go.in
--- a/gopls/internal/lsp/testdata/rename/bad/bad_test.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/bad/bad_test.go.in	1969-12-31 16:00:00
@@ -1 +0,0 @@
-package bad
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/rename/c/c.go b/gopls/internal/lsp/testdata/rename/c/c.go
--- a/gopls/internal/lsp/testdata/rename/c/c.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/c/c.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package c
-
-import "golang.org/lsptests/rename/b"
-
-func _() {
-	b.Hello() //@rename("Hello", "Goodbye")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/c/c.go.golden b/gopls/internal/lsp/testdata/rename/c/c.go.golden
--- a/gopls/internal/lsp/testdata/rename/c/c.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/c/c.go.golden	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
--- Goodbye-rename --
-b.go:
-package b
-
-var c int //@rename("int", "uint")
-
-func _() {
-	a := 1 //@rename("a", "error")
-	a = 2
-	_ = a
-}
-
-var (
-	// Hello there.
-	// Foo does the thing.
-	Foo int //@rename("Foo", "Bob")
-)
-
-/*
-Goodbye description
-*/
-func Goodbye() {} //@rename("Hello", "Goodbye")
-
-c.go:
-package c
-
-import "golang.org/lsptests/rename/b"
-
-func _() {
-	b.Goodbye() //@rename("Hello", "Goodbye")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/c/c2.go b/gopls/internal/lsp/testdata/rename/c/c2.go
--- a/gopls/internal/lsp/testdata/rename/c/c2.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/c/c2.go	1969-12-31 16:00:00
@@ -1,4 +0,0 @@
-package c
-
-//go:embed Static/*
-var Static embed.FS //@rename("Static", "static")
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/rename/c/c2.go.golden b/gopls/internal/lsp/testdata/rename/c/c2.go.golden
--- a/gopls/internal/lsp/testdata/rename/c/c2.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/c/c2.go.golden	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
--- static-rename --
-package c
-
-//go:embed Static/*
-var static embed.FS //@rename("Static", "static")
diff -urN a/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go b/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go
--- a/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package another
-
-type (
-	I interface{ F() }
-	C struct{ I }
-)
-
-func (C) g()
-
-func _() {
-	var x I = C{}
-	x.F() //@rename("F", "G")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go.golden b/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go.golden
--- a/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/crosspkg/another/another.go.golden	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
--- G-rename --
-package another
-
-type (
-	I interface{ G() }
-	C struct{ I }
-)
-
-func (C) g()
-
-func _() {
-	var x I = C{}
-	x.G() //@rename("F", "G")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go b/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go
--- a/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package crosspkg
-
-func Foo() { //@rename("Foo", "Dolphin")
-
-}
-
-var Bar int //@rename("Bar", "Tomato")
diff -urN a/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go.golden b/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go.golden
--- a/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/crosspkg/crosspkg.go.golden	1969-12-31 16:00:00
@@ -1,40 +0,0 @@
--- Dolphin-rename --
-crosspkg.go:
-package crosspkg
-
-func Dolphin() { //@rename("Foo", "Dolphin")
-
-}
-
-var Bar int //@rename("Bar", "Tomato")
-
-other.go:
-package other
-
-import "golang.org/lsptests/rename/crosspkg"
-
-func Other() {
-	crosspkg.Bar
-	crosspkg.Dolphin() //@rename("Foo", "Flamingo")
-}
-
--- Tomato-rename --
-crosspkg.go:
-package crosspkg
-
-func Foo() { //@rename("Foo", "Dolphin")
-
-}
-
-var Tomato int //@rename("Bar", "Tomato")
-
-other.go:
-package other
-
-import "golang.org/lsptests/rename/crosspkg"
-
-func Other() {
-	crosspkg.Tomato
-	crosspkg.Foo() //@rename("Foo", "Flamingo")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go b/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go
--- a/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package other
-
-import "golang.org/lsptests/rename/crosspkg"
-
-func Other() {
-	crosspkg.Bar
-	crosspkg.Foo() //@rename("Foo", "Flamingo")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go.golden b/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go.golden
--- a/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/crosspkg/other/other.go.golden	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
--- Flamingo-rename --
-crosspkg.go:
-package crosspkg
-
-func Flamingo() { //@rename("Foo", "Dolphin")
-
-}
-
-var Bar int //@rename("Bar", "Tomato")
-
-other.go:
-package other
-
-import "golang.org/lsptests/rename/crosspkg"
-
-func Other() {
-	crosspkg.Bar
-	crosspkg.Flamingo() //@rename("Foo", "Flamingo")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/generics/embedded.go b/gopls/internal/lsp/testdata/rename/generics/embedded.go
--- a/gopls/internal/lsp/testdata/rename/generics/embedded.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/generics/embedded.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type foo[P any] int //@rename("foo","bar")
-
-var x struct{ foo[int] }
-
-var _ = x.foo
diff -urN a/gopls/internal/lsp/testdata/rename/generics/embedded.go.golden b/gopls/internal/lsp/testdata/rename/generics/embedded.go.golden
--- a/gopls/internal/lsp/testdata/rename/generics/embedded.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/generics/embedded.go.golden	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
--- bar-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type bar[P any] int //@rename("foo","bar")
-
-var x struct{ bar[int] }
-
-var _ = x.bar
-
diff -urN a/gopls/internal/lsp/testdata/rename/generics/generics.go b/gopls/internal/lsp/testdata/rename/generics/generics.go
--- a/gopls/internal/lsp/testdata/rename/generics/generics.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/generics/generics.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type G[P any] struct {
-	F int
-}
-
-func (G[_]) M() {}
-
-func F[P any](P) {
-	var p P //@rename("P", "Q")
-	_ = p
-}
-
-func _() {
-	var x G[int] //@rename("G", "H")
-	_ = x.F      //@rename("F", "K")
-	x.M()        //@rename("M", "N")
-
-	var y G[string]
-	_ = y.F
-	y.M()
-}
diff -urN a/gopls/internal/lsp/testdata/rename/generics/generics.go.golden b/gopls/internal/lsp/testdata/rename/generics/generics.go.golden
--- a/gopls/internal/lsp/testdata/rename/generics/generics.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/generics/generics.go.golden	1969-12-31 16:00:00
@@ -1,108 +0,0 @@
--- H-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type H[P any] struct {
-	F int
-}
-
-func (H[_]) M() {}
-
-func F[P any](P) {
-	var p P //@rename("P", "Q")
-	_ = p
-}
-
-func _() {
-	var x H[int] //@rename("G", "H")
-	_ = x.F      //@rename("F", "K")
-	x.M()        //@rename("M", "N")
-
-	var y H[string]
-	_ = y.F
-	y.M()
-}
-
--- K-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type G[P any] struct {
-	K int
-}
-
-func (G[_]) M() {}
-
-func F[P any](P) {
-	var p P //@rename("P", "Q")
-	_ = p
-}
-
-func _() {
-	var x G[int] //@rename("G", "H")
-	_ = x.K      //@rename("F", "K")
-	x.M()        //@rename("M", "N")
-
-	var y G[string]
-	_ = y.K
-	y.M()
-}
-
--- N-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type G[P any] struct {
-	F int
-}
-
-func (G[_]) N() {}
-
-func F[P any](P) {
-	var p P //@rename("P", "Q")
-	_ = p
-}
-
-func _() {
-	var x G[int] //@rename("G", "H")
-	_ = x.F      //@rename("F", "K")
-	x.N()        //@rename("M", "N")
-
-	var y G[string]
-	_ = y.F
-	y.N()
-}
-
--- Q-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type G[P any] struct {
-	F int
-}
-
-func (G[_]) M() {}
-
-func F[Q any](Q) {
-	var p Q //@rename("P", "Q")
-	_ = p
-}
-
-func _() {
-	var x G[int] //@rename("G", "H")
-	_ = x.F      //@rename("F", "K")
-	x.M()        //@rename("M", "N")
-
-	var y G[string]
-	_ = y.F
-	y.M()
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/generics/unions.go b/gopls/internal/lsp/testdata/rename/generics/unions.go
--- a/gopls/internal/lsp/testdata/rename/generics/unions.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/generics/unions.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type T string //@rename("T", "R")
-
-type C interface {
-	T | ~int //@rename("T", "S")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/generics/unions.go.golden b/gopls/internal/lsp/testdata/rename/generics/unions.go.golden
--- a/gopls/internal/lsp/testdata/rename/generics/unions.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/generics/unions.go.golden	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
--- R-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type R string //@rename("T", "R")
-
-type C interface {
-	R | ~int //@rename("T", "S")
-}
-
--- S-rename --
-//go:build go1.18
-// +build go1.18
-
-package generics
-
-type S string //@rename("T", "R")
-
-type C interface {
-	S | ~int //@rename("T", "S")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.golden b/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.golden
--- a/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.golden	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
--- bar-rename --
-package issue39614
-
-func fn() {
-	var bar bool //@rename("foo","bar")
-	make(map[string]bool
-	if true {
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.in b/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.in
--- a/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue39614/issue39614.go.in	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package issue39614
-
-func fn() {
-	var foo bool //@rename("foo","bar")
-	make(map[string]bool
-	if true {
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/1.go b/gopls/internal/lsp/testdata/rename/issue42134/1.go
--- a/gopls/internal/lsp/testdata/rename/issue42134/1.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/1.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package issue42134
-
-func _() {
-	// foo computes things.
-	foo := func() {}
-
-	foo() //@rename("foo", "bar")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/1.go.golden b/gopls/internal/lsp/testdata/rename/issue42134/1.go.golden
--- a/gopls/internal/lsp/testdata/rename/issue42134/1.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/1.go.golden	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
--- bar-rename --
-package issue42134
-
-func _() {
-	// bar computes things.
-	bar := func() {}
-
-	bar() //@rename("foo", "bar")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/2.go b/gopls/internal/lsp/testdata/rename/issue42134/2.go
--- a/gopls/internal/lsp/testdata/rename/issue42134/2.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/2.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package issue42134
-
-import "fmt"
-
-func _() {
-	// minNumber is a min number.
-	// Second line.
-	minNumber := min(1, 2)
-	fmt.Println(minNumber) //@rename("minNumber", "res")
-}
-
-func min(a, b int) int { return a }
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/2.go.golden b/gopls/internal/lsp/testdata/rename/issue42134/2.go.golden
--- a/gopls/internal/lsp/testdata/rename/issue42134/2.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/2.go.golden	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
--- res-rename --
-package issue42134
-
-import "fmt"
-
-func _() {
-	// res is a min number.
-	// Second line.
-	res := min(1, 2)
-	fmt.Println(res) //@rename("minNumber", "res")
-}
-
-func min(a, b int) int { return a }
-
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/3.go b/gopls/internal/lsp/testdata/rename/issue42134/3.go
--- a/gopls/internal/lsp/testdata/rename/issue42134/3.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/3.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package issue42134
-
-func _() {
-	/*
-	tests contains test cases
-	*/
-	tests := []struct { //@rename("tests", "testCases")
-		in, out string
-	}{}
-	_ = tests
-}
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/3.go.golden b/gopls/internal/lsp/testdata/rename/issue42134/3.go.golden
--- a/gopls/internal/lsp/testdata/rename/issue42134/3.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/3.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- testCases-rename --
-package issue42134
-
-func _() {
-	/*
-	testCases contains test cases
-	*/
-	testCases := []struct { //@rename("tests", "testCases")
-		in, out string
-	}{}
-	_ = testCases
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/4.go b/gopls/internal/lsp/testdata/rename/issue42134/4.go
--- a/gopls/internal/lsp/testdata/rename/issue42134/4.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/4.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package issue42134
-
-func _() {
-	// a is equal to 5. Comment must stay the same
-
-	a := 5
-	_ = a //@rename("a", "b")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/issue42134/4.go.golden b/gopls/internal/lsp/testdata/rename/issue42134/4.go.golden
--- a/gopls/internal/lsp/testdata/rename/issue42134/4.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue42134/4.go.golden	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
--- b-rename --
-package issue42134
-
-func _() {
-	// a is equal to 5. Comment must stay the same
-
-	b := 5
-	_ = b //@rename("a", "b")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.golden b/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.golden
--- a/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- bar-rename --
-package issue43616
-
-type bar int //@rename("foo","bar"),prepare("oo","foo","foo")
-
-var x struct{ bar } //@rename("foo","baz")
-
-var _ = x.bar //@rename("foo","quux")
-
--- baz-rename --
-can't rename embedded fields: rename the type directly or name the field
--- quux-rename --
-can't rename embedded fields: rename the type directly or name the field
diff -urN a/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.in b/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.in
--- a/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/issue43616/issue43616.go.in	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package issue43616
-
-type foo int //@rename("foo","bar"),prepare("oo","foo","foo")
-
-var x struct{ foo } //@rename("foo","baz")
-
-var _ = x.foo //@rename("foo","quux")
diff -urN a/gopls/internal/lsp/testdata/rename/shadow/shadow.go b/gopls/internal/lsp/testdata/rename/shadow/shadow.go
--- a/gopls/internal/lsp/testdata/rename/shadow/shadow.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/shadow/shadow.go	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-package shadow
-
-func _() {
-	a := true
-	b, c, _ := A(), B(), D() //@rename("A", "a"),rename("B", "b"),rename("b", "c"),rename("D", "d")
-	d := false
-	_, _, _, _ = a, b, c, d
-}
-
-func A() int {
-	return 0
-}
-
-func B() int {
-	return 0
-}
-
-func D() int {
-	return 0
-}
diff -urN a/gopls/internal/lsp/testdata/rename/shadow/shadow.go.golden b/gopls/internal/lsp/testdata/rename/shadow/shadow.go.golden
--- a/gopls/internal/lsp/testdata/rename/shadow/shadow.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/shadow/shadow.go.golden	1969-12-31 16:00:00
@@ -1,48 +0,0 @@
--- a-rename --
-renaming this func "A" to "a"	would cause this reference to become shadowed	by this intervening var definition
--- b-rename --
-package shadow
-
-func _() {
-	a := true
-	b, c, _ := A(), b(), D() //@rename("A", "a"),rename("B", "b"),rename("b", "c"),rename("D", "d")
-	d := false
-	_, _, _, _ = a, b, c, d
-}
-
-func A() int {
-	return 0
-}
-
-func b() int {
-	return 0
-}
-
-func D() int {
-	return 0
-}
-
--- c-rename --
-renaming this var "b" to "c"	conflicts with var in same block
--- d-rename --
-package shadow
-
-func _() {
-	a := true
-	b, c, _ := A(), B(), d() //@rename("A", "a"),rename("B", "b"),rename("b", "c"),rename("D", "d")
-	d := false
-	_, _, _, _ = a, b, c, d
-}
-
-func A() int {
-	return 0
-}
-
-func B() int {
-	return 0
-}
-
-func d() int {
-	return 0
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/testy/testy.go b/gopls/internal/lsp/testdata/rename/testy/testy.go
--- a/gopls/internal/lsp/testdata/rename/testy/testy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/testy/testy.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package testy
-
-type tt int //@rename("tt", "testyType")
-
-func a() {
-	foo := 42 //@rename("foo", "bar")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/testy/testy.go.golden b/gopls/internal/lsp/testdata/rename/testy/testy.go.golden
--- a/gopls/internal/lsp/testdata/rename/testy/testy.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/testy/testy.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- bar-rename --
-package testy
-
-type tt int //@rename("tt", "testyType")
-
-func a() {
-	bar := 42 //@rename("foo", "bar")
-}
-
--- testyType-rename --
-package testy
-
-type testyType int //@rename("tt", "testyType")
-
-func a() {
-	foo := 42 //@rename("foo", "bar")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rename/testy/testy_test.go b/gopls/internal/lsp/testdata/rename/testy/testy_test.go
--- a/gopls/internal/lsp/testdata/rename/testy/testy_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/testy/testy_test.go	1969-12-31 16:00:00
@@ -1,8 +0,0 @@
-package testy
-
-import "testing"
-
-func TestSomething(t *testing.T) {
-	var x int //@rename("x", "testyX")
-	a()       //@rename("a", "b")
-}
diff -urN a/gopls/internal/lsp/testdata/rename/testy/testy_test.go.golden b/gopls/internal/lsp/testdata/rename/testy/testy_test.go.golden
--- a/gopls/internal/lsp/testdata/rename/testy/testy_test.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rename/testy/testy_test.go.golden	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
--- b-rename --
-testy.go:
-package testy
-
-type tt int //@rename("tt", "testyType")
-
-func b() {
-	foo := 42 //@rename("foo", "bar")
-}
-
-testy_test.go:
-package testy
-
-import "testing"
-
-func TestSomething(t *testing.T) {
-	var x int //@rename("x", "testyX")
-	b()       //@rename("a", "b")
-}
-
--- testyX-rename --
-package testy
-
-import "testing"
-
-func TestSomething(t *testing.T) {
-	var testyX int //@rename("x", "testyX")
-	a()       //@rename("a", "b")
-}
-
diff -urN a/gopls/internal/lsp/testdata/rundespiteerrors/rundespiteerrors.go b/gopls/internal/lsp/testdata/rundespiteerrors/rundespiteerrors.go
--- a/gopls/internal/lsp/testdata/rundespiteerrors/rundespiteerrors.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/rundespiteerrors/rundespiteerrors.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-package rundespiteerrors
-
-// This test verifies that analyzers without RunDespiteErrors are not
-// executed on a package containing type errors (see issue #54762).
-func _() {
-	// A type error.
-	_ = 1 + "" //@diag("1", "compiler", "mismatched types|cannot convert", "error")
-
-	// A violation of an analyzer for which RunDespiteErrors=false:
-	// no diagnostic is produced; the diag comment is merely illustrative.
-	for _ = range "" { //diag("for _", "simplifyrange", "simplify range expression", "warning")
-
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/selectionrange/foo.go b/gopls/internal/lsp/testdata/selectionrange/foo.go
--- a/gopls/internal/lsp/testdata/selectionrange/foo.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/selectionrange/foo.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package foo
-
-import "time"
-
-func Bar(x, y int, t time.Time) int {
-	zs := []int{1, 2, 3} //@selectionrange("1")
-
-	for _, z := range zs {
-		x = x + z + y + zs[1] //@selectionrange("1")
-	}
-
-	return x + y //@selectionrange("+")
-}
diff -urN a/gopls/internal/lsp/testdata/selectionrange/foo.go.golden b/gopls/internal/lsp/testdata/selectionrange/foo.go.golden
--- a/gopls/internal/lsp/testdata/selectionrange/foo.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/selectionrange/foo.go.golden	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
--- selectionrange_foo_12_11 --
-Ranges 0: 
-	11:8-11:13 "x + y"
-	11:1-11:13 "return x + y"
-	4:36-12:1 "{\\n\tzs := []int{...ionrange(\"+\")\\n}"
-	4:0-12:1 "func Bar(x, y i...ionrange(\"+\")\\n}"
-	0:0-12:1 "package foo\\n\\nim...ionrange(\"+\")\\n}"
-
--- selectionrange_foo_6_14 --
-Ranges 0: 
-	5:13-5:14 "1"
-	5:7-5:21 "[]int{1, 2, 3}"
-	5:1-5:21 "zs := []int{1, 2, 3}"
-	4:36-12:1 "{\\n\tzs := []int{...ionrange(\"+\")\\n}"
-	4:0-12:1 "func Bar(x, y i...ionrange(\"+\")\\n}"
-	0:0-12:1 "package foo\\n\\nim...ionrange(\"+\")\\n}"
-
--- selectionrange_foo_9_22 --
-Ranges 0: 
-	8:21-8:22 "1"
-	8:18-8:23 "zs[1]"
-	8:6-8:23 "x + z + y + zs[1]"
-	8:2-8:23 "x = x + z + y + zs[1]"
-	7:22-9:2 "{\\n\t\tx = x + z +...onrange(\"1\")\\n\t}"
-	7:1-9:2 "for _, z := ran...onrange(\"1\")\\n\t}"
-	4:36-12:1 "{\\n\tzs := []int{...ionrange(\"+\")\\n}"
-	4:0-12:1 "func Bar(x, y i...ionrange(\"+\")\\n}"
-	0:0-12:1 "package foo\\n\\nim...ionrange(\"+\")\\n}"
-
diff -urN a/gopls/internal/lsp/testdata/selector/selector.go.in b/gopls/internal/lsp/testdata/selector/selector.go.in
--- a/gopls/internal/lsp/testdata/selector/selector.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/selector/selector.go.in	1969-12-31 16:00:00
@@ -1,66 +0,0 @@
-// +build go1.11
-
-package selector
-
-import (
-	"golang.org/lsptests/bar"
-)
-
-type S struct {
-	B, A, C int //@item(Bf, "B", "int", "field"),item(Af, "A", "int", "field"),item(Cf, "C", "int", "field")
-}
-
-func _() {
-	_ = S{}.; //@complete(";", Af, Bf, Cf)
-}
-
-type bob struct { a int } //@item(a, "a", "int", "field")
-type george struct { b int }
-type jack struct { c int } //@item(c, "c", "int", "field")
-type jill struct { d int }
-
-func (b *bob) george() *george {} //@item(george, "george", "func() *george", "method")
-func (g *george) jack() *jack {}
-func (j *jack) jill() *jill {} //@item(jill, "jill", "func() *jill", "method")
-
-func _() {
-	b := &bob{}
-	y := b.george().
-		jack();
-	y.; //@complete(";", c, jill)
-}
-
-func _() {
-	bar. //@complete(" /", Bar)
-	x := 5
-
-	var b *bob
-	b. //@complete(" /", a, george)
-	y, z := 5, 6
-
-	b. //@complete(" /", a, george)
-	y, z, a, b, c := 5, 6
-}
-
-func _() {
-	bar. //@complete(" /", Bar)
-	bar.Bar()
-
-	bar. //@complete(" /", Bar)
-	go f()
-}
-
-func _() {
-	var b *bob
-	if y != b. //@complete(" /", a, george)
-	z := 5
-
-	if z + y + 1 + b. //@complete(" /", a, george)
-	r, s, t := 4, 5
-
-	if y != b. //@complete(" /", a, george)
-	z = 5
-
-	if z + y + 1 + b. //@complete(" /", a, george)
-	r = 4
-}
diff -urN a/gopls/internal/lsp/testdata/semantic/README.md b/gopls/internal/lsp/testdata/semantic/README.md
--- a/gopls/internal/lsp/testdata/semantic/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/semantic/README.md	1969-12-31 16:00:00
@@ -1,2 +0,0 @@
-The golden files are the output of `gopls semtok <src-file>`, with `-- semantic --`
-inserted as the first line (the spaces are mandatory) and an extra newline at the end.
diff -urN a/gopls/internal/lsp/testdata/semantic/a.go b/gopls/internal/lsp/testdata/semantic/a.go
--- a/gopls/internal/lsp/testdata/semantic/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/semantic/a.go	1969-12-31 16:00:00
@@ -1,81 +0,0 @@
-package semantictokens //@ semantic("")
-
-import (
-	_ "encoding/utf8"
-	utf "encoding/utf8"
-	"fmt" //@ semantic("fmt")
-	. "fmt"
-	"unicode/utf8"
-)
-
-var (
-	a           = fmt.Print
-	b  []string = []string{"foo"}
-	c1 chan int
-	c2 <-chan int
-	c3 = make([]chan<- int)
-	b  = A{X: 23}
-	m  map[bool][3]*float64
-)
-
-const (
-	xx F = iota
-	yy   = xx + 3
-	zz   = ""
-	ww   = "not " + zz
-)
-
-type A struct {
-	X int `foof`
-}
-type B interface {
-	A
-	sad(int) bool
-}
-
-type F int
-
-func (a *A) f() bool {
-	var z string
-	x := "foo"
-	a(x)
-	y := "bar" + x
-	switch z {
-	case "xx":
-	default:
-	}
-	select {
-	case z := <-c3[0]:
-	default:
-	}
-	for k, v := range m {
-		return (!k) && v[0] == nil
-	}
-	c2 <- A.X
-	w := b[4:]
-	j := len(x)
-	j--
-	q := []interface{}{j, 23i, &y}
-	g(q...)
-	return true
-}
-
-func g(vv ...interface{}) {
-	ff := func() {}
-	defer ff()
-	go utf.RuneCount("")
-	go utf8.RuneCount(vv.(string))
-	if true {
-	} else {
-	}
-Never:
-	for i := 0; i < 10; {
-		break Never
-	}
-	_, ok := vv[0].(A)
-	if !ok {
-		switch x := vv[0].(type) {
-		}
-		goto Never
-	}
-}
diff -urN a/gopls/internal/lsp/testdata/semantic/a.go.golden b/gopls/internal/lsp/testdata/semantic/a.go.golden
--- a/gopls/internal/lsp/testdata/semantic/a.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/semantic/a.go.golden	1969-12-31 16:00:00
@@ -1,83 +0,0 @@
--- semantic --
-/*⇒7,keyword,[]*/package /*⇒14,namespace,[]*/semantictokens /*⇒16,comment,[]*///@ semantic("")
-
-/*⇒6,keyword,[]*/import (
-	_ "encoding/utf8"
-	/*⇒3,namespace,[]*/utf "encoding/utf8"
-	"fmt"/*⇐3,namespace,[]*/ /*⇒19,comment,[]*///@ semantic("fmt")
-	. "fmt"
-	"unicode/utf8"/*⇐4,namespace,[]*/
-)
-
-/*⇒3,keyword,[]*/var (
-	/*⇒1,variable,[definition]*/a           = /*⇒3,namespace,[]*/fmt./*⇒5,function,[]*/Print
-	/*⇒1,variable,[definition]*/b  []/*⇒6,type,[defaultLibrary]*/string = []/*⇒6,type,[defaultLibrary]*/string{/*⇒5,string,[]*/"foo"}
-	/*⇒2,variable,[definition]*/c1 /*⇒4,keyword,[]*/chan /*⇒3,type,[defaultLibrary]*/int
-	/*⇒2,variable,[definition]*/c2 /*⇒2,operator,[]*/<-/*⇒4,keyword,[]*/chan /*⇒3,type,[defaultLibrary]*/int
-	/*⇒2,variable,[definition]*/c3 = /*⇒4,function,[defaultLibrary]*/make([]/*⇒4,keyword,[]*/chan/*⇒2,operator,[]*/<- /*⇒3,type,[defaultLibrary]*/int)
-	/*⇒1,variable,[definition]*/b  = /*⇒1,type,[]*/A{/*⇒1,variable,[]*/X: /*⇒2,number,[]*/23}
-	/*⇒1,variable,[definition]*/m  /*⇒3,keyword,[]*/map[/*⇒4,type,[defaultLibrary]*/bool][/*⇒1,number,[]*/3]/*⇒1,operator,[]*/*/*⇒7,type,[defaultLibrary]*/float64
-)
-
-/*⇒5,keyword,[]*/const (
-	/*⇒2,variable,[definition readonly]*/xx /*⇒1,type,[]*/F = /*⇒4,variable,[readonly]*/iota
-	/*⇒2,variable,[definition readonly]*/yy   = /*⇒2,variable,[readonly]*/xx /*⇒1,operator,[]*/+ /*⇒1,number,[]*/3
-	/*⇒2,variable,[definition readonly]*/zz   = /*⇒2,string,[]*/""
-	/*⇒2,variable,[definition readonly]*/ww   = /*⇒6,string,[]*/"not " /*⇒1,operator,[]*/+ /*⇒2,variable,[readonly]*/zz
-)
-
-/*⇒4,keyword,[]*/type /*⇒1,type,[definition]*/A /*⇒6,keyword,[]*/struct {
-	/*⇒1,variable,[definition]*/X /*⇒3,type,[defaultLibrary]*/int /*⇒6,string,[]*/`foof`
-}
-/*⇒4,keyword,[]*/type /*⇒1,type,[definition]*/B /*⇒9,keyword,[]*/interface {
-	/*⇒1,type,[]*/A
-	/*⇒3,method,[definition]*/sad(/*⇒3,type,[defaultLibrary]*/int) /*⇒4,type,[defaultLibrary]*/bool
-}
-
-/*⇒4,keyword,[]*/type /*⇒1,type,[definition]*/F /*⇒3,type,[defaultLibrary]*/int
-
-/*⇒4,keyword,[]*/func (/*⇒1,variable,[]*/a /*⇒1,operator,[]*/*/*⇒1,type,[]*/A) /*⇒1,method,[definition]*/f() /*⇒4,type,[defaultLibrary]*/bool {
-	/*⇒3,keyword,[]*/var /*⇒1,variable,[definition]*/z /*⇒6,type,[defaultLibrary]*/string
-	/*⇒1,variable,[definition]*/x /*⇒2,operator,[]*/:= /*⇒5,string,[]*/"foo"
-	/*⇒1,variable,[]*/a(/*⇒1,variable,[]*/x)
-	/*⇒1,variable,[definition]*/y /*⇒2,operator,[]*/:= /*⇒5,string,[]*/"bar" /*⇒1,operator,[]*/+ /*⇒1,variable,[]*/x
-	/*⇒6,keyword,[]*/switch /*⇒1,variable,[]*/z {
-	/*⇒4,keyword,[]*/case /*⇒4,string,[]*/"xx":
-	/*⇒7,keyword,[]*/default:
-	}
-	/*⇒6,keyword,[]*/select {
-	/*⇒4,keyword,[]*/case /*⇒1,variable,[definition]*/z /*⇒2,operator,[]*/:= /*⇒2,operator,[]*/<-/*⇒2,variable,[]*/c3[/*⇒1,number,[]*/0]:
-	/*⇒7,keyword,[]*/default:
-	}
-	/*⇒3,keyword,[]*/for /*⇒1,variable,[definition]*/k, /*⇒1,variable,[definition]*/v := /*⇒5,keyword,[]*/range /*⇒1,variable,[]*/m {
-		/*⇒6,keyword,[]*/return (/*⇒1,operator,[]*/!/*⇒1,variable,[]*/k) /*⇒2,operator,[]*/&& /*⇒1,variable,[]*/v[/*⇒1,number,[]*/0] /*⇒2,operator,[]*/== /*⇒3,variable,[readonly defaultLibrary]*/nil
-	}
-	/*⇒2,variable,[]*/c2 /*⇒2,operator,[]*/<- /*⇒1,type,[]*/A./*⇒1,variable,[]*/X
-	/*⇒1,variable,[definition]*/w /*⇒2,operator,[]*/:= /*⇒1,variable,[]*/b[/*⇒1,number,[]*/4:]
-	/*⇒1,variable,[definition]*/j /*⇒2,operator,[]*/:= /*⇒3,function,[defaultLibrary]*/len(/*⇒1,variable,[]*/x)
-	/*⇒1,variable,[]*/j/*⇒2,operator,[]*/--
-	/*⇒1,variable,[definition]*/q /*⇒2,operator,[]*/:= []/*⇒9,keyword,[]*/interface{}{/*⇒1,variable,[]*/j, /*⇒3,number,[]*/23i, /*⇒1,operator,[]*/&/*⇒1,variable,[]*/y}
-	/*⇒1,function,[]*/g(/*⇒1,variable,[]*/q/*⇒3,operator,[]*/...)
-	/*⇒6,keyword,[]*/return /*⇒4,variable,[readonly]*/true
-}
-
-/*⇒4,keyword,[]*/func /*⇒1,function,[definition]*/g(/*⇒2,parameter,[definition]*/vv /*⇒3,operator,[]*/.../*⇒9,keyword,[]*/interface{}) {
-	/*⇒2,variable,[definition]*/ff /*⇒2,operator,[]*/:= /*⇒4,keyword,[]*/func() {}
-	/*⇒5,keyword,[]*/defer /*⇒2,function,[]*/ff()
-	/*⇒2,keyword,[]*/go /*⇒3,namespace,[]*/utf./*⇒9,function,[]*/RuneCount(/*⇒2,string,[]*/"")
-	/*⇒2,keyword,[]*/go /*⇒4,namespace,[]*/utf8./*⇒9,function,[]*/RuneCount(/*⇒2,parameter,[]*/vv.(/*⇒6,type,[]*/string))
-	/*⇒2,keyword,[]*/if /*⇒4,variable,[readonly]*/true {
-	} /*⇒4,keyword,[]*/else {
-	}
-/*⇒5,parameter,[definition]*/Never:
-	/*⇒3,keyword,[]*/for /*⇒1,variable,[definition]*/i /*⇒2,operator,[]*/:= /*⇒1,number,[]*/0; /*⇒1,variable,[]*/i /*⇒1,operator,[]*/< /*⇒2,number,[]*/10; {
-		/*⇒5,keyword,[]*/break Never
-	}
-	_, /*⇒2,variable,[definition]*/ok /*⇒2,operator,[]*/:= /*⇒2,parameter,[]*/vv[/*⇒1,number,[]*/0].(/*⇒1,type,[]*/A)
-	/*⇒2,keyword,[]*/if /*⇒1,operator,[]*/!/*⇒2,variable,[]*/ok {
-		/*⇒6,keyword,[]*/switch /*⇒1,variable,[definition]*/x /*⇒2,operator,[]*/:= /*⇒2,parameter,[]*/vv[/*⇒1,number,[]*/0].(/*⇒4,keyword,[]*/type) {
-		}
-		/*⇒4,keyword,[]*/goto Never
-	}
-}
-
diff -urN a/gopls/internal/lsp/testdata/semantic/b.go b/gopls/internal/lsp/testdata/semantic/b.go
--- a/gopls/internal/lsp/testdata/semantic/b.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/semantic/b.go	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-package semantictokens //@ semantic("")
-
-func f(x ...interface{}) {
-}
-
-func weirⰀd() { /*😀*/ // comment
-	const (
-		snil   = nil
-		nil    = true
-		true   = false
-		false  = snil
-		cmd    = `foof`
-		double = iota
-		iota   = copy
-		four   = (len(cmd)/2 < 5)
-		five   = four
-	)
-	f(cmd, nil, double, iota)
-}
-
-/*
-
-multiline */ /*
-multiline
-*/
-type AA int
-type BB struct {
-	AA
-}
-type CC struct {
-	AA int
-}
-type D func(aa AA) (BB error)
-type E func(AA) BB
-
-var a chan<- chan int
-var b chan<- <-chan int
-var c <-chan <-chan int
diff -urN a/gopls/internal/lsp/testdata/semantic/b.go.golden b/gopls/internal/lsp/testdata/semantic/b.go.golden
--- a/gopls/internal/lsp/testdata/semantic/b.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/semantic/b.go.golden	1969-12-31 16:00:00
@@ -1,40 +0,0 @@
--- semantic --
-/*⇒7,keyword,[]*/package /*⇒14,namespace,[]*/semantictokens /*⇒16,comment,[]*///@ semantic("")
-
-/*⇒4,keyword,[]*/func /*⇒1,function,[definition]*/f(/*⇒1,parameter,[definition]*/x /*⇒3,operator,[]*/.../*⇒9,keyword,[]*/interface{}) {
-}
-
-/*⇒4,keyword,[]*/func /*⇒6,function,[definition]*/weirⰀd() { /*⇒5,comment,[]*//*😀*/ /*⇒10,comment,[]*/// comment
-	/*⇒5,keyword,[]*/const (
-		/*⇒4,variable,[definition readonly]*/snil   = /*⇒3,variable,[readonly defaultLibrary]*/nil
-		/*⇒3,variable,[definition readonly]*/nil    = /*⇒4,variable,[readonly]*/true
-		/*⇒4,variable,[definition readonly]*/true   = /*⇒5,variable,[readonly]*/false
-		/*⇒5,variable,[definition readonly]*/false  = /*⇒4,variable,[readonly]*/snil
-		/*⇒3,variable,[definition readonly]*/cmd    = /*⇒6,string,[]*/`foof`
-		/*⇒6,variable,[definition readonly]*/double = /*⇒4,variable,[readonly]*/iota
-		/*⇒4,variable,[definition readonly]*/iota   = /*⇒4,function,[defaultLibrary]*/copy
-		/*⇒4,variable,[definition readonly]*/four   = (/*⇒3,function,[defaultLibrary]*/len(/*⇒3,variable,[readonly]*/cmd)/*⇒1,operator,[]*// /*⇒1,number,[]*/2 /*⇒1,operator,[]*/< /*⇒1,number,[]*/5)
-		/*⇒4,variable,[definition readonly]*/five   = /*⇒4,variable,[readonly]*/four
-	)
-	/*⇒1,function,[]*/f(/*⇒3,variable,[readonly]*/cmd, /*⇒3,variable,[readonly]*/nil, /*⇒6,variable,[readonly]*/double, /*⇒4,variable,[readonly]*/iota)
-}
-
-/*⇒2,comment,[]*//*
-/*⇒0,comment,[]*/
-/*⇒12,comment,[]*/multiline */ /*⇒2,comment,[]*//*
-/*⇒9,comment,[]*/multiline
-/*⇒2,comment,[]*/*/
-/*⇒4,keyword,[]*/type /*⇒2,type,[definition]*/AA /*⇒3,type,[defaultLibrary]*/int
-/*⇒4,keyword,[]*/type /*⇒2,type,[definition]*/BB /*⇒6,keyword,[]*/struct {
-	/*⇒2,type,[]*/AA
-}
-/*⇒4,keyword,[]*/type /*⇒2,type,[definition]*/CC /*⇒6,keyword,[]*/struct {
-	/*⇒2,variable,[definition]*/AA /*⇒3,type,[defaultLibrary]*/int
-}
-/*⇒4,keyword,[]*/type /*⇒1,type,[definition]*/D /*⇒4,keyword,[]*/func(/*⇒2,parameter,[definition]*/aa /*⇒2,type,[]*/AA) (/*⇒2,parameter,[definition]*/BB /*⇒5,type,[]*/error)
-/*⇒4,keyword,[]*/type /*⇒1,type,[definition]*/E /*⇒4,keyword,[]*/func(/*⇒2,type,[]*/AA) /*⇒2,type,[]*/BB
-
-/*⇒3,keyword,[]*/var /*⇒1,variable,[definition]*/a /*⇒4,keyword,[]*/chan/*⇒2,operator,[]*/<- /*⇒4,keyword,[]*/chan /*⇒3,type,[defaultLibrary]*/int
-/*⇒3,keyword,[]*/var /*⇒1,variable,[definition]*/b /*⇒4,keyword,[]*/chan/*⇒2,operator,[]*/<- /*⇒2,operator,[]*/<-/*⇒4,keyword,[]*/chan /*⇒3,type,[defaultLibrary]*/int
-/*⇒3,keyword,[]*/var /*⇒1,variable,[definition]*/c /*⇒2,operator,[]*/<-/*⇒4,keyword,[]*/chan /*⇒2,operator,[]*/<-/*⇒4,keyword,[]*/chan /*⇒3,type,[defaultLibrary]*/int
-
diff -urN a/gopls/internal/lsp/testdata/semantic/semantic_test.go b/gopls/internal/lsp/testdata/semantic/semantic_test.go
--- a/gopls/internal/lsp/testdata/semantic/semantic_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/semantic/semantic_test.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package semantictokens
-
-import (
-	"os"
-	"testing"
-)
-
-func TestSemanticTokens(t *testing.T) {
-	a, _ := os.Getwd()
-	// climb up to find internal/lsp
-	// find all the .go files
-
-}
diff -urN a/gopls/internal/lsp/testdata/signature/signature.go b/gopls/internal/lsp/testdata/signature/signature.go
--- a/gopls/internal/lsp/testdata/signature/signature.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature.go	1969-12-31 16:00:00
@@ -1,85 +0,0 @@
-// Package signature has tests for signature help.
-package signature
-
-import (
-	"bytes"
-	"encoding/json"
-	"math/big"
-)
-
-func Foo(a string, b int) (c bool) {
-	return
-}
-
-func Bar(float64, ...byte) {
-}
-
-type myStruct struct{}
-
-func (*myStruct) foo(e *json.Decoder) (*big.Int, error) {
-	return nil, nil
-}
-
-type MyType struct{}
-
-type MyFunc func(foo int) string
-
-type Alias = int
-type OtherAlias = int
-type StringAlias = string
-
-func AliasSlice(a []*Alias) (b Alias)                                 { return 0 }
-func AliasMap(a map[*Alias]StringAlias) (b, c map[*Alias]StringAlias) { return nil, nil }
-func OtherAliasMap(a, b map[Alias]OtherAlias) map[Alias]OtherAlias    { return nil }
-
-func Qux() {
-	Foo("foo", 123) //@signature("(", "Foo(a string, b int) (c bool)", 0)
-	Foo("foo", 123) //@signature("123", "Foo(a string, b int) (c bool)", 1)
-	Foo("foo", 123) //@signature(",", "Foo(a string, b int) (c bool)", 0)
-	Foo("foo", 123) //@signature(" 1", "Foo(a string, b int) (c bool)", 1)
-	Foo("foo", 123) //@signature(")", "Foo(a string, b int) (c bool)", 1)
-
-	Bar(13.37, 0x13)       //@signature("13.37", "Bar(float64, ...byte)", 0)
-	Bar(13.37, 0x37)       //@signature("0x37", "Bar(float64, ...byte)", 1)
-	Bar(13.37, 1, 2, 3, 4) //@signature("4", "Bar(float64, ...byte)", 1)
-
-	fn := func(hi, there string) func(i int) rune {
-		return func(int) rune { return 0 }
-	}
-
-	fn("hi", "there")    //@signature("hi", "", 0)
-	fn("hi", "there")    //@signature(",", "fn(hi string, there string) func(i int) rune", 0)
-	fn("hi", "there")(1) //@signature("1", "func(i int) rune", 0)
-
-	fnPtr := &fn
-	(*fnPtr)("hi", "there") //@signature(",", "func(hi string, there string) func(i int) rune", 0)
-
-	var fnIntf interface{} = Foo
-	fnIntf.(func(string, int) bool)("hi", 123) //@signature("123", "func(string, int) bool", 1)
-
-	(&bytes.Buffer{}).Next(2) //@signature("2", "Next(n int) []byte", 0)
-
-	myFunc := MyFunc(func(n int) string { return "" })
-	myFunc(123) //@signature("123", "myFunc(foo int) string", 0)
-
-	var ms myStruct
-	ms.foo(nil) //@signature("nil", "foo(e *json.Decoder) (*big.Int, error)", 0)
-
-	_ = make([]int, 1, 2) //@signature("2", "make(t Type, size ...int) Type", 1)
-
-	Foo(myFunc(123), 456) //@signature("myFunc", "Foo(a string, b int) (c bool)", 0)
-	Foo(myFunc(123), 456) //@signature("123", "myFunc(foo int) string", 0)
-
-	panic("oops!")            //@signature(")", "panic(v interface{})", 0)
-	println("hello", "world") //@signature(",", "println(args ...Type)", 0)
-
-	Hello(func() {
-		//@signature("//", "", 0)
-	})
-
-	AliasSlice()    //@signature(")", "AliasSlice(a []*Alias) (b Alias)", 0)
-	AliasMap()      //@signature(")", "AliasMap(a map[*Alias]StringAlias) (b map[*Alias]StringAlias, c map[*Alias]StringAlias)", 0)
-	OtherAliasMap() //@signature(")", "OtherAliasMap(a map[Alias]OtherAlias, b map[Alias]OtherAlias) map[Alias]OtherAlias", 0)
-}
-
-func Hello(func()) {}
diff -urN a/gopls/internal/lsp/testdata/signature/signature.go.golden b/gopls/internal/lsp/testdata/signature/signature.go.golden
--- a/gopls/internal/lsp/testdata/signature/signature.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature.go.golden	1969-12-31 16:00:00
@@ -1,53 +0,0 @@
--- AliasMap(a map[*Alias]StringAlias) (b map[*Alias]StringAlias, c map[*Alias]StringAlias)-signature --
-AliasMap(a map[*Alias]StringAlias) (b map[*Alias]StringAlias, c map[*Alias]StringAlias)
-
--- AliasSlice(a []*Alias) (b Alias)-signature --
-AliasSlice(a []*Alias) (b Alias)
-
--- Bar(float64, ...byte)-signature --
-Bar(float64, ...byte)
-
--- Foo(a string, b int) (c bool)-signature --
-Foo(a string, b int) (c bool)
-
--- Next(n int) []byte-signature --
-Next(n int) []byte
-
-Next returns a slice containing the next n bytes from the buffer, advancing the buffer as if the bytes had been returned by Read.
-
--- OtherAliasMap(a map[Alias]OtherAlias, b map[Alias]OtherAlias) map[Alias]OtherAlias-signature --
-OtherAliasMap(a map[Alias]OtherAlias, b map[Alias]OtherAlias) map[Alias]OtherAlias
-
--- fn(hi string, there string) func(i int) rune-signature --
-fn(hi string, there string) func(i int) rune
-
--- foo(e *json.Decoder) (*big.Int, error)-signature --
-foo(e *json.Decoder) (*big.Int, error)
-
--- func(hi string, there string) func(i int) rune-signature --
-func(hi string, there string) func(i int) rune
-
--- func(i int) rune-signature --
-func(i int) rune
-
--- func(string, int) bool-signature --
-func(string, int) bool
-
--- make(t Type, size ...int) Type-signature --
-make(t Type, size ...int) Type
-
-The make built-in function allocates and initializes an object of type slice, map, or chan (only).
-
--- myFunc(foo int) string-signature --
-myFunc(foo int) string
-
--- panic(v interface{})-signature --
-panic(v any)
-
-The panic built-in function stops normal execution of the current goroutine.
-
--- println(args ...Type)-signature --
-println(args ...Type)
-
-The println built-in function formats its arguments in an implementation-specific way and writes the result to standard error.
-
diff -urN a/gopls/internal/lsp/testdata/signature/signature2.go.golden b/gopls/internal/lsp/testdata/signature/signature2.go.golden
--- a/gopls/internal/lsp/testdata/signature/signature2.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature2.go.golden	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
--- Foo(a string, b int) (c bool)-signature --
-Foo(a string, b int) (c bool)
-
diff -urN a/gopls/internal/lsp/testdata/signature/signature2.go.in b/gopls/internal/lsp/testdata/signature/signature2.go.in
--- a/gopls/internal/lsp/testdata/signature/signature2.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature2.go.in	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package signature
-
-func _() {
-	Foo(//@signature("//", "Foo(a string, b int) (c bool)", 0)
-}
diff -urN a/gopls/internal/lsp/testdata/signature/signature3.go.golden b/gopls/internal/lsp/testdata/signature/signature3.go.golden
--- a/gopls/internal/lsp/testdata/signature/signature3.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature3.go.golden	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
--- Foo(a string, b int) (c bool)-signature --
-Foo(a string, b int) (c bool)
-
diff -urN a/gopls/internal/lsp/testdata/signature/signature3.go.in b/gopls/internal/lsp/testdata/signature/signature3.go.in
--- a/gopls/internal/lsp/testdata/signature/signature3.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature3.go.in	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package signature
-
-func _() {
-	Foo("hello",//@signature("//", "Foo(a string, b int) (c bool)", 1)
-}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/signature/signature_test.go b/gopls/internal/lsp/testdata/signature/signature_test.go
--- a/gopls/internal/lsp/testdata/signature/signature_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature_test.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package signature_test
-
-import (
-	"testing"
-
-	sig "golang.org/lsptests/signature"
-)
-
-func TestSignature(t *testing.T) {
-	sig.AliasSlice()    //@signature(")", "AliasSlice(a []*sig.Alias) (b sig.Alias)", 0)
-	sig.AliasMap()      //@signature(")", "AliasMap(a map[*sig.Alias]sig.StringAlias) (b map[*sig.Alias]sig.StringAlias, c map[*sig.Alias]sig.StringAlias)", 0)
-	sig.OtherAliasMap() //@signature(")", "OtherAliasMap(a map[sig.Alias]sig.OtherAlias, b map[sig.Alias]sig.OtherAlias) map[sig.Alias]sig.OtherAlias", 0)
-}
diff -urN a/gopls/internal/lsp/testdata/signature/signature_test.go.golden b/gopls/internal/lsp/testdata/signature/signature_test.go.golden
--- a/gopls/internal/lsp/testdata/signature/signature_test.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/signature/signature_test.go.golden	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
--- AliasMap(a map[*sig.Alias]sig.StringAlias) (b map[*sig.Alias]sig.StringAlias, c map[*sig.Alias]sig.StringAlias)-signature --
-AliasMap(a map[*sig.Alias]sig.StringAlias) (b map[*sig.Alias]sig.StringAlias, c map[*sig.Alias]sig.StringAlias)
-
--- AliasSlice(a []*sig.Alias) (b sig.Alias)-signature --
-AliasSlice(a []*sig.Alias) (b sig.Alias)
-
--- OtherAliasMap(a map[sig.Alias]sig.OtherAlias, b map[sig.Alias]sig.OtherAlias) map[sig.Alias]sig.OtherAlias-signature --
-OtherAliasMap(a map[sig.Alias]sig.OtherAlias, b map[sig.Alias]sig.OtherAlias) map[sig.Alias]sig.OtherAlias
-
diff -urN a/gopls/internal/lsp/testdata/snippets/func_snippets118.go.in b/gopls/internal/lsp/testdata/snippets/func_snippets118.go.in
--- a/gopls/internal/lsp/testdata/snippets/func_snippets118.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/func_snippets118.go.in	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
-// +build go1.18
-//go:build go1.18
-
-package snippets
-
-type SyncMap[K comparable, V any] struct{}
-
-func NewSyncMap[K comparable, V any]() (result *SyncMap[K, V]) { //@item(NewSyncMap, "NewSyncMap", "", "")
-	return
-}
-
-func Identity[P ~int](p P) P { //@item(Identity, "Identity", "", "")
-	return p
-}
-
-func _() {
-	_ = NewSyncM //@snippet(" //", NewSyncMap, "NewSyncMap[${1:}]()", "NewSyncMap[${1:K comparable}, ${2:V any}]()")
-	_ = Identi //@snippet(" //", Identity, "Identity[${1:}](${2:})", "Identity[${1:P ~int}](${2:p P})")
-}
diff -urN a/gopls/internal/lsp/testdata/snippets/literal.go b/gopls/internal/lsp/testdata/snippets/literal.go
--- a/gopls/internal/lsp/testdata/snippets/literal.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/literal.go	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
-package snippets
-
-import (
-	"golang.org/lsptests/signature"
-	t "golang.org/lsptests/types"
-)
-
-type structy struct {
-	x signature.MyType
-}
-
-func X(_ map[signature.Alias]t.CoolAlias) (map[signature.Alias]t.CoolAlias) {
-	return nil
-}
-
-func _() {
-	X() //@signature(")", "X(_ map[signature.Alias]t.CoolAlias) map[signature.Alias]t.CoolAlias", 0)
-	_ = signature.MyType{} //@item(literalMyType, "signature.MyType{}", "", "var")
-	s := structy{
-		x: //@snippet(" //", literalMyType, "signature.MyType{\\}", "signature.MyType{\\}")
-	}
-}
\ No newline at end of file
diff -urN a/gopls/internal/lsp/testdata/snippets/literal.go.golden b/gopls/internal/lsp/testdata/snippets/literal.go.golden
--- a/gopls/internal/lsp/testdata/snippets/literal.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/literal.go.golden	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
--- X(_ map[signature.Alias]t.CoolAlias) map[signature.Alias]t.CoolAlias-signature --
-X(_ map[signature.Alias]t.CoolAlias) map[signature.Alias]t.CoolAlias
-
diff -urN a/gopls/internal/lsp/testdata/snippets/literal_snippets.go.in b/gopls/internal/lsp/testdata/snippets/literal_snippets.go.in
--- a/gopls/internal/lsp/testdata/snippets/literal_snippets.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/literal_snippets.go.in	1969-12-31 16:00:00
@@ -1,233 +0,0 @@
-package snippets
-
-import (
-	"bytes"
-	"context"
-	"go/ast"
-	"net/http"
-	"sort"
-
-	"golang.org/lsptests/foo"
-)
-
-func _() {
-	[]int{}        //@item(litIntSlice, "[]int{}", "", "var")
-	&[]int{}       //@item(litIntSliceAddr, "&[]int{}", "", "var")
-	make([]int, 0) //@item(makeIntSlice, "make([]int, 0)", "", "func")
-
-	var _ *[]int = in //@snippet(" //", litIntSliceAddr, "&[]int{$0\\}", "&[]int{$0\\}")
-	var _ **[]int = in //@complete(" //")
-
-	var slice []int
-	slice = i //@snippet(" //", litIntSlice, "[]int{$0\\}", "[]int{$0\\}")
-	slice = m //@snippet(" //", makeIntSlice, "make([]int, ${1:})", "make([]int, ${1:0})")
-}
-
-func _() {
-	type namedInt []int
-
-	namedInt{}        //@item(litNamedSlice, "namedInt{}", "", "var")
-	make(namedInt, 0) //@item(makeNamedSlice, "make(namedInt, 0)", "", "func")
-
-	var namedSlice namedInt
-	namedSlice = n //@snippet(" //", litNamedSlice, "namedInt{$0\\}", "namedInt{$0\\}")
-	namedSlice = m //@snippet(" //", makeNamedSlice, "make(namedInt, ${1:})", "make(namedInt, ${1:0})")
-}
-
-func _() {
-	make(chan int) //@item(makeChan, "make(chan int)", "", "func")
-
-	var ch chan int
-	ch = m //@snippet(" //", makeChan, "make(chan int)", "make(chan int)")
-}
-
-func _() {
-	map[string]struct{}{}     //@item(litMap, "map[string]struct{}{}", "", "var")
-	make(map[string]struct{}) //@item(makeMap, "make(map[string]struct{})", "", "func")
-
-	var m map[string]struct{}
-	m = m //@snippet(" //", litMap, "map[string]struct{\\}{$0\\}", "map[string]struct{\\}{$0\\}")
-	m = m //@snippet(" //", makeMap, "make(map[string]struct{\\})", "make(map[string]struct{\\})")
-
-	struct{}{} //@item(litEmptyStruct, "struct{}{}", "", "var")
-
-	m["hi"] = s //@snippet(" //", litEmptyStruct, "struct{\\}{\\}", "struct{\\}{\\}")
-}
-
-func _() {
-	type myStruct struct{ i int } //@item(myStructType, "myStruct", "struct{...}", "struct")
-
-	myStruct{}  //@item(litStruct, "myStruct{}", "", "var")
-	&myStruct{} //@item(litStructPtr, "&myStruct{}", "", "var")
-
-	var ms myStruct
-	ms = m //@snippet(" //", litStruct, "myStruct{$0\\}", "myStruct{$0\\}")
-
-	var msPtr *myStruct
-	msPtr = m //@snippet(" //", litStructPtr, "&myStruct{$0\\}", "&myStruct{$0\\}")
-
-	msPtr = &m //@snippet(" //", litStruct, "myStruct{$0\\}", "myStruct{$0\\}")
-
-	type myStructCopy struct { i int } //@item(myStructCopyType, "myStructCopy", "struct{...}", "struct")
-
-	// Don't offer literal completion for convertible structs.
-	ms = myStruct //@complete(" //", litStruct, myStructType, myStructCopyType)
-}
-
-type myImpl struct{}
-
-func (myImpl) foo() {}
-
-func (*myImpl) bar() {}
-
-type myBasicImpl string
-
-func (myBasicImpl) foo() {}
-
-func _() {
-	type myIntf interface {
-		foo()
-	}
-
-	myImpl{} //@item(litImpl, "myImpl{}", "", "var")
-
-	var mi myIntf
-	mi = m //@snippet(" //", litImpl, "myImpl{\\}", "myImpl{\\}")
-
-	myBasicImpl() //@item(litBasicImpl, "myBasicImpl()", "string", "var")
-
-	mi = m //@snippet(" //", litBasicImpl, "myBasicImpl($0)", "myBasicImpl($0)")
-
-	// only satisfied by pointer to myImpl
-	type myPtrIntf interface {
-		bar()
-	}
-
-	&myImpl{} //@item(litImplPtr, "&myImpl{}", "", "var")
-
-	var mpi myPtrIntf
-	mpi = m //@snippet(" //", litImplPtr, "&myImpl{\\}", "&myImpl{\\}")
-}
-
-func _() {
-	var s struct{ i []int } //@item(litSliceField, "i", "[]int", "field")
-	var foo []int
-	// no literal completions after selector
-	foo = s.i //@complete(" //", litSliceField)
-}
-
-func _() {
-	type myStruct struct{ i int } //@item(litMyStructType, "myStruct", "struct{...}", "struct")
-	myStruct{} //@item(litMyStruct, "myStruct{}", "", "var")
-
-	foo := func(s string, args ...myStruct) {}
-	// Don't give literal slice candidate for variadic arg.
-	// Do give literal candidates for variadic element.
-	foo("", myStruct) //@complete(")", litMyStruct, litMyStructType)
-}
-
-func _() {
-	Buffer{} //@item(litBuffer, "Buffer{}", "", "var")
-
-	var b *bytes.Buffer
-	b = bytes.Bu //@snippet(" //", litBuffer, "Buffer{\\}", "Buffer{\\}")
-}
-
-func _() {
-	_ = "func(...) {}" //@item(litFunc, "func(...) {}", "", "var")
-
-	sort.Slice(nil, fun) //@complete(")", litFunc),snippet(")", litFunc, "func(i, j int) bool {$0\\}", "func(i, j int) bool {$0\\}")
-
-	http.HandleFunc("", f) //@snippet(")", litFunc, "func(w http.ResponseWriter, r *http.Request) {$0\\}", "func(${1:w} http.ResponseWriter, ${2:r} *http.Request) {$0\\}")
-
-	// no literal "func" completions
-	http.Handle("", fun) //@complete(")")
-
-	http.HandlerFunc() //@item(handlerFunc, "http.HandlerFunc()", "", "var")
-	http.Handle("", h) //@snippet(")", handlerFunc, "http.HandlerFunc($0)", "http.HandlerFunc($0)")
-	http.Handle("", http.HandlerFunc()) //@snippet("))", litFunc, "func(w http.ResponseWriter, r *http.Request) {$0\\}", "func(${1:w} http.ResponseWriter, ${2:r} *http.Request) {$0\\}")
-
-	var namedReturn func(s string) (b bool)
-	namedReturn = f //@snippet(" //", litFunc, "func(s string) (b bool) {$0\\}", "func(s string) (b bool) {$0\\}")
-
-	var multiReturn func() (bool, int)
-	multiReturn = f //@snippet(" //", litFunc, "func() (bool, int) {$0\\}", "func() (bool, int) {$0\\}")
-
-	var multiNamedReturn func() (b bool, i int)
-	multiNamedReturn = f //@snippet(" //", litFunc, "func() (b bool, i int) {$0\\}", "func() (b bool, i int) {$0\\}")
-
-	var duplicateParams func(myImpl, int, myImpl)
-	duplicateParams = f //@snippet(" //", litFunc, "func(mi1 myImpl, i int, mi2 myImpl) {$0\\}", "func(${1:mi1} myImpl, ${2:i} int, ${3:mi2} myImpl) {$0\\}")
-
-	type aliasImpl = myImpl
-	var aliasParams func(aliasImpl) aliasImpl
-	aliasParams = f //@snippet(" //", litFunc, "func(ai aliasImpl) aliasImpl {$0\\}", "func(${1:ai} aliasImpl) aliasImpl {$0\\}")
-
-	const two = 2
-	var builtinTypes func([]int, [two]bool, map[string]string, struct{ i int }, interface{ foo() }, <-chan int)
-	builtinTypes = f //@snippet(" //", litFunc, "func(i1 []int, b [two]bool, m map[string]string, s struct{ i int \\}, i2 interface{ foo() \\}, c <-chan int) {$0\\}", "func(${1:i1} []int, ${2:b} [two]bool, ${3:m} map[string]string, ${4:s} struct{ i int \\}, ${5:i2} interface{ foo() \\}, ${6:c} <-chan int) {$0\\}")
-
-	var _ func(ast.Node) = f //@snippet(" //", litFunc, "func(n ast.Node) {$0\\}", "func(${1:n} ast.Node) {$0\\}")
-	var _ func(error) = f //@snippet(" //", litFunc, "func(err error) {$0\\}", "func(${1:err} error) {$0\\}")
-	var _ func(context.Context) = f //@snippet(" //", litFunc, "func(ctx context.Context) {$0\\}", "func(${1:ctx} context.Context) {$0\\}")
-
-	type context struct {}
-	var _ func(context) = f //@snippet(" //", litFunc, "func(ctx context) {$0\\}", "func(${1:ctx} context) {$0\\}")
-}
-
-func _() {
-	StructFoo{} //@item(litStructFoo, "StructFoo{}", "struct{...}", "struct")
-
-	var sfp *foo.StructFoo
-	// Don't insert the "&" before "StructFoo{}".
-	sfp = foo.Str //@snippet(" //", litStructFoo, "StructFoo{$0\\}", "StructFoo{$0\\}")
-
-	var sf foo.StructFoo
-	sf = foo.Str //@snippet(" //", litStructFoo, "StructFoo{$0\\}", "StructFoo{$0\\}")
-	sf = foo. //@snippet(" //", litStructFoo, "StructFoo{$0\\}", "StructFoo{$0\\}")
-}
-
-func _() {
-	float64() //@item(litFloat64, "float64()", "float64", "var")
-
-	// don't complete to "&float64()"
-	var _ *float64 = float64 //@complete(" //")
-
-	var f float64
-	f = fl //@complete(" //", litFloat64),snippet(" //", litFloat64, "float64($0)", "float64($0)")
-
-	type myInt int
-	myInt() //@item(litMyInt, "myInt()", "", "var")
-
-	var mi myInt
-	mi = my //@snippet(" //", litMyInt, "myInt($0)", "myInt($0)")
-}
-
-func _() {
-	type ptrStruct struct {
-		p *ptrStruct
-	}
-
-	ptrStruct{} //@item(litPtrStruct, "ptrStruct{}", "", "var")
-
-	ptrStruct{
-		p: &ptrSt, //@rank(",", litPtrStruct)
-	}
-
-	&ptrStruct{} //@item(litPtrStructPtr, "&ptrStruct{}", "", "var")
-
-	&ptrStruct{
-		p: ptrSt, //@rank(",", litPtrStructPtr)
-	}
-}
-
-func _() {
-	f := func(...[]int) {}
-	f() //@snippet(")", litIntSlice, "[]int{$0\\}", "[]int{$0\\}")
-}
-
-
-func _() {
-	// don't complete to "untyped int()"
-	[]int{}[untyped] //@complete("] //")
-}
diff -urN a/gopls/internal/lsp/testdata/snippets/literal_snippets118.go.in b/gopls/internal/lsp/testdata/snippets/literal_snippets118.go.in
--- a/gopls/internal/lsp/testdata/snippets/literal_snippets118.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/literal_snippets118.go.in	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-// +build go1.18
-//go:build go1.18
-
-package snippets
-
-type Tree[T any] struct{}
-
-func (tree Tree[T]) Do(f func(s T)) {}
-
-func _() {
-    _ = "func(...) {}" //@item(litFunc, "func(...) {}", "", "var")
-	var t Tree[string]
-	t.Do(fun) //@complete(")", litFunc),snippet(")", litFunc, "func(s string) {$0\\}", "func(s string) {$0\\}")
-}
diff -urN a/gopls/internal/lsp/testdata/snippets/postfix.go b/gopls/internal/lsp/testdata/snippets/postfix.go
--- a/gopls/internal/lsp/testdata/snippets/postfix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/postfix.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-package snippets
-
-// These tests check that postfix completions do and do not show up in
-// certain cases. Tests for the postfix completion contents are under
-// regtest.
-
-func _() {
-	/* append! */ //@item(postfixAppend, "append!", "append and re-assign slice", "snippet")
-	var foo []int
-	foo.append //@rank(" //", postfixAppend)
-
-	[]int{}.append //@complete(" //")
-
-	[]int{}.last //@complete(" //")
-
-	/* copy! */ //@item(postfixCopy, "copy!", "duplicate slice", "snippet")
-
-	foo.copy //@rank(" //", postfixCopy)
-
-	var s struct{ i []int }
-	s.i.copy //@rank(" //", postfixCopy)
-
-	var _ []int = s.i.copy //@complete(" //")
-
-	var blah func() []int
-	blah().append //@complete(" //")
-}
-
-func _() {
-	/* append! */ //@item(postfixAppend, "append!", "append and re-assign slice", "snippet")
-	/* last! */ //@item(postfixLast, "last!", "s[len(s)-1]", "snippet")
-	/* print! */ //@item(postfixPrint, "print!", "print to stdout", "snippet")
-	/* range! */ //@item(postfixRange, "range!", "range over slice", "snippet")
-	/* reverse! */ //@item(postfixReverse, "reverse!", "reverse slice", "snippet")
-	/* sort! */ //@item(postfixSort, "sort!", "sort.Slice()", "snippet")
-	/* var! */ //@item(postfixVar, "var!", "assign to variable", "snippet")
-
-	var foo []int
-	foo. //@complete(" //", postfixAppend, postfixCopy, postfixLast, postfixPrint, postfixRange, postfixReverse, postfixSort, postfixVar)
-
-		foo = nil
-}
diff -urN a/gopls/internal/lsp/testdata/snippets/snippets.go.golden b/gopls/internal/lsp/testdata/snippets/snippets.go.golden
--- a/gopls/internal/lsp/testdata/snippets/snippets.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/snippets.go.golden	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
--- baz(at AliasType, b bool)-signature --
-baz(at AliasType, b bool)
-
diff -urN a/gopls/internal/lsp/testdata/snippets/snippets.go.in b/gopls/internal/lsp/testdata/snippets/snippets.go.in
--- a/gopls/internal/lsp/testdata/snippets/snippets.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/snippets/snippets.go.in	1969-12-31 16:00:00
@@ -1,61 +0,0 @@
-package snippets
-
-type AliasType = int //@item(sigAliasType, "AliasType", "AliasType", "type")
-
-func foo(i int, b bool) {} //@item(snipFoo, "foo", "func(i int, b bool)", "func")
-func bar(fn func()) func()    {} //@item(snipBar, "bar", "func(fn func())", "func")
-func baz(at AliasType, b bool) {} //@item(snipBaz, "baz", "func(at AliasType, b bool)", "func")
-
-type Foo struct {
-	Bar int //@item(snipFieldBar, "Bar", "int", "field")
-	Func func(at AliasType) error //@item(snipFieldFunc, "Func", "func(at AliasType) error", "field")
-}
-
-func (Foo) Baz() func() {} //@item(snipMethodBaz, "Baz", "func() func()", "method")
-func (Foo) BazBar() func() {} //@item(snipMethodBazBar, "BazBar", "func() func()", "method")
-func (Foo) BazBaz(at AliasType) func() {} //@item(snipMethodBazBaz, "BazBaz", "func(at AliasType) func()", "method")
-
-func _() {
-	f //@snippet(" //", snipFoo, "foo(${1:})", "foo(${1:i int}, ${2:b bool})")
-
-	bar //@snippet(" //", snipBar, "bar(${1:})", "bar(${1:fn func()})")
-
-	baz //@snippet(" //", snipBaz, "baz(${1:})", "baz(${1:at AliasType}, ${2:b bool})")
-	baz() //@signature("(", "baz(at AliasType, b bool)", 0)
-
-	bar(nil) //@snippet("(", snipBar, "bar", "bar")
-	bar(ba) //@snippet(")", snipBar, "bar(${1:})", "bar(${1:fn func()})")
-	var f Foo
-	bar(f.Ba) //@snippet(")", snipMethodBaz, "Baz()", "Baz()")
-	(bar)(nil) //@snippet(")", snipBar, "bar(${1:})", "bar(${1:fn func()})")
-	(f.Ba)() //@snippet(")", snipMethodBaz, "Baz()", "Baz()")
-
-	Foo{
-		B //@snippet(" //", snipFieldBar, "Bar: ${1:},", "Bar: ${1:int},")
-	}
-
-	Foo{
-		F //@snippet(" //", snipFieldFunc, "Func: ${1:},", "Func: ${1:func(at AliasType) error},")
-	}
-
-	Foo{B} //@snippet("}", snipFieldBar, "Bar: ${1:}", "Bar: ${1:int}")
-	Foo{} //@snippet("}", snipFieldBar, "Bar: ${1:}", "Bar: ${1:int}")
-
-	Foo{Foo{}.B} //@snippet("} ", snipFieldBar, "Bar", "Bar")
-
-	var err error
-	err.Error() //@snippet("E", Error, "Error()", "Error()")
-	f.Baz()     //@snippet("B", snipMethodBaz, "Baz()", "Baz()")
-
-	f.Baz()     //@snippet("(", snipMethodBazBar, "BazBar", "BazBar")
-
-	f.Baz()     //@snippet("B", snipMethodBazBaz, "BazBaz(${1:})", "BazBaz(${1:at AliasType})")
-}
-
-func _() {
-	type bar struct {
-		a int
-		b float64 //@item(snipBarB, "b", "float64", "field")
-	}
-	bar{b} //@snippet("}", snipBarB, "b: ${1:}", "b: ${1:float64}")
-}
diff -urN a/gopls/internal/lsp/testdata/statements/append.go b/gopls/internal/lsp/testdata/statements/append.go
--- a/gopls/internal/lsp/testdata/statements/append.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/statements/append.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-package statements
-
-func _() {
-	type mySlice []int
-
-	var (
-		abc    []int   //@item(stmtABC, "abc", "[]int", "var")
-		abcdef mySlice //@item(stmtABCDEF, "abcdef", "mySlice", "var")
-	)
-
-	/* abcdef = append(abcdef, ) */ //@item(stmtABCDEFAssignAppend, "abcdef = append(abcdef, )", "", "func")
-
-	// don't offer "abc = append(abc, )" because "abc" isn't necessarily
-	// better than "abcdef".
-	abc //@complete(" //", stmtABC, stmtABCDEF)
-
-	abcdef //@complete(" //", stmtABCDEF, stmtABCDEFAssignAppend)
-
-	/* append(abc, ) */ //@item(stmtABCAppend, "append(abc, )", "", "func")
-
-	abc = app //@snippet(" //", stmtABCAppend, "append(abc, ${1:})", "append(abc, ${1:})")
-}
-
-func _() {
-	var s struct{ xyz []int }
-
-	/* xyz = append(s.xyz, ) */ //@item(stmtXYZAppend, "xyz = append(s.xyz, )", "", "func")
-
-	s.x //@snippet(" //", stmtXYZAppend, "xyz = append(s.xyz, ${1:})", "xyz = append(s.xyz, ${1:})")
-
-	/* s.xyz = append(s.xyz, ) */ //@item(stmtDeepXYZAppend, "s.xyz = append(s.xyz, )", "", "func")
-
-	sx //@snippet(" //", stmtDeepXYZAppend, "s.xyz = append(s.xyz, ${1:})", "s.xyz = append(s.xyz, ${1:})")
-}
-
-func _() {
-	var foo [][]int
-
-	/* append(foo[0], ) */ //@item(stmtFooAppend, "append(foo[0], )", "", "func")
-
-	foo[0] = app //@complete(" //"),snippet(" //", stmtFooAppend, "append(foo[0], ${1:})", "append(foo[0], ${1:})")
-}
diff -urN a/gopls/internal/lsp/testdata/statements/if_err_check_return.go b/gopls/internal/lsp/testdata/statements/if_err_check_return.go
--- a/gopls/internal/lsp/testdata/statements/if_err_check_return.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/statements/if_err_check_return.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package statements
-
-import (
-	"bytes"
-	"io"
-	"os"
-)
-
-func one() (int, float32, io.Writer, *int, []int, bytes.Buffer, error) {
-	/* if err != nil { return err } */ //@item(stmtOneIfErrReturn, "if err != nil { return err }", "", "")
-	/* err != nil { return err } */ //@item(stmtOneErrReturn, "err != nil { return err }", "", "")
-
-	_, err := os.Open("foo")
-	//@snippet("", stmtOneIfErrReturn, "", "if err != nil {\n\treturn 0, 0, nil, nil, nil, bytes.Buffer{\\}, ${1:err}\n\\}")
-
-	_, err = os.Open("foo")
-	i //@snippet(" //", stmtOneIfErrReturn, "", "if err != nil {\n\treturn 0, 0, nil, nil, nil, bytes.Buffer{\\}, ${1:err}\n\\}")
-
-	_, err = os.Open("foo")
-	if er //@snippet(" //", stmtOneErrReturn, "", "err != nil {\n\treturn 0, 0, nil, nil, nil, bytes.Buffer{\\}, ${1:err}\n\\}")
-
-	_, err = os.Open("foo")
-	if //@snippet(" //", stmtOneIfErrReturn, "", "if err != nil {\n\treturn 0, 0, nil, nil, nil, bytes.Buffer{\\}, ${1:err}\n\\}")
-
-	_, err = os.Open("foo")
-	if //@snippet("//", stmtOneIfErrReturn, "", "if err != nil {\n\treturn 0, 0, nil, nil, nil, bytes.Buffer{\\}, ${1:err}\n\\}")
-}
diff -urN a/gopls/internal/lsp/testdata/statements/if_err_check_return_2.go b/gopls/internal/lsp/testdata/statements/if_err_check_return_2.go
--- a/gopls/internal/lsp/testdata/statements/if_err_check_return_2.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/statements/if_err_check_return_2.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package statements
-
-import "os"
-
-func two() error {
-	var s struct{ err error }
-
-	/* if s.err != nil { return s.err } */ //@item(stmtTwoIfErrReturn, "if s.err != nil { return s.err }", "", "")
-
-	_, s.err = os.Open("foo")
-	//@snippet("", stmtTwoIfErrReturn, "", "if s.err != nil {\n\treturn ${1:s.err}\n\\}")
-}
diff -urN a/gopls/internal/lsp/testdata/statements/if_err_check_test.go b/gopls/internal/lsp/testdata/statements/if_err_check_test.go
--- a/gopls/internal/lsp/testdata/statements/if_err_check_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/statements/if_err_check_test.go	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-package statements
-
-import (
-	"os"
-	"testing"
-)
-
-func TestErr(t *testing.T) {
-	/* if err != nil { t.Fatal(err) } */ //@item(stmtOneIfErrTFatal, "if err != nil { t.Fatal(err) }", "", "")
-
-	_, err := os.Open("foo")
-	//@snippet("", stmtOneIfErrTFatal, "", "if err != nil {\n\tt.Fatal(err)\n\\}")
-}
-
-func BenchmarkErr(b *testing.B) {
-	/* if err != nil { b.Fatal(err) } */ //@item(stmtOneIfErrBFatal, "if err != nil { b.Fatal(err) }", "", "")
-
-	_, err := os.Open("foo")
-	//@snippet("", stmtOneIfErrBFatal, "", "if err != nil {\n\tb.Fatal(err)\n\\}")
-}
diff -urN a/gopls/internal/lsp/testdata/stub/other/other.go b/gopls/internal/lsp/testdata/stub/other/other.go
--- a/gopls/internal/lsp/testdata/stub/other/other.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/other/other.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package other
-
-import (
-	"bytes"
-	renamed_context "context"
-)
-
-type Interface interface {
-	Get(renamed_context.Context) *bytes.Buffer
-}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_add_selector.go b/gopls/internal/lsp/testdata/stub/stub_add_selector.go
--- a/gopls/internal/lsp/testdata/stub/stub_add_selector.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_add_selector.go	1969-12-31 16:00:00
@@ -1,12 +0,0 @@
-package stub
-
-import "io"
-
-// This file tests that if an interface
-// method references a type from its own package
-// then our implementation must add the import/package selector
-// in the concrete method if the concrete type is outside of the interface
-// package
-var _ io.ReaderFrom = &readerFrom{} //@suggestedfix("&readerFrom", "refactor.rewrite", "")
-
-type readerFrom struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_add_selector.go.golden b/gopls/internal/lsp/testdata/stub/stub_add_selector.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_add_selector.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_add_selector.go.golden	1969-12-31 16:00:00
@@ -1,19 +0,0 @@
--- suggestedfix_stub_add_selector_10_23 --
-package stub
-
-import "io"
-
-// This file tests that if an interface
-// method references a type from its own package
-// then our implementation must add the import/package selector
-// in the concrete method if the concrete type is outside of the interface
-// package
-var _ io.ReaderFrom = &readerFrom{} //@suggestedfix("&readerFrom", "refactor.rewrite", "")
-
-type readerFrom struct{}
-
-// ReadFrom implements io.ReaderFrom
-func (*readerFrom) ReadFrom(r io.Reader) (n int64, err error) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_assign.go b/gopls/internal/lsp/testdata/stub/stub_assign.go
--- a/gopls/internal/lsp/testdata/stub/stub_assign.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_assign.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package stub
-
-import "io"
-
-func main() {
-	var br io.ByteWriter
-	br = &byteWriter{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type byteWriter struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_assign.go.golden b/gopls/internal/lsp/testdata/stub/stub_assign.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_assign.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_assign.go.golden	1969-12-31 16:00:00
@@ -1,17 +0,0 @@
--- suggestedfix_stub_assign_7_7 --
-package stub
-
-import "io"
-
-func main() {
-	var br io.ByteWriter
-	br = &byteWriter{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type byteWriter struct{}
-
-// WriteByte implements io.ByteWriter
-func (*byteWriter) WriteByte(c byte) error {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go b/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go
--- a/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package stub
-
-import "io"
-
-func main() {
-	var br io.ByteWriter
-	var i int
-	i, br = 1, &multiByteWriter{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type multiByteWriter struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go.golden b/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_assign_multivars.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- suggestedfix_stub_assign_multivars_8_13 --
-package stub
-
-import "io"
-
-func main() {
-	var br io.ByteWriter
-	var i int
-	i, br = 1, &multiByteWriter{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type multiByteWriter struct{}
-
-// WriteByte implements io.ByteWriter
-func (*multiByteWriter) WriteByte(c byte) error {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_call_expr.go b/gopls/internal/lsp/testdata/stub/stub_call_expr.go
--- a/gopls/internal/lsp/testdata/stub/stub_call_expr.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_call_expr.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package stub
-
-func main() {
-	check(&callExpr{}) //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-func check(err error) {
-	if err != nil {
-		panic(err)
-	}
-}
-
-type callExpr struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_call_expr.go.golden b/gopls/internal/lsp/testdata/stub/stub_call_expr.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_call_expr.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_call_expr.go.golden	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
--- suggestedfix_stub_call_expr_4_8 --
-package stub
-
-func main() {
-	check(&callExpr{}) //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-func check(err error) {
-	if err != nil {
-		panic(err)
-	}
-}
-
-type callExpr struct{}
-
-// Error implements error
-func (*callExpr) Error() string {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_embedded.go b/gopls/internal/lsp/testdata/stub/stub_embedded.go
--- a/gopls/internal/lsp/testdata/stub/stub_embedded.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_embedded.go	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-package stub
-
-import (
-	"io"
-	"sort"
-)
-
-var _ embeddedInterface = (*embeddedConcrete)(nil) //@suggestedfix("(", "refactor.rewrite", "")
-
-type embeddedConcrete struct{}
-
-type embeddedInterface interface {
-	sort.Interface
-	io.Reader
-}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_embedded.go.golden b/gopls/internal/lsp/testdata/stub/stub_embedded.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_embedded.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_embedded.go.golden	1969-12-31 16:00:00
@@ -1,37 +0,0 @@
--- suggestedfix_stub_embedded_8_27 --
-package stub
-
-import (
-	"io"
-	"sort"
-)
-
-var _ embeddedInterface = (*embeddedConcrete)(nil) //@suggestedfix("(", "refactor.rewrite", "")
-
-type embeddedConcrete struct{}
-
-// Len implements embeddedInterface
-func (*embeddedConcrete) Len() int {
-	panic("unimplemented")
-}
-
-// Less implements embeddedInterface
-func (*embeddedConcrete) Less(i int, j int) bool {
-	panic("unimplemented")
-}
-
-// Swap implements embeddedInterface
-func (*embeddedConcrete) Swap(i int, j int) {
-	panic("unimplemented")
-}
-
-// Read implements embeddedInterface
-func (*embeddedConcrete) Read(p []byte) (n int, err error) {
-	panic("unimplemented")
-}
-
-type embeddedInterface interface {
-	sort.Interface
-	io.Reader
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_err.go b/gopls/internal/lsp/testdata/stub/stub_err.go
--- a/gopls/internal/lsp/testdata/stub/stub_err.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_err.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package stub
-
-func main() {
-	var br error = &customErr{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type customErr struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_err.go.golden b/gopls/internal/lsp/testdata/stub/stub_err.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_err.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_err.go.golden	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
--- suggestedfix_stub_err_4_17 --
-package stub
-
-func main() {
-	var br error = &customErr{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type customErr struct{}
-
-// Error implements error
-func (*customErr) Error() string {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_function_return.go b/gopls/internal/lsp/testdata/stub/stub_function_return.go
--- a/gopls/internal/lsp/testdata/stub/stub_function_return.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_function_return.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package stub
-
-import (
-	"io"
-)
-
-func newCloser() io.Closer {
-	return closer{} //@suggestedfix("c", "refactor.rewrite", "")
-}
-
-type closer struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_function_return.go.golden b/gopls/internal/lsp/testdata/stub/stub_function_return.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_function_return.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_function_return.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- suggestedfix_stub_function_return_8_9 --
-package stub
-
-import (
-	"io"
-)
-
-func newCloser() io.Closer {
-	return closer{} //@suggestedfix("c", "refactor.rewrite", "")
-}
-
-type closer struct{}
-
-// Close implements io.Closer
-func (closer) Close() error {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go b/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go
--- a/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package stub
-
-import "io"
-
-// This file tests that that the stub method generator accounts for concrete
-// types that have type parameters defined.
-var _ io.ReaderFrom = &genReader[string, int]{} //@suggestedfix("&genReader", "refactor.rewrite", "Implement io.ReaderFrom")
-
-type genReader[T, Y any] struct {
-	T T
-	Y Y
-}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go.golden b/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_generic_receiver.go.golden	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
--- suggestedfix_stub_generic_receiver_10_23 --
-//go:build go1.18
-// +build go1.18
-
-package stub
-
-import "io"
-
-// This file tests that that the stub method generator accounts for concrete
-// types that have type parameters defined.
-var _ io.ReaderFrom = &genReader[string, int]{} //@suggestedfix("&genReader", "refactor.rewrite", "Implement io.ReaderFrom")
-
-type genReader[T, Y any] struct {
-	T T
-	Y Y
-}
-
-// ReadFrom implements io.ReaderFrom
-func (*genReader[T, Y]) ReadFrom(r io.Reader) (n int64, err error) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go b/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go
--- a/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-package stub
-
-import (
-	"compress/zlib"
-	. "io"
-	_ "io"
-)
-
-// This file tests that dot-imports and underscore imports
-// are properly ignored and that a new import is added to
-// reference method types
-
-var (
-	_ Reader
-	_ zlib.Resetter = (*ignoredResetter)(nil) //@suggestedfix("(", "refactor.rewrite", "")
-)
-
-type ignoredResetter struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go.golden b/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_ignored_imports.go.golden	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
--- suggestedfix_stub_ignored_imports_15_20 --
-package stub
-
-import (
-	"compress/zlib"
-	"io"
-	. "io"
-	_ "io"
-)
-
-// This file tests that dot-imports and underscore imports
-// are properly ignored and that a new import is added to
-// reference method types
-
-var (
-	_ Reader
-	_ zlib.Resetter = (*ignoredResetter)(nil) //@suggestedfix("(", "refactor.rewrite", "")
-)
-
-type ignoredResetter struct{}
-
-// Reset implements zlib.Resetter
-func (*ignoredResetter) Reset(r io.Reader, dict []byte) error {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_multi_var.go b/gopls/internal/lsp/testdata/stub/stub_multi_var.go
--- a/gopls/internal/lsp/testdata/stub/stub_multi_var.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_multi_var.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package stub
-
-import "io"
-
-// This test ensures that a variable declaration that
-// has multiple values on the same line can still be
-// analyzed correctly to target the interface implementation
-// diagnostic.
-var one, two, three io.Reader = nil, &multiVar{}, nil //@suggestedfix("&", "refactor.rewrite", "")
-
-type multiVar struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_multi_var.go.golden b/gopls/internal/lsp/testdata/stub/stub_multi_var.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_multi_var.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_multi_var.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- suggestedfix_stub_multi_var_9_38 --
-package stub
-
-import "io"
-
-// This test ensures that a variable declaration that
-// has multiple values on the same line can still be
-// analyzed correctly to target the interface implementation
-// diagnostic.
-var one, two, three io.Reader = nil, &multiVar{}, nil //@suggestedfix("&", "refactor.rewrite", "")
-
-type multiVar struct{}
-
-// Read implements io.Reader
-func (*multiVar) Read(p []byte) (n int, err error) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_pointer.go b/gopls/internal/lsp/testdata/stub/stub_pointer.go
--- a/gopls/internal/lsp/testdata/stub/stub_pointer.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_pointer.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package stub
-
-import "io"
-
-func getReaderFrom() io.ReaderFrom {
-	return &pointerImpl{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type pointerImpl struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_pointer.go.golden b/gopls/internal/lsp/testdata/stub/stub_pointer.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_pointer.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_pointer.go.golden	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
--- suggestedfix_stub_pointer_6_9 --
-package stub
-
-import "io"
-
-func getReaderFrom() io.ReaderFrom {
-	return &pointerImpl{} //@suggestedfix("&", "refactor.rewrite", "")
-}
-
-type pointerImpl struct{}
-
-// ReadFrom implements io.ReaderFrom
-func (*pointerImpl) ReadFrom(r io.Reader) (n int64, err error) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_renamed_import.go b/gopls/internal/lsp/testdata/stub/stub_renamed_import.go
--- a/gopls/internal/lsp/testdata/stub/stub_renamed_import.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_renamed_import.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package stub
-
-import (
-	"compress/zlib"
-	myio "io"
-)
-
-var _ zlib.Resetter = &myIO{} //@suggestedfix("&", "refactor.rewrite", "")
-var _ myio.Reader
-
-type myIO struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_renamed_import.go.golden b/gopls/internal/lsp/testdata/stub/stub_renamed_import.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_renamed_import.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_renamed_import.go.golden	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
--- suggestedfix_stub_renamed_import_8_23 --
-package stub
-
-import (
-	"compress/zlib"
-	myio "io"
-)
-
-var _ zlib.Resetter = &myIO{} //@suggestedfix("&", "refactor.rewrite", "")
-var _ myio.Reader
-
-type myIO struct{}
-
-// Reset implements zlib.Resetter
-func (*myIO) Reset(r myio.Reader, dict []byte) error {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go b/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go
--- a/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package stub
-
-import (
-	"golang.org/lsptests/stub/other"
-)
-
-// This file tests that if an interface
-// method references an import from its own package
-// that the concrete type does not yet import, and that import happens
-// to be renamed, then we prefer the renaming of the interface.
-var _ other.Interface = &otherInterfaceImpl{} //@suggestedfix("&otherInterfaceImpl", "refactor.rewrite", "")
-
-type otherInterfaceImpl struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go.golden b/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_renamed_import_iface.go.golden	1969-12-31 16:00:00
@@ -1,22 +0,0 @@
--- suggestedfix_stub_renamed_import_iface_11_25 --
-package stub
-
-import (
-	"bytes"
-	renamed_context "context"
-	"golang.org/lsptests/stub/other"
-)
-
-// This file tests that if an interface
-// method references an import from its own package
-// that the concrete type does not yet import, and that import happens
-// to be renamed, then we prefer the renaming of the interface.
-var _ other.Interface = &otherInterfaceImpl{} //@suggestedfix("&otherInterfaceImpl", "refactor.rewrite", "")
-
-type otherInterfaceImpl struct{}
-
-// Get implements other.Interface
-func (*otherInterfaceImpl) Get(renamed_context.Context) *bytes.Buffer {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_stdlib.go b/gopls/internal/lsp/testdata/stub/stub_stdlib.go
--- a/gopls/internal/lsp/testdata/stub/stub_stdlib.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_stdlib.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package stub
-
-import (
-	"io"
-)
-
-var _ io.Writer = writer{} //@suggestedfix("w", "refactor.rewrite", "")
-
-type writer struct{}
diff -urN a/gopls/internal/lsp/testdata/stub/stub_stdlib.go.golden b/gopls/internal/lsp/testdata/stub/stub_stdlib.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_stdlib.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_stdlib.go.golden	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
--- suggestedfix_stub_stdlib_7_19 --
-package stub
-
-import (
-	"io"
-)
-
-var _ io.Writer = writer{} //@suggestedfix("w", "refactor.rewrite", "")
-
-type writer struct{}
-
-// Write implements io.Writer
-func (writer) Write(p []byte) (n int, err error) {
-	panic("unimplemented")
-}
-
diff -urN a/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go b/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go
--- a/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-package stub
-
-// Regression test for Issue #56825: file corrupted by insertion of
-// methods after TypeSpec in a parenthesized TypeDecl.
-
-import "io"
-
-func newReadCloser() io.ReadCloser {
-	return rdcloser{} //@suggestedfix("rd", "refactor.rewrite", "")
-}
-
-type (
-	A        int
-	rdcloser struct{}
-	B        int
-)
-
-func _() {
-	// Local types can't be stubbed as there's nowhere to put the methods.
-	// The suggestedfix assertion can't express this yet. TODO(adonovan): support it.
-	type local struct{}
-	var _ io.ReadCloser = local{} // want error: `local type "local" cannot be stubbed`
-}
-
-type (
-	C int
-)
diff -urN a/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go.golden b/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go.golden
--- a/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/stub/stub_typedecl_group.go.golden	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
--- suggestedfix_stub_typedecl_group_9_9 --
-package stub
-
-// Regression test for Issue #56825: file corrupted by insertion of
-// methods after TypeSpec in a parenthesized TypeDecl.
-
-import "io"
-
-func newReadCloser() io.ReadCloser {
-	return rdcloser{} //@suggestedfix("rd", "refactor.rewrite", "")
-}
-
-type (
-	A        int
-	rdcloser struct{}
-	B        int
-)
-
-// Close implements io.ReadCloser
-func (rdcloser) Close() error {
-	panic("unimplemented")
-}
-
-// Read implements io.ReadCloser
-func (rdcloser) Read(p []byte) (n int, err error) {
-	panic("unimplemented")
-}
-
-func _() {
-	// Local types can't be stubbed as there's nowhere to put the methods.
-	// The suggestedfix assertion can't express this yet. TODO(adonovan): support it.
-	type local struct{}
-	var _ io.ReadCloser = local{} // want error: `local type "local" cannot be stubbed`
-}
-
-type (
-	C int
-)
-
diff -urN a/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go b/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go
--- a/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go	1969-12-31 16:00:00
@@ -1,11 +0,0 @@
-package suggestedfix
-
-import (
-	"log"
-)
-
-func goodbye() {
-	s := "hiiiiiii"
-	s = s //@suggestedfix("s = s", "quickfix", "")
-	log.Print(s)
-}
diff -urN a/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go.golden b/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go.golden
--- a/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/suggestedfix/has_suggested_fix.go.golden	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
--- suggestedfix_has_suggested_fix_9_2 --
-package suggestedfix
-
-import (
-	"log"
-)
-
-func goodbye() {
-	s := "hiiiiiii"
-	 //@suggestedfix("s = s", "quickfix", "")
-	log.Print(s)
-}
-
diff -urN a/gopls/internal/lsp/testdata/summary.txt.golden b/gopls/internal/lsp/testdata/summary.txt.golden
--- a/gopls/internal/lsp/testdata/summary.txt.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/summary.txt.golden	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
--- summary --
-CallHierarchyCount = 2
-CodeLensCount = 5
-CompletionsCount = 263
-CompletionSnippetCount = 106
-UnimportedCompletionsCount = 5
-DeepCompletionsCount = 5
-FuzzyCompletionsCount = 8
-RankedCompletionsCount = 164
-CaseSensitiveCompletionsCount = 4
-DiagnosticsCount = 42
-FoldingRangesCount = 2
-FormatCount = 6
-ImportCount = 8
-SemanticTokenCount = 3
-SuggestedFixCount = 64
-FunctionExtractionCount = 27
-MethodExtractionCount = 6
-DefinitionsCount = 99
-TypeDefinitionsCount = 18
-HighlightsCount = 69
-InlayHintsCount = 4
-ReferencesCount = 27
-RenamesCount = 41
-PrepareRenamesCount = 7
-SymbolsCount = 1
-WorkspaceSymbolsCount = 20
-SignaturesCount = 33
-LinksCount = 7
-ImplementationsCount = 14
-SelectionRangesCount = 3
-
diff -urN a/gopls/internal/lsp/testdata/summary_go1.18.txt.golden b/gopls/internal/lsp/testdata/summary_go1.18.txt.golden
--- a/gopls/internal/lsp/testdata/summary_go1.18.txt.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/summary_go1.18.txt.golden	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
--- summary --
-CallHierarchyCount = 2
-CodeLensCount = 5
-CompletionsCount = 264
-CompletionSnippetCount = 115
-UnimportedCompletionsCount = 5
-DeepCompletionsCount = 5
-FuzzyCompletionsCount = 8
-RankedCompletionsCount = 174
-CaseSensitiveCompletionsCount = 4
-DiagnosticsCount = 42
-FoldingRangesCount = 2
-FormatCount = 6
-ImportCount = 8
-SemanticTokenCount = 3
-SuggestedFixCount = 70
-FunctionExtractionCount = 27
-MethodExtractionCount = 6
-DefinitionsCount = 110
-TypeDefinitionsCount = 18
-HighlightsCount = 69
-InlayHintsCount = 5
-ReferencesCount = 27
-RenamesCount = 48
-PrepareRenamesCount = 7
-SymbolsCount = 2
-WorkspaceSymbolsCount = 20
-SignaturesCount = 33
-LinksCount = 7
-ImplementationsCount = 14
-SelectionRangesCount = 3
-
diff -urN a/gopls/internal/lsp/testdata/symbols/go1.18.go b/gopls/internal/lsp/testdata/symbols/go1.18.go
--- a/gopls/internal/lsp/testdata/symbols/go1.18.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/symbols/go1.18.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package main
-
-type T[P any] struct { //@symbol("T", "T", "Struct", "struct{...}", "T", "")
-	F P //@symbol("F", "F", "Field", "P", "", "T")
-}
-
-type Constraint interface { //@symbol("Constraint", "Constraint", "Interface", "interface{...}", "Constraint", "")
-	~int | struct{ int } //@symbol("~int | struct{int}", "~int | struct{ int }", "Field", "", "", "Constraint")
-
-	// TODO(rfindley): the selection range below is the entire interface field.
-	// Can we reduce it?
-	interface{ M() } //@symbol("interface{...}", "interface{ M() }", "Field", "", "iFaceField", "Constraint"), symbol("M", "M", "Method", "func()", "", "iFaceField")
-}
diff -urN a/gopls/internal/lsp/testdata/symbols/go1.18.go.golden b/gopls/internal/lsp/testdata/symbols/go1.18.go.golden
--- a/gopls/internal/lsp/testdata/symbols/go1.18.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/symbols/go1.18.go.golden	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
--- symbols --
-T Struct 6:6-6:7
-	F Field 7:2-7:3
-Constraint Interface 10:6-10:16
-	interface{...} Field 15:2-15:18
-	~int | struct{int} Field 11:2-11:22
-
diff -urN a/gopls/internal/lsp/testdata/symbols/main.go b/gopls/internal/lsp/testdata/symbols/main.go
--- a/gopls/internal/lsp/testdata/symbols/main.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/symbols/main.go	1969-12-31 16:00:00
@@ -1,91 +0,0 @@
-package main
-
-import (
-	"io"
-)
-
-// Each symbol marker in this file defines the following information:
-//  symbol(name, selectionSpan, kind, detail, id, parentID)
-//    - name: DocumentSymbol.Name
-//    - selectionSpan: DocumentSymbol.SelectionRange
-//    - kind: DocumentSymbol.Kind
-//    - detail: DocumentSymbol.Detail
-//    - id: if non-empty, a unique identifier for this symbol
-//    - parentID: if non-empty, the id of the parent of this symbol
-//
-// This data in aggregate defines a set of document symbols and their
-// parent-child relationships, which is compared against the DocummentSymbols
-// response from gopls for the current file.
-//
-// TODO(rfindley): the symbol annotations here are complicated and difficult to
-// maintain. It would be simpler to just write out the full expected response
-// in the golden file, perhaps as raw JSON.
-
-var _ = 1
-
-var x = 42 //@symbol("x", "x", "Variable", "", "", "")
-
-var nested struct { //@symbol("nested", "nested", "Variable", "struct{...}", "nested", "")
-	nestedField struct { //@symbol("nestedField", "nestedField", "Field", "struct{...}", "nestedField", "nested")
-		f int //@symbol("f", "f", "Field", "int", "", "nestedField")
-	}
-}
-
-const y = 43 //@symbol("y", "y", "Constant", "", "", "")
-
-type Number int //@symbol("Number", "Number", "Class", "int", "", "")
-
-type Alias = string //@symbol("Alias", "Alias", "Class", "string", "", "")
-
-type NumberAlias = Number //@symbol("NumberAlias", "NumberAlias", "Class", "Number", "", "")
-
-type (
-	Boolean   bool   //@symbol("Boolean", "Boolean", "Class", "bool", "", "")
-	BoolAlias = bool //@symbol("BoolAlias", "BoolAlias", "Class", "bool", "", "")
-)
-
-type Foo struct { //@symbol("Foo", "Foo", "Struct", "struct{...}", "Foo", "")
-	Quux                    //@symbol("Quux", "Quux", "Field", "Quux", "", "Foo")
-	W         io.Writer     //@symbol("W", "W", "Field", "io.Writer", "", "Foo")
-	Bar       int           //@symbol("Bar", "Bar", "Field", "int", "", "Foo")
-	baz       string        //@symbol("baz", "baz", "Field", "string", "", "Foo")
-	funcField func(int) int //@symbol("funcField", "funcField", "Field", "func(int) int", "", "Foo")
-}
-
-type Quux struct { //@symbol("Quux", "Quux", "Struct", "struct{...}", "Quux", "")
-	X, Y float64 //@symbol("X", "X", "Field", "float64", "", "Quux"), symbol("Y", "Y", "Field", "float64", "", "Quux")
-}
-
-type EmptyStruct struct{} //@symbol("EmptyStruct", "EmptyStruct", "Struct", "struct{}", "", "")
-
-func (f Foo) Baz() string { //@symbol("(Foo).Baz", "Baz", "Method", "func() string", "", "")
-	return f.baz
-}
-
-func _() {}
-
-func (q *Quux) Do() {} //@symbol("(*Quux).Do", "Do", "Method", "func()", "", "")
-
-func main() { //@symbol("main", "main", "Function", "func()", "", "")
-}
-
-type Stringer interface { //@symbol("Stringer", "Stringer", "Interface", "interface{...}", "Stringer", "")
-	String() string //@symbol("String", "String", "Method", "func() string", "", "Stringer")
-}
-
-type ABer interface { //@symbol("ABer", "ABer", "Interface", "interface{...}", "ABer", "")
-	B()        //@symbol("B", "B", "Method", "func()", "", "ABer")
-	A() string //@symbol("A", "A", "Method", "func() string", "", "ABer")
-}
-
-type WithEmbeddeds interface { //@symbol("WithEmbeddeds", "WithEmbeddeds", "Interface", "interface{...}", "WithEmbeddeds", "")
-	Do()      //@symbol("Do", "Do", "Method", "func()", "", "WithEmbeddeds")
-	ABer      //@symbol("ABer", "ABer", "Field", "ABer", "", "WithEmbeddeds")
-	io.Writer //@symbol("Writer", "Writer", "Field", "io.Writer", "", "WithEmbeddeds")
-}
-
-type EmptyInterface interface{} //@symbol("EmptyInterface", "EmptyInterface", "Interface", "interface{}", "", "")
-
-func Dunk() int { return 0 } //@symbol("Dunk", "Dunk", "Function", "func() int", "", "")
-
-func dunk() {} //@symbol("dunk", "dunk", "Function", "func()", "", "")
diff -urN a/gopls/internal/lsp/testdata/symbols/main.go.golden b/gopls/internal/lsp/testdata/symbols/main.go.golden
--- a/gopls/internal/lsp/testdata/symbols/main.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/symbols/main.go.golden	1969-12-31 16:00:00
@@ -1,36 +0,0 @@
--- symbols --
-x Variable 26:5-26:6
-nested Variable 28:5-28:11
-	nestedField Field 29:2-29:13
-y Constant 34:7-34:8
-Number Class 36:6-36:12
-Alias Class 38:6-38:11
-NumberAlias Class 40:6-40:17
-Boolean Class 43:2-43:9
-BoolAlias Class 44:2-44:11
-Foo Struct 47:6-47:9
-	Bar Field 50:2-50:5
-	Quux Field 48:2-48:6
-	W Field 49:2-49:3
-	baz Field 51:2-51:5
-	funcField Field 52:2-52:11
-Quux Struct 55:6-55:10
-	X Field 56:2-56:3
-	Y Field 56:5-56:6
-EmptyStruct Struct 59:6-59:17
-(Foo).Baz Method 61:14-61:17
-(*Quux).Do Method 67:16-67:18
-main Function 69:6-69:10
-Stringer Interface 72:6-72:14
-	String Method 73:2-73:8
-ABer Interface 76:6-76:10
-	A Method 78:2-78:3
-	B Method 77:2-77:3
-WithEmbeddeds Interface 81:6-81:19
-	ABer Field 83:2-83:6
-	Do Method 82:2-82:4
-	Writer Field 84:5-84:11
-EmptyInterface Interface 87:6-87:20
-Dunk Function 89:6-89:10
-dunk Function 91:6-91:10
-
diff -urN a/gopls/internal/lsp/testdata/testy/testy.go b/gopls/internal/lsp/testdata/testy/testy.go
--- a/gopls/internal/lsp/testdata/testy/testy.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/testy/testy.go	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package testy
-
-func a() { //@mark(identA, "a"),item(funcA, "a", "func()", "func"),refs("a", identA, testyA)
-	//@complete("", funcA)
-}
diff -urN a/gopls/internal/lsp/testdata/testy/testy_test.go b/gopls/internal/lsp/testdata/testy/testy_test.go
--- a/gopls/internal/lsp/testdata/testy/testy_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/testy/testy_test.go	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-package testy
-
-import (
-	"testing"
-
-	sig "golang.org/lsptests/signature"
-	"golang.org/lsptests/snippets"
-)
-
-func TestSomething(t *testing.T) { //@item(TestSomething, "TestSomething(t *testing.T)", "", "func")
-	var x int //@mark(testyX, "x"),diag("x", "compiler", "x declared (and|but) not used", "error"),refs("x", testyX)
-	a()       //@mark(testyA, "a")
-}
-
-func _() {
-	_ = snippets.X(nil) //@signature("nil", "X(_ map[sig.Alias]types.CoolAlias) map[sig.Alias]types.CoolAlias", 0)
-	var _ sig.Alias
-}
diff -urN a/gopls/internal/lsp/testdata/testy/testy_test.go.golden b/gopls/internal/lsp/testdata/testy/testy_test.go.golden
--- a/gopls/internal/lsp/testdata/testy/testy_test.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/testy/testy_test.go.golden	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
--- X(_ map[sig.Alias]types.CoolAlias) map[sig.Alias]types.CoolAlias-signature --
-X(_ map[sig.Alias]types.CoolAlias) map[sig.Alias]types.CoolAlias
-
diff -urN a/gopls/internal/lsp/testdata/typdef/typdef.go b/gopls/internal/lsp/testdata/typdef/typdef.go
--- a/gopls/internal/lsp/testdata/typdef/typdef.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/typdef/typdef.go	1969-12-31 16:00:00
@@ -1,65 +0,0 @@
-package typdef
-
-type Struct struct { //@item(Struct, "Struct", "struct{...}", "struct")
-	Field string
-}
-
-type Int int //@item(Int, "Int", "int", "type")
-
-func _() {
-	var (
-		value Struct
-		point *Struct
-	)
-	_ = value //@typdef("value", Struct)
-	_ = point //@typdef("point", Struct)
-
-	var (
-		array   [3]Struct
-		slice   []Struct
-		ch      chan Struct
-		complex [3]chan *[5][]Int
-	)
-	_ = array   //@typdef("array", Struct)
-	_ = slice   //@typdef("slice", Struct)
-	_ = ch      //@typdef("ch", Struct)
-	_ = complex //@typdef("complex", Int)
-
-	var s struct {
-		x struct {
-			xx struct {
-				field1 []Struct
-				field2 []Int
-			}
-		}
-	}
-	s.x.xx.field1 //@typdef("field1", Struct)
-	s.x.xx.field2 //@typdef("field2", Int)
-}
-
-func F1() Int                              { return 0 }
-func F2() (Int, float64)                   { return 0, 0 }
-func F3() (Struct, int, bool, error)       { return Struct{}, 0, false, nil }
-func F4() (**int, Int, bool, *error)       { return nil, Struct{}, false, nil }
-func F5() (int, float64, error, Struct)    { return 0, 0, nil, Struct{} }
-func F6() (int, float64, ***Struct, error) { return 0, 0, nil, nil }
-
-func _() {
-	F1() //@typdef("F1", Int)
-	F2() //@typdef("F2", Int)
-	F3() //@typdef("F3", Struct)
-	F4() //@typdef("F4", Int)
-	F5() //@typdef("F5", Struct)
-	F6() //@typdef("F6", Struct)
-
-	f := func() Int { return 0 }
-	f() //@typdef("f", Int)
-}
-
-// https://github.com/golang/go/issues/38589#issuecomment-620350922
-func _() {
-	type myFunc func(int) Int //@item(myFunc, "myFunc", "func", "type")
-
-	var foo myFunc
-	bar := foo() //@typdef("foo", myFunc)
-}
diff -urN a/gopls/internal/lsp/testdata/typeassert/type_assert.go b/gopls/internal/lsp/testdata/typeassert/type_assert.go
--- a/gopls/internal/lsp/testdata/typeassert/type_assert.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/typeassert/type_assert.go	1969-12-31 16:00:00
@@ -1,24 +0,0 @@
-package typeassert
-
-type abc interface { //@item(abcIntf, "abc", "interface{...}", "interface")
-	abc()
-}
-
-type abcImpl struct{} //@item(abcImpl, "abcImpl", "struct{...}", "struct")
-func (abcImpl) abc()
-
-type abcPtrImpl struct{} //@item(abcPtrImpl, "abcPtrImpl", "struct{...}", "struct")
-func (*abcPtrImpl) abc()
-
-type abcNotImpl struct{} //@item(abcNotImpl, "abcNotImpl", "struct{...}", "struct")
-
-func _() {
-	var a abc
-	switch a.(type) {
-	case ab: //@complete(":", abcImpl, abcPtrImpl, abcIntf, abcNotImpl)
-	case *ab: //@complete(":", abcImpl, abcPtrImpl, abcIntf, abcNotImpl)
-	}
-
-	a.(ab)  //@complete(")", abcImpl, abcPtrImpl, abcIntf, abcNotImpl)
-	a.(*ab) //@complete(")", abcImpl, abcPtrImpl, abcIntf, abcNotImpl)
-}
diff -urN a/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go b/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go
--- a/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go	1969-12-31 16:00:00
@@ -1,5 +0,0 @@
-package typeerrors
-
-func x() { return nil } //@suggestedfix("nil", "quickfix", "")
-
-func y() { return nil, "hello" } //@suggestedfix("nil", "quickfix", "")
diff -urN a/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go.golden b/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go.golden
--- a/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/typeerrors/noresultvalues.go.golden	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
--- suggestedfix_noresultvalues_3_19 --
-package typeerrors
-
-func x() { return } //@suggestedfix("nil", "quickfix", "")
-
-func y() { return nil, "hello" } //@suggestedfix("nil", "quickfix", "")
-
--- suggestedfix_noresultvalues_5_19 --
-package typeerrors
-
-func x() { return nil } //@suggestedfix("nil", "quickfix", "")
-
-func y() { return } //@suggestedfix("nil", "quickfix", "")
-
diff -urN a/gopls/internal/lsp/testdata/typemods/type_mods.go b/gopls/internal/lsp/testdata/typemods/type_mods.go
--- a/gopls/internal/lsp/testdata/typemods/type_mods.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/typemods/type_mods.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-package typemods
-
-func fooFunc() func() int { //@item(modFooFunc, "fooFunc", "func() func() int", "func")
-	return func() int {
-		return 0
-	}
-}
-
-func fooPtr() *int { //@item(modFooPtr, "fooPtr", "func() *int", "func")
-	return nil
-}
-
-func _() {
-	var _ int = foo //@snippet(" //", modFooFunc, "fooFunc()()", "fooFunc()()"),snippet(" //", modFooPtr, "*fooPtr()", "*fooPtr()")
-}
-
-func _() {
-	var m map[int][]chan int //@item(modMapChanPtr, "m", "map[int]chan *int", "var")
-
-	var _ int = m //@snippet(" //", modMapChanPtr, "<-m[${1:}][${2:}]", "<-m[${1:}][${2:}]")
-}
diff -urN a/gopls/internal/lsp/testdata/typeparams/type_params.go b/gopls/internal/lsp/testdata/typeparams/type_params.go
--- a/gopls/internal/lsp/testdata/typeparams/type_params.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/typeparams/type_params.go	1969-12-31 16:00:00
@@ -1,61 +0,0 @@
-//go:build go1.18
-// +build go1.18
-
-package typeparams
-
-func one[a int | string]()            {}
-func two[a int | string, b float64 | int]() {}
-
-func _() {
-	one[]() //@rank("]", string, float64)
-	two[]() //@rank("]", int, float64)
-	two[int, f]() //@rank("]", float64, float32)
-}
-
-func slices[a []int | []float64]() {} //@item(tpInts, "[]int", "[]int", "type"),item(tpFloats, "[]float64", "[]float64", "type")
-
-func _() {
-	slices[]() //@rank("]", tpInts),rank("]", tpFloats)
-}
-
-type s[a int | string] struct{}
-
-func _() {
-	s[]{} //@rank("]", int, float64)
-}
-
-func takesGeneric[a int | string](s[a]) {
-	"s[a]{}" //@item(tpInScopeLit, "s[a]{}", "", "var")
-	takesGeneric() //@rank(")", tpInScopeLit),snippet(")", tpInScopeLit, "s[a]{\\}", "s[a]{\\}")
-}
-
-func _() {
-	s[int]{} //@item(tpInstLit, "s[int]{}", "", "var")
-	takesGeneric[int]() //@rank(")", tpInstLit),snippet(")", tpInstLit, "s[int]{\\}", "s[int]{\\}")
-
-	"s[...]{}" //@item(tpUninstLit, "s[...]{}", "", "var")
-	takesGeneric() //@rank(")", tpUninstLit),snippet(")", tpUninstLit, "s[${1:}]{\\}", "s[${1:a}]{\\}")
-}
-
-func returnTP[A int | float64](a A) A { //@item(returnTP, "returnTP", "something", "func")
-	return a
-}
-
-func _() {
-	// disabled - see issue #54822
-	var _ int = returnTP // snippet(" //", returnTP, "returnTP[${1:}](${2:})", "returnTP[${1:A int|float64}](${2:a A})")
-
-	var aa int //@item(tpInt, "aa", "int", "var")
-	var ab float64 //@item(tpFloat, "ab", "float64", "var")
-	returnTP[int](a) //@rank(")", tpInt, tpFloat)
-}
-
-func takesFunc[T any](func(T) T) {
-	var _ func(t T) T = f //@snippet(" //", tpLitFunc, "func(t T) T {$0\\}", "func(t T) T {$0\\}")
-}
-
-func _() {
-	_ = "func(...) {}" //@item(tpLitFunc, "func(...) {}", "", "var")
-	takesFunc() //@snippet(")", tpLitFunc, "func(${1:}) ${2:} {$0\\}", "func(${1:t} ${2:T}) ${3:T} {$0\\}")
-	takesFunc[int]() //@snippet(")", tpLitFunc, "func(i int) int {$0\\}", "func(${1:i} int) int {$0\\}")
-}
diff -urN a/gopls/internal/lsp/testdata/types/types.go b/gopls/internal/lsp/testdata/types/types.go
--- a/gopls/internal/lsp/testdata/types/types.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/types/types.go	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-package types
-
-type CoolAlias = int //@item(CoolAlias, "CoolAlias", "int", "type")
-
-type X struct { //@item(X_struct, "X", "struct{...}", "struct")
-	x int
-}
-
-type Y struct { //@item(Y_struct, "Y", "struct{...}", "struct")
-	y int
-}
-
-type Bob interface { //@item(Bob_interface, "Bob", "interface{...}", "interface")
-	Bobby()
-}
-
-func (*X) Bobby() {}
-func (*Y) Bobby() {}
diff -urN a/gopls/internal/lsp/testdata/undeclared/var.go b/gopls/internal/lsp/testdata/undeclared/var.go
--- a/gopls/internal/lsp/testdata/undeclared/var.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/undeclared/var.go	1969-12-31 16:00:00
@@ -1,14 +0,0 @@
-package undeclared
-
-func m() int {
-	z, _ := 1+y, 11 //@diag("y", "compiler", "(undeclared name|undefined): y", "error"),suggestedfix("y", "quickfix", "")
-	if 100 < 90 {
-		z = 1
-	} else if 100 > n+2 { //@diag("n", "compiler", "(undeclared name|undefined): n", "error"),suggestedfix("n", "quickfix", "")
-		z = 4
-	}
-	for i < 200 { //@diag("i", "compiler", "(undeclared name|undefined): i", "error"),suggestedfix("i", "quickfix", "")
-	}
-	r() //@diag("r", "compiler", "(undeclared name|undefined): r", "error")
-	return z
-}
diff -urN a/gopls/internal/lsp/testdata/undeclared/var.go.golden b/gopls/internal/lsp/testdata/undeclared/var.go.golden
--- a/gopls/internal/lsp/testdata/undeclared/var.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/undeclared/var.go.golden	1969-12-31 16:00:00
@@ -1,51 +0,0 @@
--- suggestedfix_var_10_6 --
-package undeclared
-
-func m() int {
-	z, _ := 1+y, 11 //@diag("y", "compiler", "(undeclared name|undefined): y", "error"),suggestedfix("y", "quickfix", "")
-	if 100 < 90 {
-		z = 1
-	} else if 100 > n+2 { //@diag("n", "compiler", "(undeclared name|undefined): n", "error"),suggestedfix("n", "quickfix", "")
-		z = 4
-	}
-	i := 
-	for i < 200 { //@diag("i", "compiler", "(undeclared name|undefined): i", "error"),suggestedfix("i", "quickfix", "")
-	}
-	r() //@diag("r", "compiler", "(undeclared name|undefined): r", "error")
-	return z
-}
-
--- suggestedfix_var_4_12 --
-package undeclared
-
-func m() int {
-	y := 
-	z, _ := 1+y, 11 //@diag("y", "compiler", "(undeclared name|undefined): y", "error"),suggestedfix("y", "quickfix", "")
-	if 100 < 90 {
-		z = 1
-	} else if 100 > n+2 { //@diag("n", "compiler", "(undeclared name|undefined): n", "error"),suggestedfix("n", "quickfix", "")
-		z = 4
-	}
-	for i < 200 { //@diag("i", "compiler", "(undeclared name|undefined): i", "error"),suggestedfix("i", "quickfix", "")
-	}
-	r() //@diag("r", "compiler", "(undeclared name|undefined): r", "error")
-	return z
-}
-
--- suggestedfix_var_7_18 --
-package undeclared
-
-func m() int {
-	z, _ := 1+y, 11 //@diag("y", "compiler", "(undeclared name|undefined): y", "error"),suggestedfix("y", "quickfix", "")
-	n := 
-	if 100 < 90 {
-		z = 1
-	} else if 100 > n+2 { //@diag("n", "compiler", "(undeclared name|undefined): n", "error"),suggestedfix("n", "quickfix", "")
-		z = 4
-	}
-	for i < 200 { //@diag("i", "compiler", "(undeclared name|undefined): i", "error"),suggestedfix("i", "quickfix", "")
-	}
-	r() //@diag("r", "compiler", "(undeclared name|undefined): r", "error")
-	return z
-}
-
diff -urN a/gopls/internal/lsp/testdata/unimported/export_test.go b/gopls/internal/lsp/testdata/unimported/export_test.go
--- a/gopls/internal/lsp/testdata/unimported/export_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/unimported/export_test.go	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
-package unimported
-
-var TestExport int //@item(testexport, "TestExport", "(from \"golang.org/lsptests/unimported\")", "var")
diff -urN a/gopls/internal/lsp/testdata/unimported/unimported.go.in b/gopls/internal/lsp/testdata/unimported/unimported.go.in
--- a/gopls/internal/lsp/testdata/unimported/unimported.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/unimported/unimported.go.in	1969-12-31 16:00:00
@@ -1,20 +0,0 @@
-package unimported
-
-func _() {
-	http //@unimported("p", nethttp)
-	// container/ring is extremely unlikely to be imported by anything, so shouldn't have type information.
-	ring.Ring     //@unimported("Ring", ringring)
-	signature.Foo //@unimported("Foo", signaturefoo)
-
-	context.Bac //@unimported(" //", contextBackground, contextBackgroundErr)
-}
-
-// Create markers for unimported std lib packages. Only for use by this test.
-/* http */ //@item(nethttp, "http", "\"net/http\"", "package")
-
-/* ring.Ring */ //@item(ringring, "Ring", "(from \"container/ring\")", "var")
-
-/* signature.Foo */ //@item(signaturefoo, "Foo", "func(a string, b int) (c bool) (from \"golang.org/lsptests/signature\")", "func")
-
-/* context.Background */ //@item(contextBackground, "Background", "func() context.Context (from \"context\")", "func")
-/* context.Background().Err */ //@item(contextBackgroundErr, "Background().Err", "func() error (from \"context\")", "method")
diff -urN a/gopls/internal/lsp/testdata/unimported/unimported_cand_type.go b/gopls/internal/lsp/testdata/unimported/unimported_cand_type.go
--- a/gopls/internal/lsp/testdata/unimported/unimported_cand_type.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/unimported/unimported_cand_type.go	1969-12-31 16:00:00
@@ -1,16 +0,0 @@
-package unimported
-
-import (
-	_ "context"
-
-	"golang.org/lsptests/baz"
-	_ "golang.org/lsptests/signature" // provide type information for unimported completions in the other file
-)
-
-func _() {
-	foo.StructFoo{} //@item(litFooStructFoo, "foo.StructFoo{}", "struct{...}", "struct")
-
-	// We get the literal completion for "foo.StructFoo{}" even though we haven't
-	// imported "foo" yet.
-	baz.FooStruct = f //@snippet(" //", litFooStructFoo, "foo.StructFoo{$0\\}", "foo.StructFoo{$0\\}")
-}
diff -urN a/gopls/internal/lsp/testdata/unimported/x_test.go b/gopls/internal/lsp/testdata/unimported/x_test.go
--- a/gopls/internal/lsp/testdata/unimported/x_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/unimported/x_test.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package unimported_test
-
-import (
-	"testing"
-)
-
-func TestSomething(t *testing.T) {
-	_ = unimported.TestExport //@unimported("TestExport", testexport)
-}
diff -urN a/gopls/internal/lsp/testdata/unresolved/unresolved.go.in b/gopls/internal/lsp/testdata/unresolved/unresolved.go.in
--- a/gopls/internal/lsp/testdata/unresolved/unresolved.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/unresolved/unresolved.go.in	1969-12-31 16:00:00
@@ -1,6 +0,0 @@
-package unresolved
-
-func foo(interface{}) {
-	// don't crash on fake "resolved" type
-	foo(func(i, j f //@complete(" //")
-}
diff -urN a/gopls/internal/lsp/testdata/unsafe/unsafe.go b/gopls/internal/lsp/testdata/unsafe/unsafe.go
--- a/gopls/internal/lsp/testdata/unsafe/unsafe.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/unsafe/unsafe.go	1969-12-31 16:00:00
@@ -1,13 +0,0 @@
-package unsafe
-
-import (
-	"unsafe"
-)
-
-// Pre-set this marker, as we don't have a "source" for it in this package.
-/* unsafe.Sizeof */ //@item(Sizeof, "Sizeof", "invalid type", "text")
-
-func _() {
-	x := struct{}{}
-	_ = unsafe.Sizeof(x) //@complete("z", Sizeof)
-}
diff -urN a/gopls/internal/lsp/testdata/variadic/variadic.go.in b/gopls/internal/lsp/testdata/variadic/variadic.go.in
--- a/gopls/internal/lsp/testdata/variadic/variadic.go.in	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/variadic/variadic.go.in	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-package variadic
-
-func foo(i int, strs ...string) {}
-
-func bar() []string { //@item(vFunc, "bar", "func() []string", "func")
-	return nil
-}
-
-func _() {
-	var (
-		i  int        //@item(vInt, "i", "int", "var")
-		s  string     //@item(vStr, "s", "string", "var")
-		ss []string   //@item(vStrSlice, "ss", "[]string", "var")
-		v interface{} //@item(vIntf, "v", "interface{}", "var")
-	)
-
-	foo()           //@rank(")", vInt, vStr),rank(")", vInt, vStrSlice)
-	foo(123, )      //@rank(")", vStr, vInt),rank(")", vStrSlice, vInt)
-	foo(123, "", )  //@rank(")", vStr, vInt),rank(")", vStr, vStrSlice)
-	foo(123, s, "") //@rank(", \"", vStr, vStrSlice)
-
-  // snippet will add the "..." for you
-	foo(123, ) //@snippet(")", vStrSlice, "ss...", "ss..."),snippet(")", vFunc, "bar()...", "bar()..."),snippet(")", vStr, "s", "s")
-
-	// don't add "..." for interface{}
-	foo(123, ) //@snippet(")", vIntf, "v", "v")
-}
-
-func qux(...func()) {}
-func f()            {} //@item(vVarArg, "f", "func()", "func")
-
-func _() {
-	qux(f) //@snippet(")", vVarArg, "f", "f")
-}
-
-func _() {
-	foo(0, []string{}...) //@complete(")")
-}
diff -urN a/gopls/internal/lsp/testdata/variadic/variadic_intf.go b/gopls/internal/lsp/testdata/variadic/variadic_intf.go
--- a/gopls/internal/lsp/testdata/variadic/variadic_intf.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/variadic/variadic_intf.go	1969-12-31 16:00:00
@@ -1,21 +0,0 @@
-package variadic
-
-type baz interface {
-	baz()
-}
-
-func wantsBaz(...baz) {}
-
-type bazImpl int
-
-func (bazImpl) baz() {}
-
-func _() {
-	var (
-		impls []bazImpl //@item(vImplSlice, "impls", "[]bazImpl", "var")
-		impl  bazImpl   //@item(vImpl, "impl", "bazImpl", "var")
-		bazes []baz     //@item(vIntfSlice, "bazes", "[]baz", "var")
-	)
-
-	wantsBaz() //@rank(")", vImpl, vImplSlice),rank(")", vIntfSlice, vImplSlice)
-}
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/a/a.go b/gopls/internal/lsp/testdata/workspacesymbol/a/a.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/a/a.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/a/a.go	1969-12-31 16:00:00
@@ -1,9 +0,0 @@
-package a
-
-var RandomGopherVariableA = "a"
-
-const RandomGopherConstantA = "a"
-
-const (
-	randomgopherinvariable = iota
-)
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/a/a_test.go b/gopls/internal/lsp/testdata/workspacesymbol/a/a_test.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/a/a_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/a/a_test.go	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
-package a
-
-var RandomGopherTestVariableA = "a"
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/a/a_x_test.go b/gopls/internal/lsp/testdata/workspacesymbol/a/a_x_test.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/a/a_x_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/a/a_x_test.go	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
-package a_test
-
-var RandomGopherXTestVariableA = "a"
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/b/b.go b/gopls/internal/lsp/testdata/workspacesymbol/b/b.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/b/b.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/b/b.go	1969-12-31 16:00:00
@@ -1,7 +0,0 @@
-package b
-
-var RandomGopherVariableB = "b"
-
-type RandomGopherStructB struct {
-	Bar int
-}
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/issue44806.go b/gopls/internal/lsp/testdata/workspacesymbol/issue44806.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/issue44806.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/issue44806.go	1969-12-31 16:00:00
@@ -1,10 +0,0 @@
-package main
-
-type T struct{}
-
-// We should accept all valid receiver syntax when scanning symbols.
-func (*(T)) m1() {}
-func (*T) m2()   {}
-func (T) m3()    {}
-func ((T)) m4()    {}
-func ((*T)) m5()   {}
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/main.go b/gopls/internal/lsp/testdata/workspacesymbol/main.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/main.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/main.go	1969-12-31 16:00:00
@@ -1,47 +0,0 @@
-package main
-
-import (
-	"encoding/json"
-	"fmt"
-)
-
-func main() { // function
-	fmt.Println("Hello")
-}
-
-var myvar int // variable
-
-type myType string // basic type
-
-type myDecoder json.Decoder // to use the encoding/json import
-
-func (m *myType) Blahblah() {} // method
-
-type myStruct struct { // struct type
-	myStructField int // struct field
-}
-
-type myInterface interface { // interface
-	DoSomeCoolStuff() string // interface method
-}
-
-type embed struct {
-	myStruct
-
-	nestedStruct struct {
-		nestedField int
-
-		nestedStruct2 struct {
-			int
-		}
-	}
-
-	nestedInterface interface {
-		myInterface
-		nestedMethod()
-	}
-}
-
-func Dunk() int { return 0 }
-
-func dunk() {}
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/p/p.go b/gopls/internal/lsp/testdata/workspacesymbol/p/p.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/p/p.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/p/p.go	1969-12-31 16:00:00
@@ -1,3 +0,0 @@
-package p
-
-const Message = "Hello World." // constant
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/query.go b/gopls/internal/lsp/testdata/workspacesymbol/query.go
--- a/gopls/internal/lsp/testdata/workspacesymbol/query.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/query.go	1969-12-31 16:00:00
@@ -1,29 +0,0 @@
-package main
-
-// Contains all of the workspace symbol queries.
-
-// -- Fuzzy matching --
-//@workspacesymbolfuzzy("rgop")
-//@workspacesymbolfuzzy("randoma")
-//@workspacesymbolfuzzy("randomb")
-
-// -- Case sensitive --
-//@workspacesymbolcasesensitive("main.main")
-//@workspacesymbolcasesensitive("p.Message")
-//@workspacesymbolcasesensitive("main.myvar")
-//@workspacesymbolcasesensitive("main.myType")
-//@workspacesymbolcasesensitive("main.myType.Blahblah")
-//@workspacesymbolcasesensitive("main.myStruct")
-//@workspacesymbolcasesensitive("main.myStruct.myStructField")
-//@workspacesymbolcasesensitive("main.myInterface")
-//@workspacesymbolcasesensitive("main.myInterface.DoSomeCoolStuff")
-//@workspacesymbolcasesensitive("main.embed.myStruct")
-//@workspacesymbolcasesensitive("main.embed.nestedStruct.nestedStruct2.int")
-//@workspacesymbolcasesensitive("main.embed.nestedInterface.myInterface")
-//@workspacesymbolcasesensitive("main.embed.nestedInterface.nestedMethod")
-//@workspacesymbolcasesensitive("dunk")
-//@workspacesymbolcasesensitive("Dunk")
-
-// -- Standard --
-//@workspacesymbol("")
-//@workspacesymbol("randomgophervar")
diff -urN a/gopls/internal/lsp/testdata/workspacesymbol/query.go.golden b/gopls/internal/lsp/testdata/workspacesymbol/query.go.golden
--- a/gopls/internal/lsp/testdata/workspacesymbol/query.go.golden	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/testdata/workspacesymbol/query.go.golden	1969-12-31 16:00:00
@@ -1,83 +0,0 @@
--- workspace_symbol-caseinsensitive- --
-
-
--- workspace_symbol-caseinsensitive-randomgophervar --
-workspacesymbol/a/a.go:3:5-26 RandomGopherVariableA Variable
-workspacesymbol/b/b.go:3:5-26 RandomGopherVariableB Variable
-
--- workspace_symbol-casesensitive-Dunk --
-workspacesymbol/main.go:45:6-10 Dunk Function
-
--- workspace_symbol-casesensitive-dunk --
-workspacesymbol/main.go:47:6-10 dunk Function
-
--- workspace_symbol-casesensitive-main.embed.myStruct --
-workspacesymbol/main.go:29:2-10 main.embed.myStruct Field
-
--- workspace_symbol-casesensitive-main.embed.nestedInterface.myInterface --
-workspacesymbol/main.go:40:3-14 main.embed.nestedInterface.myInterface Interface
-
--- workspace_symbol-casesensitive-main.embed.nestedInterface.nestedMethod --
-workspacesymbol/main.go:41:3-15 main.embed.nestedInterface.nestedMethod Method
-
--- workspace_symbol-casesensitive-main.embed.nestedStruct.nestedStruct2.int --
-workspacesymbol/main.go:35:4-7 main.embed.nestedStruct.nestedStruct2.int Field
-
--- workspace_symbol-casesensitive-main.main --
-workspacesymbol/main.go:8:6-10 main.main Function
-
--- workspace_symbol-casesensitive-main.myInterface --
-workspacesymbol/main.go:24:6-17 main.myInterface Interface
-workspacesymbol/main.go:25:2-17 main.myInterface.DoSomeCoolStuff Method
-
--- workspace_symbol-casesensitive-main.myInterface.DoSomeCoolStuff --
-workspacesymbol/main.go:25:2-17 main.myInterface.DoSomeCoolStuff Method
-
--- workspace_symbol-casesensitive-main.myStruct --
-workspacesymbol/main.go:20:6-14 main.myStruct Struct
-workspacesymbol/main.go:21:2-15 main.myStruct.myStructField Field
-
--- workspace_symbol-casesensitive-main.myStruct.myStructField --
-workspacesymbol/main.go:21:2-15 main.myStruct.myStructField Field
-
--- workspace_symbol-casesensitive-main.myType --
-workspacesymbol/main.go:14:6-12 main.myType Class
-workspacesymbol/main.go:18:18-26 main.myType.Blahblah Method
-
--- workspace_symbol-casesensitive-main.myType.Blahblah --
-workspacesymbol/main.go:18:18-26 main.myType.Blahblah Method
-
--- workspace_symbol-casesensitive-main.myvar --
-workspacesymbol/main.go:12:5-10 main.myvar Variable
-
--- workspace_symbol-casesensitive-p.Message --
-workspacesymbol/p/p.go:3:7-14 p.Message Constant
-
--- workspace_symbol-fuzzy-randoma --
-workspacesymbol/a/a.go:3:5-26 RandomGopherVariableA Variable
-workspacesymbol/a/a.go:5:7-28 RandomGopherConstantA Constant
-workspacesymbol/a/a.go:8:2-24 randomgopherinvariable Constant
-workspacesymbol/a/a_test.go:3:5-30 RandomGopherTestVariableA Variable
-workspacesymbol/a/a_x_test.go:3:5-31 RandomGopherXTestVariableA Variable
-workspacesymbol/b/b.go:3:5-26 RandomGopherVariableB Variable
-workspacesymbol/b/b.go:6:2-5 RandomGopherStructB.Bar Field
-
--- workspace_symbol-fuzzy-randomb --
-workspacesymbol/a/a.go:3:5-26 RandomGopherVariableA Variable
-workspacesymbol/a/a.go:8:2-24 randomgopherinvariable Constant
-workspacesymbol/a/a_test.go:3:5-30 RandomGopherTestVariableA Variable
-workspacesymbol/a/a_x_test.go:3:5-31 RandomGopherXTestVariableA Variable
-workspacesymbol/b/b.go:3:5-26 RandomGopherVariableB Variable
-workspacesymbol/b/b.go:5:6-25 RandomGopherStructB Struct
-workspacesymbol/b/b.go:6:2-5 RandomGopherStructB.Bar Field
-
--- workspace_symbol-fuzzy-rgop --
-workspacesymbol/a/a.go:3:5-26 RandomGopherVariableA Variable
-workspacesymbol/a/a.go:5:7-28 RandomGopherConstantA Constant
-workspacesymbol/a/a.go:8:2-24 randomgopherinvariable Constant
-workspacesymbol/a/a_test.go:3:5-30 RandomGopherTestVariableA Variable
-workspacesymbol/a/a_x_test.go:3:5-31 RandomGopherXTestVariableA Variable
-workspacesymbol/b/b.go:3:5-26 RandomGopherVariableB Variable
-workspacesymbol/b/b.go:5:6-25 RandomGopherStructB Struct
-workspacesymbol/b/b.go:6:2-5 RandomGopherStructB.Bar Field
-
diff -urN a/gopls/internal/lsp/tests/README.md b/gopls/internal/lsp/tests/README.md
--- a/gopls/internal/lsp/tests/README.md	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/README.md	1969-12-31 16:00:00
@@ -1,66 +0,0 @@
-# Testing
-
-LSP has "marker tests" defined in `internal/lsp/testdata`, as well as
-traditional tests.
-
-## Marker tests
-
-Marker tests have a standard input file, like
-`internal/lsp/testdata/foo/bar.go`, and some may have a corresponding golden
-file, like `internal/lsp/testdata/foo/bar.go.golden`. The former is the "input"
-and the latter is the expected output.
-
-Each input file contains annotations like
-`//@suggestedfix("}", "refactor.rewrite", "Fill anonymous struct")`. These annotations are interpreted by
-test runners to perform certain actions. The expected output after those actions
-is encoded in the golden file.
-
-When tests are run, each annotation results in a new subtest, which is encoded
-in the golden file with a heading like,
-
-```bash
--- suggestedfix_bar_11_21 --
-// expected contents go here
--- suggestedfix_bar_13_20 --
-// expected contents go here
-```
-
-The format of these headings vary: they are defined by the
-[`Golden`](https://pkg.go.dev/golang.org/x/tools/gopls/internal/lsp/tests#Data.Golden)
-function for each annotation. In the case above, the format is: annotation
-name, file name, annotation line location, annotation character location.
-
-So, if `internal/lsp/testdata/foo/bar.go` has three `suggestedfix` annotations,
-the golden file should have three headers with `suggestedfix_bar_xx_yy`
-headings.
-
-To see a list of all available annotations, see the exported "expectations" in
-[tests.go](https://github.com/golang/tools/blob/299f270db45902e93469b1152fafed034bb3f033/internal/lsp/tests/tests.go#L418-L447).
-
-To run marker tests,
-
-```bash
-cd /path/to/tools
-
-# The marker tests are located in "internal/lsp", "internal/lsp/cmd, and
-# "internal/lsp/source".
-go test ./internal/lsp/...
-```
-
-There are quite a lot of marker tests, so to run one individually, pass the test
-path and heading into a -run argument:
-
-```bash
-cd /path/to/tools
-go test ./internal/lsp/... -v -run TestLSP/Modules/SuggestedFix/bar_11_21
-```
-
-## Resetting marker tests
-
-Sometimes, a change is made to lsp that requires a change to multiple golden
-files. When this happens, you can run,
-
-```bash
-cd /path/to/tools
-./internal/lsp/reset_golden.sh
-```
diff -urN a/gopls/internal/lsp/tests/compare/text.go b/gopls/internal/lsp/tests/compare/text.go
--- a/gopls/internal/lsp/tests/compare/text.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/compare/text.go	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package compare
-
-import (
-	"golang.org/x/tools/internal/diff"
-)
-
-// Text returns a formatted unified diff of the edits to go from want to
-// got, returning "" if and only if want == got.
-//
-// This function is intended for use in testing, and panics if any error occurs
-// while computing the diff. It is not sufficiently tested for production use.
-func Text(want, got string) string {
-	if want == got {
-		return ""
-	}
-
-	// Add newlines to avoid verbose newline messages ("No newline at end of file").
-	unified := diff.Unified("want", "got", want+"\n", got+"\n")
-
-	// Defensively assert that we get an actual diff, so that we guarantee the
-	// invariant that we return "" if and only if want == got.
-	//
-	// This is probably unnecessary, but convenient.
-	if unified == "" {
-		panic("empty diff for non-identical input")
-	}
-
-	return unified
-}
diff -urN a/gopls/internal/lsp/tests/compare/text_test.go b/gopls/internal/lsp/tests/compare/text_test.go
--- a/gopls/internal/lsp/tests/compare/text_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/compare/text_test.go	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package compare_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-)
-
-func TestText(t *testing.T) {
-	tests := []struct {
-		got, want, wantDiff string
-	}{
-		{"", "", ""},
-		{"equal", "equal", ""},
-		{"a", "b", "--- want\n+++ got\n@@ -1 +1 @@\n-b\n+a\n"},
-		{"a\nd\nc\n", "a\nb\nc\n", "--- want\n+++ got\n@@ -1,4 +1,4 @@\n a\n-b\n+d\n c\n \n"},
-	}
-
-	for _, test := range tests {
-		if gotDiff := compare.Text(test.want, test.got); gotDiff != test.wantDiff {
-			t.Errorf("compare.Text(%q, %q) =\n%q, want\n%q", test.want, test.got, gotDiff, test.wantDiff)
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/tests/markdown_go118.go b/gopls/internal/lsp/tests/markdown_go118.go
--- a/gopls/internal/lsp/tests/markdown_go118.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/markdown_go118.go	1969-12-31 16:00:00
@@ -1,63 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !go1.19
-// +build !go1.19
-
-package tests
-
-import (
-	"regexp"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-)
-
-// The markdown in the golden files matches the converter in comment.go,
-// but for go1.19 and later the conversion is done using go/doc/comment.
-// Compared to the newer version, the older version
-// has extra escapes, and treats code blocks slightly differently.
-func CheckSameMarkdown(t *testing.T, got, want string) {
-	t.Helper()
-
-	got = normalizeMarkdown(got)
-	want = normalizeMarkdown(want)
-
-	if diff := compare.Text(want, got); diff != "" {
-		t.Errorf("normalized markdown differs:\n%s", diff)
-	}
-}
-
-// normalizeMarkdown normalizes whitespace and escaping of the input string, to
-// eliminate differences between the Go 1.18 and Go 1.19 generated markdown for
-// doc comments. Note that it does not normalize to either the 1.18 or 1.19
-// formatting: it simplifies both so that they may be compared.
-//
-// This function may need to be adjusted as we encounter more differences in
-// the generated text.
-func normalizeMarkdown(input string) string {
-	input = strings.TrimSpace(input)
-
-	// For simplicity, eliminate blank lines.
-	input = regexp.MustCompile("\n+").ReplaceAllString(input, "\n")
-
-	// Replace common escaped characters with their unescaped version.
-	//
-	// This list may not be exhaustive: it was just sufficient to make tests
-	// pass.
-	input = strings.NewReplacer(
-		`\\`, ``,
-		`\@`, `@`,
-		`\(`, `(`,
-		`\)`, `)`,
-		`\"`, `"`,
-		`\.`, `.`,
-		`\-`, `-`,
-		`\'`, `'`,
-		`\n\n\n`, `\n\n`, // Note that these are *escaped* newlines.
-	).Replace(input)
-
-	return input
-}
diff -urN a/gopls/internal/lsp/tests/markdown_go119.go b/gopls/internal/lsp/tests/markdown_go119.go
--- a/gopls/internal/lsp/tests/markdown_go119.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/markdown_go119.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.19
-// +build go1.19
-
-package tests
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-)
-
-// The markdown in the golden files matches the converter in comment.go,
-// but for go1.19 and later the conversion is done using go/doc/comment.
-// Compared to the newer version, the older version
-// has extra escapes, and treats code blocks slightly differently.
-func CheckSameMarkdown(t *testing.T, got, want string) {
-	t.Helper()
-
-	if diff := compare.Text(want, got); diff != "" {
-		t.Errorf("normalized markdown differs:\n%s", diff)
-	}
-}
diff -urN a/gopls/internal/lsp/tests/normalizer.go b/gopls/internal/lsp/tests/normalizer.go
--- a/gopls/internal/lsp/tests/normalizer.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/normalizer.go	1969-12-31 16:00:00
@@ -1,129 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package tests
-
-import (
-	"path/filepath"
-	"strconv"
-	"strings"
-
-	"golang.org/x/tools/go/packages/packagestest"
-)
-
-type Normalizer struct {
-	path     string
-	slashed  string
-	escaped  string
-	fragment string
-}
-
-func CollectNormalizers(exported *packagestest.Exported) []Normalizer {
-	// build the path normalizing patterns
-	var normalizers []Normalizer
-	for _, m := range exported.Modules {
-		for fragment := range m.Files {
-			n := Normalizer{
-				path:     exported.File(m.Name, fragment),
-				fragment: fragment,
-			}
-			if n.slashed = filepath.ToSlash(n.path); n.slashed == n.path {
-				n.slashed = ""
-			}
-			quoted := strconv.Quote(n.path)
-			if n.escaped = quoted[1 : len(quoted)-1]; n.escaped == n.path {
-				n.escaped = ""
-			}
-			normalizers = append(normalizers, n)
-		}
-	}
-	return normalizers
-}
-
-// NormalizePrefix normalizes a single path at the front of the input string.
-func NormalizePrefix(s string, normalizers []Normalizer) string {
-	for _, n := range normalizers {
-		if t := strings.TrimPrefix(s, n.path); t != s {
-			return n.fragment + t
-		}
-		if t := strings.TrimPrefix(s, n.slashed); t != s {
-			return n.fragment + t
-		}
-		if t := strings.TrimPrefix(s, n.escaped); t != s {
-			return n.fragment + t
-		}
-	}
-	return s
-}
-
-// Normalize replaces all paths present in s with just the fragment portion
-// this is used to make golden files not depend on the temporary paths of the files
-func Normalize(s string, normalizers []Normalizer) string {
-	type entry struct {
-		path     string
-		index    int
-		fragment string
-	}
-	var match []entry
-	// collect the initial state of all the matchers
-	for _, n := range normalizers {
-		index := strings.Index(s, n.path)
-		if index >= 0 {
-			match = append(match, entry{n.path, index, n.fragment})
-		}
-		if n.slashed != "" {
-			index := strings.Index(s, n.slashed)
-			if index >= 0 {
-				match = append(match, entry{n.slashed, index, n.fragment})
-			}
-		}
-		if n.escaped != "" {
-			index := strings.Index(s, n.escaped)
-			if index >= 0 {
-				match = append(match, entry{n.escaped, index, n.fragment})
-			}
-		}
-	}
-	// result should be the same or shorter than the input
-	var b strings.Builder
-	last := 0
-	for {
-		// find the nearest path match to the start of the buffer
-		next := -1
-		nearest := len(s)
-		for i, c := range match {
-			if c.index >= 0 && nearest > c.index {
-				nearest = c.index
-				next = i
-			}
-		}
-		// if there are no matches, we copy the rest of the string and are done
-		if next < 0 {
-			b.WriteString(s[last:])
-			return b.String()
-		}
-		// we have a match
-		n := &match[next]
-		// copy up to the start of the match
-		b.WriteString(s[last:n.index])
-		// skip over the filename
-		last = n.index + len(n.path)
-
-		// Hack: In multi-module mode, we add a "testmodule/" prefix, so trim
-		// it from the fragment.
-		fragment := n.fragment
-		if strings.HasPrefix(fragment, "testmodule") {
-			split := strings.Split(filepath.ToSlash(fragment), "/")
-			fragment = filepath.FromSlash(strings.Join(split[1:], "/"))
-		}
-
-		// add in the fragment instead
-		b.WriteString(fragment)
-		// see what the next match for this path is
-		n.index = strings.Index(s[last:], n.path)
-		if n.index >= 0 {
-			n.index += last
-		}
-	}
-}
diff -urN a/gopls/internal/lsp/tests/tests.go b/gopls/internal/lsp/tests/tests.go
--- a/gopls/internal/lsp/tests/tests.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/tests.go	1969-12-31 16:00:00
@@ -1,1466 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package tests exports functionality to be used across a variety of gopls tests.
-package tests
-
-import (
-	"bytes"
-	"context"
-	"flag"
-	"fmt"
-	"go/ast"
-	"go/token"
-	"io"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"regexp"
-	"sort"
-	"strconv"
-	"strings"
-	"sync"
-	"testing"
-	"time"
-
-	"golang.org/x/tools/go/expect"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/go/packages/packagestest"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/source/completion"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/testenv"
-	"golang.org/x/tools/internal/typeparams"
-	"golang.org/x/tools/txtar"
-)
-
-const (
-	overlayFileSuffix = ".overlay"
-	goldenFileSuffix  = ".golden"
-	inFileSuffix      = ".in"
-
-	// The module path containing the testdata packages.
-	//
-	// Warning: the length of this module path matters, as we have bumped up
-	// against command-line limitations on windows (golang/go#54800).
-	testModule = "golang.org/lsptests"
-)
-
-var summaryFile = "summary.txt"
-
-func init() {
-	if typeparams.Enabled {
-		summaryFile = "summary_go1.18.txt"
-	}
-}
-
-var UpdateGolden = flag.Bool("golden", false, "Update golden files")
-
-// These type names apparently avoid the need to repeat the
-// type in the field name and the make() expression.
-type CallHierarchy = map[span.Span]*CallHierarchyResult
-type CodeLens = map[span.URI][]protocol.CodeLens
-type Diagnostics = map[span.URI][]*source.Diagnostic
-type CompletionItems = map[token.Pos]*completion.CompletionItem
-type Completions = map[span.Span][]Completion
-type CompletionSnippets = map[span.Span][]CompletionSnippet
-type UnimportedCompletions = map[span.Span][]Completion
-type DeepCompletions = map[span.Span][]Completion
-type FuzzyCompletions = map[span.Span][]Completion
-type CaseSensitiveCompletions = map[span.Span][]Completion
-type RankCompletions = map[span.Span][]Completion
-type FoldingRanges = []span.Span
-type Formats = []span.Span
-type Imports = []span.Span
-type SemanticTokens = []span.Span
-type SuggestedFixes = map[span.Span][]SuggestedFix
-type FunctionExtractions = map[span.Span]span.Span
-type MethodExtractions = map[span.Span]span.Span
-type Definitions = map[span.Span]Definition
-type Implementations = map[span.Span][]span.Span
-type Highlights = map[span.Span][]span.Span
-type References = map[span.Span][]span.Span
-type Renames = map[span.Span]string
-type PrepareRenames = map[span.Span]*source.PrepareItem
-type Symbols = map[span.URI][]*symbol
-type InlayHints = []span.Span
-type WorkspaceSymbols = map[WorkspaceSymbolsTestType]map[span.URI][]string
-type Signatures = map[span.Span]*protocol.SignatureHelp
-type Links = map[span.URI][]Link
-type AddImport = map[span.URI]string
-type Hovers = map[span.Span]string
-type SelectionRanges = []span.Span
-
-type Data struct {
-	Config                   packages.Config
-	Exported                 *packagestest.Exported
-	CallHierarchy            CallHierarchy
-	CodeLens                 CodeLens
-	Diagnostics              Diagnostics
-	CompletionItems          CompletionItems
-	Completions              Completions
-	CompletionSnippets       CompletionSnippets
-	UnimportedCompletions    UnimportedCompletions
-	DeepCompletions          DeepCompletions
-	FuzzyCompletions         FuzzyCompletions
-	CaseSensitiveCompletions CaseSensitiveCompletions
-	RankCompletions          RankCompletions
-	FoldingRanges            FoldingRanges
-	Formats                  Formats
-	Imports                  Imports
-	SemanticTokens           SemanticTokens
-	SuggestedFixes           SuggestedFixes
-	FunctionExtractions      FunctionExtractions
-	MethodExtractions        MethodExtractions
-	Definitions              Definitions
-	Implementations          Implementations
-	Highlights               Highlights
-	References               References
-	Renames                  Renames
-	InlayHints               InlayHints
-	PrepareRenames           PrepareRenames
-	Symbols                  Symbols
-	WorkspaceSymbols         WorkspaceSymbols
-	Signatures               Signatures
-	Links                    Links
-	AddImport                AddImport
-	Hovers                   Hovers
-	SelectionRanges          SelectionRanges
-
-	fragments map[string]string
-	dir       string
-	golden    map[string]*Golden
-	mode      string
-
-	ModfileFlagAvailable bool
-
-	mappersMu sync.Mutex
-	mappers   map[span.URI]*protocol.ColumnMapper
-}
-
-// TODO(adonovan): there are multiple implementations of this (undocumented)
-// interface, each of which must implement similar semantics. For example:
-// - *runner in ../cmd/test/check.go
-// - *runner in ../source/source_test.go
-// - *runner in ../lsp_test.go
-// Can we avoid this duplication?
-type Tests interface {
-	CallHierarchy(*testing.T, span.Span, *CallHierarchyResult)
-	CodeLens(*testing.T, span.URI, []protocol.CodeLens)
-	Diagnostics(*testing.T, span.URI, []*source.Diagnostic)
-	Completion(*testing.T, span.Span, Completion, CompletionItems)
-	CompletionSnippet(*testing.T, span.Span, CompletionSnippet, bool, CompletionItems)
-	UnimportedCompletion(*testing.T, span.Span, Completion, CompletionItems)
-	DeepCompletion(*testing.T, span.Span, Completion, CompletionItems)
-	FuzzyCompletion(*testing.T, span.Span, Completion, CompletionItems)
-	CaseSensitiveCompletion(*testing.T, span.Span, Completion, CompletionItems)
-	RankCompletion(*testing.T, span.Span, Completion, CompletionItems)
-	FoldingRanges(*testing.T, span.Span)
-	Format(*testing.T, span.Span)
-	Import(*testing.T, span.Span)
-	SemanticTokens(*testing.T, span.Span)
-	SuggestedFix(*testing.T, span.Span, []SuggestedFix, int)
-	FunctionExtraction(*testing.T, span.Span, span.Span)
-	MethodExtraction(*testing.T, span.Span, span.Span)
-	Definition(*testing.T, span.Span, Definition)
-	Implementation(*testing.T, span.Span, []span.Span)
-	Highlight(*testing.T, span.Span, []span.Span)
-	InlayHints(*testing.T, span.Span)
-	References(*testing.T, span.Span, []span.Span)
-	Rename(*testing.T, span.Span, string)
-	PrepareRename(*testing.T, span.Span, *source.PrepareItem)
-	Symbols(*testing.T, span.URI, []protocol.DocumentSymbol)
-	WorkspaceSymbols(*testing.T, span.URI, string, WorkspaceSymbolsTestType)
-	SignatureHelp(*testing.T, span.Span, *protocol.SignatureHelp)
-	Link(*testing.T, span.URI, []Link)
-	AddImport(*testing.T, span.URI, string)
-	Hover(*testing.T, span.Span, string)
-	SelectionRanges(*testing.T, span.Span)
-}
-
-type Definition struct {
-	Name      string
-	IsType    bool
-	OnlyHover bool
-	Src, Def  span.Span
-}
-
-type CompletionTestType int
-
-const (
-	// Default runs the standard completion tests.
-	CompletionDefault = CompletionTestType(iota)
-
-	// Unimported tests the autocompletion of unimported packages.
-	CompletionUnimported
-
-	// Deep tests deep completion.
-	CompletionDeep
-
-	// Fuzzy tests deep completion and fuzzy matching.
-	CompletionFuzzy
-
-	// CaseSensitive tests case sensitive completion.
-	CompletionCaseSensitive
-
-	// CompletionRank candidates in test must be valid and in the right relative order.
-	CompletionRank
-)
-
-type WorkspaceSymbolsTestType int
-
-const (
-	// Default runs the standard workspace symbols tests.
-	WorkspaceSymbolsDefault = WorkspaceSymbolsTestType(iota)
-
-	// Fuzzy tests workspace symbols with fuzzy matching.
-	WorkspaceSymbolsFuzzy
-
-	// CaseSensitive tests workspace symbols with case sensitive.
-	WorkspaceSymbolsCaseSensitive
-)
-
-type Completion struct {
-	CompletionItems []token.Pos
-}
-
-type CompletionSnippet struct {
-	CompletionItem     token.Pos
-	PlainSnippet       string
-	PlaceholderSnippet string
-}
-
-type CallHierarchyResult struct {
-	IncomingCalls, OutgoingCalls []protocol.CallHierarchyItem
-}
-
-type Link struct {
-	Src          span.Span
-	Target       string
-	NotePosition token.Position
-}
-
-type SuggestedFix struct {
-	ActionKind, Title string
-}
-
-// A symbol holds a DocumentSymbol along with its parent-child edge.
-type symbol struct {
-	pSymbol      protocol.DocumentSymbol
-	id, parentID string
-}
-
-type Golden struct {
-	Filename string
-	Archive  *txtar.Archive
-	Modified bool
-}
-
-func Context(t testing.TB) context.Context {
-	return context.Background()
-}
-
-func DefaultOptions(o *source.Options) {
-	o.SupportedCodeActions = map[source.FileKind]map[protocol.CodeActionKind]bool{
-		source.Go: {
-			protocol.SourceOrganizeImports: true,
-			protocol.QuickFix:              true,
-			protocol.RefactorRewrite:       true,
-			protocol.RefactorExtract:       true,
-			protocol.SourceFixAll:          true,
-		},
-		source.Mod: {
-			protocol.SourceOrganizeImports: true,
-		},
-		source.Sum:  {},
-		source.Work: {},
-		source.Tmpl: {},
-	}
-	o.UserOptions.Codelenses[string(command.Test)] = true
-	o.HoverKind = source.SynopsisDocumentation
-	o.InsertTextFormat = protocol.SnippetTextFormat
-	o.CompletionBudget = time.Minute
-	o.HierarchicalDocumentSymbolSupport = true
-	o.ExperimentalWorkspaceModule = true
-	o.SemanticTokens = true
-	o.InternalOptions.NewDiff = "both"
-}
-
-func RunTests(t *testing.T, dataDir string, includeMultiModule bool, f func(*testing.T, *Data)) {
-	t.Helper()
-	modes := []string{"Modules", "GOPATH"}
-	if includeMultiModule {
-		modes = append(modes, "MultiModule")
-	}
-	for _, mode := range modes {
-		t.Run(mode, func(t *testing.T) {
-			datum := load(t, mode, dataDir)
-			t.Helper()
-			f(t, datum)
-		})
-	}
-}
-
-func load(t testing.TB, mode string, dir string) *Data {
-	datum := &Data{
-		CallHierarchy:            make(CallHierarchy),
-		CodeLens:                 make(CodeLens),
-		Diagnostics:              make(Diagnostics),
-		CompletionItems:          make(CompletionItems),
-		Completions:              make(Completions),
-		CompletionSnippets:       make(CompletionSnippets),
-		UnimportedCompletions:    make(UnimportedCompletions),
-		DeepCompletions:          make(DeepCompletions),
-		FuzzyCompletions:         make(FuzzyCompletions),
-		RankCompletions:          make(RankCompletions),
-		CaseSensitiveCompletions: make(CaseSensitiveCompletions),
-		Definitions:              make(Definitions),
-		Implementations:          make(Implementations),
-		Highlights:               make(Highlights),
-		References:               make(References),
-		Renames:                  make(Renames),
-		PrepareRenames:           make(PrepareRenames),
-		SuggestedFixes:           make(SuggestedFixes),
-		FunctionExtractions:      make(FunctionExtractions),
-		MethodExtractions:        make(MethodExtractions),
-		Symbols:                  make(Symbols),
-		WorkspaceSymbols:         make(WorkspaceSymbols),
-		Signatures:               make(Signatures),
-		Links:                    make(Links),
-		AddImport:                make(AddImport),
-		Hovers:                   make(Hovers),
-
-		dir:       dir,
-		fragments: map[string]string{},
-		golden:    map[string]*Golden{},
-		mode:      mode,
-		mappers:   map[span.URI]*protocol.ColumnMapper{},
-	}
-
-	if !*UpdateGolden {
-		summary := filepath.Join(filepath.FromSlash(dir), summaryFile+goldenFileSuffix)
-		if _, err := os.Stat(summary); os.IsNotExist(err) {
-			t.Fatalf("could not find golden file summary.txt in %#v", dir)
-		}
-		archive, err := txtar.ParseFile(summary)
-		if err != nil {
-			t.Fatalf("could not read golden file %v/%v: %v", dir, summary, err)
-		}
-		datum.golden[summaryFile] = &Golden{
-			Filename: summary,
-			Archive:  archive,
-		}
-	}
-
-	files := packagestest.MustCopyFileTree(dir)
-	// Prune test cases that exercise generics.
-	if !typeparams.Enabled {
-		for name := range files {
-			if strings.Contains(name, "_generics") {
-				delete(files, name)
-			}
-		}
-	}
-	overlays := map[string][]byte{}
-	for fragment, operation := range files {
-		if trimmed := strings.TrimSuffix(fragment, goldenFileSuffix); trimmed != fragment {
-			delete(files, fragment)
-			goldFile := filepath.Join(dir, fragment)
-			archive, err := txtar.ParseFile(goldFile)
-			if err != nil {
-				t.Fatalf("could not read golden file %v: %v", fragment, err)
-			}
-			datum.golden[trimmed] = &Golden{
-				Filename: goldFile,
-				Archive:  archive,
-			}
-		} else if trimmed := strings.TrimSuffix(fragment, inFileSuffix); trimmed != fragment {
-			delete(files, fragment)
-			files[trimmed] = operation
-		} else if index := strings.Index(fragment, overlayFileSuffix); index >= 0 {
-			delete(files, fragment)
-			partial := fragment[:index] + fragment[index+len(overlayFileSuffix):]
-			contents, err := ioutil.ReadFile(filepath.Join(dir, fragment))
-			if err != nil {
-				t.Fatal(err)
-			}
-			overlays[partial] = contents
-		}
-	}
-
-	modules := []packagestest.Module{
-		{
-			Name:    testModule,
-			Files:   files,
-			Overlay: overlays,
-		},
-	}
-	switch mode {
-	case "Modules":
-		datum.Exported = packagestest.Export(t, packagestest.Modules, modules)
-	case "GOPATH":
-		datum.Exported = packagestest.Export(t, packagestest.GOPATH, modules)
-	case "MultiModule":
-		files := map[string]interface{}{}
-		for k, v := range modules[0].Files {
-			files[filepath.Join("testmodule", k)] = v
-		}
-		modules[0].Files = files
-
-		overlays := map[string][]byte{}
-		for k, v := range modules[0].Overlay {
-			overlays[filepath.Join("testmodule", k)] = v
-		}
-		modules[0].Overlay = overlays
-
-		golden := map[string]*Golden{}
-		for k, v := range datum.golden {
-			if k == summaryFile {
-				golden[k] = v
-			} else {
-				golden[filepath.Join("testmodule", k)] = v
-			}
-		}
-		datum.golden = golden
-
-		datum.Exported = packagestest.Export(t, packagestest.Modules, modules)
-	default:
-		panic("unknown mode " + mode)
-	}
-
-	for _, m := range modules {
-		for fragment := range m.Files {
-			filename := datum.Exported.File(m.Name, fragment)
-			datum.fragments[filename] = fragment
-		}
-	}
-
-	// Turn off go/packages debug logging.
-	datum.Exported.Config.Logf = nil
-	datum.Config.Logf = nil
-
-	// Merge the exported.Config with the view.Config.
-	datum.Config = *datum.Exported.Config
-	datum.Config.Fset = token.NewFileSet()
-	datum.Config.Context = Context(nil)
-	datum.Config.ParseFile = func(fset *token.FileSet, filename string, src []byte) (*ast.File, error) {
-		panic("ParseFile should not be called")
-	}
-
-	// Do a first pass to collect special markers for completion and workspace symbols.
-	if err := datum.Exported.Expect(map[string]interface{}{
-		"item": func(name string, r packagestest.Range, _ []string) {
-			datum.Exported.Mark(name, r)
-		},
-		"symbol": func(name string, r packagestest.Range, _ []string) {
-			datum.Exported.Mark(name, r)
-		},
-	}); err != nil {
-		t.Fatal(err)
-	}
-
-	// Collect any data that needs to be used by subsequent tests.
-	if err := datum.Exported.Expect(map[string]interface{}{
-		"codelens":        datum.collectCodeLens,
-		"diag":            datum.collectDiagnostics,
-		"item":            datum.collectCompletionItems,
-		"complete":        datum.collectCompletions(CompletionDefault),
-		"unimported":      datum.collectCompletions(CompletionUnimported),
-		"deep":            datum.collectCompletions(CompletionDeep),
-		"fuzzy":           datum.collectCompletions(CompletionFuzzy),
-		"casesensitive":   datum.collectCompletions(CompletionCaseSensitive),
-		"rank":            datum.collectCompletions(CompletionRank),
-		"snippet":         datum.collectCompletionSnippets,
-		"fold":            datum.collectFoldingRanges,
-		"format":          datum.collectFormats,
-		"import":          datum.collectImports,
-		"semantic":        datum.collectSemanticTokens,
-		"godef":           datum.collectDefinitions,
-		"implementations": datum.collectImplementations,
-		"typdef":          datum.collectTypeDefinitions,
-		"hoverdef":        datum.collectHoverDefinitions,
-		"hover":           datum.collectHovers,
-		"highlight":       datum.collectHighlights,
-		"inlayHint":       datum.collectInlayHints,
-		"refs":            datum.collectReferences,
-		"rename":          datum.collectRenames,
-		"prepare":         datum.collectPrepareRenames,
-		"symbol":          datum.collectSymbols,
-		"signature":       datum.collectSignatures,
-		"link":            datum.collectLinks,
-		"suggestedfix":    datum.collectSuggestedFixes,
-		"extractfunc":     datum.collectFunctionExtractions,
-		"extractmethod":   datum.collectMethodExtractions,
-		"incomingcalls":   datum.collectIncomingCalls,
-		"outgoingcalls":   datum.collectOutgoingCalls,
-		"addimport":       datum.collectAddImports,
-		"selectionrange":  datum.collectSelectionRanges,
-	}); err != nil {
-		t.Fatal(err)
-	}
-
-	// Collect names for the entries that require golden files.
-	if err := datum.Exported.Expect(map[string]interface{}{
-		"godef":                        datum.collectDefinitionNames,
-		"hoverdef":                     datum.collectDefinitionNames,
-		"workspacesymbol":              datum.collectWorkspaceSymbols(WorkspaceSymbolsDefault),
-		"workspacesymbolfuzzy":         datum.collectWorkspaceSymbols(WorkspaceSymbolsFuzzy),
-		"workspacesymbolcasesensitive": datum.collectWorkspaceSymbols(WorkspaceSymbolsCaseSensitive),
-	}); err != nil {
-		t.Fatal(err)
-	}
-	if mode == "MultiModule" {
-		if err := moveFile(filepath.Join(datum.Config.Dir, "go.mod"), filepath.Join(datum.Config.Dir, "testmodule/go.mod")); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	return datum
-}
-
-// moveFile moves the file at oldpath to newpath, by renaming if possible
-// or copying otherwise.
-func moveFile(oldpath, newpath string) (err error) {
-	renameErr := os.Rename(oldpath, newpath)
-	if renameErr == nil {
-		return nil
-	}
-
-	src, err := os.Open(oldpath)
-	if err != nil {
-		return err
-	}
-	defer func() {
-		src.Close()
-		if err == nil {
-			err = os.Remove(oldpath)
-		}
-	}()
-
-	perm := os.ModePerm
-	fi, err := src.Stat()
-	if err == nil {
-		perm = fi.Mode().Perm()
-	}
-
-	dst, err := os.OpenFile(newpath, os.O_WRONLY|os.O_CREATE|os.O_EXCL, perm)
-	if err != nil {
-		return err
-	}
-
-	_, err = io.Copy(dst, src)
-	if closeErr := dst.Close(); err == nil {
-		err = closeErr
-	}
-	return err
-}
-
-func Run(t *testing.T, tests Tests, data *Data) {
-	t.Helper()
-	checkData(t, data)
-
-	eachCompletion := func(t *testing.T, cases map[span.Span][]Completion, test func(*testing.T, span.Span, Completion, CompletionItems)) {
-		t.Helper()
-
-		for src, exp := range cases {
-			for i, e := range exp {
-				t.Run(SpanName(src)+"_"+strconv.Itoa(i), func(t *testing.T) {
-					t.Helper()
-					if strings.Contains(t.Name(), "cgo") {
-						testenv.NeedsTool(t, "cgo")
-					}
-					test(t, src, e, data.CompletionItems)
-				})
-			}
-
-		}
-	}
-
-	t.Run("CallHierarchy", func(t *testing.T) {
-		t.Helper()
-		for spn, callHierarchyResult := range data.CallHierarchy {
-			t.Run(SpanName(spn), func(t *testing.T) {
-				t.Helper()
-				tests.CallHierarchy(t, spn, callHierarchyResult)
-			})
-		}
-	})
-
-	t.Run("Completion", func(t *testing.T) {
-		t.Helper()
-		eachCompletion(t, data.Completions, tests.Completion)
-	})
-
-	t.Run("CompletionSnippets", func(t *testing.T) {
-		t.Helper()
-		for _, placeholders := range []bool{true, false} {
-			for src, expecteds := range data.CompletionSnippets {
-				for i, expected := range expecteds {
-					name := SpanName(src) + "_" + strconv.Itoa(i+1)
-					if placeholders {
-						name += "_placeholders"
-					}
-
-					t.Run(name, func(t *testing.T) {
-						t.Helper()
-						tests.CompletionSnippet(t, src, expected, placeholders, data.CompletionItems)
-					})
-				}
-			}
-		}
-	})
-
-	t.Run("UnimportedCompletion", func(t *testing.T) {
-		t.Helper()
-		eachCompletion(t, data.UnimportedCompletions, tests.UnimportedCompletion)
-	})
-
-	t.Run("DeepCompletion", func(t *testing.T) {
-		t.Helper()
-		eachCompletion(t, data.DeepCompletions, tests.DeepCompletion)
-	})
-
-	t.Run("FuzzyCompletion", func(t *testing.T) {
-		t.Helper()
-		eachCompletion(t, data.FuzzyCompletions, tests.FuzzyCompletion)
-	})
-
-	t.Run("CaseSensitiveCompletion", func(t *testing.T) {
-		t.Helper()
-		eachCompletion(t, data.CaseSensitiveCompletions, tests.CaseSensitiveCompletion)
-	})
-
-	t.Run("RankCompletions", func(t *testing.T) {
-		t.Helper()
-		eachCompletion(t, data.RankCompletions, tests.RankCompletion)
-	})
-
-	t.Run("CodeLens", func(t *testing.T) {
-		t.Helper()
-		for uri, want := range data.CodeLens {
-			// Check if we should skip this URI if the -modfile flag is not available.
-			if shouldSkip(data, uri) {
-				continue
-			}
-			t.Run(uriName(uri), func(t *testing.T) {
-				t.Helper()
-				tests.CodeLens(t, uri, want)
-			})
-		}
-	})
-
-	t.Run("Diagnostics", func(t *testing.T) {
-		t.Helper()
-		for uri, want := range data.Diagnostics {
-			// Check if we should skip this URI if the -modfile flag is not available.
-			if shouldSkip(data, uri) {
-				continue
-			}
-			t.Run(uriName(uri), func(t *testing.T) {
-				t.Helper()
-				tests.Diagnostics(t, uri, want)
-			})
-		}
-	})
-
-	t.Run("FoldingRange", func(t *testing.T) {
-		t.Helper()
-		for _, spn := range data.FoldingRanges {
-			t.Run(uriName(spn.URI()), func(t *testing.T) {
-				t.Helper()
-				tests.FoldingRanges(t, spn)
-			})
-		}
-	})
-
-	t.Run("Format", func(t *testing.T) {
-		t.Helper()
-		for _, spn := range data.Formats {
-			t.Run(uriName(spn.URI()), func(t *testing.T) {
-				t.Helper()
-				tests.Format(t, spn)
-			})
-		}
-	})
-
-	t.Run("Import", func(t *testing.T) {
-		t.Helper()
-		for _, spn := range data.Imports {
-			t.Run(uriName(spn.URI()), func(t *testing.T) {
-				t.Helper()
-				tests.Import(t, spn)
-			})
-		}
-	})
-
-	t.Run("SemanticTokens", func(t *testing.T) {
-		t.Helper()
-		for _, spn := range data.SemanticTokens {
-			t.Run(uriName(spn.URI()), func(t *testing.T) {
-				t.Helper()
-				tests.SemanticTokens(t, spn)
-			})
-		}
-	})
-
-	t.Run("SuggestedFix", func(t *testing.T) {
-		t.Helper()
-		for spn, actionKinds := range data.SuggestedFixes {
-			// Check if we should skip this spn if the -modfile flag is not available.
-			if shouldSkip(data, spn.URI()) {
-				continue
-			}
-			t.Run(SpanName(spn), func(t *testing.T) {
-				t.Helper()
-				tests.SuggestedFix(t, spn, actionKinds, 1)
-			})
-		}
-	})
-
-	t.Run("FunctionExtraction", func(t *testing.T) {
-		t.Helper()
-		for start, end := range data.FunctionExtractions {
-			// Check if we should skip this spn if the -modfile flag is not available.
-			if shouldSkip(data, start.URI()) {
-				continue
-			}
-			t.Run(SpanName(start), func(t *testing.T) {
-				t.Helper()
-				tests.FunctionExtraction(t, start, end)
-			})
-		}
-	})
-
-	t.Run("MethodExtraction", func(t *testing.T) {
-		t.Helper()
-		for start, end := range data.MethodExtractions {
-			// Check if we should skip this spn if the -modfile flag is not available.
-			if shouldSkip(data, start.URI()) {
-				continue
-			}
-			t.Run(SpanName(start), func(t *testing.T) {
-				t.Helper()
-				tests.MethodExtraction(t, start, end)
-			})
-		}
-	})
-
-	t.Run("Definition", func(t *testing.T) {
-		t.Helper()
-		for spn, d := range data.Definitions {
-			t.Run(SpanName(spn), func(t *testing.T) {
-				t.Helper()
-				if strings.Contains(t.Name(), "cgo") {
-					testenv.NeedsTool(t, "cgo")
-				}
-				tests.Definition(t, spn, d)
-			})
-		}
-	})
-
-	t.Run("Implementation", func(t *testing.T) {
-		t.Helper()
-		for spn, m := range data.Implementations {
-			t.Run(SpanName(spn), func(t *testing.T) {
-				t.Helper()
-				tests.Implementation(t, spn, m)
-			})
-		}
-	})
-
-	t.Run("Highlight", func(t *testing.T) {
-		t.Helper()
-		for pos, locations := range data.Highlights {
-			t.Run(SpanName(pos), func(t *testing.T) {
-				t.Helper()
-				tests.Highlight(t, pos, locations)
-			})
-		}
-	})
-
-	t.Run("Hover", func(t *testing.T) {
-		t.Helper()
-		for pos, info := range data.Hovers {
-			t.Run(SpanName(pos), func(t *testing.T) {
-				t.Helper()
-				tests.Hover(t, pos, info)
-			})
-		}
-	})
-
-	t.Run("InlayHints", func(t *testing.T) {
-		t.Helper()
-		for _, src := range data.InlayHints {
-			t.Run(SpanName(src), func(t *testing.T) {
-				t.Helper()
-				tests.InlayHints(t, src)
-			})
-		}
-	})
-
-	t.Run("References", func(t *testing.T) {
-		t.Helper()
-		for src, itemList := range data.References {
-			t.Run(SpanName(src), func(t *testing.T) {
-				t.Helper()
-				tests.References(t, src, itemList)
-			})
-		}
-	})
-
-	t.Run("Renames", func(t *testing.T) {
-		t.Helper()
-		for spn, newText := range data.Renames {
-			t.Run(uriName(spn.URI())+"_"+newText, func(t *testing.T) {
-				t.Helper()
-				tests.Rename(t, spn, newText)
-			})
-		}
-	})
-
-	t.Run("PrepareRenames", func(t *testing.T) {
-		t.Helper()
-		for src, want := range data.PrepareRenames {
-			t.Run(SpanName(src), func(t *testing.T) {
-				t.Helper()
-				tests.PrepareRename(t, src, want)
-			})
-		}
-	})
-
-	t.Run("Symbols", func(t *testing.T) {
-		t.Helper()
-		for uri, allSymbols := range data.Symbols {
-			byParent := make(map[string][]*symbol)
-			for _, sym := range allSymbols {
-				if sym.parentID != "" {
-					byParent[sym.parentID] = append(byParent[sym.parentID], sym)
-				}
-			}
-
-			// collectChildren does a depth-first traversal of the symbol tree,
-			// computing children of child nodes before returning to their parent.
-			// This is necessary as the Children field is slice of non-pointer types,
-			// and therefore we need to be careful to mutate children first before
-			// assigning them to their parent.
-			var collectChildren func(id string) []protocol.DocumentSymbol
-			collectChildren = func(id string) []protocol.DocumentSymbol {
-				children := byParent[id]
-				// delete from byParent before recursing, to ensure that
-				// collectChildren terminates even in the presence of cycles.
-				delete(byParent, id)
-				var result []protocol.DocumentSymbol
-				for _, child := range children {
-					child.pSymbol.Children = collectChildren(child.id)
-					result = append(result, child.pSymbol)
-				}
-				return result
-			}
-
-			var topLevel []protocol.DocumentSymbol
-			for _, sym := range allSymbols {
-				if sym.parentID == "" {
-					sym.pSymbol.Children = collectChildren(sym.id)
-					topLevel = append(topLevel, sym.pSymbol)
-				}
-			}
-
-			t.Run(uriName(uri), func(t *testing.T) {
-				t.Helper()
-				tests.Symbols(t, uri, topLevel)
-			})
-		}
-	})
-
-	t.Run("WorkspaceSymbols", func(t *testing.T) {
-		t.Helper()
-
-		for _, typ := range []WorkspaceSymbolsTestType{
-			WorkspaceSymbolsDefault,
-			WorkspaceSymbolsCaseSensitive,
-			WorkspaceSymbolsFuzzy,
-		} {
-			for uri, cases := range data.WorkspaceSymbols[typ] {
-				for _, query := range cases {
-					name := query
-					if name == "" {
-						name = "EmptyQuery"
-					}
-					t.Run(name, func(t *testing.T) {
-						t.Helper()
-						tests.WorkspaceSymbols(t, uri, query, typ)
-					})
-				}
-			}
-		}
-
-	})
-
-	t.Run("SignatureHelp", func(t *testing.T) {
-		t.Helper()
-		for spn, expectedSignature := range data.Signatures {
-			t.Run(SpanName(spn), func(t *testing.T) {
-				t.Helper()
-				tests.SignatureHelp(t, spn, expectedSignature)
-			})
-		}
-	})
-
-	t.Run("Link", func(t *testing.T) {
-		t.Helper()
-		for uri, wantLinks := range data.Links {
-			// If we are testing GOPATH, then we do not want links with the versions
-			// attached (pkg.go.dev/repoa/moda@v1.1.0/pkg), unless the file is a
-			// go.mod, then we can skip it altogether.
-			if data.Exported.Exporter == packagestest.GOPATH {
-				if strings.HasSuffix(uri.Filename(), ".mod") {
-					continue
-				}
-				re := regexp.MustCompile(`@v\d+\.\d+\.[\w-]+`)
-				for i, link := range wantLinks {
-					wantLinks[i].Target = re.ReplaceAllString(link.Target, "")
-				}
-			}
-			t.Run(uriName(uri), func(t *testing.T) {
-				t.Helper()
-				tests.Link(t, uri, wantLinks)
-			})
-		}
-	})
-
-	t.Run("AddImport", func(t *testing.T) {
-		t.Helper()
-		for uri, exp := range data.AddImport {
-			t.Run(uriName(uri), func(t *testing.T) {
-				tests.AddImport(t, uri, exp)
-			})
-		}
-	})
-
-	t.Run("SelectionRanges", func(t *testing.T) {
-		t.Helper()
-		for _, span := range data.SelectionRanges {
-			t.Run(SpanName(span), func(t *testing.T) {
-				tests.SelectionRanges(t, span)
-			})
-		}
-	})
-
-	if *UpdateGolden {
-		for _, golden := range data.golden {
-			if !golden.Modified {
-				continue
-			}
-			sort.Slice(golden.Archive.Files, func(i, j int) bool {
-				return golden.Archive.Files[i].Name < golden.Archive.Files[j].Name
-			})
-			if err := ioutil.WriteFile(golden.Filename, txtar.Format(golden.Archive), 0666); err != nil {
-				t.Fatal(err)
-			}
-		}
-	}
-}
-
-func checkData(t *testing.T, data *Data) {
-	buf := &bytes.Buffer{}
-	diagnosticsCount := 0
-	for _, want := range data.Diagnostics {
-		diagnosticsCount += len(want)
-	}
-	linksCount := 0
-	for _, want := range data.Links {
-		linksCount += len(want)
-	}
-	definitionCount := 0
-	typeDefinitionCount := 0
-	for _, d := range data.Definitions {
-		if d.IsType {
-			typeDefinitionCount++
-		} else {
-			definitionCount++
-		}
-	}
-
-	snippetCount := 0
-	for _, want := range data.CompletionSnippets {
-		snippetCount += len(want)
-	}
-
-	countCompletions := func(c map[span.Span][]Completion) (count int) {
-		for _, want := range c {
-			count += len(want)
-		}
-		return count
-	}
-
-	countCodeLens := func(c map[span.URI][]protocol.CodeLens) (count int) {
-		for _, want := range c {
-			count += len(want)
-		}
-		return count
-	}
-
-	countWorkspaceSymbols := func(c map[WorkspaceSymbolsTestType]map[span.URI][]string) (count int) {
-		for _, typs := range c {
-			for _, queries := range typs {
-				count += len(queries)
-			}
-		}
-		return count
-	}
-
-	fmt.Fprintf(buf, "CallHierarchyCount = %v\n", len(data.CallHierarchy))
-	fmt.Fprintf(buf, "CodeLensCount = %v\n", countCodeLens(data.CodeLens))
-	fmt.Fprintf(buf, "CompletionsCount = %v\n", countCompletions(data.Completions))
-	fmt.Fprintf(buf, "CompletionSnippetCount = %v\n", snippetCount)
-	fmt.Fprintf(buf, "UnimportedCompletionsCount = %v\n", countCompletions(data.UnimportedCompletions))
-	fmt.Fprintf(buf, "DeepCompletionsCount = %v\n", countCompletions(data.DeepCompletions))
-	fmt.Fprintf(buf, "FuzzyCompletionsCount = %v\n", countCompletions(data.FuzzyCompletions))
-	fmt.Fprintf(buf, "RankedCompletionsCount = %v\n", countCompletions(data.RankCompletions))
-	fmt.Fprintf(buf, "CaseSensitiveCompletionsCount = %v\n", countCompletions(data.CaseSensitiveCompletions))
-	fmt.Fprintf(buf, "DiagnosticsCount = %v\n", diagnosticsCount)
-	fmt.Fprintf(buf, "FoldingRangesCount = %v\n", len(data.FoldingRanges))
-	fmt.Fprintf(buf, "FormatCount = %v\n", len(data.Formats))
-	fmt.Fprintf(buf, "ImportCount = %v\n", len(data.Imports))
-	fmt.Fprintf(buf, "SemanticTokenCount = %v\n", len(data.SemanticTokens))
-	fmt.Fprintf(buf, "SuggestedFixCount = %v\n", len(data.SuggestedFixes))
-	fmt.Fprintf(buf, "FunctionExtractionCount = %v\n", len(data.FunctionExtractions))
-	fmt.Fprintf(buf, "MethodExtractionCount = %v\n", len(data.MethodExtractions))
-	fmt.Fprintf(buf, "DefinitionsCount = %v\n", definitionCount)
-	fmt.Fprintf(buf, "TypeDefinitionsCount = %v\n", typeDefinitionCount)
-	fmt.Fprintf(buf, "HighlightsCount = %v\n", len(data.Highlights))
-	fmt.Fprintf(buf, "InlayHintsCount = %v\n", len(data.InlayHints))
-	fmt.Fprintf(buf, "ReferencesCount = %v\n", len(data.References))
-	fmt.Fprintf(buf, "RenamesCount = %v\n", len(data.Renames))
-	fmt.Fprintf(buf, "PrepareRenamesCount = %v\n", len(data.PrepareRenames))
-	fmt.Fprintf(buf, "SymbolsCount = %v\n", len(data.Symbols))
-	fmt.Fprintf(buf, "WorkspaceSymbolsCount = %v\n", countWorkspaceSymbols(data.WorkspaceSymbols))
-	fmt.Fprintf(buf, "SignaturesCount = %v\n", len(data.Signatures))
-	fmt.Fprintf(buf, "LinksCount = %v\n", linksCount)
-	fmt.Fprintf(buf, "ImplementationsCount = %v\n", len(data.Implementations))
-	fmt.Fprintf(buf, "SelectionRangesCount = %v\n", len(data.SelectionRanges))
-
-	want := string(data.Golden(t, "summary", summaryFile, func() ([]byte, error) {
-		return buf.Bytes(), nil
-	}))
-	got := buf.String()
-	if want != got {
-		// These counters change when assertions are added or removed.
-		// They act as an independent safety net to ensure that the
-		// tests didn't spuriously pass because they did no work.
-		t.Errorf("test summary does not match:\n%s\n(Run with -golden to update golden file; also, there may be one per Go version.)", compare.Text(want, got))
-	}
-}
-
-func (data *Data) Mapper(uri span.URI) (*protocol.ColumnMapper, error) {
-	data.mappersMu.Lock()
-	defer data.mappersMu.Unlock()
-
-	if _, ok := data.mappers[uri]; !ok {
-		content, err := data.Exported.FileContents(uri.Filename())
-		if err != nil {
-			return nil, err
-		}
-		data.mappers[uri] = protocol.NewColumnMapper(uri, content)
-	}
-	return data.mappers[uri], nil
-}
-
-func (data *Data) Golden(t *testing.T, tag, target string, update func() ([]byte, error)) []byte {
-	t.Helper()
-	fragment, found := data.fragments[target]
-	if !found {
-		if filepath.IsAbs(target) {
-			t.Fatalf("invalid golden file fragment %v", target)
-		}
-		fragment = target
-	}
-	golden := data.golden[fragment]
-	if golden == nil {
-		if !*UpdateGolden {
-			t.Fatalf("could not find golden file %v: %v", fragment, tag)
-		}
-		golden = &Golden{
-			Filename: filepath.Join(data.dir, fragment+goldenFileSuffix),
-			Archive:  &txtar.Archive{},
-			Modified: true,
-		}
-		data.golden[fragment] = golden
-	}
-	var file *txtar.File
-	for i := range golden.Archive.Files {
-		f := &golden.Archive.Files[i]
-		if f.Name == tag {
-			file = f
-			break
-		}
-	}
-	if *UpdateGolden {
-		if file == nil {
-			golden.Archive.Files = append(golden.Archive.Files, txtar.File{
-				Name: tag,
-			})
-			file = &golden.Archive.Files[len(golden.Archive.Files)-1]
-		}
-		contents, err := update()
-		if err != nil {
-			t.Fatalf("could not update golden file %v: %v", fragment, err)
-		}
-		file.Data = append(contents, '\n') // add trailing \n for txtar
-		golden.Modified = true
-
-	}
-	if file == nil {
-		t.Fatalf("could not find golden contents %v: %v", fragment, tag)
-	}
-	if len(file.Data) == 0 {
-		return file.Data
-	}
-	return file.Data[:len(file.Data)-1] // drop the trailing \n
-}
-
-func (data *Data) collectCodeLens(spn span.Span, title, cmd string) {
-	data.CodeLens[spn.URI()] = append(data.CodeLens[spn.URI()], protocol.CodeLens{
-		Range: data.mustRange(spn),
-		Command: protocol.Command{
-			Title:   title,
-			Command: cmd,
-		},
-	})
-}
-
-func (data *Data) collectDiagnostics(spn span.Span, msgSource, msgPattern, msgSeverity string) {
-	severity := protocol.SeverityError
-	switch msgSeverity {
-	case "error":
-		severity = protocol.SeverityError
-	case "warning":
-		severity = protocol.SeverityWarning
-	case "hint":
-		severity = protocol.SeverityHint
-	case "information":
-		severity = protocol.SeverityInformation
-	}
-
-	data.Diagnostics[spn.URI()] = append(data.Diagnostics[spn.URI()], &source.Diagnostic{
-		Range:    data.mustRange(spn),
-		Severity: severity,
-		Source:   source.DiagnosticSource(msgSource),
-		Message:  msgPattern,
-	})
-}
-
-func (data *Data) collectCompletions(typ CompletionTestType) func(span.Span, []token.Pos) {
-	result := func(m map[span.Span][]Completion, src span.Span, expected []token.Pos) {
-		m[src] = append(m[src], Completion{
-			CompletionItems: expected,
-		})
-	}
-	switch typ {
-	case CompletionDeep:
-		return func(src span.Span, expected []token.Pos) {
-			result(data.DeepCompletions, src, expected)
-		}
-	case CompletionUnimported:
-		return func(src span.Span, expected []token.Pos) {
-			result(data.UnimportedCompletions, src, expected)
-		}
-	case CompletionFuzzy:
-		return func(src span.Span, expected []token.Pos) {
-			result(data.FuzzyCompletions, src, expected)
-		}
-	case CompletionRank:
-		return func(src span.Span, expected []token.Pos) {
-			result(data.RankCompletions, src, expected)
-		}
-	case CompletionCaseSensitive:
-		return func(src span.Span, expected []token.Pos) {
-			result(data.CaseSensitiveCompletions, src, expected)
-		}
-	default:
-		return func(src span.Span, expected []token.Pos) {
-			result(data.Completions, src, expected)
-		}
-	}
-}
-
-func (data *Data) collectCompletionItems(pos token.Pos, label, detail, kind string, args []string) {
-	var documentation string
-	if len(args) > 3 {
-		documentation = args[3]
-	}
-	data.CompletionItems[pos] = &completion.CompletionItem{
-		Label:         label,
-		Detail:        detail,
-		Kind:          protocol.ParseCompletionItemKind(kind),
-		Documentation: documentation,
-	}
-}
-
-func (data *Data) collectFoldingRanges(spn span.Span) {
-	data.FoldingRanges = append(data.FoldingRanges, spn)
-}
-
-func (data *Data) collectFormats(spn span.Span) {
-	data.Formats = append(data.Formats, spn)
-}
-
-func (data *Data) collectImports(spn span.Span) {
-	data.Imports = append(data.Imports, spn)
-}
-
-func (data *Data) collectAddImports(spn span.Span, imp string) {
-	data.AddImport[spn.URI()] = imp
-}
-
-func (data *Data) collectSemanticTokens(spn span.Span) {
-	data.SemanticTokens = append(data.SemanticTokens, spn)
-}
-
-func (data *Data) collectSuggestedFixes(spn span.Span, actionKind, fix string) {
-	data.SuggestedFixes[spn] = append(data.SuggestedFixes[spn], SuggestedFix{actionKind, fix})
-}
-
-func (data *Data) collectFunctionExtractions(start span.Span, end span.Span) {
-	if _, ok := data.FunctionExtractions[start]; !ok {
-		data.FunctionExtractions[start] = end
-	}
-}
-
-func (data *Data) collectMethodExtractions(start span.Span, end span.Span) {
-	if _, ok := data.MethodExtractions[start]; !ok {
-		data.MethodExtractions[start] = end
-	}
-}
-
-func (data *Data) collectDefinitions(src, target span.Span) {
-	data.Definitions[src] = Definition{
-		Src: src,
-		Def: target,
-	}
-}
-
-func (data *Data) collectSelectionRanges(spn span.Span) {
-	data.SelectionRanges = append(data.SelectionRanges, spn)
-}
-
-func (data *Data) collectImplementations(src span.Span, targets []span.Span) {
-	data.Implementations[src] = targets
-}
-
-func (data *Data) collectIncomingCalls(src span.Span, calls []span.Span) {
-	for _, call := range calls {
-		rng := data.mustRange(call)
-		// we're only comparing protocol.range
-		if data.CallHierarchy[src] != nil {
-			data.CallHierarchy[src].IncomingCalls = append(data.CallHierarchy[src].IncomingCalls,
-				protocol.CallHierarchyItem{
-					URI:   protocol.DocumentURI(call.URI()),
-					Range: rng,
-				})
-		} else {
-			data.CallHierarchy[src] = &CallHierarchyResult{
-				IncomingCalls: []protocol.CallHierarchyItem{
-					{URI: protocol.DocumentURI(call.URI()), Range: rng},
-				},
-			}
-		}
-	}
-}
-
-func (data *Data) collectOutgoingCalls(src span.Span, calls []span.Span) {
-	if data.CallHierarchy[src] == nil {
-		data.CallHierarchy[src] = &CallHierarchyResult{}
-	}
-	for _, call := range calls {
-		// we're only comparing protocol.range
-		data.CallHierarchy[src].OutgoingCalls = append(data.CallHierarchy[src].OutgoingCalls,
-			protocol.CallHierarchyItem{
-				URI:   protocol.DocumentURI(call.URI()),
-				Range: data.mustRange(call),
-			})
-	}
-}
-
-func (data *Data) collectHoverDefinitions(src, target span.Span) {
-	data.Definitions[src] = Definition{
-		Src:       src,
-		Def:       target,
-		OnlyHover: true,
-	}
-}
-
-func (data *Data) collectHovers(src span.Span, expected string) {
-	data.Hovers[src] = expected
-}
-
-func (data *Data) collectTypeDefinitions(src, target span.Span) {
-	data.Definitions[src] = Definition{
-		Src:    src,
-		Def:    target,
-		IsType: true,
-	}
-}
-
-func (data *Data) collectDefinitionNames(src span.Span, name string) {
-	d := data.Definitions[src]
-	d.Name = name
-	data.Definitions[src] = d
-}
-
-func (data *Data) collectHighlights(src span.Span, expected []span.Span) {
-	// Declaring a highlight in a test file: @highlight(src, expected1, expected2)
-	data.Highlights[src] = append(data.Highlights[src], expected...)
-}
-
-func (data *Data) collectInlayHints(src span.Span) {
-	data.InlayHints = append(data.InlayHints, src)
-}
-
-func (data *Data) collectReferences(src span.Span, expected []span.Span) {
-	data.References[src] = expected
-}
-
-func (data *Data) collectRenames(src span.Span, newText string) {
-	data.Renames[src] = newText
-}
-
-func (data *Data) collectPrepareRenames(src, spn span.Span, placeholder string) {
-	data.PrepareRenames[src] = &source.PrepareItem{
-		Range: data.mustRange(spn),
-		Text:  placeholder,
-	}
-}
-
-// collectSymbols is responsible for collecting @symbol annotations.
-func (data *Data) collectSymbols(name string, selectionRng span.Span, kind, detail, id, parentID string) {
-	// We don't set 'Range' here as it is difficult (impossible?) to express
-	// multi-line ranges in the packagestest framework.
-	uri := selectionRng.URI()
-	data.Symbols[uri] = append(data.Symbols[uri], &symbol{
-		pSymbol: protocol.DocumentSymbol{
-			Name:           name,
-			Kind:           protocol.ParseSymbolKind(kind),
-			SelectionRange: data.mustRange(selectionRng),
-			Detail:         detail,
-		},
-		id:       id,
-		parentID: parentID,
-	})
-}
-
-// mustRange converts spn into a protocol.Range, panicking on any error.
-func (data *Data) mustRange(spn span.Span) protocol.Range {
-	m, err := data.Mapper(spn.URI())
-	rng, err := m.Range(spn)
-	if err != nil {
-		panic(fmt.Sprintf("converting span %s to range: %v", spn, err))
-	}
-	return rng
-}
-
-func (data *Data) collectWorkspaceSymbols(typ WorkspaceSymbolsTestType) func(*expect.Note, string) {
-	return func(note *expect.Note, query string) {
-		if data.WorkspaceSymbols[typ] == nil {
-			data.WorkspaceSymbols[typ] = make(map[span.URI][]string)
-		}
-		pos := safetoken.StartPosition(data.Exported.ExpectFileSet, note.Pos)
-		uri := span.URIFromPath(pos.Filename)
-		data.WorkspaceSymbols[typ][uri] = append(data.WorkspaceSymbols[typ][uri], query)
-	}
-}
-
-func (data *Data) collectSignatures(spn span.Span, signature string, activeParam int64) {
-	data.Signatures[spn] = &protocol.SignatureHelp{
-		Signatures: []protocol.SignatureInformation{
-			{
-				Label: signature,
-			},
-		},
-		ActiveParameter: uint32(activeParam),
-	}
-	// Hardcode special case to test the lack of a signature.
-	if signature == "" && activeParam == 0 {
-		data.Signatures[spn] = nil
-	}
-}
-
-func (data *Data) collectCompletionSnippets(spn span.Span, item token.Pos, plain, placeholder string) {
-	data.CompletionSnippets[spn] = append(data.CompletionSnippets[spn], CompletionSnippet{
-		CompletionItem:     item,
-		PlainSnippet:       plain,
-		PlaceholderSnippet: placeholder,
-	})
-}
-
-func (data *Data) collectLinks(spn span.Span, link string, note *expect.Note, fset *token.FileSet) {
-	position := safetoken.StartPosition(fset, note.Pos)
-	uri := spn.URI()
-	data.Links[uri] = append(data.Links[uri], Link{
-		Src:          spn,
-		Target:       link,
-		NotePosition: position,
-	})
-}
-
-func uriName(uri span.URI) string {
-	return filepath.Base(strings.TrimSuffix(uri.Filename(), ".go"))
-}
-
-// TODO(golang/go#54845): improve the formatting here to match standard
-// line:column position formatting.
-func SpanName(spn span.Span) string {
-	return fmt.Sprintf("%v_%v_%v", uriName(spn.URI()), spn.Start().Line(), spn.Start().Column())
-}
-
-func CopyFolderToTempDir(folder string) (string, error) {
-	if _, err := os.Stat(folder); err != nil {
-		return "", err
-	}
-	dst, err := ioutil.TempDir("", "modfile_test")
-	if err != nil {
-		return "", err
-	}
-	fds, err := ioutil.ReadDir(folder)
-	if err != nil {
-		return "", err
-	}
-	for _, fd := range fds {
-		srcfp := filepath.Join(folder, fd.Name())
-		stat, err := os.Stat(srcfp)
-		if err != nil {
-			return "", err
-		}
-		if !stat.Mode().IsRegular() {
-			return "", fmt.Errorf("cannot copy non regular file %s", srcfp)
-		}
-		contents, err := ioutil.ReadFile(srcfp)
-		if err != nil {
-			return "", err
-		}
-		if err := ioutil.WriteFile(filepath.Join(dst, fd.Name()), contents, stat.Mode()); err != nil {
-			return "", err
-		}
-	}
-	return dst, nil
-}
-
-func shouldSkip(data *Data, uri span.URI) bool {
-	if data.ModfileFlagAvailable {
-		return false
-	}
-	// If the -modfile flag is not available, then we do not want to run
-	// any tests on the go.mod file.
-	if strings.HasSuffix(uri.Filename(), ".mod") {
-		return true
-	}
-	// If the -modfile flag is not available, then we do not want to test any
-	// uri that contains "go mod tidy".
-	m, err := data.Mapper(uri)
-	return err == nil && strings.Contains(string(m.Content), ", \"go mod tidy\",")
-}
diff -urN a/gopls/internal/lsp/tests/util.go b/gopls/internal/lsp/tests/util.go
--- a/gopls/internal/lsp/tests/util.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/tests/util.go	1969-12-31 16:00:00
@@ -1,549 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package tests
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/token"
-	"path"
-	"path/filepath"
-	"regexp"
-	"sort"
-	"strconv"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/source/completion"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// DiffLinks takes the links we got and checks if they are located within the source or a Note.
-// If the link is within a Note, the link is removed.
-// Returns an diff comment if there are differences and empty string if no diffs.
-func DiffLinks(mapper *protocol.ColumnMapper, wantLinks []Link, gotLinks []protocol.DocumentLink) string {
-	var notePositions []token.Position
-	links := make(map[span.Span]string, len(wantLinks))
-	for _, link := range wantLinks {
-		links[link.Src] = link.Target
-		notePositions = append(notePositions, link.NotePosition)
-	}
-
-	var msg strings.Builder
-	for _, link := range gotLinks {
-		spn, err := mapper.RangeSpan(link.Range)
-		if err != nil {
-			return fmt.Sprintf("%v", err)
-		}
-		linkInNote := false
-		for _, notePosition := range notePositions {
-			// Drop the links found inside expectation notes arguments as this links are not collected by expect package.
-			if notePosition.Line == spn.Start().Line() &&
-				notePosition.Column <= spn.Start().Column() {
-				delete(links, spn)
-				linkInNote = true
-			}
-		}
-		if linkInNote {
-			continue
-		}
-
-		if target, ok := links[spn]; ok {
-			delete(links, spn)
-			if target != link.Target {
-				fmt.Fprintf(&msg, "%s: want link with target %q, got %q\n", spn, target, link.Target)
-			}
-		} else {
-			fmt.Fprintf(&msg, "%s: got unexpected link with target %q\n", spn, link.Target)
-		}
-	}
-	for spn, target := range links {
-		fmt.Fprintf(&msg, "%s: expected link with target %q is missing\n", spn, target)
-	}
-	return msg.String()
-}
-
-// CompareDiagnostics reports testing errors to t when the diagnostic set got
-// does not match want. If the sole expectation has source "no_diagnostics",
-// the test expects that no diagnostics were received for the given document.
-func CompareDiagnostics(t *testing.T, uri span.URI, want, got []*source.Diagnostic) {
-	t.Helper()
-	fileName := path.Base(string(uri))
-
-	// A special case to test that there are no diagnostics for a file.
-	if len(want) == 1 && want[0].Source == "no_diagnostics" {
-		want = nil
-	}
-
-	// Build a helper function to match an actual diagnostic to an overlapping
-	// expected diagnostic (if any).
-	unmatched := make([]*source.Diagnostic, len(want))
-	copy(unmatched, want)
-	source.SortDiagnostics(unmatched)
-	match := func(g *source.Diagnostic) *source.Diagnostic {
-		// Find the last expected diagnostic d for which start(d) < end(g), and
-		// check to see if it overlaps.
-		i := sort.Search(len(unmatched), func(i int) bool {
-			d := unmatched[i]
-			// See rangeOverlaps: if a range is a single point, we consider End to be
-			// included in the range...
-			if g.Range.Start == g.Range.End {
-				return protocol.ComparePosition(d.Range.Start, g.Range.End) > 0
-			}
-			// ...otherwise the end position of a range is not included.
-			return protocol.ComparePosition(d.Range.Start, g.Range.End) >= 0
-		})
-		if i == 0 {
-			return nil
-		}
-		w := unmatched[i-1]
-		if rangeOverlaps(w.Range, g.Range) {
-			unmatched = append(unmatched[:i-1], unmatched[i:]...)
-			return w
-		}
-		return nil
-	}
-
-	for _, g := range got {
-		w := match(g)
-		if w == nil {
-			t.Errorf("%s:%s: unexpected diagnostic %q", fileName, g.Range, g.Message)
-			continue
-		}
-		if match, err := regexp.MatchString(w.Message, g.Message); err != nil {
-			t.Errorf("%s:%s: invalid regular expression %q: %v", fileName, w.Range.Start, w.Message, err)
-		} else if !match {
-			t.Errorf("%s:%s: got Message %q, want match for pattern %q", fileName, g.Range.Start, g.Message, w.Message)
-		}
-		if w.Severity != g.Severity {
-			t.Errorf("%s:%s: got Severity %v, want %v", fileName, g.Range.Start, g.Severity, w.Severity)
-		}
-		if w.Source != g.Source {
-			t.Errorf("%s:%s: got Source %v, want %v", fileName, g.Range.Start, g.Source, w.Source)
-		}
-	}
-
-	for _, w := range unmatched {
-		t.Errorf("%s:%s: unmatched diagnostic pattern %q", fileName, w.Range, w.Message)
-	}
-}
-
-// rangeOverlaps reports whether r1 and r2 overlap.
-func rangeOverlaps(r1, r2 protocol.Range) bool {
-	if inRange(r2.Start, r1) || inRange(r1.Start, r2) {
-		return true
-	}
-	return false
-}
-
-// inRange reports whether p is contained within [r.Start, r.End), or if p ==
-// r.Start == r.End (special handling for the case where the range is a single
-// point).
-func inRange(p protocol.Position, r protocol.Range) bool {
-	if protocol.IsPoint(r) {
-		return protocol.ComparePosition(r.Start, p) == 0
-	}
-	if protocol.ComparePosition(r.Start, p) <= 0 && protocol.ComparePosition(p, r.End) < 0 {
-		return true
-	}
-	return false
-}
-
-func DiffCodeLens(uri span.URI, want, got []protocol.CodeLens) string {
-	sortCodeLens(want)
-	sortCodeLens(got)
-
-	if len(got) != len(want) {
-		return summarizeCodeLens(-1, uri, want, got, "different lengths got %v want %v", len(got), len(want))
-	}
-	for i, w := range want {
-		g := got[i]
-		if w.Command.Command != g.Command.Command {
-			return summarizeCodeLens(i, uri, want, got, "incorrect Command Name got %v want %v", g.Command.Command, w.Command.Command)
-		}
-		if w.Command.Title != g.Command.Title {
-			return summarizeCodeLens(i, uri, want, got, "incorrect Command Title got %v want %v", g.Command.Title, w.Command.Title)
-		}
-		if protocol.ComparePosition(w.Range.Start, g.Range.Start) != 0 {
-			return summarizeCodeLens(i, uri, want, got, "incorrect Start got %v want %v", g.Range.Start, w.Range.Start)
-		}
-		if !protocol.IsPoint(g.Range) { // Accept any 'want' range if the codelens returns a zero-length range.
-			if protocol.ComparePosition(w.Range.End, g.Range.End) != 0 {
-				return summarizeCodeLens(i, uri, want, got, "incorrect End got %v want %v", g.Range.End, w.Range.End)
-			}
-		}
-	}
-	return ""
-}
-
-func sortCodeLens(c []protocol.CodeLens) {
-	sort.Slice(c, func(i int, j int) bool {
-		if r := protocol.CompareRange(c[i].Range, c[j].Range); r != 0 {
-			return r < 0
-		}
-		if c[i].Command.Command < c[j].Command.Command {
-			return true
-		} else if c[i].Command.Command == c[j].Command.Command {
-			return c[i].Command.Title < c[j].Command.Title
-		} else {
-			return false
-		}
-	})
-}
-
-func summarizeCodeLens(i int, uri span.URI, want, got []protocol.CodeLens, reason string, args ...interface{}) string {
-	msg := &bytes.Buffer{}
-	fmt.Fprint(msg, "codelens failed")
-	if i >= 0 {
-		fmt.Fprintf(msg, " at %d", i)
-	}
-	fmt.Fprint(msg, " because of ")
-	fmt.Fprintf(msg, reason, args...)
-	fmt.Fprint(msg, ":\nexpected:\n")
-	for _, d := range want {
-		fmt.Fprintf(msg, "  %s:%v: %s | %s\n", uri, d.Range, d.Command.Command, d.Command.Title)
-	}
-	fmt.Fprintf(msg, "got:\n")
-	for _, d := range got {
-		fmt.Fprintf(msg, "  %s:%v: %s | %s\n", uri, d.Range, d.Command.Command, d.Command.Title)
-	}
-	return msg.String()
-}
-
-func DiffSignatures(spn span.Span, want, got *protocol.SignatureHelp) string {
-	decorate := func(f string, args ...interface{}) string {
-		return fmt.Sprintf("invalid signature at %s: %s", spn, fmt.Sprintf(f, args...))
-	}
-	if len(got.Signatures) != 1 {
-		return decorate("wanted 1 signature, got %d", len(got.Signatures))
-	}
-	if got.ActiveSignature != 0 {
-		return decorate("wanted active signature of 0, got %d", int(got.ActiveSignature))
-	}
-	if want.ActiveParameter != got.ActiveParameter {
-		return decorate("wanted active parameter of %d, got %d", want.ActiveParameter, int(got.ActiveParameter))
-	}
-	g := got.Signatures[0]
-	w := want.Signatures[0]
-	if diff := compare.Text(NormalizeAny(w.Label), NormalizeAny(g.Label)); diff != "" {
-		return decorate("mismatched labels:\n%s", diff)
-	}
-	var paramParts []string
-	for _, p := range g.Parameters {
-		paramParts = append(paramParts, p.Label)
-	}
-	paramsStr := strings.Join(paramParts, ", ")
-	if !strings.Contains(g.Label, paramsStr) {
-		return decorate("expected signature %q to contain params %q", g.Label, paramsStr)
-	}
-	return ""
-}
-
-// NormalizeAny replaces occurrences of interface{} in input with any.
-//
-// In Go 1.18, standard library functions were changed to use the 'any'
-// alias in place of interface{}, which affects their type string.
-func NormalizeAny(input string) string {
-	return strings.ReplaceAll(input, "interface{}", "any")
-}
-
-// DiffCallHierarchyItems returns the diff between expected and actual call locations for incoming/outgoing call hierarchies
-func DiffCallHierarchyItems(gotCalls []protocol.CallHierarchyItem, expectedCalls []protocol.CallHierarchyItem) string {
-	expected := make(map[protocol.Location]bool)
-	for _, call := range expectedCalls {
-		expected[protocol.Location{URI: call.URI, Range: call.Range}] = true
-	}
-
-	got := make(map[protocol.Location]bool)
-	for _, call := range gotCalls {
-		got[protocol.Location{URI: call.URI, Range: call.Range}] = true
-	}
-	if len(got) != len(expected) {
-		return fmt.Sprintf("expected %d calls but got %d", len(expected), len(got))
-	}
-	for spn := range got {
-		if !expected[spn] {
-			return fmt.Sprintf("incorrect calls, expected locations %v but got locations %v", expected, got)
-		}
-	}
-	return ""
-}
-
-func ToProtocolCompletionItems(items []completion.CompletionItem) []protocol.CompletionItem {
-	var result []protocol.CompletionItem
-	for _, item := range items {
-		result = append(result, ToProtocolCompletionItem(item))
-	}
-	return result
-}
-
-func ToProtocolCompletionItem(item completion.CompletionItem) protocol.CompletionItem {
-	pItem := protocol.CompletionItem{
-		Label:         item.Label,
-		Kind:          item.Kind,
-		Detail:        item.Detail,
-		Documentation: item.Documentation,
-		InsertText:    item.InsertText,
-		TextEdit: &protocol.TextEdit{
-			NewText: item.Snippet(),
-		},
-		// Negate score so best score has lowest sort text like real API.
-		SortText: fmt.Sprint(-item.Score),
-	}
-	if pItem.InsertText == "" {
-		pItem.InsertText = pItem.Label
-	}
-	return pItem
-}
-
-func FilterBuiltins(src span.Span, items []protocol.CompletionItem) []protocol.CompletionItem {
-	var (
-		got          []protocol.CompletionItem
-		wantBuiltins = strings.Contains(string(src.URI()), "builtins")
-		wantKeywords = strings.Contains(string(src.URI()), "keywords")
-	)
-	for _, item := range items {
-		if !wantBuiltins && isBuiltin(item.Label, item.Detail, item.Kind) {
-			continue
-		}
-
-		if !wantKeywords && token.Lookup(item.Label).IsKeyword() {
-			continue
-		}
-
-		got = append(got, item)
-	}
-	return got
-}
-
-func isBuiltin(label, detail string, kind protocol.CompletionItemKind) bool {
-	if detail == "" && kind == protocol.ClassCompletion {
-		return true
-	}
-	// Remaining builtin constants, variables, interfaces, and functions.
-	trimmed := label
-	if i := strings.Index(trimmed, "("); i >= 0 {
-		trimmed = trimmed[:i]
-	}
-	switch trimmed {
-	case "append", "cap", "close", "complex", "copy", "delete",
-		"error", "false", "imag", "iota", "len", "make", "new",
-		"nil", "panic", "print", "println", "real", "recover", "true":
-		return true
-	}
-	return false
-}
-
-func CheckCompletionOrder(want, got []protocol.CompletionItem, strictScores bool) string {
-	var (
-		matchedIdxs []int
-		lastGotIdx  int
-		lastGotSort float64
-		inOrder     = true
-		errorMsg    = "completions out of order"
-	)
-	for _, w := range want {
-		var found bool
-		for i, g := range got {
-			if w.Label == g.Label && NormalizeAny(w.Detail) == NormalizeAny(g.Detail) && w.Kind == g.Kind {
-				matchedIdxs = append(matchedIdxs, i)
-				found = true
-
-				if i < lastGotIdx {
-					inOrder = false
-				}
-				lastGotIdx = i
-
-				sort, _ := strconv.ParseFloat(g.SortText, 64)
-				if strictScores && len(matchedIdxs) > 1 && sort <= lastGotSort {
-					inOrder = false
-					errorMsg = "candidate scores not strictly decreasing"
-				}
-				lastGotSort = sort
-
-				break
-			}
-		}
-		if !found {
-			return summarizeCompletionItems(-1, []protocol.CompletionItem{w}, got, "didn't find expected completion")
-		}
-	}
-
-	sort.Ints(matchedIdxs)
-	matched := make([]protocol.CompletionItem, 0, len(matchedIdxs))
-	for _, idx := range matchedIdxs {
-		matched = append(matched, got[idx])
-	}
-
-	if !inOrder {
-		return summarizeCompletionItems(-1, want, matched, errorMsg)
-	}
-
-	return ""
-}
-
-func DiffSnippets(want string, got *protocol.CompletionItem) string {
-	if want == "" {
-		if got != nil {
-			x := got.TextEdit
-			return fmt.Sprintf("expected no snippet but got %s", x.NewText)
-		}
-	} else {
-		if got == nil {
-			return fmt.Sprintf("couldn't find completion matching %q", want)
-		}
-		x := got.TextEdit
-		if want != x.NewText {
-			return fmt.Sprintf("expected snippet %q, got %q", want, x.NewText)
-		}
-	}
-	return ""
-}
-
-func FindItem(list []protocol.CompletionItem, want completion.CompletionItem) *protocol.CompletionItem {
-	for _, item := range list {
-		if item.Label == want.Label {
-			return &item
-		}
-	}
-	return nil
-}
-
-// DiffCompletionItems prints the diff between expected and actual completion
-// test results.
-func DiffCompletionItems(want, got []protocol.CompletionItem) string {
-	if len(got) != len(want) {
-		return summarizeCompletionItems(-1, want, got, "different lengths got %v want %v", len(got), len(want))
-	}
-	for i, w := range want {
-		g := got[i]
-		if w.Label != g.Label {
-			return summarizeCompletionItems(i, want, got, "incorrect Label got %v want %v", g.Label, w.Label)
-		}
-		if NormalizeAny(w.Detail) != NormalizeAny(g.Detail) {
-			return summarizeCompletionItems(i, want, got, "incorrect Detail got %v want %v", g.Detail, w.Detail)
-		}
-		if w.Documentation != "" && !strings.HasPrefix(w.Documentation, "@") {
-			if w.Documentation != g.Documentation {
-				return summarizeCompletionItems(i, want, got, "incorrect Documentation got %v want %v", g.Documentation, w.Documentation)
-			}
-		}
-		if w.Kind != g.Kind {
-			return summarizeCompletionItems(i, want, got, "incorrect Kind got %v want %v", g.Kind, w.Kind)
-		}
-	}
-	return ""
-}
-
-func summarizeCompletionItems(i int, want, got []protocol.CompletionItem, reason string, args ...interface{}) string {
-	msg := &bytes.Buffer{}
-	fmt.Fprint(msg, "completion failed")
-	if i >= 0 {
-		fmt.Fprintf(msg, " at %d", i)
-	}
-	fmt.Fprint(msg, " because of ")
-	fmt.Fprintf(msg, reason, args...)
-	fmt.Fprint(msg, ":\nexpected:\n")
-	for _, d := range want {
-		fmt.Fprintf(msg, "  %v\n", d)
-	}
-	fmt.Fprintf(msg, "got:\n")
-	for _, d := range got {
-		fmt.Fprintf(msg, "  %v\n", d)
-	}
-	return msg.String()
-}
-
-func EnableAllAnalyzers(opts *source.Options) {
-	if opts.Analyses == nil {
-		opts.Analyses = make(map[string]bool)
-	}
-	for _, a := range opts.DefaultAnalyzers {
-		if !a.IsEnabled(opts) {
-			opts.Analyses[a.Analyzer.Name] = true
-		}
-	}
-	for _, a := range opts.TypeErrorAnalyzers {
-		if !a.IsEnabled(opts) {
-			opts.Analyses[a.Analyzer.Name] = true
-		}
-	}
-	for _, a := range opts.ConvenienceAnalyzers {
-		if !a.IsEnabled(opts) {
-			opts.Analyses[a.Analyzer.Name] = true
-		}
-	}
-	for _, a := range opts.StaticcheckAnalyzers {
-		if !a.IsEnabled(opts) {
-			opts.Analyses[a.Analyzer.Name] = true
-		}
-	}
-}
-
-func EnableAllInlayHints(opts *source.Options) {
-	if opts.Hints == nil {
-		opts.Hints = make(map[string]bool)
-	}
-	for name := range source.AllInlayHints {
-		opts.Hints[name] = true
-	}
-}
-
-func WorkspaceSymbolsString(ctx context.Context, data *Data, queryURI span.URI, symbols []protocol.SymbolInformation) (string, error) {
-	queryDir := filepath.Dir(queryURI.Filename())
-	var filtered []string
-	for _, s := range symbols {
-		uri := s.Location.URI.SpanURI()
-		dir := filepath.Dir(uri.Filename())
-		if !source.InDir(queryDir, dir) { // assume queries always issue from higher directories
-			continue
-		}
-		m, err := data.Mapper(uri)
-		if err != nil {
-			return "", err
-		}
-		spn, err := m.Span(s.Location)
-		if err != nil {
-			return "", err
-		}
-		filtered = append(filtered, fmt.Sprintf("%s %s %s", spn, s.Name, s.Kind))
-	}
-	sort.Strings(filtered)
-	return strings.Join(filtered, "\n") + "\n", nil
-}
-
-func WorkspaceSymbolsTestTypeToMatcher(typ WorkspaceSymbolsTestType) source.SymbolMatcher {
-	switch typ {
-	case WorkspaceSymbolsFuzzy:
-		return source.SymbolFuzzy
-	case WorkspaceSymbolsCaseSensitive:
-		return source.SymbolCaseSensitive
-	default:
-		return source.SymbolCaseInsensitive
-	}
-}
-
-// StripSubscripts removes type parameter id subscripts.
-//
-// TODO(rfindley): remove this function once subscripts are removed from the
-// type parameter type string.
-func StripSubscripts(s string) string {
-	var runes []rune
-	for _, r := range s {
-		// For debugging/uniqueness purposes, TypeString on a type parameter adds a
-		// subscript corresponding to the type parameter's unique id. This is going
-		// to be removed, but in the meantime we skip the subscript runes to get a
-		// deterministic output.
-		if '₀' <= r && r < '₀'+10 {
-			continue // trim type parameter subscripts
-		}
-		runes = append(runes, r)
-	}
-	return string(runes)
-}
diff -urN a/gopls/internal/lsp/text_synchronization.go b/gopls/internal/lsp/text_synchronization.go
--- a/gopls/internal/lsp/text_synchronization.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/text_synchronization.go	1969-12-31 16:00:00
@@ -1,397 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"bytes"
-	"context"
-	"errors"
-	"fmt"
-	"path/filepath"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/xcontext"
-)
-
-// ModificationSource identifies the originating cause of a file modification.
-type ModificationSource int
-
-const (
-	// FromDidOpen is a file modification caused by opening a file.
-	FromDidOpen = ModificationSource(iota)
-
-	// FromDidChange is a file modification caused by changing a file.
-	FromDidChange
-
-	// FromDidChangeWatchedFiles is a file modification caused by a change to a
-	// watched file.
-	FromDidChangeWatchedFiles
-
-	// FromDidSave is a file modification caused by a file save.
-	FromDidSave
-
-	// FromDidClose is a file modification caused by closing a file.
-	FromDidClose
-
-	// TODO: add FromDidChangeConfiguration, once configuration changes cause a
-	// new snapshot to be created.
-
-	// FromRegenerateCgo refers to file modifications caused by regenerating
-	// the cgo sources for the workspace.
-	FromRegenerateCgo
-
-	// FromInitialWorkspaceLoad refers to the loading of all packages in the
-	// workspace when the view is first created.
-	FromInitialWorkspaceLoad
-)
-
-func (m ModificationSource) String() string {
-	switch m {
-	case FromDidOpen:
-		return "opened files"
-	case FromDidChange:
-		return "changed files"
-	case FromDidChangeWatchedFiles:
-		return "files changed on disk"
-	case FromDidSave:
-		return "saved files"
-	case FromDidClose:
-		return "close files"
-	case FromRegenerateCgo:
-		return "regenerate cgo"
-	case FromInitialWorkspaceLoad:
-		return "initial workspace load"
-	default:
-		return "unknown file modification"
-	}
-}
-
-func (s *Server) didOpen(ctx context.Context, params *protocol.DidOpenTextDocumentParams) error {
-	uri := params.TextDocument.URI.SpanURI()
-	if !uri.IsFile() {
-		return nil
-	}
-	// There may not be any matching view in the current session. If that's
-	// the case, try creating a new view based on the opened file path.
-	//
-	// TODO(rstambler): This seems like it would continuously add new
-	// views, but it won't because ViewOf only returns an error when there
-	// are no views in the session. I don't know if that logic should go
-	// here, or if we can continue to rely on that implementation detail.
-	if _, err := s.session.ViewOf(uri); err != nil {
-		dir := filepath.Dir(uri.Filename())
-		if err := s.addFolders(ctx, []protocol.WorkspaceFolder{{
-			URI:  string(protocol.URIFromPath(dir)),
-			Name: filepath.Base(dir),
-		}}); err != nil {
-			return err
-		}
-	}
-	return s.didModifyFiles(ctx, []source.FileModification{{
-		URI:        uri,
-		Action:     source.Open,
-		Version:    params.TextDocument.Version,
-		Text:       []byte(params.TextDocument.Text),
-		LanguageID: params.TextDocument.LanguageID,
-	}}, FromDidOpen)
-}
-
-func (s *Server) didChange(ctx context.Context, params *protocol.DidChangeTextDocumentParams) error {
-	uri := params.TextDocument.URI.SpanURI()
-	if !uri.IsFile() {
-		return nil
-	}
-
-	text, err := s.changedText(ctx, uri, params.ContentChanges)
-	if err != nil {
-		return err
-	}
-	c := source.FileModification{
-		URI:     uri,
-		Action:  source.Change,
-		Version: params.TextDocument.Version,
-		Text:    text,
-	}
-	if err := s.didModifyFiles(ctx, []source.FileModification{c}, FromDidChange); err != nil {
-		return err
-	}
-	return s.warnAboutModifyingGeneratedFiles(ctx, uri)
-}
-
-// warnAboutModifyingGeneratedFiles shows a warning if a user tries to edit a
-// generated file for the first time.
-func (s *Server) warnAboutModifyingGeneratedFiles(ctx context.Context, uri span.URI) error {
-	s.changedFilesMu.Lock()
-	_, ok := s.changedFiles[uri]
-	if !ok {
-		s.changedFiles[uri] = struct{}{}
-	}
-	s.changedFilesMu.Unlock()
-
-	// This file has already been edited before.
-	if ok {
-		return nil
-	}
-
-	// Ideally, we should be able to specify that a generated file should
-	// be opened as read-only. Tell the user that they should not be
-	// editing a generated file.
-	view, err := s.session.ViewOf(uri)
-	if err != nil {
-		return err
-	}
-	snapshot, release := view.Snapshot(ctx)
-	isGenerated := source.IsGenerated(ctx, snapshot, uri)
-	release()
-
-	if !isGenerated {
-		return nil
-	}
-	return s.client.ShowMessage(ctx, &protocol.ShowMessageParams{
-		Message: fmt.Sprintf("Do not edit this file! %s is a generated file.", uri.Filename()),
-		Type:    protocol.Warning,
-	})
-}
-
-func (s *Server) didChangeWatchedFiles(ctx context.Context, params *protocol.DidChangeWatchedFilesParams) error {
-	var modifications []source.FileModification
-	for _, change := range params.Changes {
-		uri := change.URI.SpanURI()
-		if !uri.IsFile() {
-			continue
-		}
-		action := changeTypeToFileAction(change.Type)
-		modifications = append(modifications, source.FileModification{
-			URI:    uri,
-			Action: action,
-			OnDisk: true,
-		})
-	}
-	return s.didModifyFiles(ctx, modifications, FromDidChangeWatchedFiles)
-}
-
-func (s *Server) didSave(ctx context.Context, params *protocol.DidSaveTextDocumentParams) error {
-	uri := params.TextDocument.URI.SpanURI()
-	if !uri.IsFile() {
-		return nil
-	}
-	c := source.FileModification{
-		URI:    uri,
-		Action: source.Save,
-	}
-	if params.Text != nil {
-		c.Text = []byte(*params.Text)
-	}
-	return s.didModifyFiles(ctx, []source.FileModification{c}, FromDidSave)
-}
-
-func (s *Server) didClose(ctx context.Context, params *protocol.DidCloseTextDocumentParams) error {
-	uri := params.TextDocument.URI.SpanURI()
-	if !uri.IsFile() {
-		return nil
-	}
-	return s.didModifyFiles(ctx, []source.FileModification{
-		{
-			URI:     uri,
-			Action:  source.Close,
-			Version: -1,
-			Text:    nil,
-		},
-	}, FromDidClose)
-}
-
-func (s *Server) didModifyFiles(ctx context.Context, modifications []source.FileModification, cause ModificationSource) error {
-	diagnoseDone := make(chan struct{})
-	if s.session.Options().VerboseWorkDoneProgress {
-		work := s.progress.Start(ctx, DiagnosticWorkTitle(cause), "Calculating file diagnostics...", nil, nil)
-		defer func() {
-			go func() {
-				<-diagnoseDone
-				work.End(ctx, "Done.")
-			}()
-		}()
-	}
-
-	onDisk := cause == FromDidChangeWatchedFiles
-	delay := s.session.Options().ExperimentalWatchedFileDelay
-	s.fileChangeMu.Lock()
-	defer s.fileChangeMu.Unlock()
-	if !onDisk || delay == 0 {
-		// No delay: process the modifications immediately.
-		return s.processModifications(ctx, modifications, onDisk, diagnoseDone)
-	}
-	// Debounce and batch up pending modifications from watched files.
-	pending := &pendingModificationSet{
-		diagnoseDone: diagnoseDone,
-		changes:      modifications,
-	}
-	// Invariant: changes appended to s.pendingOnDiskChanges are eventually
-	// handled in the order they arrive. This guarantee is only partially
-	// enforced here. Specifically:
-	//  1. s.fileChangesMu ensures that the append below happens in the order
-	//     notifications were received, so that the changes within each batch are
-	//     ordered properly.
-	//  2. The debounced func below holds s.fileChangesMu while processing all
-	//     changes in s.pendingOnDiskChanges, ensuring that no batches are
-	//     processed out of order.
-	//  3. Session.ExpandModificationsToDirectories and Session.DidModifyFiles
-	//     process changes in order.
-	s.pendingOnDiskChanges = append(s.pendingOnDiskChanges, pending)
-	ctx = xcontext.Detach(ctx)
-	okc := s.watchedFileDebouncer.debounce("", 0, time.After(delay))
-	go func() {
-		if ok := <-okc; !ok {
-			return
-		}
-		s.fileChangeMu.Lock()
-		var allChanges []source.FileModification
-		// For accurate progress notifications, we must notify all goroutines
-		// waiting for the diagnose pass following a didChangeWatchedFiles
-		// notification. This is necessary for regtest assertions.
-		var dones []chan struct{}
-		for _, pending := range s.pendingOnDiskChanges {
-			allChanges = append(allChanges, pending.changes...)
-			dones = append(dones, pending.diagnoseDone)
-		}
-
-		allDone := make(chan struct{})
-		if err := s.processModifications(ctx, allChanges, onDisk, allDone); err != nil {
-			event.Error(ctx, "processing delayed file changes", err)
-		}
-		s.pendingOnDiskChanges = nil
-		s.fileChangeMu.Unlock()
-		<-allDone
-		for _, done := range dones {
-			close(done)
-		}
-	}()
-	return nil
-}
-
-// processModifications update server state to reflect file changes, and
-// triggers diagnostics to run asynchronously. The diagnoseDone channel will be
-// closed once diagnostics complete.
-func (s *Server) processModifications(ctx context.Context, modifications []source.FileModification, onDisk bool, diagnoseDone chan struct{}) error {
-	s.stateMu.Lock()
-	if s.state >= serverShutDown {
-		// This state check does not prevent races below, and exists only to
-		// produce a better error message. The actual race to the cache should be
-		// guarded by Session.viewMu.
-		s.stateMu.Unlock()
-		close(diagnoseDone)
-		return errors.New("server is shut down")
-	}
-	s.stateMu.Unlock()
-
-	// If the set of changes included directories, expand those directories
-	// to their files.
-	modifications = s.session.ExpandModificationsToDirectories(ctx, modifications)
-
-	// Build a lookup map for file modifications, so that we can later join
-	// with the snapshot file associations.
-	modMap := make(map[span.URI]source.FileModification)
-	for _, mod := range modifications {
-		modMap[mod.URI] = mod
-	}
-
-	snapshots, release, err := s.session.DidModifyFiles(ctx, modifications)
-	if err != nil {
-		close(diagnoseDone)
-		return err
-	}
-
-	// golang/go#50267: diagnostics should be re-sent after an open or close. For
-	// some clients, it may be helpful to re-send after each change.
-	for snapshot, uris := range snapshots {
-		for _, uri := range uris {
-			mod := modMap[uri]
-			if snapshot.View().Options().ChattyDiagnostics || mod.Action == source.Open || mod.Action == source.Close {
-				s.mustPublishDiagnostics(uri)
-			}
-		}
-	}
-
-	go func() {
-		s.diagnoseSnapshots(snapshots, onDisk)
-		release()
-		close(diagnoseDone)
-	}()
-
-	// After any file modifications, we need to update our watched files,
-	// in case something changed. Compute the new set of directories to watch,
-	// and if it differs from the current set, send updated registrations.
-	return s.updateWatchedDirectories(ctx)
-}
-
-// DiagnosticWorkTitle returns the title of the diagnostic work resulting from a
-// file change originating from the given cause.
-func DiagnosticWorkTitle(cause ModificationSource) string {
-	return fmt.Sprintf("diagnosing %v", cause)
-}
-
-func (s *Server) changedText(ctx context.Context, uri span.URI, changes []protocol.TextDocumentContentChangeEvent) ([]byte, error) {
-	if len(changes) == 0 {
-		return nil, fmt.Errorf("%w: no content changes provided", jsonrpc2.ErrInternal)
-	}
-
-	// Check if the client sent the full content of the file.
-	// We accept a full content change even if the server expected incremental changes.
-	if len(changes) == 1 && changes[0].Range == nil && changes[0].RangeLength == 0 {
-		return []byte(changes[0].Text), nil
-	}
-	return s.applyIncrementalChanges(ctx, uri, changes)
-}
-
-func (s *Server) applyIncrementalChanges(ctx context.Context, uri span.URI, changes []protocol.TextDocumentContentChangeEvent) ([]byte, error) {
-	fh, err := s.session.GetFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	content, err := fh.Read()
-	if err != nil {
-		return nil, fmt.Errorf("%w: file not found (%v)", jsonrpc2.ErrInternal, err)
-	}
-	for _, change := range changes {
-		// TODO(adonovan): refactor to use diff.Apply, which is robust w.r.t.
-		// out-of-order or overlapping changes---and much more efficient.
-
-		// Make sure to update column mapper along with the content.
-		m := protocol.NewColumnMapper(uri, content)
-		if change.Range == nil {
-			return nil, fmt.Errorf("%w: unexpected nil range for change", jsonrpc2.ErrInternal)
-		}
-		spn, err := m.RangeSpan(*change.Range)
-		if err != nil {
-			return nil, err
-		}
-		start, end := spn.Start().Offset(), spn.End().Offset()
-		if end < start {
-			return nil, fmt.Errorf("%w: invalid range for content change", jsonrpc2.ErrInternal)
-		}
-		var buf bytes.Buffer
-		buf.Write(content[:start])
-		buf.WriteString(change.Text)
-		buf.Write(content[end:])
-		content = buf.Bytes()
-	}
-	return content, nil
-}
-
-func changeTypeToFileAction(ct protocol.FileChangeType) source.FileAction {
-	switch ct {
-	case protocol.Changed:
-		return source.Change
-	case protocol.Created:
-		return source.Create
-	case protocol.Deleted:
-		return source.Delete
-	}
-	return source.UnknownFileAction
-}
diff -urN a/gopls/internal/lsp/work/completion.go b/gopls/internal/lsp/work/completion.go
--- a/gopls/internal/lsp/work/completion.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/work/completion.go	1969-12-31 16:00:00
@@ -1,156 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package work
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"go/token"
-	"os"
-	"path/filepath"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func Completion(ctx context.Context, snapshot source.Snapshot, fh source.VersionedFileHandle, position protocol.Position) (*protocol.CompletionList, error) {
-	ctx, done := event.Start(ctx, "work.Completion")
-	defer done()
-
-	// Get the position of the cursor.
-	pw, err := snapshot.ParseWork(ctx, fh)
-	if err != nil {
-		return nil, fmt.Errorf("getting go.work file handle: %w", err)
-	}
-	pos, err := pw.Mapper.Pos(position)
-	if err != nil {
-		return nil, fmt.Errorf("computing cursor position: %w", err)
-	}
-
-	// Find the use statement the user is in.
-	cursor := pos - 1
-	use, pathStart, _ := usePath(pw, cursor)
-	if use == nil {
-		return &protocol.CompletionList{}, nil
-	}
-	completingFrom := use.Path[:cursor-token.Pos(pathStart)]
-
-	// We're going to find the completions of the user input
-	// (completingFrom) by doing a walk on the innermost directory
-	// of the given path, and comparing the found paths to make sure
-	// that they match the component of the path after the
-	// innermost directory.
-	//
-	// We'll maintain two paths when doing this: pathPrefixSlash
-	// is essentially the path the user typed in, and pathPrefixAbs
-	// is the path made absolute from the go.work directory.
-
-	pathPrefixSlash := completingFrom
-	pathPrefixAbs := filepath.FromSlash(pathPrefixSlash)
-	if !filepath.IsAbs(pathPrefixAbs) {
-		pathPrefixAbs = filepath.Join(filepath.Dir(pw.URI.Filename()), pathPrefixAbs)
-	}
-
-	// pathPrefixDir is the directory that will be walked to find matches.
-	// If pathPrefixSlash is not explicitly a directory boundary (is either equivalent to "." or
-	// ends in a separator) we need to examine its parent directory to find sibling files that
-	// match.
-	depthBound := 5
-	pathPrefixDir, pathPrefixBase := pathPrefixAbs, ""
-	pathPrefixSlashDir := pathPrefixSlash
-	if filepath.Clean(pathPrefixSlash) != "." && !strings.HasSuffix(pathPrefixSlash, "/") {
-		depthBound++
-		pathPrefixDir, pathPrefixBase = filepath.Split(pathPrefixAbs)
-		pathPrefixSlashDir = dirNonClean(pathPrefixSlash)
-	}
-
-	var completions []string
-	// Stop traversing deeper once we've hit 10k files to try to stay generally under 100ms.
-	const numSeenBound = 10000
-	var numSeen int
-	stopWalking := errors.New("hit numSeenBound")
-	err = filepath.Walk(pathPrefixDir, func(wpath string, info os.FileInfo, err error) error {
-		if numSeen > numSeenBound {
-			// Stop traversing if we hit bound.
-			return stopWalking
-		}
-		numSeen++
-
-		// rel is the path relative to pathPrefixDir.
-		// Make sure that it has pathPrefixBase as a prefix
-		// otherwise it won't match the beginning of the
-		// base component of the path the user typed in.
-		rel := strings.TrimPrefix(wpath[len(pathPrefixDir):], string(filepath.Separator))
-		if info.IsDir() && wpath != pathPrefixDir && !strings.HasPrefix(rel, pathPrefixBase) {
-			return filepath.SkipDir
-		}
-
-		// Check for a match (a module directory).
-		if filepath.Base(rel) == "go.mod" {
-			relDir := strings.TrimSuffix(dirNonClean(rel), string(os.PathSeparator))
-			completionPath := join(pathPrefixSlashDir, filepath.ToSlash(relDir))
-
-			if !strings.HasPrefix(completionPath, completingFrom) {
-				return nil
-			}
-			if strings.HasSuffix(completionPath, "/") {
-				// Don't suggest paths that end in "/". This happens
-				// when the input is a path that ends in "/" and
-				// the completion is empty.
-				return nil
-			}
-			completion := completionPath[len(completingFrom):]
-			if completingFrom == "" && !strings.HasPrefix(completion, "./") {
-				// Bias towards "./" prefixes.
-				completion = join(".", completion)
-			}
-
-			completions = append(completions, completion)
-		}
-
-		if depth := strings.Count(rel, string(filepath.Separator)); depth >= depthBound {
-			return filepath.SkipDir
-		}
-		return nil
-	})
-	if err != nil && !errors.Is(err, stopWalking) {
-		return nil, fmt.Errorf("walking to find completions: %w", err)
-	}
-
-	sort.Strings(completions)
-
-	var items []protocol.CompletionItem
-	for _, c := range completions {
-		items = append(items, protocol.CompletionItem{
-			Label:      c,
-			InsertText: c,
-		})
-	}
-	return &protocol.CompletionList{Items: items}, nil
-}
-
-// dirNonClean is filepath.Dir, without the Clean at the end.
-func dirNonClean(path string) string {
-	vol := filepath.VolumeName(path)
-	i := len(path) - 1
-	for i >= len(vol) && !os.IsPathSeparator(path[i]) {
-		i--
-	}
-	return path[len(vol) : i+1]
-}
-
-func join(a, b string) string {
-	if a == "" {
-		return b
-	}
-	if b == "" {
-		return a
-	}
-	return strings.TrimSuffix(a, "/") + "/" + b
-}
diff -urN a/gopls/internal/lsp/work/diagnostics.go b/gopls/internal/lsp/work/diagnostics.go
--- a/gopls/internal/lsp/work/diagnostics.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/work/diagnostics.go	1969-12-31 16:00:00
@@ -1,92 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package work
-
-import (
-	"context"
-	"fmt"
-	"os"
-	"path/filepath"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/internal/event"
-)
-
-func Diagnostics(ctx context.Context, snapshot source.Snapshot) (map[source.VersionedFileIdentity][]*source.Diagnostic, error) {
-	ctx, done := event.Start(ctx, "work.Diagnostics", source.SnapshotLabels(snapshot)...)
-	defer done()
-
-	reports := map[source.VersionedFileIdentity][]*source.Diagnostic{}
-	uri := snapshot.WorkFile()
-	if uri == "" {
-		return nil, nil
-	}
-	fh, err := snapshot.GetVersionedFile(ctx, uri)
-	if err != nil {
-		return nil, err
-	}
-	reports[fh.VersionedFileIdentity()] = []*source.Diagnostic{}
-	diagnostics, err := DiagnosticsForWork(ctx, snapshot, fh)
-	if err != nil {
-		return nil, err
-	}
-	for _, d := range diagnostics {
-		fh, err := snapshot.GetVersionedFile(ctx, d.URI)
-		if err != nil {
-			return nil, err
-		}
-		reports[fh.VersionedFileIdentity()] = append(reports[fh.VersionedFileIdentity()], d)
-	}
-
-	return reports, nil
-}
-
-func DiagnosticsForWork(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]*source.Diagnostic, error) {
-	pw, err := snapshot.ParseWork(ctx, fh)
-	if err != nil {
-		if pw == nil || len(pw.ParseErrors) == 0 {
-			return nil, err
-		}
-		return pw.ParseErrors, nil
-	}
-
-	// Add diagnostic if a directory does not contain a module.
-	var diagnostics []*source.Diagnostic
-	for _, use := range pw.File.Use {
-		rng, err := pw.Mapper.OffsetRange(use.Syntax.Start.Byte, use.Syntax.End.Byte)
-		if err != nil {
-			return nil, err
-		}
-
-		modfh, err := snapshot.GetFile(ctx, modFileURI(pw, use))
-		if err != nil {
-			return nil, err
-		}
-		if _, err := modfh.Read(); err != nil && os.IsNotExist(err) {
-			diagnostics = append(diagnostics, &source.Diagnostic{
-				URI:      fh.URI(),
-				Range:    rng,
-				Severity: protocol.SeverityError,
-				Source:   source.WorkFileError,
-				Message:  fmt.Sprintf("directory %v does not contain a module", use.Path),
-			})
-		}
-	}
-	return diagnostics, nil
-}
-
-func modFileURI(pw *source.ParsedWorkFile, use *modfile.Use) span.URI {
-	workdir := filepath.Dir(pw.URI.Filename())
-
-	modroot := filepath.FromSlash(use.Path)
-	if !filepath.IsAbs(modroot) {
-		modroot = filepath.Join(workdir, modroot)
-	}
-
-	return span.URIFromPath(filepath.Join(modroot, "go.mod"))
-}
diff -urN a/gopls/internal/lsp/work/format.go b/gopls/internal/lsp/work/format.go
--- a/gopls/internal/lsp/work/format.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/work/format.go	1969-12-31 16:00:00
@@ -1,28 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package work
-
-import (
-	"context"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-func Format(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle) ([]protocol.TextEdit, error) {
-	ctx, done := event.Start(ctx, "work.Format")
-	defer done()
-
-	pw, err := snapshot.ParseWork(ctx, fh)
-	if err != nil {
-		return nil, err
-	}
-	formatted := modfile.Format(pw.File.Syntax)
-	// Calculate the edits to be made due to the change.
-	diffs := snapshot.View().Options().ComputeEdits(string(pw.Mapper.Content), string(formatted))
-	return source.ToProtocolEdits(pw.Mapper, diffs)
-}
diff -urN a/gopls/internal/lsp/work/hover.go b/gopls/internal/lsp/work/hover.go
--- a/gopls/internal/lsp/work/hover.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/work/hover.go	1969-12-31 16:00:00
@@ -1,90 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package work
-
-import (
-	"bytes"
-	"context"
-	"fmt"
-	"go/token"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-func Hover(ctx context.Context, snapshot source.Snapshot, fh source.FileHandle, position protocol.Position) (*protocol.Hover, error) {
-	// We only provide hover information for the view's go.work file.
-	if fh.URI() != snapshot.WorkFile() {
-		return nil, nil
-	}
-
-	ctx, done := event.Start(ctx, "work.Hover")
-	defer done()
-
-	// Get the position of the cursor.
-	pw, err := snapshot.ParseWork(ctx, fh)
-	if err != nil {
-		return nil, fmt.Errorf("getting go.work file handle: %w", err)
-	}
-	pos, err := pw.Mapper.Pos(position)
-	if err != nil {
-		return nil, fmt.Errorf("computing cursor position: %w", err)
-	}
-
-	// Confirm that the cursor is inside a use statement, and then find
-	// the position of the use statement's directory path.
-	use, pathStart, pathEnd := usePath(pw, pos)
-
-	// The cursor position is not on a use statement.
-	if use == nil {
-		return nil, nil
-	}
-
-	// Get the mod file denoted by the use.
-	modfh, err := snapshot.GetFile(ctx, modFileURI(pw, use))
-	if err != nil {
-		return nil, fmt.Errorf("getting modfile handle: %w", err)
-	}
-	pm, err := snapshot.ParseMod(ctx, modfh)
-	if err != nil {
-		return nil, fmt.Errorf("getting modfile handle: %w", err)
-	}
-	mod := pm.File.Module.Mod
-
-	// Get the range to highlight for the hover.
-	rng, err := pw.Mapper.OffsetRange(pathStart, pathEnd)
-	if err != nil {
-		return nil, err
-	}
-	options := snapshot.View().Options()
-	return &protocol.Hover{
-		Contents: protocol.MarkupContent{
-			Kind:  options.PreferredContentFormat,
-			Value: mod.Path,
-		},
-		Range: rng,
-	}, nil
-}
-
-func usePath(pw *source.ParsedWorkFile, pos token.Pos) (use *modfile.Use, pathStart, pathEnd int) {
-	for _, u := range pw.File.Use {
-		path := []byte(u.Path)
-		s, e := u.Syntax.Start.Byte, u.Syntax.End.Byte
-		i := bytes.Index(pw.Mapper.Content[s:e], path)
-		if i == -1 {
-			// This should not happen.
-			continue
-		}
-		// Shift the start position to the location of the
-		// module directory within the use statement.
-		pathStart, pathEnd = s+i, s+i+len(path)
-		if token.Pos(pathStart) <= pos && pos <= token.Pos(pathEnd) {
-			return u, pathStart, pathEnd
-		}
-	}
-	return nil, 0, 0
-}
diff -urN a/gopls/internal/lsp/workspace.go b/gopls/internal/lsp/workspace.go
--- a/gopls/internal/lsp/workspace.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/workspace.go	1969-12-31 16:00:00
@@ -1,113 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-	"fmt"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-func (s *Server) didChangeWorkspaceFolders(ctx context.Context, params *protocol.DidChangeWorkspaceFoldersParams) error {
-	event := params.Event
-	for _, folder := range event.Removed {
-		view := s.session.View(folder.Name)
-		if view != nil {
-			s.session.RemoveView(view)
-		} else {
-			return fmt.Errorf("view %s for %v not found", folder.Name, folder.URI)
-		}
-	}
-	return s.addFolders(ctx, event.Added)
-}
-
-// addView returns a Snapshot and a release function that must be
-// called when it is no longer needed.
-func (s *Server) addView(ctx context.Context, name string, uri span.URI) (source.Snapshot, func(), error) {
-	s.stateMu.Lock()
-	state := s.state
-	s.stateMu.Unlock()
-	if state < serverInitialized {
-		return nil, nil, fmt.Errorf("addView called before server initialized")
-	}
-	options := s.session.Options().Clone()
-	if err := s.fetchConfig(ctx, name, uri, options); err != nil {
-		return nil, nil, err
-	}
-	_, snapshot, release, err := s.session.NewView(ctx, name, uri, options)
-	return snapshot, release, err
-}
-
-func (s *Server) didChangeConfiguration(ctx context.Context, _ *protocol.DidChangeConfigurationParams) error {
-	// Apply any changes to the session-level settings.
-	options := s.session.Options().Clone()
-	semanticTokensRegistered := options.SemanticTokens
-	if err := s.fetchConfig(ctx, "", "", options); err != nil {
-		return err
-	}
-	s.session.SetOptions(options)
-
-	// Go through each view, getting and updating its configuration.
-	for _, view := range s.session.Views() {
-		options := s.session.Options().Clone()
-		if err := s.fetchConfig(ctx, view.Name(), view.Folder(), options); err != nil {
-			return err
-		}
-		view, err := s.session.SetViewOptions(ctx, view, options)
-		if err != nil {
-			return err
-		}
-		go func() {
-			snapshot, release := view.Snapshot(ctx)
-			defer release()
-			s.diagnoseDetached(snapshot)
-		}()
-	}
-
-	// An options change may have affected the detected Go version.
-	s.checkViewGoVersions()
-
-	registration := semanticTokenRegistration(options.SemanticTypes, options.SemanticMods)
-	// Update any session-specific registrations or unregistrations.
-	if !semanticTokensRegistered && options.SemanticTokens {
-		if err := s.client.RegisterCapability(ctx, &protocol.RegistrationParams{
-			Registrations: []protocol.Registration{registration},
-		}); err != nil {
-			return err
-		}
-	} else if semanticTokensRegistered && !options.SemanticTokens {
-		if err := s.client.UnregisterCapability(ctx, &protocol.UnregistrationParams{
-			Unregisterations: []protocol.Unregistration{
-				{
-					ID:     registration.ID,
-					Method: registration.Method,
-				},
-			},
-		}); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-func semanticTokenRegistration(tokenTypes, tokenModifiers []string) protocol.Registration {
-	return protocol.Registration{
-		ID:     "textDocument/semanticTokens",
-		Method: "textDocument/semanticTokens",
-		RegisterOptions: &protocol.SemanticTokensOptions{
-			Legend: protocol.SemanticTokensLegend{
-				// TODO(pjw): trim these to what we use (and an unused one
-				// at position 0 of TokTypes, to catch typos)
-				TokenTypes:     tokenTypes,
-				TokenModifiers: tokenModifiers,
-			},
-			Full:  true,
-			Range: true,
-		},
-	}
-}
diff -urN a/gopls/internal/lsp/workspace_symbol.go b/gopls/internal/lsp/workspace_symbol.go
--- a/gopls/internal/lsp/workspace_symbol.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/lsp/workspace_symbol.go	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package lsp
-
-import (
-	"context"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/event"
-)
-
-func (s *Server) symbol(ctx context.Context, params *protocol.WorkspaceSymbolParams) ([]protocol.SymbolInformation, error) {
-	ctx, done := event.Start(ctx, "lsp.Server.symbol")
-	defer done()
-
-	views := s.session.Views()
-	matcher := s.session.Options().SymbolMatcher
-	style := s.session.Options().SymbolStyle
-	// TODO(rfindley): it looks wrong that we need to pass views here.
-	//
-	// Evidence:
-	//  - this is the only place we convert views to []source.View
-	//  - workspace symbols is the only place where we call source.View.Snapshot
-	var sourceViews []source.View
-	for _, v := range views {
-		sourceViews = append(sourceViews, v)
-	}
-	return source.WorkspaceSymbols(ctx, matcher, style, sourceViews, params.Query)
-}
diff -urN a/gopls/internal/regtest/bench/bench_test.go b/gopls/internal/regtest/bench/bench_test.go
--- a/gopls/internal/regtest/bench/bench_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/bench_test.go	1969-12-31 16:00:00
@@ -1,277 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"io/ioutil"
-	"log"
-	"os"
-	"os/exec"
-	"path/filepath"
-	"sync"
-	"testing"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/fakenet"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// This package implements benchmarks that share a common editor session.
-//
-// It is a work-in-progress.
-//
-// Remaining TODO(rfindley):
-//   - add detailed documentation for how to write a benchmark, as a package doc
-//   - add benchmarks for more features
-//   - eliminate flags, and just run benchmarks on with a predefined set of
-//     arguments
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	event.SetExporter(nil) // don't log to stderr
-	code := doMain(m)
-	os.Exit(code)
-}
-
-func doMain(m *testing.M) (code int) {
-	defer func() {
-		if editor != nil {
-			if err := editor.Close(context.Background()); err != nil {
-				fmt.Fprintf(os.Stderr, "closing editor: %v", err)
-				if code == 0 {
-					code = 1
-				}
-			}
-		}
-		if tempDir != "" {
-			if err := os.RemoveAll(tempDir); err != nil {
-				fmt.Fprintf(os.Stderr, "cleaning temp dir: %v", err)
-				if code == 0 {
-					code = 1
-				}
-			}
-		}
-	}()
-	return m.Run()
-}
-
-var (
-	workdir   = flag.String("workdir", "", "if set, working directory to use for benchmarks; overrides -repo and -commit")
-	repo      = flag.String("repo", "https://go.googlesource.com/tools", "if set (and -workdir is unset), run benchmarks in this repo")
-	file      = flag.String("file", "go/ast/astutil/util.go", "active file, for benchmarks that operate on a file")
-	commitish = flag.String("commit", "gopls/v0.9.0", "if set (and -workdir is unset), run benchmarks at this commit")
-
-	goplsPath   = flag.String("gopls_path", "", "if set, use this gopls for testing; incompatible with -gopls_commit")
-	goplsCommit = flag.String("gopls_commit", "", "if set, install and use gopls at this commit for testing; incompatible with -gopls_path")
-
-	// If non-empty, tempDir is a temporary working dir that was created by this
-	// test suite.
-	//
-	// The sync.Once variables guard various modifications of the temp directory.
-	makeTempDirOnce  sync.Once
-	checkoutRepoOnce sync.Once
-	installGoplsOnce sync.Once
-	tempDir          string
-
-	setupEditorOnce sync.Once
-	sandbox         *fake.Sandbox
-	editor          *fake.Editor
-	awaiter         *Awaiter
-)
-
-// getTempDir returns the temporary directory to use for benchmark files,
-// creating it if necessary.
-func getTempDir() string {
-	makeTempDirOnce.Do(func() {
-		var err error
-		tempDir, err = ioutil.TempDir("", "gopls-bench")
-		if err != nil {
-			log.Fatal(err)
-		}
-	})
-	return tempDir
-}
-
-// benchmarkDir returns the directory to use for benchmarks.
-//
-// If -workdir is set, just use that directory. Otherwise, check out a shallow
-// copy of -repo at the given -commit, and clean up when the test suite exits.
-func benchmarkDir() string {
-	if *workdir != "" {
-		return *workdir
-	}
-	if *repo == "" {
-		log.Fatal("-repo must be provided if -workdir is unset")
-	}
-	if *commitish == "" {
-		log.Fatal("-commit must be provided if -workdir is unset")
-	}
-
-	dir := filepath.Join(getTempDir(), "repo")
-	checkoutRepoOnce.Do(func() {
-		log.Printf("creating working dir: checking out %s@%s to %s\n", *repo, *commitish, dir)
-		if err := shallowClone(dir, *repo, *commitish); err != nil {
-			log.Fatal(err)
-		}
-	})
-	return dir
-}
-
-// shallowClone performs a shallow clone of repo into dir at the given
-// 'commitish' ref (any commit reference understood by git).
-//
-// The directory dir must not already exist.
-func shallowClone(dir, repo, commitish string) error {
-	if err := os.Mkdir(dir, 0750); err != nil {
-		return fmt.Errorf("creating dir for %s: %v", repo, err)
-	}
-
-	// Set a timeout for git fetch. If this proves flaky, it can be removed.
-	ctx, cancel := context.WithTimeout(context.Background(), 1*time.Minute)
-	defer cancel()
-
-	// Use a shallow fetch to download just the relevant commit.
-	shInit := fmt.Sprintf("git init && git fetch --depth=1 %q %q && git checkout FETCH_HEAD", repo, commitish)
-	initCmd := exec.CommandContext(ctx, "/bin/sh", "-c", shInit)
-	initCmd.Dir = dir
-	if output, err := initCmd.CombinedOutput(); err != nil {
-		return fmt.Errorf("checking out %s: %v\n%s", repo, err, output)
-	}
-	return nil
-}
-
-// benchmarkEnv returns a shared benchmark environment
-func benchmarkEnv(tb testing.TB) *Env {
-	setupEditorOnce.Do(func() {
-		dir := benchmarkDir()
-
-		var err error
-		sandbox, editor, awaiter, err = connectEditor(dir, fake.EditorConfig{})
-		if err != nil {
-			log.Fatalf("connecting editor: %v", err)
-		}
-
-		if err := awaiter.Await(context.Background(), InitialWorkspaceLoad); err != nil {
-			panic(err)
-		}
-	})
-
-	return &Env{
-		T:       tb,
-		Ctx:     context.Background(),
-		Editor:  editor,
-		Sandbox: sandbox,
-		Awaiter: awaiter,
-	}
-}
-
-// connectEditor connects a fake editor session in the given dir, using the
-// given editor config.
-func connectEditor(dir string, config fake.EditorConfig) (*fake.Sandbox, *fake.Editor, *Awaiter, error) {
-	s, err := fake.NewSandbox(&fake.SandboxConfig{
-		Workdir: dir,
-		GOPROXY: "https://proxy.golang.org",
-	})
-	if err != nil {
-		return nil, nil, nil, err
-	}
-
-	a := NewAwaiter(s.Workdir)
-	ts := getServer()
-	e, err := fake.NewEditor(s, config).Connect(context.Background(), ts, a.Hooks())
-	if err != nil {
-		return nil, nil, nil, err
-	}
-	return s, e, a, nil
-}
-
-// getServer returns a server connector that either starts a new in-process
-// server, or starts a separate gopls process.
-func getServer() servertest.Connector {
-	if *goplsPath != "" && *goplsCommit != "" {
-		panic("can't set both -gopls_path and -gopls_commit")
-	}
-	if *goplsPath != "" {
-		return &SidecarServer{*goplsPath}
-	}
-	if *goplsCommit != "" {
-		path := getInstalledGopls()
-		return &SidecarServer{path}
-	}
-	server := lsprpc.NewStreamServer(cache.New(nil, nil), false, hooks.Options)
-	return servertest.NewPipeServer(server, jsonrpc2.NewRawStream)
-}
-
-// getInstalledGopls builds gopls at the given -gopls_commit, returning the
-// path to the gopls binary.
-func getInstalledGopls() string {
-	if *goplsCommit == "" {
-		panic("must provide -gopls_commit")
-	}
-	toolsDir := filepath.Join(getTempDir(), "tools")
-	goplsPath := filepath.Join(toolsDir, "gopls", "gopls")
-
-	installGoplsOnce.Do(func() {
-		log.Printf("installing gopls: checking out x/tools@%s\n", *goplsCommit)
-		if err := shallowClone(toolsDir, "https://go.googlesource.com/tools", *goplsCommit); err != nil {
-			log.Fatal(err)
-		}
-
-		log.Println("installing gopls: building...")
-		bld := exec.Command("go", "build", ".")
-		bld.Dir = filepath.Join(getTempDir(), "tools", "gopls")
-		if output, err := bld.CombinedOutput(); err != nil {
-			log.Fatalf("building gopls: %v\n%s", err, output)
-		}
-
-		// Confirm that the resulting path now exists.
-		if _, err := os.Stat(goplsPath); err != nil {
-			log.Fatalf("os.Stat(%s): %v", goplsPath, err)
-		}
-	})
-	return goplsPath
-}
-
-// A SidecarServer starts (and connects to) a separate gopls process at the
-// given path.
-type SidecarServer struct {
-	goplsPath string
-}
-
-// Connect creates new io.Pipes and binds them to the underlying StreamServer.
-func (s *SidecarServer) Connect(ctx context.Context) jsonrpc2.Conn {
-	cmd := exec.CommandContext(ctx, s.goplsPath, "serve")
-
-	stdin, err := cmd.StdinPipe()
-	if err != nil {
-		log.Fatal(err)
-	}
-	stdout, err := cmd.StdoutPipe()
-	if err != nil {
-		log.Fatal(err)
-	}
-	cmd.Stderr = os.Stdout
-	if err := cmd.Start(); err != nil {
-		log.Fatalf("starting gopls: %v", err)
-	}
-
-	go cmd.Wait() // to free resources; error is ignored
-
-	clientStream := jsonrpc2.NewHeaderStream(fakenet.NewConn("stdio", stdout, stdin))
-	clientConn := jsonrpc2.NewConn(clientStream)
-	return clientConn
-}
diff -urN a/gopls/internal/regtest/bench/completion_test.go b/gopls/internal/regtest/bench/completion_test.go
--- a/gopls/internal/regtest/bench/completion_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/completion_test.go	1969-12-31 16:00:00
@@ -1,204 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"context"
-	"fmt"
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-)
-
-type completionBenchOptions struct {
-	file, locationRegexp string
-
-	// Hooks to run edits before initial completion
-	setup            func(*Env) // run before the benchmark starts
-	beforeCompletion func(*Env) // run before each completion
-}
-
-func benchmarkCompletion(options completionBenchOptions, b *testing.B) {
-	dir := benchmarkDir()
-
-	// Use a new environment for each test, to avoid any existing state from the
-	// previous session.
-	sandbox, editor, awaiter, err := connectEditor(dir, fake.EditorConfig{
-		Settings: map[string]interface{}{
-			"completionBudget": "1m", // arbitrary long completion budget
-		},
-	})
-	if err != nil {
-		b.Fatal(err)
-	}
-	ctx := context.Background()
-	defer func() {
-		if err := editor.Close(ctx); err != nil {
-			b.Errorf("closing editor: %v", err)
-		}
-	}()
-
-	env := &Env{
-		T:       b,
-		Ctx:     ctx,
-		Editor:  editor,
-		Sandbox: sandbox,
-		Awaiter: awaiter,
-	}
-
-	// Run edits required for this completion.
-	if options.setup != nil {
-		options.setup(env)
-	}
-
-	// Run a completion to make sure the system is warm.
-	pos := env.RegexpSearch(options.file, options.locationRegexp)
-	completions := env.Completion(options.file, pos)
-
-	if testing.Verbose() {
-		fmt.Println("Results:")
-		for i := 0; i < len(completions.Items); i++ {
-			fmt.Printf("\t%d. %v\n", i, completions.Items[i])
-		}
-	}
-
-	b.ResetTimer()
-
-	// Use a subtest to ensure that benchmarkCompletion does not itself get
-	// executed multiple times (as it is doing expensive environment
-	// initialization).
-	b.Run("completion", func(b *testing.B) {
-		for i := 0; i < b.N; i++ {
-			if options.beforeCompletion != nil {
-				options.beforeCompletion(env)
-			}
-			env.Completion(options.file, pos)
-		}
-	})
-}
-
-// endPosInBuffer returns the position for last character in the buffer for
-// the given file.
-func endPosInBuffer(env *Env, name string) fake.Pos {
-	buffer := env.BufferText(name)
-	lines := strings.Split(buffer, "\n")
-	numLines := len(lines)
-
-	return fake.Pos{
-		Line:   numLines - 1,
-		Column: len([]rune(lines[numLines-1])),
-	}
-}
-
-// Benchmark struct completion in tools codebase.
-func BenchmarkStructCompletion(b *testing.B) {
-	file := "internal/lsp/cache/session.go"
-
-	setup := func(env *Env) {
-		env.OpenFile(file)
-		originalBuffer := env.BufferText(file)
-		env.EditBuffer(file, fake.Edit{
-			End:  endPosInBuffer(env, file),
-			Text: originalBuffer + "\nvar testVariable map[string]bool = Session{}.\n",
-		})
-	}
-
-	benchmarkCompletion(completionBenchOptions{
-		file:           file,
-		locationRegexp: `var testVariable map\[string\]bool = Session{}(\.)`,
-		setup:          setup,
-	}, b)
-}
-
-// Benchmark import completion in tools codebase.
-func BenchmarkImportCompletion(b *testing.B) {
-	const file = "internal/lsp/source/completion/completion.go"
-	benchmarkCompletion(completionBenchOptions{
-		file:           file,
-		locationRegexp: `go\/()`,
-		setup:          func(env *Env) { env.OpenFile(file) },
-	}, b)
-}
-
-// Benchmark slice completion in tools codebase.
-func BenchmarkSliceCompletion(b *testing.B) {
-	file := "internal/lsp/cache/session.go"
-
-	setup := func(env *Env) {
-		env.OpenFile(file)
-		originalBuffer := env.BufferText(file)
-		env.EditBuffer(file, fake.Edit{
-			End:  endPosInBuffer(env, file),
-			Text: originalBuffer + "\nvar testVariable []byte = \n",
-		})
-	}
-
-	benchmarkCompletion(completionBenchOptions{
-		file:           file,
-		locationRegexp: `var testVariable \[\]byte (=)`,
-		setup:          setup,
-	}, b)
-}
-
-// Benchmark deep completion in function call in tools codebase.
-func BenchmarkFuncDeepCompletion(b *testing.B) {
-	file := "internal/lsp/source/completion/completion.go"
-	fileContent := `
-func (c *completer) _() {
-	c.inference.kindMatches(c.)
-}
-`
-	setup := func(env *Env) {
-		env.OpenFile(file)
-		originalBuffer := env.BufferText(file)
-		env.EditBuffer(file, fake.Edit{
-			End:  endPosInBuffer(env, file),
-			Text: originalBuffer + fileContent,
-		})
-	}
-
-	benchmarkCompletion(completionBenchOptions{
-		file:           file,
-		locationRegexp: `func \(c \*completer\) _\(\) {\n\tc\.inference\.kindMatches\((c)`,
-		setup:          setup,
-	}, b)
-}
-
-// Benchmark completion following an arbitrary edit.
-//
-// Edits force type-checked packages to be invalidated, so we want to measure
-// how long it takes before completion results are available.
-func BenchmarkCompletionFollowingEdit(b *testing.B) {
-	file := "internal/lsp/source/completion/completion2.go"
-	fileContent := `
-package completion
-
-func (c *completer) _() {
-	c.inference.kindMatches(c.)
-	// __MAGIC_STRING_1
-}
-`
-	setup := func(env *Env) {
-		env.CreateBuffer(file, fileContent)
-	}
-
-	n := 1
-	beforeCompletion := func(env *Env) {
-		old := fmt.Sprintf("__MAGIC_STRING_%d", n)
-		new := fmt.Sprintf("__MAGIC_STRING_%d", n+1)
-		n++
-		env.RegexpReplace(file, old, new)
-	}
-
-	benchmarkCompletion(completionBenchOptions{
-		file:             file,
-		locationRegexp:   `func \(c \*completer\) _\(\) {\n\tc\.inference\.kindMatches\((c)`,
-		setup:            setup,
-		beforeCompletion: beforeCompletion,
-	}, b)
-}
diff -urN a/gopls/internal/regtest/bench/didchange_test.go b/gopls/internal/regtest/bench/didchange_test.go
--- a/gopls/internal/regtest/bench/didchange_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/didchange_test.go	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-)
-
-// BenchmarkDidChange benchmarks modifications of a single file by making
-// synthetic modifications in a comment. It controls pacing by waiting for the
-// server to actually start processing the didChange notification before
-// proceeding. Notably it does not wait for diagnostics to complete.
-//
-// Uses -workdir and -file to control where the edits occur.
-func BenchmarkDidChange(b *testing.B) {
-	env := benchmarkEnv(b)
-	env.OpenFile(*file)
-	env.Await(env.DoneWithOpen())
-
-	// Insert the text we'll be modifying at the top of the file.
-	env.EditBuffer(*file, fake.Edit{Text: "// __REGTEST_PLACEHOLDER_0__\n"})
-
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		env.EditBuffer(*file, fake.Edit{
-			Start: fake.Pos{Line: 0, Column: 0},
-			End:   fake.Pos{Line: 1, Column: 0},
-			// Increment the placeholder text, to ensure cache misses.
-			Text: fmt.Sprintf("// __REGTEST_PLACEHOLDER_%d__\n", i+1),
-		})
-		env.Await(env.StartedChange())
-	}
-}
diff -urN a/gopls/internal/regtest/bench/editor_features_test.go b/gopls/internal/regtest/bench/editor_features_test.go
--- a/gopls/internal/regtest/bench/editor_features_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/editor_features_test.go	1969-12-31 16:00:00
@@ -1,55 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"fmt"
-	"testing"
-)
-
-func BenchmarkGoToDefinition(b *testing.B) {
-	env := benchmarkEnv(b)
-
-	env.OpenFile("internal/imports/mod.go")
-	pos := env.RegexpSearch("internal/imports/mod.go", "ModuleJSON")
-	env.GoToDefinition("internal/imports/mod.go", pos)
-	env.Await(env.DoneWithOpen())
-
-	b.ResetTimer()
-
-	for i := 0; i < b.N; i++ {
-		env.GoToDefinition("internal/imports/mod.go", pos)
-	}
-}
-
-func BenchmarkFindAllReferences(b *testing.B) {
-	env := benchmarkEnv(b)
-
-	env.OpenFile("internal/imports/mod.go")
-	pos := env.RegexpSearch("internal/imports/mod.go", "gopathwalk")
-	env.References("internal/imports/mod.go", pos)
-	env.Await(env.DoneWithOpen())
-
-	b.ResetTimer()
-
-	for i := 0; i < b.N; i++ {
-		env.References("internal/imports/mod.go", pos)
-	}
-}
-
-func BenchmarkRename(b *testing.B) {
-	env := benchmarkEnv(b)
-
-	env.OpenFile("internal/imports/mod.go")
-	env.Await(env.DoneWithOpen())
-
-	b.ResetTimer()
-
-	for i := 0; i < b.N; i++ {
-		pos := env.RegexpSearch("internal/imports/mod.go", "gopathwalk")
-		newName := fmt.Sprintf("%s%d", "gopathwalk", i)
-		env.Rename("internal/imports/mod.go", pos, newName)
-	}
-}
diff -urN a/gopls/internal/regtest/bench/iwl_test.go b/gopls/internal/regtest/bench/iwl_test.go
--- a/gopls/internal/regtest/bench/iwl_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/iwl_test.go	1969-12-31 16:00:00
@@ -1,36 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"context"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// BenchmarkInitialWorkspaceLoad benchmarks the initial workspace load time for
-// a new editing session.
-func BenchmarkInitialWorkspaceLoad(b *testing.B) {
-	dir := benchmarkDir()
-	b.ResetTimer()
-
-	ctx := context.Background()
-	for i := 0; i < b.N; i++ {
-		_, editor, awaiter, err := connectEditor(dir, fake.EditorConfig{})
-		if err != nil {
-			b.Fatal(err)
-		}
-		if err := awaiter.Await(ctx, InitialWorkspaceLoad); err != nil {
-			b.Fatal(err)
-		}
-		b.StopTimer()
-		if err := editor.Close(ctx); err != nil {
-			b.Fatal(err)
-		}
-		b.StartTimer()
-	}
-}
diff -urN a/gopls/internal/regtest/bench/mem_test.go b/gopls/internal/regtest/bench/mem_test.go
--- a/gopls/internal/regtest/bench/mem_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/mem_test.go	1969-12-31 16:00:00
@@ -1,39 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"runtime"
-	"testing"
-)
-
-// TestPrintMemStats measures the memory usage of loading a project.
-// It uses the same -didchange_dir flag as above.
-// Always run it in isolation since it measures global heap usage.
-//
-// Kubernetes example:
-//
-//	$ go test -v -run=TestPrintMemStats -workdir=$HOME/w/kubernetes
-//	TotalAlloc:      5766 MB
-//	HeapAlloc:       1984 MB
-//
-// Both figures exhibit variance of less than 1%.
-func TestPrintMemStats(t *testing.T) {
-	// This test only makes sense when run in isolation, so for now it is
-	// manually skipped.
-	//
-	// TODO(rfindley): figure out a better way to capture memstats as a benchmark
-	// metric.
-	t.Skip("unskip to run this test manually")
-
-	_ = benchmarkEnv(t)
-
-	runtime.GC()
-	runtime.GC()
-	var mem runtime.MemStats
-	runtime.ReadMemStats(&mem)
-	t.Logf("TotalAlloc:\t%d MB", mem.TotalAlloc/1e6)
-	t.Logf("HeapAlloc:\t%d MB", mem.HeapAlloc/1e6)
-}
diff -urN a/gopls/internal/regtest/bench/stress_test.go b/gopls/internal/regtest/bench/stress_test.go
--- a/gopls/internal/regtest/bench/stress_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/stress_test.go	1969-12-31 16:00:00
@@ -1,93 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"context"
-	"flag"
-	"fmt"
-	"testing"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-)
-
-// github.com/pilosa/pilosa is a repository that has historically caused
-// significant memory problems for Gopls. We use it for a simple stress test
-// that types arbitrarily in a file with lots of dependents.
-
-var pilosaPath = flag.String("pilosa_path", "", "Path to a directory containing "+
-	"github.com/pilosa/pilosa, for stress testing. Do not set this unless you "+
-	"know what you're doing!")
-
-func TestPilosaStress(t *testing.T) {
-	// TODO(rfindley): revisit this test and make it is hermetic: it should check
-	// out pilosa into a directory.
-	//
-	// Note: This stress test has not been run recently, and may no longer
-	// function properly.
-	if *pilosaPath == "" {
-		t.Skip("-pilosa_path not configured")
-	}
-
-	sandbox, err := fake.NewSandbox(&fake.SandboxConfig{
-		Workdir: *pilosaPath,
-		GOPROXY: "https://proxy.golang.org",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	server := lsprpc.NewStreamServer(cache.New(nil, nil), false, hooks.Options)
-	ts := servertest.NewPipeServer(server, jsonrpc2.NewRawStream)
-	ctx := context.Background()
-
-	editor, err := fake.NewEditor(sandbox, fake.EditorConfig{}).Connect(ctx, ts, fake.ClientHooks{})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	files := []string{
-		"cmd.go",
-		"internal/private.pb.go",
-		"roaring/roaring.go",
-		"roaring/roaring_internal_test.go",
-		"server/handler_test.go",
-	}
-	for _, file := range files {
-		if err := editor.OpenFile(ctx, file); err != nil {
-			t.Fatal(err)
-		}
-	}
-	ctx, cancel := context.WithTimeout(ctx, 10*time.Minute)
-	defer cancel()
-
-	i := 1
-	// MagicNumber is an identifier that occurs in roaring.go. Just change it
-	// arbitrarily.
-	if err := editor.RegexpReplace(ctx, "roaring/roaring.go", "MagicNumber", fmt.Sprintf("MagicNumber%d", 1)); err != nil {
-		t.Fatal(err)
-	}
-	for {
-		select {
-		case <-ctx.Done():
-			return
-		default:
-		}
-		if err := editor.RegexpReplace(ctx, "roaring/roaring.go", fmt.Sprintf("MagicNumber%d", i), fmt.Sprintf("MagicNumber%d", i+1)); err != nil {
-			t.Fatal(err)
-		}
-		// Simulate (very fast) typing.
-		//
-		// Typing 80 wpm ~150ms per keystroke.
-		time.Sleep(150 * time.Millisecond)
-		i++
-	}
-}
diff -urN a/gopls/internal/regtest/bench/workspace_symbols_test.go b/gopls/internal/regtest/bench/workspace_symbols_test.go
--- a/gopls/internal/regtest/bench/workspace_symbols_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/bench/workspace_symbols_test.go	1969-12-31 16:00:00
@@ -1,35 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package bench
-
-import (
-	"flag"
-	"fmt"
-	"testing"
-)
-
-var symbolQuery = flag.String("symbol_query", "test", "symbol query to use in benchmark")
-
-// BenchmarkWorkspaceSymbols benchmarks the time to execute a workspace symbols
-// request (controlled by the -symbol_query flag).
-func BenchmarkWorkspaceSymbols(b *testing.B) {
-	env := benchmarkEnv(b)
-
-	// Make an initial symbol query to warm the cache.
-	symbols := env.WorkspaceSymbol(*symbolQuery)
-
-	if testing.Verbose() {
-		fmt.Println("Results:")
-		for i := 0; i < len(symbols); i++ {
-			fmt.Printf("\t%d. %s (%s)\n", i, symbols[i].Name, symbols[i].ContainerName)
-		}
-	}
-
-	b.ResetTimer()
-
-	for i := 0; i < b.N; i++ {
-		env.WorkspaceSymbol(*symbolQuery)
-	}
-}
diff -urN a/gopls/internal/regtest/codelens/codelens_test.go b/gopls/internal/regtest/codelens/codelens_test.go
--- a/gopls/internal/regtest/codelens/codelens_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/codelens/codelens_test.go	1969-12-31 16:00:00
@@ -1,335 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package codelens
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/internal/bug"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-func TestDisablingCodeLens(t *testing.T) {
-	const workspace = `
--- go.mod --
-module codelens.test
-
-go 1.12
--- lib.go --
-package lib
-
-type Number int
-
-const (
-	Zero Number = iota
-	One
-	Two
-)
-
-//go:generate stringer -type=Number
-`
-	tests := []struct {
-		label        string
-		enabled      map[string]bool
-		wantCodeLens bool
-	}{
-		{
-			label:        "default",
-			wantCodeLens: true,
-		},
-		{
-			label:        "generate disabled",
-			enabled:      map[string]bool{string(command.Generate): false},
-			wantCodeLens: false,
-		},
-	}
-	for _, test := range tests {
-		t.Run(test.label, func(t *testing.T) {
-			WithOptions(
-				Settings{"codelenses": test.enabled},
-			).Run(t, workspace, func(t *testing.T, env *Env) {
-				env.OpenFile("lib.go")
-				lens := env.CodeLens("lib.go")
-				if gotCodeLens := len(lens) > 0; gotCodeLens != test.wantCodeLens {
-					t.Errorf("got codeLens: %t, want %t", gotCodeLens, test.wantCodeLens)
-				}
-			})
-		})
-	}
-}
-
-// This test confirms the full functionality of the code lenses for updating
-// dependencies in a go.mod file. It checks for the code lens that suggests
-// an update and then executes the command associated with that code lens. A
-// regression test for golang/go#39446. It also checks that these code lenses
-// only affect the diagnostics and contents of the containing go.mod file.
-func TestUpgradeCodelens(t *testing.T) {
-	const proxyWithLatest = `
--- golang.org/x/hello@v1.3.3/go.mod --
-module golang.org/x/hello
-
-go 1.12
--- golang.org/x/hello@v1.3.3/hi/hi.go --
-package hi
-
-var Goodbye error
--- golang.org/x/hello@v1.2.3/go.mod --
-module golang.org/x/hello
-
-go 1.12
--- golang.org/x/hello@v1.2.3/hi/hi.go --
-package hi
-
-var Goodbye error
-`
-
-	const shouldUpdateDep = `
--- go.work --
-go 1.18
-
-use (
-	./a
-	./b
-)
--- a/go.mod --
-module mod.com/a
-
-go 1.14
-
-require golang.org/x/hello v1.2.3
--- a/go.sum --
-golang.org/x/hello v1.2.3 h1:7Wesfkx/uBd+eFgPrq0irYj/1XfmbvLV8jZ/W7C2Dwg=
-golang.org/x/hello v1.2.3/go.mod h1:OgtlzsxVMUUdsdQCIDYgaauCTH47B8T8vofouNJfzgY=
--- a/main.go --
-package main
-
-import "golang.org/x/hello/hi"
-
-func main() {
-	_ = hi.Goodbye
-}
--- b/go.mod --
-module mod.com/b
-
-go 1.14
-
-require golang.org/x/hello v1.2.3
--- b/go.sum --
-golang.org/x/hello v1.2.3 h1:7Wesfkx/uBd+eFgPrq0irYj/1XfmbvLV8jZ/W7C2Dwg=
-golang.org/x/hello v1.2.3/go.mod h1:OgtlzsxVMUUdsdQCIDYgaauCTH47B8T8vofouNJfzgY=
--- b/main.go --
-package main
-
-import (
-	"golang.org/x/hello/hi"
-)
-
-func main() {
-	_ = hi.Goodbye
-}
-`
-
-	const wantGoModA = `module mod.com/a
-
-go 1.14
-
-require golang.org/x/hello v1.3.3
-`
-	// Applying the diagnostics or running the codelenses for a/go.mod
-	// should not change the contents of b/go.mod
-	const wantGoModB = `module mod.com/b
-
-go 1.14
-
-require golang.org/x/hello v1.2.3
-`
-
-	for _, commandTitle := range []string{
-		"Upgrade transitive dependencies",
-		"Upgrade direct dependencies",
-	} {
-		t.Run(commandTitle, func(t *testing.T) {
-			WithOptions(
-				ProxyFiles(proxyWithLatest),
-			).Run(t, shouldUpdateDep, func(t *testing.T, env *Env) {
-				env.OpenFile("a/go.mod")
-				env.OpenFile("b/go.mod")
-				var lens protocol.CodeLens
-				var found bool
-				for _, l := range env.CodeLens("a/go.mod") {
-					if l.Command.Title == commandTitle {
-						lens = l
-						found = true
-					}
-				}
-				if !found {
-					t.Fatalf("found no command with the title %s", commandTitle)
-				}
-				if _, err := env.Editor.ExecuteCommand(env.Ctx, &protocol.ExecuteCommandParams{
-					Command:   lens.Command.Command,
-					Arguments: lens.Command.Arguments,
-				}); err != nil {
-					t.Fatal(err)
-				}
-				env.Await(env.DoneWithChangeWatchedFiles())
-				if got := env.BufferText("a/go.mod"); got != wantGoModA {
-					t.Fatalf("a/go.mod upgrade failed:\n%s", compare.Text(wantGoModA, got))
-				}
-				if got := env.BufferText("b/go.mod"); got != wantGoModB {
-					t.Fatalf("b/go.mod changed unexpectedly:\n%s", compare.Text(wantGoModB, got))
-				}
-			})
-		})
-	}
-	for _, vendoring := range []bool{false, true} {
-		t.Run(fmt.Sprintf("Upgrade individual dependency vendoring=%v", vendoring), func(t *testing.T) {
-			WithOptions(ProxyFiles(proxyWithLatest)).Run(t, shouldUpdateDep, func(t *testing.T, env *Env) {
-				if vendoring {
-					env.RunGoCommandInDir("a", "mod", "vendor")
-				}
-				env.Await(env.DoneWithChangeWatchedFiles())
-				env.OpenFile("a/go.mod")
-				env.OpenFile("b/go.mod")
-				env.ExecuteCodeLensCommand("a/go.mod", command.CheckUpgrades, nil)
-				d := &protocol.PublishDiagnosticsParams{}
-				env.Await(
-					OnceMet(
-						env.DiagnosticAtRegexpWithMessage("a/go.mod", `require`, "can be upgraded"),
-						ReadDiagnostics("a/go.mod", d),
-						// We do not want there to be a diagnostic for b/go.mod,
-						// but there may be some subtlety in timing here, where this
-						// should always succeed, but may not actually test the correct
-						// behavior.
-						env.NoDiagnosticAtRegexp("b/go.mod", `require`),
-					),
-				)
-				// Check for upgrades in b/go.mod and then clear them.
-				env.ExecuteCodeLensCommand("b/go.mod", command.CheckUpgrades, nil)
-				env.Await(env.DiagnosticAtRegexpWithMessage("b/go.mod", `require`, "can be upgraded"))
-				env.ExecuteCodeLensCommand("b/go.mod", command.ResetGoModDiagnostics, nil)
-				env.Await(EmptyDiagnostics("b/go.mod"))
-
-				// Apply the diagnostics to a/go.mod.
-				env.ApplyQuickFixes("a/go.mod", d.Diagnostics)
-				env.Await(env.DoneWithChangeWatchedFiles())
-				if got := env.BufferText("a/go.mod"); got != wantGoModA {
-					t.Fatalf("a/go.mod upgrade failed:\n%s", compare.Text(wantGoModA, got))
-				}
-				if got := env.BufferText("b/go.mod"); got != wantGoModB {
-					t.Fatalf("b/go.mod changed unexpectedly:\n%s", compare.Text(wantGoModB, got))
-				}
-			})
-		})
-	}
-}
-
-func TestUnusedDependenciesCodelens(t *testing.T) {
-	const proxy = `
--- golang.org/x/hello@v1.0.0/go.mod --
-module golang.org/x/hello
-
-go 1.14
--- golang.org/x/hello@v1.0.0/hi/hi.go --
-package hi
-
-var Goodbye error
--- golang.org/x/unused@v1.0.0/go.mod --
-module golang.org/x/unused
-
-go 1.14
--- golang.org/x/unused@v1.0.0/nouse/nouse.go --
-package nouse
-
-var NotUsed error
-`
-
-	const shouldRemoveDep = `
--- go.mod --
-module mod.com
-
-go 1.14
-
-require golang.org/x/hello v1.0.0
-require golang.org/x/unused v1.0.0
--- go.sum --
-golang.org/x/hello v1.0.0 h1:qbzE1/qT0/zojAMd/JcPsO2Vb9K4Bkeyq0vB2JGMmsw=
-golang.org/x/hello v1.0.0/go.mod h1:WW7ER2MRNXWA6c8/4bDIek4Hc/+DofTrMaQQitGXcco=
-golang.org/x/unused v1.0.0 h1:LecSbCn5P3vTcxubungSt1Pn4D/WocCaiWOPDC0y0rw=
-golang.org/x/unused v1.0.0/go.mod h1:ihoW8SgWzugwwj0N2SfLfPZCxTB1QOVfhMfB5PWTQ8U=
--- main.go --
-package main
-
-import "golang.org/x/hello/hi"
-
-func main() {
-	_ = hi.Goodbye
-}
-`
-	WithOptions(ProxyFiles(proxy)).Run(t, shouldRemoveDep, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.ExecuteCodeLensCommand("go.mod", command.Tidy, nil)
-		env.Await(env.DoneWithChangeWatchedFiles())
-		got := env.BufferText("go.mod")
-		const wantGoMod = `module mod.com
-
-go 1.14
-
-require golang.org/x/hello v1.0.0
-`
-		if got != wantGoMod {
-			t.Fatalf("go.mod tidy failed:\n%s", compare.Text(wantGoMod, got))
-		}
-	})
-}
-
-func TestRegenerateCgo(t *testing.T) {
-	testenv.NeedsTool(t, "cgo")
-	const workspace = `
--- go.mod --
-module example.com
-
-go 1.12
--- cgo.go --
-package x
-
-/*
-int fortythree() { return 42; }
-*/
-import "C"
-
-func Foo() {
-	print(C.fortytwo())
-}
-`
-	Run(t, workspace, func(t *testing.T, env *Env) {
-		// Open the file. We have a nonexistant symbol that will break cgo processing.
-		env.OpenFile("cgo.go")
-		env.Await(env.DiagnosticAtRegexpWithMessage("cgo.go", ``, "go list failed to return CompiledGoFiles"))
-
-		// Fix the C function name. We haven't regenerated cgo, so nothing should be fixed.
-		env.RegexpReplace("cgo.go", `int fortythree`, "int fortytwo")
-		env.SaveBuffer("cgo.go")
-		env.Await(OnceMet(
-			env.DoneWithSave(),
-			env.DiagnosticAtRegexpWithMessage("cgo.go", ``, "go list failed to return CompiledGoFiles"),
-		))
-
-		// Regenerate cgo, fixing the diagnostic.
-		env.ExecuteCodeLensCommand("cgo.go", command.RegenerateCgo, nil)
-		env.Await(EmptyDiagnostics("cgo.go"))
-	})
-}
diff -urN a/gopls/internal/regtest/codelens/gcdetails_test.go b/gopls/internal/regtest/codelens/gcdetails_test.go
--- a/gopls/internal/regtest/codelens/gcdetails_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/codelens/gcdetails_test.go	1969-12-31 16:00:00
@@ -1,131 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package codelens
-
-import (
-	"runtime"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-)
-
-func TestGCDetails_Toggle(t *testing.T) {
-	if runtime.GOOS == "android" {
-		t.Skipf("the gc details code lens doesn't work on Android")
-	}
-
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.15
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println(42)
-}
-`
-	WithOptions(
-		Settings{
-			"codelenses": map[string]bool{
-				"gc_details": true,
-			},
-		},
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.ExecuteCodeLensCommand("main.go", command.GCDetails, nil)
-		d := &protocol.PublishDiagnosticsParams{}
-		env.Await(
-			OnceMet(
-				DiagnosticAt("main.go", 5, 13),
-				ReadDiagnostics("main.go", d),
-			),
-		)
-		// Confirm that the diagnostics come from the gc details code lens.
-		var found bool
-		for _, d := range d.Diagnostics {
-			if d.Severity != protocol.SeverityInformation {
-				t.Fatalf("unexpected diagnostic severity %v, wanted Information", d.Severity)
-			}
-			if strings.Contains(d.Message, "42 escapes") {
-				found = true
-			}
-		}
-		if !found {
-			t.Fatalf(`expected to find diagnostic with message "escape(42 escapes to heap)", found none`)
-		}
-
-		// Editing a buffer should cause gc_details diagnostics to disappear, since
-		// they only apply to saved buffers.
-		env.EditBuffer("main.go", fake.NewEdit(0, 0, 0, 0, "\n\n"))
-		env.Await(EmptyDiagnostics("main.go"))
-
-		// Saving a buffer should re-format back to the original state, and
-		// re-enable the gc_details diagnostics.
-		env.SaveBuffer("main.go")
-		env.Await(DiagnosticAt("main.go", 5, 13))
-
-		// Toggle the GC details code lens again so now it should be off.
-		env.ExecuteCodeLensCommand("main.go", command.GCDetails, nil)
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
-
-// Test for the crasher in golang/go#54199
-func TestGCDetails_NewFile(t *testing.T) {
-	bug.PanicOnBugs = false
-	const src = `
--- go.mod --
-module mod.test
-
-go 1.12
-`
-
-	WithOptions(
-		Settings{
-			"codelenses": map[string]bool{
-				"gc_details": true,
-			},
-		},
-	).Run(t, src, func(t *testing.T, env *Env) {
-		env.CreateBuffer("p_test.go", "")
-
-		const gcDetailsCommand = "gopls." + string(command.GCDetails)
-
-		hasGCDetails := func() bool {
-			lenses := env.CodeLens("p_test.go") // should not crash
-			for _, lens := range lenses {
-				if lens.Command.Command == gcDetailsCommand {
-					return true
-				}
-			}
-			return false
-		}
-
-		// With an empty file, we shouldn't get the gc_details codelens because
-		// there is nowhere to position it (it needs a package name).
-		if hasGCDetails() {
-			t.Errorf("got the gc_details codelens for an empty file")
-		}
-
-		// Edit to provide a package name.
-		env.EditBuffer("p_test.go", fake.NewEdit(0, 0, 0, 0, "package p"))
-
-		// Now we should get the gc_details codelens.
-		if !hasGCDetails() {
-			t.Errorf("didn't get the gc_details codelens for a valid non-empty Go file")
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/completion/completion18_test.go b/gopls/internal/regtest/completion/completion18_test.go
--- a/gopls/internal/regtest/completion/completion18_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/completion/completion18_test.go	1969-12-31 16:00:00
@@ -1,123 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package completion
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// test generic receivers
-func TestGenericReceiver(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-type SyncMap[K any, V comparable] struct {}
-func (s *SyncMap[K,V]) f() {}
-type XX[T any] struct {}
-type UU[T any] struct {}
-func (s SyncMap[XX,string]) g(v UU) {}
-`
-
-	tests := []struct {
-		pat  string
-		want []string
-	}{
-		{"s .Syn", []string{"SyncMap[K, V]"}},
-		{"Map.X", []string{}}, // This is probably wrong, Maybe "XX"?
-		{"v U", []string{"UU", "uint", "uint16", "uint32", "uint64", "uint8", "uintptr"}}, // not U[T]
-	}
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.Await(env.DoneWithOpen())
-		for _, tst := range tests {
-			pos := env.RegexpSearch("main.go", tst.pat)
-			pos.Column += len(tst.pat)
-			completions := env.Completion("main.go", pos)
-			result := compareCompletionResults(tst.want, completions.Items)
-			if result != "" {
-				t.Errorf("%s: wanted %v", result, tst.want)
-				for i, g := range completions.Items {
-					t.Errorf("got %d %s %s", i, g.Label, g.Detail)
-				}
-			}
-		}
-	})
-}
-func TestFuzzFunc(t *testing.T) {
-	// use the example from the package documentation
-	modfile := `
--- go.mod --
-module mod.com
-
-go 1.18
-`
-	part0 := `package foo
-import "testing"
-func FuzzNone(f *testing.F) {
-	f.Add(12) // better not find this f.Add
-}
-func FuzzHex(f *testing.F) {
-	for _, seed := range [][]byte{{}, {0}, {9}, {0xa}, {0xf}, {1, 2, 3, 4}} {
-		f.Ad`
-	part1 := `d(seed)
-	}
-	f.F`
-	part2 := `uzz(func(t *testing.T, in []byte) {
-		enc := hex.EncodeToString(in)
-		out, err := hex.DecodeString(enc)
-		if err != nil {
-		  f.Failed()
-		}
-		if !bytes.Equal(in, out) {
-		  t.Fatalf("%v: round trip: %v, %s", in, out, f.Name())
-		}
-	})
-}
-`
-	data := modfile + `-- a_test.go --
-` + part0 + `
--- b_test.go --
-` + part0 + part1 + `
--- c_test.go --
-` + part0 + part1 + part2
-
-	tests := []struct {
-		file   string
-		pat    string
-		offset int // from the beginning of pat to what the user just typed
-		want   []string
-	}{
-		{"a_test.go", "f.Ad", 3, []string{"Add"}},
-		{"c_test.go", " f.F", 4, []string{"Failed"}},
-		{"c_test.go", "f.N", 3, []string{"Name"}},
-		{"b_test.go", "f.F", 3, []string{"Fuzz(func(t *testing.T, a []byte)", "Fail", "FailNow",
-			"Failed", "Fatal", "Fatalf"}},
-	}
-	Run(t, data, func(t *testing.T, env *Env) {
-		for _, test := range tests {
-			env.OpenFile(test.file)
-			env.Await(env.DoneWithOpen())
-			pos := env.RegexpSearch(test.file, test.pat)
-			pos.Column += test.offset // character user just typed? will type?
-			completions := env.Completion(test.file, pos)
-			result := compareCompletionResults(test.want, completions.Items)
-			if result != "" {
-				t.Errorf("pat %q %q", test.pat, result)
-				for i, it := range completions.Items {
-					t.Errorf("%d got %q %q", i, it.Label, it.Detail)
-				}
-			}
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/completion/completion_test.go b/gopls/internal/regtest/completion/completion_test.go
--- a/gopls/internal/regtest/completion/completion_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/completion/completion_test.go	1969-12-31 16:00:00
@@ -1,727 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"fmt"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/testenv"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/blah/blah.go --
-package hello
-
-const Name = "Hello"
-`
-
-func TestPackageCompletion(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- fruits/apple.go --
-package apple
-
-fun apple() int {
-	return 0
-}
-
--- fruits/testfile.go --
-// this is a comment
-
-/*
- this is a multiline comment
-*/
-
-import "fmt"
-
-func test() {}
-
--- fruits/testfile2.go --
-package
-
--- fruits/testfile3.go --
-pac
--- 123f_r.u~its-123/testfile.go --
-package
-
--- .invalid-dir@-name/testfile.go --
-package
-`
-	var (
-		testfile4 = ""
-		testfile5 = "/*a comment*/ "
-		testfile6 = "/*a comment*/\n"
-	)
-	for _, tc := range []struct {
-		name          string
-		filename      string
-		content       *string
-		triggerRegexp string
-		want          []string
-		editRegexp    string
-	}{
-		{
-			name:          "package completion at valid position",
-			filename:      "fruits/testfile.go",
-			triggerRegexp: "\n()",
-			want:          []string{"package apple", "package apple_test", "package fruits", "package fruits_test", "package main"},
-			editRegexp:    "\n()",
-		},
-		{
-			name:          "package completion in a comment",
-			filename:      "fruits/testfile.go",
-			triggerRegexp: "th(i)s",
-			want:          nil,
-		},
-		{
-			name:          "package completion in a multiline comment",
-			filename:      "fruits/testfile.go",
-			triggerRegexp: `\/\*\n()`,
-			want:          nil,
-		},
-		{
-			name:          "package completion at invalid position",
-			filename:      "fruits/testfile.go",
-			triggerRegexp: "import \"fmt\"\n()",
-			want:          nil,
-		},
-		{
-			name:          "package completion after keyword 'package'",
-			filename:      "fruits/testfile2.go",
-			triggerRegexp: "package()",
-			want:          []string{"package apple", "package apple_test", "package fruits", "package fruits_test", "package main"},
-			editRegexp:    "package\n",
-		},
-		{
-			name:          "package completion with 'pac' prefix",
-			filename:      "fruits/testfile3.go",
-			triggerRegexp: "pac()",
-			want:          []string{"package apple", "package apple_test", "package fruits", "package fruits_test", "package main"},
-			editRegexp:    "pac",
-		},
-		{
-			name:          "package completion for empty file",
-			filename:      "fruits/testfile4.go",
-			triggerRegexp: "^$",
-			content:       &testfile4,
-			want:          []string{"package apple", "package apple_test", "package fruits", "package fruits_test", "package main"},
-			editRegexp:    "^$",
-		},
-		{
-			name:          "package completion without terminal newline",
-			filename:      "fruits/testfile5.go",
-			triggerRegexp: `\*\/ ()`,
-			content:       &testfile5,
-			want:          []string{"package apple", "package apple_test", "package fruits", "package fruits_test", "package main"},
-			editRegexp:    `\*\/ ()`,
-		},
-		{
-			name:          "package completion on terminal newline",
-			filename:      "fruits/testfile6.go",
-			triggerRegexp: `\*\/\n()`,
-			content:       &testfile6,
-			want:          []string{"package apple", "package apple_test", "package fruits", "package fruits_test", "package main"},
-			editRegexp:    `\*\/\n()`,
-		},
-		// Issue golang/go#44680
-		{
-			name:          "package completion for dir name with punctuation",
-			filename:      "123f_r.u~its-123/testfile.go",
-			triggerRegexp: "package()",
-			want:          []string{"package fruits123", "package fruits123_test", "package main"},
-			editRegexp:    "package\n",
-		},
-		{
-			name:          "package completion for invalid dir name",
-			filename:      ".invalid-dir@-name/testfile.go",
-			triggerRegexp: "package()",
-			want:          []string{"package main"},
-			editRegexp:    "package\n",
-		},
-	} {
-		t.Run(tc.name, func(t *testing.T) {
-			Run(t, files, func(t *testing.T, env *Env) {
-				if tc.content != nil {
-					env.WriteWorkspaceFile(tc.filename, *tc.content)
-					env.Await(
-						env.DoneWithChangeWatchedFiles(),
-					)
-				}
-				env.OpenFile(tc.filename)
-				completions := env.Completion(tc.filename, env.RegexpSearch(tc.filename, tc.triggerRegexp))
-
-				// Check that the completion item suggestions are in the range
-				// of the file.
-				lineCount := len(strings.Split(env.BufferText(tc.filename), "\n"))
-				for _, item := range completions.Items {
-					if start := int(item.TextEdit.Range.Start.Line); start >= lineCount {
-						t.Fatalf("unexpected text edit range start line number: got %d, want less than %d", start, lineCount)
-					}
-					if end := int(item.TextEdit.Range.End.Line); end >= lineCount {
-						t.Fatalf("unexpected text edit range end line number: got %d, want less than %d", end, lineCount)
-					}
-				}
-
-				if tc.want != nil {
-					start, end := env.RegexpRange(tc.filename, tc.editRegexp)
-					expectedRng := protocol.Range{
-						Start: fake.Pos.ToProtocolPosition(start),
-						End:   fake.Pos.ToProtocolPosition(end),
-					}
-					for _, item := range completions.Items {
-						gotRng := item.TextEdit.Range
-						if expectedRng != gotRng {
-							t.Errorf("unexpected completion range for completion item %s: got %v, want %v",
-								item.Label, gotRng, expectedRng)
-						}
-					}
-				}
-
-				diff := compareCompletionResults(tc.want, completions.Items)
-				if diff != "" {
-					t.Error(diff)
-				}
-			})
-		})
-	}
-}
-
-func TestPackageNameCompletion(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- math/add.go --
-package ma
-`
-
-	want := []string{"ma", "ma_test", "main", "math", "math_test"}
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("math/add.go")
-		completions := env.Completion("math/add.go", fake.Pos{
-			Line:   0,
-			Column: 10,
-		})
-
-		diff := compareCompletionResults(want, completions.Items)
-		if diff != "" {
-			t.Fatal(diff)
-		}
-	})
-}
-
-func compareCompletionResults(want []string, gotItems []protocol.CompletionItem) string {
-	if len(gotItems) != len(want) {
-		return fmt.Sprintf("got %v completion(s), want %v", len(gotItems), len(want))
-	}
-
-	var got []string
-	for _, item := range gotItems {
-		got = append(got, item.Label)
-		if item.Label != item.InsertText && item.TextEdit == nil {
-			// Label should be the same as InsertText, if InsertText is to be used
-			return fmt.Sprintf("label not the same as InsertText %#v", item)
-		}
-	}
-
-	for i, v := range got {
-		if v != want[i] {
-			return fmt.Sprintf("%d completion result not the same: got %q, want %q", i, v, want[i])
-		}
-	}
-
-	return ""
-}
-
-func TestUnimportedCompletion(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.14
-
-require example.com v1.2.3
--- go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- main.go --
-package main
-
-func main() {
-	_ = blah
-}
--- main2.go --
-package main
-
-import "example.com/blah"
-
-func _() {
-	_ = blah.Hello
-}
-`
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		// Make sure the dependency is in the module cache and accessible for
-		// unimported completions, and then remove it before proceeding.
-		env.RemoveWorkspaceFile("main2.go")
-		env.RunGoCommand("mod", "tidy")
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		// Trigger unimported completions for the example.com/blah package.
-		env.OpenFile("main.go")
-		env.Await(env.DoneWithOpen())
-		pos := env.RegexpSearch("main.go", "ah")
-		completions := env.Completion("main.go", pos)
-		if len(completions.Items) == 0 {
-			t.Fatalf("no completion items")
-		}
-		env.AcceptCompletion("main.go", pos, completions.Items[0])
-		env.Await(env.DoneWithChange())
-
-		// Trigger completions once again for the blah.<> selector.
-		env.RegexpReplace("main.go", "_ = blah", "_ = blah.")
-		env.Await(env.DoneWithChange())
-		pos = env.RegexpSearch("main.go", "\n}")
-		completions = env.Completion("main.go", pos)
-		if len(completions.Items) != 1 {
-			t.Fatalf("expected 1 completion item, got %v", len(completions.Items))
-		}
-		item := completions.Items[0]
-		if item.Label != "Name" {
-			t.Fatalf("expected completion item blah.Name, got %v", item.Label)
-		}
-		env.AcceptCompletion("main.go", pos, item)
-
-		// Await the diagnostics to add example.com/blah to the go.mod file.
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", `"example.com/blah"`),
-		)
-	})
-}
-
-// Test that completions still work with an undownloaded module, golang/go#43333.
-func TestUndownloadedModule(t *testing.T) {
-	// mod.com depends on example.com, but only in a file that's hidden by a
-	// build tag, so the IWL won't download example.com. That will cause errors
-	// in the go list -m call performed by the imports package.
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.14
-
-require example.com v1.2.3
--- go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- useblah.go --
-// +build hidden
-
-package pkg
-import "example.com/blah"
-var _ = blah.Name
--- mainmod/mainmod.go --
-package mainmod
-
-const Name = "mainmod"
-`
-	WithOptions(ProxyFiles(proxy)).Run(t, files, func(t *testing.T, env *Env) {
-		env.CreateBuffer("import.go", "package pkg\nvar _ = mainmod.Name\n")
-		env.SaveBuffer("import.go")
-		content := env.ReadWorkspaceFile("import.go")
-		if !strings.Contains(content, `import "mod.com/mainmod`) {
-			t.Errorf("expected import of mod.com/mainmod in %q", content)
-		}
-	})
-}
-
-// Test that we can doctor the source code enough so the file is
-// parseable and completion works as expected.
-func TestSourceFixup(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo.go --
-package foo
-
-func _() {
-	var s S
-	if s.
-}
-
-type S struct {
-	i int
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo.go")
-		completions := env.Completion("foo.go", env.RegexpSearch("foo.go", `if s\.()`))
-		diff := compareCompletionResults([]string{"i"}, completions.Items)
-		if diff != "" {
-			t.Fatal(diff)
-		}
-	})
-}
-
-func TestCompletion_Issue45510(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func _() {
-	type a *a
-	var aaaa1, aaaa2 a
-	var _ a = aaaa
-
-	type b a
-	var bbbb1, bbbb2 b
-	var _ b = bbbb
-}
-
-type (
-	c *d
-	d *e
-	e **c
-)
-
-func _() {
-	var (
-		xxxxc c
-		xxxxd d
-		xxxxe e
-	)
-
-	var _ c = xxxx
-	var _ d = xxxx
-	var _ e = xxxx
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-
-		tests := []struct {
-			re   string
-			want []string
-		}{
-			{`var _ a = aaaa()`, []string{"aaaa1", "aaaa2"}},
-			{`var _ b = bbbb()`, []string{"bbbb1", "bbbb2"}},
-			{`var _ c = xxxx()`, []string{"xxxxc", "xxxxd", "xxxxe"}},
-			{`var _ d = xxxx()`, []string{"xxxxc", "xxxxd", "xxxxe"}},
-			{`var _ e = xxxx()`, []string{"xxxxc", "xxxxd", "xxxxe"}},
-		}
-		for _, tt := range tests {
-			completions := env.Completion("main.go", env.RegexpSearch("main.go", tt.re))
-			diff := compareCompletionResults(tt.want, completions.Items)
-			if diff != "" {
-				t.Errorf("%s: %s", tt.re, diff)
-			}
-		}
-	})
-}
-
-func TestCompletionDeprecation(t *testing.T) {
-	const files = `
--- go.mod --
-module test.com
-
-go 1.16
--- prog.go --
-package waste
-// Deprecated, use newFoof
-func fooFunc() bool {
-	return false
-}
-
-// Deprecated
-const badPi = 3.14
-
-func doit() {
-	if fooF
-	panic()
-	x := badP
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("prog.go")
-		pos := env.RegexpSearch("prog.go", "if fooF")
-		pos.Column += len("if fooF")
-		completions := env.Completion("prog.go", pos)
-		diff := compareCompletionResults([]string{"fooFunc"}, completions.Items)
-		if diff != "" {
-			t.Error(diff)
-		}
-		if completions.Items[0].Tags == nil {
-			t.Errorf("expected Tags to show deprecation %#v", diff[0])
-		}
-		pos = env.RegexpSearch("prog.go", "= badP")
-		pos.Column += len("= badP")
-		completions = env.Completion("prog.go", pos)
-		diff = compareCompletionResults([]string{"badPi"}, completions.Items)
-		if diff != "" {
-			t.Error(diff)
-		}
-		if completions.Items[0].Tags == nil {
-			t.Errorf("expected Tags to show deprecation %#v", diff[0])
-		}
-	})
-}
-
-func TestUnimportedCompletion_VSCodeIssue1489(t *testing.T) {
-	const src = `
--- go.mod --
-module mod.com
-
-go 1.14
-
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("a")
-	math.Sqr
-}
-`
-	WithOptions(
-		WindowsLineEndings(),
-	).Run(t, src, func(t *testing.T, env *Env) {
-		// Trigger unimported completions for the example.com/blah package.
-		env.OpenFile("main.go")
-		env.Await(env.DoneWithOpen())
-		pos := env.RegexpSearch("main.go", "Sqr()")
-		completions := env.Completion("main.go", pos)
-		if len(completions.Items) == 0 {
-			t.Fatalf("no completion items")
-		}
-		env.AcceptCompletion("main.go", pos, completions.Items[0])
-		env.Await(env.DoneWithChange())
-		got := env.BufferText("main.go")
-		want := "package main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"math\"\r\n)\r\n\r\nfunc main() {\r\n\tfmt.Println(\"a\")\r\n\tmath.Sqrt(${1:})\r\n}\r\n"
-		if got != want {
-			t.Errorf("unimported completion: got %q, want %q", got, want)
-		}
-	})
-}
-
-func TestDefinition(t *testing.T) {
-	stuff := `
--- go.mod --
-module mod.com
-
-go 1.18
--- a_test.go --
-package foo
-func T()
-func TestG()
-func TestM()
-func TestMi()
-func Ben()
-func Fuz()
-func Testx()
-func TestMe(t *testing.T)
-func BenchmarkFoo()
-`
-	// All those parentheses are needed for the completion code to see
-	// later lines as being definitions
-	tests := []struct {
-		pat  string
-		want []string
-	}{
-		{"T", []string{"TestXxx(t *testing.T)", "TestMain(m *testing.M)"}},
-		{"TestM", []string{"TestMain(m *testing.M)", "TestM(t *testing.T)"}},
-		{"TestMi", []string{"TestMi(t *testing.T)"}},
-		{"TestG", []string{"TestG(t *testing.T)"}},
-		{"B", []string{"BenchmarkXxx(b *testing.B)"}},
-		{"BenchmarkFoo", []string{"BenchmarkFoo(b *testing.B)"}},
-		{"F", []string{"FuzzXxx(f *testing.F)"}},
-		{"Testx", nil},
-		{"TestMe", []string{"TestMe"}},
-	}
-	fname := "a_test.go"
-	Run(t, stuff, func(t *testing.T, env *Env) {
-		env.OpenFile(fname)
-		env.Await(env.DoneWithOpen())
-		for _, tst := range tests {
-			pos := env.RegexpSearch(fname, tst.pat)
-			pos.Column += len(tst.pat)
-			completions := env.Completion(fname, pos)
-			result := compareCompletionResults(tst.want, completions.Items)
-			if result != "" {
-				t.Errorf("%s failed: %s:%q", tst.pat, result, tst.want)
-				for i, it := range completions.Items {
-					t.Errorf("%d got %q %q", i, it.Label, it.Detail)
-				}
-			}
-		}
-	})
-}
-
-// Test that completing a definition replaces source text when applied, golang/go#56852.
-// Note: With go <= 1.16 the completions does not add parameters and fails these tests.
-func TestDefinitionReplaceRange(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.17
-`
-
-	tests := []struct {
-		name          string
-		before, after string
-	}{
-		{
-			name: "func TestMa",
-			before: `
-package foo_test
-
-func TestMa
-`,
-			after: `
-package foo_test
-
-func TestMain(m *testing.M)
-`,
-		},
-		{
-			name: "func TestSome",
-			before: `
-package foo_test
-
-func TestSome
-`,
-			after: `
-package foo_test
-
-func TestSome(t *testing.T)
-`,
-		},
-		{
-			name: "func Bench",
-			before: `
-package foo_test
-
-func Bench
-`,
-			// Note: Snippet with escaped }.
-			after: `
-package foo_test
-
-func Benchmark${1:Xxx}(b *testing.B) {
-$0
-\}
-`,
-		},
-	}
-
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.CreateBuffer("foo_test.go", "")
-
-		for _, tst := range tests {
-			tst.before = strings.Trim(tst.before, "\n")
-			tst.after = strings.Trim(tst.after, "\n")
-			env.SetBufferContent("foo_test.go", tst.before)
-
-			pos := env.RegexpSearch("foo_test.go", tst.name)
-			pos.Column = len(tst.name)
-			completions := env.Completion("foo_test.go", pos)
-			if len(completions.Items) == 0 {
-				t.Fatalf("no completion items")
-			}
-
-			env.AcceptCompletion("foo_test.go", pos, completions.Items[0])
-			env.Await(env.DoneWithChange())
-			if buf := env.BufferText("foo_test.go"); buf != tst.after {
-				t.Errorf("incorrect completion: got %q, want %q", buf, tst.after)
-			}
-		}
-	})
-}
-
-func TestGoWorkCompletion(t *testing.T) {
-	const files = `
--- go.work --
-go 1.18
-
-use ./a
-use ./a/ba
-use ./a/b/
-use ./dir/foo
-use ./dir/foobar/
--- a/go.mod --
--- go.mod --
--- a/bar/go.mod --
--- a/b/c/d/e/f/go.mod --
--- dir/bar --
--- dir/foobar/go.mod --
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.work")
-
-		tests := []struct {
-			re   string
-			want []string
-		}{
-			{`use ()\.`, []string{".", "./a", "./a/bar", "./dir/foobar"}},
-			{`use \.()`, []string{"", "/a", "/a/bar", "/dir/foobar"}},
-			{`use \./()`, []string{"a", "a/bar", "dir/foobar"}},
-			{`use ./a()`, []string{"", "/b/c/d/e/f", "/bar"}},
-			{`use ./a/b()`, []string{"/c/d/e/f", "ar"}},
-			{`use ./a/b/()`, []string{`c/d/e/f`}},
-			{`use ./a/ba()`, []string{"r"}},
-			{`use ./dir/foo()`, []string{"bar"}},
-			{`use ./dir/foobar/()`, []string{}},
-		}
-		for _, tt := range tests {
-			completions := env.Completion("go.work", env.RegexpSearch("go.work", tt.re))
-			diff := compareCompletionResults(tt.want, completions.Items)
-			if diff != "" {
-				t.Errorf("%s: %s", tt.re, diff)
-			}
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/completion/postfix_snippet_test.go b/gopls/internal/regtest/completion/postfix_snippet_test.go
--- a/gopls/internal/regtest/completion/postfix_snippet_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/completion/postfix_snippet_test.go	1969-12-31 16:00:00
@@ -1,464 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package completion
-
-import (
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestPostfixSnippetCompletion(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-`
-
-	cases := []struct {
-		name          string
-		before, after string
-	}{
-		{
-			name: "sort",
-			before: `
-package foo
-
-func _() {
-	var foo []int
-	foo.sort
-}
-`,
-			after: `
-package foo
-
-import "sort"
-
-func _() {
-	var foo []int
-	sort.Slice(foo, func(i, j int) bool {
-	$0
-})
-}
-`,
-		},
-		{
-			name: "sort_renamed_sort_package",
-			before: `
-package foo
-
-import blahsort "sort"
-
-var j int
-
-func _() {
-	var foo []int
-	foo.sort
-}
-`,
-			after: `
-package foo
-
-import blahsort "sort"
-
-var j int
-
-func _() {
-	var foo []int
-	blahsort.Slice(foo, func(i, j2 int) bool {
-	$0
-})
-}
-`,
-		},
-		{
-			name: "last",
-			before: `
-package foo
-
-func _() {
-	var s struct { i []int }
-	s.i.last
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var s struct { i []int }
-	s.i[len(s.i)-1]
-}
-`,
-		},
-		{
-			name: "reverse",
-			before: `
-package foo
-
-func _() {
-	var foo []int
-	foo.reverse
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo []int
-	for i, j := 0, len(foo)-1; i < j; i, j = i+1, j-1 {
-	foo[i], foo[j] = foo[j], foo[i]
-}
-
-}
-`,
-		},
-		{
-			name: "slice_range",
-			before: `
-package foo
-
-func _() {
-	type myThing struct{}
-	var foo []myThing
-	foo.range
-}
-`,
-			after: `
-package foo
-
-func _() {
-	type myThing struct{}
-	var foo []myThing
-	for i, mt := range foo {
-	$0
-}
-}
-`,
-		},
-		{
-			name: "append_stmt",
-			before: `
-package foo
-
-func _() {
-	var foo []int
-	foo.append
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo []int
-	foo = append(foo, $0)
-}
-`,
-		},
-		{
-			name: "append_expr",
-			before: `
-package foo
-
-func _() {
-	var foo []int
-	var _ []int = foo.append
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo []int
-	var _ []int = append(foo, $0)
-}
-`,
-		},
-		{
-			name: "slice_copy",
-			before: `
-package foo
-
-func _() {
-	var foo []int
-	foo.copy
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo []int
-	fooCopy := make([]int, len(foo))
-copy(fooCopy, foo)
-
-}
-`,
-		},
-		{
-			name: "map_range",
-			before: `
-package foo
-
-func _() {
-	var foo map[string]int
-	foo.range
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo map[string]int
-	for k, v := range foo {
-	$0
-}
-}
-`,
-		},
-		{
-			name: "map_clear",
-			before: `
-package foo
-
-func _() {
-	var foo map[string]int
-	foo.clear
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo map[string]int
-	for k := range foo {
-	delete(foo, k)
-}
-
-}
-`,
-		},
-		{
-			name: "map_keys",
-			before: `
-package foo
-
-func _() {
-	var foo map[string]int
-	foo.keys
-}
-`,
-			after: `
-package foo
-
-func _() {
-	var foo map[string]int
-	keys := make([]string, 0, len(foo))
-for k := range foo {
-	keys = append(keys, k)
-}
-
-}
-`,
-		},
-		{
-			name: "channel_range",
-			before: `
-package foo
-
-func _() {
-	foo := make(chan int)
-	foo.range
-}
-`,
-			after: `
-package foo
-
-func _() {
-	foo := make(chan int)
-	for e := range foo {
-	$0
-}
-}
-`,
-		},
-		{
-			name: "var",
-			before: `
-package foo
-
-func foo() (int, error) { return 0, nil }
-
-func _() {
-	foo().var
-}
-`,
-			after: `
-package foo
-
-func foo() (int, error) { return 0, nil }
-
-func _() {
-	i, err := foo()
-}
-`,
-		},
-		{
-			name: "var_single_value",
-			before: `
-package foo
-
-func foo() error { return nil }
-
-func _() {
-	foo().var
-}
-`,
-			after: `
-package foo
-
-func foo() error { return nil }
-
-func _() {
-	err := foo()
-}
-`,
-		},
-		{
-			name: "var_same_type",
-			before: `
-package foo
-
-func foo() (int, int) { return 0, 0 }
-
-func _() {
-	foo().var
-}
-`,
-			after: `
-package foo
-
-func foo() (int, int) { return 0, 0 }
-
-func _() {
-	i, i2 := foo()
-}
-`,
-		},
-		{
-			name: "print_scalar",
-			before: `
-package foo
-
-func _() {
-	var foo int
-	foo.print
-}
-`,
-			after: `
-package foo
-
-import "fmt"
-
-func _() {
-	var foo int
-	fmt.Printf("foo: %v\n", foo)
-}
-`,
-		},
-		{
-			name: "print_multi",
-			before: `
-package foo
-
-func foo() (int, error) { return 0, nil }
-
-func _() {
-	foo().print
-}
-`,
-			after: `
-package foo
-
-import "fmt"
-
-func foo() (int, error) { return 0, nil }
-
-func _() {
-	fmt.Println(foo())
-}
-`,
-		},
-		{
-			name: "string split",
-			before: `
-package foo
-
-func foo() []string {
-	x := "test"
-	return x.split
-}`,
-			after: `
-package foo
-
-import "strings"
-
-func foo() []string {
-	x := "test"
-	return strings.Split(x, "$0")
-}`,
-		},
-		{
-			name: "string slice join",
-			before: `
-package foo
-
-func foo() string {
-	x := []string{"a", "test"}
-	return x.join
-}`,
-			after: `
-package foo
-
-import "strings"
-
-func foo() string {
-	x := []string{"a", "test"}
-	return strings.Join(x, "$0")
-}`,
-		},
-	}
-
-	r := WithOptions(
-		Settings{
-			"experimentalPostfixCompletions": true,
-		},
-	)
-	r.Run(t, mod, func(t *testing.T, env *Env) {
-		env.CreateBuffer("foo.go", "")
-
-		for _, c := range cases {
-			t.Run(c.name, func(t *testing.T) {
-				c.before = strings.Trim(c.before, "\n")
-				c.after = strings.Trim(c.after, "\n")
-
-				env.SetBufferContent("foo.go", c.before)
-
-				pos := env.RegexpSearch("foo.go", "\n}")
-				completions := env.Completion("foo.go", pos)
-				if len(completions.Items) != 1 {
-					t.Fatalf("expected one completion, got %v", completions.Items)
-				}
-
-				env.AcceptCompletion("foo.go", pos, completions.Items[0])
-
-				if buf := env.BufferText("foo.go"); buf != c.after {
-					t.Errorf("\nGOT:\n%s\nEXPECTED:\n%s", buf, c.after)
-				}
-			})
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/debug/debug_test.go b/gopls/internal/regtest/debug/debug_test.go
--- a/gopls/internal/regtest/debug/debug_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/debug/debug_test.go	1969-12-31 16:00:00
@@ -1,30 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package debug
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-)
-
-func TestMain(m *testing.M) {
-	Main(m, hooks.Options)
-}
-
-func TestBugNotification(t *testing.T) {
-	// Verify that a properly configured session gets notified of a bug on the
-	// server.
-	WithOptions(
-		Modes(Default), // must be in-process to receive the bug report below
-		Settings{"showBugReports": true},
-	).Run(t, "", func(t *testing.T, env *Env) {
-		const desc = "got a bug"
-		bug.Report(desc, nil)
-		env.Await(ShownMessage(desc))
-	})
-}
diff -urN a/gopls/internal/regtest/diagnostics/analysis_test.go b/gopls/internal/regtest/diagnostics/analysis_test.go
--- a/gopls/internal/regtest/diagnostics/analysis_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/diagnostics/analysis_test.go	1969-12-31 16:00:00
@@ -1,54 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package diagnostics
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// Test for the timeformat analyzer, following golang/vscode-go#2406.
-//
-// This test checks that applying the suggested fix from the analyzer resolves
-// the diagnostic warning.
-func TestTimeFormatAnalyzer(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-
-import (
-	"fmt"
-	"time"
-)
-
-func main() {
-	now := time.Now()
-	fmt.Println(now.Format("2006-02-01"))
-}`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexp("main.go", "2006-02-01"),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/diagnostics/builtin_test.go b/gopls/internal/regtest/diagnostics/builtin_test.go
--- a/gopls/internal/regtest/diagnostics/builtin_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/diagnostics/builtin_test.go	1969-12-31 16:00:00
@@ -1,38 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package diagnostics
-
-import (
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestIssue44866(t *testing.T) {
-	src := `
--- go.mod --
-module mod.com
-
-go 1.12
--- a.go --
-package a
-
-const (
-	c = iota
-)
-`
-	Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		name, _ := env.GoToDefinition("a.go", env.RegexpSearch("a.go", "iota"))
-		if !strings.HasSuffix(name, "builtin.go") {
-			t.Fatalf("jumped to %q, want builtin.go", name)
-		}
-		env.Await(OnceMet(
-			env.DoneWithOpen(),
-			NoDiagnostics("builtin.go"),
-		))
-	})
-}
diff -urN a/gopls/internal/regtest/diagnostics/diagnostics_test.go b/gopls/internal/regtest/diagnostics/diagnostics_test.go
--- a/gopls/internal/regtest/diagnostics/diagnostics_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/diagnostics/diagnostics_test.go	1969-12-31 16:00:00
@@ -1,2104 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package diagnostics
-
-import (
-	"context"
-	"fmt"
-	"os/exec"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-// Use mod.com for all go.mod files due to golang/go#35230.
-const exampleProgram = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hello World.")
-}`
-
-func TestDiagnosticErrorInEditedFile(t *testing.T) {
-	// This test is very basic: start with a clean Go program, make an error, and
-	// get a diagnostic for that error. However, it also demonstrates how to
-	// combine Expectations to await more complex state in the editor.
-	Run(t, exampleProgram, func(t *testing.T, env *Env) {
-		// Deleting the 'n' at the end of Println should generate a single error
-		// diagnostic.
-		env.OpenFile("main.go")
-		env.RegexpReplace("main.go", "Printl(n)", "")
-		env.Await(
-			// Once we have gotten diagnostics for the change above, we should
-			// satisfy the DiagnosticAtRegexp assertion.
-			OnceMet(
-				env.DoneWithChange(),
-				env.DiagnosticAtRegexp("main.go", "Printl"),
-			),
-			// Assert that this test has sent no error logs to the client. This is not
-			// strictly necessary for testing this regression, but is included here
-			// as an example of using the NoErrorLogs() expectation. Feel free to
-			// delete.
-			NoErrorLogs(),
-		)
-	})
-}
-
-func TestMissingImportDiagsClearOnFirstFile(t *testing.T) {
-	const onlyMod = `
--- go.mod --
-module mod.com
-
-go 1.12
-`
-	Run(t, onlyMod, func(t *testing.T, env *Env) {
-		env.CreateBuffer("main.go", `package main
-
-func m() {
-	log.Println()
-}
-`)
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", "log"),
-		)
-		env.SaveBuffer("main.go")
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
-
-func TestDiagnosticErrorInNewFile(t *testing.T) {
-	const brokenFile = `package main
-
-const Foo = "abc
-`
-	Run(t, brokenFile, func(t *testing.T, env *Env) {
-		env.CreateBuffer("broken.go", brokenFile)
-		env.Await(env.DiagnosticAtRegexp("broken.go", "\"abc"))
-	})
-}
-
-// badPackage contains a duplicate definition of the 'a' const.
-const badPackage = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a.go --
-package consts
-
-const a = 1
--- b.go --
-package consts
-
-const a = 2
-`
-
-func TestDiagnosticClearingOnEdit(t *testing.T) {
-	Run(t, badPackage, func(t *testing.T, env *Env) {
-		env.OpenFile("b.go")
-		env.Await(env.DiagnosticAtRegexp("a.go", "a = 1"), env.DiagnosticAtRegexp("b.go", "a = 2"))
-
-		// Fix the error by editing the const name in b.go to `b`.
-		env.RegexpReplace("b.go", "(a) = 2", "b")
-		env.Await(
-			EmptyDiagnostics("a.go"),
-			EmptyDiagnostics("b.go"),
-		)
-	})
-}
-
-func TestDiagnosticClearingOnDelete_Issue37049(t *testing.T) {
-	Run(t, badPackage, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		env.Await(env.DiagnosticAtRegexp("a.go", "a = 1"), env.DiagnosticAtRegexp("b.go", "a = 2"))
-		env.RemoveWorkspaceFile("b.go")
-
-		env.Await(EmptyDiagnostics("a.go"), EmptyDiagnostics("b.go"))
-	})
-}
-
-func TestDiagnosticClearingOnClose(t *testing.T) {
-	Run(t, badPackage, func(t *testing.T, env *Env) {
-		env.CreateBuffer("c.go", `package consts
-
-const a = 3`)
-		env.Await(
-			env.DiagnosticAtRegexp("a.go", "a = 1"),
-			env.DiagnosticAtRegexp("b.go", "a = 2"),
-			env.DiagnosticAtRegexp("c.go", "a = 3"),
-		)
-		env.CloseBuffer("c.go")
-		env.Await(
-			env.DiagnosticAtRegexp("a.go", "a = 1"),
-			env.DiagnosticAtRegexp("b.go", "a = 2"),
-			EmptyDiagnostics("c.go"),
-		)
-	})
-}
-
-// Tests golang/go#37978.
-func TestIssue37978(t *testing.T) {
-	Run(t, exampleProgram, func(t *testing.T, env *Env) {
-		// Create a new workspace-level directory and empty file.
-		env.CreateBuffer("c/c.go", "")
-
-		// Write the file contents with a missing import.
-		env.EditBuffer("c/c.go", fake.Edit{
-			Text: `package c
-
-const a = http.MethodGet
-`,
-		})
-		env.Await(
-			env.DiagnosticAtRegexp("c/c.go", "http.MethodGet"),
-		)
-		// Save file, which will organize imports, adding the expected import.
-		// Expect the diagnostics to clear.
-		env.SaveBuffer("c/c.go")
-		env.Await(
-			EmptyDiagnostics("c/c.go"),
-		)
-	})
-}
-
-// Tests golang/go#38878: good a.go, bad a_test.go, remove a_test.go but its errors remain
-// If the file is open in the editor, this is working as intended
-// If the file is not open in the editor, the errors go away
-const test38878 = `
--- go.mod --
-module foo
-
-go 1.12
--- a.go --
-package x
-
-// import "fmt"
-
-func f() {}
-
--- a_test.go --
-package x
-
-import "testing"
-
-func TestA(t *testing.T) {
-	f(3)
-}
-`
-
-// Tests golang/go#38878: deleting a test file should clear its errors, and
-// not break the workspace.
-func TestDeleteTestVariant(t *testing.T) {
-	Run(t, test38878, func(t *testing.T, env *Env) {
-		env.Await(env.DiagnosticAtRegexp("a_test.go", `f\((3)\)`))
-		env.RemoveWorkspaceFile("a_test.go")
-		env.Await(EmptyDiagnostics("a_test.go"))
-
-		// Make sure the test variant has been removed from the workspace by
-		// triggering a metadata load.
-		env.OpenFile("a.go")
-		env.RegexpReplace("a.go", `// import`, "import")
-		env.Await(env.DiagnosticAtRegexp("a.go", `"fmt"`))
-	})
-}
-
-// Tests golang/go#38878: deleting a test file on disk while it's still open
-// should not clear its errors.
-func TestDeleteTestVariant_DiskOnly(t *testing.T) {
-	Run(t, test38878, func(t *testing.T, env *Env) {
-		env.OpenFile("a_test.go")
-		env.Await(DiagnosticAt("a_test.go", 5, 3))
-		env.Sandbox.Workdir.RemoveFile(context.Background(), "a_test.go")
-		env.Await(OnceMet(
-			env.DoneWithChangeWatchedFiles(),
-			DiagnosticAt("a_test.go", 5, 3)))
-	})
-}
-
-// TestNoMod confirms that gopls continues to work when a user adds a go.mod
-// file to their workspace.
-func TestNoMod(t *testing.T) {
-	const noMod = `
--- main.go --
-package main
-
-import "mod.com/bob"
-
-func main() {
-	bob.Hello()
-}
--- bob/bob.go --
-package bob
-
-func Hello() {
-	var x int
-}
-`
-
-	t.Run("manual", func(t *testing.T) {
-		Run(t, noMod, func(t *testing.T, env *Env) {
-			env.Await(
-				env.DiagnosticAtRegexp("main.go", `"mod.com/bob"`),
-			)
-			env.CreateBuffer("go.mod", `module mod.com
-
-	go 1.12
-`)
-			env.SaveBuffer("go.mod")
-			env.Await(
-				EmptyDiagnostics("main.go"),
-			)
-			var d protocol.PublishDiagnosticsParams
-			env.Await(
-				OnceMet(
-					env.DiagnosticAtRegexp("bob/bob.go", "x"),
-					ReadDiagnostics("bob/bob.go", &d),
-				),
-			)
-			if len(d.Diagnostics) != 1 {
-				t.Fatalf("expected 1 diagnostic, got %v", len(d.Diagnostics))
-			}
-		})
-	})
-	t.Run("initialized", func(t *testing.T) {
-		Run(t, noMod, func(t *testing.T, env *Env) {
-			env.Await(
-				env.DiagnosticAtRegexp("main.go", `"mod.com/bob"`),
-			)
-			env.RunGoCommand("mod", "init", "mod.com")
-			env.Await(
-				EmptyDiagnostics("main.go"),
-				env.DiagnosticAtRegexp("bob/bob.go", "x"),
-			)
-		})
-	})
-
-	t.Run("without workspace module", func(t *testing.T) {
-		WithOptions(
-			Modes(Default),
-		).Run(t, noMod, func(t *testing.T, env *Env) {
-			env.Await(
-				env.DiagnosticAtRegexp("main.go", `"mod.com/bob"`),
-			)
-			if err := env.Sandbox.RunGoCommand(env.Ctx, "", "mod", []string{"init", "mod.com"}, true); err != nil {
-				t.Fatal(err)
-			}
-			env.Await(
-				EmptyDiagnostics("main.go"),
-				env.DiagnosticAtRegexp("bob/bob.go", "x"),
-			)
-		})
-	})
-}
-
-// Tests golang/go#38267.
-func TestIssue38267(t *testing.T) {
-	const testPackage = `
--- go.mod --
-module mod.com
-
-go 1.12
--- lib.go --
-package lib
-
-func Hello(x string) {
-	_ = x
-}
--- lib_test.go --
-package lib
-
-import "testing"
-
-type testStruct struct{
-	name string
-}
-
-func TestHello(t *testing.T) {
-	testStructs := []*testStruct{
-		&testStruct{"hello"},
-		&testStruct{"goodbye"},
-	}
-	for y := range testStructs {
-		_ = y
-	}
-}
-`
-
-	Run(t, testPackage, func(t *testing.T, env *Env) {
-		env.OpenFile("lib_test.go")
-		env.Await(
-			DiagnosticAt("lib_test.go", 10, 2),
-			DiagnosticAt("lib_test.go", 11, 2),
-		)
-		env.OpenFile("lib.go")
-		env.RegexpReplace("lib.go", "_ = x", "var y int")
-		env.Await(
-			env.DiagnosticAtRegexp("lib.go", "y int"),
-			EmptyDiagnostics("lib_test.go"),
-		)
-	})
-}
-
-// Tests golang/go#38328.
-func TestPackageChange_Issue38328(t *testing.T) {
-	const packageChange = `
--- go.mod --
-module fake
-
-go 1.12
--- a.go --
-package foo
-func main() {}
-`
-	Run(t, packageChange, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		env.RegexpReplace("a.go", "foo", "foox")
-		env.Await(
-			// When the bug reported in #38328 was present, we didn't get erroneous
-			// file diagnostics until after the didChange message generated by the
-			// package renaming was fully processed. Therefore, in order for this
-			// test to actually exercise the bug, we must wait until that work has
-			// completed.
-			OnceMet(
-				env.DoneWithChange(),
-				EmptyDiagnostics("a.go"),
-			),
-		)
-	})
-}
-
-const testPackageWithRequire = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require foo.test v1.2.3
--- go.sum --
-foo.test v1.2.3 h1:TMA+lyd1ck0TqjSFpNe4T6cf/K6TYkoHwOOcMBMjaEw=
-foo.test v1.2.3/go.mod h1:Ij3kyLIe5lzjycjh13NL8I2gX0quZuTdW0MnmlwGBL4=
--- print.go --
-package lib
-
-import (
-	"fmt"
-
-	"foo.test/bar"
-)
-
-func PrintAnswer() {
-	fmt.Printf("answer: %s", bar.Answer)
-}
-`
-
-const testPackageWithRequireProxy = `
--- foo.test@v1.2.3/go.mod --
-module foo.test
-
-go 1.12
--- foo.test@v1.2.3/bar/const.go --
-package bar
-
-const Answer = 42
-`
-
-func TestResolveDiagnosticWithDownload(t *testing.T) {
-	WithOptions(
-		ProxyFiles(testPackageWithRequireProxy),
-	).Run(t, testPackageWithRequire, func(t *testing.T, env *Env) {
-		env.OpenFile("print.go")
-		// Check that gopackages correctly loaded this dependency. We should get a
-		// diagnostic for the wrong formatting type.
-		// TODO: we should be able to easily also match the diagnostic message.
-		env.Await(env.DiagnosticAtRegexp("print.go", "fmt.Printf"))
-	})
-}
-
-func TestMissingDependency(t *testing.T) {
-	Run(t, testPackageWithRequire, func(t *testing.T, env *Env) {
-		env.OpenFile("print.go")
-		env.Await(LogMatching(protocol.Error, "initial workspace load failed", 1, false))
-	})
-}
-
-// Tests golang/go#36951.
-func TestAdHocPackages_Issue36951(t *testing.T) {
-	const adHoc = `
--- b/b.go --
-package b
-
-func Hello() {
-	var x int
-}
-`
-	Run(t, adHoc, func(t *testing.T, env *Env) {
-		env.OpenFile("b/b.go")
-		env.Await(env.DiagnosticAtRegexp("b/b.go", "x"))
-	})
-}
-
-// Tests golang/go#37984: GOPATH should be read from the go command.
-func TestNoGOPATH_Issue37984(t *testing.T) {
-	const files = `
--- main.go --
-package main
-
-func _() {
-	fmt.Println("Hello World")
-}
-`
-	WithOptions(
-		EnvVars{
-			"GOPATH":      "",
-			"GO111MODULE": "off",
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.Await(env.DiagnosticAtRegexp("main.go", "fmt"))
-		env.SaveBuffer("main.go")
-		env.Await(EmptyDiagnostics("main.go"))
-	})
-}
-
-// Tests golang/go#38669.
-func TestEqualInEnv_Issue38669(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-var _ = x.X
--- x/x.go --
-package x
-
-var X = 0
-`
-	WithOptions(
-		EnvVars{"GOFLAGS": "-tags=foo"},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.OrganizeImports("main.go")
-		env.Await(EmptyDiagnostics("main.go"))
-	})
-}
-
-// Tests golang/go#38467.
-func TestNoSuggestedFixesForGeneratedFiles_Issue38467(t *testing.T) {
-	const generated = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-// Code generated by generator.go. DO NOT EDIT.
-
-func _() {
-	for i, _ := range []string{} {
-		_ = i
-	}
-}
-`
-	Run(t, generated, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				DiagnosticAt("main.go", 5, 8),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-		if fixes := env.GetQuickFixes("main.go", d.Diagnostics); len(fixes) != 0 {
-			t.Errorf("got quick fixes %v, wanted none", fixes)
-		}
-	})
-}
-
-// Expect a module/GOPATH error if there is an error in the file at startup.
-// Tests golang/go#37279.
-func TestBrokenWorkspace_OutsideModule(t *testing.T) {
-	const noModule = `
--- a.go --
-package foo
-
-import "mod.com/hello"
-
-func f() {
-	hello.Goodbye()
-}
-`
-	Run(t, noModule, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		env.Await(
-			// Expect the adHocPackagesWarning.
-			OutstandingWork(lsp.WorkspaceLoadFailure, "outside of a module"),
-		)
-		// Deleting the import dismisses the warning.
-		env.RegexpReplace("a.go", `import "mod.com/hello"`, "")
-		env.Await(
-			NoOutstandingWork(),
-		)
-	})
-}
-
-func TestNonGoFolder(t *testing.T) {
-	const files = `
--- hello.txt --
-hi mom
-`
-	for _, go111module := range []string{"on", "off", ""} {
-		t.Run(fmt.Sprintf("GO111MODULE_%v", go111module), func(t *testing.T) {
-			WithOptions(
-				EnvVars{"GO111MODULE": go111module},
-			).Run(t, files, func(t *testing.T, env *Env) {
-				env.Await(
-					NoOutstandingWork(),
-				)
-			})
-		})
-	}
-}
-
-// Tests the repro case from golang/go#38602. Diagnostics are now handled properly,
-// which blocks type checking.
-func TestConflictingMainPackageErrors(t *testing.T) {
-	const collision = `
--- x/x.go --
-package x
-
-import "x/hello"
-
-func Hello() {
-	hello.HiThere()
-}
--- x/main.go --
-package main
-
-func main() {
-	fmt.Println("")
-}
-`
-	WithOptions(
-		InGOPATH(),
-		EnvVars{"GO111MODULE": "off"},
-	).Run(t, collision, func(t *testing.T, env *Env) {
-		env.OpenFile("x/x.go")
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("x/x.go", `^`, "found packages main (main.go) and x (x.go)"),
-			env.DiagnosticAtRegexpWithMessage("x/main.go", `^`, "found packages main (main.go) and x (x.go)"),
-		)
-
-		// We don't recover cleanly from the errors without good overlay support.
-		if testenv.Go1Point() >= 16 {
-			env.RegexpReplace("x/x.go", `package x`, `package main`)
-			env.Await(OnceMet(
-				env.DoneWithChange(),
-				env.DiagnosticAtRegexp("x/main.go", `fmt`)))
-		}
-	})
-}
-
-const ardanLabsProxy = `
--- github.com/ardanlabs/conf@v1.2.3/go.mod --
-module github.com/ardanlabs/conf
-
-go 1.12
--- github.com/ardanlabs/conf@v1.2.3/conf.go --
-package conf
-
-var ErrHelpWanted error
-`
-
-// Test for golang/go#38211.
-func Test_Issue38211(t *testing.T) {
-	const ardanLabs = `
--- go.mod --
-module mod.com
-
-go 1.14
--- main.go --
-package main
-
-import "github.com/ardanlabs/conf"
-
-func main() {
-	_ = conf.ErrHelpWanted
-}
-`
-	WithOptions(
-		ProxyFiles(ardanLabsProxy),
-	).Run(t, ardanLabs, func(t *testing.T, env *Env) {
-		// Expect a diagnostic with a suggested fix to add
-		// "github.com/ardanlabs/conf" to the go.mod file.
-		env.OpenFile("go.mod")
-		env.OpenFile("main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("main.go", `"github.com/ardanlabs/conf"`),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-		env.SaveBuffer("go.mod")
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-		// Comment out the line that depends on conf and expect a
-		// diagnostic and a fix to remove the import.
-		env.RegexpReplace("main.go", "_ = conf.ErrHelpWanted", "//_ = conf.ErrHelpWanted")
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", `"github.com/ardanlabs/conf"`),
-		)
-		env.SaveBuffer("main.go")
-		// Expect a diagnostic and fix to remove the dependency in the go.mod.
-		env.Await(EmptyDiagnostics("main.go"))
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexpWithMessage("go.mod", "require github.com/ardanlabs/conf", "not used in this module"),
-				ReadDiagnostics("go.mod", &d),
-			),
-		)
-		env.ApplyQuickFixes("go.mod", d.Diagnostics)
-		env.SaveBuffer("go.mod")
-		env.Await(
-			EmptyDiagnostics("go.mod"),
-		)
-		// Uncomment the lines and expect a new diagnostic for the import.
-		env.RegexpReplace("main.go", "//_ = conf.ErrHelpWanted", "_ = conf.ErrHelpWanted")
-		env.SaveBuffer("main.go")
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", `"github.com/ardanlabs/conf"`),
-		)
-	})
-}
-
-// Test for golang/go#38207.
-func TestNewModule_Issue38207(t *testing.T) {
-	const emptyFile = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-`
-	WithOptions(
-		ProxyFiles(ardanLabsProxy),
-	).Run(t, emptyFile, func(t *testing.T, env *Env) {
-		env.CreateBuffer("main.go", `package main
-
-import "github.com/ardanlabs/conf"
-
-func main() {
-	_ = conf.ErrHelpWanted
-}
-`)
-		env.SaveBuffer("main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexpWithMessage("main.go", `"github.com/ardanlabs/conf"`, "no required module"),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
-
-// Test for golang/go#36960.
-func TestNewFileBadImports_Issue36960(t *testing.T) {
-	const simplePackage = `
--- go.mod --
-module mod.com
-
-go 1.14
--- a/a1.go --
-package a
-
-import "fmt"
-
-func _() {
-	fmt.Println("hi")
-}
-`
-	Run(t, simplePackage, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a1.go")
-		env.CreateBuffer("a/a2.go", ``)
-		env.SaveBufferWithoutActions("a/a2.go")
-		// We can't use OnceMet here (at least, not easily) because the didSave
-		// races with the didChangeWatchedFiles.
-		//
-		// TODO(rfindley): add an AllOf expectation combinator, or an expectation
-		// that all notifications have been processed.
-		env.Await(
-			EmptyDiagnostics("a/a1.go"),
-		)
-		env.EditBuffer("a/a2.go", fake.NewEdit(0, 0, 0, 0, `package a`))
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				EmptyDiagnostics("a/a1.go"),
-			),
-		)
-	})
-}
-
-// This test tries to replicate the workflow of a user creating a new x test.
-// It also tests golang/go#39315.
-func TestManuallyCreatingXTest(t *testing.T) {
-	// Create a package that already has a test variant (in-package test).
-	const testVariant = `
--- go.mod --
-module mod.com
-
-go 1.15
--- hello/hello.go --
-package hello
-
-func Hello() {
-	var x int
-}
--- hello/hello_test.go --
-package hello
-
-import "testing"
-
-func TestHello(t *testing.T) {
-	var x int
-	Hello()
-}
-`
-	Run(t, testVariant, func(t *testing.T, env *Env) {
-		// Open the file, triggering the workspace load.
-		// There are errors in the code to ensure all is working as expected.
-		env.OpenFile("hello/hello.go")
-		env.Await(
-			env.DiagnosticAtRegexp("hello/hello.go", "x"),
-			env.DiagnosticAtRegexp("hello/hello_test.go", "x"),
-		)
-
-		// Create an empty file with the intention of making it an x test.
-		// This resembles a typical flow in an editor like VS Code, in which
-		// a user would create an empty file and add content, saving
-		// intermittently.
-		// TODO(rstambler): There might be more edge cases here, as file
-		// content can be added incrementally.
-		env.CreateBuffer("hello/hello_x_test.go", ``)
-
-		// Save the empty file (no actions since formatting will fail).
-		env.SaveBufferWithoutActions("hello/hello_x_test.go")
-
-		// Add the content. The missing import is for the package under test.
-		env.EditBuffer("hello/hello_x_test.go", fake.NewEdit(0, 0, 0, 0, `package hello_test
-
-import (
-	"testing"
-)
-
-func TestHello(t *testing.T) {
-	hello.Hello()
-}
-`))
-		// Expect a diagnostic for the missing import. Save, which should
-		// trigger import organization. The diagnostic should clear.
-		env.Await(
-			env.DiagnosticAtRegexp("hello/hello_x_test.go", "hello.Hello"),
-		)
-		env.SaveBuffer("hello/hello_x_test.go")
-		env.Await(
-			EmptyDiagnostics("hello/hello_x_test.go"),
-		)
-	})
-}
-
-// Reproduce golang/go#40690.
-func TestCreateOnlyXTest(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo/foo.go --
-package foo
--- foo/bar_test.go --
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/bar_test.go")
-		env.EditBuffer("foo/bar_test.go", fake.NewEdit(0, 0, 0, 0, "package foo"))
-		env.Await(env.DoneWithChange())
-		env.RegexpReplace("foo/bar_test.go", "package foo", `package foo_test
-
-import "testing"
-
-func TestX(t *testing.T) {
-	var x int
-}
-`)
-		env.Await(
-			env.DiagnosticAtRegexp("foo/bar_test.go", "x"),
-		)
-	})
-}
-
-func TestChangePackageName(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo/foo.go --
-package foo
--- foo/bar_test.go --
-package foo_
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/bar_test.go")
-		env.RegexpReplace("foo/bar_test.go", "package foo_", "package foo_test")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				EmptyOrNoDiagnostics("foo/bar_test.go"),
-				EmptyOrNoDiagnostics("foo/foo.go"),
-			),
-		)
-	})
-}
-
-func TestIgnoredFiles(t *testing.T) {
-	const ws = `
--- go.mod --
-module mod.com
-
-go 1.12
--- _foo/x.go --
-package x
-
-var _ = foo.Bar
-`
-	Run(t, ws, func(t *testing.T, env *Env) {
-		env.OpenFile("_foo/x.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				EmptyDiagnostics("_foo/x.go"),
-			))
-	})
-}
-
-// Partially reproduces golang/go#38977, moving a file between packages.
-// It also gets hit by some go command bug fixed in 1.15, but we don't
-// care about that so much here.
-func TestDeletePackage(t *testing.T) {
-	const ws = `
--- go.mod --
-module mod.com
-
-go 1.15
--- a/a.go --
-package a
-
-const A = 1
-
--- b/b.go --
-package b
-
-import "mod.com/a"
-
-const B = a.A
-
--- c/c.go --
-package c
-
-import "mod.com/a"
-
-const C = a.A
-`
-	Run(t, ws, func(t *testing.T, env *Env) {
-		env.OpenFile("b/b.go")
-		env.Await(env.DoneWithOpen())
-		// Delete c/c.go, the only file in package c.
-		env.RemoveWorkspaceFile("c/c.go")
-
-		// We should still get diagnostics for files that exist.
-		env.RegexpReplace("b/b.go", `a.A`, "a.Nonexistant")
-		env.Await(env.DiagnosticAtRegexp("b/b.go", `Nonexistant`))
-	})
-}
-
-// This is a copy of the scenario_default/quickfix_empty_files.txt test from
-// govim. Reproduces golang/go#39646.
-func TestQuickFixEmptyFiles(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-`
-	// To fully recreate the govim tests, we create files by inserting
-	// a newline, adding to the file, and then deleting the newline.
-	// Wait for each event to process to avoid cancellations and force
-	// package loads.
-	writeGoVim := func(env *Env, name, content string) {
-		env.WriteWorkspaceFile(name, "")
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		env.CreateBuffer(name, "\n")
-		env.Await(env.DoneWithOpen())
-
-		env.EditBuffer(name, fake.NewEdit(1, 0, 1, 0, content))
-		env.Await(env.DoneWithChange())
-
-		env.EditBuffer(name, fake.NewEdit(0, 0, 1, 0, ""))
-		env.Await(env.DoneWithChange())
-	}
-
-	const p = `package p; func DoIt(s string) {};`
-	const main = `package main
-
-import "mod.com/p"
-
-func main() {
-	p.DoIt(5)
-}
-`
-	// A simple version of the test that reproduces most of the problems it
-	// exposes.
-	t.Run("short", func(t *testing.T) {
-		Run(t, mod, func(t *testing.T, env *Env) {
-			writeGoVim(env, "p/p.go", p)
-			writeGoVim(env, "main.go", main)
-			env.Await(env.DiagnosticAtRegexp("main.go", "5"))
-		})
-	})
-
-	// A full version that replicates the whole flow of the test.
-	t.Run("full", func(t *testing.T) {
-		Run(t, mod, func(t *testing.T, env *Env) {
-			writeGoVim(env, "p/p.go", p)
-			writeGoVim(env, "main.go", main)
-			writeGoVim(env, "p/p_test.go", `package p
-
-import "testing"
-
-func TestDoIt(t *testing.T) {
-	DoIt(5)
-}
-`)
-			writeGoVim(env, "p/x_test.go", `package p_test
-
-import (
-	"testing"
-
-	"mod.com/p"
-)
-
-func TestDoIt(t *testing.T) {
-	p.DoIt(5)
-}
-`)
-			env.Await(
-				env.DiagnosticAtRegexp("main.go", "5"),
-				env.DiagnosticAtRegexp("p/p_test.go", "5"),
-				env.DiagnosticAtRegexp("p/x_test.go", "5"),
-			)
-			env.RegexpReplace("p/p.go", "s string", "i int")
-			env.Await(
-				EmptyDiagnostics("main.go"),
-				EmptyDiagnostics("p/p_test.go"),
-				EmptyDiagnostics("p/x_test.go"),
-			)
-		})
-	})
-}
-
-func TestSingleFile(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.13
--- a/a.go --
-package a
-
-func _() {
-	var x int
-}
-`
-	WithOptions(
-		// Empty workspace folders.
-		WorkspaceFolders(),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "x"),
-		)
-	})
-}
-
-// Reproduces the case described in
-// https://github.com/golang/go/issues/39296#issuecomment-652058883.
-func TestPkgm(t *testing.T) {
-	const basic = `
--- go.mod --
-module mod.com
-
-go 1.15
--- foo/foo.go --
-package foo
-
-import "fmt"
-
-func Foo() {
-	fmt.Println("")
-}
-`
-	Run(t, basic, func(t *testing.T, env *Env) {
-		env.WriteWorkspaceFile("foo/foo_test.go", `package main
-
-func main() {
-
-}`)
-		env.OpenFile("foo/foo_test.go")
-		env.RegexpReplace("foo/foo_test.go", `package main`, `package foo`)
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				NoDiagnostics("foo/foo.go"),
-			),
-		)
-	})
-}
-
-func TestClosingBuffer(t *testing.T) {
-	const basic = `
--- go.mod --
-module mod.com
-
-go 1.14
--- main.go --
-package main
-
-func main() {}
-`
-	Run(t, basic, func(t *testing.T, env *Env) {
-		env.Editor.CreateBuffer(env.Ctx, "foo.go", `package main`)
-		env.Await(
-			env.DoneWithOpen(),
-		)
-		env.CloseBuffer("foo.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithClose(),
-				NoLogMatching(protocol.Info, "packages=0"),
-			),
-		)
-	})
-}
-
-// Reproduces golang/go#38424.
-func TestCutAndPaste(t *testing.T) {
-	const basic = `
--- go.mod --
-module mod.com
-
-go 1.14
--- main2.go --
-package main
-`
-	Run(t, basic, func(t *testing.T, env *Env) {
-		env.CreateBuffer("main.go", "")
-		env.Await(env.DoneWithOpen())
-
-		env.SaveBufferWithoutActions("main.go")
-		env.Await(env.DoneWithSave(), env.DoneWithChangeWatchedFiles())
-
-		env.EditBuffer("main.go", fake.NewEdit(0, 0, 0, 0, `package main
-
-func main() {
-}
-`))
-		env.Await(env.DoneWithChange())
-
-		env.SaveBuffer("main.go")
-		env.Await(env.DoneWithSave(), env.DoneWithChangeWatchedFiles())
-
-		env.EditBuffer("main.go", fake.NewEdit(0, 0, 4, 0, ""))
-		env.Await(env.DoneWithChange())
-
-		env.EditBuffer("main.go", fake.NewEdit(0, 0, 0, 0, `package main
-
-func main() {
-	var x int
-}
-`))
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", "x"),
-		)
-	})
-}
-
-// Reproduces golang/go#39763.
-func TestInvalidPackageName(t *testing.T) {
-	const pkgDefault = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package default
-
-func main() {}
-`
-	Run(t, pkgDefault, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("main.go", "default", "expected 'IDENT'"),
-		)
-	})
-}
-
-// This tests the functionality of the "limitWorkspaceScope"
-func TestLimitWorkspaceScope(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/main.go --
-package main
-
-func main() {}
--- main.go --
-package main
-
-func main() {
-	var x int
-}
-`
-	WithOptions(
-		WorkspaceFolders("a"),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", "x"),
-		)
-	})
-	WithOptions(
-		WorkspaceFolders("a"),
-		Settings{"expandWorkspaceToModule": false},
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		env.Await(
-			NoDiagnostics("main.go"),
-		)
-	})
-}
-
-func TestSimplifyCompositeLitDiagnostic(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-type t struct {
-	msg string
-}
-
-func main() {
-	x := []t{t{"msg"}}
-	fmt.Println(x)
-}
-`
-
-	WithOptions(
-		Settings{"staticcheck": true},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(OnceMet(
-			env.DiagnosticAtRegexpWithMessage("main.go", `t{"msg"}`, "redundant type"),
-			ReadDiagnostics("main.go", &d),
-		))
-		if tags := d.Diagnostics[0].Tags; len(tags) == 0 || tags[0] != protocol.Unnecessary {
-			t.Errorf("wanted Unnecessary tag on diagnostic, got %v", tags)
-		}
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-		env.Await(EmptyDiagnostics("main.go"))
-	})
-}
-
-// Test some secondary diagnostics
-func TestSecondaryDiagnostics(t *testing.T) {
-	const dir = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-func main() {
-	panic("not here")
-}
--- other.go --
-package main
-func main() {}
-`
-	Run(t, dir, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.OpenFile("other.go")
-		x := env.Awaiter.DiagnosticsFor("main.go")
-		if x == nil {
-			t.Fatalf("expected 1 diagnostic, got none")
-		}
-		if len(x.Diagnostics) != 1 {
-			t.Fatalf("main.go, got %d diagnostics, expected 1", len(x.Diagnostics))
-		}
-		keep := x.Diagnostics[0]
-		y := env.Awaiter.DiagnosticsFor("other.go")
-		if len(y.Diagnostics) != 1 {
-			t.Fatalf("other.go: got %d diagnostics, expected 1", len(y.Diagnostics))
-		}
-		if len(y.Diagnostics[0].RelatedInformation) != 1 {
-			t.Fatalf("got %d RelatedInformations, expected 1", len(y.Diagnostics[0].RelatedInformation))
-		}
-		// check that the RelatedInformation matches the error from main.go
-		c := y.Diagnostics[0].RelatedInformation[0]
-		if c.Location.Range != keep.Range {
-			t.Errorf("locations don't match. Got %v expected %v", c.Location.Range, keep.Range)
-		}
-	})
-}
-
-func TestNotifyOrphanedFiles(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.go --
-package a
-
-func main() {
-	var x int
-}
--- a/a_exclude.go --
-// +build exclude
-
-package a
-
-func _() {
-	var x int
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "x"),
-		)
-		env.OpenFile("a/a_exclude.go")
-		env.Await(
-			DiagnosticAt("a/a_exclude.go", 2, 8),
-		)
-	})
-}
-
-func TestEnableAllExperiments(t *testing.T) {
-	// Before the oldest supported Go version, gopls sends a warning to upgrade
-	// Go, which fails the expectation below.
-	testenv.NeedsGo1Point(t, lsp.OldestSupportedGoVersion())
-
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "bytes"
-
-func b(c bytes.Buffer) {
-	_ = 1
-}
-`
-	WithOptions(
-		Settings{"allExperiments": true},
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		// Confirm that the setting doesn't cause any warnings.
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				NoShownMessage(""), // empty substring to match any message
-			),
-		)
-	})
-}
-
-func TestSwig(t *testing.T) {
-	// This is fixed in Go 1.17, but not earlier.
-	testenv.NeedsGo1Point(t, 17)
-
-	if _, err := exec.LookPath("swig"); err != nil {
-		t.Skip("skipping test: swig not available")
-	}
-	if _, err := exec.LookPath("g++"); err != nil {
-		t.Skip("skipping test: g++ not available")
-	}
-
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- pkg/simple/export_swig.go --
-package simple
-
-func ExportSimple(x, y int) int {
-	return Gcd(x, y)
-}
--- pkg/simple/simple.swigcxx --
-%module simple
-
-%inline %{
-extern int gcd(int x, int y)
-{
-  int g;
-  g = y;
-  while (x > 0) {
-    g = x;
-    x = y % x;
-    y = g;
-  }
-  return g;
-}
-%}
--- main.go --
-package a
-
-func main() {
-	var x int
-}
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				NoDiagnosticWithMessage("", "illegal character U+0023 '#'"),
-			),
-		)
-	})
-}
-
-// When foo_test.go is opened, gopls will object to the borked package name.
-// This test asserts that when the package name is fixed, gopls will soon after
-// have no more complaints about it.
-// https://github.com/golang/go/issues/41061
-func TestRenamePackage(t *testing.T) {
-	const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/blah/blah.go --
-package hello
-
-const Name = "Hello"
-`
-
-	const contents = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	blah.Hello()
-}
--- bob.go --
-package main
--- foo/foo.go --
-package foo
--- foo/foo_test.go --
-package foo_
-`
-
-	WithOptions(
-		ProxyFiles(proxy),
-		InGOPATH(),
-		EnvVars{"GO111MODULE": "off"},
-	).Run(t, contents, func(t *testing.T, env *Env) {
-		// Simulate typing character by character.
-		env.OpenFile("foo/foo_test.go")
-		env.Await(env.DoneWithOpen())
-		env.RegexpReplace("foo/foo_test.go", "_", "_t")
-		env.Await(env.DoneWithChange())
-		env.RegexpReplace("foo/foo_test.go", "_t", "_test")
-		env.Await(env.DoneWithChange())
-
-		env.Await(
-			EmptyDiagnostics("foo/foo_test.go"),
-			NoOutstandingWork(),
-		)
-	})
-}
-
-// TestProgressBarErrors confirms that critical workspace load errors are shown
-// and updated via progress reports.
-func TestProgressBarErrors(t *testing.T) {
-	const pkg = `
--- go.mod --
-modul mod.com
-
-go 1.12
--- main.go --
-package main
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.Await(
-			OutstandingWork(lsp.WorkspaceLoadFailure, "unknown directive"),
-		)
-		env.EditBuffer("go.mod", fake.NewEdit(0, 0, 3, 0, `module mod.com
-
-go 1.hello
-`))
-		// As of golang/go#42529, go.mod changes do not reload the workspace until
-		// they are saved.
-		env.SaveBufferWithoutActions("go.mod")
-		env.Await(
-			OutstandingWork(lsp.WorkspaceLoadFailure, "invalid go version"),
-		)
-		env.RegexpReplace("go.mod", "go 1.hello", "go 1.12")
-		env.SaveBufferWithoutActions("go.mod")
-		env.Await(
-			NoOutstandingWork(),
-		)
-	})
-}
-
-func TestDeleteDirectory(t *testing.T) {
-	const mod = `
--- bob/bob.go --
-package bob
-
-func Hello() {
-	var x int
-}
--- go.mod --
-module mod.com
--- cmd/main.go --
-package main
-
-import "mod.com/bob"
-
-func main() {
-	bob.Hello()
-}
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(FileWatchMatching("bob"))
-		env.RemoveWorkspaceFile("bob")
-		env.Await(
-			env.DiagnosticAtRegexp("cmd/main.go", `"mod.com/bob"`),
-			EmptyDiagnostics("bob/bob.go"),
-			NoFileWatchMatching("bob"),
-		)
-	})
-}
-
-// Confirms that circular imports are tested and reported.
-func TestCircularImports(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- self/self.go --
-package self
-
-import _ "mod.com/self"
-func Hello() {}
--- double/a/a.go --
-package a
-
-import _ "mod.com/double/b"
--- double/b/b.go --
-package b
-
-import _ "mod.com/double/a"
--- triple/a/a.go --
-package a
-
-import _ "mod.com/triple/b"
--- triple/b/b.go --
-package b
-
-import _ "mod.com/triple/c"
--- triple/c/c.go --
-package c
-
-import _ "mod.com/triple/a"
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("self/self.go", `_ "mod.com/self"`, "import cycle not allowed"),
-			env.DiagnosticAtRegexpWithMessage("double/a/a.go", `_ "mod.com/double/b"`, "import cycle not allowed"),
-			env.DiagnosticAtRegexpWithMessage("triple/a/a.go", `_ "mod.com/triple/b"`, "import cycle not allowed"),
-		)
-	})
-}
-
-// Tests golang/go#46667: deleting a problematic import path should resolve
-// import cycle errors.
-func TestResolveImportCycle(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.test
-
-go 1.16
--- a/a.go --
-package a
-
-import "mod.test/b"
-
-const A = b.A
-const B = 2
--- b/b.go --
-package b
-
-import "mod.test/a"
-
-const A = 1
-const B = a.B
-	`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.OpenFile("b/b.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				// The Go command sometimes tells us about only one of the import cycle
-				// errors below. For robustness of this test, succeed if we get either.
-				//
-				// TODO(golang/go#52904): we should get *both* of these errors.
-				AnyOf(
-					env.DiagnosticAtRegexpWithMessage("a/a.go", `"mod.test/b"`, "import cycle"),
-					env.DiagnosticAtRegexpWithMessage("b/b.go", `"mod.test/a"`, "import cycle"),
-				),
-			),
-		)
-		env.RegexpReplace("b/b.go", `const B = a\.B`, "")
-		env.SaveBuffer("b/b.go")
-		env.Await(
-			EmptyOrNoDiagnostics("a/a.go"),
-			EmptyOrNoDiagnostics("b/b.go"),
-		)
-	})
-}
-
-func TestBadImport(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import (
-	_ "nosuchpkg"
-)
-`
-	t.Run("module", func(t *testing.T) {
-		Run(t, mod, func(t *testing.T, env *Env) {
-			env.Await(
-				env.DiagnosticAtRegexpWithMessage("main.go", `"nosuchpkg"`, `could not import nosuchpkg (no required module provides package "nosuchpkg"`),
-			)
-		})
-	})
-	t.Run("GOPATH", func(t *testing.T) {
-		WithOptions(
-			InGOPATH(),
-			EnvVars{"GO111MODULE": "off"},
-			Modes(Default),
-		).Run(t, mod, func(t *testing.T, env *Env) {
-			env.Await(
-				env.DiagnosticAtRegexpWithMessage("main.go", `"nosuchpkg"`, `cannot find package "nosuchpkg" in any of`),
-			)
-		})
-	})
-}
-
-func TestNestedModules(t *testing.T) {
-	const proxy = `
--- nested.com@v1.0.0/go.mod --
-module nested.com
-
-go 1.12
--- nested.com@v1.0.0/hello/hello.go --
-package hello
-
-func Hello() {}
-`
-
-	const nested = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require nested.com v1.0.0
--- go.sum --
-nested.com v1.0.0 h1:I6spLE4CgFqMdBPc+wTV2asDO2QJ3tU0YAT+jkLeN1I=
-nested.com v1.0.0/go.mod h1:ly53UzXQgVjSlV7wicdBB4p8BxfytuGT1Xcyv0ReJfI=
--- main.go --
-package main
-
-import "nested.com/hello"
-
-func main() {
-	hello.Hello()
-}
--- nested/go.mod --
-module nested.com
-
--- nested/hello/hello.go --
-package hello
-
-func Hello() {
-	helloHelper()
-}
--- nested/hello/hello_helper.go --
-package hello
-
-func helloHelper() {}
-`
-	WithOptions(
-		ProxyFiles(proxy),
-		Modes(Default),
-	).Run(t, nested, func(t *testing.T, env *Env) {
-		// Expect a diagnostic in a nested module.
-		env.OpenFile("nested/hello/hello.go")
-		didOpen := env.DoneWithOpen()
-		env.Await(
-			OnceMet(
-				didOpen,
-				env.DiagnosticAtRegexp("nested/hello/hello.go", "helloHelper"),
-			),
-			OnceMet(
-				didOpen,
-				env.DiagnosticAtRegexpWithMessage("nested/hello/hello.go", "package hello", "nested module"),
-			),
-			OnceMet(
-				didOpen,
-				OutstandingWork(lsp.WorkspaceLoadFailure, "nested module"),
-			),
-		)
-	})
-}
-
-func TestAdHocPackagesReloading(t *testing.T) {
-	const nomod = `
--- main.go --
-package main
-
-func main() {}
-`
-	Run(t, nomod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.RegexpReplace("main.go", "{}", "{ var x int; }") // simulate typing
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				NoLogMatching(protocol.Info, "packages=1"),
-			),
-		)
-	})
-}
-
-func TestBuildTagChange(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo.go --
-// decoy comment
-// +build hidden
-// decoy comment
-
-package foo
-var Foo = 1
--- bar.go --
-package foo
-var Bar = Foo
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo.go")
-		env.Await(env.DiagnosticAtRegexp("bar.go", `Foo`))
-		env.RegexpReplace("foo.go", `\+build`, "")
-		env.Await(EmptyDiagnostics("bar.go"))
-	})
-
-}
-
-func TestIssue44736(t *testing.T) {
-	const files = `
-	-- go.mod --
-module blah.com
-
-go 1.16
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	asdf
-	fmt.Printf("This is a test %v")
-	fdas
-}
--- other.go --
-package main
-
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.OpenFile("other.go")
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", "asdf"),
-			env.DiagnosticAtRegexp("main.go", "fdas"),
-		)
-		env.SetBufferContent("other.go", "package main\n\nasdf")
-		// The new diagnostic in other.go should not suppress diagnostics in main.go.
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexpWithMessage("other.go", "asdf", "expected declaration"),
-				env.DiagnosticAtRegexp("main.go", "asdf"),
-			),
-		)
-	})
-}
-
-func TestInitialization(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.16
--- main.go --
-package main
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.Await(env.DoneWithOpen())
-		env.RegexpReplace("go.mod", "module", "modul")
-		env.SaveBufferWithoutActions("go.mod")
-		env.Await(
-			OnceMet(
-				env.DoneWithSave(),
-				NoLogMatching(protocol.Error, "initial workspace load failed"),
-			),
-		)
-	})
-}
-
-// This test confirms that the view does not reinitialize when a go.mod file is
-// opened.
-func TestNoReinitialize(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func main() {}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				LogMatching(protocol.Info, `.*query=\[builtin mod.com/...\].*`, 1, false),
-			),
-		)
-	})
-}
-
-func TestLangVersion(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // Requires types.Config.GoVersion, new in 1.18.
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-const C = 0b10
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(env.DiagnosticAtRegexpWithMessage("main.go", `0b10`, "go1.13 or later"))
-		env.WriteWorkspaceFile("go.mod", "module mod.com \n\ngo 1.13\n")
-		env.Await(EmptyDiagnostics("main.go"))
-	})
-}
-
-func TestNoQuickFixForUndeclaredConstraint(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-
-func F[T C](_ T) {
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("main.go", `C`),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-		if fixes := env.GetQuickFixes("main.go", d.Diagnostics); len(fixes) != 0 {
-			t.Errorf("got quick fixes %v, wanted none", fixes)
-		}
-	})
-}
-
-func TestEditGoDirective(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.16
--- main.go --
-package main
-
-func F[T any](_ T) {
-}
-`
-	Run(t, files, func(_ *testing.T, env *Env) { // Create a new workspace-level directory and empty file.
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexpWithMessage("main.go", `T any`, "type parameter"),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
-
-func TestEditGoDirectiveWorkspace(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.16
--- go.work --
-go 1.18
-
-use .
--- main.go --
-package main
-
-func F[T any](_ T) {
-}
-`
-	Run(t, files, func(_ *testing.T, env *Env) { // Create a new workspace-level directory and empty file.
-		var d protocol.PublishDiagnosticsParams
-
-		// Once the initial workspace load is complete, we should have a diagnostic
-		// because generics are not supported at 1.16.
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				env.DiagnosticAtRegexpWithMessage("main.go", `T any`, "type parameter"),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-
-		// This diagnostic should have a quick fix to edit the go version.
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-
-		// Once the edit is applied, the problematic diagnostics should be
-		// resolved.
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(), // go.mod should have been quick-fixed
-				EmptyDiagnostics("main.go"),
-			),
-		)
-	})
-}
-
-// This test demonstrates that analysis facts are correctly propagated
-// across packages.
-func TestInterpackageAnalysis(t *testing.T) {
-	const src = `
--- go.mod --
-module example.com
--- a/a.go --
-package a
-
-import "example.com/b"
-
-func _() {
-	new(b.B).Printf("%d", "s") // printf error
-}
-
--- b/b.go --
-package b
-
-import "example.com/c"
-
-type B struct{}
-
-func (B) Printf(format string, args ...interface{}) {
-	c.MyPrintf(format, args...)
-}
-
--- c/c.go --
-package c
-
-import "fmt"
-
-func MyPrintf(format string, args ...interface{}) {
-	fmt.Printf(format, args...)
-}
-`
-	Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.AfterChange(
-			env.DiagnosticAtRegexpWithMessage("a/a.go", "new.*Printf",
-				"format %d has arg \"s\" of wrong type string"))
-	})
-}
-
-// This test ensures that only Analyzers with RunDespiteErrors=true
-// are invoked on a package that would not compile, even if the errors
-// are distant and localized.
-func TestErrorsThatPreventAnalysis(t *testing.T) {
-	const src = `
--- go.mod --
-module example.com
--- a/a.go --
-package a
-
-import "fmt"
-import "sync"
-import _ "example.com/b"
-
-func _() {
-	// The copylocks analyzer (RunDespiteErrors, FactTypes={}) does run.
-	var mu sync.Mutex
-	mu2 := mu // copylocks error, reported
-	_ = &mu2
-
-	// The printf analyzer (!RunDespiteErrors, FactTypes!={}) does not run:
-	//  (c, printf) failed because of type error in c
-	//  (b, printf) and (a, printf) do not run because of failed prerequisites.
-	fmt.Printf("%d", "s") // printf error, unreported
-
-	// The bools analyzer (!RunDespiteErrors, FactTypes={}) does not run:
-	var cond bool
-	_ = cond != true && cond != true // bools error, unreported
-}
-
--- b/b.go --
-package b
-
-import _ "example.com/c"
-
--- c/c.go --
-package c
-
-var _ = 1 / "" // type error
-
-`
-	Run(t, src, func(t *testing.T, env *Env) {
-		var diags protocol.PublishDiagnosticsParams
-		env.OpenFile("a/a.go")
-		env.AfterChange(
-			env.DiagnosticAtRegexpWithMessage("a/a.go", "mu2 := (mu)", "assignment copies lock value"),
-			ReadDiagnostics("a/a.go", &diags))
-
-		// Assert that there were no other diagnostics.
-		// In particular:
-		// - "fmt.Printf" does not trigger a [printf] finding;
-		// - "cond != true" does not trigger a [bools] finding.
-		//
-		// We use this check in preference to NoDiagnosticAtRegexp
-		// as it is robust in case of minor mistakes in the position
-		// regexp, and because it reports unexpected diagnostics.
-		if got, want := len(diags.Diagnostics), 1; got != want {
-			t.Errorf("got %d diagnostics in a/a.go, want %d:", got, want)
-			for i, diag := range diags.Diagnostics {
-				t.Logf("Diagnostics[%d] = %+v", i, diag)
-			}
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/diagnostics/invalidation_test.go b/gopls/internal/regtest/diagnostics/invalidation_test.go
--- a/gopls/internal/regtest/diagnostics/invalidation_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/diagnostics/invalidation_test.go	1969-12-31 16:00:00
@@ -1,126 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package diagnostics
-
-import (
-	"fmt"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// Test for golang/go#50267: diagnostics should be re-sent after a file is
-// opened.
-func TestDiagnosticsAreResentAfterCloseOrOpen(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.16
--- main.go --
-package main
-
-func _() {
-	x := 2
-}
-`
-	Run(t, files, func(_ *testing.T, env *Env) { // Create a new workspace-level directory and empty file.
-		env.OpenFile("main.go")
-		var afterOpen protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				ReadDiagnostics("main.go", &afterOpen),
-			),
-		)
-		env.CloseBuffer("main.go")
-		var afterClose protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DoneWithClose(),
-				ReadDiagnostics("main.go", &afterClose),
-			),
-		)
-		if afterOpen.Version == afterClose.Version {
-			t.Errorf("publishDiagnostics: got the same version after closing (%d) as after opening", afterOpen.Version)
-		}
-		env.OpenFile("main.go")
-		var afterReopen protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				ReadDiagnostics("main.go", &afterReopen),
-			),
-		)
-		if afterReopen.Version == afterClose.Version {
-			t.Errorf("pubslishDiagnostics: got the same version after reopening (%d) as after closing", afterClose.Version)
-		}
-	})
-}
-
-// Test for the "chattyDiagnostics" setting: we should get re-published
-// diagnostics after every file change, even if diagnostics did not change.
-func TestChattyDiagnostics(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.16
--- main.go --
-package main
-
-func _() {
-	x := 2
-}
-
-// Irrelevant comment #0
-`
-
-	WithOptions(
-		Settings{
-			"chattyDiagnostics": true,
-		},
-	).Run(t, files, func(_ *testing.T, env *Env) { // Create a new workspace-level directory and empty file.
-
-		env.OpenFile("main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				ReadDiagnostics("main.go", &d),
-			),
-		)
-
-		if len(d.Diagnostics) != 1 {
-			t.Fatalf("len(Diagnostics) = %d, want 1", len(d.Diagnostics))
-		}
-		msg := d.Diagnostics[0].Message
-
-		for i := 0; i < 5; i++ {
-			before := d.Version
-			env.RegexpReplace("main.go", "Irrelevant comment #.", fmt.Sprintf("Irrelevant comment #%d", i))
-			env.Await(
-				OnceMet(
-					env.DoneWithChange(),
-					ReadDiagnostics("main.go", &d),
-				),
-			)
-
-			if d.Version == before {
-				t.Errorf("after change, got version %d, want new version", d.Version)
-			}
-
-			// As a sanity check, make sure we have the same diagnostic.
-			if len(d.Diagnostics) != 1 {
-				t.Fatalf("len(Diagnostics) = %d, want 1", len(d.Diagnostics))
-			}
-			newMsg := d.Diagnostics[0].Message
-			if newMsg != msg {
-				t.Errorf("after change, got message %q, want %q", newMsg, msg)
-			}
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/diagnostics/undeclared_test.go b/gopls/internal/regtest/diagnostics/undeclared_test.go
--- a/gopls/internal/regtest/diagnostics/undeclared_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/diagnostics/undeclared_test.go	1969-12-31 16:00:00
@@ -1,67 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package diagnostics
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestUndeclaredDiagnostics(t *testing.T) {
-	src := `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.go --
-package a
-
-func _() int {
-	return x
-}
--- b/b.go --
-package b
-
-func _() int {
-	var y int
-	y = y
-	return y
-}
-`
-	Run(t, src, func(t *testing.T, env *Env) {
-		isUnnecessary := func(diag protocol.Diagnostic) bool {
-			for _, tag := range diag.Tags {
-				if tag == protocol.Unnecessary {
-					return true
-				}
-			}
-			return false
-		}
-
-		// 'x' is undeclared, but still necessary.
-		env.OpenFile("a/a.go")
-		env.Await(env.DiagnosticAtRegexp("a/a.go", "x"))
-		diags := env.Awaiter.DiagnosticsFor("a/a.go")
-		if got := len(diags.Diagnostics); got != 1 {
-			t.Errorf("len(Diagnostics) = %d, want 1", got)
-		}
-		if diag := diags.Diagnostics[0]; isUnnecessary(diag) {
-			t.Errorf("%v tagged unnecessary, want necessary", diag)
-		}
-
-		// 'y = y' is pointless, and should be detected as unnecessary.
-		env.OpenFile("b/b.go")
-		env.Await(env.DiagnosticAtRegexp("b/b.go", "y = y"))
-		diags = env.Awaiter.DiagnosticsFor("b/b.go")
-		if got := len(diags.Diagnostics); got != 1 {
-			t.Errorf("len(Diagnostics) = %d, want 1", got)
-		}
-		if diag := diags.Diagnostics[0]; !isUnnecessary(diag) {
-			t.Errorf("%v tagged necessary, want unnecessary", diag)
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/inlayhints/inlayhints_test.go b/gopls/internal/regtest/inlayhints/inlayhints_test.go
--- a/gopls/internal/regtest/inlayhints/inlayhints_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/inlayhints/inlayhints_test.go	1969-12-31 16:00:00
@@ -1,69 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package inlayhint
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/internal/bug"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-func TestEnablingInlayHints(t *testing.T) {
-	const workspace = `
--- go.mod --
-module inlayHint.test
-go 1.12
--- lib.go --
-package lib
-type Number int
-const (
-	Zero Number = iota
-	One
-	Two
-)
-`
-	tests := []struct {
-		label         string
-		enabled       map[string]bool
-		wantInlayHint bool
-	}{
-		{
-			label:         "default",
-			wantInlayHint: false,
-		},
-		{
-			label:         "enable const",
-			enabled:       map[string]bool{source.ConstantValues: true},
-			wantInlayHint: true,
-		},
-		{
-			label:         "enable parameter names",
-			enabled:       map[string]bool{source.ParameterNames: true},
-			wantInlayHint: false,
-		},
-	}
-	for _, test := range tests {
-		t.Run(test.label, func(t *testing.T) {
-			WithOptions(
-				Settings{
-					"hints": test.enabled,
-				},
-			).Run(t, workspace, func(t *testing.T, env *Env) {
-				env.OpenFile("lib.go")
-				lens := env.InlayHints("lib.go")
-				if gotInlayHint := len(lens) > 0; gotInlayHint != test.wantInlayHint {
-					t.Errorf("got inlayHint: %t, want %t", gotInlayHint, test.wantInlayHint)
-				}
-			})
-		})
-	}
-}
diff -urN a/gopls/internal/regtest/misc/call_hierarchy_test.go b/gopls/internal/regtest/misc/call_hierarchy_test.go
--- a/gopls/internal/regtest/misc/call_hierarchy_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/call_hierarchy_test.go	1969-12-31 16:00:00
@@ -1,35 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package misc
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// Test for golang/go#49125
-func TestCallHierarchy_Issue49125(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- p.go --
-package pkg
-`
-	// TODO(rfindley): this could probably just be a marker test.
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("p.go")
-		pos := env.RegexpSearch("p.go", "pkg")
-
-		var params protocol.CallHierarchyPrepareParams
-		params.TextDocument.URI = env.Sandbox.Workdir.URI("p.go")
-		params.Position = pos.ToProtocolPosition()
-
-		// Check that this doesn't panic.
-		env.Editor.Server.PrepareCallHierarchy(env.Ctx, &params)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/configuration_test.go b/gopls/internal/regtest/misc/configuration_test.go
--- a/gopls/internal/regtest/misc/configuration_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/configuration_test.go	1969-12-31 16:00:00
@@ -1,115 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-
-	"golang.org/x/tools/internal/testenv"
-)
-
-// Test that enabling and disabling produces the expected results of showing
-// and hiding staticcheck analysis results.
-func TestChangeConfiguration(t *testing.T) {
-	// Staticcheck only supports Go versions >= 1.17.
-	// Note: keep this in sync with TestStaticcheckWarning. Below this version we
-	// should get an error when setting staticcheck configuration.
-	testenv.NeedsGo1Point(t, 17)
-
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.go --
-package a
-
-import "errors"
-
-// FooErr should be called ErrFoo (ST1012)
-var FooErr = errors.New("foo")
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.Await(
-			env.DoneWithOpen(),
-			EmptyDiagnostics("a/a.go"),
-		)
-		cfg := env.Editor.Config()
-		cfg.Settings = map[string]interface{}{
-			"staticcheck": true,
-		}
-		env.ChangeConfiguration(cfg)
-		env.Await(
-			DiagnosticAt("a/a.go", 5, 4),
-		)
-	})
-}
-
-func TestStaticcheckWarning(t *testing.T) {
-	// Note: keep this in sync with TestChangeConfiguration.
-	testenv.SkipAfterGo1Point(t, 16)
-
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.go --
-package a
-
-import "errors"
-
-// FooErr should be called ErrFoo (ST1012)
-var FooErr = errors.New("foo")
-`
-
-	WithOptions(
-		Settings{"staticcheck": true},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				ShownMessage("staticcheck is not supported"),
-			),
-		)
-	})
-}
-
-func TestGofumptWarning(t *testing.T) {
-	testenv.SkipAfterGo1Point(t, 17)
-
-	WithOptions(
-		Settings{"gofumpt": true},
-	).Run(t, "", func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				ShownMessage("gofumpt is not supported"),
-			),
-		)
-	})
-}
-
-func TestDeprecatedSettings(t *testing.T) {
-	WithOptions(
-		Settings{
-			"experimentalUseInvalidMetadata": true,
-			"experimentalWatchedFileDelay":   "1s",
-			"experimentalWorkspaceModule":    true,
-		},
-	).Run(t, "", func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				ShownMessage("experimentalWorkspaceModule"),
-				ShownMessage("experimentalUseInvalidMetadata"),
-				ShownMessage("experimentalWatchedFileDelay"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/debugserver_test.go b/gopls/internal/regtest/misc/debugserver_test.go
--- a/gopls/internal/regtest/misc/debugserver_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/debugserver_test.go	1969-12-31 16:00:00
@@ -1,46 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"net/http"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestStartDebugging(t *testing.T) {
-	WithOptions(
-		Modes(Forwarded),
-	).Run(t, "", func(t *testing.T, env *Env) {
-		args, err := command.MarshalArgs(command.DebuggingArgs{})
-		if err != nil {
-			t.Fatal(err)
-		}
-		params := &protocol.ExecuteCommandParams{
-			Command:   command.StartDebugging.ID(),
-			Arguments: args,
-		}
-		var result command.DebuggingResult
-		env.ExecuteCommand(params, &result)
-		if got, want := len(result.URLs), 2; got != want {
-			t.Fatalf("got %d urls, want %d; urls: %#v", got, want, result.URLs)
-		}
-		for i, u := range result.URLs {
-			resp, err := http.Get(u)
-			if err != nil {
-				t.Errorf("getting url #%d (%q): %v", i, u, err)
-				continue
-			}
-			defer resp.Body.Close()
-			if got, want := resp.StatusCode, http.StatusOK; got != want {
-				t.Errorf("debug server #%d returned HTTP %d, want %d", i, got, want)
-			}
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/misc/definition_test.go b/gopls/internal/regtest/misc/definition_test.go
--- a/gopls/internal/regtest/misc/definition_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/definition_test.go	1969-12-31 16:00:00
@@ -1,372 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"os"
-	"path"
-	"path/filepath"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-)
-
-const internalDefinition = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println(message)
-}
--- const.go --
-package main
-
-const message = "Hello World."
-`
-
-func TestGoToInternalDefinition(t *testing.T) {
-	Run(t, internalDefinition, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		name, pos := env.GoToDefinition("main.go", env.RegexpSearch("main.go", "message"))
-		if want := "const.go"; name != want {
-			t.Errorf("GoToDefinition: got file %q, want %q", name, want)
-		}
-		if want := env.RegexpSearch("const.go", "message"); pos != want {
-			t.Errorf("GoToDefinition: got position %v, want %v", pos, want)
-		}
-	})
-}
-
-const stdlibDefinition = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Printf()
-}`
-
-func TestGoToStdlibDefinition_Issue37045(t *testing.T) {
-	Run(t, stdlibDefinition, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		name, pos := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `fmt.(Printf)`))
-		if got, want := path.Base(name), "print.go"; got != want {
-			t.Errorf("GoToDefinition: got file %q, want %q", name, want)
-		}
-
-		// Test that we can jump to definition from outside our workspace.
-		// See golang.org/issues/37045.
-		newName, newPos := env.GoToDefinition(name, pos)
-		if newName != name {
-			t.Errorf("GoToDefinition is not idempotent: got %q, want %q", newName, name)
-		}
-		if newPos != pos {
-			t.Errorf("GoToDefinition is not idempotent: got %v, want %v", newPos, pos)
-		}
-	})
-}
-
-func TestUnexportedStdlib_Issue40809(t *testing.T) {
-	Run(t, stdlibDefinition, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		name, _ := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `fmt.(Printf)`))
-
-		pos := env.RegexpSearch(name, `:=\s*(newPrinter)\(\)`)
-
-		// Check that we can find references on a reference
-		refs := env.References(name, pos)
-		if len(refs) < 5 {
-			t.Errorf("expected 5+ references to newPrinter, found: %#v", refs)
-		}
-
-		name, pos = env.GoToDefinition(name, pos)
-		content, _ := env.Hover(name, pos)
-		if !strings.Contains(content.Value, "newPrinter") {
-			t.Fatal("definition of newPrinter went to the incorrect place")
-		}
-		// And on the definition too.
-		refs = env.References(name, pos)
-		if len(refs) < 5 {
-			t.Errorf("expected 5+ references to newPrinter, found: %#v", refs)
-		}
-	})
-}
-
-// Test the hover on an error's Error function.
-// This can't be done via the marker tests because Error is a builtin.
-func TestHoverOnError(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func main() {
-	var err error
-	err.Error()
-}`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		content, _ := env.Hover("main.go", env.RegexpSearch("main.go", "Error"))
-		if content == nil {
-			t.Fatalf("nil hover content for Error")
-		}
-		want := "```go\nfunc (error).Error() string\n```"
-		if content.Value != want {
-			t.Fatalf("hover failed:\n%s", compare.Text(want, content.Value))
-		}
-	})
-}
-
-func TestImportShortcut(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {}
-`
-	for _, tt := range []struct {
-		wantLinks      int
-		wantDef        bool
-		importShortcut string
-	}{
-		{1, false, "Link"},
-		{0, true, "Definition"},
-		{1, true, "Both"},
-	} {
-		t.Run(tt.importShortcut, func(t *testing.T) {
-			WithOptions(
-				Settings{"importShortcut": tt.importShortcut},
-			).Run(t, mod, func(t *testing.T, env *Env) {
-				env.OpenFile("main.go")
-				file, pos := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `"fmt"`))
-				if !tt.wantDef && (file != "" || pos != (fake.Pos{})) {
-					t.Fatalf("expected no definition, got one: %s:%v", file, pos)
-				} else if tt.wantDef && file == "" && pos == (fake.Pos{}) {
-					t.Fatalf("expected definition, got none")
-				}
-				links := env.DocumentLink("main.go")
-				if len(links) != tt.wantLinks {
-					t.Fatalf("expected %v links, got %v", tt.wantLinks, len(links))
-				}
-			})
-		})
-	}
-}
-
-func TestGoToTypeDefinition_Issue38589(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-type Int int
-
-type Struct struct{}
-
-func F1() {}
-func F2() (int, error) { return 0, nil }
-func F3() (**Struct, bool, *Int, error) { return nil, false, nil, nil }
-func F4() (**Struct, bool, *float64, error) { return nil, false, nil, nil }
-
-func main() {}
-`
-
-	for _, tt := range []struct {
-		re         string
-		wantError  bool
-		wantTypeRe string
-	}{
-		{re: `F1`, wantError: true},
-		{re: `F2`, wantError: true},
-		{re: `F3`, wantError: true},
-		{re: `F4`, wantError: false, wantTypeRe: `type (Struct)`},
-	} {
-		t.Run(tt.re, func(t *testing.T) {
-			Run(t, mod, func(t *testing.T, env *Env) {
-				env.OpenFile("main.go")
-
-				_, pos, err := env.Editor.GoToTypeDefinition(env.Ctx, "main.go", env.RegexpSearch("main.go", tt.re))
-				if tt.wantError {
-					if err == nil {
-						t.Fatal("expected error, got nil")
-					}
-					return
-				}
-				if err != nil {
-					t.Fatalf("expected nil error, got %s", err)
-				}
-
-				typePos := env.RegexpSearch("main.go", tt.wantTypeRe)
-				if pos != typePos {
-					t.Errorf("invalid pos: want %+v, got %+v", typePos, pos)
-				}
-			})
-		})
-	}
-}
-
-// Test for golang/go#47825.
-func TestImportTestVariant(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- client/test/role.go --
-package test
-
-import _ "mod.com/client"
-
-type RoleSetup struct{}
--- client/client_role_test.go --
-package client_test
-
-import (
-	"testing"
-	_ "mod.com/client"
-	ctest "mod.com/client/test"
-)
-
-func TestClient(t *testing.T) {
-	_ = ctest.RoleSetup{}
-}
--- client/client_test.go --
-package client
-
-import "testing"
-
-func TestClient(t *testing.T) {}
--- client.go --
-package client
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("client/client_role_test.go")
-		env.GoToDefinition("client/client_role_test.go", env.RegexpSearch("client/client_role_test.go", "RoleSetup"))
-	})
-}
-
-// This test exercises a crashing pattern from golang/go#49223.
-func TestGoToCrashingDefinition_Issue49223(t *testing.T) {
-	Run(t, "", func(t *testing.T, env *Env) {
-		params := &protocol.DefinitionParams{}
-		params.TextDocument.URI = protocol.DocumentURI("fugitive%3A///Users/user/src/mm/ems/.git//0/pkg/domain/treasury/provider.go")
-		params.Position.Character = 18
-		params.Position.Line = 0
-		env.Editor.Server.Definition(env.Ctx, params)
-	})
-}
-
-// TestVendoringInvalidatesMetadata ensures that gopls uses the
-// correct metadata even after an external 'go mod vendor' command
-// causes packages to move; see issue #55995.
-// See also TestImplementationsInVendor, which tests the same fix.
-func TestVendoringInvalidatesMetadata(t *testing.T) {
-	const proxy = `
--- other.com/b@v1.0.0/go.mod --
-module other.com/b
-go 1.14
-
--- other.com/b@v1.0.0/b.go --
-package b
-const K = 0
-`
-	const src = `
--- go.mod --
-module example.com/a
-go 1.14
-require other.com/b v1.0.0
-
--- go.sum --
-other.com/b v1.0.0 h1:1wb3PMGdet5ojzrKl+0iNksRLnOM9Jw+7amBNqmYwqk=
-other.com/b v1.0.0/go.mod h1:TgHQFucl04oGT+vrUm/liAzukYHNxCwKNkQZEyn3m9g=
-
--- a.go --
-package a
-import "other.com/b"
-const _ = b.K
-
-`
-	WithOptions(
-		ProxyFiles(proxy),
-		Modes(Default), // fails in 'experimental' mode
-	).Run(t, src, func(t *testing.T, env *Env) {
-		// Enable to debug go.sum mismatch, which may appear as
-		// "module lookup disabled by GOPROXY=off", confusingly.
-		if false {
-			env.DumpGoSum(".")
-		}
-
-		env.OpenFile("a.go")
-		refPos := env.RegexpSearch("a.go", "K") // find "b.K" reference
-
-		// Initially, b.K is defined in the module cache.
-		gotFile, _ := env.GoToDefinition("a.go", refPos)
-		wantCache := filepath.ToSlash(env.Sandbox.GOPATH()) + "/pkg/mod/other.com/b@v1.0.0/b.go"
-		if gotFile != wantCache {
-			t.Errorf("GoToDefinition, before: got file %q, want %q", gotFile, wantCache)
-		}
-
-		// Run 'go mod vendor' outside the editor.
-		if err := env.Sandbox.RunGoCommand(env.Ctx, ".", "mod", []string{"vendor"}, true); err != nil {
-			t.Fatalf("go mod vendor: %v", err)
-		}
-
-		// Synchronize changes to watched files.
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		// Now, b.K is defined in the vendor tree.
-		gotFile, _ = env.GoToDefinition("a.go", refPos)
-		wantVendor := "vendor/other.com/b/b.go"
-		if gotFile != wantVendor {
-			t.Errorf("GoToDefinition, after go mod vendor: got file %q, want %q", gotFile, wantVendor)
-		}
-
-		// Delete the vendor tree.
-		if err := os.RemoveAll(env.Sandbox.Workdir.AbsPath("vendor")); err != nil {
-			t.Fatal(err)
-		}
-		// Notify the server of the deletion.
-		if err := env.Sandbox.Workdir.CheckForFileChanges(env.Ctx); err != nil {
-			t.Fatal(err)
-		}
-
-		// Synchronize again.
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		// b.K is once again defined in the module cache.
-		gotFile, _ = env.GoToDefinition("a.go", refPos)
-		if gotFile != wantCache {
-			t.Errorf("GoToDefinition, after rm -rf vendor: got file %q, want %q", gotFile, wantCache)
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/misc/embed_test.go b/gopls/internal/regtest/misc/embed_test.go
--- a/gopls/internal/regtest/misc/embed_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/embed_test.go	1969-12-31 16:00:00
@@ -1,35 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestMissingPatternDiagnostic(t *testing.T) {
-	const files = `
--- go.mod --
-module example.com
--- x.go --
-package x
-
-import (
-	_ "embed"
-)
-
-// Issue 47436
-func F() {}
-
-//go:embed NONEXISTENT
-var foo string
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("x.go")
-		env.Await(env.DiagnosticAtRegexpWithMessage("x.go", `NONEXISTENT`, "no matching files found"))
-		env.RegexpReplace("x.go", `NONEXISTENT`, "x.go")
-		env.Await(EmptyDiagnostics("x.go"))
-	})
-}
diff -urN a/gopls/internal/regtest/misc/extract_test.go b/gopls/internal/regtest/misc/extract_test.go
--- a/gopls/internal/regtest/misc/extract_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/extract_test.go	1969-12-31 16:00:00
@@ -1,69 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func TestExtractFunction(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func Foo() int {
-	a := 5
-	return a
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-
-		start := env.RegexpSearch("main.go", "a := 5").ToProtocolPosition()
-		end := env.RegexpSearch("main.go", "return a").ToProtocolPosition()
-
-		actions, err := env.Editor.CodeAction(env.Ctx, "main.go", &protocol.Range{Start: start, End: end}, nil)
-		if err != nil {
-			t.Fatal(err)
-		}
-
-		// Find the extract function code action.
-		var extractFunc *protocol.CodeAction
-		for _, action := range actions {
-			if action.Kind == protocol.RefactorExtract && action.Title == "Extract function" {
-				extractFunc = &action
-				break
-			}
-		}
-		if extractFunc == nil {
-			t.Fatal("could not find extract function action")
-		}
-
-		env.ApplyCodeAction(*extractFunc)
-		want := `package main
-
-func Foo() int {
-	a := newFunction()
-	return a
-}
-
-func newFunction() int {
-	a := 5
-	return a
-}
-`
-		if got := env.BufferText("main.go"); got != want {
-			t.Fatalf("TestFillStruct failed:\n%s", compare.Text(want, got))
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/misc/failures_test.go b/gopls/internal/regtest/misc/failures_test.go
--- a/gopls/internal/regtest/misc/failures_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/failures_test.go	1969-12-31 16:00:00
@@ -1,84 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-)
-
-// This is a slight variant of TestHoverOnError in definition_test.go
-// that includes a line directive, which makes no difference since
-// gopls ignores line directives.
-func TestHoverFailure(t *testing.T) {
-	t.Skip("line directives //line ")
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a.y --
-DWIM(main)
-
--- main.go --
-//line a.y:1
-package main
-
-func main() {
-	var err error
-	err.Error()
-}`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		content, _ := env.Hover("main.go", env.RegexpSearch("main.go", "Error"))
-		if content == nil {
-			t.Fatalf("Hover('Error') returned nil")
-		}
-		want := "```go\nfunc (error).Error() string\n```"
-		if content.Value != want {
-			t.Fatalf("wrong Hover('Error') content:\n%s", compare.Text(want, content.Value))
-		}
-	})
-}
-
-// This test demonstrates a case where gopls is not at all confused by
-// line directives, because it completely ignores them.
-func TestFailingDiagnosticClearingOnEdit(t *testing.T) {
-	t.Skip("line directives //line ")
-	// badPackageDup contains a duplicate definition of the 'a' const.
-	// This is a minor variant of TestDiagnosticClearingOnEditfrom from
-	// diagnostics_test.go, with a line directive, which makes no difference.
-	const badPackageDup = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a.go --
-package consts
-
-const a = 1
--- b.go --
-package consts
-//line gen.go:5
-const a = 2
-`
-
-	Run(t, badPackageDup, func(t *testing.T, env *Env) {
-		env.OpenFile("b.go")
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("b.go", `a = 2`, "a redeclared"),
-			env.DiagnosticAtRegexpWithMessage("a.go", `a = 1`, "other declaration"),
-		)
-
-		// Fix the error by editing the const name in b.go to `b`.
-		env.RegexpReplace("b.go", "(a) = 2", "b")
-		env.Await(
-			EmptyOrNoDiagnostics("a.go"),
-			EmptyOrNoDiagnostics("b.go"),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/fix_test.go b/gopls/internal/regtest/misc/fix_test.go
--- a/gopls/internal/regtest/misc/fix_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/fix_test.go	1969-12-31 16:00:00
@@ -1,107 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// A basic test for fillstruct, now that it uses a command.
-func TestFillStruct(t *testing.T) {
-	const basic = `
--- go.mod --
-module mod.com
-
-go 1.14
--- main.go --
-package main
-
-type Info struct {
-	WordCounts map[string]int
-	Words []string
-}
-
-func Foo() {
-	_ = Info{}
-}
-`
-	Run(t, basic, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		pos := env.RegexpSearch("main.go", "Info{}").ToProtocolPosition()
-		if err := env.Editor.RefactorRewrite(env.Ctx, "main.go", &protocol.Range{
-			Start: pos,
-			End:   pos,
-		}); err != nil {
-			t.Fatal(err)
-		}
-		want := `package main
-
-type Info struct {
-	WordCounts map[string]int
-	Words []string
-}
-
-func Foo() {
-	_ = Info{
-		WordCounts: map[string]int{},
-		Words:      []string{},
-	}
-}
-`
-		if got := env.BufferText("main.go"); got != want {
-			t.Fatalf("TestFillStruct failed:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestFillReturns(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func Foo() error {
-	return
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(OnceMet(
-			// The error message here changed in 1.18; "return values" covers both forms.
-			env.DiagnosticAtRegexpWithMessage("main.go", `return`, "return values"),
-			ReadDiagnostics("main.go", &d),
-		))
-		codeActions := env.CodeAction("main.go", d.Diagnostics)
-		if len(codeActions) != 2 {
-			t.Fatalf("expected 2 code actions, got %v", len(codeActions))
-		}
-		var foundQuickFix, foundFixAll bool
-		for _, a := range codeActions {
-			if a.Kind == protocol.QuickFix {
-				foundQuickFix = true
-			}
-			if a.Kind == protocol.SourceFixAll {
-				foundFixAll = true
-			}
-		}
-		if !foundQuickFix {
-			t.Fatalf("expected quickfix code action, got none")
-		}
-		if !foundFixAll {
-			t.Fatalf("expected fixall code action, got none")
-		}
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-		env.Await(EmptyDiagnostics("main.go"))
-	})
-}
diff -urN a/gopls/internal/regtest/misc/formatting_test.go b/gopls/internal/regtest/misc/formatting_test.go
--- a/gopls/internal/regtest/misc/formatting_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/formatting_test.go	1969-12-31 16:00:00
@@ -1,368 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/internal/testenv"
-)
-
-const unformattedProgram = `
--- main.go --
-package main
-import "fmt"
-func main(  ) {
-	fmt.Println("Hello World.")
-}
--- main.go.golden --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hello World.")
-}
-`
-
-func TestFormatting(t *testing.T) {
-	Run(t, unformattedProgram, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.FormatBuffer("main.go")
-		got := env.BufferText("main.go")
-		want := env.ReadWorkspaceFile("main.go.golden")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Tests golang/go#36824.
-func TestFormattingOneLine36824(t *testing.T) {
-	const onelineProgram = `
--- a.go --
-package main; func f() {}
-
--- a.go.formatted --
-package main
-
-func f() {}
-`
-	Run(t, onelineProgram, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		env.FormatBuffer("a.go")
-		got := env.BufferText("a.go")
-		want := env.ReadWorkspaceFile("a.go.formatted")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Tests golang/go#36824.
-func TestFormattingOneLineImports36824(t *testing.T) {
-	const onelineProgramA = `
--- a.go --
-package x; func f() {fmt.Println()}
-
--- a.go.imported --
-package x
-
-import "fmt"
-
-func f() { fmt.Println() }
-`
-	Run(t, onelineProgramA, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		env.OrganizeImports("a.go")
-		got := env.BufferText("a.go")
-		want := env.ReadWorkspaceFile("a.go.imported")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestFormattingOneLineRmImports36824(t *testing.T) {
-	const onelineProgramB = `
--- a.go --
-package x; import "os"; func f() {}
-
--- a.go.imported --
-package x
-
-func f() {}
-`
-	Run(t, onelineProgramB, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		env.OrganizeImports("a.go")
-		got := env.BufferText("a.go")
-		want := env.ReadWorkspaceFile("a.go.imported")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-const disorganizedProgram = `
--- main.go --
-package main
-
-import (
-	"fmt"
-	"errors"
-)
-func main(  ) {
-	fmt.Println(errors.New("bad"))
-}
--- main.go.organized --
-package main
-
-import (
-	"errors"
-	"fmt"
-)
-func main(  ) {
-	fmt.Println(errors.New("bad"))
-}
--- main.go.formatted --
-package main
-
-import (
-	"errors"
-	"fmt"
-)
-
-func main() {
-	fmt.Println(errors.New("bad"))
-}
-`
-
-func TestOrganizeImports(t *testing.T) {
-	Run(t, disorganizedProgram, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.OrganizeImports("main.go")
-		got := env.BufferText("main.go")
-		want := env.ReadWorkspaceFile("main.go.organized")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestFormattingOnSave(t *testing.T) {
-	Run(t, disorganizedProgram, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.SaveBuffer("main.go")
-		got := env.BufferText("main.go")
-		want := env.ReadWorkspaceFile("main.go.formatted")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Tests various possibilities for comments in files with CRLF line endings.
-// Import organization in these files has historically been a source of bugs.
-func TestCRLFLineEndings(t *testing.T) {
-	for _, tt := range []struct {
-		issue, input, want string
-	}{
-		{
-			issue: "41057",
-			want: `package main
-
-/*
-Hi description
-*/
-func Hi() {
-}
-`,
-		},
-		{
-			issue: "42646",
-			want: `package main
-
-import (
-	"fmt"
-)
-
-/*
-func upload(c echo.Context) error {
-	if err := r.ParseForm(); err != nil {
-		fmt.Fprintf(w, "ParseForm() err: %v", err)
-		return
-	}
-	fmt.Fprintf(w, "POST request successful")
-	path_ver := r.FormValue("path_ver")
-	ukclin_ver := r.FormValue("ukclin_ver")
-
-	fmt.Fprintf(w, "Name = %s\n", path_ver)
-	fmt.Fprintf(w, "Address = %s\n", ukclin_ver)
-}
-*/
-
-func main() {
-	const server_port = 8080
-	fmt.Printf("port: %d\n", server_port)
-}
-`,
-		},
-		{
-			issue: "42923",
-			want: `package main
-
-// Line 1.
-// aa
-type Tree struct {
-	arr []string
-}
-`,
-		},
-		{
-			issue: "47200",
-			input: `package main
-
-import "fmt"
-
-func main() {
-	math.Sqrt(9)
-	fmt.Println("hello")
-}
-`,
-			want: `package main
-
-import (
-	"fmt"
-	"math"
-)
-
-func main() {
-	math.Sqrt(9)
-	fmt.Println("hello")
-}
-`,
-		},
-	} {
-		t.Run(tt.issue, func(t *testing.T) {
-			Run(t, "-- main.go --", func(t *testing.T, env *Env) {
-				input := tt.input
-				if input == "" {
-					input = tt.want
-				}
-				crlf := strings.ReplaceAll(input, "\n", "\r\n")
-				env.CreateBuffer("main.go", crlf)
-				env.Await(env.DoneWithOpen())
-				env.OrganizeImports("main.go")
-				got := env.BufferText("main.go")
-				got = strings.ReplaceAll(got, "\r\n", "\n") // convert everything to LF for simplicity
-				if tt.want != got {
-					t.Errorf("unexpected content after save:\n%s", compare.Text(tt.want, got))
-				}
-			})
-		})
-	}
-}
-
-func TestFormattingOfGeneratedFile_Issue49555(t *testing.T) {
-	const input = `
--- main.go --
-// Code generated by generator.go. DO NOT EDIT.
-
-package main
-
-import "fmt"
-
-func main() {
-
-
-
-
-	fmt.Print("hello")
-}
-`
-
-	Run(t, input, func(t *testing.T, env *Env) {
-		wantErrSuffix := "file is generated"
-
-		env.OpenFile("main.go")
-		err := env.Editor.FormatBuffer(env.Ctx, "main.go")
-		if err == nil {
-			t.Fatal("expected error, got nil")
-		}
-		// Check only the suffix because an error contains a dynamic path to main.go
-		if !strings.HasSuffix(err.Error(), wantErrSuffix) {
-			t.Fatalf("unexpected error %q, want suffix %q", err.Error(), wantErrSuffix)
-		}
-	})
-}
-
-func TestGofumptFormatting(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-
-	// Exercise some gofumpt formatting rules:
-	//  - No empty lines following an assignment operator
-	//  - Octal integer literals should use the 0o prefix on modules using Go
-	//    1.13 and later. Requires LangVersion to be correctly resolved.
-	//  - std imports must be in a separate group at the top. Requires ModulePath
-	//    to be correctly resolved.
-	const input = `
--- go.mod --
-module foo
-
-go 1.17
--- foo.go --
-package foo
-
-import (
-	"foo/bar"
-	"fmt"
-)
-
-const perm = 0755
-
-func foo() {
-	foo :=
-		"bar"
-	fmt.Println(foo, bar.Bar)
-}
--- foo.go.formatted --
-package foo
-
-import (
-	"fmt"
-
-	"foo/bar"
-)
-
-const perm = 0o755
-
-func foo() {
-	foo := "bar"
-	fmt.Println(foo, bar.Bar)
-}
--- bar/bar.go --
-package bar
-
-const Bar = 42
-`
-
-	WithOptions(
-		Settings{
-			"gofumpt": true,
-		},
-	).Run(t, input, func(t *testing.T, env *Env) {
-		env.OpenFile("foo.go")
-		env.FormatBuffer("foo.go")
-		got := env.BufferText("foo.go")
-		want := env.ReadWorkspaceFile("foo.go.formatted")
-		if got != want {
-			t.Errorf("unexpected formatting result:\n%s", compare.Text(want, got))
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/misc/generate_test.go b/gopls/internal/regtest/misc/generate_test.go
--- a/gopls/internal/regtest/misc/generate_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/generate_test.go	1969-12-31 16:00:00
@@ -1,73 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// TODO(rfindley): figure out why go generate fails on android builders.
-
-//go:build !android
-// +build !android
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestGenerateProgress(t *testing.T) {
-	const generatedWorkspace = `
--- go.mod --
-module fake.test
-
-go 1.14
--- generate.go --
-// +build ignore
-
-package main
-
-import (
-	"io/ioutil"
-	"os"
-)
-
-func main() {
-	ioutil.WriteFile("generated.go", []byte("package " + os.Args[1] + "\n\nconst Answer = 21"), 0644)
-}
-
--- lib1/lib.go --
-package lib1
-
-//go:generate go run ../generate.go lib1
-
--- lib2/lib.go --
-package lib2
-
-//go:generate go run ../generate.go lib2
-
--- main.go --
-package main
-
-import (
-	"fake.test/lib1"
-	"fake.test/lib2"
-)
-
-func main() {
-	println(lib1.Answer + lib2.Answer)
-}
-`
-
-	Run(t, generatedWorkspace, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", "lib1.(Answer)"),
-		)
-		env.RunGenerate("./lib1")
-		env.RunGenerate("./lib2")
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				EmptyDiagnostics("main.go")),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/highlight_test.go b/gopls/internal/regtest/misc/highlight_test.go
--- a/gopls/internal/regtest/misc/highlight_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/highlight_test.go	1969-12-31 16:00:00
@@ -1,151 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"sort"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestWorkspacePackageHighlight(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func main() {
-	var A string = "A"
-	x := "x-" + A
-	println(A, x)
-}`
-
-	Run(t, mod, func(t *testing.T, env *Env) {
-		const file = "main.go"
-		env.OpenFile(file)
-		_, pos := env.GoToDefinition(file, env.RegexpSearch(file, `var (A) string`))
-
-		checkHighlights(env, file, pos, 3)
-	})
-}
-
-func TestStdPackageHighlight_Issue43511(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Printf()
-}`
-
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		file, _ := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `fmt\.(Printf)`))
-		pos := env.RegexpSearch(file, `func Printf\((format) string`)
-
-		checkHighlights(env, file, pos, 2)
-	})
-}
-
-func TestThirdPartyPackageHighlight_Issue43511(t *testing.T) {
-	const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/global/global.go --
-package global
-
-const A = 1
-
-func foo() {
-	_ = A
-}
-
-func bar() int {
-	return A + A
-}
--- example.com@v1.2.3/local/local.go --
-package local
-
-func foo() int {
-	const b = 2
-
-	return b * b * (b+1) + b
-}`
-
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require example.com v1.2.3
--- go.sum --
-example.com v1.2.3 h1:WFzrgiQJwEDJNLDUOV1f9qlasQkvzXf2UNLaNIqbWsI=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- main.go --
-package main
-
-import (
-	_ "example.com/global"
-	_ "example.com/local"
-)
-
-func main() {}`
-
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-
-		file, _ := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `"example.com/global"`))
-		pos := env.RegexpSearch(file, `const (A)`)
-		checkHighlights(env, file, pos, 4)
-
-		file, _ = env.GoToDefinition("main.go", env.RegexpSearch("main.go", `"example.com/local"`))
-		pos = env.RegexpSearch(file, `const (b)`)
-		checkHighlights(env, file, pos, 5)
-	})
-}
-
-func checkHighlights(env *Env, file string, pos fake.Pos, highlightCount int) {
-	t := env.T
-	t.Helper()
-
-	highlights := env.DocumentHighlight(file, pos)
-	if len(highlights) != highlightCount {
-		t.Fatalf("expected %v highlight(s), got %v", highlightCount, len(highlights))
-	}
-
-	references := env.References(file, pos)
-	if len(highlights) != len(references) {
-		t.Fatalf("number of highlights and references is expected to be equal: %v != %v", len(highlights), len(references))
-	}
-
-	sort.Slice(highlights, func(i, j int) bool {
-		return protocol.CompareRange(highlights[i].Range, highlights[j].Range) < 0
-	})
-	sort.Slice(references, func(i, j int) bool {
-		return protocol.CompareRange(references[i].Range, references[j].Range) < 0
-	})
-	for i := range highlights {
-		if highlights[i].Range != references[i].Range {
-			t.Errorf("highlight and reference ranges are expected to be equal: %v != %v", highlights[i].Range, references[i].Range)
-		}
-	}
-}
diff -urN a/gopls/internal/regtest/misc/hover_test.go b/gopls/internal/regtest/misc/hover_test.go
--- a/gopls/internal/regtest/misc/hover_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/hover_test.go	1969-12-31 16:00:00
@@ -1,255 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"fmt"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestHoverUnexported(t *testing.T) {
-	const proxy = `
--- golang.org/x/structs@v1.0.0/go.mod --
-module golang.org/x/structs
-
-go 1.12
-
--- golang.org/x/structs@v1.0.0/types.go --
-package structs
-
-type Mixed struct {
-	// Exported comment
-	Exported   int
-	unexported string
-}
-
-func printMixed(m Mixed) {
-	println(m)
-}
-`
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require golang.org/x/structs v1.0.0
--- go.sum --
-golang.org/x/structs v1.0.0 h1:Ito/a7hBYZaNKShFrZKjfBA/SIPvmBrcPCBWPx5QeKk=
-golang.org/x/structs v1.0.0/go.mod h1:47gkSIdo5AaQaWJS0upVORsxfEr1LL1MWv9dmYF3iq4=
--- main.go --
-package main
-
-import "golang.org/x/structs"
-
-func main() {
-	var m structs.Mixed
-	_ = m.Exported
-}
-`
-
-	// TODO: use a nested workspace folder here.
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		mixedPos := env.RegexpSearch("main.go", "Mixed")
-		got, _ := env.Hover("main.go", mixedPos)
-		if !strings.Contains(got.Value, "unexported") {
-			t.Errorf("Workspace hover: missing expected field 'unexported'. Got:\n%q", got.Value)
-		}
-
-		cacheFile, _ := env.GoToDefinition("main.go", mixedPos)
-		argPos := env.RegexpSearch(cacheFile, "printMixed.*(Mixed)")
-		got, _ = env.Hover(cacheFile, argPos)
-		if !strings.Contains(got.Value, "unexported") {
-			t.Errorf("Non-workspace hover: missing expected field 'unexported'. Got:\n%q", got.Value)
-		}
-
-		exportedFieldPos := env.RegexpSearch("main.go", "Exported")
-		got, _ = env.Hover("main.go", exportedFieldPos)
-		if !strings.Contains(got.Value, "comment") {
-			t.Errorf("Workspace hover: missing comment for field 'Exported'. Got:\n%q", got.Value)
-		}
-	})
-}
-
-func TestHoverIntLiteral(t *testing.T) {
-	const source = `
--- main.go --
-package main
-
-var (
-	bigBin = 0b1001001
-)
-
-var hex = 0xe34e
-
-func main() {
-}
-`
-	Run(t, source, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		hexExpected := "58190"
-		got, _ := env.Hover("main.go", env.RegexpSearch("main.go", "hex"))
-		if got != nil && !strings.Contains(got.Value, hexExpected) {
-			t.Errorf("Hover: missing expected field '%s'. Got:\n%q", hexExpected, got.Value)
-		}
-
-		binExpected := "73"
-		got, _ = env.Hover("main.go", env.RegexpSearch("main.go", "bigBin"))
-		if got != nil && !strings.Contains(got.Value, binExpected) {
-			t.Errorf("Hover: missing expected field '%s'. Got:\n%q", binExpected, got.Value)
-		}
-	})
-}
-
-// Tests that hovering does not trigger the panic in golang/go#48249.
-func TestPanicInHoverBrokenCode(t *testing.T) {
-	const source = `
--- main.go --
-package main
-
-type Example struct`
-	Run(t, source, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.Editor.Hover(env.Ctx, "main.go", env.RegexpSearch("main.go", "Example"))
-	})
-}
-
-func TestHoverRune_48492(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.EditBuffer("main.go", fake.NewEdit(0, 0, 1, 0, "package main\nfunc main() {\nconst x = `\nfoo\n`\n}"))
-		env.Editor.Hover(env.Ctx, "main.go", env.RegexpSearch("main.go", "foo"))
-	})
-}
-
-func TestHoverImport(t *testing.T) {
-	const packageDoc1 = "Package lib1 hover documentation"
-	const packageDoc2 = "Package lib2 hover documentation"
-	tests := []struct {
-		hoverPackage string
-		want         string
-	}{
-		{
-			"mod.com/lib1",
-			packageDoc1,
-		},
-		{
-			"mod.com/lib2",
-			packageDoc2,
-		},
-		{
-			"mod.com/lib3",
-			"",
-		},
-	}
-	source := fmt.Sprintf(`
--- go.mod --
-module mod.com
-
-go 1.12
--- lib1/a.go --
-// %s
-package lib1
-
-const C = 1
-
--- lib1/b.go --
-package lib1
-
-const D = 1
-
--- lib2/a.go --
-// %s
-package lib2
-
-const E = 1
-
--- lib3/a.go --
-package lib3
-
-const F = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib1"
-	"mod.com/lib2"
-	"mod.com/lib3"
-	"mod.com/lib4"
-)
-
-func main() {
-	println("Hello")
-}
-	`, packageDoc1, packageDoc2)
-	Run(t, source, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		for _, test := range tests {
-			got, _ := env.Hover("main.go", env.RegexpSearch("main.go", test.hoverPackage))
-			if !strings.Contains(got.Value, test.want) {
-				t.Errorf("Hover: got:\n%q\nwant:\n%q", got.Value, test.want)
-			}
-		}
-
-		got, _ := env.Hover("main.go", env.RegexpSearch("main.go", "mod.com/lib4"))
-		if got != nil {
-			t.Errorf("Hover: got:\n%q\nwant:\n%v", got.Value, nil)
-		}
-	})
-}
-
-// for x/tools/gopls: unhandled named anchor on the hover #57048
-func TestHoverTags(t *testing.T) {
-	const source = `
--- go.mod --
-module mod.com
-
-go 1.19
-
--- lib/a.go --
-
-// variety of execution modes.
-//
-// # Test package setup
-//
-// The regression test package uses a couple of uncommon patterns to reduce
-package lib
-
--- a.go --
-	package main
-	import "mod.com/lib"
-
-	const A = 1
-
-}
-`
-	Run(t, source, func(t *testing.T, env *Env) {
-		t.Run("tags", func(t *testing.T) {
-			env.OpenFile("a.go")
-			z := env.RegexpSearch("a.go", "lib")
-			t.Logf("%#v", z)
-			got, _ := env.Hover("a.go", env.RegexpSearch("a.go", "lib"))
-			if strings.Contains(got.Value, "{#hdr-") {
-				t.Errorf("Hover: got {#hdr- tag:\n%q", got)
-			}
-		})
-	})
-}
diff -urN a/gopls/internal/regtest/misc/import_test.go b/gopls/internal/regtest/misc/import_test.go
--- a/gopls/internal/regtest/misc/import_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/import_test.go	1969-12-31 16:00:00
@@ -1,133 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-)
-
-func TestAddImport(t *testing.T) {
-	const before = `package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("hello world")
-}
-`
-
-	const want = `package main
-
-import (
-	"bytes"
-	"fmt"
-)
-
-func main() {
-	fmt.Println("hello world")
-}
-`
-
-	Run(t, "", func(t *testing.T, env *Env) {
-		env.CreateBuffer("main.go", before)
-		cmd, err := command.NewAddImportCommand("Add Import", command.AddImportArgs{
-			URI:        env.Sandbox.Workdir.URI("main.go"),
-			ImportPath: "bytes",
-		})
-		if err != nil {
-			t.Fatal(err)
-		}
-		env.ExecuteCommand(&protocol.ExecuteCommandParams{
-			Command:   "gopls.add_import",
-			Arguments: cmd.Arguments,
-		}, nil)
-		got := env.BufferText("main.go")
-		if got != want {
-			t.Fatalf("gopls.add_import failed\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestListImports(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo.go --
-package foo
-const C = 1
--- import_strings_test.go --
-package foo
-import (
-	x "strings"
-	"testing"
-)
-
-func TestFoo(t *testing.T) {}
--- import_testing_test.go --
-package foo
-
-import "testing"
-
-func TestFoo2(t *testing.T) {}
-`
-	tests := []struct {
-		filename string
-		want     command.ListImportsResult
-	}{
-		{
-			filename: "import_strings_test.go",
-			want: command.ListImportsResult{
-				Imports: []command.FileImport{
-					{Name: "x", Path: "strings"},
-					{Path: "testing"},
-				},
-				PackageImports: []command.PackageImport{
-					{Path: "strings"},
-					{Path: "testing"},
-				},
-			},
-		},
-		{
-			filename: "import_testing_test.go",
-			want: command.ListImportsResult{
-				Imports: []command.FileImport{
-					{Path: "testing"},
-				},
-				PackageImports: []command.PackageImport{
-					{Path: "strings"},
-					{Path: "testing"},
-				},
-			},
-		},
-	}
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		for _, tt := range tests {
-			cmd, err := command.NewListImportsCommand("List Imports", command.URIArg{
-				URI: env.Sandbox.Workdir.URI(tt.filename),
-			})
-			if err != nil {
-				t.Fatal(err)
-			}
-			var result command.ListImportsResult
-			env.ExecuteCommand(&protocol.ExecuteCommandParams{
-				Command:   command.ListImports.ID(),
-				Arguments: cmd.Arguments,
-			}, &result)
-			if diff := cmp.Diff(tt.want, result); diff != "" {
-				t.Errorf("unexpected list imports result for %q (-want +got):\n%s", tt.filename, diff)
-			}
-		}
-
-	})
-}
diff -urN a/gopls/internal/regtest/misc/imports_test.go b/gopls/internal/regtest/misc/imports_test.go
--- a/gopls/internal/regtest/misc/imports_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/imports_test.go	1969-12-31 16:00:00
@@ -1,259 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/testenv"
-)
-
-// Tests golang/go#38815.
-func TestIssue38815(t *testing.T) {
-	const needs = `
--- go.mod --
-module foo
-
-go 1.12
--- a.go --
-package main
-func f() {}
-`
-	const ntest = `package main
-func TestZ(t *testing.T) {
-	f()
-}
-`
-	const want = `package main
-
-import "testing"
-
-func TestZ(t *testing.T) {
-	f()
-}
-`
-
-	// it was returning
-	// "package main\nimport \"testing\"\npackage main..."
-	Run(t, needs, func(t *testing.T, env *Env) {
-		env.CreateBuffer("a_test.go", ntest)
-		env.SaveBuffer("a_test.go")
-		got := env.BufferText("a_test.go")
-		if want != got {
-			t.Errorf("got\n%q, wanted\n%q", got, want)
-		}
-	})
-}
-
-func TestVim1(t *testing.T) {
-	const vim1 = `package main
-
-import "fmt"
-
-var foo = 1
-var bar = 2
-
-func main() {
-	fmt.Printf("This is a test %v\n", foo)
-	fmt.Printf("This is another test %v\n", foo)
-	fmt.Printf("This is also a test %v\n", foo)
-}
-`
-
-	// The file remains unchanged, but if there are any CodeActions returned, they confuse vim.
-	// Therefore check for no CodeActions
-	Run(t, "", func(t *testing.T, env *Env) {
-		env.CreateBuffer("main.go", vim1)
-		env.OrganizeImports("main.go")
-		actions := env.CodeAction("main.go", nil)
-		if len(actions) > 0 {
-			got := env.BufferText("main.go")
-			t.Errorf("unexpected actions %#v", actions)
-			if got == vim1 {
-				t.Errorf("no changes")
-			} else {
-				t.Errorf("got\n%q", got)
-				t.Errorf("was\n%q", vim1)
-			}
-		}
-	})
-}
-
-func TestVim2(t *testing.T) {
-	const vim2 = `package main
-
-import (
-	"fmt"
-
-	"example.com/blah"
-
-	"rubbish.com/useless"
-)
-
-func main() {
-	fmt.Println(blah.Name, useless.Name)
-}
-`
-
-	Run(t, "", func(t *testing.T, env *Env) {
-		env.CreateBuffer("main.go", vim2)
-		env.OrganizeImports("main.go")
-		actions := env.CodeAction("main.go", nil)
-		if len(actions) > 0 {
-			t.Errorf("unexpected actions %#v", actions)
-		}
-	})
-}
-
-func TestGOMODCACHE(t *testing.T) {
-	const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/x/x.go --
-package x
-
-const X = 1
--- example.com@v1.2.3/y/y.go --
-package y
-
-const Y = 2
-`
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require example.com v1.2.3
--- go.sum --
-example.com v1.2.3 h1:6vTQqzX+pnwngZF1+5gcO3ZEWmix1jJ/h+pWS8wUxK0=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- main.go --
-package main
-
-import "example.com/x"
-
-var _, _ = x.X, y.Y
-`
-	modcache, err := ioutil.TempDir("", "TestGOMODCACHE-modcache")
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(modcache)
-	WithOptions(
-		EnvVars{"GOMODCACHE": modcache},
-		ProxyFiles(proxy),
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.Await(env.DiagnosticAtRegexp("main.go", `y.Y`))
-		env.SaveBuffer("main.go")
-		env.Await(EmptyDiagnostics("main.go"))
-		path, _ := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `y.(Y)`))
-		if !strings.HasPrefix(path, filepath.ToSlash(modcache)) {
-			t.Errorf("found module dependency outside of GOMODCACHE: got %v, wanted subdir of %v", path, filepath.ToSlash(modcache))
-		}
-	})
-}
-
-// Tests golang/go#40685.
-func TestAcceptImportsQuickFixTestVariant(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.go --
-package a
-
-import (
-	"fmt"
-)
-
-func _() {
-	fmt.Println("")
-	os.Stat("")
-}
--- a/a_test.go --
-package a
-
-import (
-	"os"
-	"testing"
-)
-
-func TestA(t *testing.T) {
-	os.Stat("")
-}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/a.go", "os.Stat"),
-				ReadDiagnostics("a/a.go", &d),
-			),
-		)
-		env.ApplyQuickFixes("a/a.go", d.Diagnostics)
-		env.Await(
-			EmptyDiagnostics("a/a.go"),
-		)
-	})
-}
-
-// Test for golang/go#52784
-func TestGoWorkImports(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const pkg = `
--- go.work --
-go 1.19
-
-use (
-        ./caller
-        ./mod
-)
--- caller/go.mod --
-module caller.com
-
-go 1.18
-
-require mod.com v0.0.0
-
-replace mod.com => ../mod
--- caller/caller.go --
-package main
-
-func main() {
-        a.Test()
-}
--- mod/go.mod --
-module mod.com
-
-go 1.18
--- mod/a/a.go --
-package a
-
-func Test() {
-}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.OpenFile("caller/caller.go")
-		env.Await(env.DiagnosticAtRegexp("caller/caller.go", "a.Test"))
-
-		// Saving caller.go should trigger goimports, which should find a.Test in
-		// the mod.com module, thanks to the go.work file.
-		env.SaveBuffer("caller/caller.go")
-		env.Await(EmptyDiagnostics("caller/caller.go"))
-	})
-}
diff -urN a/gopls/internal/regtest/misc/leak_test.go b/gopls/internal/regtest/misc/leak_test.go
--- a/gopls/internal/regtest/misc/leak_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/leak_test.go	1969-12-31 16:00:00
@@ -1,85 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"context"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/lsprpc"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/jsonrpc2"
-	"golang.org/x/tools/internal/jsonrpc2/servertest"
-)
-
-// Test for golang/go#57222.
-func TestCacheLeak(t *testing.T) {
-	// TODO(rfindley): either fix this test with additional instrumentation, or
-	// delete it.
-	t.Skip("This test races with cache eviction.")
-	const files = `-- a.go --
-package a
-
-func _() {
-	println("1")
-}
-`
-	c := cache.New(nil, nil)
-	env := setupEnv(t, files, c)
-	env.Await(InitialWorkspaceLoad)
-	env.OpenFile("a.go")
-
-	// Make a couple edits to stabilize cache state.
-	//
-	// For some reason, after only one edit we're left with two parsed files
-	// (perhaps because something had to ParseHeader). If this test proves flaky,
-	// we'll need to investigate exactly what is causing various parse modes to
-	// be present (or rewrite the test to be more tolerant, for example make ~100
-	// modifications and assert that we're within a few of where we're started).
-	env.RegexpReplace("a.go", "1", "2")
-	env.RegexpReplace("a.go", "2", "3")
-	env.AfterChange()
-
-	// Capture cache state, make an arbitrary change, and wait for gopls to do
-	// its work. Afterward, we should have the exact same number of parsed
-	before := c.MemStats()
-	env.RegexpReplace("a.go", "3", "4")
-	env.AfterChange()
-	after := c.MemStats()
-
-	if diff := cmp.Diff(before, after); diff != "" {
-		t.Errorf("store objects differ after change (-before +after)\n%s", diff)
-	}
-}
-
-// setupEnv creates a new sandbox environment for editing the txtar encoded
-// content of files. It uses a new gopls instance backed by the Cache c.
-func setupEnv(t *testing.T, files string, c *cache.Cache) *Env {
-	ctx := debug.WithInstance(context.Background(), "", "off")
-	server := lsprpc.NewStreamServer(c, false, hooks.Options)
-	ts := servertest.NewPipeServer(server, jsonrpc2.NewRawStream)
-	s, err := fake.NewSandbox(&fake.SandboxConfig{
-		Files: fake.UnpackTxt(files),
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	a := NewAwaiter(s.Workdir)
-	e, err := fake.NewEditor(s, fake.EditorConfig{}).Connect(ctx, ts, a.Hooks())
-
-	return &Env{
-		T:       t,
-		Ctx:     ctx,
-		Editor:  e,
-		Sandbox: s,
-		Awaiter: a,
-	}
-}
diff -urN a/gopls/internal/regtest/misc/link_test.go b/gopls/internal/regtest/misc/link_test.go
--- a/gopls/internal/regtest/misc/link_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/link_test.go	1969-12-31 16:00:00
@@ -1,96 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestHoverAndDocumentLink(t *testing.T) {
-	const program = `
--- go.mod --
-module mod.test
-
-go 1.12
-
-require import.test v1.2.3
--- go.sum --
-import.test v1.2.3 h1:Mu4N9BICLJFxwwn8YNg6T3frkFWW1O7evXvo0HiRjBc=
-import.test v1.2.3/go.mod h1:KooCN1g237upRg7irU7F+3oADn5tVClU8YYW4I1xhMk=
--- main.go --
-package main
-
-import "import.test/pkg"
-
-func main() {
-	// Issue 43990: this is not a link that most users can open from an LSP
-	// client: mongodb://not.a.link.com
-	println(pkg.Hello)
-}`
-
-	const proxy = `
--- import.test@v1.2.3/go.mod --
-module import.test
-
-go 1.12
--- import.test@v1.2.3/pkg/const.go --
-package pkg
-
-const Hello = "Hello"
-`
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, program, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.OpenFile("go.mod")
-
-		modLink := "https://pkg.go.dev/mod/import.test@v1.2.3"
-		pkgLink := "https://pkg.go.dev/import.test@v1.2.3/pkg"
-
-		// First, check that we get the expected links via hover and documentLink.
-		content, _ := env.Hover("main.go", env.RegexpSearch("main.go", "pkg.Hello"))
-		if content == nil || !strings.Contains(content.Value, pkgLink) {
-			t.Errorf("hover: got %v in main.go, want contains %q", content, pkgLink)
-		}
-		content, _ = env.Hover("go.mod", env.RegexpSearch("go.mod", "import.test"))
-		if content == nil || !strings.Contains(content.Value, pkgLink) {
-			t.Errorf("hover: got %v in go.mod, want contains %q", content, pkgLink)
-		}
-		links := env.DocumentLink("main.go")
-		if len(links) != 1 || links[0].Target != pkgLink {
-			t.Errorf("documentLink: got links %+v for main.go, want one link with target %q", links, pkgLink)
-		}
-		links = env.DocumentLink("go.mod")
-		if len(links) != 1 || links[0].Target != modLink {
-			t.Errorf("documentLink: got links %+v for go.mod, want one link with target %q", links, modLink)
-		}
-
-		// Then change the environment to make these links private.
-		cfg := env.Editor.Config()
-		cfg.Env = map[string]string{"GOPRIVATE": "import.test"}
-		env.ChangeConfiguration(cfg)
-
-		// Finally, verify that the links are gone.
-		content, _ = env.Hover("main.go", env.RegexpSearch("main.go", "pkg.Hello"))
-		if content == nil || strings.Contains(content.Value, pkgLink) {
-			t.Errorf("hover: got %v in main.go, want non-empty hover without %q", content, pkgLink)
-		}
-		content, _ = env.Hover("go.mod", env.RegexpSearch("go.mod", "import.test"))
-		if content == nil || strings.Contains(content.Value, modLink) {
-			t.Errorf("hover: got %v in go.mod, want contains %q", content, modLink)
-		}
-		links = env.DocumentLink("main.go")
-		if len(links) != 0 {
-			t.Errorf("documentLink: got %d document links for main.go, want 0\nlinks: %v", len(links), links)
-		}
-		links = env.DocumentLink("go.mod")
-		if len(links) != 0 {
-			t.Errorf("documentLink: got %d document links for go.mod, want 0\nlinks: %v", len(links), links)
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/misc/misc_test.go b/gopls/internal/regtest/misc/misc_test.go
--- a/gopls/internal/regtest/misc/misc_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/misc_test.go	1969-12-31 16:00:00
@@ -1,18 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	regtest.Main(m, hooks.Options)
-}
diff -urN a/gopls/internal/regtest/misc/multiple_adhoc_test.go b/gopls/internal/regtest/misc/multiple_adhoc_test.go
--- a/gopls/internal/regtest/misc/multiple_adhoc_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/multiple_adhoc_test.go	1969-12-31 16:00:00
@@ -1,44 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestMultipleAdHocPackages(t *testing.T) {
-	Run(t, `
--- a/a.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("")
-}
--- a/b.go --
-package main
-
-import "fmt"
-
-func main() () {
-	fmt.Println("")
-}
-`, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		if list := env.Completion("a/a.go", env.RegexpSearch("a/a.go", "Println")); list == nil || len(list.Items) == 0 {
-			t.Fatal("expected completions, got none")
-		}
-		env.OpenFile("a/b.go")
-		if list := env.Completion("a/b.go", env.RegexpSearch("a/b.go", "Println")); list == nil || len(list.Items) == 0 {
-			t.Fatal("expected completions, got none")
-		}
-		if list := env.Completion("a/a.go", env.RegexpSearch("a/a.go", "Println")); list == nil || len(list.Items) == 0 {
-			t.Fatal("expected completions, got none")
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/misc/references_test.go b/gopls/internal/regtest/misc/references_test.go
--- a/gopls/internal/regtest/misc/references_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/references_test.go	1969-12-31 16:00:00
@@ -1,377 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"fmt"
-	"os"
-	"sort"
-	"strings"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestStdlibReferences(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Print()
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		file, pos := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `fmt.(Print)`))
-		refs, err := env.Editor.References(env.Ctx, file, pos)
-		if err != nil {
-			t.Fatal(err)
-		}
-		if len(refs) != 2 {
-			// TODO(adonovan): make this assertion less maintainer-hostile.
-			t.Fatalf("got %v reference(s), want 2", len(refs))
-		}
-		// The first reference is guaranteed to be the definition.
-		if got, want := refs[1].URI, env.Sandbox.Workdir.URI("main.go"); got != want {
-			t.Errorf("found reference in %v, wanted %v", got, want)
-		}
-	})
-}
-
-// This reproduces and tests golang/go#48400.
-func TestReferencesPanicOnError(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-type t interface {
-	error
-}
-
-type s struct{}
-
-func (*s) Error() string {
-	return ""
-}
-
-func _() {
-	var s s
-	_ = s.Error()
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		file, pos := env.GoToDefinition("main.go", env.RegexpSearch("main.go", `Error`))
-		refs, err := env.Editor.References(env.Ctx, file, pos)
-		if err == nil {
-			t.Fatalf("expected error for references, instead got %v", refs)
-		}
-		wantErr := "no position for func (error).Error() string"
-		if err.Error() != wantErr {
-			t.Fatalf("expected error with message %s, instead got %s", wantErr, err.Error())
-		}
-	})
-}
-
-func TestPackageReferences(t *testing.T) {
-	tests := []struct {
-		packageName  string
-		wantRefCount int
-		wantFiles    []string
-	}{
-		{
-			"lib1",
-			3,
-			[]string{
-				"main.go",
-				"lib1/a.go",
-				"lib1/b.go",
-			},
-		},
-		{
-			"lib2",
-			2,
-			[]string{
-				"main.go",
-				"lib2/a.go",
-			},
-		},
-	}
-
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib1/a.go --
-package lib1
-
-const A = 1
-
--- lib1/b.go --
-package lib1
-
-const B = 1
-
--- lib2/a.go --
-package lib2
-
-const C = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib1"
-	"mod.com/lib2"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		for _, test := range tests {
-			f := fmt.Sprintf("%s/a.go", test.packageName)
-			env.OpenFile(f)
-			pos := env.RegexpSearch(f, test.packageName)
-			refs := env.References(fmt.Sprintf("%s/a.go", test.packageName), pos)
-			if len(refs) != test.wantRefCount {
-				// TODO(adonovan): make this assertion less maintainer-hostile.
-				t.Fatalf("got %v reference(s), want %d", len(refs), test.wantRefCount)
-			}
-			var refURIs []string
-			for _, ref := range refs {
-				refURIs = append(refURIs, string(ref.URI))
-			}
-			for _, base := range test.wantFiles {
-				hasBase := false
-				for _, ref := range refURIs {
-					if strings.HasSuffix(ref, base) {
-						hasBase = true
-						break
-					}
-				}
-				if !hasBase {
-					t.Fatalf("got [%v], want reference ends with \"%v\"", strings.Join(refURIs, ","), base)
-				}
-			}
-		}
-	})
-}
-
-// Test for golang/go#43144.
-//
-// Verify that we search for references and implementations in intermediate
-// test variants.
-func TestReferencesInTestVariants(t *testing.T) {
-	const files = `
--- go.mod --
-module foo.mod
-
-go 1.12
--- foo/foo.go --
-package foo
-
-import "foo.mod/bar"
-
-const Foo = 42
-
-type T int
-type Interface interface{ M() }
-
-func _() {
-	_ = bar.Blah
-}
-
--- bar/bar.go --
-package bar
-
-var Blah = 123
-
--- bar/bar_test.go --
-package bar
-
-type Mer struct{}
-func (Mer) M() {}
-
-func TestBar() {
-	_ = Blah
-}
--- bar/bar_x_test.go --
-package bar_test
-
-import (
-	"foo.mod/bar"
-	"foo.mod/foo"
-)
-
-type Mer struct{}
-func (Mer) M() {}
-
-func _() {
-	_ = bar.Blah
-	_ = foo.Foo
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/foo.go")
-
-		// Helper to map locations relative file paths.
-		fileLocations := func(locs []protocol.Location) []string {
-			var got []string
-			for _, loc := range locs {
-				got = append(got, env.Sandbox.Workdir.URIToPath(loc.URI))
-			}
-			sort.Strings(got)
-			return got
-		}
-
-		refTests := []struct {
-			re       string
-			wantRefs []string
-		}{
-			// Blah is referenced:
-			// - inside the foo.mod/bar (ordinary) package
-			// - inside the foo.mod/bar [foo.mod/bar.test] test variant package
-			// - from the foo.mod/bar_test [foo.mod/bar.test] x_test package
-			// - from the foo.mod/foo package
-			{"Blah", []string{"bar/bar.go", "bar/bar_test.go", "bar/bar_x_test.go", "foo/foo.go"}},
-
-			// Foo is referenced in bar_x_test.go via the intermediate test variant
-			// foo.mod/foo [foo.mod/bar.test].
-			{"Foo", []string{"bar/bar_x_test.go", "foo/foo.go"}},
-		}
-
-		for _, test := range refTests {
-			pos := env.RegexpSearch("foo/foo.go", test.re)
-			refs := env.References("foo/foo.go", pos)
-
-			got := fileLocations(refs)
-			if diff := cmp.Diff(test.wantRefs, got); diff != "" {
-				t.Errorf("References(%q) returned unexpected diff (-want +got):\n%s", test.re, diff)
-			}
-		}
-
-		implTests := []struct {
-			re        string
-			wantImpls []string
-		}{
-			// Interface is implemented both in foo.mod/bar [foo.mod/bar.test] (which
-			// doesn't import foo), and in foo.mod/bar_test [foo.mod/bar.test], which
-			// imports the test variant of foo.
-			{"Interface", []string{"bar/bar_test.go", "bar/bar_x_test.go"}},
-		}
-
-		for _, test := range implTests {
-			pos := env.RegexpSearch("foo/foo.go", test.re)
-			refs := env.Implementations("foo/foo.go", pos)
-
-			got := fileLocations(refs)
-			if diff := cmp.Diff(test.wantImpls, got); diff != "" {
-				t.Errorf("Implementations(%q) returned unexpected diff (-want +got):\n%s", test.re, diff)
-			}
-		}
-	})
-}
-
-// This is a regression test for Issue #56169, in which interface
-// implementations in vendored modules were not found. The actual fix
-// was the same as for #55995; see TestVendoringInvalidatesMetadata.
-func TestImplementationsInVendor(t *testing.T) {
-	const proxy = `
--- other.com/b@v1.0.0/go.mod --
-module other.com/b
-go 1.14
-
--- other.com/b@v1.0.0/b.go --
-package b
-type B int
-func (B) F() {}
-`
-	const src = `
--- go.mod --
-module example.com/a
-go 1.14
-require other.com/b v1.0.0
-
--- go.sum --
-other.com/b v1.0.0 h1:9WyCKS+BLAMRQM0CegP6zqP2beP+ShTbPaARpNY31II=
-other.com/b v1.0.0/go.mod h1:TgHQFucl04oGT+vrUm/liAzukYHNxCwKNkQZEyn3m9g=
-
--- a.go --
-package a
-import "other.com/b"
-type I interface { F() }
-var _ b.B
-
-`
-	WithOptions(
-		ProxyFiles(proxy),
-		Modes(Default), // fails in 'experimental' mode
-	).Run(t, src, func(t *testing.T, env *Env) {
-		// Enable to debug go.sum mismatch, which may appear as
-		// "module lookup disabled by GOPROXY=off", confusingly.
-		if false {
-			env.DumpGoSum(".")
-		}
-
-		checkVendor := func(locs []protocol.Location, wantVendor bool) {
-			if len(locs) != 1 {
-				t.Errorf("got %d locations, want 1", len(locs))
-			} else if strings.Contains(string(locs[0].URI), "/vendor/") != wantVendor {
-				t.Errorf("got location %s, wantVendor=%t", locs[0], wantVendor)
-			}
-		}
-
-		env.OpenFile("a.go")
-		refPos := env.RegexpSearch("a.go", "I") // find "I" reference
-
-		// Initially, a.I has one implementation b.B in
-		// the module cache, not the vendor tree.
-		checkVendor(env.Implementations("a.go", refPos), false)
-
-		// Run 'go mod vendor' outside the editor.
-		if err := env.Sandbox.RunGoCommand(env.Ctx, ".", "mod", []string{"vendor"}, true); err != nil {
-			t.Fatalf("go mod vendor: %v", err)
-		}
-
-		// Synchronize changes to watched files.
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		// Now, b.B is found in the vendor tree.
-		checkVendor(env.Implementations("a.go", refPos), true)
-
-		// Delete the vendor tree.
-		if err := os.RemoveAll(env.Sandbox.Workdir.AbsPath("vendor")); err != nil {
-			t.Fatal(err)
-		}
-		// Notify the server of the deletion.
-		if err := env.Sandbox.Workdir.CheckForFileChanges(env.Ctx); err != nil {
-			t.Fatal(err)
-		}
-
-		// Synchronize again.
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		// b.B is once again defined in the module cache.
-		checkVendor(env.Implementations("a.go", refPos), false)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/rename_test.go b/gopls/internal/regtest/misc/rename_test.go
--- a/gopls/internal/regtest/misc/rename_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/rename_test.go	1969-12-31 16:00:00
@@ -1,966 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestPrepareRenameMainPackage(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-
-import (
-	"fmt"
-)
-
-func main() {
-	fmt.Println(1)
-}
-`
-	const wantErr = "can't rename package \"main\""
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		pos := env.RegexpSearch("main.go", `main`)
-		tdpp := protocol.TextDocumentPositionParams{
-			TextDocument: env.Editor.TextDocumentIdentifier("main.go"),
-			Position:     pos.ToProtocolPosition(),
-		}
-		params := &protocol.PrepareRenameParams{
-			TextDocumentPositionParams: tdpp,
-		}
-		_, err := env.Editor.Server.PrepareRename(env.Ctx, params)
-		if err == nil {
-			t.Errorf("missing can't rename package main error from PrepareRename")
-		}
-
-		if err.Error() != wantErr {
-			t.Errorf("got %v, want %v", err.Error(), wantErr)
-		}
-	})
-}
-
-// Test case for golang/go#56227
-func TestRenameWithUnsafeSlice(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17) // unsafe.Slice was added in Go 1.17
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- p.go --
-package p
-
-import "unsafe"
-
-type T struct{}
-
-func (T) M() {}
-
-func _() {
-	x := [3]int{1, 2, 3}
-	ptr := unsafe.Pointer(&x)
-	_ = unsafe.Slice((*int)(ptr), 3)
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("p.go")
-		env.Rename("p.go", env.RegexpSearch("p.go", "M"), "N") // must not panic
-	})
-}
-
-func TestPrepareRenameWithNoPackageDeclaration(t *testing.T) {
-	const files = `
-go 1.14
--- lib/a.go --
-import "fmt"
-
-const A = 1
-
-func bar() {
-	fmt.Println("Bar")
-}
-
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hello")
-}
-`
-	const wantErr = "no object found"
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "fmt")
-
-		err := env.Editor.Rename(env.Ctx, "lib/a.go", pos, "fmt1")
-		if err == nil {
-			t.Errorf("missing no object found from Rename")
-		}
-
-		if err.Error() != wantErr {
-			t.Errorf("got %v, want %v", err.Error(), wantErr)
-		}
-	})
-}
-
-func TestPrepareRenameFailWithUnknownModule(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
-go 1.14
--- lib/a.go --
-package lib
-
-const A = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	const wantErr = "can't rename package: missing module information for package"
-	Run(t, files, func(t *testing.T, env *Env) {
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		tdpp := protocol.TextDocumentPositionParams{
-			TextDocument: env.Editor.TextDocumentIdentifier("lib/a.go"),
-			Position:     pos.ToProtocolPosition(),
-		}
-		params := &protocol.PrepareRenameParams{
-			TextDocumentPositionParams: tdpp,
-		}
-		_, err := env.Editor.Server.PrepareRename(env.Ctx, params)
-		if err == nil || !strings.Contains(err.Error(), wantErr) {
-			t.Errorf("missing cannot rename packages with unknown module from PrepareRename")
-		}
-	})
-}
-
-func TestRenamePackageWithConflicts(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/nested/a.go --
-package nested
-
-const B = 1
-
--- lib/x/a.go --
-package nested1
-
-const C = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	"mod.com/lib/nested"
-	nested1 "mod.com/lib/x"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "nested")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("nested/a.go", "package nested")
-		env.RegexpSearch("main.go", `nested2 "mod.com/nested"`)
-		env.RegexpSearch("main.go", "mod.com/nested/nested")
-		env.RegexpSearch("main.go", `nested1 "mod.com/nested/x"`)
-	})
-}
-
-func TestRenamePackageWithAlias(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/nested/a.go --
-package nested
-
-const B = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	lib1 "mod.com/lib/nested"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "nested")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("nested/a.go", "package nested")
-		env.RegexpSearch("main.go", "mod.com/nested")
-		env.RegexpSearch("main.go", `lib1 "mod.com/nested/nested"`)
-	})
-}
-
-func TestRenamePackageWithDifferentDirectoryPath(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/nested/a.go --
-package foo
-
-const B = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	foo "mod.com/lib/nested"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "nested")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("nested/a.go", "package nested")
-		env.RegexpSearch("main.go", "mod.com/nested")
-		env.RegexpSearch("main.go", `foo "mod.com/nested/nested"`)
-	})
-}
-
-func TestRenamePackage(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/b.go --
-package lib
-
-const B = 1
-
--- lib/nested/a.go --
-package nested
-
-const C = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	"mod.com/lib/nested"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "lib1")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("lib1/a.go", "package lib1")
-		env.RegexpSearch("lib1/b.go", "package lib1")
-		env.RegexpSearch("main.go", "mod.com/lib1")
-		env.RegexpSearch("main.go", "mod.com/lib1/nested")
-	})
-}
-
-// Test for golang/go#47564.
-func TestRenameInTestVariant(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- stringutil/stringutil.go --
-package stringutil
-
-func Identity(s string) string {
-	return s
-}
--- stringutil/stringutil_test.go --
-package stringutil
-
-func TestIdentity(t *testing.T) {
-	if got := Identity("foo"); got != "foo" {
-		t.Errorf("bad")
-	}
-}
--- main.go --
-package main
-
-import (
-	"fmt"
-
-	"mod.com/stringutil"
-)
-
-func main() {
-	fmt.Println(stringutil.Identity("hello world"))
-}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		pos := env.RegexpSearch("main.go", `stringutil\.(Identity)`)
-		env.Rename("main.go", pos, "Identityx")
-		text := env.BufferText("stringutil/stringutil_test.go")
-		if !strings.Contains(text, "Identityx") {
-			t.Errorf("stringutil/stringutil_test.go: missing expected token `Identityx` after rename:\n%s", text)
-		}
-	})
-}
-
-// This is a test that rename operation initiated by the editor function as expected.
-func TestRenameFileFromEditor(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.16
--- a/a.go --
-package a
-
-const X = 1
--- a/x.go --
-package a
-
-const X = 2
--- b/b.go --
-package b
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		// Rename files and verify that diagnostics are affected accordingly.
-
-		// Initially, we should have diagnostics on both X's, for their duplicate declaration.
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				env.DiagnosticAtRegexp("a/a.go", "X"),
-				env.DiagnosticAtRegexp("a/x.go", "X"),
-			),
-		)
-
-		// Moving x.go should make the diagnostic go away.
-		env.RenameFile("a/x.go", "b/x.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				EmptyDiagnostics("a/a.go"),                  // no more duplicate declarations
-				env.DiagnosticAtRegexp("b/b.go", "package"), // as package names mismatch
-			),
-		)
-
-		// Renaming should also work on open buffers.
-		env.OpenFile("b/x.go")
-
-		// Moving x.go back to a/ should cause the diagnostics to reappear.
-		env.RenameFile("b/x.go", "a/x.go")
-		// TODO(rfindley): enable using a OnceMet precondition here. We can't
-		// currently do this because DidClose, DidOpen and DidChangeWatchedFiles
-		// are sent, and it is not easy to use all as a precondition.
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "X"),
-			env.DiagnosticAtRegexp("a/x.go", "X"),
-		)
-
-		// Renaming the entire directory should move both the open and closed file.
-		env.RenameFile("a", "x")
-		env.Await(
-			env.DiagnosticAtRegexp("x/a.go", "X"),
-			env.DiagnosticAtRegexp("x/x.go", "X"),
-		)
-
-		// As a sanity check, verify that x/x.go is open.
-		if text := env.BufferText("x/x.go"); text == "" {
-			t.Fatal("got empty buffer for x/x.go")
-		}
-	})
-}
-
-func TestRenamePackage_Tests(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/b.go --
-package lib
-
-const B = 1
-
--- lib/a_test.go --
-package lib_test
-
-import (
-	"mod.com/lib"
-	"fmt
-)
-
-const C = 1
-
--- lib/b_test.go --
-package lib
-
-import (
-	"fmt
-)
-
-const D = 1
-
--- lib/nested/a.go --
-package nested
-
-const D = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	"mod.com/lib/nested"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "lib1")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("lib1/a.go", "package lib1")
-		env.RegexpSearch("lib1/b.go", "package lib1")
-		env.RegexpSearch("main.go", "mod.com/lib1")
-		env.RegexpSearch("main.go", "mod.com/lib1/nested")
-
-		// Check if the test package is renamed
-		env.RegexpSearch("lib1/a_test.go", "package lib1_test")
-		env.RegexpSearch("lib1/b_test.go", "package lib1")
-	})
-}
-
-func TestRenamePackage_NestedModule(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const files = `
--- go.work --
-go 1.18
-use (
-	.
-	./foo/bar
-	./foo/baz
-)
-
--- go.mod --
-module mod.com
-
-go 1.18
-
-require (
-    mod.com/foo/bar v0.0.0
-)
-
-replace (
-	mod.com/foo/bar => ./foo/bar
-	mod.com/foo/baz => ./foo/baz
-)
--- foo/foo.go --
-package foo
-
-import "fmt"
-
-func Bar() {
-	fmt.Println("In foo before renamed to foox.")
-}
-
--- foo/bar/go.mod --
-module mod.com/foo/bar
-
--- foo/bar/bar.go --
-package bar
-
-const Msg = "Hi from package bar"
-
--- foo/baz/go.mod --
-module mod.com/foo/baz
-
--- foo/baz/baz.go --
-package baz
-
-const Msg = "Hi from package baz"
-
--- main.go --
-package main
-
-import (
-	"fmt"
-	"mod.com/foo/bar"
-	"mod.com/foo/baz"
-	"mod.com/foo"
-)
-
-func main() {
-	foo.Bar()
-	fmt.Println(bar.Msg)
-	fmt.Println(baz.Msg)
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/foo.go")
-		pos := env.RegexpSearch("foo/foo.go", "foo")
-		env.Rename("foo/foo.go", pos, "foox")
-
-		env.RegexpSearch("foox/foo.go", "package foox")
-		env.OpenFile("foox/bar/bar.go")
-		env.OpenFile("foox/bar/go.mod")
-
-		env.RegexpSearch("main.go", "mod.com/foo/bar")
-		env.RegexpSearch("main.go", "mod.com/foox")
-		env.RegexpSearch("main.go", "foox.Bar()")
-
-		env.RegexpSearch("go.mod", "./foox/bar")
-		env.RegexpSearch("go.mod", "./foox/baz")
-	})
-}
-
-func TestRenamePackage_DuplicateImport(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/nested/a.go --
-package nested
-
-const B = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	lib1 "mod.com/lib"
-	lib2 "mod.com/lib/nested"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "nested")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("nested/a.go", "package nested")
-		env.RegexpSearch("main.go", "mod.com/nested")
-		env.RegexpSearch("main.go", `lib1 "mod.com/nested"`)
-		env.RegexpSearch("main.go", `lib2 "mod.com/nested/nested"`)
-	})
-}
-
-func TestRenamePackage_DuplicateBlankImport(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-const A = 1
-
--- lib/nested/a.go --
-package nested
-
-const B = 1
-
--- main.go --
-package main
-
-import (
-	"mod.com/lib"
-	_ "mod.com/lib"
-	lib1 "mod.com/lib/nested"
-)
-
-func main() {
-	println("Hello")
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "nested")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("nested/a.go", "package nested")
-		env.RegexpSearch("main.go", "mod.com/nested")
-		env.RegexpSearch("main.go", `_ "mod.com/nested"`)
-		env.RegexpSearch("main.go", `lib1 "mod.com/nested/nested"`)
-	})
-}
-
-func TestRenamePackage_TestVariant(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo/foo.go --
-package foo
-
-const Foo = 42
--- bar/bar.go --
-package bar
-
-import "mod.com/foo"
-
-const Bar = foo.Foo
--- bar/bar_test.go --
-package bar
-
-import "mod.com/foo"
-
-const Baz = foo.Foo
--- testdata/bar/bar.go --
-package bar
-
-import "mod.com/foox"
-
-const Bar = foox.Foo
--- testdata/bar/bar_test.go --
-package bar
-
-import "mod.com/foox"
-
-const Baz = foox.Foo
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/foo.go")
-		env.Rename("foo/foo.go", env.RegexpSearch("foo/foo.go", "package (foo)"), "foox")
-
-		checkTestdata(t, env)
-	})
-}
-
-func TestRenamePackage_IntermediateTestVariant(t *testing.T) {
-	// In this test set up, we have the following import edges:
-	//   bar_test -> baz -> foo -> bar
-	//   bar_test -> foo -> bar
-	//   bar_test -> bar
-	//
-	// As a consequence, bar_x_test.go is in the reverse closure of both
-	// `foo [bar.test]` and `baz [bar.test]`. This test confirms that we don't
-	// produce duplicate edits in this case.
-	const files = `
--- go.mod --
-module foo.mod
-
-go 1.12
--- foo/foo.go --
-package foo
-
-import "foo.mod/bar"
-
-const Foo = 42
-
-const _ = bar.Bar
--- baz/baz.go --
-package baz
-
-import "foo.mod/foo"
-
-const Baz = foo.Foo
--- bar/bar.go --
-package bar
-
-var Bar = 123
--- bar/bar_test.go --
-package bar
-
-const _ = Bar
--- bar/bar_x_test.go --
-package bar_test
-
-import (
-	"foo.mod/bar"
-	"foo.mod/baz"
-	"foo.mod/foo"
-)
-
-const _ = bar.Bar + baz.Baz + foo.Foo
--- testdata/foox/foo.go --
-package foox
-
-import "foo.mod/bar"
-
-const Foo = 42
-
-const _ = bar.Bar
--- testdata/baz/baz.go --
-package baz
-
-import "foo.mod/foox"
-
-const Baz = foox.Foo
--- testdata/bar/bar_x_test.go --
-package bar_test
-
-import (
-	"foo.mod/bar"
-	"foo.mod/baz"
-	"foo.mod/foox"
-)
-
-const _ = bar.Bar + baz.Baz + foox.Foo
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/foo.go")
-		env.Rename("foo/foo.go", env.RegexpSearch("foo/foo.go", "package (foo)"), "foox")
-
-		checkTestdata(t, env)
-	})
-}
-
-func TestRenamePackage_Nesting(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-import "mod.com/lib/nested"
-
-const A = 1 + nested.B
--- lib/nested/a.go --
-package nested
-
-const B = 1
--- other/other.go --
-package other
-
-import (
-	"mod.com/lib"
-	"mod.com/lib/nested"
-)
-
-const C = lib.A + nested.B
--- testdata/libx/a.go --
-package libx
-
-import "mod.com/libx/nested"
-
-const A = 1 + nested.B
--- testdata/other/other.go --
-package other
-
-import (
-	"mod.com/libx"
-	"mod.com/libx/nested"
-)
-
-const C = libx.A + nested.B
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "package (lib)")
-		env.Rename("lib/a.go", pos, "libx")
-
-		checkTestdata(t, env)
-	})
-}
-
-func TestRenamePackage_InvalidName(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-import "mod.com/lib/nested"
-
-const A = 1 + nested.B
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/a.go")
-		pos := env.RegexpSearch("lib/a.go", "package (lib)")
-
-		for _, badName := range []string{"$$$", "lib_test"} {
-			if err := env.Editor.Rename(env.Ctx, "lib/a.go", pos, badName); err == nil {
-				t.Errorf("Rename(lib, libx) succeeded, want non-nil error")
-			}
-		}
-	})
-}
-
-func TestRenamePackage_InternalPackage(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- lib/a.go --
-package lib
-
-import (
-	"fmt"
-	"mod.com/lib/internal/x"
-)
-
-const A = 1
-
-func print() {
-	fmt.Println(x.B)
-}
-
--- lib/internal/x/a.go --
-package x
-
-const B = 1
-
--- main.go --
-package main
-
-import "mod.com/lib"
-
-func main() {
-	lib.print()
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("lib/internal/x/a.go")
-		pos := env.RegexpSearch("lib/internal/x/a.go", "x")
-		env.Rename("lib/internal/x/a.go", pos, "utils")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("lib/a.go", "mod.com/lib/internal/utils")
-		env.RegexpSearch("lib/a.go", "utils.B")
-
-		// Check if the test package is renamed
-		env.RegexpSearch("lib/internal/utils/a.go", "package utils")
-
-		env.OpenFile("lib/a.go")
-		pos = env.RegexpSearch("lib/a.go", "lib")
-		env.Rename("lib/a.go", pos, "lib1")
-
-		// Check if the new package name exists.
-		env.RegexpSearch("lib1/a.go", "package lib1")
-		env.RegexpSearch("lib1/a.go", "mod.com/lib1/internal/utils")
-		env.RegexpSearch("main.go", `import "mod.com/lib1"`)
-		env.RegexpSearch("main.go", "lib1.print()")
-	})
-}
-
-// checkTestdata checks that current buffer contents match their corresponding
-// expected content in the testdata directory.
-func checkTestdata(t *testing.T, env *Env) {
-	t.Helper()
-	files := env.ListFiles("testdata")
-	if len(files) == 0 {
-		t.Fatal("no files in testdata directory")
-	}
-	for _, file := range files {
-		suffix := strings.TrimPrefix(file, "testdata/")
-		got := env.BufferText(suffix)
-		want := env.ReadWorkspaceFile(file)
-		if diff := compare.Text(want, got); diff != "" {
-			t.Errorf("Rename: unexpected buffer content for %s (-want +got):\n%s", suffix, diff)
-		}
-	}
-}
diff -urN a/gopls/internal/regtest/misc/semantictokens_test.go b/gopls/internal/regtest/misc/semantictokens_test.go
--- a/gopls/internal/regtest/misc/semantictokens_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/semantictokens_test.go	1969-12-31 16:00:00
@@ -1,155 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"strings"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/typeparams"
-)
-
-func TestBadURICrash_VSCodeIssue1498(t *testing.T) {
-	const src = `
--- go.mod --
-module example.com
-
-go 1.12
-
--- main.go --
-package main
-
-func main() {}
-
-`
-	WithOptions(
-		Modes(Default),
-		Settings{"allExperiments": true},
-	).Run(t, src, func(t *testing.T, env *Env) {
-		params := &protocol.SemanticTokensParams{}
-		const badURI = "http://foo"
-		params.TextDocument.URI = badURI
-		// This call panicked in the past: golang/vscode-go#1498.
-		if _, err := env.Editor.Server.SemanticTokensFull(env.Ctx, params); err != nil {
-			// Requests to an invalid URI scheme shouldn't result in an error, we
-			// simply don't support this so return empty result. This could be
-			// changed, but for now assert on the current behavior.
-			t.Errorf("SemanticTokensFull(%q): %v", badURI, err)
-		}
-	})
-}
-
-// fix bug involving type parameters and regular parameters
-// (golang/vscode-go#2527)
-func TestSemantic_2527(t *testing.T) {
-	if !typeparams.Enabled {
-		t.Skip("type parameters are needed for this test")
-	}
-	// these are the expected types of identfiers in textt order
-	want := []result{
-		{"package", "keyword", ""},
-		{"foo", "namespace", ""},
-		{"func", "keyword", ""},
-		{"Add", "function", "definition deprecated"},
-		{"T", "typeParameter", "definition"},
-		{"int", "type", "defaultLibrary"},
-		{"target", "parameter", "definition"},
-		{"T", "typeParameter", ""},
-		{"l", "parameter", "definition"},
-		{"T", "typeParameter", ""},
-		{"T", "typeParameter", ""},
-		{"return", "keyword", ""},
-		{"append", "function", "defaultLibrary"},
-		{"l", "parameter", ""},
-		{"target", "parameter", ""},
-		{"for", "keyword", ""},
-		{"range", "keyword", ""},
-		{"l", "parameter", ""},
-		{"return", "keyword", ""},
-		{"nil", "variable", "readonly defaultLibrary"},
-	}
-	src := `
--- go.mod --
-module example.com
-
-go 1.19
--- main.go --
-package foo
-// Deprecated (for testing)
-func Add[T int](target T, l []T) []T {
-	return append(l, target)
-	for range l {} // test coverage
-	return nil
-}
-`
-	WithOptions(
-		Modes(Default),
-		Settings{"semanticTokens": true},
-	).Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.AfterChange(env.DiagnosticAtRegexp("main.go", "for range"))
-		p := &protocol.SemanticTokensParams{
-			TextDocument: protocol.TextDocumentIdentifier{
-				URI: env.Sandbox.Workdir.URI("main.go"),
-			},
-		}
-		v, err := env.Editor.Server.SemanticTokensFull(env.Ctx, p)
-		if err != nil {
-			t.Fatal(err)
-		}
-		seen := interpret(v.Data, env.BufferText("main.go"))
-		if x := cmp.Diff(want, seen); x != "" {
-			t.Errorf("Semantic tokens do not match (-want +got):\n%s", x)
-		}
-	})
-
-}
-
-type result struct {
-	Token     string
-	TokenType string
-	Mod       string
-}
-
-// human-readable version of the semantic tokens
-// comment, string, number are elided
-// (and in the future, maybe elide other things, like operators)
-func interpret(x []uint32, contents string) []result {
-	lines := strings.Split(contents, "\n")
-	ans := []result{}
-	line, col := 1, 1
-	for i := 0; i < len(x); i += 5 {
-		line += int(x[i])
-		col += int(x[i+1])
-		if x[i] != 0 { // new line
-			col = int(x[i+1]) + 1 // 1-based column numbers
-		}
-		sz := x[i+2]
-		t := semanticTypes[x[i+3]]
-		if t == "comment" || t == "string" || t == "number" {
-			continue
-		}
-		l := x[i+4]
-		var mods []string
-		for i, mod := range semanticModifiers {
-			if l&(1<<i) != 0 {
-				mods = append(mods, mod)
-			}
-		}
-		// col is a utf-8 offset
-		tok := lines[line-1][col-1 : col-1+int(sz)]
-		ans = append(ans, result{tok, t, strings.Join(mods, " ")})
-	}
-	return ans
-}
-
-var (
-	semanticTypes     = lsp.SemanticTypes()
-	semanticModifiers = lsp.SemanticModifiers()
-)
diff -urN a/gopls/internal/regtest/misc/settings_test.go b/gopls/internal/regtest/misc/settings_test.go
--- a/gopls/internal/regtest/misc/settings_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/settings_test.go	1969-12-31 16:00:00
@@ -1,32 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestEmptyDirectoryFilters_Issue51843(t *testing.T) {
-	const src = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func main() {
-}
-`
-
-	WithOptions(
-		Settings{"directoryFilters": []string{""}},
-	).Run(t, src, func(t *testing.T, env *Env) {
-		// No need to do anything. Issue golang/go#51843 is triggered by the empty
-		// directory filter above.
-	})
-}
diff -urN a/gopls/internal/regtest/misc/shared_test.go b/gopls/internal/regtest/misc/shared_test.go
--- a/gopls/internal/regtest/misc/shared_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/shared_test.go	1969-12-31 16:00:00
@@ -1,74 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// Smoke test that simultaneous editing sessions in the same workspace works.
-func TestSimultaneousEdits(t *testing.T) {
-	const sharedProgram = `
--- go.mod --
-module mod
-
-go 1.12
--- main.go --
-package main
-
-import "fmt"
-
-func main() {
-	fmt.Println("Hello World.")
-}`
-
-	WithOptions(
-		Modes(DefaultModes()&(Forwarded|SeparateProcess)),
-	).Run(t, sharedProgram, func(t *testing.T, env1 *Env) {
-		// Create a second test session connected to the same workspace and server
-		// as the first.
-		awaiter := NewAwaiter(env1.Sandbox.Workdir)
-		editor, err := fake.NewEditor(env1.Sandbox, env1.Editor.Config()).Connect(env1.Ctx, env1.Server, awaiter.Hooks())
-		if err != nil {
-			t.Fatal(err)
-		}
-		env2 := &Env{
-			T:       t,
-			Ctx:     env1.Ctx,
-			Sandbox: env1.Sandbox,
-			Server:  env1.Server,
-			Editor:  editor,
-			Awaiter: awaiter,
-		}
-		env2.Await(InitialWorkspaceLoad)
-		// In editor #1, break fmt.Println as before.
-		env1.OpenFile("main.go")
-		env1.RegexpReplace("main.go", "Printl(n)", "")
-		// In editor #2 remove the closing brace.
-		env2.OpenFile("main.go")
-		env2.RegexpReplace("main.go", "\\)\n(})", "")
-
-		// Now check that we got different diagnostics in each environment.
-		env1.Await(env1.DiagnosticAtRegexp("main.go", "Printl"))
-		env2.Await(env2.DiagnosticAtRegexp("main.go", "$"))
-
-		// Now close editor #2, and verify that operation in editor #1 is
-		// unaffected.
-		if err := env2.Editor.Close(env2.Ctx); err != nil {
-			t.Errorf("closing second editor: %v", err)
-		}
-
-		env1.RegexpReplace("main.go", "Printl", "Println")
-		env1.Await(
-			OnceMet(
-				env1.DoneWithChange(),
-				EmptyDiagnostics("main.go"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/staticcheck_test.go b/gopls/internal/regtest/misc/staticcheck_test.go
--- a/gopls/internal/regtest/misc/staticcheck_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/staticcheck_test.go	1969-12-31 16:00:00
@@ -1,113 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	"golang.org/x/tools/internal/testenv"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestStaticcheckGenerics(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // generics were introduced in Go 1.18
-
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- a/a.go --
-package a
-
-import (
-	"errors"
-	"sort"
-	"strings"
-)
-
-func Zero[P any]() P {
-	var p P
-	return p
-}
-
-type Inst[P any] struct {
-	Field P
-}
-
-func testGenerics[P *T, T any](p P) {
-	// Calls to instantiated functions should not break checks.
-	slice := Zero[string]()
-	sort.Slice(slice, func(i, j int) bool {
-		return slice[i] < slice[j]
-	})
-
-	// Usage of instantiated fields should not break checks.
-	g := Inst[string]{"hello"}
-	g.Field = strings.TrimLeft(g.Field, "12234")
-
-	// Use of type parameters should not break checks.
-	var q P
-	p = q // SA4009: p is overwritten before its first use
-	q = &*p // SA4001: &* will be simplified
-}
-
-
-// FooErr should be called ErrFoo (ST1012)
-var FooErr error = errors.New("foo")
-`
-
-	WithOptions(
-		Settings{"staticcheck": true},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.Await(
-			env.DiagnosticAtRegexpFromSource("a/a.go", "sort.Slice", "sortslice"),
-			env.DiagnosticAtRegexpFromSource("a/a.go", "sort.Slice.(slice)", "SA1028"),
-			env.DiagnosticAtRegexpFromSource("a/a.go", "var (FooErr)", "ST1012"),
-			env.DiagnosticAtRegexpFromSource("a/a.go", `"12234"`, "SA1024"),
-			env.DiagnosticAtRegexpFromSource("a/a.go", "testGenerics.*(p P)", "SA4009"),
-			env.DiagnosticAtRegexpFromSource("a/a.go", "q = (&\\*p)", "SA4001"),
-		)
-	})
-}
-
-// Test for golang/go#56270: an analysis with related info should not panic if
-// analysis.RelatedInformation.End is not set.
-func TestStaticcheckRelatedInfo(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17) // staticcheck is only supported at Go 1.17+
-	const files = `
--- go.mod --
-module mod.test
-
-go 1.18
--- p.go --
-package p
-
-import (
-	"fmt"
-)
-
-func Foo(enabled interface{}) {
-	if enabled, ok := enabled.(bool); ok {
-	} else {
-		_ = fmt.Sprintf("invalid type %T", enabled) // enabled is always bool here
-	}
-}
-`
-
-	WithOptions(
-		Settings{"staticcheck": true},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("p.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexpFromSource("p.go", ", (enabled)", "SA9008"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/vendor_test.go b/gopls/internal/regtest/misc/vendor_test.go
--- a/gopls/internal/regtest/misc/vendor_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/vendor_test.go	1969-12-31 16:00:00
@@ -1,66 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-const basicProxy = `
--- golang.org/x/hello@v1.2.3/go.mod --
-module golang.org/x/hello
-
-go 1.14
--- golang.org/x/hello@v1.2.3/hi/hi.go --
-package hi
-
-var Goodbye error
-`
-
-func TestInconsistentVendoring(t *testing.T) {
-	const pkgThatUsesVendoring = `
--- go.mod --
-module mod.com
-
-go 1.14
-
-require golang.org/x/hello v1.2.3
--- go.sum --
-golang.org/x/hello v1.2.3 h1:EcMp5gSkIhaTkPXp8/3+VH+IFqTpk3ZbpOhqk0Ncmho=
-golang.org/x/hello v1.2.3/go.mod h1:WW7ER2MRNXWA6c8/4bDIek4Hc/+DofTrMaQQitGXcco=
--- vendor/modules.txt --
--- a/a1.go --
-package a
-
-import "golang.org/x/hello/hi"
-
-func _() {
-	_ = hi.Goodbye
-	var q int // hardcode a diagnostic
-}
-`
-	WithOptions(
-		Modes(Default),
-		ProxyFiles(basicProxy),
-	).Run(t, pkgThatUsesVendoring, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a1.go")
-		d := &protocol.PublishDiagnosticsParams{}
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexpWithMessage("go.mod", "module mod.com", "Inconsistent vendoring"),
-				ReadDiagnostics("go.mod", d),
-			),
-		)
-		env.ApplyQuickFixes("go.mod", d.Diagnostics)
-
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("a/a1.go", `q int`, "not used"),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/misc/vuln_test.go b/gopls/internal/regtest/misc/vuln_test.go
--- a/gopls/internal/regtest/misc/vuln_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/vuln_test.go	1969-12-31 16:00:00
@@ -1,982 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package misc
-
-import (
-	"context"
-	"encoding/json"
-	"path/filepath"
-	"sort"
-	"strings"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/command"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/gopls/internal/vulncheck"
-	"golang.org/x/tools/gopls/internal/vulncheck/vulntest"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestRunGovulncheckError(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo.go --
-package foo
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		cmd, err := command.NewRunGovulncheckCommand("Run Vulncheck Exp", command.VulncheckArgs{
-			URI: "/invalid/file/url", // invalid arg
-		})
-		if err != nil {
-			t.Fatal(err)
-		}
-
-		params := &protocol.ExecuteCommandParams{
-			Command:   command.RunGovulncheck.ID(),
-			Arguments: cmd.Arguments,
-		}
-
-		response, err := env.Editor.ExecuteCommand(env.Ctx, params)
-		// We want an error!
-		if err == nil {
-			t.Errorf("got success, want invalid file URL error: %v", response)
-		}
-	})
-}
-
-func TestRunGovulncheckError2(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- foo.go --
-package foo
-
-func F() { // build error incomplete
-`
-	WithOptions(
-		EnvVars{
-			"_GOPLS_TEST_BINARY_RUN_AS_GOPLS": "true", // needed to run `gopls vulncheck`.
-		},
-		Settings{
-			"codelenses": map[string]bool{
-				"run_govulncheck": true,
-			},
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		var result command.RunVulncheckResult
-		env.ExecuteCodeLensCommand("go.mod", command.RunGovulncheck, &result)
-		var ws WorkStatus
-		env.Await(
-			CompletedProgress(result.Token, &ws),
-		)
-		wantEndMsg, wantMsgPart := "failed", "failed to load packages due to errors"
-		if ws.EndMsg != "failed" || !strings.Contains(ws.Msg, wantMsgPart) {
-			t.Errorf("work status = %+v, want {EndMessage: %q, Message: %q}", ws, wantEndMsg, wantMsgPart)
-		}
-	})
-}
-
-const vulnsData = `
--- GO-2022-01.yaml --
-modules:
-  - module: golang.org/amod
-    versions:
-      - introduced: 1.0.0
-      - fixed: 1.0.4
-      - introduced: 1.1.2
-    packages:
-      - package: golang.org/amod/avuln
-        symbols:
-          - VulnData.Vuln1
-          - VulnData.Vuln2
-description: >
-    vuln in amod
-references:
-  - href: pkg.go.dev/vuln/GO-2022-01
--- GO-2022-03.yaml --
-modules:
-  - module: golang.org/amod
-    versions:
-      - introduced: 1.0.0
-      - fixed: 1.0.6
-    packages:
-      - package: golang.org/amod/avuln
-        symbols:
-          - nonExisting
-description: >
-  unaffecting vulnerability  
--- GO-2022-02.yaml --
-modules:
-  - module: golang.org/bmod
-    packages:
-      - package: golang.org/bmod/bvuln
-        symbols:
-          - Vuln
-description: |
-    vuln in bmod
-    
-    This is a long description
-    of this vulnerability.
-references:
-  - href: pkg.go.dev/vuln/GO-2022-03
--- GO-2022-04.yaml --
-modules:
-  - module: golang.org/bmod
-    packages:
-      - package: golang.org/bmod/unused
-        symbols:
-          - Vuln
-description: |
-    vuln in bmod/somtrhingelse
-references:
-  - href: pkg.go.dev/vuln/GO-2022-04
--- GOSTDLIB.yaml --
-modules:
-  - module: stdlib
-    versions:
-      - introduced: 1.18.0
-    packages:
-      - package: archive/zip
-        symbols:
-          - OpenReader
-references:
-  - href: pkg.go.dev/vuln/GOSTDLIB
-`
-
-func TestRunGovulncheckStd(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-
-import (
-        "archive/zip"
-        "fmt"
-)
-
-func main() {
-        _, err := zip.OpenReader("file.zip")  // vulnerability id: GOSTDLIB
-        fmt.Println(err)
-}
-`
-
-	db, err := vulntest.NewDatabase(context.Background(), []byte(vulnsData))
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer db.Clean()
-	WithOptions(
-		EnvVars{
-			// Let the analyzer read vulnerabilities data from the testdata/vulndb.
-			"GOVULNDB": db.URI(),
-			// When fetchinging stdlib package vulnerability info,
-			// behave as if our go version is go1.18 for this testing.
-			// The default behavior is to run `go env GOVERSION` (which isn't mutable env var).
-			vulncheck.GoVersionForVulnTest:    "go1.18",
-			"_GOPLS_TEST_BINARY_RUN_AS_GOPLS": "true", // needed to run `gopls vulncheck`.
-		},
-		Settings{
-			"codelenses": map[string]bool{
-				"run_govulncheck": true,
-			},
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-
-		// Test CodeLens is present.
-		lenses := env.CodeLens("go.mod")
-
-		const wantCommand = "gopls." + string(command.RunGovulncheck)
-		var gotCodelens = false
-		var lens protocol.CodeLens
-		for _, l := range lenses {
-			if l.Command.Command == wantCommand {
-				gotCodelens = true
-				lens = l
-				break
-			}
-		}
-		if !gotCodelens {
-			t.Fatal("got no vulncheck codelens")
-		}
-		// Run Command included in the codelens.
-		var result command.RunVulncheckResult
-		env.ExecuteCommand(&protocol.ExecuteCommandParams{
-			Command:   lens.Command.Command,
-			Arguments: lens.Command.Arguments,
-		}, &result)
-
-		env.Await(
-			OnceMet(
-				CompletedProgress(result.Token, nil),
-				ShownMessage("Found GOSTDLIB"),
-				EmptyOrNoDiagnostics("go.mod"),
-			),
-		)
-		testFetchVulncheckResult(t, env, map[string]fetchVulncheckResult{
-			"go.mod": {IDs: []string{"GOSTDLIB"}, Mode: govulncheck.ModeGovulncheck}})
-	})
-}
-
-func TestFetchVulncheckResultStd(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.18
--- main.go --
-package main
-
-import (
-        "archive/zip"
-        "fmt"
-)
-
-func main() {
-        _, err := zip.OpenReader("file.zip")  // vulnerability id: GOSTDLIB
-        fmt.Println(err)
-}
-`
-
-	db, err := vulntest.NewDatabase(context.Background(), []byte(vulnsData))
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer db.Clean()
-	WithOptions(
-		EnvVars{
-			// Let the analyzer read vulnerabilities data from the testdata/vulndb.
-			"GOVULNDB": db.URI(),
-			// When fetchinging stdlib package vulnerability info,
-			// behave as if our go version is go1.18 for this testing.
-			vulncheck.GoVersionForVulnTest:    "go1.18",
-			"_GOPLS_TEST_BINARY_RUN_AS_GOPLS": "true", // needed to run `gopls vulncheck`.
-		},
-		Settings{"ui.diagnostic.vulncheck": "Imports"},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.AfterChange(
-			EmptyOrNoDiagnostics("go.mod"),
-			// we don't publish diagnostics for standard library vulnerability yet.
-		)
-		testFetchVulncheckResult(t, env, map[string]fetchVulncheckResult{
-			"go.mod": {
-				IDs:  []string{"GOSTDLIB"},
-				Mode: govulncheck.ModeImports,
-			},
-		})
-	})
-}
-
-type fetchVulncheckResult struct {
-	IDs  []string
-	Mode govulncheck.AnalysisMode
-}
-
-func testFetchVulncheckResult(t *testing.T, env *Env, want map[string]fetchVulncheckResult) {
-	t.Helper()
-
-	var result map[protocol.DocumentURI]*govulncheck.Result
-	fetchCmd, err := command.NewFetchVulncheckResultCommand("fetch", command.URIArg{
-		URI: env.Sandbox.Workdir.URI("go.mod"),
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	env.ExecuteCommand(&protocol.ExecuteCommandParams{
-		Command:   fetchCmd.Command,
-		Arguments: fetchCmd.Arguments,
-	}, &result)
-
-	for _, v := range want {
-		sort.Strings(v.IDs)
-	}
-	got := map[string]fetchVulncheckResult{}
-	for k, r := range result {
-		var osv []string
-		for _, v := range r.Vulns {
-			osv = append(osv, v.OSV.ID)
-		}
-		sort.Strings(osv)
-		modfile := env.Sandbox.Workdir.RelPath(k.SpanURI().Filename())
-		got[modfile] = fetchVulncheckResult{
-			IDs:  osv,
-			Mode: r.Mode,
-		}
-	}
-	if diff := cmp.Diff(want, got); diff != "" {
-		t.Errorf("fetch vulnchheck result = got %v, want %v: diff %v", got, want, diff)
-	}
-}
-
-const workspace1 = `
--- go.mod --
-module golang.org/entry
-
-go 1.18
-
-require golang.org/cmod v1.1.3
-
-require (
-	golang.org/amod v1.0.0 // indirect
-	golang.org/bmod v0.5.0 // indirect
-)
--- go.sum --
-golang.org/amod v1.0.0 h1:EUQOI2m5NhQZijXZf8WimSnnWubaFNrrKUH/PopTN8k=
-golang.org/amod v1.0.0/go.mod h1:yvny5/2OtYFomKt8ax+WJGvN6pfN1pqjGnn7DQLUi6E=
-golang.org/bmod v0.5.0 h1:KgvUulMyMiYRB7suKA0x+DfWRVdeyPgVJvcishTH+ng=
-golang.org/bmod v0.5.0/go.mod h1:f6o+OhF66nz/0BBc/sbCsshyPRKMSxZIlG50B/bsM4c=
-golang.org/cmod v1.1.3 h1:PJ7rZFTk7xGAunBRDa0wDe7rZjZ9R/vr1S2QkVVCngQ=
-golang.org/cmod v1.1.3/go.mod h1:eCR8dnmvLYQomdeAZRCPgS5JJihXtqOQrpEkNj5feQA=
--- x/x.go --
-package x
-
-import 	(
-   "golang.org/cmod/c"
-   "golang.org/entry/y"
-)
-
-func X() {
-	c.C1().Vuln1() // vuln use: X -> Vuln1
-}
-
-func CallY() {
-	y.Y()  // vuln use: CallY -> y.Y -> bvuln.Vuln 
-}
-
--- y/y.go --
-package y
-
-import "golang.org/cmod/c"
-
-func Y() {
-	c.C2()() // vuln use: Y -> bvuln.Vuln
-}
-`
-
-// cmod/c imports amod/avuln and bmod/bvuln.
-const proxy1 = `
--- golang.org/cmod@v1.1.3/go.mod --
-module golang.org/cmod
-
-go 1.12
--- golang.org/cmod@v1.1.3/c/c.go --
-package c
-
-import (
-	"golang.org/amod/avuln"
-	"golang.org/bmod/bvuln"
-)
-
-type I interface {
-	Vuln1()
-}
-
-func C1() I {
-	v := avuln.VulnData{}
-	v.Vuln2() // vuln use
-	return v
-}
-
-func C2() func() {
-	return bvuln.Vuln
-}
--- golang.org/amod@v1.0.0/go.mod --
-module golang.org/amod
-
-go 1.14
--- golang.org/amod@v1.0.0/avuln/avuln.go --
-package avuln
-
-type VulnData struct {}
-func (v VulnData) Vuln1() {}
-func (v VulnData) Vuln2() {}
--- golang.org/amod@v1.0.4/go.mod --
-module golang.org/amod
-
-go 1.14
--- golang.org/amod@v1.0.4/avuln/avuln.go --
-package avuln
-
-type VulnData struct {}
-func (v VulnData) Vuln1() {}
-func (v VulnData) Vuln2() {}
-
--- golang.org/bmod@v0.5.0/go.mod --
-module golang.org/bmod
-
-go 1.14
--- golang.org/bmod@v0.5.0/bvuln/bvuln.go --
-package bvuln
-
-func Vuln() {
-	// something evil
-}
--- golang.org/bmod@v0.5.0/unused/unused.go --
-package unused
-
-func Vuln() {
-	// something evil
-}
--- golang.org/amod@v1.0.6/go.mod --
-module golang.org/amod
-
-go 1.14
--- golang.org/amod@v1.0.6/avuln/avuln.go --
-package avuln
-
-type VulnData struct {}
-func (v VulnData) Vuln1() {}
-func (v VulnData) Vuln2() {}
-`
-
-func vulnTestEnv(vulnsDB, proxyData string) (*vulntest.DB, []RunOption, error) {
-	db, err := vulntest.NewDatabase(context.Background(), []byte(vulnsData))
-	if err != nil {
-		return nil, nil, nil
-	}
-	settings := Settings{
-		"codelenses": map[string]bool{
-			"run_govulncheck": true,
-		},
-	}
-	ev := EnvVars{
-		// Let the analyzer read vulnerabilities data from the testdata/vulndb.
-		"GOVULNDB": db.URI(),
-		// When fetching stdlib package vulnerability info,
-		// behave as if our go version is go1.18 for this testing.
-		// The default behavior is to run `go env GOVERSION` (which isn't mutable env var).
-		vulncheck.GoVersionForVulnTest:    "go1.18",
-		"_GOPLS_TEST_BINARY_RUN_AS_GOPLS": "true", // needed to run `gopls vulncheck`.
-		"GOSUMDB":                         "off",
-	}
-	return db, []RunOption{ProxyFiles(proxyData), ev, settings}, nil
-}
-
-func TestRunVulncheckPackageDiagnostics(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-
-	db, opts0, err := vulnTestEnv(vulnsData, proxy1)
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer db.Clean()
-
-	checkVulncheckDiagnostics := func(env *Env, t *testing.T) {
-		env.OpenFile("go.mod")
-
-		gotDiagnostics := &protocol.PublishDiagnosticsParams{}
-		env.AfterChange(
-			env.DiagnosticAtRegexp("go.mod", `golang.org/amod`),
-			ReadDiagnostics("go.mod", gotDiagnostics),
-		)
-
-		testFetchVulncheckResult(t, env, map[string]fetchVulncheckResult{
-			"go.mod": {
-				IDs:  []string{"GO-2022-01", "GO-2022-02", "GO-2022-03"},
-				Mode: govulncheck.ModeImports,
-			},
-		})
-
-		wantVulncheckDiagnostics := map[string]vulnDiagExpectation{
-			"golang.org/amod": {
-				diagnostics: []vulnDiag{
-					{
-						msg:      "golang.org/amod has known vulnerabilities GO-2022-01, GO-2022-03.",
-						severity: protocol.SeverityInformation,
-						codeActions: []string{
-							"Upgrade to latest",
-							"Upgrade to v1.0.6",
-							"Run govulncheck to verify",
-						},
-					},
-				},
-				codeActions: []string{
-					"Upgrade to latest",
-					"Upgrade to v1.0.6",
-					"Run govulncheck to verify",
-				},
-				hover: []string{"GO-2022-01", "Fixed in v1.0.4.", "GO-2022-03"},
-			},
-			"golang.org/bmod": {
-				diagnostics: []vulnDiag{
-					{
-						msg:      "golang.org/bmod has a vulnerability GO-2022-02.",
-						severity: protocol.SeverityInformation,
-						codeActions: []string{
-							"Run govulncheck to verify",
-						},
-					},
-				},
-				codeActions: []string{
-					"Run govulncheck to verify",
-				},
-				hover: []string{"GO-2022-02", "This is a long description of this vulnerability.", "No fix is available."},
-			},
-		}
-
-		for pattern, want := range wantVulncheckDiagnostics {
-			modPathDiagnostics := testVulnDiagnostics(t, env, pattern, want, gotDiagnostics)
-
-			gotActions := env.CodeAction("go.mod", modPathDiagnostics)
-			if diff := diffCodeActions(gotActions, want.codeActions); diff != "" {
-				t.Errorf("code actions for %q do not match, got %v, want %v\n%v\n", pattern, gotActions, want.codeActions, diff)
-				continue
-			}
-		}
-	}
-
-	wantNoVulncheckDiagnostics := func(env *Env, t *testing.T) {
-		env.OpenFile("go.mod")
-
-		gotDiagnostics := &protocol.PublishDiagnosticsParams{}
-		env.AfterChange(
-			ReadDiagnostics("go.mod", gotDiagnostics),
-		)
-
-		if len(gotDiagnostics.Diagnostics) > 0 {
-			t.Errorf("Unexpected diagnostics: %v", stringify(gotDiagnostics))
-		}
-		testFetchVulncheckResult(t, env, map[string]fetchVulncheckResult{})
-	}
-
-	for _, tc := range []struct {
-		name            string
-		setting         Settings
-		wantDiagnostics bool
-	}{
-		{"imports", Settings{"ui.diagnostic.vulncheck": "Imports"}, true},
-		{"default", Settings{}, false},
-		{"invalid", Settings{"ui.diagnostic.vulncheck": "invalid"}, false},
-	} {
-		t.Run(tc.name, func(t *testing.T) {
-			// override the settings options to enable diagnostics
-			opts := append(opts0, tc.setting)
-			WithOptions(opts...).Run(t, workspace1, func(t *testing.T, env *Env) {
-				// TODO(hyangah): implement it, so we see GO-2022-01, GO-2022-02, and GO-2022-03.
-				// Check that the actions we get when including all diagnostics at a location return the same result
-				if tc.wantDiagnostics {
-					checkVulncheckDiagnostics(env, t)
-				} else {
-					wantNoVulncheckDiagnostics(env, t)
-				}
-
-				if tc.name == "imports" && tc.wantDiagnostics {
-					// test we get only govulncheck-based diagnostics after "run govulncheck".
-					var result command.RunVulncheckResult
-					env.ExecuteCodeLensCommand("go.mod", command.RunGovulncheck, &result)
-					gotDiagnostics := &protocol.PublishDiagnosticsParams{}
-					env.Await(
-						OnceMet(
-							CompletedProgress(result.Token, nil),
-							ShownMessage("Found"),
-						),
-					)
-					env.Await(
-						OnceMet(
-							env.DiagnosticAtRegexp("go.mod", "golang.org/bmod"),
-							ReadDiagnostics("go.mod", gotDiagnostics),
-						),
-					)
-					// We expect only one diagnostic for GO-2022-02.
-					count := 0
-					for _, diag := range gotDiagnostics.Diagnostics {
-						if strings.Contains(diag.Message, "GO-2022-02") {
-							count++
-							if got, want := diag.Severity, protocol.SeverityWarning; got != want {
-								t.Errorf("Diagnostic for GO-2022-02 = %v, want %v", got, want)
-							}
-						}
-					}
-					if count != 1 {
-						t.Errorf("Unexpected number of diagnostics about GO-2022-02 = %v, want 1:\n%+v", count, stringify(gotDiagnostics))
-					}
-				}
-			})
-		})
-	}
-}
-
-func stringify(a interface{}) string {
-	data, _ := json.Marshal(a)
-	return string(data)
-}
-
-func TestRunVulncheckWarning(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-
-	db, opts, err := vulnTestEnv(vulnsData, proxy1)
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer db.Clean()
-	WithOptions(opts...).Run(t, workspace1, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-
-		var result command.RunVulncheckResult
-		env.ExecuteCodeLensCommand("go.mod", command.RunGovulncheck, &result)
-		gotDiagnostics := &protocol.PublishDiagnosticsParams{}
-		env.Await(
-			OnceMet(
-				CompletedProgress(result.Token, nil),
-				ShownMessage("Found"),
-			),
-		)
-		// Vulncheck diagnostics asynchronous to the vulncheck command.
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("go.mod", `golang.org/amod`),
-				ReadDiagnostics("go.mod", gotDiagnostics),
-			),
-		)
-
-		testFetchVulncheckResult(t, env, map[string]fetchVulncheckResult{
-			"go.mod": {IDs: []string{"GO-2022-01", "GO-2022-02", "GO-2022-03"}, Mode: govulncheck.ModeGovulncheck},
-		})
-		env.OpenFile("x/x.go")
-		lineX := env.RegexpSearch("x/x.go", `c\.C1\(\)\.Vuln1\(\)`)
-		env.OpenFile("y/y.go")
-		lineY := env.RegexpSearch("y/y.go", `c\.C2\(\)\(\)`)
-		wantDiagnostics := map[string]vulnDiagExpectation{
-			"golang.org/amod": {
-				applyAction: "Upgrade to v1.0.6",
-				diagnostics: []vulnDiag{
-					{
-						msg:      "golang.org/amod has a vulnerability used in the code: GO-2022-01.",
-						severity: protocol.SeverityWarning,
-						codeActions: []string{
-							"Upgrade to latest",
-							"Upgrade to v1.0.4",
-							"Reset govulncheck result",
-						},
-						relatedInfo: []vulnRelatedInfo{
-							{"x.go", uint32(lineX.Line), "[GO-2022-01]"}, // avuln.VulnData.Vuln1
-							{"x.go", uint32(lineX.Line), "[GO-2022-01]"}, // avuln.VulnData.Vuln2
-						},
-					},
-					{
-						msg:      "golang.org/amod has a vulnerability GO-2022-03 that is not used in the code.",
-						severity: protocol.SeverityInformation,
-						codeActions: []string{
-							"Upgrade to latest",
-							"Upgrade to v1.0.6",
-							"Reset govulncheck result",
-						},
-						relatedInfo: []vulnRelatedInfo{
-							{"x.go", uint32(lineX.Line), "[GO-2022-01]"}, // avuln.VulnData.Vuln1
-							{"x.go", uint32(lineX.Line), "[GO-2022-01]"}, // avuln.VulnData.Vuln2
-						},
-					},
-				},
-				codeActions: []string{
-					"Upgrade to latest",
-					"Upgrade to v1.0.6",
-					"Reset govulncheck result",
-				},
-				hover: []string{"GO-2022-01", "Fixed in v1.0.4.", "GO-2022-03"},
-			},
-			"golang.org/bmod": {
-				diagnostics: []vulnDiag{
-					{
-						msg:      "golang.org/bmod has a vulnerability used in the code: GO-2022-02.",
-						severity: protocol.SeverityWarning,
-						codeActions: []string{
-							"Reset govulncheck result", // no fix, but we should give an option to reset.
-						},
-						relatedInfo: []vulnRelatedInfo{
-							{"y.go", uint32(lineY.Line), "[GO-2022-02]"}, // bvuln.Vuln
-						},
-					},
-				},
-				codeActions: []string{
-					"Reset govulncheck result", // no fix, but we should give an option to reset.
-				},
-				hover: []string{"GO-2022-02", "This is a long description of this vulnerability.", "No fix is available."},
-			},
-		}
-
-		for mod, want := range wantDiagnostics {
-			modPathDiagnostics := testVulnDiagnostics(t, env, mod, want, gotDiagnostics)
-
-			// Check that the actions we get when including all diagnostics at a location return the same result
-			gotActions := env.CodeAction("go.mod", modPathDiagnostics)
-			if diff := diffCodeActions(gotActions, want.codeActions); diff != "" {
-				t.Errorf("code actions for %q do not match, expected %v, got %v\n%v\n", mod, want.codeActions, gotActions, diff)
-				continue
-			}
-
-			// Apply the code action matching applyAction.
-			if want.applyAction == "" {
-				continue
-			}
-			for _, action := range gotActions {
-				if action.Title == want.applyAction {
-					env.ApplyCodeAction(action)
-					break
-				}
-			}
-		}
-
-		env.Await(env.DoneWithChangeWatchedFiles())
-		wantGoMod := `module golang.org/entry
-
-go 1.18
-
-require golang.org/cmod v1.1.3
-
-require (
-	golang.org/amod v1.0.6 // indirect
-	golang.org/bmod v0.5.0 // indirect
-)
-`
-		if got := env.BufferText("go.mod"); got != wantGoMod {
-			t.Fatalf("go.mod vulncheck fix failed:\n%s", compare.Text(wantGoMod, got))
-		}
-	})
-}
-
-func diffCodeActions(gotActions []protocol.CodeAction, want []string) string {
-	var gotTitles []string
-	for _, ca := range gotActions {
-		gotTitles = append(gotTitles, ca.Title)
-	}
-	return cmp.Diff(want, gotTitles)
-}
-
-const workspace2 = `
--- go.mod --
-module golang.org/entry
-
-go 1.18
-
-require golang.org/bmod v0.5.0
-
--- go.sum --
-golang.org/bmod v0.5.0 h1:MT/ysNRGbCiURc5qThRFWaZ5+rK3pQRPo9w7dYZfMDk=
-golang.org/bmod v0.5.0/go.mod h1:k+zl+Ucu4yLIjndMIuWzD/MnOHy06wqr3rD++y0abVs=
--- x/x.go --
-package x
-
-import "golang.org/bmod/bvuln"
-
-func F() {
-	// Calls a benign func in bvuln.
-	bvuln.OK()
-}
-`
-
-const proxy2 = `
--- golang.org/bmod@v0.5.0/bvuln/bvuln.go --
-package bvuln
-
-func Vuln() {} // vulnerable.
-func OK() {} // ok.
-`
-
-func TestGovulncheckInfo(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-
-	db, opts, err := vulnTestEnv(vulnsData, proxy2)
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer db.Clean()
-	WithOptions(opts...).Run(t, workspace2, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		var result command.RunVulncheckResult
-		env.ExecuteCodeLensCommand("go.mod", command.RunGovulncheck, &result)
-		gotDiagnostics := &protocol.PublishDiagnosticsParams{}
-		env.Await(
-			OnceMet(
-				CompletedProgress(result.Token, nil),
-				ShownMessage("No vulnerabilities found"), // only count affecting vulnerabilities.
-			),
-		)
-
-		// Vulncheck diagnostics asynchronous to the vulncheck command.
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("go.mod", "golang.org/bmod"),
-				ReadDiagnostics("go.mod", gotDiagnostics),
-			),
-		)
-
-		testFetchVulncheckResult(t, env, map[string]fetchVulncheckResult{"go.mod": {IDs: []string{"GO-2022-02"}, Mode: govulncheck.ModeGovulncheck}})
-		// wantDiagnostics maps a module path in the require
-		// section of a go.mod to diagnostics that will be returned
-		// when running vulncheck.
-		wantDiagnostics := map[string]vulnDiagExpectation{
-			"golang.org/bmod": {
-				diagnostics: []vulnDiag{
-					{
-						msg:      "golang.org/bmod has a vulnerability GO-2022-02 that is not used in the code.",
-						severity: protocol.SeverityInformation,
-						codeActions: []string{
-							"Reset govulncheck result",
-						},
-					},
-				},
-				codeActions: []string{
-					"Reset govulncheck result",
-				},
-				hover: []string{"GO-2022-02", "This is a long description of this vulnerability.", "No fix is available."},
-			},
-		}
-
-		var allActions []protocol.CodeAction
-		for mod, want := range wantDiagnostics {
-			modPathDiagnostics := testVulnDiagnostics(t, env, mod, want, gotDiagnostics)
-			// Check that the actions we get when including all diagnostics at a location return the same result
-			gotActions := env.CodeAction("go.mod", modPathDiagnostics)
-			allActions = append(allActions, gotActions...)
-			if diff := diffCodeActions(gotActions, want.codeActions); diff != "" {
-				t.Errorf("code actions for %q do not match, expected %v, got %v\n%v\n", mod, want.codeActions, gotActions, diff)
-				continue
-			}
-		}
-
-		// Clear Diagnostics by using one of the reset code actions.
-		var reset protocol.CodeAction
-		for _, a := range allActions {
-			if a.Title == "Reset govulncheck result" {
-				reset = a
-				break
-			}
-		}
-		if reset.Title != "Reset govulncheck result" {
-			t.Errorf("failed to find a 'Reset govulncheck result' code action, got %v", allActions)
-		}
-		env.ApplyCodeAction(reset)
-
-		env.Await(EmptyOrNoDiagnostics("go.mod"))
-	})
-}
-
-// testVulnDiagnostics finds the require or module statement line for the requireMod in go.mod file
-// and runs checks if diagnostics and code actions associated with the line match expectation.
-func testVulnDiagnostics(t *testing.T, env *Env, pattern string, want vulnDiagExpectation, got *protocol.PublishDiagnosticsParams) []protocol.Diagnostic {
-	t.Helper()
-	pos := env.RegexpSearch("go.mod", pattern)
-	var modPathDiagnostics []protocol.Diagnostic
-	for _, w := range want.diagnostics {
-		// Find the diagnostics at pos.
-		var diag *protocol.Diagnostic
-		for _, g := range got.Diagnostics {
-			g := g
-			if g.Range.Start == pos.ToProtocolPosition() && w.msg == g.Message {
-				modPathDiagnostics = append(modPathDiagnostics, g)
-				diag = &g
-				break
-			}
-		}
-		if diag == nil {
-			t.Errorf("no diagnostic at %q matching %q found\n", pattern, w.msg)
-			continue
-		}
-		if diag.Severity != w.severity {
-			t.Errorf("incorrect severity for %q, want %s got %s\n", w.msg, w.severity, diag.Severity)
-		}
-		sort.Slice(w.relatedInfo, func(i, j int) bool { return w.relatedInfo[i].less(w.relatedInfo[j]) })
-		if got, want := summarizeRelatedInfo(diag.RelatedInformation), w.relatedInfo; !cmp.Equal(got, want) {
-			t.Errorf("related info for %q do not match, want %v, got %v\n", w.msg, want, got)
-		}
-		// Check expected code actions appear.
-		gotActions := env.CodeAction("go.mod", []protocol.Diagnostic{*diag})
-		if diff := diffCodeActions(gotActions, w.codeActions); diff != "" {
-			t.Errorf("code actions for %q do not match, want %v, got %v\n%v\n", w.msg, w.codeActions, gotActions, diff)
-			continue
-		}
-	}
-	// Check that useful info is supplemented as hover.
-	if len(want.hover) > 0 {
-		hover, _ := env.Hover("go.mod", pos)
-		for _, part := range want.hover {
-			if !strings.Contains(hover.Value, part) {
-				t.Errorf("hover contents for %q do not match, want %v, got %v\n", pattern, strings.Join(want.hover, ","), hover.Value)
-				break
-			}
-		}
-	}
-	return modPathDiagnostics
-}
-
-// summarizeRelatedInfo converts protocol.DiagnosticRelatedInformation to vulnRelatedInfo
-// that captures only the part that we want to test.
-func summarizeRelatedInfo(rinfo []protocol.DiagnosticRelatedInformation) []vulnRelatedInfo {
-	var res []vulnRelatedInfo
-	for _, r := range rinfo {
-		filename := filepath.Base(r.Location.URI.SpanURI().Filename())
-		message, _, _ := strings.Cut(r.Message, " ")
-		line := r.Location.Range.Start.Line
-		res = append(res, vulnRelatedInfo{filename, line, message})
-	}
-	sort.Slice(res, func(i, j int) bool {
-		return res[i].less(res[j])
-	})
-	return res
-}
-
-type vulnRelatedInfo struct {
-	Filename string
-	Line     uint32
-	Message  string
-}
-
-type vulnDiag struct {
-	msg      string
-	severity protocol.DiagnosticSeverity
-	// codeActions is a list titles of code actions that we get with this
-	// diagnostics as the context.
-	codeActions []string
-	// relatedInfo is related info message prefixed by the file base.
-	// See summarizeRelatedInfo.
-	relatedInfo []vulnRelatedInfo
-}
-
-func (i vulnRelatedInfo) less(j vulnRelatedInfo) bool {
-	if i.Filename != j.Filename {
-		return i.Filename < j.Filename
-	}
-	if i.Line != j.Line {
-		return i.Line < j.Line
-	}
-	return i.Message < j.Message
-}
-
-// vulnDiagExpectation maps a module path in the require
-// section of a go.mod to diagnostics that will be returned
-// when running vulncheck.
-type vulnDiagExpectation struct {
-	// applyAction is the title of the code action to run for this module.
-	// If empty, no code actions will be executed.
-	applyAction string
-	// diagnostics is the list of diagnostics we expect at the require line for
-	// the module path.
-	diagnostics []vulnDiag
-	// codeActions is a list titles of code actions that we get with context
-	// diagnostics.
-	codeActions []string
-	// hover message is the list of expected hover message parts for this go.mod require line.
-	// all parts must appear in the hover message.
-	hover []string
-}
diff -urN a/gopls/internal/regtest/misc/workspace_symbol_test.go b/gopls/internal/regtest/misc/workspace_symbol_test.go
--- a/gopls/internal/regtest/misc/workspace_symbol_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/misc/workspace_symbol_test.go	1969-12-31 16:00:00
@@ -1,124 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package misc
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-func TestWorkspaceSymbolMissingMetadata(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.17
--- a.go --
-package p
-
-const C1 = "a.go"
--- exclude.go --
-
-//go:build exclude
-// +build exclude
-
-package exclude
-
-const C2 = "exclude.go"
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a.go")
-		syms := env.WorkspaceSymbol("C")
-		if got, want := len(syms), 1; got != want {
-			t.Errorf("got %d symbols, want %d", got, want)
-		}
-
-		// Opening up an ignored file will result in an overlay with missing
-		// metadata, but this shouldn't break workspace symbols requests.
-		env.OpenFile("exclude.go")
-		syms = env.WorkspaceSymbol("C")
-		if got, want := len(syms), 1; got != want {
-			t.Errorf("got %d symbols, want %d", got, want)
-		}
-	})
-}
-
-func TestWorkspaceSymbolSorting(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.17
--- a/a.go --
-package a
-
-const (
-	Foo = iota
-	FooBar
-	Fooey
-	Fooex
-	Fooest
-)
-`
-
-	var symbolMatcher = string(source.SymbolFastFuzzy)
-	WithOptions(
-		Settings{"symbolMatcher": symbolMatcher},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		want := []string{
-			"Foo",    // prefer exact segment matches first
-			"FooBar", // ...followed by exact word matches
-			"Fooex",  // shorter than Fooest, FooBar, lexically before Fooey
-			"Fooey",  // shorter than Fooest, Foobar
-			"Fooest",
-		}
-		got := env.WorkspaceSymbol("Foo")
-		compareSymbols(t, got, want)
-	})
-}
-
-func TestWorkspaceSymbolSpecialPatterns(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.17
--- a/a.go --
-package a
-
-const (
-	AxxBxxCxx
-	ABC
-)
-`
-
-	var symbolMatcher = string(source.SymbolFastFuzzy)
-	WithOptions(
-		Settings{"symbolMatcher": symbolMatcher},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		compareSymbols(t, env.WorkspaceSymbol("ABC"), []string{"ABC", "AxxBxxCxx"})
-		compareSymbols(t, env.WorkspaceSymbol("'ABC"), []string{"ABC"})
-		compareSymbols(t, env.WorkspaceSymbol("^mod.com"), []string{"mod.com/a.ABC", "mod.com/a.AxxBxxCxx"})
-		compareSymbols(t, env.WorkspaceSymbol("^mod.com Axx"), []string{"mod.com/a.AxxBxxCxx"})
-		compareSymbols(t, env.WorkspaceSymbol("C$"), []string{"ABC"})
-	})
-}
-
-func compareSymbols(t *testing.T, got []protocol.SymbolInformation, want []string) {
-	t.Helper()
-	if len(got) != len(want) {
-		t.Errorf("got %d symbols, want %d", len(got), len(want))
-	}
-
-	for i := range got {
-		if got[i].Name != want[i] {
-			t.Errorf("got[%d] = %q, want %q", i, got[i].Name, want[i])
-		}
-	}
-}
diff -urN a/gopls/internal/regtest/modfile/modfile_test.go b/gopls/internal/regtest/modfile/modfile_test.go
--- a/gopls/internal/regtest/modfile/modfile_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/modfile/modfile_test.go	1969-12-31 16:00:00
@@ -1,1187 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package modfile
-
-import (
-	"path/filepath"
-	"runtime"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/gopls/internal/lsp/tests/compare"
-	"golang.org/x/tools/internal/bug"
-
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-const workspaceProxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-func SaySomething() {
-	fmt.Println("something")
-}
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/bye/bye.go --
-package bye
-
-func Goodbye() {
-	println("Bye")
-}
-`
-
-const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/blah/blah.go --
-package hello
-
-const Name = "Hello"
-`
-
-func TestModFileModification(t *testing.T) {
-	const untidyModule = `
--- a/go.mod --
-module mod.com
-
--- a/main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	println(blah.Name)
-}
-`
-
-	runner := RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}
-
-	t.Run("basic", func(t *testing.T) {
-		runner.Run(t, untidyModule, func(t *testing.T, env *Env) {
-			// Open the file and make sure that the initial workspace load does not
-			// modify the go.mod file.
-			goModContent := env.ReadWorkspaceFile("a/go.mod")
-			env.OpenFile("a/main.go")
-			env.Await(
-				OnceMet(
-					env.DoneWithOpen(),
-					env.DiagnosticAtRegexp("a/main.go", "\"example.com/blah\""),
-				),
-			)
-			if got := env.ReadWorkspaceFile("a/go.mod"); got != goModContent {
-				t.Fatalf("go.mod changed on disk:\n%s", compare.Text(goModContent, got))
-			}
-			// Save the buffer, which will format and organize imports.
-			// Confirm that the go.mod file still does not change.
-			env.SaveBuffer("a/main.go")
-			env.Await(
-				env.DiagnosticAtRegexp("a/main.go", "\"example.com/blah\""),
-			)
-			if got := env.ReadWorkspaceFile("a/go.mod"); got != goModContent {
-				t.Fatalf("go.mod changed on disk:\n%s", compare.Text(goModContent, got))
-			}
-		})
-	})
-
-	// Reproduce golang/go#40269 by deleting and recreating main.go.
-	t.Run("delete main.go", func(t *testing.T) {
-		runner.Run(t, untidyModule, func(t *testing.T, env *Env) {
-			goModContent := env.ReadWorkspaceFile("a/go.mod")
-			mainContent := env.ReadWorkspaceFile("a/main.go")
-			env.OpenFile("a/main.go")
-			env.SaveBuffer("a/main.go")
-
-			// Ensure that we're done processing all the changes caused by opening
-			// and saving above. If not, we may run into a file locking issue on
-			// windows.
-			//
-			// If this proves insufficient, env.RemoveWorkspaceFile can be updated to
-			// retry file lock errors on windows.
-			env.Await(
-				env.DoneWithOpen(),
-				env.DoneWithSave(),
-				env.DoneWithChangeWatchedFiles(),
-			)
-			env.RemoveWorkspaceFile("a/main.go")
-
-			// TODO(rfindley): awaiting here shouldn't really be necessary. We should
-			// be consistent eventually.
-			//
-			// Probably this was meant to exercise a race with the change below.
-			env.Await(
-				env.DoneWithOpen(),
-				env.DoneWithSave(),
-				env.DoneWithChangeWatchedFiles(),
-			)
-
-			env.WriteWorkspaceFile("a/main.go", mainContent)
-			env.Await(
-				OnceMet(
-					env.DoneWithChangeWatchedFiles(),
-					env.DiagnosticAtRegexp("a/main.go", "\"example.com/blah\""),
-				),
-			)
-			if got := env.ReadWorkspaceFile("a/go.mod"); got != goModContent {
-				t.Fatalf("go.mod changed on disk:\n%s", compare.Text(goModContent, got))
-			}
-		})
-	})
-}
-
-func TestGoGetFix(t *testing.T) {
-	const mod = `
--- a/go.mod --
-module mod.com
-
-go 1.12
-
--- a/main.go --
-package main
-
-import "example.com/blah"
-
-var _ = blah.Name
-`
-
-	const want = `module mod.com
-
-go 1.12
-
-require example.com v1.2.3
-`
-
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, mod, func(t *testing.T, env *Env) {
-		if strings.Contains(t.Name(), "workspace_module") {
-			t.Skip("workspace module mode doesn't set -mod=readonly")
-		}
-		env.OpenFile("a/main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/main.go", `"example.com/blah"`),
-				ReadDiagnostics("a/main.go", &d),
-			),
-		)
-		var goGetDiag protocol.Diagnostic
-		for _, diag := range d.Diagnostics {
-			if strings.Contains(diag.Message, "could not import") {
-				goGetDiag = diag
-			}
-		}
-		env.ApplyQuickFixes("a/main.go", []protocol.Diagnostic{goGetDiag})
-		if got := env.ReadWorkspaceFile("a/go.mod"); got != want {
-			t.Fatalf("unexpected go.mod content:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Tests that multiple missing dependencies gives good single fixes.
-func TestMissingDependencyFixes(t *testing.T) {
-	const mod = `
--- a/go.mod --
-module mod.com
-
-go 1.12
-
--- a/main.go --
-package main
-
-import "example.com/blah"
-import "random.org/blah"
-
-var _, _ = blah.Name, hello.Name
-`
-
-	const want = `module mod.com
-
-go 1.12
-
-require random.org v1.2.3
-`
-
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/main.go", `"random.org/blah"`),
-				ReadDiagnostics("a/main.go", &d),
-			),
-		)
-		var randomDiag protocol.Diagnostic
-		for _, diag := range d.Diagnostics {
-			if strings.Contains(diag.Message, "random.org") {
-				randomDiag = diag
-			}
-		}
-		env.ApplyQuickFixes("a/main.go", []protocol.Diagnostic{randomDiag})
-		if got := env.ReadWorkspaceFile("a/go.mod"); got != want {
-			t.Fatalf("unexpected go.mod content:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Tests that multiple missing dependencies gives good single fixes.
-func TestMissingDependencyFixesWithGoWork(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const mod = `
--- go.work --
-go 1.18
-
-use (
-	./a
-)
--- a/go.mod --
-module mod.com
-
-go 1.12
-
--- a/main.go --
-package main
-
-import "example.com/blah"
-import "random.org/blah"
-
-var _, _ = blah.Name, hello.Name
-`
-
-	const want = `module mod.com
-
-go 1.12
-
-require random.org v1.2.3
-`
-
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/main.go", `"random.org/blah"`),
-				ReadDiagnostics("a/main.go", &d),
-			),
-		)
-		var randomDiag protocol.Diagnostic
-		for _, diag := range d.Diagnostics {
-			if strings.Contains(diag.Message, "random.org") {
-				randomDiag = diag
-			}
-		}
-		env.ApplyQuickFixes("a/main.go", []protocol.Diagnostic{randomDiag})
-		if got := env.ReadWorkspaceFile("a/go.mod"); got != want {
-			t.Fatalf("unexpected go.mod content:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestIndirectDependencyFix(t *testing.T) {
-	const mod = `
--- a/go.mod --
-module mod.com
-
-go 1.12
-
-require example.com v1.2.3 // indirect
--- a/go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- a/main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	fmt.Println(blah.Name)
-`
-	const want = `module mod.com
-
-go 1.12
-
-require example.com v1.2.3
-`
-
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("a/go.mod")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/go.mod", "// indirect"),
-				ReadDiagnostics("a/go.mod", &d),
-			),
-		)
-		env.ApplyQuickFixes("a/go.mod", d.Diagnostics)
-		if got := env.BufferText("a/go.mod"); got != want {
-			t.Fatalf("unexpected go.mod content:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestUnusedDiag(t *testing.T) {
-
-	const proxy = `
--- example.com@v1.0.0/x.go --
-package pkg
-const X = 1
-`
-	const files = `
--- a/go.mod --
-module mod.com
-go 1.14
-require example.com v1.0.0
--- a/go.sum --
-example.com v1.0.0 h1:38O7j5rEBajXk+Q5wzLbRN7KqMkSgEiN9NqcM1O2bBM=
-example.com v1.0.0/go.mod h1:vUsPMGpx9ZXXzECCOsOmYCW7npJTwuA16yl89n3Mgls=
--- a/main.go --
-package main
-func main() {}
-`
-
-	const want = `module mod.com
-
-go 1.14
-`
-
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a/go.mod")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/go.mod", `require example.com`),
-				ReadDiagnostics("a/go.mod", &d),
-			),
-		)
-		env.ApplyQuickFixes("a/go.mod", d.Diagnostics)
-		if got := env.BufferText("a/go.mod"); got != want {
-			t.Fatalf("unexpected go.mod content:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Test to reproduce golang/go#39041. It adds a new require to a go.mod file
-// that already has an unused require.
-func TestNewDepWithUnusedDep(t *testing.T) {
-
-	const proxy = `
--- github.com/esimov/caire@v1.2.5/go.mod --
-module github.com/esimov/caire
-
-go 1.12
--- github.com/esimov/caire@v1.2.5/caire.go --
-package caire
-
-func RemoveTempImage() {}
--- google.golang.org/protobuf@v1.20.0/go.mod --
-module google.golang.org/protobuf
-
-go 1.12
--- google.golang.org/protobuf@v1.20.0/hello/hello.go --
-package hello
-`
-	const repro = `
--- a/go.mod --
-module mod.com
-
-go 1.14
-
-require google.golang.org/protobuf v1.20.0
--- a/go.sum --
-github.com/esimov/caire v1.2.5 h1:OcqDII/BYxcBYj3DuwDKjd+ANhRxRqLa2n69EGje7qw=
-github.com/esimov/caire v1.2.5/go.mod h1:mXnjRjg3+WUtuhfSC1rKRmdZU9vJZyS1ZWU0qSvJhK8=
-google.golang.org/protobuf v1.20.0 h1:y9T1vAtFKQg0faFNMOxJU7WuEqPWolVkjIkU6aI8qCY=
-google.golang.org/protobuf v1.20.0/go.mod h1:FcqsytGClbtLv1ot8NvsJHjBi0h22StKVP+K/j2liKA=
--- a/main.go --
-package main
-
-import (
-    "github.com/esimov/caire"
-)
-
-func _() {
-    caire.RemoveTempImage()
-}`
-
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, repro, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		var d protocol.PublishDiagnosticsParams
-		env.Await(
-			OnceMet(
-				env.DiagnosticAtRegexp("a/main.go", `"github.com/esimov/caire"`),
-				ReadDiagnostics("a/main.go", &d),
-			),
-		)
-		env.ApplyQuickFixes("a/main.go", d.Diagnostics)
-		want := `module mod.com
-
-go 1.14
-
-require (
-	github.com/esimov/caire v1.2.5
-	google.golang.org/protobuf v1.20.0
-)
-`
-		if got := env.ReadWorkspaceFile("a/go.mod"); got != want {
-			t.Fatalf("TestNewDepWithUnusedDep failed:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// TODO: For this test to be effective, the sandbox's file watcher must respect
-// the file watching GlobPattern in the capability registration. See
-// golang/go#39384.
-func TestModuleChangesOnDisk(t *testing.T) {
-	const mod = `
--- a/go.mod --
-module mod.com
-
-go 1.12
-
-require example.com v1.2.3
--- a/go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- a/main.go --
-package main
-
-func main() {
-	fmt.Println(blah.Name)
-`
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(env.DiagnosticAtRegexp("a/go.mod", "require"))
-		env.RunGoCommandInDir("a", "mod", "tidy")
-		env.Await(
-			EmptyDiagnostics("a/go.mod"),
-		)
-	})
-}
-
-// Tests golang/go#39784: a missing indirect dependency, necessary
-// due to blah@v2.0.0's incomplete go.mod file.
-func TestBadlyVersionedModule(t *testing.T) {
-	const proxy = `
--- example.com/blah/@v/v1.0.0.mod --
-module example.com
-
-go 1.12
--- example.com/blah@v1.0.0/blah.go --
-package blah
-
-const Name = "Blah"
--- example.com/blah/v2/@v/v2.0.0.mod --
-module example.com
-
-go 1.12
--- example.com/blah/v2@v2.0.0/blah.go --
-package blah
-
-import "example.com/blah"
-
-var V1Name = blah.Name
-const Name = "Blah"
-`
-	const files = `
--- a/go.mod --
-module mod.com
-
-go 1.12
-
-require example.com/blah/v2 v2.0.0
--- a/go.sum --
-example.com/blah v1.0.0 h1:kGPlWJbMsn1P31H9xp/q2mYI32cxLnCvauHN0AVaHnc=
-example.com/blah v1.0.0/go.mod h1:PZUQaGFeVjyDmAE8ywmLbmDn3fj4Ws8epg4oLuDzW3M=
-example.com/blah/v2 v2.0.0 h1:DNPsFPkKtTdxclRheaMCiYAoYizp6PuBzO0OmLOO0pY=
-example.com/blah/v2 v2.0.0/go.mod h1:UZiKbTwobERo/hrqFLvIQlJwQZQGxWMVY4xere8mj7w=
--- a/main.go --
-package main
-
-import "example.com/blah/v2"
-
-var _ = blah.Name
-`
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}.Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		env.OpenFile("a/go.mod")
-		env.Await(
-			// We would like for the error to appear in the v2 module, but
-			// as of writing non-workspace packages are not diagnosed.
-			env.DiagnosticAtRegexpWithMessage("a/main.go", `"example.com/blah/v2"`, "cannot find module providing"),
-			env.DiagnosticAtRegexpWithMessage("a/go.mod", `require example.com/blah/v2`, "cannot find module providing"),
-		)
-		env.ApplyQuickFixes("a/go.mod", env.Awaiter.DiagnosticsFor("a/go.mod").Diagnostics)
-		const want = `module mod.com
-
-go 1.12
-
-require (
-	example.com/blah v1.0.0 // indirect
-	example.com/blah/v2 v2.0.0
-)
-`
-		env.SaveBuffer("a/go.mod")
-		env.Await(EmptyDiagnostics("a/main.go"))
-		if got := env.BufferText("a/go.mod"); got != want {
-			t.Fatalf("suggested fixes failed:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-// Reproduces golang/go#38232.
-func TestUnknownRevision(t *testing.T) {
-	if runtime.GOOS == "plan9" {
-		t.Skipf("skipping test that fails for unknown reasons on plan9; see https://go.dev/issue/50477")
-	}
-	const unknown = `
--- a/go.mod --
-module mod.com
-
-require (
-	example.com v1.2.2
-)
--- a/main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	var x = blah.Name
-}
-`
-
-	runner := RunMultiple{
-		{"default", WithOptions(ProxyFiles(proxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(proxy))},
-	}
-	// Start from a bad state/bad IWL, and confirm that we recover.
-	t.Run("bad", func(t *testing.T) {
-		runner.Run(t, unknown, func(t *testing.T, env *Env) {
-			env.OpenFile("a/go.mod")
-			env.Await(
-				env.DiagnosticAtRegexp("a/go.mod", "example.com v1.2.2"),
-			)
-			env.RegexpReplace("a/go.mod", "v1.2.2", "v1.2.3")
-			env.SaveBuffer("a/go.mod") // Save to trigger diagnostics.
-
-			d := protocol.PublishDiagnosticsParams{}
-			env.AfterChange(
-				// Make sure the diagnostic mentions the new version -- the old diagnostic is in the same place.
-				env.DiagnosticAtRegexpWithMessage("a/go.mod", "example.com v1.2.3", "example.com@v1.2.3"),
-				ReadDiagnostics("a/go.mod", &d),
-			)
-			qfs := env.GetQuickFixes("a/go.mod", d.Diagnostics)
-			if len(qfs) == 0 {
-				t.Fatalf("got 0 code actions to fix %v, wanted at least 1", d.Diagnostics)
-			}
-			env.ApplyCodeAction(qfs[0]) // Arbitrarily pick a single fix to apply. Applying all of them seems to cause trouble in this particular test.
-			env.SaveBuffer("a/go.mod")  // Save to trigger diagnostics.
-			env.AfterChange(
-				EmptyDiagnostics("a/go.mod"),
-				env.DiagnosticAtRegexp("a/main.go", "x = "),
-			)
-		})
-	})
-
-	const known = `
--- a/go.mod --
-module mod.com
-
-require (
-	example.com v1.2.3
-)
--- a/go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- a/main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	var x = blah.Name
-}
-`
-	// Start from a good state, transform to a bad state, and confirm that we
-	// still recover.
-	t.Run("good", func(t *testing.T) {
-		runner.Run(t, known, func(t *testing.T, env *Env) {
-			env.OpenFile("a/go.mod")
-			env.AfterChange(
-				env.DiagnosticAtRegexp("a/main.go", "x = "),
-			)
-			env.RegexpReplace("a/go.mod", "v1.2.3", "v1.2.2")
-			env.Editor.SaveBuffer(env.Ctx, "a/go.mod") // go.mod changes must be on disk
-			env.AfterChange(
-				env.DiagnosticAtRegexp("a/go.mod", "example.com v1.2.2"),
-			)
-			env.RegexpReplace("a/go.mod", "v1.2.2", "v1.2.3")
-			env.Editor.SaveBuffer(env.Ctx, "a/go.mod") // go.mod changes must be on disk
-			env.AfterChange(
-				env.DiagnosticAtRegexp("a/main.go", "x = "),
-			)
-		})
-	})
-}
-
-// Confirm that an error in an indirect dependency of a requirement is surfaced
-// as a diagnostic in the go.mod file.
-func TestErrorInIndirectDependency(t *testing.T) {
-	const badProxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
-
-require random.org v1.2.3 // indirect
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
--- random.org@v1.2.3/go.mod --
-module bob.org
-
-go 1.12
--- random.org@v1.2.3/blah/blah.go --
-package hello
-
-const Name = "Hello"
-`
-	const module = `
--- a/go.mod --
-module mod.com
-
-go 1.14
-
-require example.com v1.2.3
--- a/main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	println(blah.Name)
-}
-`
-	RunMultiple{
-		{"default", WithOptions(ProxyFiles(badProxy), WorkspaceFolders("a"))},
-		{"nested", WithOptions(ProxyFiles(badProxy))},
-	}.Run(t, module, func(t *testing.T, env *Env) {
-		env.OpenFile("a/go.mod")
-		env.Await(
-			env.DiagnosticAtRegexp("a/go.mod", "require example.com v1.2.3"),
-		)
-	})
-}
-
-// A copy of govim's config_set_env_goflags_mod_readonly test.
-func TestGovimModReadonly(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.13
--- main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	println(blah.Name)
-}
-`
-	WithOptions(
-		EnvVars{"GOFLAGS": "-mod=readonly"},
-		ProxyFiles(proxy),
-		Modes(Default),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		original := env.ReadWorkspaceFile("go.mod")
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", `"example.com/blah"`),
-		)
-		got := env.ReadWorkspaceFile("go.mod")
-		if got != original {
-			t.Fatalf("go.mod file modified:\n%s", compare.Text(original, got))
-		}
-		env.RunGoCommand("get", "example.com/blah@v1.2.3")
-		env.RunGoCommand("mod", "tidy")
-		env.Await(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
-
-func TestMultiModuleModDiagnostics(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	const mod = `
--- go.work --
-go 1.18
-
-use (
-	a
-	b
-)
--- a/go.mod --
-module moda.com
-
-go 1.14
-
-require (
-	example.com v1.2.3
-)
--- a/go.sum --
-example.com v1.2.3 h1:Yryq11hF02fEf2JlOS2eph+ICE2/ceevGV3C9dl5V/c=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- a/main.go --
-package main
-
-func main() {}
--- b/go.mod --
-module modb.com
-
-require example.com v1.2.3
-
-go 1.14
--- b/main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	blah.SaySomething()
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("a/go.mod", "example.com v1.2.3", "is not used"),
-		)
-	})
-}
-
-func TestModTidyWithBuildTags(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.14
--- main.go --
-// +build bob
-
-package main
-
-import "example.com/blah"
-
-func main() {
-	blah.SaySomething()
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		Settings{"buildFlags": []string{"-tags", "bob"}},
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", `"example.com/blah"`),
-		)
-	})
-}
-
-func TestModTypoDiagnostic(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func main() {}
-`
-	Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.RegexpReplace("go.mod", "module", "modul")
-		env.Await(
-			env.DiagnosticAtRegexp("go.mod", "modul"),
-		)
-	})
-}
-
-func TestSumUpdateFixesDiagnostics(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require (
-	example.com v1.2.3
-)
--- go.sum --
--- main.go --
-package main
-
-import (
-	"example.com/blah"
-)
-
-func main() {
-	println(blah.Name)
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		d := &protocol.PublishDiagnosticsParams{}
-		env.OpenFile("go.mod")
-		env.Await(
-			OnceMet(
-				env.GoSumDiagnostic("go.mod", `example.com v1.2.3`),
-				ReadDiagnostics("go.mod", d),
-			),
-		)
-		env.ApplyQuickFixes("go.mod", d.Diagnostics)
-		env.SaveBuffer("go.mod") // Save to trigger diagnostics.
-		env.Await(
-			EmptyDiagnostics("go.mod"),
-		)
-	})
-}
-
-// This test confirms that editing a go.mod file only causes metadata
-// to be invalidated when it's saved.
-func TestGoModInvalidatesOnSave(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- main.go --
-package main
-
-func main() {
-	hello()
-}
--- hello.go --
-package main
-
-func hello() {}
-`
-	WithOptions(
-		// TODO(rFindley) this doesn't work in multi-module workspace mode, because
-		// it keeps around the last parsing modfile. Update this test to also
-		// exercise the workspace module.
-		Modes(Default),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		env.Await(env.DoneWithOpen())
-		env.RegexpReplace("go.mod", "module", "modul")
-		// Confirm that we still have metadata with only on-disk edits.
-		env.OpenFile("main.go")
-		file, _ := env.GoToDefinition("main.go", env.RegexpSearch("main.go", "hello"))
-		if filepath.Base(file) != "hello.go" {
-			t.Fatalf("expected definition in hello.go, got %s", file)
-		}
-		// Confirm that we no longer have metadata when the file is saved.
-		env.SaveBufferWithoutActions("go.mod")
-		_, _, err := env.Editor.GoToDefinition(env.Ctx, "main.go", env.RegexpSearch("main.go", "hello"))
-		if err == nil {
-			t.Fatalf("expected error, got none")
-		}
-	})
-}
-
-func TestRemoveUnusedDependency(t *testing.T) {
-	const proxy = `
--- hasdep.com@v1.2.3/go.mod --
-module hasdep.com
-
-go 1.12
-
-require example.com v1.2.3
--- hasdep.com@v1.2.3/a/a.go --
-package a
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
--- random.com@v1.2.3/go.mod --
-module random.com
-
-go 1.12
--- random.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
-`
-	t.Run("almost tidied", func(t *testing.T) {
-		const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require hasdep.com v1.2.3
--- go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
-hasdep.com v1.2.3 h1:00y+N5oD+SpKoqV1zP2VOPawcW65Zb9NebANY3GSzGI=
-hasdep.com v1.2.3/go.mod h1:ePVZOlez+KZEOejfLPGL2n4i8qiAjrkhQZ4wcImqAes=
--- main.go --
-package main
-
-func main() {}
-`
-		WithOptions(
-			ProxyFiles(proxy),
-		).Run(t, mod, func(t *testing.T, env *Env) {
-			env.OpenFile("go.mod")
-			d := &protocol.PublishDiagnosticsParams{}
-			env.Await(
-				OnceMet(
-					env.DiagnosticAtRegexp("go.mod", "require hasdep.com v1.2.3"),
-					ReadDiagnostics("go.mod", d),
-				),
-			)
-			const want = `module mod.com
-
-go 1.12
-`
-			env.ApplyQuickFixes("go.mod", d.Diagnostics)
-			if got := env.BufferText("go.mod"); got != want {
-				t.Fatalf("unexpected content in go.mod:\n%s", compare.Text(want, got))
-			}
-		})
-	})
-
-	t.Run("not tidied", func(t *testing.T) {
-		const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require hasdep.com v1.2.3
-require random.com v1.2.3
--- go.sum --
-example.com v1.2.3 h1:ihBTGWGjTU3V4ZJ9OmHITkU9WQ4lGdQkMjgyLFk0FaY=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
-hasdep.com v1.2.3 h1:00y+N5oD+SpKoqV1zP2VOPawcW65Zb9NebANY3GSzGI=
-hasdep.com v1.2.3/go.mod h1:ePVZOlez+KZEOejfLPGL2n4i8qiAjrkhQZ4wcImqAes=
-random.com v1.2.3 h1:PzYTykzqqH6+qU0dIgh9iPFbfb4Mm8zNBjWWreRKtx0=
-random.com v1.2.3/go.mod h1:8EGj+8a4Hw1clAp8vbaeHAsKE4sbm536FP7nKyXO+qQ=
--- main.go --
-package main
-
-func main() {}
-`
-		WithOptions(
-			ProxyFiles(proxy),
-		).Run(t, mod, func(t *testing.T, env *Env) {
-			d := &protocol.PublishDiagnosticsParams{}
-			env.OpenFile("go.mod")
-			pos := env.RegexpSearch("go.mod", "require hasdep.com v1.2.3")
-			env.Await(
-				OnceMet(
-					DiagnosticAt("go.mod", pos.Line, pos.Column),
-					ReadDiagnostics("go.mod", d),
-				),
-			)
-			const want = `module mod.com
-
-go 1.12
-
-require random.com v1.2.3
-`
-			var diagnostics []protocol.Diagnostic
-			for _, d := range d.Diagnostics {
-				if d.Range.Start.Line != uint32(pos.Line) {
-					continue
-				}
-				diagnostics = append(diagnostics, d)
-			}
-			env.ApplyQuickFixes("go.mod", diagnostics)
-			if got := env.BufferText("go.mod"); got != want {
-				t.Fatalf("unexpected content in go.mod:\n%s", compare.Text(want, got))
-			}
-		})
-	})
-}
-
-func TestSumUpdateQuickFix(t *testing.T) {
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require (
-	example.com v1.2.3
-)
--- go.sum --
--- main.go --
-package main
-
-import (
-	"example.com/blah"
-)
-
-func main() {
-	blah.Hello()
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		Modes(Default),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("go.mod")
-		params := &protocol.PublishDiagnosticsParams{}
-		env.Await(
-			OnceMet(
-				env.GoSumDiagnostic("go.mod", "example.com"),
-				ReadDiagnostics("go.mod", params),
-			),
-		)
-		env.ApplyQuickFixes("go.mod", params.Diagnostics)
-		const want = `example.com v1.2.3 h1:Yryq11hF02fEf2JlOS2eph+ICE2/ceevGV3C9dl5V/c=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
-`
-		if got := env.ReadWorkspaceFile("go.sum"); got != want {
-			t.Fatalf("unexpected go.sum contents:\n%s", compare.Text(want, got))
-		}
-	})
-}
-
-func TestDownloadDeps(t *testing.T) {
-	const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
-
-require random.org v1.2.3
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-import "random.org/bye"
-
-func SaySomething() {
-	bye.Goodbye()
-}
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/bye/bye.go --
-package bye
-
-func Goodbye() {
-	println("Bye")
-}
-`
-
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
--- go.sum --
--- main.go --
-package main
-
-import (
-	"example.com/blah"
-)
-
-func main() {
-	blah.SaySomething()
-}
-`
-	WithOptions(
-		ProxyFiles(proxy),
-		Modes(Default),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		d := &protocol.PublishDiagnosticsParams{}
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("main.go", `"example.com/blah"`, `could not import example.com/blah (no required module provides package "example.com/blah")`),
-			ReadDiagnostics("main.go", d),
-		)
-		env.ApplyQuickFixes("main.go", d.Diagnostics)
-		env.Await(
-			EmptyOrNoDiagnostics("main.go"),
-			EmptyOrNoDiagnostics("go.mod"),
-		)
-	})
-}
-
-func TestInvalidGoVersion(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go foo
--- main.go --
-package main
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(env.DiagnosticAtRegexpWithMessage("go.mod", `go foo`, "invalid go version"))
-		env.WriteWorkspaceFile("go.mod", "module mod.com \n\ngo 1.12\n")
-		env.Await(EmptyDiagnostics("go.mod"))
-	})
-}
diff -urN a/gopls/internal/regtest/template/template_test.go b/gopls/internal/regtest/template/template_test.go
--- a/gopls/internal/regtest/template/template_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/template/template_test.go	1969-12-31 16:00:00
@@ -1,224 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package template
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-func TestMultilineTokens(t *testing.T) {
-	// 51731: panic: runtime error: slice bounds out of range [38:3]
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.17
--- hi.tmpl --
-{{if (foÜx .X.Y)}}😀{{$A := 
-	"hi"
-	}}{{.Z $A}}{{else}}
-{{$A.X 12}}
-{{foo (.X.Y) 23 ($A.Z)}}
-{{end}}
-`
-	WithOptions(
-		Settings{
-			"templateExtensions": []string{"tmpl"},
-			"semanticTokens":     true,
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		var p protocol.SemanticTokensParams
-		p.TextDocument.URI = env.Sandbox.Workdir.URI("hi.tmpl")
-		toks, err := env.Editor.Server.SemanticTokensFull(env.Ctx, &p)
-		if err != nil {
-			t.Errorf("semantic token failed: %v", err)
-		}
-		if toks == nil || len(toks.Data) == 0 {
-			t.Errorf("got no semantic tokens")
-		}
-	})
-}
-
-func TestTemplatesFromExtensions(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- hello.tmpl --
-{{range .Planets}}
-Hello {{}} <-- missing body
-{{end}}
-`
-	WithOptions(
-		Settings{
-			"templateExtensions": []string{"tmpl"},
-			"semanticTokens":     true,
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		// TODO: can we move this diagnostic onto {{}}?
-		env.Await(env.DiagnosticAtRegexp("hello.tmpl", "()Hello {{}}"))
-		d := env.Awaiter.DiagnosticsFor("hello.tmpl").Diagnostics // issue 50786: check for Source
-		if len(d) != 1 {
-			t.Errorf("expected 1 diagnostic, got %d", len(d))
-			return
-		}
-		if d[0].Source != "template" {
-			t.Errorf("expected Source 'template', got %q", d[0].Source)
-		}
-		// issue 50801 (even broken templates could return some semantic tokens)
-		var p protocol.SemanticTokensParams
-		p.TextDocument.URI = env.Sandbox.Workdir.URI("hello.tmpl")
-		toks, err := env.Editor.Server.SemanticTokensFull(env.Ctx, &p)
-		if err != nil {
-			t.Errorf("semantic token failed: %v", err)
-		}
-		if toks == nil || len(toks.Data) == 0 {
-			t.Errorf("got no semantic tokens")
-		}
-
-		env.WriteWorkspaceFile("hello.tmpl", "{{range .Planets}}\nHello {{.}}\n{{end}}")
-		env.Await(EmptyDiagnostics("hello.tmpl"))
-	})
-}
-
-func TestTemplatesObserveDirectoryFilters(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.tmpl --
-A {{}} <-- missing body
--- b/b.tmpl --
-B {{}} <-- missing body
-`
-
-	WithOptions(
-		Settings{
-			"directoryFilters":   []string{"-b"},
-			"templateExtensions": []string{"tmpl"},
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(env.DiagnosticAtRegexp("a/a.tmpl", "()A")),
-			NoDiagnostics("b/b.tmpl"),
-		)
-	})
-}
-
-func TestTemplatesFromLangID(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.CreateBuffer("hello.tmpl", "")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				EmptyDiagnostics("hello.tmpl"), // Don't get spurious errors for empty templates.
-			),
-		)
-		env.SetBufferContent("hello.tmpl", "{{range .Planets}}\nHello {{}}\n{{end}}")
-		env.Await(env.DiagnosticAtRegexp("hello.tmpl", "()Hello {{}}"))
-		env.RegexpReplace("hello.tmpl", "{{}}", "{{.}}")
-		env.Await(EmptyOrNoDiagnostics("hello.tmpl"))
-	})
-}
-
-func TestClosingTemplatesMakesDiagnosticsDisappear(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- hello.tmpl --
-{{range .Planets}}
-Hello {{}} <-- missing body
-{{end}}
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("hello.tmpl")
-		env.Await(env.DiagnosticAtRegexp("hello.tmpl", "()Hello {{}}"))
-		// Since we don't have templateExtensions configured, closing hello.tmpl
-		// should make its diagnostics disappear.
-		env.CloseBuffer("hello.tmpl")
-		env.Await(EmptyDiagnostics("hello.tmpl"))
-	})
-}
-
-func TestMultipleSuffixes(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- b.gotmpl --
-{{define "A"}}goo{{end}}
--- a.tmpl --
-{{template "A"}}
-`
-
-	WithOptions(
-		Settings{
-			"templateExtensions": []string{"tmpl", "gotmpl"},
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a.tmpl")
-		x := env.RegexpSearch("a.tmpl", `A`)
-		file, pos := env.GoToDefinition("a.tmpl", x)
-		refs := env.References(file, pos)
-		if len(refs) != 2 {
-			t.Fatalf("got %v reference(s), want 2", len(refs))
-		}
-		// make sure we got one from b.gotmpl
-		want := env.Sandbox.Workdir.URI("b.gotmpl")
-		if refs[0].URI != want && refs[1].URI != want {
-			t.Errorf("failed to find reference to %s", shorten(want))
-			for i, r := range refs {
-				t.Logf("%d: URI:%s %v", i, shorten(r.URI), r.Range)
-			}
-		}
-
-		content, npos := env.Hover(file, pos)
-		if pos != npos {
-			t.Errorf("pos? got %v, wanted %v", npos, pos)
-		}
-		if content.Value != "template A defined" {
-			t.Errorf("got %s, wanted 'template A defined", content.Value)
-		}
-	})
-}
-
-// shorten long URIs
-func shorten(fn protocol.DocumentURI) string {
-	if len(fn) <= 20 {
-		return string(fn)
-	}
-	pieces := strings.Split(string(fn), "/")
-	if len(pieces) < 2 {
-		return string(fn)
-	}
-	j := len(pieces)
-	return pieces[j-2] + "/" + pieces[j-1]
-}
-
-// Hover needs tests
diff -urN a/gopls/internal/regtest/watch/watch_test.go b/gopls/internal/regtest/watch/watch_test.go
--- a/gopls/internal/regtest/watch/watch_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/watch/watch_test.go	1969-12-31 16:00:00
@@ -1,736 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package regtest
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/bug"
-
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-func TestEditFile(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- a/a.go --
-package a
-
-func _() {
-	var x int
-}
-`
-	// Edit the file when it's *not open* in the workspace, and check that
-	// diagnostics are updated.
-	t.Run("unopened", func(t *testing.T) {
-		Run(t, pkg, func(t *testing.T, env *Env) {
-			env.Await(
-				env.DiagnosticAtRegexp("a/a.go", "x"),
-			)
-			env.WriteWorkspaceFile("a/a.go", `package a; func _() {};`)
-			env.Await(
-				EmptyDiagnostics("a/a.go"),
-			)
-		})
-	})
-
-	// Edit the file when it *is open* in the workspace, and check that
-	// diagnostics are *not* updated.
-	t.Run("opened", func(t *testing.T) {
-		Run(t, pkg, func(t *testing.T, env *Env) {
-			env.OpenFile("a/a.go")
-			// Insert a trivial edit so that we don't automatically update the buffer
-			// (see CL 267577).
-			env.EditBuffer("a/a.go", fake.NewEdit(0, 0, 0, 0, " "))
-			env.Await(env.DoneWithOpen())
-			env.WriteWorkspaceFile("a/a.go", `package a; func _() {};`)
-			env.Await(
-				OnceMet(
-					env.DoneWithChangeWatchedFiles(),
-					env.DiagnosticAtRegexp("a/a.go", "x"),
-				))
-		})
-	})
-}
-
-// Edit a dependency on disk and expect a new diagnostic.
-func TestEditDependency(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- b/b.go --
-package b
-
-func B() int { return 0 }
--- a/a.go --
-package a
-
-import (
-	"mod.com/b"
-)
-
-func _() {
-	_ = b.B()
-}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.Await(env.DoneWithOpen())
-		env.WriteWorkspaceFile("b/b.go", `package b; func B() {};`)
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "b.B"),
-		)
-	})
-}
-
-// Edit both the current file and one of its dependencies on disk and
-// expect diagnostic changes.
-func TestEditFileAndDependency(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- b/b.go --
-package b
-
-func B() int { return 0 }
--- a/a.go --
-package a
-
-import (
-	"mod.com/b"
-)
-
-func _() {
-	var x int
-	_ = b.B()
-}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "x"),
-		)
-		env.WriteWorkspaceFiles(map[string]string{
-			"b/b.go": `package b; func B() {};`,
-			"a/a.go": `package a
-
-import "mod.com/b"
-
-func _() {
-	b.B()
-}`,
-		})
-		env.Await(
-			EmptyDiagnostics("a/a.go"),
-			EmptyOrNoDiagnostics("b/b.go"),
-		)
-	})
-}
-
-// Delete a dependency and expect a new diagnostic.
-func TestDeleteDependency(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- b/b.go --
-package b
-
-func B() int { return 0 }
--- a/a.go --
-package a
-
-import (
-	"mod.com/b"
-)
-
-func _() {
-	_ = b.B()
-}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.OpenFile("a/a.go")
-		env.Await(env.DoneWithOpen())
-		env.RemoveWorkspaceFile("b/b.go")
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "\"mod.com/b\""),
-		)
-	})
-}
-
-// Create a dependency on disk and expect the diagnostic to go away.
-func TestCreateDependency(t *testing.T) {
-	const missing = `
--- go.mod --
-module mod.com
-
-go 1.14
--- b/b.go --
-package b
-
-func B() int { return 0 }
--- a/a.go --
-package a
-
-import (
-	"mod.com/c"
-)
-
-func _() {
-	c.C()
-}
-`
-	Run(t, missing, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "\"mod.com/c\""),
-		)
-		env.WriteWorkspaceFile("c/c.go", `package c; func C() {};`)
-		env.Await(
-			EmptyDiagnostics("a/a.go"),
-		)
-	})
-}
-
-// Create a new dependency and add it to the file on disk.
-// This is similar to what might happen if you switch branches.
-func TestCreateAndAddDependency(t *testing.T) {
-	const original = `
--- go.mod --
-module mod.com
-
-go 1.14
--- a/a.go --
-package a
-
-func _() {}
-`
-	Run(t, original, func(t *testing.T, env *Env) {
-		env.WriteWorkspaceFile("c/c.go", `package c; func C() {};`)
-		env.WriteWorkspaceFile("a/a.go", `package a; import "mod.com/c"; func _() { c.C() }`)
-		env.Await(
-			NoDiagnostics("a/a.go"),
-		)
-	})
-}
-
-// Create a new file that defines a new symbol, in the same package.
-func TestCreateFile(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- a/a.go --
-package a
-
-func _() {
-	hello()
-}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexp("a/a.go", "hello"),
-		)
-		env.WriteWorkspaceFile("a/a2.go", `package a; func hello() {};`)
-		env.Await(
-			EmptyDiagnostics("a/a.go"),
-		)
-	})
-}
-
-// Add a new method to an interface and implement it.
-// Inspired by the structure of internal/lsp/source and internal/lsp/cache.
-func TestCreateImplementation(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- b/b.go --
-package b
-
-type B interface{
-	Hello() string
-}
-
-func SayHello(bee B) {
-	println(bee.Hello())
-}
--- a/a.go --
-package a
-
-import "mod.com/b"
-
-type X struct {}
-
-func (_ X) Hello() string {
-	return ""
-}
-
-func _() {
-	x := X{}
-	b.SayHello(x)
-}
-`
-	const newMethod = `package b
-type B interface{
-	Hello() string
-	Bye() string
-}
-
-func SayHello(bee B) {
-	println(bee.Hello())
-}`
-	const implementation = `package a
-
-import "mod.com/b"
-
-type X struct {}
-
-func (_ X) Hello() string {
-	return ""
-}
-
-func (_ X) Bye() string {
-	return ""
-}
-
-func _() {
-	x := X{}
-	b.SayHello(x)
-}`
-
-	// Add the new method before the implementation. Expect diagnostics.
-	t.Run("method before implementation", func(t *testing.T) {
-		Run(t, pkg, func(t *testing.T, env *Env) {
-			env.WriteWorkspaceFile("b/b.go", newMethod)
-			env.Await(
-				OnceMet(
-					env.DoneWithChangeWatchedFiles(),
-					DiagnosticAt("a/a.go", 12, 12),
-				),
-			)
-			env.WriteWorkspaceFile("a/a.go", implementation)
-			env.Await(
-				EmptyDiagnostics("a/a.go"),
-			)
-		})
-	})
-	// Add the new implementation before the new method. Expect no diagnostics.
-	t.Run("implementation before method", func(t *testing.T) {
-		Run(t, pkg, func(t *testing.T, env *Env) {
-			env.WriteWorkspaceFile("a/a.go", implementation)
-			env.Await(
-				OnceMet(
-					env.DoneWithChangeWatchedFiles(),
-					EmptyOrNoDiagnostics("a/a.go"),
-				),
-			)
-			env.WriteWorkspaceFile("b/b.go", newMethod)
-			env.Await(
-				EmptyOrNoDiagnostics("a/a.go"),
-			)
-		})
-	})
-	// Add both simultaneously. Expect no diagnostics.
-	t.Run("implementation and method simultaneously", func(t *testing.T) {
-		Run(t, pkg, func(t *testing.T, env *Env) {
-			env.WriteWorkspaceFiles(map[string]string{
-				"a/a.go": implementation,
-				"b/b.go": newMethod,
-			})
-			env.Await(
-				OnceMet(
-					env.DoneWithChangeWatchedFiles(),
-					EmptyOrNoDiagnostics("a/a.go"),
-				),
-				EmptyOrNoDiagnostics("b/b.go"),
-			)
-		})
-	})
-}
-
-// Tests golang/go#38498. Delete a file and then force a reload.
-// Assert that we no longer try to load the file.
-func TestDeleteFiles(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- a/a.go --
-package a
-
-func _() {
-	var _ int
-}
--- a/a_unneeded.go --
-package a
-`
-	t.Run("close then delete", func(t *testing.T) {
-		WithOptions(
-			Settings{"verboseOutput": true},
-		).Run(t, pkg, func(t *testing.T, env *Env) {
-			env.OpenFile("a/a.go")
-			env.OpenFile("a/a_unneeded.go")
-			env.Await(
-				OnceMet(
-					env.DoneWithOpen(),
-					LogMatching(protocol.Info, "a_unneeded.go", 1, false),
-				),
-			)
-
-			// Close and delete the open file, mimicking what an editor would do.
-			env.CloseBuffer("a/a_unneeded.go")
-			env.RemoveWorkspaceFile("a/a_unneeded.go")
-			env.RegexpReplace("a/a.go", "var _ int", "fmt.Println(\"\")")
-			env.Await(
-				env.DiagnosticAtRegexp("a/a.go", "fmt"),
-			)
-			env.SaveBuffer("a/a.go")
-			env.Await(
-				OnceMet(
-					env.DoneWithSave(),
-					// There should only be one log message containing
-					// a_unneeded.go, from the initial workspace load, which we
-					// check for earlier. If there are more, there's a bug.
-					LogMatching(protocol.Info, "a_unneeded.go", 1, false),
-				),
-				EmptyDiagnostics("a/a.go"),
-			)
-		})
-	})
-
-	t.Run("delete then close", func(t *testing.T) {
-		WithOptions(
-			Settings{"verboseOutput": true},
-		).Run(t, pkg, func(t *testing.T, env *Env) {
-			env.OpenFile("a/a.go")
-			env.OpenFile("a/a_unneeded.go")
-			env.Await(
-				OnceMet(
-					env.DoneWithOpen(),
-					LogMatching(protocol.Info, "a_unneeded.go", 1, false),
-				),
-			)
-
-			// Delete and then close the file.
-			env.RemoveWorkspaceFile("a/a_unneeded.go")
-			env.CloseBuffer("a/a_unneeded.go")
-			env.RegexpReplace("a/a.go", "var _ int", "fmt.Println(\"\")")
-			env.Await(
-				env.DiagnosticAtRegexp("a/a.go", "fmt"),
-			)
-			env.SaveBuffer("a/a.go")
-			env.Await(
-				OnceMet(
-					env.DoneWithSave(),
-					// There should only be one log message containing
-					// a_unneeded.go, from the initial workspace load, which we
-					// check for earlier. If there are more, there's a bug.
-					LogMatching(protocol.Info, "a_unneeded.go", 1, false),
-				),
-				EmptyDiagnostics("a/a.go"),
-			)
-		})
-	})
-}
-
-// This change reproduces the behavior of switching branches, with multiple
-// files being created and deleted. The key change here is the movement of a
-// symbol from one file to another in a given package through a deletion and
-// creation. To reproduce an issue with metadata invalidation in batched
-// changes, the last change in the batch is an on-disk file change that doesn't
-// require metadata invalidation.
-func TestMoveSymbol(t *testing.T) {
-	const pkg = `
--- go.mod --
-module mod.com
-
-go 1.14
--- main.go --
-package main
-
-import "mod.com/a"
-
-func main() {
-	var x int
-	x = a.Hello
-	println(x)
-}
--- a/a1.go --
-package a
-
-var Hello int
--- a/a2.go --
-package a
-
-func _() {}
-`
-	Run(t, pkg, func(t *testing.T, env *Env) {
-		env.WriteWorkspaceFile("a/a3.go", "package a\n\nvar Hello int\n")
-		env.RemoveWorkspaceFile("a/a1.go")
-		env.WriteWorkspaceFile("a/a2.go", "package a; func _() {};")
-		env.AfterChange(
-			NoDiagnostics("main.go"),
-		)
-	})
-}
-
-// Reproduce golang/go#40456.
-func TestChangeVersion(t *testing.T) {
-	const proxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-const Name = "Blah"
-
-func X(x int) {}
--- example.com@v1.2.2/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.2/blah/blah.go --
-package blah
-
-const Name = "Blah"
-
-func X() {}
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/blah/blah.go --
-package hello
-
-const Name = "Hello"
-`
-	const mod = `
--- go.mod --
-module mod.com
-
-go 1.12
-
-require example.com v1.2.2
--- go.sum --
-example.com v1.2.3 h1:OnPPkx+rW63kj9pgILsu12MORKhSlnFa3DVRJq1HZ7g=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- main.go --
-package main
-
-import "example.com/blah"
-
-func main() {
-	blah.X()
-}
-`
-	WithOptions(ProxyFiles(proxy)).Run(t, mod, func(t *testing.T, env *Env) {
-		env.WriteWorkspaceFiles(map[string]string{
-			"go.mod": `module mod.com
-
-go 1.12
-
-require example.com v1.2.3
-`,
-			"main.go": `package main
-
-import (
-	"example.com/blah"
-)
-
-func main() {
-	blah.X(1)
-}
-`,
-		})
-		env.AfterChange(
-			env.DoneWithChangeWatchedFiles(),
-			EmptyOrNoDiagnostics("main.go"),
-		)
-	})
-}
-
-// Reproduces golang/go#40340.
-func TestSwitchFromGOPATHToModuleMode(t *testing.T) {
-	const files = `
--- foo/blah/blah.go --
-package blah
-
-const Name = ""
--- main.go --
-package main
-
-import "foo/blah"
-
-func main() {
-	_ = blah.Name
-}
-`
-	WithOptions(
-		InGOPATH(),
-		Modes(Default), // golang/go#57521: this test is temporarily failing in 'experimental' mode
-		EnvVars{"GO111MODULE": "auto"},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.AfterChange(
-			EmptyDiagnostics("main.go"),
-		)
-		if err := env.Sandbox.RunGoCommand(env.Ctx, "", "mod", []string{"init", "mod.com"}, true); err != nil {
-			t.Fatal(err)
-		}
-
-		// TODO(golang/go#57558, golang/go#57512): file watching is asynchronous,
-		// and we must wait for the view to be reconstructed before touching
-		// main.go, so that the new view "knows" about main.go. This is a bug, but
-		// awaiting the change here avoids it.
-		env.AfterChange()
-
-		env.RegexpReplace("main.go", `"foo/blah"`, `"mod.com/foo/blah"`)
-		env.AfterChange(
-			EmptyDiagnostics("main.go"),
-		)
-	})
-}
-
-// Reproduces golang/go#40487.
-func TestSwitchFromModulesToGOPATH(t *testing.T) {
-	const files = `
--- foo/go.mod --
-module mod.com
-
-go 1.14
--- foo/blah/blah.go --
-package blah
-
-const Name = ""
--- foo/main.go --
-package main
-
-import "mod.com/blah"
-
-func main() {
-	_ = blah.Name
-}
-`
-	WithOptions(
-		InGOPATH(),
-		EnvVars{"GO111MODULE": "auto"},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("foo/main.go")
-		env.RemoveWorkspaceFile("foo/go.mod")
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				env.DiagnosticAtRegexp("foo/main.go", `"mod.com/blah"`),
-			),
-		)
-		env.RegexpReplace("foo/main.go", `"mod.com/blah"`, `"foo/blah"`)
-		env.Await(
-			EmptyDiagnostics("foo/main.go"),
-		)
-	})
-}
-
-func TestNewSymbolInTestVariant(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- a/a.go --
-package a
-
-func bob() {}
--- a/a_test.go --
-package a
-
-import "testing"
-
-func TestBob(t *testing.T) {
-	bob()
-}
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		// Add a new symbol to the package under test and use it in the test
-		// variant. Expect no diagnostics.
-		env.WriteWorkspaceFiles(map[string]string{
-			"a/a.go": `package a
-
-func bob() {}
-func george() {}
-`,
-			"a/a_test.go": `package a
-
-import "testing"
-
-func TestAll(t *testing.T) {
-	bob()
-	george()
-}
-`,
-		})
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				EmptyOrNoDiagnostics("a/a.go"),
-			),
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				EmptyOrNoDiagnostics("a/a_test.go"),
-			),
-		)
-		// Now, add a new file to the test variant and use its symbol in the
-		// original test file. Expect no diagnostics.
-		env.WriteWorkspaceFiles(map[string]string{
-			"a/a_test.go": `package a
-
-import "testing"
-
-func TestAll(t *testing.T) {
-	bob()
-	george()
-	hi()
-}
-`,
-			"a/a2_test.go": `package a
-
-import "testing"
-
-func hi() {}
-
-func TestSomething(t *testing.T) {}
-`,
-		})
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				EmptyOrNoDiagnostics("a/a_test.go"),
-			),
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				EmptyOrNoDiagnostics("a/a2_test.go"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/workspace/broken_test.go b/gopls/internal/regtest/workspace/broken_test.go
--- a/gopls/internal/regtest/workspace/broken_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/workspace/broken_test.go	1969-12-31 16:00:00
@@ -1,267 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package workspace
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/lsp"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/testenv"
-)
-
-// This file holds various tests for UX with respect to broken workspaces.
-//
-// TODO: consolidate other tests here.
-//
-// TODO: write more tests:
-//  - an explicit GOWORK value that doesn't exist
-//  - using modules and/or GOWORK inside of GOPATH?
-
-// Test for golang/go#53933
-func TestBrokenWorkspace_DuplicateModules(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-
-	// This proxy module content is replaced by the workspace, but is still
-	// required for module resolution to function in the Go command.
-	const proxy = `
--- example.com/foo@v0.0.1/go.mod --
-module example.com/foo
-
-go 1.12
-`
-
-	const src = `
--- go.work --
-go 1.18
-
-use (
-	./package1
-	./package1/vendor/example.com/foo
-	./package2
-	./package2/vendor/example.com/foo
-)
-
--- package1/go.mod --
-module mod.test
-
-go 1.18
-
-require example.com/foo v0.0.1
--- package1/main.go --
-package main
-
-import "example.com/foo"
-
-func main() {
-	_ = foo.CompleteMe
-}
--- package1/vendor/example.com/foo/go.mod --
-module example.com/foo
-
-go 1.18
--- package1/vendor/example.com/foo/foo.go --
-package foo
-
-const CompleteMe = 111
--- package2/go.mod --
-module mod2.test
-
-go 1.18
-
-require example.com/foo v0.0.1
--- package2/main.go --
-package main
-
-import "example.com/foo"
-
-func main() {
-	_ = foo.CompleteMe
-}
--- package2/vendor/example.com/foo/go.mod --
-module example.com/foo
-
-go 1.18
--- package2/vendor/example.com/foo/foo.go --
-package foo
-
-const CompleteMe = 222
-`
-
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("package1/main.go")
-		env.Await(
-			OutstandingWork(lsp.WorkspaceLoadFailure, `found module "example.com/foo" multiple times in the workspace`),
-		)
-
-		// Remove the redundant vendored copy of example.com.
-		env.WriteWorkspaceFile("go.work", `go 1.18
-		use (
-			./package1
-			./package2
-			./package2/vendor/example.com/foo
-		)
-		`)
-		env.Await(NoOutstandingWork())
-
-		// Check that definitions in package1 go to the copy vendored in package2.
-		location, _ := env.GoToDefinition("package1/main.go", env.RegexpSearch("package1/main.go", "CompleteMe"))
-		const wantLocation = "package2/vendor/example.com/foo/foo.go"
-		if !strings.HasSuffix(location, wantLocation) {
-			t.Errorf("got definition of CompleteMe at %q, want %q", location, wantLocation)
-		}
-	})
-}
-
-// Test for golang/go#43186: correcting the module path should fix errors
-// without restarting gopls.
-func TestBrokenWorkspace_WrongModulePath(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.testx
-
-go 1.18
--- p/internal/foo/foo.go --
-package foo
-
-const C = 1
--- p/internal/bar/bar.go --
-package bar
-
-import "mod.test/p/internal/foo"
-
-const D = foo.C + 1
--- p/internal/bar/bar_test.go --
-package bar_test
-
-import (
-	"mod.test/p/internal/foo"
-	. "mod.test/p/internal/bar"
-)
-
-const E = D + foo.C
--- p/internal/baz/baz_test.go --
-package baz_test
-
-import (
-	named "mod.test/p/internal/bar"
-)
-
-const F = named.D - 3
-`
-
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("p/internal/bar/bar.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexp("p/internal/bar/bar.go", "\"mod.test/p/internal/foo\""),
-			),
-		)
-		env.OpenFile("go.mod")
-		env.RegexpReplace("go.mod", "mod.testx", "mod.test")
-		env.SaveBuffer("go.mod") // saving triggers a reload
-		env.Await(NoOutstandingDiagnostics())
-	})
-}
-
-func TestMultipleModules_Warning(t *testing.T) {
-	msgForVersion := func(ver int) string {
-		if ver >= 18 {
-			return `gopls was not able to find modules in your workspace.`
-		} else {
-			return `gopls requires a module at the root of your workspace.`
-		}
-	}
-
-	const modules = `
--- a/go.mod --
-module a.com
-
-go 1.12
--- a/a.go --
-package a
--- a/empty.go --
-// an empty file
--- b/go.mod --
-module b.com
-
-go 1.12
--- b/b.go --
-package b
-`
-	for _, go111module := range []string{"on", "auto"} {
-		t.Run("GO111MODULE="+go111module, func(t *testing.T) {
-			WithOptions(
-				Modes(Default),
-				EnvVars{"GO111MODULE": go111module},
-			).Run(t, modules, func(t *testing.T, env *Env) {
-				ver := env.GoVersion()
-				msg := msgForVersion(ver)
-				env.OpenFile("a/a.go")
-				env.OpenFile("a/empty.go")
-				env.OpenFile("b/go.mod")
-				env.AfterChange(
-					env.DiagnosticAtRegexp("a/a.go", "package a"),
-					env.DiagnosticAtRegexp("b/go.mod", "module b.com"),
-					OutstandingWork(lsp.WorkspaceLoadFailure, msg),
-				)
-
-				// Changing the workspace folders to the valid modules should resolve
-				// the workspace errors and diagnostics.
-				//
-				// TODO(rfindley): verbose work tracking doesn't follow changing the
-				// workspace folder, therefore we can't invoke AfterChange here.
-				env.ChangeWorkspaceFolders("a", "b")
-				env.Await(
-					EmptyDiagnostics("a/a.go"),
-					EmptyDiagnostics("b/go.mod"),
-					NoOutstandingWork(),
-				)
-
-				env.ChangeWorkspaceFolders(".")
-
-				// TODO(rfindley): when GO111MODULE=auto, we need to open or change a
-				// file here in order to detect a critical error. This is because gopls
-				// has forgotten about a/a.go, and therefore doesn't hit the heuristic
-				// "all packages are command-line-arguments".
-				//
-				// This is broken, and could be fixed by adjusting the heuristic to
-				// account for the scenario where there are *no* workspace packages, or
-				// (better) trying to get workspace packages for each open file. See
-				// also golang/go#54261.
-				env.OpenFile("b/b.go")
-				env.Await(
-					// TODO(rfindley): fix these missing diagnostics.
-					// env.DiagnosticAtRegexp("a/a.go", "package a"),
-					// env.DiagnosticAtRegexp("b/go.mod", "module b.com"),
-					env.DiagnosticAtRegexp("b/b.go", "package b"),
-					OutstandingWork(lsp.WorkspaceLoadFailure, msg),
-				)
-			})
-		})
-	}
-
-	// Expect no warning if GO111MODULE=auto in a directory in GOPATH.
-	t.Run("GOPATH_GO111MODULE_auto", func(t *testing.T) {
-		WithOptions(
-			Modes(Default),
-			EnvVars{"GO111MODULE": "auto"},
-			InGOPATH(),
-		).Run(t, modules, func(t *testing.T, env *Env) {
-			env.OpenFile("a/a.go")
-			env.Await(
-				OnceMet(
-					env.DoneWithOpen(),
-					EmptyDiagnostics("a/a.go"),
-				),
-				NoOutstandingWork(),
-			)
-		})
-	})
-}
diff -urN a/gopls/internal/regtest/workspace/directoryfilters_test.go b/gopls/internal/regtest/workspace/directoryfilters_test.go
--- a/gopls/internal/regtest/workspace/directoryfilters_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/workspace/directoryfilters_test.go	1969-12-31 16:00:00
@@ -1,252 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package workspace
-
-import (
-	"sort"
-	"strings"
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// This file contains regression tests for the directoryFilters setting.
-//
-// TODO:
-//  - consolidate some of these tests into a single test
-//  - add more tests for changing directory filters
-
-func TestDirectoryFilters(t *testing.T) {
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		WorkspaceFolders("pkg"),
-		Settings{
-			"directoryFilters": []string{"-inner"},
-		},
-	).Run(t, workspaceModule, func(t *testing.T, env *Env) {
-		syms := env.WorkspaceSymbol("Hi")
-		sort.Slice(syms, func(i, j int) bool { return syms[i].ContainerName < syms[j].ContainerName })
-		for _, s := range syms {
-			if strings.Contains(s.ContainerName, "inner") {
-				t.Errorf("WorkspaceSymbol: found symbol %q with container %q, want \"inner\" excluded", s.Name, s.ContainerName)
-			}
-		}
-	})
-}
-
-func TestDirectoryFiltersLoads(t *testing.T) {
-	// exclude, and its error, should be excluded from the workspace.
-	const files = `
--- go.mod --
-module example.com
-
-go 1.12
--- exclude/exclude.go --
-package exclude
-
-const _ = Nonexistant
-`
-
-	WithOptions(
-		Settings{"directoryFilters": []string{"-exclude"}},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(NoDiagnostics("exclude/x.go"))
-	})
-}
-
-func TestDirectoryFiltersTransitiveDep(t *testing.T) {
-	// Even though exclude is excluded from the workspace, it should
-	// still be importable as a non-workspace package.
-	const files = `
--- go.mod --
-module example.com
-
-go 1.12
--- include/include.go --
-package include
-import "example.com/exclude"
-
-const _ = exclude.X
--- exclude/exclude.go --
-package exclude
-
-const _ = Nonexistant // should be ignored, since this is a non-workspace package
-const X = 1
-`
-
-	WithOptions(
-		Settings{"directoryFilters": []string{"-exclude"}},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(
-			NoDiagnostics("exclude/exclude.go"), // filtered out
-			NoDiagnostics("include/include.go"), // successfully builds
-		)
-	})
-}
-
-func TestDirectoryFiltersWorkspaceModules(t *testing.T) {
-	// Define a module include.com which should be in the workspace, plus a
-	// module exclude.com which should be excluded and therefore come from
-	// the proxy.
-	const files = `
--- include/go.mod --
-module include.com
-
-go 1.12
-
-require exclude.com v1.0.0
-
--- include/go.sum --
-exclude.com v1.0.0 h1:Q5QSfDXY5qyNCBeUiWovUGqcLCRZKoTs9XdBeVz+w1I=
-exclude.com v1.0.0/go.mod h1:hFox2uDlNB2s2Jfd9tHlQVfgqUiLVTmh6ZKat4cvnj4=
-
--- include/include.go --
-package include
-
-import "exclude.com"
-
-var _ = exclude.X // satisfied only by the workspace version
--- exclude/go.mod --
-module exclude.com
-
-go 1.12
--- exclude/exclude.go --
-package exclude
-
-const X = 1
-`
-	const proxy = `
--- exclude.com@v1.0.0/go.mod --
-module exclude.com
-
-go 1.12
--- exclude.com@v1.0.0/exclude.go --
-package exclude
-`
-	WithOptions(
-		Modes(Experimental),
-		ProxyFiles(proxy),
-		Settings{"directoryFilters": []string{"-exclude"}},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.Await(env.DiagnosticAtRegexp("include/include.go", `exclude.(X)`))
-	})
-}
-
-// Test for golang/go#46438: support for '**' in directory filters.
-func TestDirectoryFilters_Wildcard(t *testing.T) {
-	filters := []string{"-**/bye"}
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		WorkspaceFolders("pkg"),
-		Settings{
-			"directoryFilters": filters,
-		},
-	).Run(t, workspaceModule, func(t *testing.T, env *Env) {
-		syms := env.WorkspaceSymbol("Bye")
-		sort.Slice(syms, func(i, j int) bool { return syms[i].ContainerName < syms[j].ContainerName })
-		for _, s := range syms {
-			if strings.Contains(s.ContainerName, "bye") {
-				t.Errorf("WorkspaceSymbol: found symbol %q with container %q with filters %v", s.Name, s.ContainerName, filters)
-			}
-		}
-	})
-}
-
-// Test for golang/go#52993: wildcard directoryFilters should apply to
-// goimports scanning as well.
-func TestDirectoryFilters_ImportScanning(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.test
-
-go 1.12
--- main.go --
-package main
-
-func main() {
-	bye.Goodbye()
-}
--- p/bye/bye.go --
-package bye
-
-func Goodbye() {}
-`
-
-	WithOptions(
-		Settings{
-			"directoryFilters": []string{"-**/bye"},
-		},
-		// This test breaks in 'Experimental' mode, because with
-		// experimentalWorkspaceModule set we the goimports scan behaves
-		// differently.
-		//
-		// Since this feature is going away (golang/go#52897), don't investigate.
-		Modes(Default),
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		beforeSave := env.BufferText("main.go")
-		env.OrganizeImports("main.go")
-		got := env.BufferText("main.go")
-		if got != beforeSave {
-			t.Errorf("after organizeImports code action, got modified buffer:\n%s", got)
-		}
-	})
-}
-
-// Test for golang/go#52993: non-wildcard directoryFilters should still be
-// applied relative to the workspace folder, not the module root.
-func TestDirectoryFilters_MultiRootImportScanning(t *testing.T) {
-	const files = `
--- go.work --
-go 1.18
-
-use (
-	a
-	b
-)
--- a/go.mod --
-module mod1.test
-
-go 1.18
--- a/main.go --
-package main
-
-func main() {
-	hi.Hi()
-}
--- a/hi/hi.go --
-package hi
-
-func Hi() {}
--- b/go.mod --
-module mod2.test
-
-go 1.18
--- b/main.go --
-package main
-
-func main() {
-	hi.Hi()
-}
--- b/hi/hi.go --
-package hi
-
-func Hi() {}
-`
-
-	WithOptions(
-		Settings{
-			"directoryFilters": []string{"-hi"}, // this test fails with -**/hi
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("a/main.go")
-		beforeSave := env.BufferText("a/main.go")
-		env.OrganizeImports("a/main.go")
-		got := env.BufferText("a/main.go")
-		if got == beforeSave {
-			t.Errorf("after organizeImports code action, got identical buffer:\n%s", got)
-		}
-	})
-}
diff -urN a/gopls/internal/regtest/workspace/fromenv_test.go b/gopls/internal/regtest/workspace/fromenv_test.go
--- a/gopls/internal/regtest/workspace/fromenv_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/workspace/fromenv_test.go	1969-12-31 16:00:00
@@ -1,56 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package workspace
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-// Test that setting go.work via environment variables or settings works.
-func TestUseGoWorkOutsideTheWorkspace(t *testing.T) {
-	const files = `
--- work/a/go.mod --
-module a.com
-
-go 1.12
--- work/a/a.go --
-package a
--- work/b/go.mod --
-module b.com
-
-go 1.12
--- work/b/b.go --
-package b
-
-func _() {
-	x := 1 // unused
-}
--- config/go.work --
-go 1.18
-
-use (
-	$SANDBOX_WORKDIR/work/a
-	$SANDBOX_WORKDIR/work/b
-)
-`
-
-	WithOptions(
-		EnvVars{"GOWORK": "$SANDBOX_WORKDIR/config/go.work"},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		// When we have an explicit GOWORK set, we should get a file watch request.
-		env.Await(FileWatchMatching(`config.go\.work`))
-		// Even though work/b is not open, we should get its diagnostics as it is
-		// included in the workspace.
-		env.OpenFile("work/a/a.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexpWithMessage("work/b/b.go", "x := 1", "not used"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/workspace/metadata_test.go b/gopls/internal/regtest/workspace/metadata_test.go
--- a/gopls/internal/regtest/workspace/metadata_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/workspace/metadata_test.go	1969-12-31 16:00:00
@@ -1,111 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package workspace
-
-import (
-	"testing"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-	"golang.org/x/tools/internal/testenv"
-)
-
-// TODO(rfindley): move workspace tests related to metadata bugs into this
-// file.
-
-func TestFixImportDecl(t *testing.T) {
-	const src = `
--- go.mod --
-module mod.test
-
-go 1.12
--- p.go --
-package p
-
-import (
-	_ "fmt"
-
-const C = 42
-`
-
-	Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("p.go")
-		env.RegexpReplace("p.go", "\"fmt\"", "\"fmt\"\n)")
-		env.Await(OnceMet(
-			env.DoneWithChange(),
-			EmptyDiagnostics("p.go"),
-		))
-	})
-}
-
-// Test that moving ignoring a file via build constraints causes diagnostics to
-// be resolved.
-func TestIgnoreFile(t *testing.T) {
-	testenv.NeedsGo1Point(t, 17) // needs native overlays and support for go:build directives
-
-	const src = `
--- go.mod --
-module mod.test
-
-go 1.12
--- foo.go --
-package main
-
-func main() {}
--- bar.go --
-package main
-
-func main() {}
-	`
-
-	WithOptions(
-		// TODO(golang/go#54180): we don't run in 'experimental' mode here, because
-		// with "experimentalUseInvalidMetadata", this test fails because the
-		// orphaned bar.go is diagnosed using stale metadata, and then not
-		// re-diagnosed when new metadata arrives.
-		//
-		// We could fix this by re-running diagnostics after a load, but should
-		// consider whether that is worthwhile.
-		Modes(Default),
-	).Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("foo.go")
-		env.OpenFile("bar.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexp("foo.go", "func (main)"),
-				env.DiagnosticAtRegexp("bar.go", "func (main)"),
-			),
-		)
-
-		// Ignore bar.go. This should resolve diagnostics.
-		env.RegexpReplace("bar.go", "package main", "//go:build ignore\n\npackage main")
-
-		// To make this test pass with experimentalUseInvalidMetadata, we could make
-		// an arbitrary edit that invalidates the snapshot, at which point the
-		// orphaned diagnostics will be invalidated.
-		//
-		// But of course, this should not be necessary: we should invalidate stale
-		// information when fresh metadata arrives.
-		// env.RegexpReplace("foo.go", "package main", "package main // test")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				EmptyDiagnostics("foo.go"),
-				EmptyDiagnostics("bar.go"),
-			),
-		)
-
-		// If instead of 'ignore' (which gopls treats as a standalone package) we
-		// used a different build tag, we should get a warning about having no
-		// packages for bar.go
-		env.RegexpReplace("bar.go", "ignore", "excluded")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				env.DiagnosticAtRegexpWithMessage("bar.go", "package (main)", "No packages"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/workspace/standalone_test.go b/gopls/internal/regtest/workspace/standalone_test.go
--- a/gopls/internal/regtest/workspace/standalone_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/workspace/standalone_test.go	1969-12-31 16:00:00
@@ -1,244 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package workspace
-
-import (
-	"sort"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestStandaloneFiles(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.test
-
-go 1.16
--- lib/lib.go --
-package lib
-
-const C = 0
-
-type I interface {
-	M()
-}
--- lib/ignore.go --
-//go:build ignore
-// +build ignore
-
-package main
-
-import (
-	"mod.test/lib"
-)
-
-const C = 1
-
-type Mer struct{}
-func (Mer) M()
-
-func main() {
-	println(lib.C + C)
-}
-`
-	WithOptions(
-		// On Go 1.17 and earlier, this test fails with
-		// experimentalWorkspaceModule. Not investigated, as
-		// experimentalWorkspaceModule will be removed.
-		Modes(Default),
-	).Run(t, files, func(t *testing.T, env *Env) {
-		// Initially, gopls should not know about the standalone file as it hasn't
-		// been opened. Therefore, we should only find one symbol 'C'.
-		syms := env.WorkspaceSymbol("C")
-		if got, want := len(syms), 1; got != want {
-			t.Errorf("got %d symbols, want %d", got, want)
-		}
-
-		// Similarly, we should only find one reference to "C", and no
-		// implementations of I.
-		checkLocations := func(method string, gotLocations []protocol.Location, wantFiles ...string) {
-			var gotFiles []string
-			for _, l := range gotLocations {
-				gotFiles = append(gotFiles, env.Sandbox.Workdir.URIToPath(l.URI))
-			}
-			sort.Strings(gotFiles)
-			sort.Strings(wantFiles)
-			if diff := cmp.Diff(wantFiles, gotFiles); diff != "" {
-				t.Errorf("%s(...): unexpected locations (-want +got):\n%s", method, diff)
-			}
-		}
-
-		env.OpenFile("lib/lib.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				NoOutstandingDiagnostics(),
-			),
-		)
-
-		// Replacing C with D should not cause any workspace diagnostics, since we
-		// haven't yet opened the standalone file.
-		env.RegexpReplace("lib/lib.go", "C", "D")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				NoOutstandingDiagnostics(),
-			),
-		)
-		env.RegexpReplace("lib/lib.go", "D", "C")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				NoOutstandingDiagnostics(),
-			),
-		)
-
-		refs := env.References("lib/lib.go", env.RegexpSearch("lib/lib.go", "C"))
-		checkLocations("References", refs, "lib/lib.go")
-
-		impls := env.Implementations("lib/lib.go", env.RegexpSearch("lib/lib.go", "I"))
-		checkLocations("Implementations", impls) // no implementations
-
-		// Opening the standalone file should not result in any diagnostics.
-		env.OpenFile("lib/ignore.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				NoOutstandingDiagnostics(),
-			),
-		)
-
-		// Having opened the standalone file, we should find its symbols in the
-		// workspace.
-		syms = env.WorkspaceSymbol("C")
-		if got, want := len(syms), 2; got != want {
-			t.Fatalf("got %d symbols, want %d", got, want)
-		}
-
-		foundMainC := false
-		var symNames []string
-		for _, sym := range syms {
-			symNames = append(symNames, sym.Name)
-			if sym.Name == "main.C" {
-				foundMainC = true
-			}
-		}
-		if !foundMainC {
-			t.Errorf("WorkspaceSymbol(\"C\") = %v, want containing main.C", symNames)
-		}
-
-		// We should resolve workspace definitions in the standalone file.
-		file, _ := env.GoToDefinition("lib/ignore.go", env.RegexpSearch("lib/ignore.go", "lib.(C)"))
-		if got, want := file, "lib/lib.go"; got != want {
-			t.Errorf("GoToDefinition(lib.C) = %v, want %v", got, want)
-		}
-
-		// ...as well as intra-file definitions
-		file, pos := env.GoToDefinition("lib/ignore.go", env.RegexpSearch("lib/ignore.go", "\\+ (C)"))
-		if got, want := file, "lib/ignore.go"; got != want {
-			t.Errorf("GoToDefinition(C) = %v, want %v", got, want)
-		}
-		wantPos := env.RegexpSearch("lib/ignore.go", "const (C)")
-		if pos != wantPos {
-			t.Errorf("GoToDefinition(C) = %v, want %v", pos, wantPos)
-		}
-
-		// Renaming "lib.C" to "lib.D" should cause a diagnostic in the standalone
-		// file.
-		env.RegexpReplace("lib/lib.go", "C", "D")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				env.DiagnosticAtRegexp("lib/ignore.go", "lib.(C)"),
-			),
-		)
-
-		// Undoing the replacement should fix diagnostics
-		env.RegexpReplace("lib/lib.go", "D", "C")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				NoOutstandingDiagnostics(),
-			),
-		)
-
-		// Now that our workspace has no errors, we should be able to find
-		// references and rename.
-		refs = env.References("lib/lib.go", env.RegexpSearch("lib/lib.go", "C"))
-		checkLocations("References", refs, "lib/lib.go", "lib/ignore.go")
-
-		impls = env.Implementations("lib/lib.go", env.RegexpSearch("lib/lib.go", "I"))
-		checkLocations("Implementations", impls, "lib/ignore.go")
-
-		// Renaming should rename in the standalone package.
-		env.Rename("lib/lib.go", env.RegexpSearch("lib/lib.go", "C"), "D")
-		env.RegexpSearch("lib/ignore.go", "lib.D")
-	})
-}
-
-func TestStandaloneFiles_Configuration(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.test
-
-go 1.18
--- lib.go --
-package lib // without this package, files are loaded as command-line-arguments
--- ignore.go --
-//go:build ignore
-// +build ignore
-
-package main
-
-// An arbitrary comment.
-
-func main() {}
--- standalone.go --
-//go:build standalone
-// +build standalone
-
-package main
-
-func main() {}
-`
-
-	WithOptions(
-		Settings{
-			"standaloneTags": []string{"standalone", "script"},
-		},
-	).Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("ignore.go")
-		env.OpenFile("standalone.go")
-
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexp("ignore.go", "package (main)"),
-				EmptyOrNoDiagnostics("standalone.go"),
-			),
-		)
-
-		cfg := env.Editor.Config()
-		cfg.Settings = map[string]interface{}{
-			"standaloneTags": []string{"ignore"},
-		}
-		env.ChangeConfiguration(cfg)
-
-		// TODO(golang/go#56158): gopls does not purge previously published
-		// diagnostice when configuration changes.
-		env.RegexpReplace("ignore.go", "arbitrary", "meaningless")
-
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				EmptyOrNoDiagnostics("ignore.go"),
-				env.DiagnosticAtRegexp("standalone.go", "package (main)"),
-			),
-		)
-	})
-}
diff -urN a/gopls/internal/regtest/workspace/workspace_test.go b/gopls/internal/regtest/workspace/workspace_test.go
--- a/gopls/internal/regtest/workspace/workspace_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/regtest/workspace/workspace_test.go	1969-12-31 16:00:00
@@ -1,1401 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package workspace
-
-import (
-	"context"
-	"fmt"
-	"path/filepath"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp"
-	"golang.org/x/tools/gopls/internal/lsp/fake"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/gocommand"
-	"golang.org/x/tools/internal/testenv"
-
-	. "golang.org/x/tools/gopls/internal/lsp/regtest"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	Main(m, hooks.Options)
-}
-
-const workspaceProxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-import "fmt"
-
-func SaySomething() {
-	fmt.Println("something")
-}
--- random.org@v1.2.3/go.mod --
-module random.org
-
-go 1.12
--- random.org@v1.2.3/bye/bye.go --
-package bye
-
-func Goodbye() {
-	println("Bye")
-}
-`
-
-// TODO: Add a replace directive.
-const workspaceModule = `
--- pkg/go.mod --
-module mod.com
-
-go 1.14
-
-require (
-	example.com v1.2.3
-	random.org v1.2.3
-)
--- pkg/go.sum --
-example.com v1.2.3 h1:veRD4tUnatQRgsULqULZPjeoBGFr2qBhevSCZllD2Ds=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
-random.org v1.2.3 h1:+JE2Fkp7gS0zsHXGEQJ7hraom3pNTlkxC4b2qPfA+/Q=
-random.org v1.2.3/go.mod h1:E9KM6+bBX2g5ykHZ9H27w16sWo3QwgonyjM44Dnej3I=
--- pkg/main.go --
-package main
-
-import (
-	"example.com/blah"
-	"mod.com/inner"
-	"random.org/bye"
-)
-
-func main() {
-	blah.SaySomething()
-	inner.Hi()
-	bye.Goodbye()
-}
--- pkg/main2.go --
-package main
-
-import "fmt"
-
-func _() {
-	fmt.Print("%s")
-}
--- pkg/inner/inner.go --
-package inner
-
-import "example.com/blah"
-
-func Hi() {
-	blah.SaySomething()
-}
--- goodbye/bye/bye.go --
-package bye
-
-func Bye() {}
--- goodbye/go.mod --
-module random.org
-
-go 1.12
-`
-
-// Confirm that find references returns all of the references in the module,
-// regardless of what the workspace root is.
-func TestReferences(t *testing.T) {
-	for _, tt := range []struct {
-		name, rootPath string
-	}{
-		{
-			name:     "module root",
-			rootPath: "pkg",
-		},
-		{
-			name:     "subdirectory",
-			rootPath: "pkg/inner",
-		},
-	} {
-		t.Run(tt.name, func(t *testing.T) {
-			opts := []RunOption{ProxyFiles(workspaceProxy)}
-			if tt.rootPath != "" {
-				opts = append(opts, WorkspaceFolders(tt.rootPath))
-			}
-			WithOptions(opts...).Run(t, workspaceModule, func(t *testing.T, env *Env) {
-				f := "pkg/inner/inner.go"
-				env.OpenFile(f)
-				locations := env.References(f, env.RegexpSearch(f, `SaySomething`))
-				want := 3
-				if got := len(locations); got != want {
-					t.Fatalf("expected %v locations, got %v", want, got)
-				}
-			})
-		})
-	}
-}
-
-// Make sure that analysis diagnostics are cleared for the whole package when
-// the only opened file is closed. This test was inspired by the experience in
-// VS Code, where clicking on a reference result triggers a
-// textDocument/didOpen without a corresponding textDocument/didClose.
-func TestClearAnalysisDiagnostics(t *testing.T) {
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		WorkspaceFolders("pkg/inner"),
-	).Run(t, workspaceModule, func(t *testing.T, env *Env) {
-		env.OpenFile("pkg/main.go")
-		env.Await(
-			env.DiagnosticAtRegexp("pkg/main2.go", "fmt.Print"),
-		)
-		env.CloseBuffer("pkg/main.go")
-		env.Await(
-			EmptyDiagnostics("pkg/main2.go"),
-		)
-	})
-}
-
-// TestReloadOnlyOnce checks that changes to the go.mod file do not result in
-// redundant package loads (golang/go#54473).
-//
-// Note that this test may be fragile, as it depends on specific structure to
-// log messages around reinitialization. Nevertheless, it is important for
-// guarding against accidentally duplicate reloading.
-func TestReloadOnlyOnce(t *testing.T) {
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		WorkspaceFolders("pkg"),
-	).Run(t, workspaceModule, func(t *testing.T, env *Env) {
-		dir := env.Sandbox.Workdir.URI("goodbye").SpanURI().Filename()
-		goModWithReplace := fmt.Sprintf(`%s
-replace random.org => %s
-`, env.ReadWorkspaceFile("pkg/go.mod"), dir)
-		env.WriteWorkspaceFile("pkg/go.mod", goModWithReplace)
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				LogMatching(protocol.Info, `packages\.Load #\d+\n`, 2, false),
-			),
-		)
-	})
-}
-
-// This test checks that gopls updates the set of files it watches when a
-// replace target is added to the go.mod.
-func TestWatchReplaceTargets(t *testing.T) {
-	t.Skipf("skipping known-flaky test: see https://go.dev/issue/50748")
-
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-		WorkspaceFolders("pkg"),
-	).Run(t, workspaceModule, func(t *testing.T, env *Env) {
-		// Add a replace directive and expect the files that gopls is watching
-		// to change.
-		dir := env.Sandbox.Workdir.URI("goodbye").SpanURI().Filename()
-		goModWithReplace := fmt.Sprintf(`%s
-replace random.org => %s
-`, env.ReadWorkspaceFile("pkg/go.mod"), dir)
-		env.WriteWorkspaceFile("pkg/go.mod", goModWithReplace)
-		env.Await(
-			env.DoneWithChangeWatchedFiles(),
-			UnregistrationMatching("didChangeWatchedFiles"),
-			RegistrationMatching("didChangeWatchedFiles"),
-		)
-	})
-}
-
-const workspaceModuleProxy = `
--- example.com@v1.2.3/go.mod --
-module example.com
-
-go 1.12
--- example.com@v1.2.3/blah/blah.go --
-package blah
-
-import "fmt"
-
-func SaySomething() {
-	fmt.Println("something")
-}
--- b.com@v1.2.3/go.mod --
-module b.com
-
-go 1.12
--- b.com@v1.2.3/b/b.go --
-package b
-
-func Hello() {}
-`
-
-func TestAutomaticWorkspaceModule_Interdependent(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	const multiModule = `
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
--- moda/a/go.sum --
-b.com v1.2.3 h1:tXrlXP0rnjRpKNmkbLYoWBdq0ikb3C3bKK9//moAWBI=
-b.com v1.2.3/go.mod h1:D+J7pfFBZK5vdIdZEFquR586vKKIkqG7Qjw9AxG5BQ8=
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
--- modb/go.mod --
-module b.com
-
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceModuleProxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		env.RunGoCommand("work", "init")
-		env.RunGoCommand("work", "use", "-r", ".")
-		env.AfterChange(
-			env.DiagnosticAtRegexp("moda/a/a.go", "x"),
-			env.DiagnosticAtRegexp("modb/b/b.go", "x"),
-			env.NoDiagnosticAtRegexp("moda/a/a.go", `"b.com/b"`),
-		)
-	})
-}
-
-func TestModuleWithExclude(t *testing.T) {
-	const proxy = `
--- c.com@v1.2.3/go.mod --
-module c.com
-
-go 1.12
-
-require b.com v1.2.3
--- c.com@v1.2.3/blah/blah.go --
-package blah
-
-import "fmt"
-
-func SaySomething() {
-	fmt.Println("something")
-}
--- b.com@v1.2.3/go.mod --
-module b.com
-
-go 1.12
--- b.com@v1.2.4/b/b.go --
-package b
-
-func Hello() {}
--- b.com@v1.2.4/go.mod --
-module b.com
-
-go 1.12
-`
-	const multiModule = `
--- go.mod --
-module a.com
-
-require c.com v1.2.3
-
-exclude b.com v1.2.3
--- go.sum --
-c.com v1.2.3 h1:n07Dz9fYmpNqvZMwZi5NEqFcSHbvLa9lacMX+/g25tw=
-c.com v1.2.3/go.mod h1:/4TyYgU9Nu5tA4NymP5xyqE8R2VMzGD3TbJCwCOvHAg=
--- main.go --
-package a
-
-func main() {
-	var x int
-}
-`
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		env.Await(
-			env.DiagnosticAtRegexp("main.go", "x"),
-		)
-	})
-}
-
-// This change tests that the version of the module used changes after it has
-// been deleted from the workspace.
-//
-// TODO(golang/go#55331): delete this placeholder along with experimental
-// workspace module.
-func TestDeleteModule_Interdependent(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	const multiModule = `
--- go.work --
-go 1.18
-
-use (
-	moda/a
-	modb
-)
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
--- moda/a/go.sum --
-b.com v1.2.3 h1:tXrlXP0rnjRpKNmkbLYoWBdq0ikb3C3bKK9//moAWBI=
-b.com v1.2.3/go.mod h1:D+J7pfFBZK5vdIdZEFquR586vKKIkqG7Qjw9AxG5BQ8=
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
--- modb/go.mod --
-module b.com
-
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceModuleProxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		env.OpenFile("moda/a/a.go")
-		env.Await(env.DoneWithOpen())
-
-		original, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-		if want := "modb/b/b.go"; !strings.HasSuffix(original, want) {
-			t.Errorf("expected %s, got %v", want, original)
-		}
-		env.CloseBuffer(original)
-		env.AfterChange()
-
-		env.RemoveWorkspaceFile("modb/b/b.go")
-		env.RemoveWorkspaceFile("modb/go.mod")
-		env.WriteWorkspaceFile("go.work", "go 1.18\nuse moda/a")
-		env.AfterChange()
-
-		got, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-		if want := "b.com@v1.2.3/b/b.go"; !strings.HasSuffix(got, want) {
-			t.Errorf("expected %s, got %v", want, got)
-		}
-	})
-}
-
-// Tests that the version of the module used changes after it has been added
-// to the workspace.
-func TestCreateModule_Interdependent(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	const multiModule = `
--- go.work --
-go 1.18
-
-use (
-	moda/a
-)
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
--- moda/a/go.sum --
-b.com v1.2.3 h1:tXrlXP0rnjRpKNmkbLYoWBdq0ikb3C3bKK9//moAWBI=
-b.com v1.2.3/go.mod h1:D+J7pfFBZK5vdIdZEFquR586vKKIkqG7Qjw9AxG5BQ8=
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceModuleProxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		env.OpenFile("moda/a/a.go")
-		original, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-		if want := "b.com@v1.2.3/b/b.go"; !strings.HasSuffix(original, want) {
-			t.Errorf("expected %s, got %v", want, original)
-		}
-		env.CloseBuffer(original)
-		env.WriteWorkspaceFiles(map[string]string{
-			"go.work": `go 1.18
-
-use (
-	moda/a
-	modb
-)
-`,
-			"modb/go.mod": "module b.com",
-			"modb/b/b.go": `package b
-
-func Hello() int {
-	var x int
-}
-`,
-		})
-		env.AfterChange(env.DiagnosticAtRegexp("modb/b/b.go", "x"))
-		got, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-		if want := "modb/b/b.go"; !strings.HasSuffix(got, want) {
-			t.Errorf("expected %s, got %v", want, original)
-		}
-	})
-}
-
-// This test confirms that a gopls workspace can recover from initialization
-// with one invalid module.
-func TestOneBrokenModule(t *testing.T) {
-	t.Skip("golang/go#55331: this test is temporarily broken as go.work handling tries to build the workspace module")
-
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	const multiModule = `
--- go.work --
-go 1.18
-
-use (
-	moda/a
-	modb
-)
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
-
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
--- modb/go.mod --
-modul b.com // typo here
-
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceModuleProxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		env.OpenFile("modb/go.mod")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				DiagnosticAt("modb/go.mod", 0, 0),
-			),
-		)
-		env.RegexpReplace("modb/go.mod", "modul", "module")
-		env.SaveBufferWithoutActions("modb/go.mod")
-		env.Await(
-			env.DiagnosticAtRegexp("modb/b/b.go", "x"),
-		)
-	})
-}
-
-func TestUseGoplsMod(t *testing.T) {
-	// This test validates certain functionality related to using a gopls.mod
-	// file to specify workspace modules.
-	const multiModule = `
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
--- moda/a/go.sum --
-b.com v1.2.3 h1:tXrlXP0rnjRpKNmkbLYoWBdq0ikb3C3bKK9//moAWBI=
-b.com v1.2.3/go.mod h1:D+J7pfFBZK5vdIdZEFquR586vKKIkqG7Qjw9AxG5BQ8=
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
--- modb/go.mod --
-module b.com
-
-require example.com v1.2.3
--- modb/go.sum --
-example.com v1.2.3 h1:veRD4tUnatQRgsULqULZPjeoBGFr2qBhevSCZllD2Ds=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
--- gopls.mod --
-module gopls-workspace
-
-require (
-	a.com v0.0.0-goplsworkspace
-	b.com v1.2.3
-)
-
-replace a.com => $SANDBOX_WORKDIR/moda/a
-`
-	WithOptions(
-		ProxyFiles(workspaceModuleProxy),
-		Modes(Experimental),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		// Initially, the gopls.mod should cause only the a.com module to be
-		// loaded. Validate this by jumping to a definition in b.com and ensuring
-		// that we go to the module cache.
-		env.OpenFile("moda/a/a.go")
-		env.Await(env.DoneWithOpen())
-
-		// To verify which modules are loaded, we'll jump to the definition of
-		// b.Hello.
-		checkHelloLocation := func(want string) error {
-			location, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-			if !strings.HasSuffix(location, want) {
-				return fmt.Errorf("expected %s, got %v", want, location)
-			}
-			return nil
-		}
-
-		// Initially this should be in the module cache, as b.com is not replaced.
-		if err := checkHelloLocation("b.com@v1.2.3/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-
-		// Now, modify the gopls.mod file on disk to activate the b.com module in
-		// the workspace.
-		workdir := env.Sandbox.Workdir.RootURI().SpanURI().Filename()
-		env.WriteWorkspaceFile("gopls.mod", fmt.Sprintf(`module gopls-workspace
-
-require (
-	a.com v1.9999999.0-goplsworkspace
-	b.com v1.9999999.0-goplsworkspace
-)
-
-replace a.com => %s/moda/a
-replace b.com => %s/modb
-`, workdir, workdir))
-
-		// As of golang/go#54069, writing a gopls.mod to the workspace triggers a
-		// workspace reload.
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				env.DiagnosticAtRegexp("modb/b/b.go", "x"),
-			),
-		)
-
-		// Jumping to definition should now go to b.com in the workspace.
-		if err := checkHelloLocation("modb/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-
-		// Now, let's modify the gopls.mod *overlay* (not on disk), and verify that
-		// this change is only picked up once it is saved.
-		env.OpenFile("gopls.mod")
-		env.Await(env.DoneWithOpen())
-		env.SetBufferContent("gopls.mod", fmt.Sprintf(`module gopls-workspace
-
-require (
-	a.com v0.0.0-goplsworkspace
-)
-
-replace a.com => %s/moda/a
-`, workdir))
-
-		// Editing the gopls.mod removes modb from the workspace modules, and so
-		// should clear outstanding diagnostics...
-		env.Await(OnceMet(
-			env.DoneWithChange(),
-			EmptyDiagnostics("modb/go.mod"),
-		))
-		// ...but does not yet cause a workspace reload, so we should still jump to modb.
-		if err := checkHelloLocation("modb/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-		// Saving should reload the workspace.
-		env.SaveBufferWithoutActions("gopls.mod")
-		if err := checkHelloLocation("b.com@v1.2.3/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-	})
-}
-
-// TestBadGoWork exercises the panic from golang/vscode-go#2121.
-func TestBadGoWork(t *testing.T) {
-	const files = `
--- go.work --
-use ./bar
--- bar/go.mod --
-module example.com/bar
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.work")
-	})
-}
-
-func TestUseGoWork(t *testing.T) {
-	// This test validates certain functionality related to using a go.work
-	// file to specify workspace modules.
-	const multiModule = `
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
--- moda/a/go.sum --
-b.com v1.2.3 h1:tXrlXP0rnjRpKNmkbLYoWBdq0ikb3C3bKK9//moAWBI=
-b.com v1.2.3/go.mod h1:D+J7pfFBZK5vdIdZEFquR586vKKIkqG7Qjw9AxG5BQ8=
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
--- modb/go.mod --
-module b.com
-
-require example.com v1.2.3
--- modb/go.sum --
-example.com v1.2.3 h1:Yryq11hF02fEf2JlOS2eph+ICE2/ceevGV3C9dl5V/c=
-example.com v1.2.3/go.mod h1:Y2Rc5rVWjWur0h3pd9aEvK5Pof8YKDANh9gHA2Maujo=
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
--- go.work --
-go 1.17
-
-use (
-	./moda/a
-)
-`
-	WithOptions(
-		ProxyFiles(workspaceModuleProxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		// Initially, the go.work should cause only the a.com module to be
-		// loaded. Validate this by jumping to a definition in b.com and ensuring
-		// that we go to the module cache.
-		env.OpenFile("moda/a/a.go")
-		env.Await(env.DoneWithOpen())
-
-		// To verify which modules are loaded, we'll jump to the definition of
-		// b.Hello.
-		checkHelloLocation := func(want string) error {
-			location, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-			if !strings.HasSuffix(location, want) {
-				return fmt.Errorf("expected %s, got %v", want, location)
-			}
-			return nil
-		}
-
-		// Initially this should be in the module cache, as b.com is not replaced.
-		if err := checkHelloLocation("b.com@v1.2.3/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-
-		// Now, modify the go.work file on disk to activate the b.com module in
-		// the workspace.
-		env.WriteWorkspaceFile("go.work", `
-go 1.17
-
-use (
-	./moda/a
-	./modb
-)
-`)
-
-		// As of golang/go#54069, writing go.work to the workspace triggers a
-		// workspace reload.
-		env.Await(
-			OnceMet(
-				env.DoneWithChangeWatchedFiles(),
-				env.DiagnosticAtRegexp("modb/b/b.go", "x"),
-			),
-		)
-
-		// Jumping to definition should now go to b.com in the workspace.
-		if err := checkHelloLocation("modb/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-
-		// Now, let's modify the go.work *overlay* (not on disk), and verify that
-		// this change is only picked up once it is saved.
-		env.OpenFile("go.work")
-		env.Await(env.DoneWithOpen())
-		env.SetBufferContent("go.work", `go 1.17
-
-use (
-	./moda/a
-)`)
-
-		// Simply modifying the go.work file does not cause a reload, so we should
-		// still jump within the workspace.
-		//
-		// TODO: should editing the go.work above cause modb diagnostics to be
-		// suppressed?
-		env.Await(env.DoneWithChange())
-		if err := checkHelloLocation("modb/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-
-		// Saving should reload the workspace.
-		env.SaveBufferWithoutActions("go.work")
-		if err := checkHelloLocation("b.com@v1.2.3/b/b.go"); err != nil {
-			t.Fatal(err)
-		}
-
-		// This fails if guarded with a OnceMet(DoneWithSave(), ...), because it is
-		// debounced (and therefore not synchronous with the change).
-		env.Await(EmptyOrNoDiagnostics("modb/go.mod"))
-
-		// Test Formatting.
-		env.SetBufferContent("go.work", `go 1.18
-  use      (
-
-
-
-		./moda/a
-)
-`) // TODO(matloob): For some reason there's a "start position 7:0 is out of bounds" error when the ")" is on the last character/line in the file. Rob probably knows what's going on.
-		env.SaveBuffer("go.work")
-		env.Await(env.DoneWithSave())
-		gotWorkContents := env.ReadWorkspaceFile("go.work")
-		wantWorkContents := `go 1.18
-
-use (
-	./moda/a
-)
-`
-		if gotWorkContents != wantWorkContents {
-			t.Fatalf("formatted contents of workspace: got %q; want %q", gotWorkContents, wantWorkContents)
-		}
-	})
-}
-
-func TestUseGoWorkDiagnosticMissingModule(t *testing.T) {
-	const files = `
--- go.work --
-go 1.18
-
-use ./foo
--- bar/go.mod --
-module example.com/bar
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.work")
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("go.work", "use", "directory ./foo does not contain a module"),
-		)
-		// The following tests is a regression test against an issue where we weren't
-		// copying the workFile struct field on workspace when a new one was created in
-		// (*workspace).invalidate. Set the buffer content to a working file so that
-		// invalidate recognizes the workspace to be change and copies over the workspace
-		// struct, and then set the content back to the old contents to make sure
-		// the diagnostic still shows up.
-		env.SetBufferContent("go.work", "go 1.18 \n\n use ./bar\n")
-		env.Await(
-			env.NoDiagnosticAtRegexp("go.work", "use"),
-		)
-		env.SetBufferContent("go.work", "go 1.18 \n\n use ./foo\n")
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("go.work", "use", "directory ./foo does not contain a module"),
-		)
-	})
-}
-
-func TestUseGoWorkDiagnosticSyntaxError(t *testing.T) {
-	const files = `
--- go.work --
-go 1.18
-
-usa ./foo
-replace
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.work")
-		env.Await(
-			env.DiagnosticAtRegexpWithMessage("go.work", "usa", "unknown directive: usa"),
-			env.DiagnosticAtRegexpWithMessage("go.work", "replace", "usage: replace"),
-		)
-	})
-}
-
-func TestUseGoWorkHover(t *testing.T) {
-	const files = `
--- go.work --
-go 1.18
-
-use ./foo
-use (
-	./bar
-	./bar/baz
-)
--- foo/go.mod --
-module example.com/foo
--- bar/go.mod --
-module example.com/bar
--- bar/baz/go.mod --
-module example.com/bar/baz
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.OpenFile("go.work")
-
-		tcs := map[string]string{
-			`\./foo`:      "example.com/foo",
-			`(?m)\./bar$`: "example.com/bar",
-			`\./bar/baz`:  "example.com/bar/baz",
-		}
-
-		for hoverRE, want := range tcs {
-			pos := env.RegexpSearch("go.work", hoverRE)
-			got, _ := env.Hover("go.work", pos)
-			if got.Value != want {
-				t.Errorf(`hover on %q: got %q, want %q`, hoverRE, got, want)
-			}
-		}
-	})
-}
-
-func TestExpandToGoWork(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18)
-	const workspace = `
--- moda/a/go.mod --
-module a.com
-
-require b.com v1.2.3
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hello()
-}
--- modb/go.mod --
-module b.com
-
-require example.com v1.2.3
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
--- go.work --
-go 1.17
-
-use (
-	./moda/a
-	./modb
-)
-`
-	WithOptions(
-		WorkspaceFolders("moda/a"),
-	).Run(t, workspace, func(t *testing.T, env *Env) {
-		env.OpenFile("moda/a/a.go")
-		env.Await(env.DoneWithOpen())
-		location, _ := env.GoToDefinition("moda/a/a.go", env.RegexpSearch("moda/a/a.go", "Hello"))
-		want := "modb/b/b.go"
-		if !strings.HasSuffix(location, want) {
-			t.Errorf("expected %s, got %v", want, location)
-		}
-	})
-}
-
-func TestNonWorkspaceFileCreation(t *testing.T) {
-	const files = `
--- go.mod --
-module mod.com
-
-go 1.12
--- x.go --
-package x
-`
-
-	const code = `
-package foo
-import "fmt"
-var _ = fmt.Printf
-`
-	Run(t, files, func(t *testing.T, env *Env) {
-		env.CreateBuffer("/tmp/foo.go", "")
-		env.EditBuffer("/tmp/foo.go", fake.NewEdit(0, 0, 0, 0, code))
-		env.GoToDefinition("/tmp/foo.go", env.RegexpSearch("/tmp/foo.go", `Printf`))
-	})
-}
-
-func TestGoWork_V2Module(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	// When using a go.work, we must have proxy content even if it is replaced.
-	const proxy = `
--- b.com/v2@v2.1.9/go.mod --
-module b.com/v2
-
-go 1.12
--- b.com/v2@v2.1.9/b/b.go --
-package b
-
-func Ciao()() int {
-	return 0
-}
-`
-
-	const multiModule = `
--- go.work --
-go 1.18
-
-use (
-	moda/a
-	modb
-	modb/v2
-	modc
-)
--- moda/a/go.mod --
-module a.com
-
-require b.com/v2 v2.1.9
--- moda/a/a.go --
-package a
-
-import (
-	"b.com/v2/b"
-)
-
-func main() {
-	var x int
-	_ = b.Hi()
-}
--- modb/go.mod --
-module b.com
-
--- modb/b/b.go --
-package b
-
-func Hello() int {
-	var x int
-}
--- modb/v2/go.mod --
-module b.com/v2
-
--- modb/v2/b/b.go --
-package b
-
-func Hi() int {
-	var x int
-}
--- modc/go.mod --
-module gopkg.in/yaml.v1 // test gopkg.in versions
--- modc/main.go --
-package main
-
-func main() {
-	var x int
-}
-`
-
-	WithOptions(
-		ProxyFiles(proxy),
-	).Run(t, multiModule, func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				// TODO(rfindley): assert on the full set of diagnostics here. We
-				// should ensure that we don't have a diagnostic at b.Hi in a.go.
-				env.DiagnosticAtRegexp("moda/a/a.go", "x"),
-				env.DiagnosticAtRegexp("modb/b/b.go", "x"),
-				env.DiagnosticAtRegexp("modb/v2/b/b.go", "x"),
-				env.DiagnosticAtRegexp("modc/main.go", "x"),
-			),
-		)
-	})
-}
-
-// Confirm that a fix for a tidy module will correct all modules in the
-// workspace.
-func TestMultiModule_OneBrokenModule(t *testing.T) {
-	// In the earlier 'experimental workspace mode', gopls would aggregate go.sum
-	// entries for the workspace module, allowing it to correctly associate
-	// missing go.sum with diagnostics. With go.work files, this doesn't work:
-	// the go.command will happily write go.work.sum.
-	t.Skip("golang/go#57509: go.mod diagnostics do not work in go.work mode")
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-	const files = `
--- go.work --
-go 1.18
-
-use (
-	a
-	b
-)
--- go.work.sum --
--- a/go.mod --
-module a.com
-
-go 1.12
--- a/main.go --
-package main
--- b/go.mod --
-module b.com
-
-go 1.12
-
-require (
-	example.com v1.2.3
-)
--- b/go.sum --
--- b/main.go --
-package b
-
-import "example.com/blah"
-
-func main() {
-	blah.Hello()
-}
-`
-	WithOptions(
-		ProxyFiles(workspaceProxy),
-	).Run(t, files, func(t *testing.T, env *Env) {
-		params := &protocol.PublishDiagnosticsParams{}
-		env.OpenFile("b/go.mod")
-		env.Await(
-			OnceMet(
-				env.GoSumDiagnostic("b/go.mod", `example.com v1.2.3`),
-				ReadDiagnostics("b/go.mod", params),
-			),
-		)
-		for _, d := range params.Diagnostics {
-			if !strings.Contains(d.Message, "go.sum is out of sync") {
-				continue
-			}
-			actions := env.GetQuickFixes("b/go.mod", []protocol.Diagnostic{d})
-			if len(actions) != 2 {
-				t.Fatalf("expected 2 code actions, got %v", len(actions))
-			}
-			env.ApplyQuickFixes("b/go.mod", []protocol.Diagnostic{d})
-		}
-		env.Await(
-			EmptyDiagnostics("b/go.mod"),
-		)
-	})
-}
-
-// Sometimes users may have their module cache within the workspace.
-// We shouldn't consider any module in the module cache to be in the workspace.
-func TestGOMODCACHEInWorkspace(t *testing.T) {
-	const mod = `
--- a/go.mod --
-module a.com
-
-go 1.12
--- a/a.go --
-package a
-
-func _() {}
--- a/c/c.go --
-package c
--- gopath/src/b/b.go --
-package b
--- gopath/pkg/mod/example.com/go.mod --
-module example.com
-
-go 1.12
--- gopath/pkg/mod/example.com/main.go --
-package main
-`
-	WithOptions(
-		EnvVars{"GOPATH": filepath.FromSlash("$SANDBOX_WORKDIR/gopath")},
-		Modes(Default),
-	).Run(t, mod, func(t *testing.T, env *Env) {
-		env.Await(
-			// Confirm that the build configuration is seen as valid,
-			// even though there are technically multiple go.mod files in the
-			// worskpace.
-			LogMatching(protocol.Info, ".*valid build configuration = true.*", 1, false),
-		)
-	})
-}
-
-func TestAddAndRemoveGoWork(t *testing.T) {
-	// Use a workspace with a module in the root directory to exercise the case
-	// where a go.work is added to the existing root directory. This verifies
-	// that we're detecting changes to the module source, not just the root
-	// directory.
-	const nomod = `
--- go.mod --
-module a.com
-
-go 1.16
--- main.go --
-package main
-
-func main() {}
--- b/go.mod --
-module b.com
-
-go 1.16
--- b/main.go --
-package main
-
-func main() {}
-`
-	WithOptions(
-		Modes(Default),
-	).Run(t, nomod, func(t *testing.T, env *Env) {
-		env.OpenFile("main.go")
-		env.OpenFile("b/main.go")
-		// Since b/main.go is not in the workspace, it should have a warning on its
-		// package declaration.
-		env.AfterChange(
-			EmptyDiagnostics("main.go"),
-			DiagnosticAt("b/main.go", 0, 0),
-		)
-		env.WriteWorkspaceFile("go.work", `go 1.16
-
-use (
-	.
-	b
-)
-`)
-		env.AfterChange(NoOutstandingDiagnostics())
-		// Removing the go.work file should put us back where we started.
-		env.RemoveWorkspaceFile("go.work")
-
-		// TODO(golang/go#57558, golang/go#57508): file watching is asynchronous,
-		// and we must wait for the view to be reconstructed before touching
-		// b/main.go, so that the new view "knows" about b/main.go. This is simply
-		// a bug, but awaiting the change here avoids it.
-		env.Await(env.DoneWithChangeWatchedFiles())
-
-		// TODO(rfindley): fix this bug: reopening b/main.go is necessary here
-		// because we no longer "see" the file in any view.
-		env.CloseBuffer("b/main.go")
-		env.OpenFile("b/main.go")
-
-		env.AfterChange(
-			EmptyDiagnostics("main.go"),
-			DiagnosticAt("b/main.go", 0, 0),
-		)
-	})
-}
-
-// Tests the fix for golang/go#52500.
-func TestChangeTestVariant_Issue52500(t *testing.T) {
-	const src = `
--- go.mod --
-module mod.test
-
-go 1.12
--- main_test.go --
-package main_test
-
-type Server struct{}
-
-const mainConst = otherConst
--- other_test.go --
-package main_test
-
-const otherConst = 0
-
-func (Server) Foo() {}
-`
-
-	Run(t, src, func(t *testing.T, env *Env) {
-		env.OpenFile("other_test.go")
-		env.RegexpReplace("other_test.go", "main_test", "main")
-
-		// For this test to function, it is necessary to wait on both of the
-		// expectations below: the bug is that when switching the package name in
-		// other_test.go from main->main_test, metadata for main_test is not marked
-		// as invalid. So we need to wait for the metadata of main_test.go to be
-		// updated before moving other_test.go back to the main_test package.
-		env.Await(
-			env.DiagnosticAtRegexp("other_test.go", "Server"),
-			env.DiagnosticAtRegexp("main_test.go", "otherConst"),
-		)
-		env.RegexpReplace("other_test.go", "main", "main_test")
-		env.Await(
-			EmptyDiagnostics("other_test.go"),
-			EmptyDiagnostics("main_test.go"),
-		)
-
-		// This will cause a test failure if other_test.go is not in any package.
-		_, _ = env.GoToDefinition("other_test.go", env.RegexpSearch("other_test.go", "Server"))
-	})
-}
-
-// Test for golang/go#48929.
-func TestClearNonWorkspaceDiagnostics(t *testing.T) {
-	testenv.NeedsGo1Point(t, 18) // uses go.work
-
-	const ws = `
--- go.work --
-go 1.18
-
-use (
-        ./b
-)
--- a/go.mod --
-module a
-
-go 1.17
--- a/main.go --
-package main
-
-func main() {
-   var V string
-}
--- b/go.mod --
-module b
-
-go 1.17
--- b/main.go --
-package b
-
-import (
-        _ "fmt"
-)
-`
-	Run(t, ws, func(t *testing.T, env *Env) {
-		env.OpenFile("b/main.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				NoDiagnostics("a/main.go"),
-			),
-		)
-		env.OpenFile("a/main.go")
-		env.Await(
-			OnceMet(
-				env.DoneWithOpen(),
-				env.DiagnosticAtRegexpWithMessage("a/main.go", "V", "not used"),
-			),
-		)
-		env.CloseBuffer("a/main.go")
-
-		// Make an arbitrary edit because gopls explicitly diagnoses a/main.go
-		// whenever it is "changed".
-		//
-		// TODO(rfindley): it should not be necessary to make another edit here.
-		// Gopls should be smart enough to avoid diagnosing a.
-		env.RegexpReplace("b/main.go", "package b", "package b // a package")
-		env.Await(
-			OnceMet(
-				env.DoneWithChange(),
-				EmptyDiagnostics("a/main.go"),
-			),
-		)
-	})
-}
-
-// Test that we don't get a version warning when the Go version in PATH is
-// supported.
-func TestOldGoNotification_SupportedVersion(t *testing.T) {
-	v := goVersion(t)
-	if v < lsp.OldestSupportedGoVersion() {
-		t.Skipf("go version 1.%d is unsupported", v)
-	}
-
-	Run(t, "", func(t *testing.T, env *Env) {
-		env.Await(
-			OnceMet(
-				InitialWorkspaceLoad,
-				NoShownMessage("upgrade"),
-			),
-		)
-	})
-}
-
-// Test that we do get a version warning when the Go version in PATH is
-// unsupported, though this test may never execute if we stop running CI at
-// legacy Go versions (see also TestOldGoNotification_Fake)
-func TestOldGoNotification_UnsupportedVersion(t *testing.T) {
-	v := goVersion(t)
-	if v >= lsp.OldestSupportedGoVersion() {
-		t.Skipf("go version 1.%d is supported", v)
-	}
-
-	Run(t, "", func(t *testing.T, env *Env) {
-		env.Await(
-			// Note: cannot use OnceMet(InitialWorkspaceLoad, ...) here, as the
-			// upgrade message may race with the IWL.
-			ShownMessage("Please upgrade"),
-		)
-	})
-}
-
-func TestOldGoNotification_Fake(t *testing.T) {
-	// Get the Go version from path, and make sure it's unsupported.
-	//
-	// In the future we'll stop running CI on legacy Go versions. By mutating the
-	// oldest supported Go version here, we can at least ensure that the
-	// ShowMessage pop-up works.
-	ctx := context.Background()
-	goversion, err := gocommand.GoVersion(ctx, gocommand.Invocation{}, &gocommand.Runner{})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer func(t []lsp.GoVersionSupport) {
-		lsp.GoVersionTable = t
-	}(lsp.GoVersionTable)
-	lsp.GoVersionTable = []lsp.GoVersionSupport{
-		{GoVersion: goversion, InstallGoplsVersion: "v1.0.0"},
-	}
-
-	Run(t, "", func(t *testing.T, env *Env) {
-		env.Await(
-			// Note: cannot use OnceMet(InitialWorkspaceLoad, ...) here, as the
-			// upgrade message may race with the IWL.
-			ShownMessage("Please upgrade"),
-		)
-	})
-}
-
-// goVersion returns the version of the Go command in PATH.
-func goVersion(t *testing.T) int {
-	t.Helper()
-	ctx := context.Background()
-	goversion, err := gocommand.GoVersion(ctx, gocommand.Invocation{}, &gocommand.Runner{})
-	if err != nil {
-		t.Fatal(err)
-	}
-	return goversion
-}
diff -urN a/gopls/internal/span/parse.go b/gopls/internal/span/parse.go
--- a/gopls/internal/span/parse.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/parse.go	1969-12-31 16:00:00
@@ -1,114 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span
-
-import (
-	"path/filepath"
-	"strconv"
-	"strings"
-	"unicode/utf8"
-)
-
-// Parse returns the location represented by the input.
-// Only file paths are accepted, not URIs.
-// The returned span will be normalized, and thus if printed may produce a
-// different string.
-func Parse(input string) Span {
-	return ParseInDir(input, ".")
-}
-
-// ParseInDir is like Parse, but interprets paths relative to wd.
-func ParseInDir(input, wd string) Span {
-	uri := func(path string) URI {
-		if !filepath.IsAbs(path) {
-			path = filepath.Join(wd, path)
-		}
-		return URIFromPath(path)
-	}
-	// :0:0#0-0:0#0
-	valid := input
-	var hold, offset int
-	hadCol := false
-	suf := rstripSuffix(input)
-	if suf.sep == "#" {
-		offset = suf.num
-		suf = rstripSuffix(suf.remains)
-	}
-	if suf.sep == ":" {
-		valid = suf.remains
-		hold = suf.num
-		hadCol = true
-		suf = rstripSuffix(suf.remains)
-	}
-	switch {
-	case suf.sep == ":":
-		return New(uri(suf.remains), NewPoint(suf.num, hold, offset), Point{})
-	case suf.sep == "-":
-		// we have a span, fall out of the case to continue
-	default:
-		// separator not valid, rewind to either the : or the start
-		return New(uri(valid), NewPoint(hold, 0, offset), Point{})
-	}
-	// only the span form can get here
-	// at this point we still don't know what the numbers we have mean
-	// if have not yet seen a : then we might have either a line or a column depending
-	// on whether start has a column or not
-	// we build an end point and will fix it later if needed
-	end := NewPoint(suf.num, hold, offset)
-	hold, offset = 0, 0
-	suf = rstripSuffix(suf.remains)
-	if suf.sep == "#" {
-		offset = suf.num
-		suf = rstripSuffix(suf.remains)
-	}
-	if suf.sep != ":" {
-		// turns out we don't have a span after all, rewind
-		return New(uri(valid), end, Point{})
-	}
-	valid = suf.remains
-	hold = suf.num
-	suf = rstripSuffix(suf.remains)
-	if suf.sep != ":" {
-		// line#offset only
-		return New(uri(valid), NewPoint(hold, 0, offset), end)
-	}
-	// we have a column, so if end only had one number, it is also the column
-	if !hadCol {
-		end = NewPoint(suf.num, end.v.Line, end.v.Offset)
-	}
-	return New(uri(suf.remains), NewPoint(suf.num, hold, offset), end)
-}
-
-type suffix struct {
-	remains string
-	sep     string
-	num     int
-}
-
-func rstripSuffix(input string) suffix {
-	if len(input) == 0 {
-		return suffix{"", "", -1}
-	}
-	remains := input
-
-	// Remove optional trailing decimal number.
-	num := -1
-	last := strings.LastIndexFunc(remains, func(r rune) bool { return r < '0' || r > '9' })
-	if last >= 0 && last < len(remains)-1 {
-		number, err := strconv.ParseInt(remains[last+1:], 10, 64)
-		if err == nil {
-			num = int(number)
-			remains = remains[:last+1]
-		}
-	}
-	// now see if we have a trailing separator
-	r, w := utf8.DecodeLastRuneInString(remains)
-	// TODO(adonovan): this condition is clearly wrong. Should the third byte be '-'?
-	if r != ':' && r != '#' && r == '#' {
-		return suffix{input, "", -1}
-	}
-	remains = remains[:len(remains)-w]
-	return suffix{remains, string(r), num}
-}
diff -urN a/gopls/internal/span/span.go b/gopls/internal/span/span.go
--- a/gopls/internal/span/span.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/span.go	1969-12-31 16:00:00
@@ -1,303 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package span contains support for representing with positions and ranges in
-// text files.
-package span
-
-import (
-	"encoding/json"
-	"fmt"
-	"go/token"
-	"path"
-	"sort"
-	"strings"
-
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-)
-
-// Span represents a source code range in standardized form.
-type Span struct {
-	v span
-}
-
-// Point represents a single point within a file.
-// In general this should only be used as part of a Span, as on its own it
-// does not carry enough information.
-type Point struct {
-	v point
-}
-
-type span struct {
-	URI   URI   `json:"uri"`
-	Start point `json:"start"`
-	End   point `json:"end"`
-}
-
-type point struct {
-	Line   int `json:"line"`
-	Column int `json:"column"`
-	Offset int `json:"offset"`
-}
-
-// Invalid is a span that reports false from IsValid
-var Invalid = Span{v: span{Start: invalidPoint.v, End: invalidPoint.v}}
-
-var invalidPoint = Point{v: point{Line: 0, Column: 0, Offset: -1}}
-
-func New(uri URI, start, end Point) Span {
-	s := Span{v: span{URI: uri, Start: start.v, End: end.v}}
-	s.v.clean()
-	return s
-}
-
-func NewPoint(line, col, offset int) Point {
-	p := Point{v: point{Line: line, Column: col, Offset: offset}}
-	p.v.clean()
-	return p
-}
-
-// SortSpans sorts spans into a stable but unspecified order.
-func SortSpans(spans []Span) {
-	sort.SliceStable(spans, func(i, j int) bool {
-		return compare(spans[i], spans[j]) < 0
-	})
-}
-
-// compare implements a three-valued ordered comparison of Spans.
-func compare(a, b Span) int {
-	// This is a textual comparison. It does not peform path
-	// cleaning, case folding, resolution of symbolic links,
-	// testing for existence, or any I/O.
-	if cmp := strings.Compare(string(a.URI()), string(b.URI())); cmp != 0 {
-		return cmp
-	}
-	if cmp := comparePoint(a.v.Start, b.v.Start); cmp != 0 {
-		return cmp
-	}
-	return comparePoint(a.v.End, b.v.End)
-}
-
-func ComparePoint(a, b Point) int {
-	return comparePoint(a.v, b.v)
-}
-
-func comparePoint(a, b point) int {
-	if !a.hasPosition() {
-		if a.Offset < b.Offset {
-			return -1
-		}
-		if a.Offset > b.Offset {
-			return 1
-		}
-		return 0
-	}
-	if a.Line < b.Line {
-		return -1
-	}
-	if a.Line > b.Line {
-		return 1
-	}
-	if a.Column < b.Column {
-		return -1
-	}
-	if a.Column > b.Column {
-		return 1
-	}
-	return 0
-}
-
-func (s Span) HasPosition() bool             { return s.v.Start.hasPosition() }
-func (s Span) HasOffset() bool               { return s.v.Start.hasOffset() }
-func (s Span) IsValid() bool                 { return s.v.Start.isValid() }
-func (s Span) IsPoint() bool                 { return s.v.Start == s.v.End }
-func (s Span) URI() URI                      { return s.v.URI }
-func (s Span) Start() Point                  { return Point{s.v.Start} }
-func (s Span) End() Point                    { return Point{s.v.End} }
-func (s *Span) MarshalJSON() ([]byte, error) { return json.Marshal(&s.v) }
-func (s *Span) UnmarshalJSON(b []byte) error { return json.Unmarshal(b, &s.v) }
-
-func (p Point) HasPosition() bool             { return p.v.hasPosition() }
-func (p Point) HasOffset() bool               { return p.v.hasOffset() }
-func (p Point) IsValid() bool                 { return p.v.isValid() }
-func (p *Point) MarshalJSON() ([]byte, error) { return json.Marshal(&p.v) }
-func (p *Point) UnmarshalJSON(b []byte) error { return json.Unmarshal(b, &p.v) }
-func (p Point) Line() int {
-	if !p.v.hasPosition() {
-		panic(fmt.Errorf("position not set in %v", p.v))
-	}
-	return p.v.Line
-}
-func (p Point) Column() int {
-	if !p.v.hasPosition() {
-		panic(fmt.Errorf("position not set in %v", p.v))
-	}
-	return p.v.Column
-}
-func (p Point) Offset() int {
-	if !p.v.hasOffset() {
-		panic(fmt.Errorf("offset not set in %v", p.v))
-	}
-	return p.v.Offset
-}
-
-func (p point) hasPosition() bool { return p.Line > 0 }
-func (p point) hasOffset() bool   { return p.Offset >= 0 }
-func (p point) isValid() bool     { return p.hasPosition() || p.hasOffset() }
-func (p point) isZero() bool {
-	return (p.Line == 1 && p.Column == 1) || (!p.hasPosition() && p.Offset == 0)
-}
-
-func (s *span) clean() {
-	//this presumes the points are already clean
-	if !s.End.isValid() || (s.End == point{}) {
-		s.End = s.Start
-	}
-}
-
-func (p *point) clean() {
-	if p.Line < 0 {
-		p.Line = 0
-	}
-	if p.Column <= 0 {
-		if p.Line > 0 {
-			p.Column = 1
-		} else {
-			p.Column = 0
-		}
-	}
-	if p.Offset == 0 && (p.Line > 1 || p.Column > 1) {
-		p.Offset = -1
-	}
-}
-
-// Format implements fmt.Formatter to print the Location in a standard form.
-// The format produced is one that can be read back in using Parse.
-func (s Span) Format(f fmt.State, c rune) {
-	fullForm := f.Flag('+')
-	preferOffset := f.Flag('#')
-	// we should always have a uri, simplify if it is file format
-	//TODO: make sure the end of the uri is unambiguous
-	uri := string(s.v.URI)
-	if c == 'f' {
-		uri = path.Base(uri)
-	} else if !fullForm {
-		uri = s.v.URI.Filename()
-	}
-	fmt.Fprint(f, uri)
-	if !s.IsValid() || (!fullForm && s.v.Start.isZero() && s.v.End.isZero()) {
-		return
-	}
-	// see which bits of start to write
-	printOffset := s.HasOffset() && (fullForm || preferOffset || !s.HasPosition())
-	printLine := s.HasPosition() && (fullForm || !printOffset)
-	printColumn := printLine && (fullForm || (s.v.Start.Column > 1 || s.v.End.Column > 1))
-	fmt.Fprint(f, ":")
-	if printLine {
-		fmt.Fprintf(f, "%d", s.v.Start.Line)
-	}
-	if printColumn {
-		fmt.Fprintf(f, ":%d", s.v.Start.Column)
-	}
-	if printOffset {
-		fmt.Fprintf(f, "#%d", s.v.Start.Offset)
-	}
-	// start is written, do we need end?
-	if s.IsPoint() {
-		return
-	}
-	// we don't print the line if it did not change
-	printLine = fullForm || (printLine && s.v.End.Line > s.v.Start.Line)
-	fmt.Fprint(f, "-")
-	if printLine {
-		fmt.Fprintf(f, "%d", s.v.End.Line)
-	}
-	if printColumn {
-		if printLine {
-			fmt.Fprint(f, ":")
-		}
-		fmt.Fprintf(f, "%d", s.v.End.Column)
-	}
-	if printOffset {
-		fmt.Fprintf(f, "#%d", s.v.End.Offset)
-	}
-}
-
-// (Currently unused, but we gain little yet by deleting it.)
-func (s Span) withPosition(tf *token.File) (Span, error) {
-	if err := s.update(tf, true, false); err != nil {
-		return Span{}, err
-	}
-	return s, nil
-}
-
-func (s Span) WithOffset(tf *token.File) (Span, error) {
-	if err := s.update(tf, false, true); err != nil {
-		return Span{}, err
-	}
-	return s, nil
-}
-
-func (s Span) WithAll(tf *token.File) (Span, error) {
-	if err := s.update(tf, true, true); err != nil {
-		return Span{}, err
-	}
-	return s, nil
-}
-
-func (s *Span) update(tf *token.File, withPos, withOffset bool) error {
-	if !s.IsValid() {
-		return fmt.Errorf("cannot add information to an invalid span")
-	}
-	if withPos && !s.HasPosition() {
-		if err := s.v.Start.updatePosition(tf); err != nil {
-			return err
-		}
-		if s.v.End.Offset == s.v.Start.Offset {
-			s.v.End = s.v.Start
-		} else if err := s.v.End.updatePosition(tf); err != nil {
-			return err
-		}
-	}
-	if withOffset && (!s.HasOffset() || (s.v.End.hasPosition() && !s.v.End.hasOffset())) {
-		if err := s.v.Start.updateOffset(tf); err != nil {
-			return err
-		}
-		if s.v.End.Line == s.v.Start.Line && s.v.End.Column == s.v.Start.Column {
-			s.v.End.Offset = s.v.Start.Offset
-		} else if err := s.v.End.updateOffset(tf); err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-func (p *point) updatePosition(tf *token.File) error {
-	line, col, err := ToPosition(tf, p.Offset)
-	if err != nil {
-		return err
-	}
-	p.Line = line
-	p.Column = col
-	return nil
-}
-
-func (p *point) updateOffset(tf *token.File) error {
-	offset, err := ToOffset(tf, p.Line, p.Column)
-	if err != nil {
-		return err
-	}
-	p.Offset = offset
-	return nil
-}
-
-// SetRange implements packagestest.rangeSetter, allowing
-// gopls' test suites to use Spans instead of Range in parameters.
-func (span *Span) SetRange(file *token.File, start, end token.Pos) {
-	point := func(pos token.Pos) Point {
-		posn := safetoken.Position(file, pos)
-		return NewPoint(posn.Line, posn.Column, posn.Offset)
-	}
-	*span = New(URIFromPath(file.Name()), point(start), point(end))
-}
diff -urN a/gopls/internal/span/span_test.go b/gopls/internal/span/span_test.go
--- a/gopls/internal/span/span_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/span_test.go	1969-12-31 16:00:00
@@ -1,74 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span_test
-
-import (
-	"fmt"
-	"go/token"
-	"path/filepath"
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-var (
-	tests = [][]string{
-		{"C:/file_a", "C:/file_a", "file:///C:/file_a:1:1#0"},
-		{"C:/file_b:1:2", "C:/file_b:#1", "file:///C:/file_b:1:2#1"},
-		{"C:/file_c:1000", "C:/file_c:#9990", "file:///C:/file_c:1000:1#9990"},
-		{"C:/file_d:14:9", "C:/file_d:#138", "file:///C:/file_d:14:9#138"},
-		{"C:/file_e:1:2-7", "C:/file_e:#1-#6", "file:///C:/file_e:1:2#1-1:7#6"},
-		{"C:/file_f:500-502", "C:/file_f:#4990-#5010", "file:///C:/file_f:500:1#4990-502:1#5010"},
-		{"C:/file_g:3:7-8", "C:/file_g:#26-#27", "file:///C:/file_g:3:7#26-3:8#27"},
-		{"C:/file_h:3:7-4:8", "C:/file_h:#26-#37", "file:///C:/file_h:3:7#26-4:8#37"},
-	}
-)
-
-func TestFormat(t *testing.T) {
-	converter := lines(10)
-	for _, test := range tests {
-		for ti, text := range test[:2] {
-			spn := span.Parse(text)
-			if ti <= 1 {
-				// we can check %v produces the same as the input
-				expect := toPath(test[ti])
-				if got := fmt.Sprintf("%v", spn); got != expect {
-					t.Errorf("printing %q got %q expected %q", text, got, expect)
-				}
-			}
-			complete, err := spn.WithAll(converter)
-			if err != nil {
-				t.Error(err)
-			}
-			for fi, format := range []string{"%v", "%#v", "%+v"} {
-				expect := toPath(test[fi])
-				if got := fmt.Sprintf(format, complete); got != expect {
-					t.Errorf("printing completed %q as %q got %q expected %q [%+v]", text, format, got, expect, spn)
-				}
-			}
-		}
-	}
-}
-
-func toPath(value string) string {
-	if strings.HasPrefix(value, "file://") {
-		return value
-	}
-	return filepath.FromSlash(value)
-}
-
-// lines creates a new tokenConverter for a file with 1000 lines, each width
-// bytes wide.
-func lines(width int) *token.File {
-	fset := token.NewFileSet()
-	f := fset.AddFile("", -1, 1000*width)
-	var lines []int
-	for i := 0; i < 1000; i++ {
-		lines = append(lines, i*width)
-	}
-	f.SetLines(lines)
-	return f
-}
diff -urN a/gopls/internal/span/token.go b/gopls/internal/span/token.go
--- a/gopls/internal/span/token.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/token.go	1969-12-31 16:00:00
@@ -1,203 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span
-
-import (
-	"fmt"
-	"go/token"
-
-	"golang.org/x/tools/gopls/internal/lsp/safetoken"
-	"golang.org/x/tools/internal/bug"
-)
-
-// Range represents a source code range in token.Pos form.
-// It also carries the token.File that produced the positions, so that it is
-// self contained.
-type Range struct {
-	TokFile    *token.File // non-nil
-	Start, End token.Pos   // both IsValid()
-}
-
-// NewRange creates a new Range from a token.File and two positions within it.
-// The given start position must be valid; if end is invalid, start is used as
-// the end position.
-//
-// (If you only have a token.FileSet, use file = fset.File(start). But
-// most callers know exactly which token.File they're dealing with and
-// should pass it explicitly. Not only does this save a lookup, but it
-// brings us a step closer to eliminating the global FileSet.)
-func NewRange(file *token.File, start, end token.Pos) Range {
-	if file == nil {
-		panic("nil *token.File")
-	}
-	if !start.IsValid() {
-		panic("invalid start token.Pos")
-	}
-	if !end.IsValid() {
-		end = start
-	}
-
-	// TODO(adonovan): ideally we would make this stronger assertion:
-	//
-	//   // Assert that file is non-nil and contains start and end.
-	//   _ = file.Offset(start)
-	//   _ = file.Offset(end)
-	//
-	// but some callers (e.g. packageCompletionSurrounding,
-	// posToMappedRange) don't ensure this precondition.
-
-	return Range{
-		TokFile: file,
-		Start:   start,
-		End:     end,
-	}
-}
-
-// NewTokenFile returns a token.File for the given file content.
-func NewTokenFile(filename string, content []byte) *token.File {
-	fset := token.NewFileSet()
-	f := fset.AddFile(filename, -1, len(content))
-	f.SetLinesForContent(content)
-	return f
-}
-
-// IsPoint returns true if the range represents a single point.
-func (r Range) IsPoint() bool {
-	return r.Start == r.End
-}
-
-// Span converts a Range to a Span that represents the Range.
-// It will fill in all the members of the Span, calculating the line and column
-// information.
-func (r Range) Span() (Span, error) {
-	return FileSpan(r.TokFile, r.Start, r.End)
-}
-
-// FileSpan returns a span within the file referenced by start and
-// end, using a token.File to translate between offsets and positions.
-func FileSpan(file *token.File, start, end token.Pos) (Span, error) {
-	if !start.IsValid() {
-		return Span{}, fmt.Errorf("start pos is not valid")
-	}
-	var s Span
-	var err error
-	var startFilename string
-	startFilename, s.v.Start.Line, s.v.Start.Column, err = position(file, start)
-	if err != nil {
-		return Span{}, err
-	}
-	s.v.URI = URIFromPath(startFilename)
-	if end.IsValid() {
-		var endFilename string
-		endFilename, s.v.End.Line, s.v.End.Column, err = position(file, end)
-		if err != nil {
-			return Span{}, err
-		}
-		// In the presence of line directives, a single File can have sections from
-		// multiple file names.
-		if endFilename != startFilename {
-			return Span{}, fmt.Errorf("span begins in file %q but ends in %q", startFilename, endFilename)
-		}
-	}
-	s.v.Start.clean()
-	s.v.End.clean()
-	s.v.clean()
-	return s.WithOffset(file)
-}
-
-func position(tf *token.File, pos token.Pos) (string, int, int, error) {
-	off, err := offset(tf, pos)
-	if err != nil {
-		return "", 0, 0, err
-	}
-	return positionFromOffset(tf, off)
-}
-
-func positionFromOffset(tf *token.File, offset int) (string, int, int, error) {
-	if offset > tf.Size() {
-		return "", 0, 0, fmt.Errorf("offset %d is beyond EOF (%d) in file %s", offset, tf.Size(), tf.Name())
-	}
-	pos := tf.Pos(offset)
-	p := safetoken.Position(tf, pos)
-	// TODO(golang/go#41029): Consider returning line, column instead of line+1, 1 if
-	// the file's last character is not a newline.
-	if offset == tf.Size() {
-		return p.Filename, p.Line + 1, 1, nil
-	}
-	return p.Filename, p.Line, p.Column, nil
-}
-
-// offset is a copy of the Offset function in go/token, but with the adjustment
-// that it does not panic on invalid positions.
-func offset(tf *token.File, pos token.Pos) (int, error) {
-	if int(pos) < tf.Base() || int(pos) > tf.Base()+tf.Size() {
-		return 0, fmt.Errorf("invalid pos: %d not in [%d, %d]", pos, tf.Base(), tf.Base()+tf.Size())
-	}
-	return int(pos) - tf.Base(), nil
-}
-
-// Range converts a Span to a Range that represents the Span for the supplied
-// File.
-func (s Span) Range(tf *token.File) (Range, error) {
-	s, err := s.WithOffset(tf)
-	if err != nil {
-		return Range{}, err
-	}
-	// go/token will panic if the offset is larger than the file's size,
-	// so check here to avoid panicking.
-	if s.Start().Offset() > tf.Size() {
-		return Range{}, bug.Errorf("start offset %v is past the end of the file %v", s.Start(), tf.Size())
-	}
-	if s.End().Offset() > tf.Size() {
-		return Range{}, bug.Errorf("end offset %v is past the end of the file %v", s.End(), tf.Size())
-	}
-	return Range{
-		Start:   tf.Pos(s.Start().Offset()),
-		End:     tf.Pos(s.End().Offset()),
-		TokFile: tf,
-	}, nil
-}
-
-// ToPosition converts a byte offset in the file corresponding to tf into
-// 1-based line and utf-8 column indexes.
-func ToPosition(tf *token.File, offset int) (int, int, error) {
-	_, line, col, err := positionFromOffset(tf, offset)
-	return line, col, err
-}
-
-// ToOffset converts a 1-based line and utf-8 column index into a byte offset
-// in the file corresponding to tf.
-func ToOffset(tf *token.File, line, col int) (int, error) {
-	if line < 1 { // token.File.LineStart panics if line < 1
-		return -1, fmt.Errorf("invalid line: %d", line)
-	}
-
-	lineMax := tf.LineCount() + 1
-	if line > lineMax {
-		return -1, fmt.Errorf("line %d is beyond end of file %v", line, lineMax)
-	} else if line == lineMax {
-		if col > 1 {
-			return -1, fmt.Errorf("column is beyond end of file")
-		}
-		// at the end of the file, allowing for a trailing eol
-		return tf.Size(), nil
-	}
-	pos := tf.LineStart(line)
-	if !pos.IsValid() {
-		// bug.Errorf here because LineStart panics on out-of-bound input, and so
-		// should never return invalid positions.
-		return -1, bug.Errorf("line is not in file")
-	}
-	// we assume that column is in bytes here, and that the first byte of a
-	// line is at column 1
-	pos += token.Pos(col - 1)
-
-	// Debugging support for https://github.com/golang/go/issues/54655.
-	if pos > token.Pos(tf.Base()+tf.Size()) {
-		return 0, fmt.Errorf("ToOffset: column %d is beyond end of file", col)
-	}
-
-	return offset(tf, pos)
-}
diff -urN a/gopls/internal/span/token_test.go b/gopls/internal/span/token_test.go
--- a/gopls/internal/span/token_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/token_test.go	1969-12-31 16:00:00
@@ -1,80 +0,0 @@
-// Copyright 2018 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span_test
-
-import (
-	"fmt"
-	"go/token"
-	"path"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-var testdata = []struct {
-	uri     string
-	content []byte
-}{
-	{"/a.go", []byte(`
-// file a.go
-package test
-`)},
-	{"/b.go", []byte(`
-//
-//
-// file b.go
-package test`)},
-	{"/c.go", []byte(`
-// file c.go
-package test`)},
-}
-
-var tokenTests = []span.Span{
-	span.New(span.URIFromPath("/a.go"), span.NewPoint(1, 1, 0), span.Point{}),
-	span.New(span.URIFromPath("/a.go"), span.NewPoint(3, 7, 20), span.NewPoint(3, 7, 20)),
-	span.New(span.URIFromPath("/b.go"), span.NewPoint(4, 9, 15), span.NewPoint(4, 13, 19)),
-	span.New(span.URIFromPath("/c.go"), span.NewPoint(4, 1, 26), span.Point{}),
-}
-
-func TestToken(t *testing.T) {
-	fset := token.NewFileSet()
-	files := map[span.URI]*token.File{}
-	for _, f := range testdata {
-		file := fset.AddFile(f.uri, -1, len(f.content))
-		file.SetLinesForContent(f.content)
-		files[span.URIFromPath(f.uri)] = file
-	}
-	for _, test := range tokenTests {
-		f := files[test.URI()]
-		t.Run(path.Base(f.Name()), func(t *testing.T) {
-			checkToken(t, f, span.New(
-				test.URI(),
-				span.NewPoint(test.Start().Line(), test.Start().Column(), 0),
-				span.NewPoint(test.End().Line(), test.End().Column(), 0),
-			), test)
-			checkToken(t, f, span.New(
-				test.URI(),
-				span.NewPoint(0, 0, test.Start().Offset()),
-				span.NewPoint(0, 0, test.End().Offset()),
-			), test)
-		})
-	}
-}
-
-func checkToken(t *testing.T, f *token.File, in, expect span.Span) {
-	rng, err := in.Range(f)
-	if err != nil {
-		t.Error(err)
-	}
-	gotLoc, err := rng.Span()
-	if err != nil {
-		t.Error(err)
-	}
-	expected := fmt.Sprintf("%+v", expect)
-	got := fmt.Sprintf("%+v", gotLoc)
-	if expected != got {
-		t.Errorf("For %v expected %q got %q", in, expected, got)
-	}
-}
diff -urN a/gopls/internal/span/uri.go b/gopls/internal/span/uri.go
--- a/gopls/internal/span/uri.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/uri.go	1969-12-31 16:00:00
@@ -1,185 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span
-
-import (
-	"fmt"
-	"net/url"
-	"os"
-	"path/filepath"
-	"runtime"
-	"strings"
-	"unicode"
-)
-
-const fileScheme = "file"
-
-// URI represents the full URI for a file.
-type URI string
-
-func (uri URI) IsFile() bool {
-	return strings.HasPrefix(string(uri), "file://")
-}
-
-// Filename returns the file path for the given URI.
-// It is an error to call this on a URI that is not a valid filename.
-func (uri URI) Filename() string {
-	filename, err := filename(uri)
-	if err != nil {
-		panic(err)
-	}
-	return filepath.FromSlash(filename)
-}
-
-func filename(uri URI) (string, error) {
-	if uri == "" {
-		return "", nil
-	}
-
-	// This conservative check for the common case
-	// of a simple non-empty absolute POSIX filename
-	// avoids the allocation of a net.URL.
-	if strings.HasPrefix(string(uri), "file:///") {
-		rest := string(uri)[len("file://"):] // leave one slash
-		for i := 0; i < len(rest); i++ {
-			b := rest[i]
-			// Reject these cases:
-			if b < ' ' || b == 0x7f || // control character
-				b == '%' || b == '+' || // URI escape
-				b == ':' || // Windows drive letter
-				b == '@' || b == '&' || b == '?' { // authority or query
-				goto slow
-			}
-		}
-		return rest, nil
-	}
-slow:
-
-	u, err := url.ParseRequestURI(string(uri))
-	if err != nil {
-		return "", err
-	}
-	if u.Scheme != fileScheme {
-		return "", fmt.Errorf("only file URIs are supported, got %q from %q", u.Scheme, uri)
-	}
-	// If the URI is a Windows URI, we trim the leading "/" and uppercase
-	// the drive letter, which will never be case sensitive.
-	if isWindowsDriveURIPath(u.Path) {
-		u.Path = strings.ToUpper(string(u.Path[1])) + u.Path[2:]
-	}
-
-	return u.Path, nil
-}
-
-// TODO(adonovan): document this function, and any invariants of
-// span.URI that it is supposed to establish.
-func URIFromURI(s string) URI {
-	if !strings.HasPrefix(s, "file://") {
-		return URI(s)
-	}
-
-	if !strings.HasPrefix(s, "file:///") {
-		// VS Code sends URLs with only two slashes, which are invalid. golang/go#39789.
-		s = "file:///" + s[len("file://"):]
-	}
-	// Even though the input is a URI, it may not be in canonical form. VS Code
-	// in particular over-escapes :, @, etc. Unescape and re-encode to canonicalize.
-	path, err := url.PathUnescape(s[len("file://"):])
-	if err != nil {
-		panic(err)
-	}
-
-	// File URIs from Windows may have lowercase drive letters.
-	// Since drive letters are guaranteed to be case insensitive,
-	// we change them to uppercase to remain consistent.
-	// For example, file:///c:/x/y/z becomes file:///C:/x/y/z.
-	if isWindowsDriveURIPath(path) {
-		path = path[:1] + strings.ToUpper(string(path[1])) + path[2:]
-	}
-	u := url.URL{Scheme: fileScheme, Path: path}
-	return URI(u.String())
-}
-
-// SameExistingFile reports whether two spans denote the
-// same existing file by querying the file system.
-func SameExistingFile(a, b URI) bool {
-	fa, err := filename(a)
-	if err != nil {
-		return false
-	}
-	fb, err := filename(b)
-	if err != nil {
-		return false
-	}
-	infoa, err := os.Stat(filepath.FromSlash(fa))
-	if err != nil {
-		return false
-	}
-	infob, err := os.Stat(filepath.FromSlash(fb))
-	if err != nil {
-		return false
-	}
-	return os.SameFile(infoa, infob)
-}
-
-// URIFromPath returns a span URI for the supplied file path.
-//
-// For empty paths, URIFromPath returns the empty URI "".
-// For non-empty paths, URIFromPath returns a uri with the file:// scheme.
-func URIFromPath(path string) URI {
-	if path == "" {
-		return ""
-	}
-	// Handle standard library paths that contain the literal "$GOROOT".
-	// TODO(rstambler): The go/packages API should allow one to determine a user's $GOROOT.
-	const prefix = "$GOROOT"
-	if len(path) >= len(prefix) && strings.EqualFold(prefix, path[:len(prefix)]) {
-		suffix := path[len(prefix):]
-		path = runtime.GOROOT() + suffix
-	}
-	if !isWindowsDrivePath(path) {
-		if abs, err := filepath.Abs(path); err == nil {
-			path = abs
-		}
-	}
-	// Check the file path again, in case it became absolute.
-	if isWindowsDrivePath(path) {
-		path = "/" + strings.ToUpper(string(path[0])) + path[1:]
-	}
-	path = filepath.ToSlash(path)
-	u := url.URL{
-		Scheme: fileScheme,
-		Path:   path,
-	}
-	return URI(u.String())
-}
-
-// isWindowsDrivePath returns true if the file path is of the form used by
-// Windows. We check if the path begins with a drive letter, followed by a ":".
-// For example: C:/x/y/z.
-func isWindowsDrivePath(path string) bool {
-	if len(path) < 3 {
-		return false
-	}
-	return unicode.IsLetter(rune(path[0])) && path[1] == ':'
-}
-
-// isWindowsDriveURIPath returns true if the file URI is of the format used by
-// Windows URIs. The url.Parse package does not specially handle Windows paths
-// (see golang/go#6027), so we check if the URI path has a drive prefix (e.g. "/C:").
-func isWindowsDriveURIPath(uri string) bool {
-	if len(uri) < 4 {
-		return false
-	}
-	return uri[0] == '/' && unicode.IsLetter(rune(uri[1])) && uri[2] == ':'
-}
-
-// Dir returns the URI for the directory containing uri. Dir panics if uri is
-// not a file uri.
-//
-// TODO(rfindley): add a unit test for various edge cases.
-func Dir(uri URI) URI {
-	return URIFromPath(filepath.Dir(uri.Filename()))
-}
diff -urN a/gopls/internal/span/uri_test.go b/gopls/internal/span/uri_test.go
--- a/gopls/internal/span/uri_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/uri_test.go	1969-12-31 16:00:00
@@ -1,117 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !windows
-// +build !windows
-
-package span_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// TestURI tests the conversion between URIs and filenames. The test cases
-// include Windows-style URIs and filepaths, but we avoid having OS-specific
-// tests by using only forward slashes, assuming that the standard library
-// functions filepath.ToSlash and filepath.FromSlash do not need testing.
-func TestURIFromPath(t *testing.T) {
-	for _, test := range []struct {
-		path, wantFile string
-		wantURI        span.URI
-	}{
-		{
-			path:     ``,
-			wantFile: ``,
-			wantURI:  span.URI(""),
-		},
-		{
-			path:     `C:/Windows/System32`,
-			wantFile: `C:/Windows/System32`,
-			wantURI:  span.URI("file:///C:/Windows/System32"),
-		},
-		{
-			path:     `C:/Go/src/bob.go`,
-			wantFile: `C:/Go/src/bob.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob.go"),
-		},
-		{
-			path:     `c:/Go/src/bob.go`,
-			wantFile: `C:/Go/src/bob.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob.go"),
-		},
-		{
-			path:     `/path/to/dir`,
-			wantFile: `/path/to/dir`,
-			wantURI:  span.URI("file:///path/to/dir"),
-		},
-		{
-			path:     `/a/b/c/src/bob.go`,
-			wantFile: `/a/b/c/src/bob.go`,
-			wantURI:  span.URI("file:///a/b/c/src/bob.go"),
-		},
-		{
-			path:     `c:/Go/src/bob george/george/george.go`,
-			wantFile: `C:/Go/src/bob george/george/george.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob%20george/george/george.go"),
-		},
-	} {
-		got := span.URIFromPath(test.path)
-		if got != test.wantURI {
-			t.Errorf("URIFromPath(%q): got %q, expected %q", test.path, got, test.wantURI)
-		}
-		gotFilename := got.Filename()
-		if gotFilename != test.wantFile {
-			t.Errorf("Filename(%q): got %q, expected %q", got, gotFilename, test.wantFile)
-		}
-	}
-}
-
-func TestURIFromURI(t *testing.T) {
-	for _, test := range []struct {
-		inputURI, wantFile string
-		wantURI            span.URI
-	}{
-		{
-			inputURI: `file:///c:/Go/src/bob%20george/george/george.go`,
-			wantFile: `C:/Go/src/bob george/george/george.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob%20george/george/george.go"),
-		},
-		{
-			inputURI: `file:///C%3A/Go/src/bob%20george/george/george.go`,
-			wantFile: `C:/Go/src/bob george/george/george.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob%20george/george/george.go"),
-		},
-		{
-			inputURI: `file:///path/to/%25p%25ercent%25/per%25cent.go`,
-			wantFile: `/path/to/%p%ercent%/per%cent.go`,
-			wantURI:  span.URI(`file:///path/to/%25p%25ercent%25/per%25cent.go`),
-		},
-		{
-			inputURI: `file:///C%3A/`,
-			wantFile: `C:/`,
-			wantURI:  span.URI(`file:///C:/`),
-		},
-		{
-			inputURI: `file:///`,
-			wantFile: `/`,
-			wantURI:  span.URI(`file:///`),
-		},
-		{
-			inputURI: `file://wsl%24/Ubuntu/home/wdcui/repo/VMEnclaves/cvm-runtime`,
-			wantFile: `/wsl$/Ubuntu/home/wdcui/repo/VMEnclaves/cvm-runtime`,
-			wantURI:  span.URI(`file:///wsl$/Ubuntu/home/wdcui/repo/VMEnclaves/cvm-runtime`),
-		},
-	} {
-		got := span.URIFromURI(test.inputURI)
-		if got != test.wantURI {
-			t.Errorf("NewURI(%q): got %q, expected %q", test.inputURI, got, test.wantURI)
-		}
-		gotFilename := got.Filename()
-		if gotFilename != test.wantFile {
-			t.Errorf("Filename(%q): got %q, expected %q", got, gotFilename, test.wantFile)
-		}
-	}
-}
diff -urN a/gopls/internal/span/uri_windows_test.go b/gopls/internal/span/uri_windows_test.go
--- a/gopls/internal/span/uri_windows_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/uri_windows_test.go	1969-12-31 16:00:00
@@ -1,112 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build windows
-// +build windows
-
-package span_test
-
-import (
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// TestURI tests the conversion between URIs and filenames. The test cases
-// include Windows-style URIs and filepaths, but we avoid having OS-specific
-// tests by using only forward slashes, assuming that the standard library
-// functions filepath.ToSlash and filepath.FromSlash do not need testing.
-func TestURIFromPath(t *testing.T) {
-	for _, test := range []struct {
-		path, wantFile string
-		wantURI        span.URI
-	}{
-		{
-			path:     ``,
-			wantFile: ``,
-			wantURI:  span.URI(""),
-		},
-		{
-			path:     `C:\Windows\System32`,
-			wantFile: `C:\Windows\System32`,
-			wantURI:  span.URI("file:///C:/Windows/System32"),
-		},
-		{
-			path:     `C:\Go\src\bob.go`,
-			wantFile: `C:\Go\src\bob.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob.go"),
-		},
-		{
-			path:     `c:\Go\src\bob.go`,
-			wantFile: `C:\Go\src\bob.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob.go"),
-		},
-		{
-			path:     `\path\to\dir`,
-			wantFile: `C:\path\to\dir`,
-			wantURI:  span.URI("file:///C:/path/to/dir"),
-		},
-		{
-			path:     `\a\b\c\src\bob.go`,
-			wantFile: `C:\a\b\c\src\bob.go`,
-			wantURI:  span.URI("file:///C:/a/b/c/src/bob.go"),
-		},
-		{
-			path:     `c:\Go\src\bob george\george\george.go`,
-			wantFile: `C:\Go\src\bob george\george\george.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob%20george/george/george.go"),
-		},
-	} {
-		got := span.URIFromPath(test.path)
-		if got != test.wantURI {
-			t.Errorf("URIFromPath(%q): got %q, expected %q", test.path, got, test.wantURI)
-		}
-		gotFilename := got.Filename()
-		if gotFilename != test.wantFile {
-			t.Errorf("Filename(%q): got %q, expected %q", got, gotFilename, test.wantFile)
-		}
-	}
-}
-
-func TestURIFromURI(t *testing.T) {
-	for _, test := range []struct {
-		inputURI, wantFile string
-		wantURI            span.URI
-	}{
-		{
-			inputURI: `file:///c:/Go/src/bob%20george/george/george.go`,
-			wantFile: `C:\Go\src\bob george\george\george.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob%20george/george/george.go"),
-		},
-		{
-			inputURI: `file:///C%3A/Go/src/bob%20george/george/george.go`,
-			wantFile: `C:\Go\src\bob george\george\george.go`,
-			wantURI:  span.URI("file:///C:/Go/src/bob%20george/george/george.go"),
-		},
-		{
-			inputURI: `file:///c:/path/to/%25p%25ercent%25/per%25cent.go`,
-			wantFile: `C:\path\to\%p%ercent%\per%cent.go`,
-			wantURI:  span.URI(`file:///C:/path/to/%25p%25ercent%25/per%25cent.go`),
-		},
-		{
-			inputURI: `file:///C%3A/`,
-			wantFile: `C:\`,
-			wantURI:  span.URI(`file:///C:/`),
-		},
-		{
-			inputURI: `file:///`,
-			wantFile: `\`,
-			wantURI:  span.URI(`file:///`),
-		},
-	} {
-		got := span.URIFromURI(test.inputURI)
-		if got != test.wantURI {
-			t.Errorf("NewURI(%q): got %q, expected %q", test.inputURI, got, test.wantURI)
-		}
-		gotFilename := got.Filename()
-		if gotFilename != test.wantFile {
-			t.Errorf("Filename(%q): got %q, expected %q", got, gotFilename, test.wantFile)
-		}
-	}
-}
diff -urN a/gopls/internal/span/utf16.go b/gopls/internal/span/utf16.go
--- a/gopls/internal/span/utf16.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/utf16.go	1969-12-31 16:00:00
@@ -1,105 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span
-
-import (
-	"fmt"
-	"unicode/utf8"
-)
-
-// ToUTF16Column calculates the utf16 column expressed by the point given the
-// supplied file contents.
-// This is used to convert from the native (always in bytes) column
-// representation and the utf16 counts used by some editors.
-//
-// TODO(adonovan): this function is unused except by its test. Delete,
-// or consolidate with (*protocol.ColumnMapper).utf16Column.
-func ToUTF16Column(p Point, content []byte) (int, error) {
-	if !p.HasPosition() {
-		return -1, fmt.Errorf("ToUTF16Column: point is missing position")
-	}
-	if !p.HasOffset() {
-		return -1, fmt.Errorf("ToUTF16Column: point is missing offset")
-	}
-	offset := p.Offset()      // 0-based
-	colZero := p.Column() - 1 // 0-based
-	if colZero == 0 {
-		// 0-based column 0, so it must be chr 1
-		return 1, nil
-	} else if colZero < 0 {
-		return -1, fmt.Errorf("ToUTF16Column: column is invalid (%v)", colZero)
-	}
-	// work out the offset at the start of the line using the column
-	lineOffset := offset - colZero
-	if lineOffset < 0 || offset > len(content) {
-		return -1, fmt.Errorf("ToUTF16Column: offsets %v-%v outside file contents (%v)", lineOffset, offset, len(content))
-	}
-	// Use the offset to pick out the line start.
-	// This cannot panic: offset > len(content) and lineOffset < offset.
-	start := content[lineOffset:]
-
-	// Now, truncate down to the supplied column.
-	start = start[:colZero]
-
-	cnt := 0
-	for _, r := range string(start) {
-		cnt++
-		if r > 0xffff {
-			cnt++
-		}
-	}
-	return cnt + 1, nil // the +1 is for 1-based columns
-}
-
-// FromUTF16Column advances the point by the utf16 character offset given the
-// supplied line contents.
-// This is used to convert from the utf16 counts used by some editors to the
-// native (always in bytes) column representation.
-//
-// The resulting Point always has an offset.
-//
-// TODO: it looks like this may incorrectly confer a "position" to the
-// resulting Point, when it shouldn't. If p.HasPosition() == false, the
-// resulting Point will return p.HasPosition() == true, but have the wrong
-// position.
-func FromUTF16Column(p Point, chr int, content []byte) (Point, error) {
-	if !p.HasOffset() {
-		return Point{}, fmt.Errorf("FromUTF16Column: point is missing offset")
-	}
-	// if chr is 1 then no adjustment needed
-	if chr <= 1 {
-		return p, nil
-	}
-	if p.Offset() >= len(content) {
-		return p, fmt.Errorf("FromUTF16Column: offset (%v) greater than length of content (%v)", p.Offset(), len(content))
-	}
-	remains := content[p.Offset():]
-	// scan forward the specified number of characters
-	for count := 1; count < chr; count++ {
-		if len(remains) <= 0 {
-			return Point{}, fmt.Errorf("FromUTF16Column: chr goes beyond the content")
-		}
-		r, w := utf8.DecodeRune(remains)
-		if r == '\n' {
-			// Per the LSP spec:
-			//
-			// > If the character value is greater than the line length it
-			// > defaults back to the line length.
-			break
-		}
-		remains = remains[w:]
-		if r >= 0x10000 {
-			// a two point rune
-			count++
-			// if we finished in a two point rune, do not advance past the first
-			if count >= chr {
-				break
-			}
-		}
-		p.v.Column += w
-		p.v.Offset += w
-	}
-	return p, nil
-}
diff -urN a/gopls/internal/span/utf16_test.go b/gopls/internal/span/utf16_test.go
--- a/gopls/internal/span/utf16_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/span/utf16_test.go	1969-12-31 16:00:00
@@ -1,322 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package span_test
-
-import (
-	"strings"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-// The funny character below is 4 bytes long in UTF-8; two UTF-16 code points
-var funnyString = []byte("𐐀23\n𐐀45")
-
-var toUTF16Tests = []struct {
-	scenario    string
-	input       []byte
-	line        int    // 1-indexed count
-	col         int    // 1-indexed byte position in line
-	offset      int    // 0-indexed byte offset into input
-	resUTF16col int    // 1-indexed UTF-16 col number
-	pre         string // everything before the cursor on the line
-	post        string // everything from the cursor onwards
-	err         string // expected error string in call to ToUTF16Column
-	issue       *bool
-}{
-	{
-		scenario: "cursor missing content",
-		input:    nil,
-		err:      "ToUTF16Column: point is missing position",
-	},
-	{
-		scenario: "cursor missing position",
-		input:    funnyString,
-		line:     -1,
-		col:      -1,
-		err:      "ToUTF16Column: point is missing position",
-	},
-	{
-		scenario: "cursor missing offset",
-		input:    funnyString,
-		line:     1,
-		col:      1,
-		offset:   -1,
-		err:      "ToUTF16Column: point is missing offset",
-	},
-	{
-		scenario:    "zero length input; cursor at first col, first line",
-		input:       []byte(""),
-		line:        1,
-		col:         1,
-		offset:      0,
-		resUTF16col: 1,
-	},
-	{
-		scenario:    "cursor before funny character; first line",
-		input:       funnyString,
-		line:        1,
-		col:         1,
-		offset:      0,
-		resUTF16col: 1,
-		pre:         "",
-		post:        "𐐀23",
-	},
-	{
-		scenario:    "cursor after funny character; first line",
-		input:       funnyString,
-		line:        1,
-		col:         5, // 4 + 1 (1-indexed)
-		offset:      4,
-		resUTF16col: 3, // 2 + 1 (1-indexed)
-		pre:         "𐐀",
-		post:        "23",
-	},
-	{
-		scenario:    "cursor after last character on first line",
-		input:       funnyString,
-		line:        1,
-		col:         7, // 4 + 1 + 1 + 1 (1-indexed)
-		offset:      6, // 4 + 1 + 1
-		resUTF16col: 5, // 2 + 1 + 1 + 1 (1-indexed)
-		pre:         "𐐀23",
-		post:        "",
-	},
-	{
-		scenario:    "cursor before funny character; second line",
-		input:       funnyString,
-		line:        2,
-		col:         1,
-		offset:      7, // length of first line
-		resUTF16col: 1,
-		pre:         "",
-		post:        "𐐀45",
-	},
-	{
-		scenario:    "cursor after funny character; second line",
-		input:       funnyString,
-		line:        1,
-		col:         5,  // 4 + 1 (1-indexed)
-		offset:      11, // 7 (length of first line) + 4
-		resUTF16col: 3,  // 2 + 1 (1-indexed)
-		pre:         "𐐀",
-		post:        "45",
-	},
-	{
-		scenario:    "cursor after last character on second line",
-		input:       funnyString,
-		line:        2,
-		col:         7,  // 4 + 1 + 1 + 1 (1-indexed)
-		offset:      13, // 7 (length of first line) + 4 + 1 + 1
-		resUTF16col: 5,  // 2 + 1 + 1 + 1 (1-indexed)
-		pre:         "𐐀45",
-		post:        "",
-	},
-	{
-		scenario: "cursor beyond end of file",
-		input:    funnyString,
-		line:     2,
-		col:      8,  // 4 + 1 + 1 + 1 + 1 (1-indexed)
-		offset:   14, // 4 + 1 + 1 + 1
-		err:      "ToUTF16Column: offsets 7-14 outside file contents (13)",
-	},
-}
-
-var fromUTF16Tests = []struct {
-	scenario  string
-	input     []byte
-	line      int    // 1-indexed line number (isn't actually used)
-	offset    int    // 0-indexed byte offset to beginning of line
-	utf16col  int    // 1-indexed UTF-16 col number
-	resCol    int    // 1-indexed byte position in line
-	resOffset int    // 0-indexed byte offset into input
-	pre       string // everything before the cursor on the line
-	post      string // everything from the cursor onwards
-	err       string // expected error string in call to ToUTF16Column
-}{
-	{
-		scenario:  "zero length input; cursor at first col, first line",
-		input:     []byte(""),
-		line:      1,
-		offset:    0,
-		utf16col:  1,
-		resCol:    1,
-		resOffset: 0,
-		pre:       "",
-		post:      "",
-	},
-	{
-		scenario: "missing offset",
-		input:    funnyString,
-		line:     1,
-		offset:   -1,
-		err:      "FromUTF16Column: point is missing offset",
-	},
-	{
-		scenario:  "cursor before funny character",
-		input:     funnyString,
-		line:      1,
-		utf16col:  1,
-		resCol:    1,
-		resOffset: 0,
-		pre:       "",
-		post:      "𐐀23",
-	},
-	{
-		scenario:  "cursor after funny character",
-		input:     funnyString,
-		line:      1,
-		utf16col:  3,
-		resCol:    5,
-		resOffset: 4,
-		pre:       "𐐀",
-		post:      "23",
-	},
-	{
-		scenario:  "cursor after last character on line",
-		input:     funnyString,
-		line:      1,
-		utf16col:  5,
-		resCol:    7,
-		resOffset: 6,
-		pre:       "𐐀23",
-		post:      "",
-	},
-	{
-		scenario:  "cursor beyond last character on line",
-		input:     funnyString,
-		line:      1,
-		offset:    0,
-		utf16col:  6,
-		resCol:    7,
-		resOffset: 6,
-		pre:       "𐐀23",
-		post:      "",
-	},
-	{
-		scenario:  "cursor before funny character; second line",
-		input:     funnyString,
-		line:      2,
-		offset:    7, // length of first line
-		utf16col:  1,
-		resCol:    1,
-		resOffset: 7,
-		pre:       "",
-		post:      "𐐀45",
-	},
-	{
-		scenario:  "cursor after funny character; second line",
-		input:     funnyString,
-		line:      2,
-		offset:    7,  // length of first line
-		utf16col:  3,  // 2 + 1 (1-indexed)
-		resCol:    5,  // 4 + 1 (1-indexed)
-		resOffset: 11, // 7 (length of first line) + 4
-		pre:       "𐐀",
-		post:      "45",
-	},
-	{
-		scenario:  "cursor after last character on second line",
-		input:     funnyString,
-		line:      2,
-		offset:    7,  // length of first line
-		utf16col:  5,  // 2 + 1 + 1 + 1 (1-indexed)
-		resCol:    7,  // 4 + 1 + 1 + 1 (1-indexed)
-		resOffset: 13, // 7 (length of first line) + 4 + 1 + 1
-		pre:       "𐐀45",
-		post:      "",
-	},
-	{
-		scenario:  "cursor beyond end of file",
-		input:     funnyString,
-		line:      2,
-		offset:    7,
-		utf16col:  6,  // 2 + 1 + 1 + 1 + 1(1-indexed)
-		resCol:    8,  // 4 + 1 + 1 + 1 + 1 (1-indexed)
-		resOffset: 14, // 7 (length of first line) + 4 + 1 + 1 + 1
-		err:       "FromUTF16Column: chr goes beyond the content",
-	},
-	{
-		scenario: "offset beyond end of file",
-		input:    funnyString,
-		line:     2,
-		offset:   14,
-		utf16col: 2,
-		err:      "FromUTF16Column: offset (14) greater than length of content (13)",
-	},
-}
-
-func TestToUTF16(t *testing.T) {
-	for _, e := range toUTF16Tests {
-		t.Run(e.scenario, func(t *testing.T) {
-			if e.issue != nil && !*e.issue {
-				t.Skip("expected to fail")
-			}
-			p := span.NewPoint(e.line, e.col, e.offset)
-			got, err := span.ToUTF16Column(p, e.input)
-			if err != nil {
-				if err.Error() != e.err {
-					t.Fatalf("expected error %v; got %v", e.err, err)
-				}
-				return
-			}
-			if e.err != "" {
-				t.Fatalf("unexpected success; wanted %v", e.err)
-			}
-			if got != e.resUTF16col {
-				t.Fatalf("expected result %v; got %v", e.resUTF16col, got)
-			}
-			pre, post := getPrePost(e.input, p.Offset())
-			if string(pre) != e.pre {
-				t.Fatalf("expected #%d pre %q; got %q", p.Offset(), e.pre, pre)
-			}
-			if string(post) != e.post {
-				t.Fatalf("expected #%d, post %q; got %q", p.Offset(), e.post, post)
-			}
-		})
-	}
-}
-
-func TestFromUTF16(t *testing.T) {
-	for _, e := range fromUTF16Tests {
-		t.Run(e.scenario, func(t *testing.T) {
-			p := span.NewPoint(e.line, 1, e.offset)
-			p, err := span.FromUTF16Column(p, e.utf16col, []byte(e.input))
-			if err != nil {
-				if err.Error() != e.err {
-					t.Fatalf("expected error %v; got %v", e.err, err)
-				}
-				return
-			}
-			if e.err != "" {
-				t.Fatalf("unexpected success; wanted %v", e.err)
-			}
-			if p.Column() != e.resCol {
-				t.Fatalf("expected resulting col %v; got %v", e.resCol, p.Column())
-			}
-			if p.Offset() != e.resOffset {
-				t.Fatalf("expected resulting offset %v; got %v", e.resOffset, p.Offset())
-			}
-			pre, post := getPrePost(e.input, p.Offset())
-			if string(pre) != e.pre {
-				t.Fatalf("expected #%d pre %q; got %q", p.Offset(), e.pre, pre)
-			}
-			if string(post) != e.post {
-				t.Fatalf("expected #%d post %q; got %q", p.Offset(), e.post, post)
-			}
-		})
-	}
-}
-
-func getPrePost(content []byte, offset int) (string, string) {
-	pre, post := string(content)[:offset], string(content)[offset:]
-	if i := strings.LastIndex(pre, "\n"); i >= 0 {
-		pre = pre[i+1:]
-	}
-	if i := strings.IndexRune(post, '\n'); i >= 0 {
-		post = post[:i]
-	}
-	return pre, post
-}
diff -urN a/gopls/internal/vulncheck/command.go b/gopls/internal/vulncheck/command.go
--- a/gopls/internal/vulncheck/command.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/command.go	1969-12-31 16:00:00
@@ -1,373 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package vulncheck
-
-import (
-	"context"
-	"encoding/json"
-	"errors"
-	"fmt"
-	"log"
-	"os"
-	"regexp"
-	"sort"
-	"strings"
-	"sync"
-
-	"golang.org/x/mod/semver"
-	"golang.org/x/sync/errgroup"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/vuln/client"
-	gvcapi "golang.org/x/vuln/exp/govulncheck"
-	"golang.org/x/vuln/osv"
-	"golang.org/x/vuln/vulncheck"
-)
-
-func init() {
-	VulnerablePackages = vulnerablePackages
-}
-
-func findGOVULNDB(env []string) []string {
-	for _, kv := range env {
-		if strings.HasPrefix(kv, "GOVULNDB=") {
-			return strings.Split(kv[len("GOVULNDB="):], ",")
-		}
-	}
-	if GOVULNDB := os.Getenv("GOVULNDB"); GOVULNDB != "" {
-		return strings.Split(GOVULNDB, ",")
-	}
-	return []string{"https://vuln.go.dev"}
-}
-
-// GoVersionForVulnTest is an internal environment variable used in gopls
-// testing to examine govulncheck behavior with a go version different
-// than what `go version` returns in the system.
-const GoVersionForVulnTest = "_GOPLS_TEST_VULNCHECK_GOVERSION"
-
-func init() {
-	Main = func(cfg packages.Config, patterns ...string) error {
-		// Set the mode that Source needs.
-		cfg.Mode = packages.NeedName | packages.NeedImports | packages.NeedTypes |
-			packages.NeedSyntax | packages.NeedTypesInfo | packages.NeedDeps |
-			packages.NeedModule
-		logf := log.New(os.Stderr, "", log.Ltime).Printf
-		logf("Loading packages...")
-		pkgs, err := packages.Load(&cfg, patterns...)
-		if err != nil {
-			logf("Failed to load packages: %v", err)
-			return err
-		}
-		if n := packages.PrintErrors(pkgs); n > 0 {
-			err := errors.New("failed to load packages due to errors")
-			logf("%v", err)
-			return err
-		}
-		logf("Loaded %d packages and their dependencies", len(pkgs))
-		cli, err := client.NewClient(findGOVULNDB(cfg.Env), client.Options{
-			HTTPCache: govulncheck.DefaultCache(),
-		})
-		if err != nil {
-			return err
-		}
-		res, err := gvcapi.Source(context.Background(), &gvcapi.Config{
-			Client:    cli,
-			GoVersion: os.Getenv(GoVersionForVulnTest),
-		}, vulncheck.Convert(pkgs))
-		if err != nil {
-			return err
-		}
-		affecting := 0
-		for _, v := range res.Vulns {
-			if v.IsCalled() {
-				affecting++
-			}
-		}
-		logf("Found %d affecting vulns and %d unaffecting vulns in imported packages", affecting, len(res.Vulns)-affecting)
-		if err := json.NewEncoder(os.Stdout).Encode(res); err != nil {
-			return err
-		}
-		return nil
-	}
-}
-
-var (
-	// Regexp for matching go tags. The groups are:
-	// 1  the major.minor version
-	// 2  the patch version, or empty if none
-	// 3  the entire prerelease, if present
-	// 4  the prerelease type ("beta" or "rc")
-	// 5  the prerelease number
-	tagRegexp = regexp.MustCompile(`^go(\d+\.\d+)(\.\d+|)((beta|rc|-pre)(\d+))?$`)
-)
-
-// This is a modified copy of pkgsite/internal/stdlib:VersionForTag.
-func GoTagToSemver(tag string) string {
-	if tag == "" {
-		return ""
-	}
-
-	tag = strings.Fields(tag)[0]
-	// Special cases for go1.
-	if tag == "go1" {
-		return "v1.0.0"
-	}
-	if tag == "go1.0" {
-		return ""
-	}
-	m := tagRegexp.FindStringSubmatch(tag)
-	if m == nil {
-		return ""
-	}
-	version := "v" + m[1]
-	if m[2] != "" {
-		version += m[2]
-	} else {
-		version += ".0"
-	}
-	if m[3] != "" {
-		if !strings.HasPrefix(m[4], "-") {
-			version += "-"
-		}
-		version += m[4] + "." + m[5]
-	}
-	return version
-}
-
-// semverToGoTag returns the Go standard library repository tag corresponding
-// to semver, a version string without the initial "v".
-// Go tags differ from standard semantic versions in a few ways,
-// such as beginning with "go" instead of "v".
-func semverToGoTag(v string) string {
-	if strings.HasPrefix(v, "v0.0.0") {
-		return "master"
-	}
-	// Special case: v1.0.0 => go1.
-	if v == "v1.0.0" {
-		return "go1"
-	}
-	if !semver.IsValid(v) {
-		return fmt.Sprintf("<!%s:invalid semver>", v)
-	}
-	goVersion := semver.Canonical(v)
-	prerelease := semver.Prerelease(goVersion)
-	versionWithoutPrerelease := strings.TrimSuffix(goVersion, prerelease)
-	patch := strings.TrimPrefix(versionWithoutPrerelease, semver.MajorMinor(goVersion)+".")
-	if patch == "0" {
-		versionWithoutPrerelease = strings.TrimSuffix(versionWithoutPrerelease, ".0")
-	}
-	goVersion = fmt.Sprintf("go%s", strings.TrimPrefix(versionWithoutPrerelease, "v"))
-	if prerelease != "" {
-		// Go prereleases look like  "beta1" instead of "beta.1".
-		// "beta1" is bad for sorting (since beta10 comes before beta9), so
-		// require the dot form.
-		i := finalDigitsIndex(prerelease)
-		if i >= 1 {
-			if prerelease[i-1] != '.' {
-				return fmt.Sprintf("<!%s:final digits in a prerelease must follow a period>", v)
-			}
-			// Remove the dot.
-			prerelease = prerelease[:i-1] + prerelease[i:]
-		}
-		goVersion += strings.TrimPrefix(prerelease, "-")
-	}
-	return goVersion
-}
-
-// finalDigitsIndex returns the index of the first digit in the sequence of digits ending s.
-// If s doesn't end in digits, it returns -1.
-func finalDigitsIndex(s string) int {
-	// Assume ASCII (since the semver package does anyway).
-	var i int
-	for i = len(s) - 1; i >= 0; i-- {
-		if s[i] < '0' || s[i] > '9' {
-			break
-		}
-	}
-	if i == len(s)-1 {
-		return -1
-	}
-	return i + 1
-}
-
-// vulnerablePackages queries the vulndb and reports which vulnerabilities
-// apply to this snapshot. The result contains a set of packages,
-// grouped by vuln ID and by module.
-func vulnerablePackages(ctx context.Context, snapshot source.Snapshot, modfile source.FileHandle) (*govulncheck.Result, error) {
-	// We want to report the intersection of vulnerable packages in the vulndb
-	// and packages transitively imported by this module ('go list -deps all').
-	// We use snapshot.AllMetadata to retrieve the list of packages
-	// as an approximation.
-	//
-	// TODO(hyangah): snapshot.AllMetadata is a superset of
-	// `go list all` - e.g. when the workspace has multiple main modules
-	// (multiple go.mod files), that can include packages that are not
-	// used by this module. Vulncheck behavior with go.work is not well
-	// defined. Figure out the meaning, and if we decide to present
-	// the result as if each module is analyzed independently, make
-	// gopls track a separate build list for each module and use that
-	// information instead of snapshot.AllMetadata.
-	metadata, err := snapshot.AllMetadata(ctx)
-	if err != nil {
-		return nil, err
-	}
-
-	// TODO(hyangah): handle vulnerabilities in the standard library.
-
-	// Group packages by modules since vuln db is keyed by module.
-	metadataByModule := map[source.PackagePath][]*source.Metadata{}
-	for _, md := range metadata {
-		mi := md.Module
-		modulePath := source.PackagePath("stdlib")
-		if mi != nil {
-			modulePath = source.PackagePath(mi.Path)
-		}
-		metadataByModule[modulePath] = append(metadataByModule[modulePath], md)
-	}
-
-	// Request vuln entries from remote service.
-	cli, err := client.NewClient(
-		findGOVULNDB(snapshot.View().Options().EnvSlice()),
-		client.Options{HTTPCache: govulncheck.NewInMemoryCache(govulncheck.DefaultCache())})
-	if err != nil {
-		return nil, err
-	}
-	// Keys are osv.Entry.IDs
-	vulnsResult := map[string]*govulncheck.Vuln{}
-	var (
-		group errgroup.Group
-		mu    sync.Mutex
-	)
-
-	goVersion := snapshot.View().Options().Env[GoVersionForVulnTest]
-	if goVersion == "" {
-		goVersion = snapshot.View().GoVersionString()
-	}
-	group.SetLimit(10)
-	stdlibModule := &packages.Module{
-		Path:    "stdlib",
-		Version: goVersion,
-	}
-	for path, mds := range metadataByModule {
-		path, mds := path, mds
-		group.Go(func() error {
-			effectiveModule := stdlibModule
-			if m := mds[0].Module; m != nil {
-				effectiveModule = m
-			}
-			for effectiveModule.Replace != nil {
-				effectiveModule = effectiveModule.Replace
-			}
-			ver := effectiveModule.Version
-
-			// TODO(go.dev/issues/56312): batch these requests for efficiency.
-			vulns, err := cli.GetByModule(ctx, effectiveModule.Path)
-			if err != nil {
-				return err
-			}
-			if len(vulns) == 0 { // No known vulnerability.
-				return nil
-			}
-
-			// set of packages in this module known to gopls.
-			// This will be lazily initialized when we need it.
-			var knownPkgs map[source.PackagePath]bool
-
-			// Report vulnerabilities that affect packages of this module.
-			for _, entry := range vulns {
-				var vulnerablePkgs []*govulncheck.Package
-
-				for _, a := range entry.Affected {
-					if a.Package.Ecosystem != osv.GoEcosystem || a.Package.Name != effectiveModule.Path {
-						continue
-					}
-					if !a.Ranges.AffectsSemver(ver) {
-						continue
-					}
-					for _, imp := range a.EcosystemSpecific.Imports {
-						if knownPkgs == nil {
-							knownPkgs = toPackagePathSet(mds)
-						}
-						if knownPkgs[source.PackagePath(imp.Path)] {
-							vulnerablePkgs = append(vulnerablePkgs, &govulncheck.Package{
-								Path: imp.Path,
-							})
-						}
-					}
-				}
-				if len(vulnerablePkgs) == 0 {
-					continue
-				}
-				mu.Lock()
-				vuln, ok := vulnsResult[entry.ID]
-				if !ok {
-					vuln = &govulncheck.Vuln{OSV: entry}
-					vulnsResult[entry.ID] = vuln
-				}
-				vuln.Modules = append(vuln.Modules, &govulncheck.Module{
-					Path:         string(path),
-					FoundVersion: ver,
-					FixedVersion: fixedVersion(effectiveModule.Path, entry.Affected),
-					Packages:     vulnerablePkgs,
-				})
-				mu.Unlock()
-			}
-			return nil
-		})
-	}
-	if err := group.Wait(); err != nil {
-		return nil, err
-	}
-
-	vulns := make([]*govulncheck.Vuln, 0, len(vulnsResult))
-	for _, v := range vulnsResult {
-		vulns = append(vulns, v)
-	}
-	// Sort so the results are deterministic.
-	sort.Slice(vulns, func(i, j int) bool {
-		return vulns[i].OSV.ID < vulns[j].OSV.ID
-	})
-	ret := &govulncheck.Result{
-		Vulns: vulns,
-		Mode:  govulncheck.ModeImports,
-	}
-	return ret, nil
-}
-
-// toPackagePathSet transforms the metadata to a set of package paths.
-func toPackagePathSet(mds []*source.Metadata) map[source.PackagePath]bool {
-	pkgPaths := make(map[source.PackagePath]bool, len(mds))
-	for _, md := range mds {
-		pkgPaths[md.PkgPath] = true
-	}
-	return pkgPaths
-}
-
-func fixedVersion(modulePath string, affected []osv.Affected) string {
-	fixed := govulncheck.LatestFixed(modulePath, affected)
-	if fixed != "" {
-		fixed = versionString(modulePath, fixed)
-	}
-	return fixed
-}
-
-// versionString prepends a version string prefix (`v` or `go`
-// depending on the modulePath) to the given semver-style version string.
-func versionString(modulePath, version string) string {
-	if version == "" {
-		return ""
-	}
-	v := "v" + version
-	// These are internal Go module paths used by the vuln DB
-	// when listing vulns in standard library and the go command.
-	if modulePath == "stdlib" || modulePath == "toolchain" {
-		return semverToGoTag(v)
-	}
-	return v
-}
diff -urN a/gopls/internal/vulncheck/vulncheck.go b/gopls/internal/vulncheck/vulncheck.go
--- a/gopls/internal/vulncheck/vulncheck.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulncheck.go	1969-12-31 16:00:00
@@ -1,25 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Package vulncheck provides an analysis command
-// that runs vulnerability analysis using data from
-// golang.org/x/vuln/vulncheck.
-// This package requires go1.18 or newer.
-package vulncheck
-
-import (
-	"context"
-
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/govulncheck"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-)
-
-// With go1.18+, this is swapped with the real implementation.
-var Main func(cfg packages.Config, patterns ...string) error = nil
-
-// VulnerablePackages queries the vulndb and reports which vulnerabilities
-// apply to this snapshot. The result contains a set of packages,
-// grouped by vuln ID and by module.
-var VulnerablePackages func(ctx context.Context, snapshot source.Snapshot, modfile source.FileHandle) (*govulncheck.Result, error) = nil
diff -urN a/gopls/internal/vulncheck/vulntest/db.go b/gopls/internal/vulncheck/vulntest/db.go
--- a/gopls/internal/vulncheck/vulntest/db.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/db.go	1969-12-31 16:00:00
@@ -1,303 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-// Package vulntest provides helpers for vulncheck functionality testing.
-package vulntest
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"sort"
-	"strings"
-	"time"
-
-	"golang.org/x/tools/gopls/internal/span"
-	"golang.org/x/tools/txtar"
-	"golang.org/x/vuln/client"
-	"golang.org/x/vuln/osv"
-)
-
-// NewDatabase returns a read-only DB containing the provided
-// txtar-format collection of vulnerability reports.
-// Each vulnerability report is a YAML file whose format
-// is defined in golang.org/x/vulndb/doc/format.md.
-// A report file name must have the id as its base name,
-// and have .yaml as its extension.
-//
-//	db, err := NewDatabase(ctx, reports)
-//	...
-//	defer db.Clean()
-//	client, err := NewClient(db)
-//	...
-//
-// The returned DB's Clean method must be called to clean up the
-// generated database.
-func NewDatabase(ctx context.Context, txtarReports []byte) (*DB, error) {
-	disk, err := ioutil.TempDir("", "vulndb-test")
-	if err != nil {
-		return nil, err
-	}
-	if err := generateDB(ctx, txtarReports, disk, false); err != nil {
-		os.RemoveAll(disk)
-		return nil, err
-	}
-
-	return &DB{disk: disk}, nil
-}
-
-// DB is a read-only vulnerability database on disk.
-// Users can use this database with golang.org/x/vuln APIs
-// by setting the `VULNDB“ environment variable.
-type DB struct {
-	disk string
-}
-
-// URI returns the file URI that can be used for VULNDB environment
-// variable.
-func (db *DB) URI() string {
-	u := span.URIFromPath(db.disk)
-	return string(u)
-}
-
-// Clean deletes the database.
-func (db *DB) Clean() error {
-	return os.RemoveAll(db.disk)
-}
-
-// NewClient returns a vuln DB client that works with the given DB.
-func NewClient(db *DB) (client.Client, error) {
-	return client.NewClient([]string{db.URI()}, client.Options{})
-}
-
-//
-// The following was selectively copied from golang.org/x/vulndb/internal/database
-//
-
-const (
-	dbURL = "https://pkg.go.dev/vuln/"
-
-	// idDirectory is the name of the directory that contains entries
-	// listed by their IDs.
-	idDirectory = "ID"
-
-	// stdFileName is the name of the .json file in the vulndb repo
-	// that will contain info on standard library vulnerabilities.
-	stdFileName = "stdlib"
-
-	// toolchainFileName is the name of the .json file in the vulndb repo
-	// that will contain info on toolchain (cmd/...) vulnerabilities.
-	toolchainFileName = "toolchain"
-
-	// cmdModule is the name of the module containing Go toolchain
-	// binaries.
-	cmdModule = "cmd"
-
-	// stdModule is the name of the module containing Go std packages.
-	stdModule = "std"
-)
-
-// generateDB generates the file-based vuln DB in the directory jsonDir.
-func generateDB(ctx context.Context, txtarData []byte, jsonDir string, indent bool) error {
-	archive := txtar.Parse(txtarData)
-
-	jsonVulns, entries, err := generateEntries(ctx, archive)
-	if err != nil {
-		return err
-	}
-
-	index := make(client.DBIndex, len(jsonVulns))
-	for modulePath, vulns := range jsonVulns {
-		epath, err := client.EscapeModulePath(modulePath)
-		if err != nil {
-			return err
-		}
-		if err := writeVulns(filepath.Join(jsonDir, epath), vulns, indent); err != nil {
-			return err
-		}
-		for _, v := range vulns {
-			if v.Modified.After(index[modulePath]) {
-				index[modulePath] = v.Modified
-			}
-		}
-	}
-	if err := writeJSON(filepath.Join(jsonDir, "index.json"), index, indent); err != nil {
-		return err
-	}
-	if err := writeAliasIndex(jsonDir, entries, indent); err != nil {
-		return err
-	}
-	return writeEntriesByID(filepath.Join(jsonDir, idDirectory), entries, indent)
-}
-
-func generateEntries(_ context.Context, archive *txtar.Archive) (map[string][]osv.Entry, []osv.Entry, error) {
-	now := time.Now()
-	jsonVulns := map[string][]osv.Entry{}
-	var entries []osv.Entry
-	for _, f := range archive.Files {
-		if !strings.HasSuffix(f.Name, ".yaml") {
-			continue
-		}
-		r, err := readReport(bytes.NewReader(f.Data))
-		if err != nil {
-			return nil, nil, err
-		}
-		name := strings.TrimSuffix(filepath.Base(f.Name), filepath.Ext(f.Name))
-		linkName := fmt.Sprintf("%s%s", dbURL, name)
-		entry, modulePaths := generateOSVEntry(name, linkName, now, *r)
-		for _, modulePath := range modulePaths {
-			jsonVulns[modulePath] = append(jsonVulns[modulePath], entry)
-		}
-		entries = append(entries, entry)
-	}
-	return jsonVulns, entries, nil
-}
-
-func writeVulns(outPath string, vulns []osv.Entry, indent bool) error {
-	if err := os.MkdirAll(filepath.Dir(outPath), 0755); err != nil {
-		return fmt.Errorf("failed to create directory %q: %s", filepath.Dir(outPath), err)
-	}
-	return writeJSON(outPath+".json", vulns, indent)
-}
-
-func writeEntriesByID(idDir string, entries []osv.Entry, indent bool) error {
-	// Write a directory containing entries by ID.
-	if err := os.MkdirAll(idDir, 0755); err != nil {
-		return fmt.Errorf("failed to create directory %q: %v", idDir, err)
-	}
-	var idIndex []string
-	for _, e := range entries {
-		outPath := filepath.Join(idDir, e.ID+".json")
-		if err := writeJSON(outPath, e, indent); err != nil {
-			return err
-		}
-		idIndex = append(idIndex, e.ID)
-	}
-	// Write an index.json in the ID directory with a list of all the IDs.
-	return writeJSON(filepath.Join(idDir, "index.json"), idIndex, indent)
-}
-
-// Write a JSON file containing a map from alias to GO IDs.
-func writeAliasIndex(dir string, entries []osv.Entry, indent bool) error {
-	aliasToGoIDs := map[string][]string{}
-	for _, e := range entries {
-		for _, a := range e.Aliases {
-			aliasToGoIDs[a] = append(aliasToGoIDs[a], e.ID)
-		}
-	}
-	return writeJSON(filepath.Join(dir, "aliases.json"), aliasToGoIDs, indent)
-}
-
-func writeJSON(filename string, value any, indent bool) (err error) {
-	j, err := jsonMarshal(value, indent)
-	if err != nil {
-		return err
-	}
-	return os.WriteFile(filename, j, 0644)
-}
-
-func jsonMarshal(v any, indent bool) ([]byte, error) {
-	if indent {
-		return json.MarshalIndent(v, "", "  ")
-	}
-	return json.Marshal(v)
-}
-
-// generateOSVEntry create an osv.Entry for a report. In addition to the report, it
-// takes the ID for the vuln and a URL that will point to the entry in the vuln DB.
-// It returns the osv.Entry and a list of module paths that the vuln affects.
-func generateOSVEntry(id, url string, lastModified time.Time, r Report) (osv.Entry, []string) {
-	entry := osv.Entry{
-		ID:        id,
-		Published: r.Published,
-		Modified:  lastModified,
-		Withdrawn: r.Withdrawn,
-		Details:   r.Description,
-	}
-
-	moduleMap := make(map[string]bool)
-	for _, m := range r.Modules {
-		switch m.Module {
-		case stdModule:
-			moduleMap[stdFileName] = true
-		case cmdModule:
-			moduleMap[toolchainFileName] = true
-		default:
-			moduleMap[m.Module] = true
-		}
-		entry.Affected = append(entry.Affected, generateAffected(m, url))
-	}
-	for _, ref := range r.References {
-		entry.References = append(entry.References, osv.Reference{
-			Type: string(ref.Type),
-			URL:  ref.URL,
-		})
-	}
-
-	var modulePaths []string
-	for module := range moduleMap {
-		modulePaths = append(modulePaths, module)
-	}
-	// TODO: handle missing fields - Aliases
-
-	return entry, modulePaths
-}
-
-func generateAffectedRanges(versions []VersionRange) osv.Affects {
-	a := osv.AffectsRange{Type: osv.TypeSemver}
-	if len(versions) == 0 || versions[0].Introduced == "" {
-		a.Events = append(a.Events, osv.RangeEvent{Introduced: "0"})
-	}
-	for _, v := range versions {
-		if v.Introduced != "" {
-			a.Events = append(a.Events, osv.RangeEvent{Introduced: v.Introduced.Canonical()})
-		}
-		if v.Fixed != "" {
-			a.Events = append(a.Events, osv.RangeEvent{Fixed: v.Fixed.Canonical()})
-		}
-	}
-	return osv.Affects{a}
-}
-
-func generateImports(m *Module) (imps []osv.EcosystemSpecificImport) {
-	for _, p := range m.Packages {
-		syms := append([]string{}, p.Symbols...)
-		syms = append(syms, p.DerivedSymbols...)
-		sort.Strings(syms)
-		imps = append(imps, osv.EcosystemSpecificImport{
-			Path:    p.Package,
-			GOOS:    p.GOOS,
-			GOARCH:  p.GOARCH,
-			Symbols: syms,
-		})
-	}
-	return imps
-}
-func generateAffected(m *Module, url string) osv.Affected {
-	name := m.Module
-	switch name {
-	case stdModule:
-		name = "stdlib"
-	case cmdModule:
-		name = "toolchain"
-	}
-	return osv.Affected{
-		Package: osv.Package{
-			Name:      name,
-			Ecosystem: osv.GoEcosystem,
-		},
-		Ranges:           generateAffectedRanges(m.Versions),
-		DatabaseSpecific: osv.DatabaseSpecific{URL: url},
-		EcosystemSpecific: osv.EcosystemSpecific{
-			Imports: generateImports(m),
-		},
-	}
-}
diff -urN a/gopls/internal/vulncheck/vulntest/db_test.go b/gopls/internal/vulncheck/vulntest/db_test.go
--- a/gopls/internal/vulncheck/vulntest/db_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/db_test.go	1969-12-31 16:00:00
@@ -1,61 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package vulntest
-
-import (
-	"context"
-	"encoding/json"
-	"testing"
-)
-
-func TestNewDatabase(t *testing.T) {
-	ctx := context.Background()
-	in := []byte(`
--- GO-2020-0001.yaml --
-modules:
-  - module: github.com/gin-gonic/gin
-    versions:
-      - fixed: 1.6.0
-    packages:
-      - package: github.com/gin-gonic/gin
-        symbols:
-          - defaultLogFormatter
-description: |
-    Something.
-published: 2021-04-14T20:04:52Z
-references:
-  - fix: https://github.com/gin-gonic/gin/pull/2237
-`)
-
-	db, err := NewDatabase(ctx, in)
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer db.Clean()
-
-	cli, err := NewClient(db)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, err := cli.GetByID(ctx, "GO-2020-0001")
-	if err != nil {
-		t.Fatal(err)
-	}
-	if got.ID != "GO-2020-0001" {
-		m, _ := json.Marshal(got)
-		t.Errorf("got %s\nwant GO-2020-0001 entry", m)
-	}
-	gotAll, err := cli.GetByModule(ctx, "github.com/gin-gonic/gin")
-	if err != nil {
-		t.Fatal(err)
-	}
-	if len(gotAll) != 1 || gotAll[0].ID != "GO-2020-0001" {
-		m, _ := json.Marshal(got)
-		t.Errorf("got %s\nwant GO-2020-0001 entry", m)
-	}
-}
diff -urN a/gopls/internal/vulncheck/vulntest/report.go b/gopls/internal/vulncheck/vulntest/report.go
--- a/gopls/internal/vulncheck/vulntest/report.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/report.go	1969-12-31 16:00:00
@@ -1,176 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package vulntest
-
-import (
-	"fmt"
-	"io"
-	"os"
-	"strings"
-	"time"
-
-	"golang.org/x/mod/semver"
-	"gopkg.in/yaml.v3"
-)
-
-//
-// The following was selectively copied from golang.org/x/vulndb/internal/report
-//
-
-// readReport reads a Report in YAML format.
-func readReport(in io.Reader) (*Report, error) {
-	d := yaml.NewDecoder(in)
-	// Require that all fields in the file are in the struct.
-	// This corresponds to v2's UnmarshalStrict.
-	d.KnownFields(true)
-	var r Report
-	if err := d.Decode(&r); err != nil {
-		return nil, fmt.Errorf("yaml.Decode: %v", err)
-	}
-	return &r, nil
-}
-
-// Report represents a vulnerability report in the vulndb.
-// Remember to update doc/format.md when this structure changes.
-type Report struct {
-	Modules []*Module `yaml:",omitempty"`
-
-	// Description is the CVE description from an existing CVE. If we are
-	// assigning a CVE ID ourselves, use CVEMetadata.Description instead.
-	Description string     `yaml:",omitempty"`
-	Published   time.Time  `yaml:",omitempty"`
-	Withdrawn   *time.Time `yaml:",omitempty"`
-
-	References []*Reference `yaml:",omitempty"`
-}
-
-// Write writes r to filename in YAML format.
-func (r *Report) Write(filename string) (err error) {
-	f, err := os.Create(filename)
-	if err != nil {
-		return err
-	}
-	err = r.encode(f)
-	err2 := f.Close()
-	if err == nil {
-		err = err2
-	}
-	return err
-}
-
-// ToString encodes r to a YAML string.
-func (r *Report) ToString() (string, error) {
-	var b strings.Builder
-	if err := r.encode(&b); err != nil {
-		return "", err
-	}
-	return b.String(), nil
-}
-
-func (r *Report) encode(w io.Writer) error {
-	e := yaml.NewEncoder(w)
-	defer e.Close()
-	e.SetIndent(4)
-	return e.Encode(r)
-}
-
-type VersionRange struct {
-	Introduced Version `yaml:"introduced,omitempty"`
-	Fixed      Version `yaml:"fixed,omitempty"`
-}
-
-type Module struct {
-	Module   string         `yaml:",omitempty"`
-	Versions []VersionRange `yaml:",omitempty"`
-	Packages []*Package     `yaml:",omitempty"`
-}
-
-type Package struct {
-	Package string   `yaml:",omitempty"`
-	GOOS    []string `yaml:"goos,omitempty"`
-	GOARCH  []string `yaml:"goarch,omitempty"`
-	// Symbols originally identified as vulnerable.
-	Symbols []string `yaml:",omitempty"`
-	// Additional vulnerable symbols, computed from Symbols via static analysis
-	// or other technique.
-	DerivedSymbols []string `yaml:"derived_symbols,omitempty"`
-}
-
-// Version is an SemVer 2.0.0 semantic version with no leading "v" prefix,
-// as used by OSV.
-type Version string
-
-// V returns the version with a "v" prefix.
-func (v Version) V() string {
-	return "v" + string(v)
-}
-
-// IsValid reports whether v is a valid semantic version string.
-func (v Version) IsValid() bool {
-	return semver.IsValid(v.V())
-}
-
-// Before reports whether v < v2.
-func (v Version) Before(v2 Version) bool {
-	return semver.Compare(v.V(), v2.V()) < 0
-}
-
-// Canonical returns the canonical formatting of the version.
-func (v Version) Canonical() string {
-	return strings.TrimPrefix(semver.Canonical(v.V()), "v")
-}
-
-// Reference type is a reference (link) type.
-type ReferenceType string
-
-const (
-	ReferenceTypeAdvisory = ReferenceType("ADVISORY")
-	ReferenceTypeArticle  = ReferenceType("ARTICLE")
-	ReferenceTypeReport   = ReferenceType("REPORT")
-	ReferenceTypeFix      = ReferenceType("FIX")
-	ReferenceTypePackage  = ReferenceType("PACKAGE")
-	ReferenceTypeEvidence = ReferenceType("EVIDENCE")
-	ReferenceTypeWeb      = ReferenceType("WEB")
-)
-
-// ReferenceTypes is the set of reference types defined in OSV.
-var ReferenceTypes = []ReferenceType{
-	ReferenceTypeAdvisory,
-	ReferenceTypeArticle,
-	ReferenceTypeReport,
-	ReferenceTypeFix,
-	ReferenceTypePackage,
-	ReferenceTypeEvidence,
-	ReferenceTypeWeb,
-}
-
-// A Reference is a link to some external resource.
-//
-// For ease of typing, References are represented in the YAML as a
-// single-element mapping of type to URL.
-type Reference struct {
-	Type ReferenceType `json:"type,omitempty"`
-	URL  string        `json:"url,omitempty"`
-}
-
-func (r *Reference) MarshalYAML() (interface{}, error) {
-	return map[string]string{
-		strings.ToLower(string(r.Type)): r.URL,
-	}, nil
-}
-
-func (r *Reference) UnmarshalYAML(n *yaml.Node) (err error) {
-	if n.Kind != yaml.MappingNode || len(n.Content) != 2 || n.Content[0].Kind != yaml.ScalarNode || n.Content[1].Kind != yaml.ScalarNode {
-		return &yaml.TypeError{Errors: []string{
-			fmt.Sprintf("line %d: report.Reference must contain a mapping with one value", n.Line),
-		}}
-	}
-	r.Type = ReferenceType(strings.ToUpper(n.Content[0].Value))
-	r.URL = n.Content[1].Value
-	return nil
-}
diff -urN a/gopls/internal/vulncheck/vulntest/report_test.go b/gopls/internal/vulncheck/vulntest/report_test.go
--- a/gopls/internal/vulncheck/vulntest/report_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/report_test.go	1969-12-31 16:00:00
@@ -1,52 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package vulntest
-
-import (
-	"bytes"
-	"io"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-)
-
-func readAll(t *testing.T, filename string) io.Reader {
-	d, err := ioutil.ReadFile(filename)
-	if err != nil {
-		t.Fatal(err)
-	}
-	return bytes.NewReader(d)
-}
-
-func TestRoundTrip(t *testing.T) {
-	// A report shouldn't change after being read and then written.
-	in := filepath.Join("testdata", "report.yaml")
-	r, err := readReport(readAll(t, in))
-	if err != nil {
-		t.Fatal(err)
-	}
-	out := filepath.Join(t.TempDir(), "report.yaml")
-	if err := r.Write(out); err != nil {
-		t.Fatal(err)
-	}
-
-	want, err := os.ReadFile(in)
-	if err != nil {
-		t.Fatal(err)
-	}
-	got, err := os.ReadFile(out)
-	if err != nil {
-		t.Fatal(err)
-	}
-	if diff := cmp.Diff(want, got); diff != "" {
-		t.Errorf("mismatch (-want, +got):\n%s", diff)
-	}
-}
diff -urN a/gopls/internal/vulncheck/vulntest/stdlib.go b/gopls/internal/vulncheck/vulntest/stdlib.go
--- a/gopls/internal/vulncheck/vulntest/stdlib.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/stdlib.go	1969-12-31 16:00:00
@@ -1,26 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package vulntest
-
-import (
-	"strings"
-
-	"golang.org/x/mod/module"
-)
-
-// maybeStdlib reports whether the given import path could be part of the Go
-// standard library, by reporting whether the first component lacks a '.'.
-func maybeStdlib(path string) bool {
-	if err := module.CheckImportPath(path); err != nil {
-		return false
-	}
-	if i := strings.IndexByte(path, '/'); i != -1 {
-		path = path[:i]
-	}
-	return !strings.Contains(path, ".")
-}
diff -urN a/gopls/internal/vulncheck/vulntest/stdlib_test.go b/gopls/internal/vulncheck/vulntest/stdlib_test.go
--- a/gopls/internal/vulncheck/vulntest/stdlib_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/stdlib_test.go	1969-12-31 16:00:00
@@ -1,27 +0,0 @@
-// Copyright 2022 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build go1.18
-// +build go1.18
-
-package vulntest
-
-import "testing"
-
-func TestMaybeStdlib(t *testing.T) {
-	for _, test := range []struct {
-		in   string
-		want bool
-	}{
-		{"", false},
-		{"math/crypto", true},
-		{"github.com/pkg/errors", false},
-		{"Path is unknown", false},
-	} {
-		got := maybeStdlib(test.in)
-		if got != test.want {
-			t.Errorf("%q: got %t, want %t", test.in, got, test.want)
-		}
-	}
-}
diff -urN a/gopls/internal/vulncheck/vulntest/testdata/report.yaml b/gopls/internal/vulncheck/vulntest/testdata/report.yaml
--- a/gopls/internal/vulncheck/vulntest/testdata/report.yaml	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/internal/vulncheck/vulntest/testdata/report.yaml	1969-12-31 16:00:00
@@ -1,15 +0,0 @@
-modules:
-    - module: github.com/gin-gonic/gin
-      versions:
-        - fixed: 1.6.0
-      packages:
-        - package: github.com/gin-gonic/gin
-          symbols:
-            - defaultLogFormatter
-description: |
-    The default Formatter for the Logger middleware (LoggerConfig.Formatter),
-    which is included in the Default engine, allows attackers to inject arbitrary
-    log entries by manipulating the request path.
-references:
-    - fix: https://github.com/gin-gonic/gin/pull/1234
-    - fix: https://github.com/gin-gonic/gin/commit/abcdefg
diff -urN a/gopls/main.go b/gopls/main.go
--- a/gopls/main.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/main.go	1969-12-31 16:00:00
@@ -1,33 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-// Gopls (pronounced “go please”) is an LSP server for Go.
-// The Language Server Protocol allows any text editor
-// to be extended with IDE-like features;
-// see https://langserver.org/ for details.
-//
-// See https://github.com/golang/tools/blob/master/gopls/README.md
-// for the most up-to-date documentation.
-package main // import "golang.org/x/tools/gopls"
-
-//go:generate go run doc/generate.go
-
-import (
-	"context"
-	"golang.org/x/tools/internal/analysisinternal"
-	"os"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	"golang.org/x/tools/gopls/internal/lsp/cmd"
-	"golang.org/x/tools/internal/tool"
-)
-
-func main() {
-	// In 1.18, diagnostics for Fuzz tests must not be used by cmd/vet.
-	// So the code for Fuzz tests diagnostics is guarded behind flag analysisinternal.DiagnoseFuzzTests
-	// Turn on analysisinternal.DiagnoseFuzzTests for gopls
-	analysisinternal.DiagnoseFuzzTests = true
-	ctx := context.Background()
-	tool.Main(ctx, cmd.New("gopls", "", nil, hooks.Options), os.Args[1:])
-}
diff -urN a/gopls/release/release.go b/gopls/release/release.go
--- a/gopls/release/release.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/release/release.go	1969-12-31 16:00:00
@@ -1,217 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-//
-// Package release checks that the a given version of gopls is ready for
-// release. It can also tag and publish the release.
-//
-// To run:
-//
-// $ cd $GOPATH/src/golang.org/x/tools/gopls
-// $ go run release/release.go -version=<version>
-package main
-
-import (
-	"flag"
-	"fmt"
-	"go/types"
-	"io/ioutil"
-	"log"
-	"os"
-	"os/user"
-	"path/filepath"
-	"strconv"
-	"strings"
-
-	exec "golang.org/x/sys/execabs"
-
-	"golang.org/x/mod/modfile"
-	"golang.org/x/mod/semver"
-	"golang.org/x/tools/go/packages"
-)
-
-var (
-	versionFlag = flag.String("version", "", "version to tag")
-	remoteFlag  = flag.String("remote", "", "remote to which to push the tag")
-	releaseFlag = flag.Bool("release", false, "release is true if you intend to tag and push a release")
-)
-
-func main() {
-	flag.Parse()
-
-	if *versionFlag == "" {
-		log.Fatalf("must provide -version flag")
-	}
-	if !semver.IsValid(*versionFlag) {
-		log.Fatalf("invalid version %s", *versionFlag)
-	}
-	if semver.Major(*versionFlag) != "v0" {
-		log.Fatalf("expected major version v0, got %s", semver.Major(*versionFlag))
-	}
-	if semver.Build(*versionFlag) != "" {
-		log.Fatalf("unexpected build suffix: %s", *versionFlag)
-	}
-	if *releaseFlag && *remoteFlag == "" {
-		log.Fatalf("must provide -remote flag if releasing")
-	}
-	user, err := user.Current()
-	if err != nil {
-		log.Fatal(err)
-	}
-	// Validate that the user is running the program from the gopls module.
-	wd, err := os.Getwd()
-	if err != nil {
-		log.Fatal(err)
-	}
-	if filepath.Base(wd) != "gopls" {
-		log.Fatalf("must run from the gopls module")
-	}
-	// Confirm that they are running on a branch with a name following the
-	// format of "gopls-release-branch.<major>.<minor>".
-	if err := validateBranchName(*versionFlag); err != nil {
-		log.Fatal(err)
-	}
-	// Confirm that they have updated the hardcoded version.
-	if err := validateHardcodedVersion(*versionFlag); err != nil {
-		log.Fatal(err)
-	}
-	// Confirm that the versions in the go.mod file are correct.
-	if err := validateGoModFile(wd); err != nil {
-		log.Fatal(err)
-	}
-	earlyExitMsg := "Validated that the release is ready. Exiting without tagging and publishing."
-	if !*releaseFlag {
-		fmt.Println(earlyExitMsg)
-		os.Exit(0)
-	}
-	fmt.Println(`Proceeding to tagging and publishing the release...
-Please enter Y if you wish to proceed or anything else if you wish to exit.`)
-	// Accept and process user input.
-	var input string
-	fmt.Scanln(&input)
-	switch input {
-	case "Y":
-		fmt.Println("Proceeding to tagging and publishing the release.")
-	default:
-		fmt.Println(earlyExitMsg)
-		os.Exit(0)
-	}
-	// To tag the release:
-	// $ git -c user.email=username@google.com tag -a -m “<message>” gopls/v<major>.<minor>.<patch>-<pre-release>
-	goplsVersion := fmt.Sprintf("gopls/%s", *versionFlag)
-	cmd := exec.Command("git", "-c", fmt.Sprintf("user.email=%s@google.com", user.Username), "tag", "-a", "-m", fmt.Sprintf("%q", goplsVersion), goplsVersion)
-	if err := cmd.Run(); err != nil {
-		log.Fatal(err)
-	}
-	// Push the tag to the remote:
-	// $ git push <remote> gopls/v<major>.<minor>.<patch>-pre.1
-	cmd = exec.Command("git", "push", *remoteFlag, goplsVersion)
-	if err := cmd.Run(); err != nil {
-		log.Fatal(err)
-	}
-}
-
-// validateBranchName reports whether the user's current branch name is of the
-// form "gopls-release-branch.<major>.<minor>". It reports an error if not.
-func validateBranchName(version string) error {
-	cmd := exec.Command("git", "branch", "--show-current")
-	stdout, err := cmd.Output()
-	if err != nil {
-		return err
-	}
-	branch := strings.TrimSpace(string(stdout))
-	expectedBranch := fmt.Sprintf("gopls-release-branch.%s", strings.TrimPrefix(semver.MajorMinor(version), "v"))
-	if branch != expectedBranch {
-		return fmt.Errorf("expected release branch %s, got %s", expectedBranch, branch)
-	}
-	return nil
-}
-
-// validateHardcodedVersion reports whether the version hardcoded in the gopls
-// binary is equivalent to the version being published. It reports an error if
-// not.
-func validateHardcodedVersion(version string) error {
-	const debugPkg = "golang.org/x/tools/gopls/internal/lsp/debug"
-	pkgs, err := packages.Load(&packages.Config{
-		Mode: packages.NeedName | packages.NeedFiles |
-			packages.NeedCompiledGoFiles | packages.NeedImports |
-			packages.NeedTypes | packages.NeedTypesSizes,
-	}, debugPkg)
-	if err != nil {
-		return err
-	}
-	if len(pkgs) != 1 {
-		return fmt.Errorf("expected 1 package, got %v", len(pkgs))
-	}
-	pkg := pkgs[0]
-	if len(pkg.Errors) > 0 {
-		return fmt.Errorf("failed to load %q: first error: %w", debugPkg, pkg.Errors[0])
-	}
-	obj := pkg.Types.Scope().Lookup("Version")
-	c, ok := obj.(*types.Const)
-	if !ok {
-		return fmt.Errorf("no constant named Version")
-	}
-	hardcodedVersion, err := strconv.Unquote(c.Val().ExactString())
-	if err != nil {
-		return err
-	}
-	if semver.Prerelease(hardcodedVersion) != "" {
-		return fmt.Errorf("unexpected pre-release for hardcoded version: %s", hardcodedVersion)
-	}
-	// Don't worry about pre-release tags and expect that there is no build
-	// suffix.
-	version = strings.TrimSuffix(version, semver.Prerelease(version))
-	if hardcodedVersion != version {
-		return fmt.Errorf("expected version to be %s, got %s", *versionFlag, hardcodedVersion)
-	}
-	return nil
-}
-
-func validateGoModFile(goplsDir string) error {
-	filename := filepath.Join(goplsDir, "go.mod")
-	data, err := ioutil.ReadFile(filename)
-	if err != nil {
-		return err
-	}
-	gomod, err := modfile.Parse(filename, data, nil)
-	if err != nil {
-		return err
-	}
-	// Confirm that there is no replace directive in the go.mod file.
-	if len(gomod.Replace) > 0 {
-		return fmt.Errorf("expected no replace directives, got %v", len(gomod.Replace))
-	}
-	// Confirm that the version of x/tools in the gopls/go.mod file points to
-	// the second-to-last commit. (The last commit will be the one to update the
-	// go.mod file.)
-	cmd := exec.Command("git", "rev-parse", "@~")
-	stdout, err := cmd.Output()
-	if err != nil {
-		return err
-	}
-	hash := string(stdout)
-	// Find the golang.org/x/tools require line and compare the versions.
-	var version string
-	for _, req := range gomod.Require {
-		if req.Mod.Path == "golang.org/x/tools" {
-			version = req.Mod.Version
-			break
-		}
-	}
-	if version == "" {
-		return fmt.Errorf("no require for golang.org/x/tools")
-	}
-	split := strings.Split(version, "-")
-	if len(split) != 3 {
-		return fmt.Errorf("unexpected pseudoversion format %s", version)
-	}
-	last := split[len(split)-1]
-	if last == "" {
-		return fmt.Errorf("unexpected pseudoversion format %s", version)
-	}
-	if !strings.HasPrefix(hash, last) {
-		return fmt.Errorf("golang.org/x/tools pseudoversion should be at commit %s, instead got %s", hash, last)
-	}
-	return nil
-}
diff -urN a/gopls/test/debug/debug_test.go b/gopls/test/debug/debug_test.go
--- a/gopls/test/debug/debug_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/test/debug/debug_test.go	1969-12-31 16:00:00
@@ -1,181 +0,0 @@
-// Copyright 2020 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package debug_test
-
-// Provide 'static type checking' of the templates. This guards against changes is various
-// gopls datastructures causing template execution to fail. The checking is done by
-// the github.com/jba/templatecheck pacakge. Before that is run, the test checks that
-// its list of templates and their arguments corresponds to the arguments in
-// calls to render(). The test assumes that all uses of templates are done through render().
-
-import (
-	"go/ast"
-	"html/template"
-	"log"
-	"runtime"
-	"sort"
-	"strings"
-	"testing"
-
-	"github.com/jba/templatecheck"
-	"golang.org/x/tools/go/packages"
-	"golang.org/x/tools/gopls/internal/lsp/cache"
-	"golang.org/x/tools/gopls/internal/lsp/debug"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/span"
-)
-
-type tdata struct {
-	tmpl *template.Template
-	data interface{} // a value of the needed type
-}
-
-var templates = map[string]tdata{
-	"MainTmpl":    {debug.MainTmpl, &debug.Instance{}},
-	"DebugTmpl":   {debug.DebugTmpl, nil},
-	"RPCTmpl":     {debug.RPCTmpl, &debug.Rpcs{}},
-	"TraceTmpl":   {debug.TraceTmpl, debug.TraceResults{}},
-	"CacheTmpl":   {debug.CacheTmpl, &cache.Cache{}},
-	"SessionTmpl": {debug.SessionTmpl, &cache.Session{}},
-	"ViewTmpl":    {debug.ViewTmpl, &cache.View{}},
-	"ClientTmpl":  {debug.ClientTmpl, &debug.Client{}},
-	"ServerTmpl":  {debug.ServerTmpl, &debug.Server{}},
-	//"FileTmpl":    {FileTmpl, source.Overlay{}}, // need to construct a source.Overlay in init
-	"InfoTmpl":   {debug.InfoTmpl, "something"},
-	"MemoryTmpl": {debug.MemoryTmpl, runtime.MemStats{}},
-}
-
-// construct a source.Overlay for fileTmpl
-type fakeOverlay struct{}
-
-func (fakeOverlay) Version() int32 {
-	return 0
-}
-func (fakeOverlay) Session() string {
-	return ""
-}
-func (fakeOverlay) VersionedFileIdentity() source.VersionedFileIdentity {
-	return source.VersionedFileIdentity{}
-}
-func (fakeOverlay) FileIdentity() source.FileIdentity {
-	return source.FileIdentity{}
-}
-func (fakeOverlay) Kind() source.FileKind {
-	return 0
-}
-func (fakeOverlay) Read() ([]byte, error) {
-	return nil, nil
-}
-func (fakeOverlay) Saved() bool {
-	return true
-}
-func (fakeOverlay) URI() span.URI {
-	return ""
-}
-
-var _ source.Overlay = fakeOverlay{}
-
-func init() {
-	log.SetFlags(log.Lshortfile)
-	var v fakeOverlay
-	templates["FileTmpl"] = tdata{debug.FileTmpl, v}
-}
-
-func TestTemplates(t *testing.T) {
-	if runtime.GOOS == "android" {
-		t.Skip("this test is not supported for Android")
-	}
-	cfg := &packages.Config{
-		Mode: packages.NeedTypesInfo | packages.LoadAllSyntax, // figure out what's necessary PJW
-	}
-	pkgs, err := packages.Load(cfg, "golang.org/x/tools/gopls/internal/lsp/debug")
-	if err != nil {
-		t.Fatal(err)
-	}
-	if len(pkgs) != 1 {
-		t.Fatalf("expected a single package, but got %d", len(pkgs))
-	}
-	p := pkgs[0]
-	if len(p.Errors) != 0 {
-		t.Fatalf("compiler error, e.g. %v", p.Errors[0])
-	}
-	// find the calls to render in serve.go
-	tree := treeOf(p, "serve.go")
-	if tree == nil {
-		t.Fatalf("found no syntax tree for %s", "serve.go")
-	}
-	renders := callsOf(p, tree, "render")
-	if len(renders) == 0 {
-		t.Fatalf("found no calls to render")
-	}
-	var found = make(map[string]bool)
-	for _, r := range renders {
-		if len(r.Args) != 2 {
-			// template, func
-			t.Fatalf("got %d args, expected 2", len(r.Args))
-		}
-		t0, ok := p.TypesInfo.Types[r.Args[0]]
-		if !ok || !t0.IsValue() || t0.Type.String() != "*html/template.Template" {
-			t.Fatalf("no type info for template")
-		}
-		if id, ok := r.Args[0].(*ast.Ident); !ok {
-			t.Errorf("expected *ast.Ident, got %T", r.Args[0])
-		} else {
-			found[id.Name] = true
-		}
-	}
-	// make sure found and templates have the same templates
-	for k := range found {
-		if _, ok := templates[k]; !ok {
-			t.Errorf("code has template %s, but test does not", k)
-		}
-	}
-	for k := range templates {
-		if _, ok := found[k]; !ok {
-			t.Errorf("test has template %s, code does not", k)
-		}
-	}
-	// now check all the known templates, in alphabetic order, for determinacy
-	keys := []string{}
-	for k := range templates {
-		keys = append(keys, k)
-	}
-	sort.Strings(keys)
-	for _, k := range keys {
-		v := templates[k]
-		// the FuncMap is an annoyance; should not be necessary
-		if err := templatecheck.CheckHTML(v.tmpl, v.data); err != nil {
-			t.Errorf("%s: %v", k, err)
-		}
-	}
-}
-
-func callsOf(p *packages.Package, tree *ast.File, name string) []*ast.CallExpr {
-	var ans []*ast.CallExpr
-	f := func(n ast.Node) bool {
-		x, ok := n.(*ast.CallExpr)
-		if !ok {
-			return true
-		}
-		if y, ok := x.Fun.(*ast.Ident); ok {
-			if y.Name == name {
-				ans = append(ans, x)
-			}
-		}
-		return true
-	}
-	ast.Inspect(tree, f)
-	return ans
-}
-func treeOf(p *packages.Package, fname string) *ast.File {
-	for _, tree := range p.Syntax {
-		loc := tree.Package
-		pos := p.Fset.PositionFor(loc, false)
-		if strings.HasSuffix(pos.Filename, fname) {
-			return tree
-		}
-	}
-	return nil
-}
diff -urN a/gopls/test/gopls_test.go b/gopls/test/gopls_test.go
--- a/gopls/test/gopls_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/test/gopls_test.go	1969-12-31 16:00:00
@@ -1,42 +0,0 @@
-// Copyright 2019 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package gopls_test
-
-import (
-	"os"
-	"testing"
-
-	"golang.org/x/tools/gopls/internal/hooks"
-	cmdtest "golang.org/x/tools/gopls/internal/lsp/cmd/test"
-	"golang.org/x/tools/gopls/internal/lsp/source"
-	"golang.org/x/tools/gopls/internal/lsp/tests"
-	"golang.org/x/tools/internal/bug"
-	"golang.org/x/tools/internal/event"
-	"golang.org/x/tools/internal/testenv"
-)
-
-func TestMain(m *testing.M) {
-	bug.PanicOnBugs = true
-	testenv.ExitIfSmallMachine()
-
-	// Set the global exporter to nil so that we don't log to stderr. This avoids
-	// a lot of misleading noise in test output.
-	//
-	// See also ../internal/lsp/lsp_test.go.
-	event.SetExporter(nil)
-
-	os.Exit(m.Run())
-}
-
-func TestCommandLine(t *testing.T) {
-	cmdtest.TestCommandLine(t, "../internal/lsp/testdata", commandLineOptions)
-}
-
-func commandLineOptions(options *source.Options) {
-	options.Staticcheck = true
-	options.GoDiff = false // workaround for golang/go#57290   TODO(pjw): fix
-	tests.DefaultOptions(options)
-	hooks.Options(options)
-}
diff -urN a/gopls/test/json_test.go b/gopls/test/json_test.go
--- a/gopls/test/json_test.go	2000-01-01 00:00:00.000000000 -0000
+++ b/gopls/test/json_test.go	1969-12-31 16:00:00
@@ -1,134 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package gopls_test
-
-import (
-	"encoding/json"
-	"fmt"
-	"regexp"
-	"strings"
-	"testing"
-
-	"github.com/google/go-cmp/cmp"
-	"golang.org/x/tools/gopls/internal/lsp/protocol"
-)
-
-// verify that type errors in Initialize lsp messages don't cause
-// any other unmarshalling errors. The code looks at single values and the
-// first component of array values. Each occurrence is replaced by something
-// of a different type,  the resulting string unmarshalled, and compared to
-// the unmarshalling of the unchanged strings. The test passes if there is no
-// more than a single difference reported. That is, if changing a single value
-// in the message changes no more than a single value in the unmarshalled struct,
-// it is safe to ignore *json.UnmarshalTypeError.
-
-// strings are changed to numbers or bools (true)
-// bools are changed to numbers or strings
-// numbers are changed to strings or bools
-
-// a recent Initialize message taken from a log
-const input = `{"processId":38349,"clientInfo":{"name":"vscode","version":"1.56.0-insider"},"rootPath":"/Users/pjw/latest/tools","rootUri":"file:///Users/pjw/latest/tools","capabilities":{"workspace":{"applyEdit":true,"workspaceEdit":{"documentChanges":true,"resourceOperations":["create","rename","delete"],"failureHandling":"textOnlyTransactional"},"didChangeConfiguration":{"dynamicRegistration":true},"didChangeWatchedFiles":{"dynamicRegistration":true},"symbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"tagSupport":{"valueSet":[1]}},"executeCommand":{"dynamicRegistration":true},"configuration":true,"workspaceFolders":true,"semanticTokens":{"refreshSupport":true}},"textDocument":{"publishDiagnostics":{"relatedInformation":true,"versionSupport":false,"tagSupport":{"valueSet":[1,2]},"codeDescriptionSupport":true,"dataSupport":true},"synchronization":{"dynamicRegistration":true,"willSave":true,"willSaveWaitUntil":true,"didSave":true},"completion":{"dynamicRegistration":true,"contextSupport":true,"completionItem":{"snippetSupport":true,"commitCharactersSupport":true,"documentationFormat":["markdown","plaintext"],"deprecatedSupport":true,"preselectSupport":true,"tagSupport":{"valueSet":[1]},"insertReplaceSupport":true,"resolveSupport":{"properties":["documentation","detail","additionalTextEdits"]}},"completionItemKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]}},"hover":{"dynamicRegistration":true,"contentFormat":["markdown","plaintext"]},"signatureHelp":{"dynamicRegistration":true,"signatureInformation":{"documentationFormat":["markdown","plaintext"],"parameterInformation":{"labelOffsetSupport":true},"activeParameterSupport":true},"contextSupport":true},"definition":{"dynamicRegistration":true,"linkSupport":true},"references":{"dynamicRegistration":true},"documentHighlight":{"dynamicRegistration":true},"documentSymbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"hierarchicalDocumentSymbolSupport":true,"tagSupport":{"valueSet":[1]},"labelSupport":true},"codeAction":{"dynamicRegistration":true,"isPreferredSupport":true,"disabledSupport":true,"dataSupport":true,"resolveSupport":{"properties":["edit"]},"codeActionLiteralSupport":{"codeActionKind":{"valueSet":["","quickfix","refactor","refactor.extract","refactor.inline","refactor.rewrite","source","source.organizeImports"]}}},"codeLens":{"dynamicRegistration":true},"formatting":{"dynamicRegistration":true},"rangeFormatting":{"dynamicRegistration":true},"onTypeFormatting":{"dynamicRegistration":true},"rename":{"dynamicRegistration":true,"prepareSupport":true,"prepareSupportDefaultBehavior":true},"documentLink":{"dynamicRegistration":true,"tooltipSupport":true},"typeDefinition":{"dynamicRegistration":true,"linkSupport":true},"implementation":{"dynamicRegistration":true,"linkSupport":true},"colorProvider":{"dynamicRegistration":true},"foldingRange":{"dynamicRegistration":true,"rangeLimit":5000,"lineFoldingOnly":true},"declaration":{"dynamicRegistration":true,"linkSupport":true},"selectionRange":{"dynamicRegistration":true},"callHierarchy":{"dynamicRegistration":true},"semanticTokens":{"dynamicRegistration":true,"tokenTypes":["namespace","type","class","enum","interface","struct","typeParameter","parameter","variable","property","enumMember","event","function","member","macro","keyword","modifier","comment","string","number","regexp","operator"],"tokenModifiers":["declaration","definition","readonly","static","deprecated","abstract","async","modification","documentation","defaultLibrary"],"formats":["relative"],"requests":{"range":true,"full":{"delta":true}}}},"window":{"workDoneProgress":true}},"initializationOptions":{"usePlaceholders":true,"completionDocumentation":true,"verboseOutput":false,"codelenses":{"gc_details":true},"analyses":{"fillstruct":true,"staticcheck":true},"experimentalWorkspaceModule":true,"semanticTokens":true},"trace":"off","workspaceFolders":[{"uri":"file:///Users/pjw/latest/tools","name":"tools"}]}`
-
-type DiffReporter struct {
-	path  cmp.Path
-	diffs []string
-}
-
-func (r *DiffReporter) PushStep(ps cmp.PathStep) {
-	r.path = append(r.path, ps)
-}
-
-func (r *DiffReporter) Report(rs cmp.Result) {
-	if !rs.Equal() {
-		vx, vy := r.path.Last().Values()
-		r.diffs = append(r.diffs, fmt.Sprintf("%#v:\n\t-: %+v\n\t+: %+v\n", r.path, vx, vy))
-	}
-}
-
-func (r *DiffReporter) PopStep() {
-	r.path = r.path[:len(r.path)-1]
-}
-
-func (r *DiffReporter) String() string {
-	return strings.Join(r.diffs, "\n")
-}
-
-func TestStringChanges(t *testing.T) {
-	// string as value
-	stringLeaf := regexp.MustCompile(`:("[^"]*")`)
-	leafs := stringLeaf.FindAllStringSubmatchIndex(input, -1)
-	allDeltas(t, leafs, "23", "true")
-	// string as first element of array
-	stringArray := regexp.MustCompile(`[[]("[^"]*")`)
-	arrays := stringArray.FindAllStringSubmatchIndex(input, -1)
-	allDeltas(t, arrays, "23", "true")
-}
-
-func TestBoolChanges(t *testing.T) {
-	boolLeaf := regexp.MustCompile(`:(true|false)(,|})`)
-	leafs := boolLeaf.FindAllStringSubmatchIndex(input, -1)
-	allDeltas(t, leafs, "23", `"xx"`)
-	boolArray := regexp.MustCompile(`:[[](true|false)(,|])`)
-	arrays := boolArray.FindAllStringSubmatchIndex(input, -1)
-	allDeltas(t, arrays, "23", `"xx"`)
-}
-
-func TestNumberChanges(t *testing.T) {
-	numLeaf := regexp.MustCompile(`:(\d+)(,|})`)
-	leafs := numLeaf.FindAllStringSubmatchIndex(input, -1)
-	allDeltas(t, leafs, "true", `"xx"`)
-	numArray := regexp.MustCompile(`:[[](\d+)(,|])`)
-	arrays := numArray.FindAllStringSubmatchIndex(input, -1)
-	allDeltas(t, arrays, "true", `"xx"`)
-}
-
-// v is a set of matches. check that substituting any repl never
-// creates more than 1 unmarshaling error
-func allDeltas(t *testing.T, v [][]int, repls ...string) {
-	t.Helper()
-	for _, repl := range repls {
-		for i, x := range v {
-			err := tryChange(x[2], x[3], repl)
-			if err != nil {
-				t.Errorf("%d:%q %v", i, input[x[2]:x[3]], err)
-			}
-		}
-	}
-}
-
-func tryChange(start, end int, repl string) error {
-	var p, q protocol.ParamInitialize
-	mod := input[:start] + repl + input[end:]
-	excerpt := func() (string, string) {
-		a := start - 5
-		if a < 0 {
-			a = 0
-		}
-		b := end + 5
-		if b > len(input) {
-			// trusting repl to be no longer than what it replaces
-			b = len(input)
-		}
-		ma := input[a:b]
-		mb := mod[a:b]
-		return ma, mb
-	}
-	if err := json.Unmarshal([]byte(input), &p); err != nil {
-		return fmt.Errorf("%s %v", repl, err)
-	}
-	if err := json.Unmarshal([]byte(mod), &q); err == nil {
-		return nil // no errors is ok
-	} else if _, ok := err.(*json.UnmarshalTypeError); !ok {
-		return fmt.Errorf("%T, not *json.UnmarshalTypeError", err)
-	}
-
-	var r DiffReporter
-	cmp.Diff(p, q, cmp.Reporter(&r))
-	if len(r.diffs) > 1 { // 0 is possible, e.g., for interface{}
-		ma, mb := excerpt()
-		return fmt.Errorf("got %d diffs for %q\n%s\n%s", len(r.diffs), repl, ma, mb)
-	}
-	return nil
-}
